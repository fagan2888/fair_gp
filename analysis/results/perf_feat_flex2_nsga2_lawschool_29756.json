[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 29756,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.5382851473972052,
            "auditor_fn_violation": 0.008106694560669462,
            "auditor_fp_violation": 0.029226291535289845,
            "ave_precision_score": 0.504633418703085,
            "fpr": 0.15570175438596492,
            "logloss": 0.6969388873728263,
            "mae": 0.5015468645121968,
            "precision": 0.4409448818897638,
            "recall": 0.23430962343096234
        },
        "train": {
            "accuracy": 0.43249176728869376,
            "auc_prc": 0.5379792647994821,
            "auditor_fn_violation": 0.013513638166572898,
            "auditor_fp_violation": 0.020364131874787087,
            "ave_precision_score": 0.4981620130684767,
            "fpr": 0.18111964873765093,
            "logloss": 0.6979511769034012,
            "mae": 0.5020077951522349,
            "precision": 0.4290657439446367,
            "recall": 0.2605042016806723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 29756,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.5382851473972052,
            "auditor_fn_violation": 0.008106694560669462,
            "auditor_fp_violation": 0.029226291535289845,
            "ave_precision_score": 0.504633418703085,
            "fpr": 0.15570175438596492,
            "logloss": 0.6968166750496253,
            "mae": 0.5015299465964761,
            "precision": 0.4409448818897638,
            "recall": 0.23430962343096234
        },
        "train": {
            "accuracy": 0.43249176728869376,
            "auc_prc": 0.5379792647994821,
            "auditor_fn_violation": 0.013513638166572898,
            "auditor_fp_violation": 0.020364131874787087,
            "ave_precision_score": 0.4981620130684767,
            "fpr": 0.18111964873765093,
            "logloss": 0.6977624210854727,
            "mae": 0.5019652850018113,
            "precision": 0.4290657439446367,
            "recall": 0.2605042016806723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6755250184761936,
            "auditor_fn_violation": 0.010841040886735674,
            "auditor_fp_violation": 0.0036431805319751044,
            "ave_precision_score": 0.5452324139238375,
            "fpr": 0.22587719298245615,
            "logloss": 0.6914377878910595,
            "mae": 0.4976451785810161,
            "precision": 0.5635593220338984,
            "recall": 0.5564853556485355
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6699271627770316,
            "auditor_fn_violation": 0.007361012462064958,
            "auditor_fp_violation": 0.014724251485673193,
            "ave_precision_score": 0.5455512087999963,
            "fpr": 0.21405049396267836,
            "logloss": 0.6884436716699185,
            "mae": 0.49626082607210664,
            "precision": 0.5637583892617449,
            "recall": 0.5294117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6749380138659917,
            "auditor_fn_violation": 0.010841040886735674,
            "auditor_fp_violation": 0.005676994906621407,
            "ave_precision_score": 0.5445693853619958,
            "fpr": 0.22697368421052633,
            "logloss": 0.6914232759414424,
            "mae": 0.4971358951900089,
            "precision": 0.5623678646934461,
            "recall": 0.5564853556485355
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6709077870747124,
            "auditor_fn_violation": 0.006867511000009226,
            "auditor_fp_violation": 0.014724251485673193,
            "ave_precision_score": 0.5461500206421335,
            "fpr": 0.21405049396267836,
            "logloss": 0.6880521625363142,
            "mae": 0.495609510252426,
            "precision": 0.5647321428571429,
            "recall": 0.5315126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.8032375396098502,
            "auditor_fn_violation": 0.009366053732658027,
            "auditor_fp_violation": 0.0022940415555016574,
            "ave_precision_score": 0.8027599046042004,
            "fpr": 0.0043859649122807015,
            "logloss": 1.9698365602055803,
            "mae": 0.4402306340267831,
            "precision": 0.9603960396039604,
            "recall": 0.20292887029288703
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7929248006333167,
            "auditor_fn_violation": 0.011336697137691535,
            "auditor_fp_violation": 0.0031341080283129566,
            "ave_precision_score": 0.7923023563061383,
            "fpr": 0.006586169045005488,
            "logloss": 1.991579647243298,
            "mae": 0.4462133827200906,
            "precision": 0.9347826086956522,
            "recall": 0.18067226890756302
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5642345083585606,
            "auditor_fn_violation": 0.08837077002128751,
            "auditor_fp_violation": 0.09639016897081414,
            "ave_precision_score": 0.5656462624391716,
            "fpr": 0.27521929824561403,
            "logloss": 0.6829266570988773,
            "mae": 0.4898140449240281,
            "precision": 0.5788590604026845,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6003237521164496,
            "auditor_fn_violation": 0.09270909241852615,
            "auditor_fp_violation": 0.0923350618872781,
            "ave_precision_score": 0.6014516522236664,
            "fpr": 0.265642151481888,
            "logloss": 0.678305862516993,
            "mae": 0.48714588224299,
            "precision": 0.5849056603773585,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7004027382762117,
            "auditor_fn_violation": 0.0033766424429274053,
            "auditor_fp_violation": 0.006745694882367208,
            "ave_precision_score": 0.6996628976060268,
            "fpr": 0.10964912280701754,
            "logloss": 0.6315728399921746,
            "mae": 0.4500080732007821,
            "precision": 0.6763754045307443,
            "recall": 0.4372384937238494
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.666257348528187,
            "auditor_fn_violation": 0.004748222011087643,
            "auditor_fp_violation": 0.008668004087966991,
            "ave_precision_score": 0.6659763607787267,
            "fpr": 0.09879253567508232,
            "logloss": 0.648400844101208,
            "mae": 0.45984340603867163,
            "precision": 0.7029702970297029,
            "recall": 0.4474789915966387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7021787668651425,
            "auditor_fn_violation": 0.0074827497614328746,
            "auditor_fp_violation": 0.005568356374807986,
            "ave_precision_score": 0.7003672526471276,
            "fpr": 0.10964912280701754,
            "logloss": 0.6292516799559639,
            "mae": 0.44904181821958017,
            "precision": 0.6784565916398714,
            "recall": 0.44142259414225943
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6685435316962551,
            "auditor_fn_violation": 0.0030855371786475435,
            "auditor_fp_violation": 0.006770379903352386,
            "ave_precision_score": 0.6671076291958344,
            "fpr": 0.10757409440175632,
            "logloss": 0.6467058597318368,
            "mae": 0.45949898769774367,
            "precision": 0.6858974358974359,
            "recall": 0.4495798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7037449190900162,
            "auditor_fn_violation": 0.006069698304338255,
            "auditor_fp_violation": 0.00774617996604414,
            "ave_precision_score": 0.703406826211305,
            "fpr": 0.10635964912280702,
            "logloss": 0.6312144839352671,
            "mae": 0.44796257985657767,
            "precision": 0.6798679867986799,
            "recall": 0.4309623430962343
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6799818627363826,
            "auditor_fn_violation": 0.007019712385503065,
            "auditor_fp_violation": 0.007381051515954432,
            "ave_precision_score": 0.6801623102920742,
            "fpr": 0.09330406147091108,
            "logloss": 0.645217090849813,
            "mae": 0.4561589633234246,
            "precision": 0.7098976109215017,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.8470361572618823,
            "auditor_fn_violation": 0.00423915437128386,
            "auditor_fp_violation": 0.011899708949793855,
            "ave_precision_score": 0.8320961793814942,
            "fpr": 0.39473684210526316,
            "logloss": 4.9599295621861295,
            "mae": 0.43231245970529647,
            "precision": 0.5516811955168119,
            "recall": 0.9267782426778243
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8515490529284994,
            "auditor_fn_violation": 0.00548847420417124,
            "auditor_fp_violation": 0.01091638593436545,
            "ave_precision_score": 0.8446358903902526,
            "fpr": 0.38529088913282106,
            "logloss": 4.517833665597737,
            "mae": 0.42277334476762574,
            "precision": 0.5573770491803278,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7862435232230214,
            "auditor_fn_violation": 0.005454929163913971,
            "auditor_fp_violation": 0.01713962325167758,
            "ave_precision_score": 0.7782017197001628,
            "fpr": 0.15789473684210525,
            "logloss": 0.6146908732287678,
            "mae": 0.405250512684385,
            "precision": 0.708502024291498,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.788071212937421,
            "auditor_fn_violation": 0.021930836000701052,
            "auditor_fp_violation": 0.018713804458912155,
            "ave_precision_score": 0.7788397353343403,
            "fpr": 0.13830954994511527,
            "logloss": 0.6069900328274456,
            "mae": 0.40470153849028073,
            "precision": 0.7266811279826464,
            "recall": 0.7037815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6745686714793695,
            "auditor_fn_violation": 0.010474014534243565,
            "auditor_fp_violation": 0.0036431805319751044,
            "ave_precision_score": 0.5446321165002176,
            "fpr": 0.22587719298245615,
            "logloss": 0.6914482275352025,
            "mae": 0.49734829928268465,
            "precision": 0.5626326963906582,
            "recall": 0.5543933054393305
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6699271627770316,
            "auditor_fn_violation": 0.007361012462064958,
            "auditor_fp_violation": 0.014724251485673193,
            "ave_precision_score": 0.5455512087999963,
            "fpr": 0.21405049396267836,
            "logloss": 0.6882791301805699,
            "mae": 0.49590328149293045,
            "precision": 0.5637583892617449,
            "recall": 0.5294117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.4662698194230346,
            "auditor_fn_violation": 0.000610181311018149,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5437706452323277,
            "fpr": 0.0,
            "logloss": 0.7556956399042388,
            "mae": 0.5054230362569031,
            "precision": 1.0,
            "recall": 0.0020920502092050207
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.40083395984406484,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0023291318117011745,
            "ave_precision_score": 0.5427634826397875,
            "fpr": 0.007683863885839737,
            "logloss": 0.7579301913267371,
            "mae": 0.5062228939797562,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7045954134418564,
            "auditor_fn_violation": 0.006432136827424223,
            "auditor_fp_violation": 0.008734032662300922,
            "ave_precision_score": 0.7043774397821938,
            "fpr": 0.11074561403508772,
            "logloss": 0.6310158483753933,
            "mae": 0.4489211966201924,
            "precision": 0.6752411575562701,
            "recall": 0.4393305439330544
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6767251634883169,
            "auditor_fn_violation": 0.005091828169247942,
            "auditor_fp_violation": 0.00912222264279496,
            "ave_precision_score": 0.6771069857100792,
            "fpr": 0.10208562019758508,
            "logloss": 0.6472541489007353,
            "mae": 0.459006765638565,
            "precision": 0.6950819672131148,
            "recall": 0.44537815126050423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7574974436981614,
            "auditor_fn_violation": 0.0035486860456580807,
            "auditor_fp_violation": 0.01967873312313041,
            "ave_precision_score": 0.741342809848919,
            "fpr": 0.21162280701754385,
            "logloss": 1.954890352682588,
            "mae": 0.3038884238672132,
            "precision": 0.6717687074829932,
            "recall": 0.8263598326359832
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.778337994952154,
            "auditor_fn_violation": 0.012623490669593855,
            "auditor_fp_violation": 0.02337206808231451,
            "ave_precision_score": 0.7669300326648589,
            "fpr": 0.20636663007683864,
            "logloss": 1.6971796280739102,
            "mae": 0.3050218615429468,
            "precision": 0.6753022452504318,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5653117904663594,
            "auditor_fn_violation": 0.08837077002128751,
            "auditor_fp_violation": 0.09639016897081414,
            "ave_precision_score": 0.566891499655332,
            "fpr": 0.27521929824561403,
            "logloss": 0.68280241952678,
            "mae": 0.48981812225425975,
            "precision": 0.5788590604026845,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6018410188166352,
            "auditor_fn_violation": 0.09270909241852615,
            "auditor_fp_violation": 0.0923350618872781,
            "ave_precision_score": 0.6029648328593435,
            "fpr": 0.265642151481888,
            "logloss": 0.6784387439686203,
            "mae": 0.48726115219548555,
            "precision": 0.5849056603773585,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6802728320285478,
            "auditor_fn_violation": 0.008223684210526322,
            "auditor_fp_violation": 0.003895828280378375,
            "ave_precision_score": 0.6456393309264126,
            "fpr": 0.16666666666666666,
            "logloss": 1.9528879687414347,
            "mae": 0.43915691512022087,
            "precision": 0.6112531969309463,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6436547239747227,
            "auditor_fn_violation": 0.014528314069865055,
            "auditor_fp_violation": 0.009985237896968101,
            "ave_precision_score": 0.6090093100087954,
            "fpr": 0.1734357848518112,
            "logloss": 1.9891513570400439,
            "mae": 0.44901924560459444,
            "precision": 0.5706521739130435,
            "recall": 0.4411764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6763086175348426,
            "auditor_fn_violation": 0.00901508478308744,
            "auditor_fp_violation": 0.0037543455412725364,
            "ave_precision_score": 0.6616680845226537,
            "fpr": 0.01206140350877193,
            "logloss": 0.6308215694324054,
            "mae": 0.45110179634209263,
            "precision": 0.9185185185185185,
            "recall": 0.2594142259414226
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6258990371891389,
            "auditor_fn_violation": 0.007988266656827385,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.6254524548632482,
            "fpr": 0.013172338090010977,
            "logloss": 0.6487680618029781,
            "mae": 0.46201004439598903,
            "precision": 0.8928571428571429,
            "recall": 0.21008403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7825220848212172,
            "auditor_fn_violation": 0.00901508478308744,
            "auditor_fp_violation": 0.003228838224593743,
            "ave_precision_score": 0.6307168207904175,
            "fpr": 0.013157894736842105,
            "logloss": 0.629858412985331,
            "mae": 0.45027146622407854,
            "precision": 0.9117647058823529,
            "recall": 0.2594142259414226
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7603813894708171,
            "auditor_fn_violation": 0.00831573024379895,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.6100148237252696,
            "fpr": 0.013172338090010977,
            "logloss": 0.6475369058847746,
            "mae": 0.46133573786749144,
            "precision": 0.8956521739130435,
            "recall": 0.21638655462184875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6701072872699753,
            "auditor_fn_violation": 0.00901508478308744,
            "auditor_fp_violation": 0.0037543455412725364,
            "ave_precision_score": 0.657215266678876,
            "fpr": 0.01206140350877193,
            "logloss": 0.6307397354810065,
            "mae": 0.4512189667541207,
            "precision": 0.9185185185185185,
            "recall": 0.2594142259414226
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6199603542683899,
            "auditor_fn_violation": 0.007988266656827385,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.6205194061251702,
            "fpr": 0.013172338090010977,
            "logloss": 0.6487025693423257,
            "mae": 0.46216423039117055,
            "precision": 0.8928571428571429,
            "recall": 0.21008403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 29756,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.5382851473972052,
            "auditor_fn_violation": 0.008106694560669462,
            "auditor_fp_violation": 0.029226291535289845,
            "ave_precision_score": 0.504633418703085,
            "fpr": 0.15570175438596492,
            "logloss": 0.6968166750496253,
            "mae": 0.5015299465964761,
            "precision": 0.4409448818897638,
            "recall": 0.23430962343096234
        },
        "train": {
            "accuracy": 0.43249176728869376,
            "auc_prc": 0.5379792647994821,
            "auditor_fn_violation": 0.013513638166572898,
            "auditor_fp_violation": 0.020364131874787087,
            "ave_precision_score": 0.4981620130684767,
            "fpr": 0.18111964873765093,
            "logloss": 0.6977624210854727,
            "mae": 0.5019652850018113,
            "precision": 0.4290657439446367,
            "recall": 0.2605042016806723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8063727544203145,
            "auditor_fn_violation": 0.014456250458782948,
            "auditor_fp_violation": 0.0019226493653488564,
            "ave_precision_score": 0.8058556480189698,
            "fpr": 0.029605263157894735,
            "logloss": 1.9904953895798665,
            "mae": 0.432160525179478,
            "precision": 0.88,
            "recall": 0.41422594142259417
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7962577489486369,
            "auditor_fn_violation": 0.01829645140163642,
            "auditor_fp_violation": 0.005475857022092686,
            "ave_precision_score": 0.7956590532615883,
            "fpr": 0.025246981339187707,
            "logloss": 2.02959120455071,
            "mae": 0.4420810850454697,
            "precision": 0.8899521531100478,
            "recall": 0.3907563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7028614154320679,
            "auditor_fn_violation": 0.03512442193349483,
            "auditor_fp_violation": 0.03328634085213033,
            "ave_precision_score": 0.668820470725737,
            "fpr": 0.13925438596491227,
            "logloss": 1.9191790078554192,
            "mae": 0.4362889556276732,
            "precision": 0.6586021505376344,
            "recall": 0.5125523012552301
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.671611378657161,
            "auditor_fn_violation": 0.035836508039000466,
            "auditor_fp_violation": 0.02638252772625762,
            "ave_precision_score": 0.6340716372685331,
            "fpr": 0.13062568605927552,
            "logloss": 1.9336704330297663,
            "mae": 0.4416855199251976,
            "precision": 0.6609686609686609,
            "recall": 0.48739495798319327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7031006459912205,
            "auditor_fn_violation": 0.012923915437128392,
            "auditor_fp_violation": 0.0036987630366238184,
            "ave_precision_score": 0.626142102545284,
            "fpr": 0.01206140350877193,
            "logloss": 1.912762096329071,
            "mae": 0.43576880677415214,
            "precision": 0.916030534351145,
            "recall": 0.2510460251046025
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6651620736597175,
            "auditor_fn_violation": 0.010296654336817056,
            "auditor_fp_violation": 0.00432769345294422,
            "ave_precision_score": 0.584843153406299,
            "fpr": 0.010976948408342482,
            "logloss": 1.9322496875405588,
            "mae": 0.4434378295587533,
            "precision": 0.908256880733945,
            "recall": 0.20798319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8483424692200505,
            "auditor_fn_violation": 0.014529655729281369,
            "auditor_fp_violation": 0.005598674104616383,
            "ave_precision_score": 0.8435940802185898,
            "fpr": 0.10526315789473684,
            "logloss": 0.8023464935734221,
            "mae": 0.29642219777423506,
            "precision": 0.788546255506608,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8546908208058779,
            "auditor_fn_violation": 0.02159876025053271,
            "auditor_fp_violation": 0.014749485849830305,
            "ave_precision_score": 0.8538221334246736,
            "fpr": 0.09989023051591657,
            "logloss": 0.639017749717884,
            "mae": 0.3045588560175824,
            "precision": 0.7873831775700935,
            "recall": 0.707983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7877499660690692,
            "auditor_fn_violation": 0.021652260882331353,
            "auditor_fp_violation": 0.017917778316759655,
            "ave_precision_score": 0.7597863752247571,
            "fpr": 0.16776315789473684,
            "logloss": 3.731899228825903,
            "mae": 0.29681762359755925,
            "precision": 0.7034883720930233,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7964464726103958,
            "auditor_fn_violation": 0.024797295427501406,
            "auditor_fp_violation": 0.025693629584768538,
            "ave_precision_score": 0.7690947919363416,
            "fpr": 0.1602634467618002,
            "logloss": 3.5279022672669496,
            "mae": 0.28333571791445417,
            "precision": 0.7153996101364523,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6801768966662161,
            "auditor_fn_violation": 0.009556448653013295,
            "auditor_fp_violation": 0.002698277952946883,
            "ave_precision_score": 0.6810757825817608,
            "fpr": 0.021929824561403508,
            "logloss": 0.6328308457204534,
            "mae": 0.4517113651361382,
            "precision": 0.8620689655172413,
            "recall": 0.2615062761506276
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6543554795552411,
            "auditor_fn_violation": 0.00864319383077052,
            "auditor_fp_violation": 0.00022710927741398273,
            "ave_precision_score": 0.6551651800086782,
            "fpr": 0.021953896816684963,
            "logloss": 0.6495732661572241,
            "mae": 0.46241940562863776,
            "precision": 0.8412698412698413,
            "recall": 0.22268907563025211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6331411017265463,
            "auditor_fn_violation": 0.05896966527196652,
            "auditor_fp_violation": 0.06030701754385966,
            "ave_precision_score": 0.5670118459450771,
            "fpr": 0.3223684210526316,
            "logloss": 0.694281656122301,
            "mae": 0.4856303277049671,
            "precision": 0.5565610859728507,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6638531132109328,
            "auditor_fn_violation": 0.056950991153870985,
            "auditor_fp_violation": 0.05859924044563887,
            "ave_precision_score": 0.5978564664076782,
            "fpr": 0.3040614709110867,
            "logloss": 0.6778601910510542,
            "mae": 0.4780970112421641,
            "precision": 0.5758039816232772,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6991839853244992,
            "auditor_fn_violation": 0.03512442193349483,
            "auditor_fp_violation": 0.0323793354353626,
            "ave_precision_score": 0.6675458699561783,
            "fpr": 0.1425438596491228,
            "logloss": 1.9194458822538156,
            "mae": 0.4361763053281322,
            "precision": 0.6533333333333333,
            "recall": 0.5125523012552301
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6694505260315792,
            "auditor_fn_violation": 0.03651449602892749,
            "auditor_fp_violation": 0.02638252772625762,
            "ave_precision_score": 0.6335108344504605,
            "fpr": 0.13062568605927552,
            "logloss": 1.9378812175178604,
            "mae": 0.44119490798321553,
            "precision": 0.6628895184135978,
            "recall": 0.49159663865546216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7138252573885886,
            "auditor_fn_violation": 0.03270204800704691,
            "auditor_fp_violation": 0.04078997897970735,
            "ave_precision_score": 0.6842911148115672,
            "fpr": 0.11732456140350878,
            "logloss": 1.906582096950111,
            "mae": 0.43318418927950764,
            "precision": 0.69164265129683,
            "recall": 0.502092050209205
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6930398607949404,
            "auditor_fn_violation": 0.041859993173998473,
            "auditor_fp_violation": 0.036387953114551404,
            "ave_precision_score": 0.6618729638472143,
            "fpr": 0.11086717892425905,
            "logloss": 1.9113403047896023,
            "mae": 0.4356864186101565,
            "precision": 0.7038123167155426,
            "recall": 0.5042016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.533954156052984,
            "auditor_fn_violation": 0.043855061293400874,
            "auditor_fp_violation": 0.034380305602716474,
            "ave_precision_score": 0.5356885076972107,
            "fpr": 0.06140350877192982,
            "logloss": 0.7067645986611223,
            "mae": 0.49667363381830226,
            "precision": 0.552,
            "recall": 0.14435146443514643
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5323823898926073,
            "auditor_fn_violation": 0.03241428294698782,
            "auditor_fp_violation": 0.031240142826501137,
            "ave_precision_score": 0.534046773472763,
            "fpr": 0.05817782656421515,
            "logloss": 0.7078761820839432,
            "mae": 0.49698176798456717,
            "precision": 0.5181818181818182,
            "recall": 0.11974789915966387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.773769783757017,
            "auditor_fn_violation": 0.004968619246861926,
            "auditor_fp_violation": 0.014820316921335605,
            "ave_precision_score": 0.735716885526239,
            "fpr": 0.19188596491228072,
            "logloss": 3.5818805422372284,
            "mae": 0.2972974594787727,
            "precision": 0.6891651865008881,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7843388575711622,
            "auditor_fn_violation": 0.01081552269645509,
            "auditor_fp_violation": 0.031174533479692654,
            "ave_precision_score": 0.7548960475212252,
            "fpr": 0.19099890230515917,
            "logloss": 3.230295480179691,
            "mae": 0.29407418540289126,
            "precision": 0.6887298747763864,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6423885171519981,
            "auditor_fn_violation": 0.00901508478308744,
            "auditor_fp_violation": 0.0045678712911310536,
            "ave_precision_score": 0.6442196645758733,
            "fpr": 0.013157894736842105,
            "logloss": 0.6317215272746559,
            "mae": 0.4516423746551338,
            "precision": 0.9117647058823529,
            "recall": 0.2594142259414226
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6219730376175651,
            "auditor_fn_violation": 0.0073656246252617385,
            "auditor_fp_violation": 0.004463959019392608,
            "ave_precision_score": 0.6236355490648977,
            "fpr": 0.014270032930845226,
            "logloss": 0.6489815496459573,
            "mae": 0.4622142116664924,
            "precision": 0.8859649122807017,
            "recall": 0.21218487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7057138531924622,
            "auditor_fn_violation": 0.03512442193349483,
            "auditor_fp_violation": 0.0323793354353626,
            "ave_precision_score": 0.6730687621682896,
            "fpr": 0.1425438596491228,
            "logloss": 1.9217021153326637,
            "mae": 0.43633732830216654,
            "precision": 0.6533333333333333,
            "recall": 0.5125523012552301
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6774185938600579,
            "auditor_fn_violation": 0.03651449602892749,
            "auditor_fp_violation": 0.02638252772625762,
            "ave_precision_score": 0.6425137210285259,
            "fpr": 0.13062568605927552,
            "logloss": 1.938986194886767,
            "mae": 0.4414187006880052,
            "precision": 0.6628895184135978,
            "recall": 0.49159663865546216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6974701810151778,
            "auditor_fn_violation": 0.003993705498054758,
            "auditor_fp_violation": 0.008418222976796827,
            "ave_precision_score": 0.696750722708434,
            "fpr": 0.1074561403508772,
            "logloss": 0.6332441756162991,
            "mae": 0.4506460717111303,
            "precision": 0.6807817589576547,
            "recall": 0.4372384937238494
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6678600424473715,
            "auditor_fn_violation": 0.004748222011087643,
            "auditor_fp_violation": 0.00912222264279496,
            "ave_precision_score": 0.6675409958186267,
            "fpr": 0.10208562019758508,
            "logloss": 0.6473422964894432,
            "mae": 0.45898723981775646,
            "precision": 0.696078431372549,
            "recall": 0.4474789915966387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7457348034454063,
            "auditor_fn_violation": 0.007347408793951405,
            "auditor_fp_violation": 0.011682431886167032,
            "ave_precision_score": 0.7308674412206295,
            "fpr": 0.19298245614035087,
            "logloss": 1.7514505203254265,
            "mae": 0.2964594263153987,
            "precision": 0.6949740034662045,
            "recall": 0.8389121338912134
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7480780787401357,
            "auditor_fn_violation": 0.012937117766975068,
            "auditor_fp_violation": 0.019203351123560055,
            "ave_precision_score": 0.7354662781189062,
            "fpr": 0.2030735455543359,
            "logloss": 1.6663499819597667,
            "mae": 0.3054223276657234,
            "precision": 0.6788194444444444,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6259127444504227,
            "auditor_fn_violation": 0.005551273581443158,
            "auditor_fp_violation": 0.003698763036623818,
            "ave_precision_score": 0.6267382051461187,
            "fpr": 0.019736842105263157,
            "logloss": 2.265920672308157,
            "mae": 0.47769418563365074,
            "precision": 0.7631578947368421,
            "recall": 0.12133891213389121
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6119815739980636,
            "auditor_fn_violation": 0.005184071433183596,
            "auditor_fp_violation": 0.0065483174987698255,
            "ave_precision_score": 0.6126229538293877,
            "fpr": 0.02305159165751921,
            "logloss": 2.4457808897885895,
            "mae": 0.4842650084412505,
            "precision": 0.7375,
            "recall": 0.12394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6342416912411049,
            "auditor_fn_violation": 0.05839848051090068,
            "auditor_fp_violation": 0.06030701754385966,
            "ave_precision_score": 0.5678190205641566,
            "fpr": 0.3223684210526316,
            "logloss": 0.6937161144894323,
            "mae": 0.48575363608828764,
            "precision": 0.5572289156626506,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6641105811949539,
            "auditor_fn_violation": 0.056337573448698906,
            "auditor_fp_violation": 0.05859924044563887,
            "ave_precision_score": 0.5981305982384204,
            "fpr": 0.3040614709110867,
            "logloss": 0.6774693331811487,
            "mae": 0.47828898088992233,
            "precision": 0.5764525993883792,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5631107686050225,
            "auditor_fn_violation": 0.08837077002128751,
            "auditor_fp_violation": 0.0967741935483871,
            "ave_precision_score": 0.5646967866670065,
            "fpr": 0.27631578947368424,
            "logloss": 0.6848620274073487,
            "mae": 0.4887380536871333,
            "precision": 0.5778894472361809,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6002443628745909,
            "auditor_fn_violation": 0.09270909241852615,
            "auditor_fp_violation": 0.0923350618872781,
            "ave_precision_score": 0.6013653454396466,
            "fpr": 0.265642151481888,
            "logloss": 0.6741233366958158,
            "mae": 0.48412215428296007,
            "precision": 0.5849056603773585,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7668689113640783,
            "auditor_fn_violation": 0.0028696872935476793,
            "auditor_fp_violation": 0.01722552348613469,
            "ave_precision_score": 0.7289746316323263,
            "fpr": 0.18969298245614036,
            "logloss": 4.149961948408017,
            "mae": 0.30049356036615077,
            "precision": 0.6888489208633094,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7816485315390237,
            "auditor_fn_violation": 0.010596444944607925,
            "auditor_fp_violation": 0.026824129099007037,
            "ave_precision_score": 0.7535786411148698,
            "fpr": 0.17892425905598244,
            "logloss": 3.7395116475871872,
            "mae": 0.2946554684557981,
            "precision": 0.6970260223048327,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.676978912022858,
            "auditor_fn_violation": 0.010483190193055872,
            "auditor_fp_violation": 0.006351564394858126,
            "ave_precision_score": 0.5459341961845298,
            "fpr": 0.22807017543859648,
            "logloss": 0.6890207439840751,
            "mae": 0.49664879472632156,
            "precision": 0.5630252100840336,
            "recall": 0.5606694560669456
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6729328521720149,
            "auditor_fn_violation": 0.005087216006051165,
            "auditor_fp_violation": 0.00951083185081444,
            "ave_precision_score": 0.5452938344582201,
            "fpr": 0.21844127332601537,
            "logloss": 0.6889528124001597,
            "mae": 0.49664626641017023,
            "precision": 0.5645514223194749,
            "recall": 0.542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.787413832739793,
            "auditor_fn_violation": 0.021652260882331353,
            "auditor_fp_violation": 0.017917778316759655,
            "ave_precision_score": 0.7594883796073141,
            "fpr": 0.16776315789473684,
            "logloss": 3.7393267324274384,
            "mae": 0.29699831376222907,
            "precision": 0.7034883720930233,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7965105399243625,
            "auditor_fn_violation": 0.02396479997048216,
            "auditor_fp_violation": 0.026791324425602787,
            "ave_precision_score": 0.7691765228049992,
            "fpr": 0.1602634467618002,
            "logloss": 3.5317859620056615,
            "mae": 0.2828535294869419,
            "precision": 0.7159533073929961,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4440789473684211,
            "auc_prc": 0.45462313571715923,
            "auditor_fn_violation": 0.03170648902591206,
            "auditor_fp_violation": 0.07093590831918506,
            "ave_precision_score": 0.4566288837944002,
            "fpr": 0.20942982456140352,
            "logloss": 1.6765520309022435,
            "mae": 0.5347091978495842,
            "precision": 0.45892351274787535,
            "recall": 0.3389121338912134
        },
        "train": {
            "accuracy": 0.4445664105378705,
            "auc_prc": 0.4716900717925034,
            "auditor_fn_violation": 0.034183047532953925,
            "auditor_fp_violation": 0.06647488549907263,
            "ave_precision_score": 0.4730780775638221,
            "fpr": 0.2074643249176729,
            "logloss": 1.7979445746091174,
            "mae": 0.5393380812347838,
            "precision": 0.45689655172413796,
            "recall": 0.33403361344537813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7030705109064417,
            "auditor_fn_violation": 0.03512442193349483,
            "auditor_fp_violation": 0.03328634085213033,
            "ave_precision_score": 0.6686934167850717,
            "fpr": 0.13925438596491227,
            "logloss": 1.9181302397489768,
            "mae": 0.4362165511973897,
            "precision": 0.6586021505376344,
            "recall": 0.5125523012552301
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.672394630706358,
            "auditor_fn_violation": 0.0362216236659318,
            "auditor_fp_violation": 0.02638252772625762,
            "ave_precision_score": 0.6346023880353533,
            "fpr": 0.13062568605927552,
            "logloss": 1.9343477102940962,
            "mae": 0.4414336211764983,
            "precision": 0.6619318181818182,
            "recall": 0.4894957983193277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7505154283642361,
            "auditor_fn_violation": 0.007276297438156063,
            "auditor_fp_violation": 0.013198318376586632,
            "ave_precision_score": 0.7358985729676799,
            "fpr": 0.19407894736842105,
            "logloss": 1.735844258336153,
            "mae": 0.2981706815995291,
            "precision": 0.6916376306620209,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7605550594317836,
            "auditor_fn_violation": 0.012937117766975068,
            "auditor_fp_violation": 0.02131042053067868,
            "ave_precision_score": 0.7478825409095432,
            "fpr": 0.19978046103183314,
            "logloss": 1.6120053360590807,
            "mae": 0.3046828328467633,
            "precision": 0.6823734729493892,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7009037309028039,
            "auditor_fn_violation": 0.03512442193349483,
            "auditor_fp_violation": 0.03328634085213033,
            "ave_precision_score": 0.6681557882574741,
            "fpr": 0.13925438596491227,
            "logloss": 1.9192084168934116,
            "mae": 0.43627050512834376,
            "precision": 0.6586021505376344,
            "recall": 0.5125523012552301
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6694911219068355,
            "auditor_fn_violation": 0.035836508039000466,
            "auditor_fp_violation": 0.02638252772625762,
            "ave_precision_score": 0.6331400796415996,
            "fpr": 0.13062568605927552,
            "logloss": 1.9342127148069657,
            "mae": 0.4416206610627472,
            "precision": 0.6609686609686609,
            "recall": 0.48739495798319327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.712974409240982,
            "auditor_fn_violation": 0.0012203626220362721,
            "auditor_fp_violation": 0.030075187969924814,
            "ave_precision_score": 0.691262103336663,
            "fpr": 0.1337719298245614,
            "logloss": 2.232771566838531,
            "mae": 0.31594076187544134,
            "precision": 0.7312775330396476,
            "recall": 0.694560669456067
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7020309803977793,
            "auditor_fn_violation": 0.012448228468116124,
            "auditor_fp_violation": 0.03925205344638329,
            "ave_precision_score": 0.6790390966258586,
            "fpr": 0.13721185510428102,
            "logloss": 2.366522922501454,
            "mae": 0.3225768198097268,
            "precision": 0.7228381374722838,
            "recall": 0.6848739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8297531326924046,
            "auditor_fn_violation": 0.0022113337737649573,
            "auditor_fp_violation": 0.006316193710081654,
            "ave_precision_score": 0.8242456242667426,
            "fpr": 0.11732456140350878,
            "logloss": 2.111223239673649,
            "mae": 0.3045287740882599,
            "precision": 0.7688984881209503,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.837345230257327,
            "auditor_fn_violation": 0.021522659557785796,
            "auditor_fp_violation": 0.016629445979534932,
            "ave_precision_score": 0.8357393958068142,
            "fpr": 0.10428100987925357,
            "logloss": 1.9506173587673261,
            "mae": 0.31042248012570156,
            "precision": 0.7780373831775701,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7877319866476538,
            "auditor_fn_violation": 0.021652260882331353,
            "auditor_fp_violation": 0.017917778316759655,
            "ave_precision_score": 0.7597745629977724,
            "fpr": 0.16776315789473684,
            "logloss": 3.736351372517897,
            "mae": 0.2968150248317813,
            "precision": 0.7034883720930233,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7964370390680925,
            "auditor_fn_violation": 0.024797295427501406,
            "auditor_fp_violation": 0.025693629584768538,
            "ave_precision_score": 0.7690811187331494,
            "fpr": 0.1602634467618002,
            "logloss": 3.530923218011932,
            "mae": 0.28324906581676895,
            "precision": 0.7153996101364523,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.8434430803648476,
            "auditor_fn_violation": 0.00423915437128386,
            "auditor_fp_violation": 0.011899708949793855,
            "ave_precision_score": 0.8283360016395432,
            "fpr": 0.39473684210526316,
            "logloss": 4.958617901441671,
            "mae": 0.43235182894463425,
            "precision": 0.5516811955168119,
            "recall": 0.9267782426778243
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8503977667148401,
            "auditor_fn_violation": 0.00548847420417124,
            "auditor_fp_violation": 0.012708025789520173,
            "ave_precision_score": 0.8434200379239053,
            "fpr": 0.38309549945115257,
            "logloss": 4.48494498779168,
            "mae": 0.42105590035724394,
            "precision": 0.5587863463969659,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8483017004966426,
            "auditor_fn_violation": 0.004390552741686855,
            "auditor_fp_violation": 0.004411229687121032,
            "ave_precision_score": 0.8436285036338347,
            "fpr": 0.1162280701754386,
            "logloss": 0.803495956761021,
            "mae": 0.30092717462511837,
            "precision": 0.7773109243697479,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8549991038491519,
            "auditor_fn_violation": 0.013877999059118714,
            "auditor_fp_violation": 0.0117440730787186,
            "ave_precision_score": 0.8541385081834105,
            "fpr": 0.11306256860592755,
            "logloss": 0.6406236970976302,
            "mae": 0.3098980696930915,
            "precision": 0.7706013363028953,
            "recall": 0.726890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8473762512853455,
            "auditor_fn_violation": 0.010861686119063355,
            "auditor_fp_violation": 0.006119128466327108,
            "ave_precision_score": 0.8425899773564455,
            "fpr": 0.1074561403508772,
            "logloss": 0.8200034076020898,
            "mae": 0.2967180246883299,
            "precision": 0.7864923747276689,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8535170342867275,
            "auditor_fn_violation": 0.02159876025053271,
            "auditor_fp_violation": 0.015223891895983955,
            "ave_precision_score": 0.8526566132654207,
            "fpr": 0.10208562019758508,
            "logloss": 0.6579020471709753,
            "mae": 0.3047678968364585,
            "precision": 0.7837209302325582,
            "recall": 0.707983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7731700969866361,
            "auditor_fn_violation": 0.0030371430668722026,
            "auditor_fp_violation": 0.018534238822863612,
            "ave_precision_score": 0.7623425296772299,
            "fpr": 0.18421052631578946,
            "logloss": 1.5618390499191823,
            "mae": 0.29363394613076477,
            "precision": 0.701067615658363,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7953335719519725,
            "auditor_fn_violation": 0.012351373040983687,
            "auditor_fp_violation": 0.02782088648321284,
            "ave_precision_score": 0.7897214831816413,
            "fpr": 0.18441273326015367,
            "logloss": 1.3230610808512218,
            "mae": 0.29906323343496977,
            "precision": 0.6934306569343066,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.8470325325316005,
            "auditor_fn_violation": 0.00423915437128386,
            "auditor_fp_violation": 0.011899708949793855,
            "ave_precision_score": 0.8320959370694306,
            "fpr": 0.39473684210526316,
            "logloss": 4.959588945938097,
            "mae": 0.43231003248970334,
            "precision": 0.5516811955168119,
            "recall": 0.9267782426778243
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8515734678247737,
            "auditor_fn_violation": 0.00548847420417124,
            "auditor_fp_violation": 0.01091638593436545,
            "ave_precision_score": 0.8446799783289822,
            "fpr": 0.38529088913282106,
            "logloss": 4.51737853896405,
            "mae": 0.42277085484194354,
            "precision": 0.5573770491803278,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.8432411042801707,
            "auditor_fn_violation": 0.00423915437128386,
            "auditor_fp_violation": 0.012460586951249089,
            "ave_precision_score": 0.8282003558813573,
            "fpr": 0.39364035087719296,
            "logloss": 4.883273832933885,
            "mae": 0.431661470666635,
            "precision": 0.5523690773067331,
            "recall": 0.9267782426778243
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.850627327594336,
            "auditor_fn_violation": 0.00548847420417124,
            "auditor_fp_violation": 0.012708025789520173,
            "ave_precision_score": 0.8437730712773491,
            "fpr": 0.38309549945115257,
            "logloss": 4.415624951977918,
            "mae": 0.41999755476498163,
            "precision": 0.5587863463969659,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8360563245112669,
            "auditor_fn_violation": 0.007496513249651328,
            "auditor_fp_violation": 0.019052166707090316,
            "ave_precision_score": 0.8317503114458772,
            "fpr": 0.1962719298245614,
            "logloss": 2.0535550728793255,
            "mae": 0.288276278817708,
            "precision": 0.688695652173913,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8528292578440269,
            "auditor_fn_violation": 0.011419716075233607,
            "auditor_fp_violation": 0.02354618519499855,
            "ave_precision_score": 0.851344549383096,
            "fpr": 0.17672886937431395,
            "logloss": 1.8091753669707817,
            "mae": 0.28477611294032074,
            "precision": 0.7056672760511883,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.8478619923829397,
            "auditor_fn_violation": 0.00423915437128386,
            "auditor_fp_violation": 0.012460586951249089,
            "ave_precision_score": 0.8355127198832972,
            "fpr": 0.39364035087719296,
            "logloss": 4.888602477670458,
            "mae": 0.4307452827555646,
            "precision": 0.5523690773067331,
            "recall": 0.9267782426778243
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8537174544734762,
            "auditor_fn_violation": 0.00581132562794602,
            "auditor_fp_violation": 0.01285690853804712,
            "ave_precision_score": 0.8487638851225457,
            "fpr": 0.38419319429198684,
            "logloss": 4.469852958380699,
            "mae": 0.42082150098761506,
            "precision": 0.5575221238938053,
            "recall": 0.9264705882352942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.8429306845571342,
            "auditor_fn_violation": 0.0048493356823019924,
            "auditor_fp_violation": 0.012460586951249089,
            "ave_precision_score": 0.8278536074269185,
            "fpr": 0.39364035087719296,
            "logloss": 4.9198531068054505,
            "mae": 0.43229668915932257,
            "precision": 0.55125,
            "recall": 0.9225941422594143
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8496238079325056,
            "auditor_fn_violation": 0.005691409384829676,
            "auditor_fp_violation": 0.013878900286410034,
            "ave_precision_score": 0.842610782600579,
            "fpr": 0.3809001097694841,
            "logloss": 4.457013494763634,
            "mae": 0.4206562306448966,
            "precision": 0.5590851334180432,
            "recall": 0.9243697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6145554347049343,
            "auditor_fn_violation": 0.00901508478308744,
            "auditor_fp_violation": 0.0037543455412725364,
            "ave_precision_score": 0.6218347167734631,
            "fpr": 0.01206140350877193,
            "logloss": 0.6333923632525259,
            "mae": 0.45205250852986384,
            "precision": 0.9185185185185185,
            "recall": 0.2594142259414226
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5684764121499772,
            "auditor_fn_violation": 0.007988266656827385,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.596830274116973,
            "fpr": 0.013172338090010977,
            "logloss": 0.6479117393631457,
            "mae": 0.46121254566602987,
            "precision": 0.8928571428571429,
            "recall": 0.21008403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8483481782283525,
            "auditor_fn_violation": 0.014529655729281369,
            "auditor_fp_violation": 0.005598674104616383,
            "ave_precision_score": 0.8436008998869629,
            "fpr": 0.10526315789473684,
            "logloss": 0.8023067874258397,
            "mae": 0.2964136696092729,
            "precision": 0.788546255506608,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8546866497227705,
            "auditor_fn_violation": 0.020985342545360636,
            "auditor_fp_violation": 0.014749485849830305,
            "ave_precision_score": 0.8538180029755768,
            "fpr": 0.09989023051591657,
            "logloss": 0.638976057810546,
            "mae": 0.304549231787705,
            "precision": 0.7878787878787878,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7736893662366249,
            "auditor_fn_violation": 0.007877303090361892,
            "auditor_fp_violation": 0.014597986902740728,
            "ave_precision_score": 0.746367718235763,
            "fpr": 0.16776315789473684,
            "logloss": 2.9299697284378126,
            "mae": 0.2913606240913441,
            "precision": 0.7129455909943715,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7897542772472644,
            "auditor_fn_violation": 0.015086385816675736,
            "auditor_fp_violation": 0.026382527726257623,
            "ave_precision_score": 0.7693003309284565,
            "fpr": 0.16465422612513722,
            "logloss": 2.598715760158235,
            "mae": 0.293839693654432,
            "precision": 0.7098646034816247,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7240436382776843,
            "auditor_fn_violation": 0.0017548447478528996,
            "auditor_fp_violation": 0.03341519120381599,
            "ave_precision_score": 0.7036358250037404,
            "fpr": 0.14802631578947367,
            "logloss": 2.0771484718751636,
            "mae": 0.30257902556051003,
            "precision": 0.725609756097561,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7143252944806192,
            "auditor_fn_violation": 0.012157662186718815,
            "auditor_fp_violation": 0.03889120203893663,
            "ave_precision_score": 0.6919452485057643,
            "fpr": 0.1525795828759605,
            "logloss": 2.212319419440031,
            "mae": 0.3109870315585642,
            "precision": 0.7145790554414785,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5618964715987091,
            "auditor_fn_violation": 0.08837077002128751,
            "auditor_fp_violation": 0.0967741935483871,
            "ave_precision_score": 0.5634831806074598,
            "fpr": 0.27631578947368424,
            "logloss": 0.6835927086193262,
            "mae": 0.4899363479364598,
            "precision": 0.5778894472361809,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.5990749081842076,
            "auditor_fn_violation": 0.09270909241852615,
            "auditor_fp_violation": 0.0923350618872781,
            "ave_precision_score": 0.6002014395352915,
            "fpr": 0.265642151481888,
            "logloss": 0.6786755421586281,
            "mae": 0.48713587836232586,
            "precision": 0.5849056603773585,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.715490930396619,
            "auditor_fn_violation": 0.007076726858988485,
            "auditor_fp_violation": 0.003228838224593743,
            "ave_precision_score": 0.6282690824556193,
            "fpr": 0.013157894736842105,
            "logloss": 0.6355864250719672,
            "mae": 0.4478615273609824,
            "precision": 0.9124087591240876,
            "recall": 0.2615062761506276
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7615719671649354,
            "auditor_fn_violation": 0.00831573024379895,
            "auditor_fp_violation": 0.005236130562600149,
            "ave_precision_score": 0.611729075966656,
            "fpr": 0.014270032930845226,
            "logloss": 0.6599333017411306,
            "mae": 0.45710135099156385,
            "precision": 0.8879310344827587,
            "recall": 0.21638655462184875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7465001191183545,
            "auditor_fn_violation": 0.00797823533729722,
            "auditor_fp_violation": 0.010803217721723666,
            "ave_precision_score": 0.7314771777192136,
            "fpr": 0.19407894736842105,
            "logloss": 1.7529481225371135,
            "mae": 0.29642206783255126,
            "precision": 0.694300518134715,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7481291602517447,
            "auditor_fn_violation": 0.013624330083295671,
            "auditor_fp_violation": 0.019203351123560055,
            "ave_precision_score": 0.7355955985685102,
            "fpr": 0.2030735455543359,
            "logloss": 1.667814223392701,
            "mae": 0.30534108646696106,
            "precision": 0.6793760831889082,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6986149115777422,
            "auditor_fn_violation": 0.006432136827424223,
            "auditor_fp_violation": 0.006745694882367208,
            "ave_precision_score": 0.6978798458966553,
            "fpr": 0.10964912280701754,
            "logloss": 0.6316508663754934,
            "mae": 0.4500305818949352,
            "precision": 0.6774193548387096,
            "recall": 0.4393305439330544
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6665246804143596,
            "auditor_fn_violation": 0.004748222011087643,
            "auditor_fp_violation": 0.008668004087966991,
            "ave_precision_score": 0.6662117483790437,
            "fpr": 0.09879253567508232,
            "logloss": 0.6484012042783296,
            "mae": 0.4598244194403438,
            "precision": 0.7029702970297029,
            "recall": 0.4474789915966387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.8432371924423855,
            "auditor_fn_violation": 0.00423915437128386,
            "auditor_fp_violation": 0.012460586951249089,
            "ave_precision_score": 0.8281873169679306,
            "fpr": 0.39364035087719296,
            "logloss": 4.882654254535566,
            "mae": 0.431656712934135,
            "precision": 0.5523690773067331,
            "recall": 0.9267782426778243
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8506268271234532,
            "auditor_fn_violation": 0.00548847420417124,
            "auditor_fp_violation": 0.012708025789520173,
            "ave_precision_score": 0.8437974122633143,
            "fpr": 0.38309549945115257,
            "logloss": 4.41500344243613,
            "mae": 0.4199914692098587,
            "precision": 0.5587863463969659,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8493129504534459,
            "auditor_fn_violation": 0.012882624972473023,
            "auditor_fp_violation": 0.0061014431239388815,
            "ave_precision_score": 0.8454653013052464,
            "fpr": 0.10416666666666667,
            "logloss": 0.7769241454219593,
            "mae": 0.29623652855864174,
            "precision": 0.7907488986784141,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8556703812557964,
            "auditor_fn_violation": 0.02037192484018855,
            "auditor_fp_violation": 0.01482771237871734,
            "ave_precision_score": 0.8548086608022879,
            "fpr": 0.09989023051591657,
            "logloss": 0.6337991864532114,
            "mae": 0.30363640257505736,
            "precision": 0.7883720930232558,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6342416912411049,
            "auditor_fn_violation": 0.05839848051090068,
            "auditor_fp_violation": 0.06030701754385966,
            "ave_precision_score": 0.5678190205641566,
            "fpr": 0.3223684210526316,
            "logloss": 0.6937191462595648,
            "mae": 0.48575321362729657,
            "precision": 0.5572289156626506,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6641105811949539,
            "auditor_fn_violation": 0.056337573448698906,
            "auditor_fp_violation": 0.05859924044563887,
            "ave_precision_score": 0.5981305982384204,
            "fpr": 0.3040614709110867,
            "logloss": 0.6774860388933899,
            "mae": 0.47829590909567415,
            "precision": 0.5764525993883792,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7255883904012123,
            "auditor_fn_violation": 0.00027297584966601247,
            "auditor_fp_violation": 0.028273809523809527,
            "ave_precision_score": 0.7059904823132295,
            "fpr": 0.13267543859649122,
            "logloss": 2.1015417147054816,
            "mae": 0.298899858885981,
            "precision": 0.740343347639485,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7176502241264187,
            "auditor_fn_violation": 0.006731452185704138,
            "auditor_fp_violation": 0.03783892905358518,
            "ave_precision_score": 0.6972712441668993,
            "fpr": 0.13721185510428102,
            "logloss": 2.1649892503599286,
            "mae": 0.3075085946621659,
            "precision": 0.7282608695652174,
            "recall": 0.7037815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8396754850222387,
            "auditor_fn_violation": 0.00925823974161345,
            "auditor_fp_violation": 0.01952461799660442,
            "ave_precision_score": 0.8361450287124021,
            "fpr": 0.19956140350877194,
            "logloss": 2.0247706884819885,
            "mae": 0.2891734396834964,
            "precision": 0.6888888888888889,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8547653031291348,
            "auditor_fn_violation": 0.01082935918604544,
            "auditor_fp_violation": 0.025903074807272542,
            "ave_precision_score": 0.8532699822266682,
            "fpr": 0.1756311745334797,
            "logloss": 1.8012498628557303,
            "mae": 0.28449716679405945,
            "precision": 0.7074954296160878,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6986198859149454,
            "auditor_fn_violation": 0.006432136827424223,
            "auditor_fp_violation": 0.006745694882367208,
            "ave_precision_score": 0.6978846518304285,
            "fpr": 0.10964912280701754,
            "logloss": 0.631774659209141,
            "mae": 0.4498079694938241,
            "precision": 0.6774193548387096,
            "recall": 0.4393305439330544
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6678036961964942,
            "auditor_fn_violation": 0.004625999686372905,
            "auditor_fp_violation": 0.00961429274385859,
            "ave_precision_score": 0.6674840141818884,
            "fpr": 0.10098792535675083,
            "logloss": 0.6478423419471578,
            "mae": 0.45914842281592794,
            "precision": 0.6993464052287581,
            "recall": 0.4495798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7465070899464816,
            "auditor_fn_violation": 0.007347408793951405,
            "auditor_fp_violation": 0.011882023607405609,
            "ave_precision_score": 0.7315176464108752,
            "fpr": 0.18969298245614036,
            "logloss": 1.746978058378752,
            "mae": 0.2963502554737566,
            "precision": 0.6986062717770035,
            "recall": 0.8389121338912134
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7494012412249438,
            "auditor_fn_violation": 0.012937117766975068,
            "auditor_fp_violation": 0.02032628032855143,
            "ave_precision_score": 0.7370961472240631,
            "fpr": 0.20197585071350166,
            "logloss": 1.6377458787778987,
            "mae": 0.30493642922765846,
            "precision": 0.68,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7662049617483344,
            "auditor_fn_violation": 0.015552741686853125,
            "auditor_fp_violation": 0.0037543455412725364,
            "ave_precision_score": 0.604382451292843,
            "fpr": 0.008771929824561403,
            "logloss": 0.7654259397091587,
            "mae": 0.46767837122847833,
            "precision": 0.9183673469387755,
            "recall": 0.18828451882845187
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7428501508453142,
            "auditor_fn_violation": 0.01677904970989494,
            "auditor_fp_violation": 0.0036261781293765857,
            "ave_precision_score": 0.5847234018276922,
            "fpr": 0.009879253567508232,
            "logloss": 0.7366179341238134,
            "mae": 0.47363071555735486,
            "precision": 0.8902439024390244,
            "recall": 0.15336134453781514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8385136131828991,
            "auditor_fn_violation": 0.00796447184907877,
            "auditor_fp_violation": 0.00510348451774598,
            "ave_precision_score": 0.836209369938728,
            "fpr": 0.09758771929824561,
            "logloss": 1.8795532399127528,
            "mae": 0.2720650765550301,
            "precision": 0.7968036529680366,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8516694809304055,
            "auditor_fn_violation": 0.011574223542325823,
            "auditor_fp_violation": 0.015466141791892202,
            "ave_precision_score": 0.8511987789324656,
            "fpr": 0.09659714599341383,
            "logloss": 1.753621560990843,
            "mae": 0.2760999722027151,
            "precision": 0.7939110070257611,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7677667011626732,
            "auditor_fn_violation": 0.0043767892534684,
            "auditor_fp_violation": 0.017356900315304388,
            "ave_precision_score": 0.7296660204674472,
            "fpr": 0.18859649122807018,
            "logloss": 4.162922323639152,
            "mae": 0.3010129585306547,
            "precision": 0.6872727272727273,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7826409638164231,
            "auditor_fn_violation": 0.011848647252534388,
            "auditor_fp_violation": 0.026117566902607976,
            "ave_precision_score": 0.7537482351107418,
            "fpr": 0.1778265642151482,
            "logloss": 3.7699261842107585,
            "mae": 0.2954422384438415,
            "precision": 0.6949152542372882,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7729418079092518,
            "auditor_fn_violation": 0.004496072818028334,
            "auditor_fp_violation": 0.018016310938636915,
            "ave_precision_score": 0.7621025213127983,
            "fpr": 0.18311403508771928,
            "logloss": 1.5610488422763942,
            "mae": 0.29384074247523073,
            "precision": 0.7012522361359571,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7952976550089735,
            "auditor_fn_violation": 0.006134177051720799,
            "auditor_fp_violation": 0.02782088648321284,
            "ave_precision_score": 0.7896662645978797,
            "fpr": 0.18441273326015367,
            "logloss": 1.3205439862099062,
            "mae": 0.29902860998046543,
            "precision": 0.6923076923076923,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7737733440953205,
            "auditor_fn_violation": 0.009065550906555088,
            "auditor_fp_violation": 0.02095965720753497,
            "ave_precision_score": 0.7365638602412516,
            "fpr": 0.18969298245614036,
            "logloss": 3.517035435802186,
            "mae": 0.2952826835531908,
            "precision": 0.6905187835420393,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7854498472202811,
            "auditor_fn_violation": 0.010460386130302837,
            "auditor_fp_violation": 0.03126537719065824,
            "ave_precision_score": 0.7560662800778688,
            "fpr": 0.18990120746432493,
            "logloss": 3.177113943285659,
            "mae": 0.2934247243160921,
            "precision": 0.6882882882882883,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7217151676518527,
            "auditor_fn_violation": 0.002477427879321736,
            "auditor_fp_violation": 0.027659875495189588,
            "ave_precision_score": 0.7084527775846325,
            "fpr": 0.14144736842105263,
            "logloss": 1.7255748488430438,
            "mae": 0.3072111390693645,
            "precision": 0.7301255230125523,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.717465554485839,
            "auditor_fn_violation": 0.010520344251861014,
            "auditor_fp_violation": 0.031230049080838294,
            "ave_precision_score": 0.70306313915282,
            "fpr": 0.14050493962678376,
            "logloss": 1.7963548935081095,
            "mae": 0.30963607350824385,
            "precision": 0.7305263157894737,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8376877378169155,
            "auditor_fn_violation": 0.0010689642516332678,
            "auditor_fp_violation": 0.006189869835880028,
            "ave_precision_score": 0.8352425707005263,
            "fpr": 0.09868421052631579,
            "logloss": 1.934535557592958,
            "mae": 0.27263406056905004,
            "precision": 0.7968397291196389,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8512664121852417,
            "auditor_fn_violation": 0.013642778736082798,
            "auditor_fp_violation": 0.013134486543775315,
            "ave_precision_score": 0.8507799559186054,
            "fpr": 0.09879253567508232,
            "logloss": 1.7713922138706228,
            "mae": 0.2737958785748193,
            "precision": 0.7906976744186046,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5435750933033303,
            "auditor_fn_violation": 0.010474014534243565,
            "auditor_fp_violation": 0.005879113105344009,
            "ave_precision_score": 0.537027422711681,
            "fpr": 0.22697368421052633,
            "logloss": 0.6892554756816782,
            "mae": 0.4967429808814797,
            "precision": 0.5614406779661016,
            "recall": 0.5543933054393305
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.5576345503770734,
            "auditor_fn_violation": 0.006143401378114369,
            "auditor_fp_violation": 0.00951083185081444,
            "ave_precision_score": 0.5524420663865921,
            "fpr": 0.21844127332601537,
            "logloss": 0.6891517475447486,
            "mae": 0.49672394951664395,
            "precision": 0.5626373626373626,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6342416912411049,
            "auditor_fn_violation": 0.05839848051090068,
            "auditor_fp_violation": 0.06030701754385966,
            "ave_precision_score": 0.5678190205641566,
            "fpr": 0.3223684210526316,
            "logloss": 0.693786832590625,
            "mae": 0.4858215825076689,
            "precision": 0.5572289156626506,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6641105811949539,
            "auditor_fn_violation": 0.056337573448698906,
            "auditor_fp_violation": 0.05859924044563887,
            "ave_precision_score": 0.5981305982384204,
            "fpr": 0.3040614709110867,
            "logloss": 0.6775398673922072,
            "mae": 0.4783496143854541,
            "precision": 0.5764525993883792,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6331411017265463,
            "auditor_fn_violation": 0.05896966527196652,
            "auditor_fp_violation": 0.06030701754385966,
            "ave_precision_score": 0.5670118459450771,
            "fpr": 0.3223684210526316,
            "logloss": 0.694281656122301,
            "mae": 0.4856303277049671,
            "precision": 0.5565610859728507,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6638531132109328,
            "auditor_fn_violation": 0.056950991153870985,
            "auditor_fp_violation": 0.05859924044563887,
            "ave_precision_score": 0.5978564664076782,
            "fpr": 0.3040614709110867,
            "logloss": 0.6778601910510542,
            "mae": 0.4780970112421641,
            "precision": 0.5758039816232772,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8078260777440025,
            "auditor_fn_violation": 0.0009038023930118235,
            "auditor_fp_violation": 0.0076754385964912285,
            "ave_precision_score": 0.8073053902329522,
            "fpr": 0.10197368421052631,
            "logloss": 2.016261671889324,
            "mae": 0.42812907863676397,
            "precision": 0.7785714285714286,
            "recall": 0.6841004184100419
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.798033886596219,
            "auditor_fn_violation": 0.01721028696879411,
            "auditor_fp_violation": 0.008122941822173437,
            "ave_precision_score": 0.7974387530953084,
            "fpr": 0.09549945115257959,
            "logloss": 2.0628040531729437,
            "mae": 0.4387133765663407,
            "precision": 0.7769230769230769,
            "recall": 0.6365546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7256131178689026,
            "auditor_fn_violation": 0.00027297584966601247,
            "auditor_fp_violation": 0.028273809523809527,
            "ave_precision_score": 0.706017335926996,
            "fpr": 0.13267543859649122,
            "logloss": 2.1019145080687767,
            "mae": 0.29891328000588724,
            "precision": 0.740343347639485,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7176041388431063,
            "auditor_fn_violation": 0.006731452185704138,
            "auditor_fp_violation": 0.03931009248394464,
            "ave_precision_score": 0.697215144807685,
            "fpr": 0.13611416026344675,
            "logloss": 2.1654879055019376,
            "mae": 0.30752209285999343,
            "precision": 0.7298474945533769,
            "recall": 0.7037815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7082271240526636,
            "auditor_fn_violation": 0.003399581589958161,
            "auditor_fp_violation": 0.027381962971946,
            "ave_precision_score": 0.6916846207480789,
            "fpr": 0.1425438596491228,
            "logloss": 2.0108468549063327,
            "mae": 0.30691435271000816,
            "precision": 0.7286012526096033,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7014029950021881,
            "auditor_fn_violation": 0.010179044175299105,
            "auditor_fp_violation": 0.03290561086087034,
            "ave_precision_score": 0.684033720803572,
            "fpr": 0.14270032930845225,
            "logloss": 2.100613427692122,
            "mae": 0.3125507388866591,
            "precision": 0.7245762711864406,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7663679897162841,
            "auditor_fn_violation": 0.0028696872935476793,
            "auditor_fp_violation": 0.01722552348613469,
            "ave_precision_score": 0.7285156317978119,
            "fpr": 0.18969298245614036,
            "logloss": 4.132478850550244,
            "mae": 0.30037207264824967,
            "precision": 0.6888489208633094,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7812183973728276,
            "auditor_fn_violation": 0.0110784159986717,
            "auditor_fp_violation": 0.026824129099007037,
            "ave_precision_score": 0.7532616387672033,
            "fpr": 0.17892425905598244,
            "logloss": 3.722870598070832,
            "mae": 0.29476146716799606,
            "precision": 0.6975881261595547,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.847392484267765,
            "auditor_fn_violation": 0.010861686119063355,
            "auditor_fp_violation": 0.006119128466327108,
            "ave_precision_score": 0.842603769735382,
            "fpr": 0.1074561403508772,
            "logloss": 0.8199693395947063,
            "mae": 0.2967282476362582,
            "precision": 0.7864923747276689,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8535138557889324,
            "auditor_fn_violation": 0.02159876025053271,
            "auditor_fp_violation": 0.015223891895983955,
            "ave_precision_score": 0.8526530656152588,
            "fpr": 0.10208562019758508,
            "logloss": 0.6578635268663474,
            "mae": 0.3047780249127832,
            "precision": 0.7837209302325582,
            "recall": 0.707983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7532654444666006,
            "auditor_fn_violation": 0.0027894002789400304,
            "auditor_fp_violation": 0.01775103080281349,
            "ave_precision_score": 0.7392045748732682,
            "fpr": 0.20285087719298245,
            "logloss": 1.8527294007919577,
            "mae": 0.30163934001868864,
            "precision": 0.6771378708551483,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7779271211591906,
            "auditor_fn_violation": 0.013366048944275849,
            "auditor_fp_violation": 0.026662629168401532,
            "ave_precision_score": 0.7676744230970685,
            "fpr": 0.20087815587266739,
            "logloss": 1.6110138304640038,
            "mae": 0.3025697980860462,
            "precision": 0.6795096322241682,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7463231366461099,
            "auditor_fn_violation": 0.007347408793951405,
            "auditor_fp_violation": 0.011682431886167032,
            "ave_precision_score": 0.7313136547562729,
            "fpr": 0.19298245614035087,
            "logloss": 1.753995917500069,
            "mae": 0.29644709592112606,
            "precision": 0.6949740034662045,
            "recall": 0.8389121338912134
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7480813586844905,
            "auditor_fn_violation": 0.012937117766975068,
            "auditor_fp_violation": 0.020301045964394325,
            "ave_precision_score": 0.7355063697516144,
            "fpr": 0.2030735455543359,
            "logloss": 1.6686031494866425,
            "mae": 0.3053600556956158,
            "precision": 0.6788194444444444,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7424602568590533,
            "auditor_fn_violation": 0.008588416648315356,
            "auditor_fp_violation": 0.016149244077936775,
            "ave_precision_score": 0.7269342354222575,
            "fpr": 0.20065789473684212,
            "logloss": 1.813068625268094,
            "mae": 0.2978468449714343,
            "precision": 0.6882453151618398,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7429542689939719,
            "auditor_fn_violation": 0.011588060031916174,
            "auditor_fp_violation": 0.02117667840064601,
            "ave_precision_score": 0.730065051623956,
            "fpr": 0.20636663007683864,
            "logloss": 1.7384977849740797,
            "mae": 0.3075607497391166,
            "precision": 0.6764199655765921,
            "recall": 0.8256302521008403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.725603443300762,
            "auditor_fn_violation": 0.00027297584966601247,
            "auditor_fp_violation": 0.028273809523809527,
            "ave_precision_score": 0.7060054963370757,
            "fpr": 0.13267543859649122,
            "logloss": 2.1018813702023835,
            "mae": 0.29891558290269854,
            "precision": 0.740343347639485,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7176084560029915,
            "auditor_fn_violation": 0.006731452185704138,
            "auditor_fp_violation": 0.03931009248394464,
            "ave_precision_score": 0.6972132404443826,
            "fpr": 0.13611416026344675,
            "logloss": 2.1654188227005275,
            "mae": 0.3075228441109415,
            "precision": 0.7298474945533769,
            "recall": 0.7037815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.766352302454959,
            "auditor_fn_violation": 0.0028696872935476793,
            "auditor_fp_violation": 0.01722552348613469,
            "ave_precision_score": 0.7285155375808984,
            "fpr": 0.18969298245614036,
            "logloss": 4.1335889469897795,
            "mae": 0.3003814485127078,
            "precision": 0.6888489208633094,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7812698531524582,
            "auditor_fn_violation": 0.0110784159986717,
            "auditor_fp_violation": 0.026824129099007037,
            "ave_precision_score": 0.7533190180611489,
            "fpr": 0.17892425905598244,
            "logloss": 3.7236241330276534,
            "mae": 0.2947606924619584,
            "precision": 0.6975881261595547,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7115646590516016,
            "auditor_fn_violation": 0.0014635175805622891,
            "auditor_fp_violation": 0.030461739024981817,
            "ave_precision_score": 0.6868418835493444,
            "fpr": 0.13706140350877194,
            "logloss": 2.388204279795697,
            "mae": 0.31654523148800334,
            "precision": 0.7276688453159041,
            "recall": 0.698744769874477
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7020794830776931,
            "auditor_fn_violation": 0.012789528544678028,
            "auditor_fp_violation": 0.04057685756463152,
            "ave_precision_score": 0.6769300744513689,
            "fpr": 0.14270032930845225,
            "logloss": 2.471887277910585,
            "mae": 0.32363751762436443,
            "precision": 0.717391304347826,
            "recall": 0.6932773109243697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8360682746239143,
            "auditor_fn_violation": 0.0025003670263524956,
            "auditor_fp_violation": 0.007912927479990298,
            "ave_precision_score": 0.8326867085206202,
            "fpr": 0.10087719298245613,
            "logloss": 1.980150159191553,
            "mae": 0.27253971288316603,
            "precision": 0.7918552036199095,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8502891613288832,
            "auditor_fn_violation": 0.013730409836821672,
            "auditor_fp_violation": 0.014512282826753473,
            "ave_precision_score": 0.8498041652436741,
            "fpr": 0.10098792535675083,
            "logloss": 1.7903379033946234,
            "mae": 0.27328172245048754,
            "precision": 0.786046511627907,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6054623209666459,
            "auditor_fn_violation": 0.010474014534243565,
            "auditor_fp_violation": 0.005879113105344009,
            "ave_precision_score": 0.5336523332032899,
            "fpr": 0.22697368421052633,
            "logloss": 0.6891602755086041,
            "mae": 0.4956656625461683,
            "precision": 0.5614406779661016,
            "recall": 0.5543933054393305
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.633393432081927,
            "auditor_fn_violation": 0.006143401378114369,
            "auditor_fp_violation": 0.00951083185081444,
            "ave_precision_score": 0.5666083084480267,
            "fpr": 0.21844127332601537,
            "logloss": 0.6891090546487109,
            "mae": 0.4957225953773662,
            "precision": 0.5626373626373626,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7846028528000916,
            "auditor_fn_violation": 0.005911418189826028,
            "auditor_fp_violation": 0.012066456463740001,
            "ave_precision_score": 0.776044255796587,
            "fpr": 0.18092105263157895,
            "logloss": 2.441831600571261,
            "mae": 0.2958434049542746,
            "precision": 0.7,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8021286677135083,
            "auditor_fn_violation": 0.011461225544004654,
            "auditor_fp_violation": 0.027631628752034534,
            "ave_precision_score": 0.7960479293948609,
            "fpr": 0.18111964873765093,
            "logloss": 2.177110871569059,
            "mae": 0.29661114576836883,
            "precision": 0.6944444444444444,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7530016174380139,
            "auditor_fn_violation": 0.007202892167657642,
            "auditor_fp_violation": 0.01172790848087962,
            "ave_precision_score": 0.7390303584036368,
            "fpr": 0.18530701754385964,
            "logloss": 1.699054235250673,
            "mae": 0.29704696802250735,
            "precision": 0.7014134275618374,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7628807839640531,
            "auditor_fn_violation": 0.011654936398269521,
            "auditor_fp_violation": 0.020023467958666115,
            "ave_precision_score": 0.7512494035058206,
            "fpr": 0.19758507135016465,
            "logloss": 1.5699130359460938,
            "mae": 0.30387571834527066,
            "precision": 0.6836555360281195,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7240748833366601,
            "auditor_fn_violation": 0.0017158481979006098,
            "auditor_fp_violation": 0.029994340690435765,
            "ave_precision_score": 0.7045207848900044,
            "fpr": 0.13486842105263158,
            "logloss": 2.1112667923115924,
            "mae": 0.29936729185902916,
            "precision": 0.7377398720682303,
            "recall": 0.7238493723849372
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7160315495183929,
            "auditor_fn_violation": 0.006731452185704138,
            "auditor_fp_violation": 0.03736452300743152,
            "ave_precision_score": 0.6949382103718182,
            "fpr": 0.1394072447859495,
            "logloss": 2.2131948487369444,
            "mae": 0.3079556685672507,
            "precision": 0.7251082251082251,
            "recall": 0.7037815126050421
        }
    }
]