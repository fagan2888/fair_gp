[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.828083054856602,
            "auditor_fn_violation": 0.013579273597216177,
            "auditor_fp_violation": 0.023108296442039683,
            "ave_precision_score": 0.8289262507667603,
            "fpr": 0.13157894736842105,
            "logloss": 0.7733956944484469,
            "mae": 0.2639329429567203,
            "precision": 0.7595190380761523,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8270096158104558,
            "auditor_fn_violation": 0.014101875423313174,
            "auditor_fp_violation": 0.025045363919442648,
            "ave_precision_score": 0.8272489179329774,
            "fpr": 0.12733260153677278,
            "logloss": 0.8499741696066226,
            "mae": 0.2808837349014389,
            "precision": 0.7478260869565218,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.843933012660032,
            "auditor_fn_violation": 0.0018531607945483544,
            "auditor_fp_violation": 0.0009453393999016183,
            "ave_precision_score": 0.8440870410152315,
            "fpr": 0.45723684210526316,
            "logloss": 3.355193422015177,
            "mae": 0.4643104332649789,
            "precision": 0.5340782122905028,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.791434469589148,
            "auditor_fn_violation": 0.0009435504589298643,
            "auditor_fp_violation": 0.003191031260656479,
            "ave_precision_score": 0.7928644252722432,
            "fpr": 0.4654226125137212,
            "logloss": 3.3726330203815325,
            "mae": 0.4676049372636463,
            "precision": 0.5246636771300448,
            "recall": 0.9957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8313767964295775,
            "auditor_fn_violation": 0.006569885457445275,
            "auditor_fp_violation": 0.010780455812428268,
            "ave_precision_score": 0.8113396855046704,
            "fpr": 0.0625,
            "logloss": 0.5077179038056787,
            "mae": 0.3354266309301908,
            "precision": 0.8442622950819673,
            "recall": 0.6384297520661157
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8063162978032428,
            "auditor_fn_violation": 0.008085573487166316,
            "auditor_fp_violation": 0.010048512635936188,
            "ave_precision_score": 0.7829020326974037,
            "fpr": 0.06695938529088913,
            "logloss": 0.5705524810307716,
            "mae": 0.3489527964819341,
            "precision": 0.8189910979228486,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 32400,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.6334878223721022,
            "auditor_fn_violation": 0.003189792663476869,
            "auditor_fp_violation": 0.0048932202000327935,
            "ave_precision_score": 0.5535233467977718,
            "fpr": 0.019736842105263157,
            "logloss": 0.8134675455214473,
            "mae": 0.4992216578439662,
            "precision": 0.7096774193548387,
            "recall": 0.09090909090909091
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.6319729259433158,
            "auditor_fn_violation": 0.001072004110516864,
            "auditor_fp_violation": 0.0019614139106063216,
            "ave_precision_score": 0.5377714149271611,
            "fpr": 0.018660812294182216,
            "logloss": 0.801584504824995,
            "mae": 0.49362343503928996,
            "precision": 0.7068965517241379,
            "recall": 0.08723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7051240914202561,
            "auditor_fn_violation": 0.00660613310134841,
            "auditor_fp_violation": 0.004698516150188565,
            "ave_precision_score": 0.7058513765800506,
            "fpr": 0.1337719298245614,
            "logloss": 0.9029104383048949,
            "mae": 0.427803405452052,
            "precision": 0.6797900262467191,
            "recall": 0.5351239669421488
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7192270417400701,
            "auditor_fn_violation": 0.013774902492000862,
            "auditor_fp_violation": 0.022357131656175092,
            "ave_precision_score": 0.7195854313596144,
            "fpr": 0.12184412733260154,
            "logloss": 0.9170041039456805,
            "mae": 0.41895320818065745,
            "precision": 0.6782608695652174,
            "recall": 0.4978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7647283046282843,
            "auditor_fn_violation": 0.0028409090909090914,
            "auditor_fp_violation": 0.003671196097720953,
            "ave_precision_score": 0.5352176709577707,
            "fpr": 0.4550438596491228,
            "logloss": 0.7271298758203601,
            "mae": 0.48738690946055085,
            "precision": 0.5352743561030235,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7625698324022346,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0037162321935726426,
            "ave_precision_score": 0.5251396648044693,
            "fpr": 0.4665203073545554,
            "logloss": 0.7317491424848179,
            "mae": 0.48953228685125694,
            "precision": 0.5251396648044693,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7304375963517232,
            "auditor_fn_violation": 0.08886562998405105,
            "auditor_fp_violation": 0.10128709624528613,
            "ave_precision_score": 0.5767827197705431,
            "fpr": 0.2850877192982456,
            "logloss": 0.6939560067691329,
            "mae": 0.4712221438980155,
            "precision": 0.5792880258899676,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7112623521379292,
            "auditor_fn_violation": 0.08511572506247518,
            "auditor_fp_violation": 0.10161517955151327,
            "ave_precision_score": 0.5497568005065262,
            "fpr": 0.31613611416026344,
            "logloss": 0.7108393236601567,
            "mae": 0.47875294898985243,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 32400,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5980599646533846,
            "auditor_fn_violation": 0.002478432651877645,
            "auditor_fp_violation": 0.0011579767174946713,
            "ave_precision_score": 0.5941177138137352,
            "fpr": 0.0021929824561403508,
            "logloss": 11.095489752162136,
            "mae": 0.5196654544052169,
            "precision": 0.75,
            "recall": 0.012396694214876033
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5917748316423428,
            "auditor_fn_violation": 0.0002242100100427467,
            "auditor_fp_violation": 0.0013938982105831722,
            "ave_precision_score": 0.5835827102194764,
            "fpr": 0.007683863885839737,
            "logloss": 10.48685751881366,
            "mae": 0.5061048946762315,
            "precision": 0.5333333333333333,
            "recall": 0.01702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6960247239649762,
            "auditor_fn_violation": 0.09573002754820939,
            "auditor_fp_violation": 0.049275495982948024,
            "ave_precision_score": 0.5825464829955544,
            "fpr": 0.13925438596491227,
            "logloss": 0.6816943490348105,
            "mae": 0.49207723768133865,
            "precision": 0.6412429378531074,
            "recall": 0.4690082644628099
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.672807124851261,
            "auditor_fn_violation": 0.09120909918957423,
            "auditor_fp_violation": 0.05354560411797358,
            "ave_precision_score": 0.5586972223294806,
            "fpr": 0.14928649835345773,
            "logloss": 0.6840109641505374,
            "mae": 0.49323632217264857,
            "precision": 0.6103151862464183,
            "recall": 0.4531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.850659629601839,
            "auditor_fn_violation": 0.005147165434246777,
            "auditor_fp_violation": 0.011800090178717828,
            "ave_precision_score": 0.8510083943877674,
            "fpr": 0.08662280701754387,
            "logloss": 0.5117888488405251,
            "mae": 0.32575964937419294,
            "precision": 0.8183908045977012,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8481951529165523,
            "auditor_fn_violation": 0.011182474250881662,
            "auditor_fp_violation": 0.010260086471471138,
            "ave_precision_score": 0.8484067754273426,
            "fpr": 0.07903402854006586,
            "logloss": 0.5257940219328664,
            "mae": 0.32874257853223365,
            "precision": 0.812987012987013,
            "recall": 0.6659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6883348135475104,
            "auditor_fn_violation": 0.002990430622009576,
            "auditor_fp_violation": 0.008290293490736188,
            "ave_precision_score": 0.7207617841884966,
            "fpr": 0.043859649122807015,
            "logloss": 0.6132290571431512,
            "mae": 0.4315234569081089,
            "precision": 0.8523985239852399,
            "recall": 0.4772727272727273
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7004584245389756,
            "auditor_fn_violation": 0.004764462713408239,
            "auditor_fp_violation": 0.005169868898895088,
            "ave_precision_score": 0.7027287436709689,
            "fpr": 0.04061470911086718,
            "logloss": 0.6244884598438437,
            "mae": 0.4378419031361455,
            "precision": 0.8438818565400844,
            "recall": 0.425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6443353128383814,
            "auditor_fn_violation": 0.017149666521676096,
            "auditor_fp_violation": 0.023067306115756688,
            "ave_precision_score": 0.6455887552629189,
            "fpr": 0.2543859649122807,
            "logloss": 1.824820927594623,
            "mae": 0.43928733884858817,
            "precision": 0.6264090177133655,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6288404252035978,
            "auditor_fn_violation": 0.009650372515589601,
            "auditor_fp_violation": 0.027096385572157877,
            "ave_precision_score": 0.6294992186567347,
            "fpr": 0.25466520307354557,
            "logloss": 1.641343234868453,
            "mae": 0.44142434535943353,
            "precision": 0.6054421768707483,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5881685919694362,
            "auditor_fn_violation": 0.05494236624619401,
            "auditor_fp_violation": 0.05749661829808165,
            "ave_precision_score": 0.5903081696951811,
            "fpr": 0.21600877192982457,
            "logloss": 0.6861987966395052,
            "mae": 0.49344984585778756,
            "precision": 0.5491990846681922,
            "recall": 0.49586776859504134
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.568459535351251,
            "auditor_fn_violation": 0.051657052105472126,
            "auditor_fp_violation": 0.05343608354428491,
            "ave_precision_score": 0.5696776746775827,
            "fpr": 0.22941822173435786,
            "logloss": 0.688874581669449,
            "mae": 0.4946164744287631,
            "precision": 0.5426695842450766,
            "recall": 0.5276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6884426770475657,
            "auditor_fn_violation": 0.005210598811077282,
            "auditor_fp_violation": 0.005587493851451084,
            "ave_precision_score": 0.5412889398972042,
            "fpr": 0.34978070175438597,
            "logloss": 10.951587606615423,
            "mae": 0.40503263547164725,
            "precision": 0.5846354166666666,
            "recall": 0.9276859504132231
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7057055848713328,
            "auditor_fn_violation": 0.0039797276782586365,
            "auditor_fp_violation": 0.005555680010752931,
            "ave_precision_score": 0.5537145307793293,
            "fpr": 0.3424807903402854,
            "logloss": 10.692852598151296,
            "mae": 0.3843844843073537,
            "precision": 0.5867549668874172,
            "recall": 0.9425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7867043264179384,
            "auditor_fn_violation": 0.0016266130201536902,
            "auditor_fp_violation": 0.005697655353336611,
            "ave_precision_score": 0.6095811403332534,
            "fpr": 0.43640350877192985,
            "logloss": 12.650580581458193,
            "mae": 0.4481120654917607,
            "precision": 0.545662100456621,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7593427420808636,
            "auditor_fn_violation": 0.002312165728565757,
            "auditor_fp_violation": 0.007554430480571307,
            "ave_precision_score": 0.5785250429899985,
            "fpr": 0.446761800219539,
            "logloss": 13.07727526693515,
            "mae": 0.46901997990453287,
            "precision": 0.5250875145857643,
            "recall": 0.9574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5870091072954219,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5317982617441983,
            "fpr": 0.4692982456140351,
            "logloss": 0.6913076232057856,
            "mae": 0.4985386102476664,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.563787663452153,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5077747371778369,
            "fpr": 0.4840834248079034,
            "logloss": 0.692632260975032,
            "mae": 0.4991997450295709,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8485246420939161,
            "auditor_fn_violation": 0.0009605625634333776,
            "auditor_fp_violation": 0.009320175438596492,
            "ave_precision_score": 0.7441113338502563,
            "fpr": 0.08662280701754387,
            "logloss": 0.534348122376009,
            "mae": 0.36423792134512933,
            "precision": 0.8192219679633868,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8273968117593369,
            "auditor_fn_violation": 0.007672186281150012,
            "auditor_fp_violation": 0.009207195501691344,
            "ave_precision_score": 0.7140101204431468,
            "fpr": 0.09549945115257959,
            "logloss": 0.5548875091168397,
            "mae": 0.3736664459812654,
            "precision": 0.7938388625592417,
            "recall": 0.7127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7653508771929824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5307017543859649,
            "fpr": 0.4692982456140351,
            "logloss": 0.6929202968227206,
            "mae": 0.49635502016335203,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7579582875960482,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5159165751920965,
            "fpr": 0.4840834248079034,
            "logloss": 0.6964475899436912,
            "mae": 0.4981103491704629,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8208822629889171,
            "auditor_fn_violation": 0.006352399594026393,
            "auditor_fp_violation": 0.021596778160354158,
            "ave_precision_score": 0.8213493344816548,
            "fpr": 0.1425438596491228,
            "logloss": 0.5253848826016226,
            "mae": 0.35178817123820055,
            "precision": 0.7470817120622568,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8089855002625874,
            "auditor_fn_violation": 0.008529322465375909,
            "auditor_fp_violation": 0.022648356818029076,
            "ave_precision_score": 0.8093211070985433,
            "fpr": 0.14818880351262348,
            "logloss": 0.5541470866199191,
            "mae": 0.3628579683225647,
            "precision": 0.7261663286004056,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8550038164408847,
            "auditor_fn_violation": 0.0018803465274757213,
            "auditor_fp_violation": 0.008771929824561405,
            "ave_precision_score": 0.8557633607207098,
            "fpr": 0.08771929824561403,
            "logloss": 0.48735539052255467,
            "mae": 0.3234084867535306,
            "precision": 0.815668202764977,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8470287955806124,
            "auditor_fn_violation": 0.01470911086717893,
            "auditor_fp_violation": 0.006250140012097045,
            "ave_precision_score": 0.8472422278452238,
            "fpr": 0.07903402854006586,
            "logloss": 0.5123232831261475,
            "mae": 0.3321744893190914,
            "precision": 0.8204488778054863,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7965274230492794,
            "auditor_fn_violation": 0.025516075830071046,
            "auditor_fp_violation": 0.02489137563535007,
            "ave_precision_score": 0.7647384846725501,
            "fpr": 0.15570175438596492,
            "logloss": 0.5544818598312676,
            "mae": 0.38739430189557506,
            "precision": 0.723196881091618,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7348891158270052,
            "auditor_fn_violation": 0.019632389004367423,
            "auditor_fp_violation": 0.03357303404347469,
            "ave_precision_score": 0.7218957042301072,
            "fpr": 0.15148188803512624,
            "logloss": 0.5846534714372005,
            "mae": 0.3969130176645995,
            "precision": 0.7125,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7983393340495327,
            "auditor_fn_violation": 0.006578947368421054,
            "auditor_fp_violation": 0.0034534349893425207,
            "ave_precision_score": 0.7839902042249431,
            "fpr": 0.07236842105263158,
            "logloss": 0.5958375280496833,
            "mae": 0.38404224843067997,
            "precision": 0.7857142857142857,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7944322517193152,
            "auditor_fn_violation": 0.00798748160777262,
            "auditor_fp_violation": 0.009844406112243654,
            "ave_precision_score": 0.7820515666838029,
            "fpr": 0.07683863885839737,
            "logloss": 0.567791646320838,
            "mae": 0.38310240241207894,
            "precision": 0.7627118644067796,
            "recall": 0.4787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5819481443749597,
            "auditor_fn_violation": 0.006268576917500367,
            "auditor_fp_violation": 0.008853910477127398,
            "ave_precision_score": 0.576435655476735,
            "fpr": 0.08771929824561403,
            "logloss": 0.7193174300017334,
            "mae": 0.4936488377289814,
            "precision": 0.5767195767195767,
            "recall": 0.22520661157024793
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5836109827391792,
            "auditor_fn_violation": 0.005381040241025765,
            "auditor_fp_violation": 0.013493432499234601,
            "ave_precision_score": 0.5688995960769611,
            "fpr": 0.07793633369923161,
            "logloss": 0.7129398774227741,
            "mae": 0.49368674178024025,
            "precision": 0.5477707006369427,
            "recall": 0.1829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7133351909194215,
            "auditor_fn_violation": 0.00443580542264753,
            "auditor_fp_violation": 0.014408099688473537,
            "ave_precision_score": 0.5917693120847163,
            "fpr": 0.34100877192982454,
            "logloss": 0.6804629324392999,
            "mae": 0.4618912090204264,
            "precision": 0.5797297297297297,
            "recall": 0.8863636363636364
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6760619239721781,
            "auditor_fn_violation": 0.01285470724245043,
            "auditor_fp_violation": 0.014740473576917051,
            "ave_precision_score": 0.5730118073119017,
            "fpr": 0.34577387486278816,
            "logloss": 0.6913070235684505,
            "mae": 0.467015108819458,
            "precision": 0.5631067961165048,
            "recall": 0.8638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6883041558716203,
            "auditor_fn_violation": 0.009587501812382231,
            "auditor_fp_violation": 0.001122110181997053,
            "ave_precision_score": 0.6888871815927985,
            "fpr": 0.08662280701754387,
            "logloss": 0.6765255803689662,
            "mae": 0.44805802807023976,
            "precision": 0.7018867924528301,
            "recall": 0.384297520661157
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6564176144825932,
            "auditor_fn_violation": 0.004159562790480428,
            "auditor_fp_violation": 0.003629113555411187,
            "ave_precision_score": 0.657299155944007,
            "fpr": 0.09659714599341383,
            "logloss": 0.6858254519472669,
            "mae": 0.4549185833888605,
            "precision": 0.6549019607843137,
            "recall": 0.3553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7110860187577899,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7117249142666444,
            "fpr": 0.4692982456140351,
            "logloss": 1.4948132697909118,
            "mae": 0.46076572915179687,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.667743028854149,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.66860069581384,
            "fpr": 0.4840834248079034,
            "logloss": 1.5322323029935139,
            "mae": 0.4754324645687275,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7314951337900127,
            "auditor_fn_violation": 0.002668732782369146,
            "auditor_fp_violation": 0.001373175930480423,
            "ave_precision_score": 0.5212920689608325,
            "fpr": 0.46271929824561403,
            "logloss": 0.6942395438305442,
            "mae": 0.49919829994701503,
            "precision": 0.5290178571428571,
            "recall": 0.9793388429752066
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.7292704886138972,
            "auditor_fn_violation": 0.003367821192516991,
            "auditor_fp_violation": 0.003449898071193355,
            "ave_precision_score": 0.5143339404574818,
            "fpr": 0.4774972557628979,
            "logloss": 0.6946143680803814,
            "mae": 0.4994502609634504,
            "precision": 0.5150501672240803,
            "recall": 0.9829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 32400,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8566220906018838,
            "auditor_fn_violation": 0.0013592866463679892,
            "auditor_fp_violation": 0.010662608624364654,
            "ave_precision_score": 0.856873300156777,
            "fpr": 0.14364035087719298,
            "logloss": 0.5118678627444688,
            "mae": 0.33206755561925666,
            "precision": 0.7551401869158878,
            "recall": 0.8347107438016529
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8333602289127555,
            "auditor_fn_violation": 0.0068197211388000105,
            "auditor_fp_violation": 0.023014255098307165,
            "ave_precision_score": 0.8337410588707537,
            "fpr": 0.15148188803512624,
            "logloss": 0.5237044857135369,
            "mae": 0.33965456047382625,
            "precision": 0.7330754352030948,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.787779097278432,
            "auditor_fn_violation": 0.009904668696534726,
            "auditor_fp_violation": 0.02521929824561405,
            "ave_precision_score": 0.5996944305196377,
            "fpr": 0.36622807017543857,
            "logloss": 0.7057727836602959,
            "mae": 0.46740851809450407,
            "precision": 0.581453634085213,
            "recall": 0.9586776859504132
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.7669428469140708,
            "auditor_fn_violation": 0.004472522596165075,
            "auditor_fp_violation": 0.022118177677217993,
            "ave_precision_score": 0.5744936930268891,
            "fpr": 0.37102085620197583,
            "logloss": 0.7158180301628171,
            "mae": 0.47295063449444025,
            "precision": 0.5683269476372924,
            "recall": 0.9468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7532518572809278,
            "auditor_fn_violation": 0.013579273597216182,
            "auditor_fp_violation": 0.01989824151500246,
            "ave_precision_score": 0.6854203119482559,
            "fpr": 0.13925438596491227,
            "logloss": 0.5965416850832725,
            "mae": 0.4186210855024687,
            "precision": 0.7190265486725663,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7376408906434104,
            "auditor_fn_violation": 0.008832940187308784,
            "auditor_fp_violation": 0.02718101510637186,
            "ave_precision_score": 0.6693901461982099,
            "fpr": 0.14050493962678376,
            "logloss": 0.6126483424363987,
            "mae": 0.4228635630381225,
            "precision": 0.7002341920374707,
            "recall": 0.6361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.793085192003405,
            "auditor_fn_violation": 0.005795092069015521,
            "auditor_fp_violation": 0.00783939990162322,
            "ave_precision_score": 0.7907418593825164,
            "fpr": 0.10087719298245613,
            "logloss": 0.5493744384328665,
            "mae": 0.35960568807113086,
            "precision": 0.7899543378995434,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7870956892827571,
            "auditor_fn_violation": 0.005539855664806038,
            "auditor_fp_violation": 0.005610440297597269,
            "ave_precision_score": 0.7787751076096194,
            "fpr": 0.10757409440175632,
            "logloss": 0.5568382589834013,
            "mae": 0.36596118248628146,
            "precision": 0.7677725118483413,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6670858305974817,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5378495985996204,
            "fpr": 0.4692982456140351,
            "logloss": 0.6918099972974061,
            "mae": 0.49916796183638407,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6622988209496413,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5249045967390773,
            "fpr": 0.4840834248079034,
            "logloss": 0.6925280788237528,
            "mae": 0.49952542677145495,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8219690925092624,
            "auditor_fn_violation": 0.0058811802232854905,
            "auditor_fp_violation": 0.010401295294310543,
            "ave_precision_score": 0.7066337804222438,
            "fpr": 0.11403508771929824,
            "logloss": 0.5722374332862461,
            "mae": 0.3980827053453316,
            "precision": 0.7719298245614035,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7894198992776653,
            "auditor_fn_violation": 0.005273606277880286,
            "auditor_fp_violation": 0.006314856714731266,
            "ave_precision_score": 0.6637106643473899,
            "fpr": 0.132821075740944,
            "logloss": 0.6033557022471164,
            "mae": 0.4127001684858299,
            "precision": 0.7293064876957495,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6707817545878438,
            "auditor_fn_violation": 0.0005618384804987677,
            "auditor_fp_violation": 0.0038530906706017386,
            "ave_precision_score": 0.5427913835190876,
            "fpr": 0.4605263157894737,
            "logloss": 0.6879060345260727,
            "mae": 0.49347595424440344,
            "precision": 0.5348837209302325,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6667571377189598,
            "auditor_fn_violation": 0.0012611813064904128,
            "auditor_fp_violation": 0.003011815776438657,
            "ave_precision_score": 0.5320778265494766,
            "fpr": 0.4665203073545554,
            "logloss": 0.686992747287064,
            "mae": 0.49218006253765917,
            "precision": 0.5240761478163494,
            "recall": 0.9957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.8088870285963535,
            "auditor_fn_violation": 0.008162516311439758,
            "auditor_fp_violation": 0.01349094113789146,
            "ave_precision_score": 0.809343640099911,
            "fpr": 0.3618421052631579,
            "logloss": 0.7455853012294998,
            "mae": 0.38332708181380376,
            "precision": 0.5849056603773585,
            "recall": 0.9607438016528925
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.8042102991074832,
            "auditor_fn_violation": 0.005679986921082747,
            "auditor_fp_violation": 0.01904911250998754,
            "ave_precision_score": 0.804510677937869,
            "fpr": 0.3699231613611416,
            "logloss": 0.7575625472086932,
            "mae": 0.3954602970892991,
            "precision": 0.5696040868454662,
            "recall": 0.948936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8777605242438189,
            "auditor_fn_violation": 0.015301036682615631,
            "auditor_fp_violation": 0.007401315789473686,
            "ave_precision_score": 0.8601435326321898,
            "fpr": 0.11732456140350878,
            "logloss": 0.47258910961534956,
            "mae": 0.32564997202471685,
            "precision": 0.782520325203252,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8483927972843885,
            "auditor_fn_violation": 0.013660461966041523,
            "auditor_fp_violation": 0.014897287125607651,
            "ave_precision_score": 0.8250889532159837,
            "fpr": 0.10867178924259056,
            "logloss": 0.5063528230847606,
            "mae": 0.3340585024456946,
            "precision": 0.7780269058295964,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7550275861986258,
            "auditor_fn_violation": 0.012224517906336097,
            "auditor_fp_violation": 0.011149368748975241,
            "ave_precision_score": 0.7553532529247705,
            "fpr": 0.08333333333333333,
            "logloss": 1.0373834067671044,
            "mae": 0.3169067468669083,
            "precision": 0.790633608815427,
            "recall": 0.5929752066115702
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7312757646588343,
            "auditor_fn_violation": 0.015694700702991803,
            "auditor_fp_violation": 0.010192880664889449,
            "ave_precision_score": 0.7309932359884022,
            "fpr": 0.09220636663007684,
            "logloss": 1.1154205787470102,
            "mae": 0.32961824576155524,
            "precision": 0.7613636363636364,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.699847751615867,
            "auditor_fn_violation": 0.008821770334928229,
            "auditor_fp_violation": 0.018361104279390066,
            "ave_precision_score": 0.7010491819873961,
            "fpr": 0.3541666666666667,
            "logloss": 0.7520714896107428,
            "mae": 0.4186882967368267,
            "precision": 0.5885350318471337,
            "recall": 0.9545454545454546
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6291451355011355,
            "auditor_fn_violation": 0.007996823691524395,
            "auditor_fp_violation": 0.01658489960199228,
            "ave_precision_score": 0.6319707997494719,
            "fpr": 0.3578485181119649,
            "logloss": 0.7985457022088366,
            "mae": 0.4351451611488469,
            "precision": 0.5682119205298013,
            "recall": 0.9127659574468086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7666642263330006,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002192982456140351,
            "ave_precision_score": 0.5342918789935661,
            "fpr": 0.46271929824561403,
            "logloss": 15.947329355350325,
            "mae": 0.46352245473597004,
            "precision": 0.5342163355408388,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7593818984547461,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016303630855928164,
            "ave_precision_score": 0.5187637969094923,
            "fpr": 0.4796926454445664,
            "logloss": 16.531787263646986,
            "mae": 0.4796248252649764,
            "precision": 0.5181918412348401,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4331140350877193,
            "auc_prc": 0.5449019098057706,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.10231185440236104,
            "ave_precision_score": 0.5073632334356206,
            "fpr": 0.17543859649122806,
            "logloss": 19.579687863769358,
            "mae": 0.5668859649122807,
            "precision": 0.4425087108013937,
            "recall": 0.26239669421487605
        },
        "train": {
            "accuracy": 0.4456641053787047,
            "auc_prc": 0.5334845339271749,
            "auditor_fn_violation": 0.09039400238223137,
            "auditor_fp_violation": 0.10275767826340199,
            "ave_precision_score": 0.4957078899326723,
            "fpr": 0.16794731064763996,
            "logloss": 19.14621780223569,
            "mae": 0.5543358946212953,
            "precision": 0.4354243542435424,
            "recall": 0.251063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8616899113823842,
            "auditor_fn_violation": 0.0031716688415253,
            "auditor_fp_violation": 0.014794945892769317,
            "ave_precision_score": 0.8629086440667708,
            "fpr": 0.19407894736842105,
            "logloss": 0.5413519332652484,
            "mae": 0.28760630347594424,
            "precision": 0.7074380165289256,
            "recall": 0.8842975206611571
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8552446983619081,
            "auditor_fn_violation": 0.007123338860732888,
            "auditor_fp_violation": 0.025448598758932788,
            "ave_precision_score": 0.8554330229246815,
            "fpr": 0.19538968166849616,
            "logloss": 0.5767407703297441,
            "mae": 0.29997892057191905,
            "precision": 0.6904347826086956,
            "recall": 0.8446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8587812283478522,
            "auditor_fn_violation": 0.004168479048861828,
            "auditor_fp_violation": 0.010426914248237416,
            "ave_precision_score": 0.8520932404521835,
            "fpr": 0.07675438596491228,
            "logloss": 0.5015701027576939,
            "mae": 0.3086490806043066,
            "precision": 0.8356807511737089,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8361098594091847,
            "auditor_fn_violation": 0.007468995959548783,
            "auditor_fp_violation": 0.013062817516322302,
            "ave_precision_score": 0.8285253976739144,
            "fpr": 0.0801317233809001,
            "logloss": 0.5191504766307802,
            "mae": 0.3177060342182198,
            "precision": 0.8161209068010076,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7453791439811874,
            "auditor_fn_violation": 0.007974481658692186,
            "auditor_fp_violation": 0.016283407115920648,
            "ave_precision_score": 0.7460836056726454,
            "fpr": 0.18640350877192982,
            "logloss": 1.2365033715147917,
            "mae": 0.31860095822788403,
            "precision": 0.6903460837887068,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7484410123223637,
            "auditor_fn_violation": 0.010374384006352617,
            "auditor_fp_violation": 0.02963527159857723,
            "ave_precision_score": 0.7489345705969679,
            "fpr": 0.18551042810098792,
            "logloss": 1.2491945965552036,
            "mae": 0.32149096836053,
            "precision": 0.6737451737451737,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.732151169385016,
            "mae": 0.4927502952581435,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.3016771921821318,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0019564357027113807,
            "ave_precision_score": 0.5612847518690992,
            "fpr": 0.003293084522502744,
            "logloss": 0.7360504173854537,
            "mae": 0.4929044858749821,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.797320927966272,
            "auditor_fn_violation": 0.008744744091634048,
            "auditor_fp_violation": 0.012709563043121831,
            "ave_precision_score": 0.7368928479901848,
            "fpr": 0.22916666666666666,
            "logloss": 5.431250939017548,
            "mae": 0.30703650732685384,
            "precision": 0.6623586429725363,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7710347348098506,
            "auditor_fn_violation": 0.01117313216712988,
            "auditor_fp_violation": 0.03269189124607033,
            "ave_precision_score": 0.7015724239099979,
            "fpr": 0.2239297475301866,
            "logloss": 5.690617662054315,
            "mae": 0.3123543905860217,
            "precision": 0.6542372881355932,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7694757641235113,
            "auditor_fn_violation": 0.022070284181528194,
            "auditor_fp_violation": 0.013004181013280875,
            "ave_precision_score": 0.7693127760390186,
            "fpr": 0.1337719298245614,
            "logloss": 0.5804694314575879,
            "mae": 0.37828021161585,
            "precision": 0.7393162393162394,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7345616422536967,
            "auditor_fn_violation": 0.013753882803559332,
            "auditor_fp_violation": 0.02041563057714854,
            "ave_precision_score": 0.7337954062813512,
            "fpr": 0.141602634467618,
            "logloss": 0.6115783452386813,
            "mae": 0.3876093755201176,
            "precision": 0.7081447963800905,
            "recall": 0.6659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7631840170226989,
            "auditor_fn_violation": 0.013071806582572135,
            "auditor_fp_violation": 0.020356820790293495,
            "ave_precision_score": 0.7443144241299315,
            "fpr": 0.16557017543859648,
            "logloss": 1.7669908234287435,
            "mae": 0.337894166856514,
            "precision": 0.6986027944111777,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7510671842447554,
            "auditor_fn_violation": 0.007683863885839742,
            "auditor_fp_violation": 0.025296763418137108,
            "ave_precision_score": 0.7325047256796361,
            "fpr": 0.16245883644346873,
            "logloss": 1.8219322457097582,
            "mae": 0.3370354400240253,
            "precision": 0.6871035940803383,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5429914433785265,
            "auditor_fn_violation": 0.008341489053211543,
            "auditor_fp_violation": 0.016647196261682252,
            "ave_precision_score": 0.5412852113250991,
            "fpr": 0.3618421052631579,
            "logloss": 0.6911580244291503,
            "mae": 0.4984247680230622,
            "precision": 0.5319148936170213,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5195288628258693,
            "auditor_fn_violation": 0.009500899175561114,
            "auditor_fp_violation": 0.0045923967830820665,
            "ave_precision_score": 0.5197884898122916,
            "fpr": 0.3787047200878156,
            "logloss": 0.6921161772602764,
            "mae": 0.498879984888104,
            "precision": 0.5201668984700973,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6854252160656018,
            "auditor_fn_violation": 0.016773597216180963,
            "auditor_fp_violation": 0.009753135759960651,
            "ave_precision_score": 0.5950665869531345,
            "fpr": 0.1699561403508772,
            "logloss": 0.6806298808392676,
            "mae": 0.48054601794533564,
            "precision": 0.6163366336633663,
            "recall": 0.5144628099173554
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6641252646962648,
            "auditor_fn_violation": 0.019945348810052083,
            "auditor_fp_violation": 0.019225838890257904,
            "ave_precision_score": 0.5754248269138469,
            "fpr": 0.15916575192096596,
            "logloss": 0.683911608323816,
            "mae": 0.4818004045214271,
            "precision": 0.6049046321525886,
            "recall": 0.4723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 32400,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7820682664300621,
            "auditor_fn_violation": 0.014007448890822104,
            "auditor_fp_violation": 0.019726594523692412,
            "ave_precision_score": 0.7351001039832465,
            "fpr": 0.18421052631578946,
            "logloss": 4.341407350673586,
            "mae": 0.3157266868135946,
            "precision": 0.6894639556377079,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7600391090306586,
            "auditor_fn_violation": 0.008931032066702482,
            "auditor_fp_violation": 0.028505218406425878,
            "ave_precision_score": 0.7078345637008252,
            "fpr": 0.17672886937431395,
            "logloss": 4.59827707223803,
            "mae": 0.3185500667868922,
            "precision": 0.6811881188118812,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7781984972273972,
            "auditor_fn_violation": 0.011809935479193852,
            "auditor_fp_violation": 0.008005923102147896,
            "ave_precision_score": 0.6977321583796346,
            "fpr": 0.22039473684210525,
            "logloss": 0.6123285890320136,
            "mae": 0.4377958502032255,
            "precision": 0.6510416666666666,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7483117270493326,
            "auditor_fn_violation": 0.013053226522175783,
            "auditor_fp_violation": 0.01986304950081022,
            "ave_precision_score": 0.6758678908370663,
            "fpr": 0.22283205268935236,
            "logloss": 0.6223155975598829,
            "mae": 0.4403161444465101,
            "precision": 0.6335740072202166,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.6210411688114154,
            "auditor_fn_violation": 0.007369599101058446,
            "auditor_fp_violation": 0.015315010657484841,
            "ave_precision_score": 0.6240796247237079,
            "fpr": 0.1513157894736842,
            "logloss": 11.469440158636266,
            "mae": 0.5007273666209573,
            "precision": 0.5504885993485342,
            "recall": 0.34917355371900827
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6311605432093721,
            "auditor_fn_violation": 0.0048812387603054804,
            "auditor_fp_violation": 0.01754071551782074,
            "ave_precision_score": 0.6158424152727319,
            "fpr": 0.12952799121844127,
            "logloss": 10.47462951665656,
            "mae": 0.45263876998538866,
            "precision": 0.6040268456375839,
            "recall": 0.3829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.8477911635008107,
            "auditor_fn_violation": 0.010251286791358562,
            "auditor_fp_violation": 0.016065646007542234,
            "ave_precision_score": 0.8479426298923354,
            "fpr": 0.4155701754385965,
            "logloss": 0.9750667500844888,
            "mae": 0.3964332109491264,
            "precision": 0.5488095238095239,
            "recall": 0.9524793388429752
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.833042530797069,
            "auditor_fn_violation": 0.016073055094938924,
            "auditor_fp_violation": 0.019372696023158623,
            "ave_precision_score": 0.8330822928166746,
            "fpr": 0.4127332601536773,
            "logloss": 1.008792332271538,
            "mae": 0.40486048453727824,
            "precision": 0.5369458128078818,
            "recall": 0.9276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7713172176125239,
            "auditor_fn_violation": 0.00549604900681456,
            "auditor_fp_violation": 0.022908468601410086,
            "ave_precision_score": 0.5700032852004948,
            "fpr": 0.3706140350877193,
            "logloss": 0.6679986177727132,
            "mae": 0.4745791973872927,
            "precision": 0.572692793931732,
            "recall": 0.9359504132231405
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7606614147016759,
            "auditor_fn_violation": 0.0012144708877315084,
            "auditor_fp_violation": 0.01950710763632201,
            "ave_precision_score": 0.5560058795985247,
            "fpr": 0.3743139407244786,
            "logloss": 0.6713738569294095,
            "mae": 0.47491324149096703,
            "precision": 0.5594315245478036,
            "recall": 0.9212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8024636999172601,
            "auditor_fn_violation": 0.01634768740031899,
            "auditor_fp_violation": 0.015627561895392685,
            "ave_precision_score": 0.8030260962857225,
            "fpr": 0.08771929824561403,
            "logloss": 0.5549619309300255,
            "mae": 0.37176341382917344,
            "precision": 0.8034398034398035,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7889698039927934,
            "auditor_fn_violation": 0.02072774832426373,
            "auditor_fp_violation": 0.011656473786001775,
            "ave_precision_score": 0.789346542343486,
            "fpr": 0.08562019758507135,
            "logloss": 0.5667843964654503,
            "mae": 0.3730716708961682,
            "precision": 0.7963446475195822,
            "recall": 0.648936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8421456706878289,
            "auditor_fn_violation": 0.0030040234884732508,
            "auditor_fp_violation": 0.0039248237415969835,
            "ave_precision_score": 0.8360881824126863,
            "fpr": 0.14583333333333334,
            "logloss": 0.5129468073905067,
            "mae": 0.34317421577355145,
            "precision": 0.7495291902071564,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8310355340917374,
            "auditor_fn_violation": 0.009412149379919193,
            "auditor_fp_violation": 0.01254508389524855,
            "ave_precision_score": 0.8250263697485578,
            "fpr": 0.13830954994511527,
            "logloss": 0.5050408516387297,
            "mae": 0.3438236074809406,
            "precision": 0.7485029940119761,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 32400,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8686188313622705,
            "auditor_fn_violation": 0.0025078838625489444,
            "auditor_fp_violation": 0.009102414330218068,
            "ave_precision_score": 0.8654776316344007,
            "fpr": 0.0537280701754386,
            "logloss": 0.49082302302827935,
            "mae": 0.31740486714171995,
            "precision": 0.8638888888888889,
            "recall": 0.6425619834710744
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8531340248248703,
            "auditor_fn_violation": 0.009031459467034124,
            "auditor_fp_violation": 0.00550589793180353,
            "ave_precision_score": 0.8493357359017439,
            "fpr": 0.050493962678375415,
            "logloss": 0.5178454444529543,
            "mae": 0.324132950033923,
            "precision": 0.8626865671641791,
            "recall": 0.6148936170212767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7396430048579814,
            "auditor_fn_violation": 0.03429933304335218,
            "auditor_fp_violation": 0.04764356861780621,
            "ave_precision_score": 0.5464657113848557,
            "fpr": 0.3717105263157895,
            "logloss": 0.6920158281735719,
            "mae": 0.49430589368804295,
            "precision": 0.5486018641810919,
            "recall": 0.8512396694214877
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7268562363924784,
            "auditor_fn_violation": 0.0342200527827732,
            "auditor_fp_violation": 0.040684404021396336,
            "ave_precision_score": 0.5209355338693769,
            "fpr": 0.407244785949506,
            "logloss": 0.6887028961613164,
            "mae": 0.4961815826516495,
            "precision": 0.5212903225806451,
            "recall": 0.8595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.599908620961565,
            "auditor_fn_violation": 0.05718518921270117,
            "auditor_fp_violation": 0.06727793490736186,
            "ave_precision_score": 0.6012272106405309,
            "fpr": 0.15899122807017543,
            "logloss": 0.6819124319096879,
            "mae": 0.48756606416090537,
            "precision": 0.5915492957746479,
            "recall": 0.43388429752066116
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6045056992633722,
            "auditor_fn_violation": 0.06256393488567626,
            "auditor_fp_violation": 0.05174598196395281,
            "ave_precision_score": 0.6055525069963399,
            "fpr": 0.17014270032930845,
            "logloss": 0.6809627096707771,
            "mae": 0.48751420103234333,
            "precision": 0.5621468926553672,
            "recall": 0.42340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8462826204681728,
            "auditor_fn_violation": 0.0017308249963752334,
            "auditor_fp_violation": 0.009648098048860474,
            "ave_precision_score": 0.8048056655167315,
            "fpr": 0.08223684210526316,
            "logloss": 0.5275925442941158,
            "mae": 0.354817875513905,
            "precision": 0.8218527315914489,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8252541289559103,
            "auditor_fn_violation": 0.005497816287923024,
            "auditor_fp_violation": 0.010043534428041248,
            "ave_precision_score": 0.7795005651786718,
            "fpr": 0.08562019758507135,
            "logloss": 0.5453008431095075,
            "mae": 0.36277706488153,
            "precision": 0.8059701492537313,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6357939564878468,
            "auditor_fn_violation": 0.0010353233289836384,
            "auditor_fp_violation": 0.014080177078209551,
            "ave_precision_score": 0.5491030848216268,
            "fpr": 0.12280701754385964,
            "logloss": 0.6894059736308126,
            "mae": 0.49623099756998973,
            "precision": 0.5867158671586716,
            "recall": 0.3285123966942149
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6242023373347789,
            "auditor_fn_violation": 0.0012238129714832906,
            "auditor_fp_violation": 0.013035437372900137,
            "ave_precision_score": 0.5325459337175947,
            "fpr": 0.1394072447859495,
            "logloss": 0.6907329287045394,
            "mae": 0.4967628638909232,
            "precision": 0.563573883161512,
            "recall": 0.34893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.705133507177657,
            "auditor_fn_violation": 0.007566695664781779,
            "auditor_fp_violation": 0.005185276274799148,
            "ave_precision_score": 0.7060831036974012,
            "fpr": 0.0581140350877193,
            "logloss": 0.6654396070406866,
            "mae": 0.45440603036172034,
            "precision": 0.7969348659003831,
            "recall": 0.4297520661157025
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6852978150953346,
            "auditor_fn_violation": 0.00470373916902166,
            "auditor_fp_violation": 0.006185423309462829,
            "ave_precision_score": 0.6858134226688866,
            "fpr": 0.050493962678375415,
            "logloss": 0.6705984200541812,
            "mae": 0.45908279262245943,
            "precision": 0.7946428571428571,
            "recall": 0.37872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8225646852097194,
            "auditor_fn_violation": 0.007127192982456145,
            "auditor_fp_violation": 0.007680562387276607,
            "ave_precision_score": 0.8158566488671791,
            "fpr": 0.08552631578947369,
            "logloss": 0.5306206049125393,
            "mae": 0.35008455487351103,
            "precision": 0.8231292517006803,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8039266435074777,
            "auditor_fn_violation": 0.013709507905738381,
            "auditor_fp_violation": 0.01220905486234011,
            "ave_precision_score": 0.8006433553560286,
            "fpr": 0.09879253567508232,
            "logloss": 0.5353941661974767,
            "mae": 0.35618361782688446,
            "precision": 0.7857142857142857,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6979482198302372,
            "auditor_fn_violation": 0.07685406698564594,
            "auditor_fp_violation": 0.06470579193310379,
            "ave_precision_score": 0.6678117288171698,
            "fpr": 0.16776315789473684,
            "logloss": 0.6459695261581606,
            "mae": 0.46207446170349914,
            "precision": 0.6681127982646421,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.6615274027096072,
            "auditor_fn_violation": 0.06582899315692367,
            "auditor_fp_violation": 0.0692991430015109,
            "ave_precision_score": 0.6346623362418254,
            "fpr": 0.15916575192096596,
            "logloss": 0.6547164832165492,
            "mae": 0.4660624535887223,
            "precision": 0.6580188679245284,
            "recall": 0.5936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8699054260636677,
            "auditor_fn_violation": 0.0022994599101058477,
            "auditor_fp_violation": 0.010042629939334316,
            "ave_precision_score": 0.8333370166126035,
            "fpr": 0.07894736842105263,
            "logloss": 0.48689373708555145,
            "mae": 0.31317953187808917,
            "precision": 0.8313817330210773,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.847581041134869,
            "auditor_fn_violation": 0.01014550295443399,
            "auditor_fp_violation": 0.007823253706898053,
            "ave_precision_score": 0.8076587572559701,
            "fpr": 0.07683863885839737,
            "logloss": 0.5238438424851681,
            "mae": 0.3239190607432902,
            "precision": 0.8223350253807107,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8410349033078898,
            "auditor_fn_violation": 0.014403907496012764,
            "auditor_fp_violation": 0.006005082800459091,
            "ave_precision_score": 0.8438291167057533,
            "fpr": 0.09978070175438597,
            "logloss": 0.49267474988700866,
            "mae": 0.3211028456500029,
            "precision": 0.7973273942093542,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8407836700937789,
            "auditor_fn_violation": 0.007987481607772615,
            "auditor_fp_violation": 0.013451117732127612,
            "ave_precision_score": 0.8291078928723066,
            "fpr": 0.10318331503841932,
            "logloss": 0.5217411329745363,
            "mae": 0.32731834302209606,
            "precision": 0.7783018867924528,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.843861487990383,
            "auditor_fn_violation": 0.0014702950558213759,
            "auditor_fp_violation": 0.007972618462042955,
            "ave_precision_score": 0.8440753944226032,
            "fpr": 0.20175438596491227,
            "logloss": 0.7483459272086251,
            "mae": 0.33888778640209544,
            "precision": 0.6917922948073701,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8275726891985065,
            "auditor_fn_violation": 0.0028259803349137036,
            "auditor_fp_violation": 0.02613808055238195,
            "ave_precision_score": 0.827847884380429,
            "fpr": 0.18990120746432493,
            "logloss": 0.7000083169336337,
            "mae": 0.3405358725984083,
            "precision": 0.6927175843694494,
            "recall": 0.8297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.5617494609795742,
            "auditor_fn_violation": 0.019517090764100336,
            "auditor_fp_violation": 0.051319888506312514,
            "ave_precision_score": 0.5634686502754503,
            "fpr": 0.3081140350877193,
            "logloss": 0.6830216071674456,
            "mae": 0.48127225423109177,
            "precision": 0.5830860534124629,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5307728845386583,
            "auditor_fn_violation": 0.028981479318962097,
            "auditor_fp_violation": 0.04808948826511945,
            "ave_precision_score": 0.5325091012441423,
            "fpr": 0.3150384193194292,
            "logloss": 0.6833392189878947,
            "mae": 0.4836434216803895,
            "precision": 0.5690690690690691,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8383560132704867,
            "auditor_fn_violation": 0.0020661157024793415,
            "auditor_fp_violation": 0.01433892851287097,
            "ave_precision_score": 0.7640042397151763,
            "fpr": 0.15460526315789475,
            "logloss": 0.536305874995365,
            "mae": 0.37700859494834094,
            "precision": 0.7468581687612208,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8219815598882559,
            "auditor_fn_violation": 0.003942359343251511,
            "auditor_fp_violation": 0.014496541390064994,
            "ave_precision_score": 0.741773378589894,
            "fpr": 0.17672886937431395,
            "logloss": 0.5602075679704699,
            "mae": 0.3858781803059918,
            "precision": 0.7109515260323159,
            "recall": 0.8425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 32400,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6596303748025678,
            "auditor_fn_violation": 0.012867913585616937,
            "auditor_fp_violation": 0.014602803738317759,
            "ave_precision_score": 0.6615688652375119,
            "fpr": 0.30372807017543857,
            "logloss": 0.6524604113769435,
            "mae": 0.44792002394362435,
            "precision": 0.6115007012622721,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6472400723838426,
            "auditor_fn_violation": 0.01275194432118084,
            "auditor_fp_violation": 0.029070245002501546,
            "ave_precision_score": 0.6504436581406069,
            "fpr": 0.3040614709110867,
            "logloss": 0.6358184469760639,
            "mae": 0.44540212543029034,
            "precision": 0.6025824964131994,
            "recall": 0.8936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8099647796809004,
            "auditor_fn_violation": 0.009086831230969986,
            "auditor_fp_violation": 0.010585751762584033,
            "ave_precision_score": 0.7990823005029368,
            "fpr": 0.07675438596491228,
            "logloss": 0.5372458639604085,
            "mae": 0.35406798373074516,
            "precision": 0.8227848101265823,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.777051270486029,
            "auditor_fn_violation": 0.0012892075577457611,
            "auditor_fp_violation": 0.01596760182301973,
            "ave_precision_score": 0.7793512034338562,
            "fpr": 0.07793633369923161,
            "logloss": 0.5478962241898284,
            "mae": 0.35917870885192626,
            "precision": 0.8075880758807588,
            "recall": 0.6340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7516643627062218,
            "auditor_fn_violation": 0.005756578947368432,
            "auditor_fp_violation": 0.006904308083292344,
            "ave_precision_score": 0.7479498781499094,
            "fpr": 0.03399122807017544,
            "logloss": 0.8717248900891265,
            "mae": 0.4220963446341716,
            "precision": 0.7960526315789473,
            "recall": 0.25
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.736844709421926,
            "auditor_fn_violation": 0.008515309339748237,
            "auditor_fp_violation": 0.007596745247678289,
            "ave_precision_score": 0.7323444289050975,
            "fpr": 0.030735455543358946,
            "logloss": 0.86247649413126,
            "mae": 0.41250055614331355,
            "precision": 0.8028169014084507,
            "recall": 0.2425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6505423331571208,
            "auditor_fn_violation": 0.013028762505437157,
            "auditor_fp_violation": 0.013516560091818345,
            "ave_precision_score": 0.6073457333801108,
            "fpr": 0.12719298245614036,
            "logloss": 0.8989039241074958,
            "mae": 0.46013501124297473,
            "precision": 0.6578171091445427,
            "recall": 0.4607438016528926
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.629554847191219,
            "auditor_fn_violation": 0.025559941144872363,
            "auditor_fp_violation": 0.016169219242764807,
            "ave_precision_score": 0.5859670558881795,
            "fpr": 0.13062568605927552,
            "logloss": 0.8401916426348495,
            "mae": 0.4578038180955792,
            "precision": 0.6198083067092651,
            "recall": 0.4127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7438229656439656,
            "auditor_fn_violation": 0.039093083949543285,
            "auditor_fp_violation": 0.05057181505164781,
            "ave_precision_score": 0.6596137233733875,
            "fpr": 0.18421052631578946,
            "logloss": 0.6190671067344199,
            "mae": 0.428781485446451,
            "precision": 0.6830188679245283,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7390131613706902,
            "auditor_fn_violation": 0.04944297825630006,
            "auditor_fp_violation": 0.046506418154528564,
            "ave_precision_score": 0.6561648533500789,
            "fpr": 0.1712403951701427,
            "logloss": 0.6243227371055111,
            "mae": 0.43200814416458266,
            "precision": 0.6816326530612244,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7782053764040892,
            "auditor_fn_violation": 0.012958532695374812,
            "auditor_fp_violation": 0.017333784226922454,
            "ave_precision_score": 0.703590945760241,
            "fpr": 0.1699561403508772,
            "logloss": 0.6052300768008925,
            "mae": 0.4134872857023749,
            "precision": 0.6942800788954635,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7614950544369052,
            "auditor_fn_violation": 0.007468995959548775,
            "auditor_fp_violation": 0.026128124136592067,
            "ave_precision_score": 0.6860164078902642,
            "fpr": 0.16465422612513722,
            "logloss": 0.614204493432423,
            "mae": 0.4157733005991882,
            "precision": 0.6861924686192469,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 32400,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.6108763408214828,
            "auditor_fn_violation": 0.0059627374220675875,
            "auditor_fp_violation": 0.008812920150844405,
            "ave_precision_score": 0.542226495498473,
            "fpr": 0.12280701754385964,
            "logloss": 0.7070716986348144,
            "mae": 0.49691991293136534,
            "precision": 0.552,
            "recall": 0.28512396694214875
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.6018742227327267,
            "auditor_fn_violation": 0.0010976948408342759,
            "auditor_fp_violation": 0.018110720321791358,
            "ave_precision_score": 0.5286666076716534,
            "fpr": 0.13391877058177826,
            "logloss": 0.6983967874196291,
            "mae": 0.49537246458585865,
            "precision": 0.5361216730038023,
            "recall": 0.3
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7921761506676936,
            "auditor_fn_violation": 0.012958532695374812,
            "auditor_fp_violation": 0.017333784226922454,
            "ave_precision_score": 0.6744376241780913,
            "fpr": 0.1699561403508772,
            "logloss": 0.6148233689516954,
            "mae": 0.42535640224160853,
            "precision": 0.6942800788954635,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.770548043528812,
            "auditor_fn_violation": 0.007468995959548775,
            "auditor_fp_violation": 0.026128124136592067,
            "ave_precision_score": 0.6496387898401674,
            "fpr": 0.16465422612513722,
            "logloss": 0.6253242595699899,
            "mae": 0.4291222977618616,
            "precision": 0.6861924686192469,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7282972283855781,
            "auditor_fn_violation": 0.015169638973466732,
            "auditor_fp_violation": 0.015525086079685196,
            "ave_precision_score": 0.7230777603393704,
            "fpr": 0.16337719298245615,
            "logloss": 0.5788228399235607,
            "mae": 0.3839161958358569,
            "precision": 0.6977687626774848,
            "recall": 0.7107438016528925
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7144783483719284,
            "auditor_fn_violation": 0.011630894270967149,
            "auditor_fp_violation": 0.022454206710126427,
            "ave_precision_score": 0.706618131076841,
            "fpr": 0.16245883644346873,
            "logloss": 0.5973815140642412,
            "mae": 0.3920406050929998,
            "precision": 0.6796536796536796,
            "recall": 0.6680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8078683877996199,
            "auditor_fn_violation": 0.005856259968102076,
            "auditor_fp_violation": 0.014802631578947371,
            "ave_precision_score": 0.8026810550014482,
            "fpr": 0.0800438596491228,
            "logloss": 0.5321898513122825,
            "mae": 0.3540529443251528,
            "precision": 0.8253588516746412,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.775735311563043,
            "auditor_fn_violation": 0.00939813625429152,
            "auditor_fp_violation": 0.007019273131865263,
            "ave_precision_score": 0.7696641716475546,
            "fpr": 0.09001097694840834,
            "logloss": 0.5535014394829983,
            "mae": 0.36554315360502593,
            "precision": 0.7990196078431373,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8103119452401715,
            "auditor_fn_violation": 0.01294267435116719,
            "auditor_fp_violation": 0.010055439416297754,
            "ave_precision_score": 0.8107555524678828,
            "fpr": 0.09978070175438597,
            "logloss": 0.5446275102455954,
            "mae": 0.3442646096248114,
            "precision": 0.7863849765258216,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.806064126544874,
            "auditor_fn_violation": 0.004554265828993158,
            "auditor_fp_violation": 0.0181156985296863,
            "ave_precision_score": 0.8075736012031662,
            "fpr": 0.09549945115257959,
            "logloss": 0.548663448990166,
            "mae": 0.34573169789608243,
            "precision": 0.7851851851851852,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.70405435873597,
            "auditor_fn_violation": 0.01515604610700305,
            "auditor_fp_violation": 0.01567879980324644,
            "ave_precision_score": 0.6448514391345822,
            "fpr": 0.17763157894736842,
            "logloss": 0.6659768421360927,
            "mae": 0.45969381725396824,
            "precision": 0.6713995943204868,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7193776050041026,
            "auditor_fn_violation": 0.007356890954527415,
            "auditor_fp_violation": 0.00977222209776703,
            "ave_precision_score": 0.6518253169880002,
            "fpr": 0.18331503841931943,
            "logloss": 0.669022687440092,
            "mae": 0.46124311355584435,
            "precision": 0.6535269709543569,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8214470715519933,
            "auditor_fn_violation": 0.01225170363926345,
            "auditor_fp_violation": 0.018804312182324978,
            "ave_precision_score": 0.8228356580197558,
            "fpr": 0.17982456140350878,
            "logloss": 0.6198185599679465,
            "mae": 0.3035785348206685,
            "precision": 0.7201365187713311,
            "recall": 0.871900826446281
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8030714578793952,
            "auditor_fn_violation": 0.01521358338977509,
            "auditor_fp_violation": 0.02899059367618252,
            "ave_precision_score": 0.803335817308643,
            "fpr": 0.19319429198682767,
            "logloss": 0.6528217153421454,
            "mae": 0.32958295447373626,
            "precision": 0.6845878136200717,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5330315343460124,
            "auditor_fn_violation": 0.008436639118457302,
            "auditor_fp_violation": 0.01180521396950322,
            "ave_precision_score": 0.5404327505515989,
            "fpr": 0.4024122807017544,
            "logloss": 1.3053169154768811,
            "mae": 0.4739017750914747,
            "precision": 0.5406758448060075,
            "recall": 0.8925619834710744
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.523072373414525,
            "auditor_fn_violation": 0.007735245346474531,
            "auditor_fp_violation": 0.01743119494413207,
            "ave_precision_score": 0.5243576088244322,
            "fpr": 0.4039517014270033,
            "logloss": 1.3333846076530713,
            "mae": 0.4683567705353549,
            "precision": 0.5341772151898734,
            "recall": 0.8978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5715248260669282,
            "auditor_fn_violation": 0.01747362983906047,
            "auditor_fp_violation": 0.021550664043285806,
            "ave_precision_score": 0.5727806046153842,
            "fpr": 0.2982456140350877,
            "logloss": 0.7036644449908075,
            "mae": 0.48113478842730584,
            "precision": 0.5648,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5318516361368756,
            "auditor_fn_violation": 0.017679893500245236,
            "auditor_fp_violation": 0.03224385253552574,
            "ave_precision_score": 0.5332865688325152,
            "fpr": 0.31284302963776073,
            "logloss": 0.7188781751603428,
            "mae": 0.48082262354685174,
            "precision": 0.544,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.73719176160739,
            "auditor_fn_violation": 0.01072024068435552,
            "auditor_fp_violation": 0.02397934087555337,
            "ave_precision_score": 0.668544649774243,
            "fpr": 0.18530701754385964,
            "logloss": 0.6205276986181444,
            "mae": 0.42978599537654144,
            "precision": 0.6876155268022182,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7175009607299907,
            "auditor_fn_violation": 0.01084148819394166,
            "auditor_fp_violation": 0.02490348499443686,
            "ave_precision_score": 0.6438393512556276,
            "fpr": 0.1942919868276619,
            "logloss": 0.6433716974701705,
            "mae": 0.43775487558672904,
            "precision": 0.6529411764705882,
            "recall": 0.7085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.727037968646477,
            "auditor_fn_violation": 0.0019664346817456864,
            "auditor_fp_violation": 0.0030230365633710497,
            "ave_precision_score": 0.7286096282274533,
            "fpr": 0.4605263157894737,
            "logloss": 0.7302268406697209,
            "mae": 0.44284160794657573,
            "precision": 0.5333333333333333,
            "recall": 0.9917355371900827
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.702291125139861,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004109510617272906,
            "ave_precision_score": 0.7040871540017456,
            "fpr": 0.4665203073545554,
            "logloss": 0.731667842622909,
            "mae": 0.4462108955392461,
            "precision": 0.5251396648044693,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5729248642417228,
            "auditor_fn_violation": 0.010693054951428154,
            "auditor_fp_violation": 0.003274102311854405,
            "ave_precision_score": 0.5700519303604044,
            "fpr": 0.0581140350877193,
            "logloss": 1.0890113298775663,
            "mae": 0.5007862416285909,
            "precision": 0.6344827586206897,
            "recall": 0.19008264462809918
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5948230102143496,
            "auditor_fn_violation": 0.008052876194035082,
            "auditor_fp_violation": 0.009139989695109658,
            "ave_precision_score": 0.5870191756284695,
            "fpr": 0.04939626783754116,
            "logloss": 1.0109711521632088,
            "mae": 0.48348584695697205,
            "precision": 0.6341463414634146,
            "recall": 0.16595744680851063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8568654250901871,
            "auditor_fn_violation": 0.007455687255328409,
            "auditor_fp_violation": 0.008730939498278406,
            "ave_precision_score": 0.85556741167282,
            "fpr": 0.09210526315789473,
            "logloss": 0.4751487079667331,
            "mae": 0.3148972075187454,
            "precision": 0.8153846153846154,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8302027498509548,
            "auditor_fn_violation": 0.0068640960366209685,
            "auditor_fp_violation": 0.012022372066279865,
            "ave_precision_score": 0.8269557291166152,
            "fpr": 0.09220636663007684,
            "logloss": 0.5105348144131568,
            "mae": 0.325231376835007,
            "precision": 0.8004750593824228,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7762715691370792,
            "auditor_fn_violation": 0.01250543714658547,
            "auditor_fp_violation": 0.010470466469913103,
            "ave_precision_score": 0.7742449759848031,
            "fpr": 0.049342105263157895,
            "logloss": 0.6589236936376401,
            "mae": 0.4098542344918793,
            "precision": 0.8185483870967742,
            "recall": 0.4194214876033058
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7393433241734646,
            "auditor_fn_violation": 0.008618072261017828,
            "auditor_fp_violation": 0.01993025530739189,
            "ave_precision_score": 0.7376274683596313,
            "fpr": 0.050493962678375415,
            "logloss": 0.6877705570423407,
            "mae": 0.4151733468167083,
            "precision": 0.8050847457627118,
            "recall": 0.40425531914893614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7922839683786954,
            "auditor_fn_violation": 0.013003842250253729,
            "auditor_fp_violation": 0.013711264141662571,
            "ave_precision_score": 0.7810405532606289,
            "fpr": 0.11842105263157894,
            "logloss": 0.5670963811968243,
            "mae": 0.3875178678957909,
            "precision": 0.7440758293838863,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7750872510188949,
            "auditor_fn_violation": 0.01173132167129879,
            "auditor_fp_violation": 0.01810076390600148,
            "ave_precision_score": 0.7559643212404772,
            "fpr": 0.10867178924259056,
            "logloss": 0.5825162674966052,
            "mae": 0.38712902598565546,
            "precision": 0.7461538461538462,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7357004837038594,
            "auditor_fn_violation": 0.08283945918515298,
            "auditor_fp_violation": 0.05878012788981802,
            "ave_precision_score": 0.7226415512898668,
            "fpr": 0.17105263157894737,
            "logloss": 0.6194634239660513,
            "mae": 0.40516760245972955,
            "precision": 0.691699604743083,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7143124676123029,
            "auditor_fn_violation": 0.0759464698601023,
            "auditor_fp_violation": 0.05850389918133371,
            "ave_precision_score": 0.6980826029184437,
            "fpr": 0.18990120746432493,
            "logloss": 0.6196607165089582,
            "mae": 0.4093580226624501,
            "precision": 0.6574257425742575,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8185747676705156,
            "auditor_fn_violation": 0.0028930150790198637,
            "auditor_fp_violation": 0.0034380636169863902,
            "ave_precision_score": 0.819003144569202,
            "fpr": 0.19188596491228072,
            "logloss": 0.8679781735112383,
            "mae": 0.3051279051915595,
            "precision": 0.7149837133550488,
            "recall": 0.9070247933884298
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8044533494148411,
            "auditor_fn_violation": 0.009785832729990425,
            "auditor_fp_violation": 0.02098314627717169,
            "ave_precision_score": 0.8047068973537752,
            "fpr": 0.20197585071350166,
            "logloss": 0.9378495740022916,
            "mae": 0.3297174538104385,
            "precision": 0.6876061120543294,
            "recall": 0.8617021276595744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.45534231096457045,
            "auditor_fn_violation": 0.01004286283891547,
            "auditor_fp_violation": 0.031439580259058866,
            "ave_precision_score": 0.6106848685804384,
            "fpr": 0.2993421052631579,
            "logloss": 0.6382503960179186,
            "mae": 0.43434288146856587,
            "precision": 0.6197771587743732,
            "recall": 0.9194214876033058
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.516315734031488,
            "auditor_fn_violation": 0.010126818786930425,
            "auditor_fp_violation": 0.03664209921070515,
            "ave_precision_score": 0.5874857764176276,
            "fpr": 0.2996706915477497,
            "logloss": 0.671885072102464,
            "mae": 0.4415248567412242,
            "precision": 0.5997067448680352,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 32400,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8255160889100066,
            "auditor_fn_violation": 0.008688107148035385,
            "auditor_fp_violation": 0.012773610427939005,
            "ave_precision_score": 0.8260128226460263,
            "fpr": 0.11293859649122807,
            "logloss": 0.796843674105827,
            "mae": 0.2692227973549699,
            "precision": 0.7799145299145299,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.825739997121109,
            "auditor_fn_violation": 0.019889296307541403,
            "auditor_fp_violation": 0.02292962556409318,
            "ave_precision_score": 0.8259734596061592,
            "fpr": 0.10757409440175632,
            "logloss": 0.8615201259995828,
            "mae": 0.28361417865921157,
            "precision": 0.7752293577981652,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7602361635392301,
            "auditor_fn_violation": 0.0010013411628244165,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.533967303176742,
            "fpr": 0.4692982456140351,
            "logloss": 0.691814182588693,
            "mae": 0.4987957885390834,
            "precision": 0.5296703296703297,
            "recall": 0.9958677685950413
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7480920665237729,
            "auditor_fn_violation": 0.002326178854193428,
            "auditor_fp_violation": 0.0005052881013364087,
            "ave_precision_score": 0.5206969166206009,
            "fpr": 0.4829857299670692,
            "logloss": 0.6934376513375451,
            "mae": 0.499571105651353,
            "precision": 0.5143487858719646,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.5689833160791775,
            "auditor_fn_violation": 0.007892924459910107,
            "auditor_fp_violation": 0.02126373175930482,
            "ave_precision_score": 0.6858382274462883,
            "fpr": 0.38048245614035087,
            "logloss": 6.699478887636286,
            "mae": 0.41432467366879183,
            "precision": 0.5757946210268948,
            "recall": 0.9731404958677686
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.557805006984223,
            "auditor_fn_violation": 0.004472522596165075,
            "auditor_fp_violation": 0.018996841327090664,
            "ave_precision_score": 0.6676128976397416,
            "fpr": 0.3885839736553238,
            "logloss": 6.881969082409612,
            "mae": 0.43357443687650166,
            "precision": 0.5569461827284106,
            "recall": 0.9468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7597528646883408,
            "auditor_fn_violation": 0.010430259533130348,
            "auditor_fp_violation": 0.016660005738645685,
            "ave_precision_score": 0.7591231615172536,
            "fpr": 0.2598684210526316,
            "logloss": 1.76002510341209,
            "mae": 0.46853654952485185,
            "precision": 0.6201923076923077,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7179302729412694,
            "auditor_fn_violation": 0.014818880351262347,
            "auditor_fp_violation": 0.02326316549305416,
            "ave_precision_score": 0.7176940561604415,
            "fpr": 0.2645444566410538,
            "logloss": 1.8301376741848556,
            "mae": 0.4690506506259251,
            "precision": 0.6036184210526315,
            "recall": 0.7808510638297872
        }
    }
]