[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7934776870457045,
            "auditor_fn_violation": 0.005020258044213676,
            "auditor_fp_violation": 0.005684812890595588,
            "ave_precision_score": 0.7938760726159781,
            "fpr": 0.1118421052631579,
            "logloss": 0.6195727826007305,
            "mae": 0.31578739806386774,
            "precision": 0.7456359102244389,
            "recall": 0.6704035874439462
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8773882509418928,
            "auditor_fn_violation": 0.010618252850117114,
            "auditor_fp_violation": 0.004249141319358381,
            "ave_precision_score": 0.8775322716666938,
            "fpr": 0.0570801317233809,
            "logloss": 0.5670329693302156,
            "mae": 0.30326410744908655,
            "precision": 0.8652849740932642,
            "recall": 0.65748031496063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8233422135960535,
            "auditor_fn_violation": 0.0018979623947761792,
            "auditor_fp_violation": 0.015557939914163092,
            "ave_precision_score": 0.8236161585036396,
            "fpr": 0.12609649122807018,
            "logloss": 0.5280040599191753,
            "mae": 0.316895544339531,
            "precision": 0.740990990990991,
            "recall": 0.7376681614349776
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8950992989802591,
            "auditor_fn_violation": 0.010845138594777738,
            "auditor_fp_violation": 0.009217368092762026,
            "ave_precision_score": 0.8952243172104253,
            "fpr": 0.07464324917672886,
            "logloss": 0.46286143843082667,
            "mae": 0.299605266030563,
            "precision": 0.8478747203579419,
            "recall": 0.7460629921259843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8161359614159251,
            "auditor_fn_violation": 0.0018069978758555598,
            "auditor_fp_violation": 0.01152492282207665,
            "ave_precision_score": 0.8164856933453533,
            "fpr": 0.09429824561403509,
            "logloss": 0.5482982224545224,
            "mae": 0.29963068115134855,
            "precision": 0.7800511508951407,
            "recall": 0.6838565022421524
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.9019262378506723,
            "auditor_fn_violation": 0.008319143970889488,
            "auditor_fp_violation": 0.003508265397008715,
            "ave_precision_score": 0.9020531365868822,
            "fpr": 0.05598243688254665,
            "logloss": 0.47615694050907303,
            "mae": 0.281257860924288,
            "precision": 0.875609756097561,
            "recall": 0.7066929133858267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7873665425705121,
            "auditor_fn_violation": 0.003139505153017075,
            "auditor_fp_violation": 0.0019082712145169788,
            "ave_precision_score": 0.7877387264176405,
            "fpr": 0.11951754385964912,
            "logloss": 0.6374812624267373,
            "mae": 0.3215386297400855,
            "precision": 0.7328431372549019,
            "recall": 0.6704035874439462
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8650130684829311,
            "auditor_fn_violation": 0.009174827350752401,
            "auditor_fp_violation": 0.007564016310165528,
            "ave_precision_score": 0.8651801086967652,
            "fpr": 0.07025246981339188,
            "logloss": 0.585903860193598,
            "mae": 0.31076652913941655,
            "precision": 0.8391959798994975,
            "recall": 0.65748031496063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8299349857938993,
            "auditor_fn_violation": 0.007987668161434976,
            "auditor_fp_violation": 0.007713086363978621,
            "ave_precision_score": 0.8302296041363874,
            "fpr": 0.14473684210526316,
            "logloss": 0.5335268008080225,
            "mae": 0.300334524926464,
            "precision": 0.7300613496932515,
            "recall": 0.8004484304932735
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.902496941529094,
            "auditor_fn_violation": 0.010132069111558645,
            "auditor_fp_violation": 0.01224351937853585,
            "ave_precision_score": 0.9026153444278837,
            "fpr": 0.10208562019758508,
            "logloss": 0.44669505588743763,
            "mae": 0.275052076915093,
            "precision": 0.8169291338582677,
            "recall": 0.8169291338582677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.800553684217022,
            "auditor_fn_violation": 0.015731944772244523,
            "auditor_fp_violation": 0.018428582185076422,
            "ave_precision_score": 0.8019700825849692,
            "fpr": 0.11842105263157894,
            "logloss": 0.5313156018984226,
            "mae": 0.3259943330046729,
            "precision": 0.7482517482517482,
            "recall": 0.7197309417040358
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.876143207813708,
            "auditor_fn_violation": 0.016128335220446512,
            "auditor_fp_violation": 0.015934279947593926,
            "ave_precision_score": 0.8763080689821701,
            "fpr": 0.08562019758507135,
            "logloss": 0.5063051390052203,
            "mae": 0.3168734169455754,
            "precision": 0.8258928571428571,
            "recall": 0.7283464566929134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.805820077315009,
            "auditor_fn_violation": 0.007318956022342857,
            "auditor_fp_violation": 0.021826293200813193,
            "ave_precision_score": 0.8062728164981519,
            "fpr": 0.1425438596491228,
            "logloss": 0.5554554895543975,
            "mae": 0.3208839424046904,
            "precision": 0.7239915074309978,
            "recall": 0.7645739910313901
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8851974674860689,
            "auditor_fn_violation": 0.01738160885761948,
            "auditor_fp_violation": 0.015155270705711559,
            "ave_precision_score": 0.885352511872056,
            "fpr": 0.0889132821075741,
            "logloss": 0.4891233666022681,
            "mae": 0.2998892045613076,
            "precision": 0.8258064516129032,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.825464078875509,
            "auditor_fn_violation": 0.003776256785461409,
            "auditor_fp_violation": 0.009331940365936302,
            "ave_precision_score": 0.8257815281887072,
            "fpr": 0.10855263157894737,
            "logloss": 0.5143319172423235,
            "mae": 0.2997153293948494,
            "precision": 0.7681498829039812,
            "recall": 0.7354260089686099
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.9014768918607816,
            "auditor_fn_violation": 0.010207697693112187,
            "auditor_fp_violation": 0.011785919544143405,
            "ave_precision_score": 0.9016016236342048,
            "fpr": 0.06915477497255763,
            "logloss": 0.46190847565061444,
            "mae": 0.2862562057089355,
            "precision": 0.8548387096774194,
            "recall": 0.7303149606299213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8236698601650004,
            "auditor_fn_violation": 0.006446188340807178,
            "auditor_fp_violation": 0.01962860477373692,
            "ave_precision_score": 0.8240354474252849,
            "fpr": 0.11403508771929824,
            "logloss": 0.5257917109511286,
            "mae": 0.29803165258367936,
            "precision": 0.764172335600907,
            "recall": 0.7556053811659192
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9028974799210012,
            "auditor_fn_violation": 0.008522260732776126,
            "auditor_fp_violation": 0.007392416372268361,
            "ave_precision_score": 0.9030261850019717,
            "fpr": 0.08232711306256861,
            "logloss": 0.44924107826556553,
            "mae": 0.27391847017585097,
            "precision": 0.8407643312101911,
            "recall": 0.7795275590551181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.810726227806231,
            "auditor_fn_violation": 0.006190504287624895,
            "auditor_fp_violation": 0.007298960921617351,
            "ave_precision_score": 0.8110496250903088,
            "fpr": 0.09758771929824561,
            "logloss": 0.5940108501310261,
            "mae": 0.31167847981621316,
            "precision": 0.7735368956743003,
            "recall": 0.6816143497757847
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8803383700410783,
            "auditor_fn_violation": 0.011538760728454514,
            "auditor_fp_violation": 0.0032930845225027454,
            "ave_precision_score": 0.880464164101562,
            "fpr": 0.06805708013172337,
            "logloss": 0.5722179754823744,
            "mae": 0.30818881133373704,
            "precision": 0.8461538461538461,
            "recall": 0.6712598425196851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8100298338904992,
            "auditor_fn_violation": 0.004017189835575494,
            "auditor_fp_violation": 0.009404882915443114,
            "ave_precision_score": 0.8104884511724813,
            "fpr": 0.10855263157894737,
            "logloss": 0.5537088814641926,
            "mae": 0.3059836939222837,
            "precision": 0.7555555555555555,
            "recall": 0.6860986547085202
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8979590703404602,
            "auditor_fn_violation": 0.01137021703242089,
            "auditor_fp_violation": 0.005763578866514318,
            "ave_precision_score": 0.8980736831169274,
            "fpr": 0.05817782656421515,
            "logloss": 0.4770034628568002,
            "mae": 0.2850952896204676,
            "precision": 0.8722891566265061,
            "recall": 0.7125984251968503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8190945094143204,
            "auditor_fn_violation": 0.004781783494610969,
            "auditor_fp_violation": 0.012350820721331228,
            "ave_precision_score": 0.8195439999823864,
            "fpr": 0.11074561403508772,
            "logloss": 0.5308375262170983,
            "mae": 0.30282082546322625,
            "precision": 0.7629107981220657,
            "recall": 0.7286995515695067
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.900345424984407,
            "auditor_fn_violation": 0.00939523064556558,
            "auditor_fp_violation": 0.004099331849765618,
            "ave_precision_score": 0.9004655444062781,
            "fpr": 0.06915477497255763,
            "logloss": 0.4529782025239629,
            "mae": 0.28050587630578194,
            "precision": 0.8577878103837472,
            "recall": 0.7480314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8280849905087508,
            "auditor_fn_violation": 0.007026394461490046,
            "auditor_fp_violation": 0.005357747910548907,
            "ave_precision_score": 0.828494337721926,
            "fpr": 0.09539473684210527,
            "logloss": 0.5251246522823652,
            "mae": 0.2972062256541042,
            "precision": 0.7851851851851852,
            "recall": 0.7130044843049327
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8993767769053671,
            "auditor_fn_violation": 0.017087737797868575,
            "auditor_fp_violation": 0.006055026380085695,
            "ave_precision_score": 0.8994969925859502,
            "fpr": 0.05817782656421515,
            "logloss": 0.4920577827135539,
            "mae": 0.29087832140125197,
            "precision": 0.8691358024691358,
            "recall": 0.6929133858267716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8265265773271986,
            "auditor_fn_violation": 0.011436944378884435,
            "auditor_fp_violation": 0.02525929899856939,
            "ave_precision_score": 0.8270015167692484,
            "fpr": 0.13925438596491227,
            "logloss": 0.5050420919451689,
            "mae": 0.3136532162612288,
            "precision": 0.7348643006263048,
            "recall": 0.7892376681614349
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8900663469141754,
            "auditor_fn_violation": 0.017748947682308096,
            "auditor_fp_violation": 0.021278392299248505,
            "ave_precision_score": 0.8901998080043496,
            "fpr": 0.10208562019758508,
            "logloss": 0.4722581040640307,
            "mae": 0.3054898632917774,
            "precision": 0.8094262295081968,
            "recall": 0.7775590551181102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8151290534186342,
            "auditor_fn_violation": 0.0004081110848871077,
            "auditor_fp_violation": 0.01015548527972291,
            "ave_precision_score": 0.8154556156689954,
            "fpr": 0.07785087719298246,
            "logloss": 0.5830242815403485,
            "mae": 0.3208333776807801,
            "precision": 0.7917888563049853,
            "recall": 0.6053811659192825
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8947015513879637,
            "auditor_fn_violation": 0.014172796183133534,
            "auditor_fp_violation": 0.006899407026881267,
            "ave_precision_score": 0.8948053428482703,
            "fpr": 0.031833150384193196,
            "logloss": 0.5590505524291066,
            "mae": 0.31836138201701636,
            "precision": 0.9147058823529411,
            "recall": 0.6122047244094488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.8107230287863376,
            "auditor_fn_violation": 0.015414798206278026,
            "auditor_fp_violation": 0.0011435509374294105,
            "ave_precision_score": 0.8113439049016907,
            "fpr": 0.0021929824561403508,
            "logloss": 1.17296915391458,
            "mae": 0.4115432883766979,
            "precision": 0.9444444444444444,
            "recall": 0.07623318385650224
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.8946970556338509,
            "auditor_fn_violation": 0.014736769319861365,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8948266511458933,
            "fpr": 0.0,
            "logloss": 1.3027028631013544,
            "mae": 0.45894805340800915,
            "precision": 1.0,
            "recall": 0.05511811023622047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.818083114798573,
            "auditor_fn_violation": 0.007439422547399894,
            "auditor_fp_violation": 0.00802603343121753,
            "ave_precision_score": 0.8184060181810722,
            "fpr": 0.10197368421052631,
            "logloss": 0.5325061290962535,
            "mae": 0.3008295911324176,
            "precision": 0.774818401937046,
            "recall": 0.7174887892376681
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8999358106470157,
            "auditor_fn_violation": 0.00970206660501137,
            "auditor_fp_violation": 0.006079540656928144,
            "ave_precision_score": 0.9000784327378394,
            "fpr": 0.06147091108671789,
            "logloss": 0.4621348321239822,
            "mae": 0.28266677509065696,
            "precision": 0.8688524590163934,
            "recall": 0.7303149606299213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8138003210183852,
            "auditor_fn_violation": 0.019931063645661242,
            "auditor_fp_violation": 0.011670807921090279,
            "ave_precision_score": 0.8141228620072083,
            "fpr": 0.11403508771929824,
            "logloss": 0.594366278228642,
            "mae": 0.31536586135727607,
            "precision": 0.7587006960556845,
            "recall": 0.7331838565022422
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8943926165031582,
            "auditor_fn_violation": 0.019077849901034602,
            "auditor_fp_violation": 0.013229538069310036,
            "ave_precision_score": 0.8945051853210098,
            "fpr": 0.07903402854006586,
            "logloss": 0.5253302478775523,
            "mae": 0.2987407850270455,
            "precision": 0.8367346938775511,
            "recall": 0.7263779527559056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8332368761300213,
            "auditor_fn_violation": 0.013381618283376608,
            "auditor_fp_violation": 0.014494390482644377,
            "ave_precision_score": 0.8335130568456288,
            "fpr": 0.13596491228070176,
            "logloss": 0.6820039088978194,
            "mae": 0.27987883578941075,
            "precision": 0.7389473684210527,
            "recall": 0.7869955156950673
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.9060460575004625,
            "auditor_fn_violation": 0.007139338098654244,
            "auditor_fp_violation": 0.012586719254330175,
            "ave_precision_score": 0.906147972525065,
            "fpr": 0.09440175631174534,
            "logloss": 0.5922606946080395,
            "mae": 0.26449107336012456,
            "precision": 0.8208333333333333,
            "recall": 0.7755905511811023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8157843172521919,
            "auditor_fn_violation": 0.005738140193533161,
            "auditor_fp_violation": 0.015254404788796026,
            "ave_precision_score": 0.8161429545263237,
            "fpr": 0.15021929824561403,
            "logloss": 0.7088146291106022,
            "mae": 0.3109948632558561,
            "precision": 0.7254509018036072,
            "recall": 0.8116591928251121
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8919253623430476,
            "auditor_fn_violation": 0.009252616748921756,
            "auditor_fp_violation": 0.014373537655291136,
            "ave_precision_score": 0.8920466160432715,
            "fpr": 0.11964873765093303,
            "logloss": 0.6177193468542046,
            "mae": 0.2911503770941729,
            "precision": 0.7903846153846154,
            "recall": 0.8090551181102362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7855155020421328,
            "auditor_fn_violation": 0.013162811737864846,
            "auditor_fp_violation": 0.010586081620359913,
            "ave_precision_score": 0.7860115495294735,
            "fpr": 0.10416666666666667,
            "logloss": 0.5659467089088375,
            "mae": 0.35819176832298755,
            "precision": 0.7466666666666667,
            "recall": 0.6278026905829597
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8631723774493169,
            "auditor_fn_violation": 0.00907759060304071,
            "auditor_fp_violation": 0.012701119212928288,
            "ave_precision_score": 0.863341127961487,
            "fpr": 0.06695938529088913,
            "logloss": 0.5649528674738845,
            "mae": 0.3621785524587477,
            "precision": 0.8333333333333334,
            "recall": 0.6003937007874016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8214360161725359,
            "auditor_fn_violation": 0.008024545669105503,
            "auditor_fp_violation": 0.005816580076801453,
            "ave_precision_score": 0.8217954655415498,
            "fpr": 0.12609649122807018,
            "logloss": 0.5172416308016924,
            "mae": 0.31949330933633047,
            "precision": 0.7472527472527473,
            "recall": 0.7623318385650224
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8954690032521935,
            "auditor_fn_violation": 0.01589928865917008,
            "auditor_fp_violation": 0.009222815709838125,
            "ave_precision_score": 0.895606193632932,
            "fpr": 0.07793633369923161,
            "logloss": 0.45701835979304944,
            "mae": 0.29332636414058955,
            "precision": 0.8473118279569892,
            "recall": 0.7755905511811023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8020825291251097,
            "auditor_fn_violation": 0.010409291165132563,
            "auditor_fp_violation": 0.016096773586326336,
            "ave_precision_score": 0.80258668825392,
            "fpr": 0.13925438596491227,
            "logloss": 0.5524991160181546,
            "mae": 0.30407753740355636,
            "precision": 0.737603305785124,
            "recall": 0.8004484304932735
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.9017455983461566,
            "auditor_fn_violation": 0.011413433364737206,
            "auditor_fp_violation": 0.015021804087347095,
            "ave_precision_score": 0.9018856755644111,
            "fpr": 0.10318331503841932,
            "logloss": 0.445975377703878,
            "mae": 0.27432022346863494,
            "precision": 0.8104838709677419,
            "recall": 0.7913385826771654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6277060843714157,
            "auditor_fn_violation": 0.00944801746518764,
            "auditor_fp_violation": 0.014334387470822978,
            "ave_precision_score": 0.6290762313097843,
            "fpr": 0.17543859649122806,
            "logloss": 0.8783321328549251,
            "mae": 0.3604190243557943,
            "precision": 0.6514161220043573,
            "recall": 0.6704035874439462
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7064228252120868,
            "auditor_fn_violation": 0.006099985306447025,
            "auditor_fp_violation": 0.005801712186047022,
            "ave_precision_score": 0.7073936101542445,
            "fpr": 0.13062568605927552,
            "logloss": 0.8526362694379104,
            "mae": 0.34992033387887017,
            "precision": 0.7331838565022422,
            "recall": 0.6437007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7484143099342366,
            "auditor_fn_violation": 0.003107544646369292,
            "auditor_fp_violation": 0.003901249905880589,
            "ave_precision_score": 0.7494289597871766,
            "fpr": 0.13596491228070176,
            "logloss": 0.6241250938454193,
            "mae": 0.33415718716844967,
            "precision": 0.7181818181818181,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8634311970498632,
            "auditor_fn_violation": 0.01457686889029102,
            "auditor_fp_violation": 0.006809521345125609,
            "ave_precision_score": 0.8636101279708177,
            "fpr": 0.10757409440175632,
            "logloss": 0.548455575638854,
            "mae": 0.31477385423474347,
            "precision": 0.7869565217391304,
            "recall": 0.7125984251968503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8331114797176343,
            "auditor_fn_violation": 0.002325741483754226,
            "auditor_fp_violation": 0.0070707213312250616,
            "ave_precision_score": 0.8334509978063108,
            "fpr": 0.0537280701754386,
            "logloss": 0.5690969747976279,
            "mae": 0.3199879256722501,
            "precision": 0.835016835016835,
            "recall": 0.5560538116591929
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8999846180381036,
            "auditor_fn_violation": 0.014056112085879495,
            "auditor_fp_violation": 0.004102055658303668,
            "ave_precision_score": 0.9001091576065825,
            "fpr": 0.019758507135016465,
            "logloss": 0.5769402707330734,
            "mae": 0.32803489121917173,
            "precision": 0.9401993355481728,
            "recall": 0.5570866141732284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8285192990882527,
            "auditor_fn_violation": 0.010129022106836602,
            "auditor_fp_violation": 0.012254348317144798,
            "ave_precision_score": 0.8287885990647463,
            "fpr": 0.1699561403508772,
            "logloss": 0.6897345811610537,
            "mae": 0.2847365695585025,
            "precision": 0.7047619047619048,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8895278093021417,
            "auditor_fn_violation": 0.009887896833971494,
            "auditor_fp_violation": 0.017704755497326585,
            "ave_precision_score": 0.8896811007177299,
            "fpr": 0.12843029637760703,
            "logloss": 0.5872390561356714,
            "mae": 0.2676902216569656,
            "precision": 0.7771428571428571,
            "recall": 0.8031496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8172281948130932,
            "auditor_fn_violation": 0.0019668004090944895,
            "auditor_fp_violation": 0.013524960469844137,
            "ave_precision_score": 0.8186352437008997,
            "fpr": 0.08771929824561403,
            "logloss": 0.5469251550365092,
            "mae": 0.2899705435971204,
            "precision": 0.794344473007712,
            "recall": 0.6928251121076233
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.9037534801361009,
            "auditor_fn_violation": 0.017770555848466256,
            "auditor_fp_violation": 0.006667883301146996,
            "ave_precision_score": 0.9038784460341012,
            "fpr": 0.05378704720087816,
            "logloss": 0.48211039046160925,
            "mae": 0.2753695407666131,
            "precision": 0.882494004796163,
            "recall": 0.7244094488188977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6608353284299092,
            "auditor_fn_violation": 0.011119797812917944,
            "auditor_fp_violation": 0.0094307657555907,
            "ave_precision_score": 0.6621700291872805,
            "fpr": 0.20285087719298245,
            "logloss": 0.7913579871137231,
            "mae": 0.34771746753936067,
            "precision": 0.6636363636363637,
            "recall": 0.8183856502242153
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7392950756543785,
            "auditor_fn_violation": 0.006380891466503021,
            "auditor_fp_violation": 0.005877978825112426,
            "ave_precision_score": 0.7403097838592666,
            "fpr": 0.15697036223929747,
            "logloss": 0.7102225145246164,
            "mae": 0.3195810590403739,
            "precision": 0.7390510948905109,
            "recall": 0.797244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8310216345382264,
            "auditor_fn_violation": 0.008641629297458894,
            "auditor_fp_violation": 0.01162845418266697,
            "ave_precision_score": 0.8312870264521603,
            "fpr": 0.16666666666666666,
            "logloss": 0.6675855126422519,
            "mae": 0.2869944283142558,
            "precision": 0.7093690248565966,
            "recall": 0.8318385650224215
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8937567406926552,
            "auditor_fn_violation": 0.009522718825898687,
            "auditor_fp_violation": 0.015822603797533863,
            "ave_precision_score": 0.8938889680023017,
            "fpr": 0.11964873765093303,
            "logloss": 0.5737703486279689,
            "mae": 0.2704595598416035,
            "precision": 0.7903846153846154,
            "recall": 0.8090551181102362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.808567675749177,
            "auditor_fn_violation": 0.003798383290063735,
            "auditor_fp_violation": 0.01145198027256984,
            "ave_precision_score": 0.8090759241656642,
            "fpr": 0.06907894736842106,
            "logloss": 0.6297243906206087,
            "mae": 0.31153556795802534,
            "precision": 0.8125,
            "recall": 0.6121076233183856
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8886104680521216,
            "auditor_fn_violation": 0.015627025765577326,
            "auditor_fp_violation": 0.006526245257168385,
            "ave_precision_score": 0.8887715645236259,
            "fpr": 0.03732162458836443,
            "logloss": 0.6238620184719397,
            "mae": 0.3158099386542289,
            "precision": 0.8978978978978979,
            "recall": 0.5885826771653543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8081724482307779,
            "auditor_fn_violation": 0.014377310990480697,
            "auditor_fp_violation": 0.009491943377757703,
            "ave_precision_score": 0.8085192221401818,
            "fpr": 0.09210526315789473,
            "logloss": 0.633193077962192,
            "mae": 0.3140498677270788,
            "precision": 0.7741935483870968,
            "recall": 0.6457399103139013
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.886089969199921,
            "auditor_fn_violation": 0.014123097400969783,
            "auditor_fp_violation": 0.00589704548487878,
            "ave_precision_score": 0.88621198105789,
            "fpr": 0.050493962678375415,
            "logloss": 0.5936348327431329,
            "mae": 0.30830093995984165,
            "precision": 0.8770053475935828,
            "recall": 0.6456692913385826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7085881935498384,
            "auditor_fn_violation": 0.0018832113917079687,
            "auditor_fp_violation": 0.01576500263534373,
            "ave_precision_score": 0.6980212617422454,
            "fpr": 0.13815789473684212,
            "logloss": 1.709802121215658,
            "mae": 0.31629709177643656,
            "precision": 0.7266811279826464,
            "recall": 0.7511210762331838
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.825132328354264,
            "auditor_fn_violation": 0.013422992817445571,
            "auditor_fp_violation": 0.013526433199957513,
            "ave_precision_score": 0.8153731852783406,
            "fpr": 0.0801317233809001,
            "logloss": 1.6558502929277523,
            "mae": 0.28769640130201823,
            "precision": 0.8402625820568927,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8288453538264451,
            "auditor_fn_violation": 0.010620722209110221,
            "auditor_fp_violation": 0.011007266019125071,
            "ave_precision_score": 0.8291738215538342,
            "fpr": 0.10087719298245613,
            "logloss": 0.6836293114602727,
            "mae": 0.30368235242949276,
            "precision": 0.7799043062200957,
            "recall": 0.7309417040358744
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8931975406978651,
            "auditor_fn_violation": 0.016366025048186215,
            "auditor_fp_violation": 0.0056600741420684084,
            "ave_precision_score": 0.8933080566390588,
            "fpr": 0.06037321624588365,
            "logloss": 0.6681988572607246,
            "mae": 0.30790045288591783,
            "precision": 0.8651960784313726,
            "recall": 0.6948818897637795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8184012592288019,
            "auditor_fn_violation": 0.00873013531586815,
            "auditor_fp_violation": 0.00910370077554402,
            "ave_precision_score": 0.818711126759529,
            "fpr": 0.16337719298245615,
            "logloss": 0.541952388768216,
            "mae": 0.32411970918908256,
            "precision": 0.7066929133858267,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8950228482178187,
            "auditor_fn_violation": 0.013364650768818558,
            "auditor_fp_violation": 0.014408947166285787,
            "ave_precision_score": 0.895149825344482,
            "fpr": 0.11964873765093303,
            "logloss": 0.4560273874062604,
            "mae": 0.299847782771466,
            "precision": 0.7919847328244275,
            "recall": 0.8169291338582677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8287010737320275,
            "auditor_fn_violation": 0.006028243253874595,
            "auditor_fp_violation": 0.014656746479933744,
            "ave_precision_score": 0.8289631631845589,
            "fpr": 0.15460526315789475,
            "logloss": 0.564335611777074,
            "mae": 0.30333129821392185,
            "precision": 0.7191235059760956,
            "recall": 0.8094170403587444
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8988578599423434,
            "auditor_fn_violation": 0.005678626066363,
            "auditor_fp_violation": 0.013292185665685189,
            "ave_precision_score": 0.8989995143819197,
            "fpr": 0.11525795828759605,
            "logloss": 0.45620520083075033,
            "mae": 0.27148008012825176,
            "precision": 0.7988505747126436,
            "recall": 0.8208661417322834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7907079103115439,
            "auditor_fn_violation": 0.00567913618126033,
            "auditor_fp_violation": 0.012652002861230333,
            "ave_precision_score": 0.7923672534339142,
            "fpr": 0.18092105263157895,
            "logloss": 0.67692154017635,
            "mae": 0.29318041402285944,
            "precision": 0.6915887850467289,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8525469815721698,
            "auditor_fn_violation": 0.006413303715740254,
            "auditor_fp_violation": 0.019507916749515845,
            "ave_precision_score": 0.8531385042106638,
            "fpr": 0.11525795828759605,
            "logloss": 0.5705547413683095,
            "mae": 0.26583072951607384,
            "precision": 0.79,
            "recall": 0.7775590551181102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7894864349378634,
            "auditor_fn_violation": 0.014977185115254508,
            "auditor_fp_violation": 0.017590919358482043,
            "ave_precision_score": 0.7901267207086601,
            "fpr": 0.17763157894736842,
            "logloss": 0.6925045327128673,
            "mae": 0.29558942771617086,
            "precision": 0.6872586872586872,
            "recall": 0.7982062780269058
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8551101391810529,
            "auditor_fn_violation": 0.016299039733095936,
            "auditor_fp_violation": 0.027044694974300874,
            "ave_precision_score": 0.855329290337218,
            "fpr": 0.13391877058177826,
            "logloss": 0.6174290035128638,
            "mae": 0.2778293071436945,
            "precision": 0.7640232108317214,
            "recall": 0.7775590551181102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8161979253783821,
            "auditor_fn_violation": 0.004744905986940446,
            "auditor_fp_violation": 0.01112020932158723,
            "ave_precision_score": 0.8165599433592726,
            "fpr": 0.13925438596491227,
            "logloss": 0.66375837019869,
            "mae": 0.3155027476493393,
            "precision": 0.7386831275720165,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8932224638884468,
            "auditor_fn_violation": 0.01251328902218727,
            "auditor_fp_violation": 0.00975395837475793,
            "ave_precision_score": 0.8933360731820661,
            "fpr": 0.10867178924259056,
            "logloss": 0.583596238213532,
            "mae": 0.2947882779430442,
            "precision": 0.802,
            "recall": 0.7893700787401575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8074681050204153,
            "auditor_fn_violation": 0.006492899850523181,
            "auditor_fp_violation": 0.015976771327460285,
            "ave_precision_score": 0.8078820541548983,
            "fpr": 0.11403508771929824,
            "logloss": 0.5585346979769914,
            "mae": 0.308967003200291,
            "precision": 0.750599520383693,
            "recall": 0.7017937219730942
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8937221954228798,
            "auditor_fn_violation": 0.009931113166287808,
            "auditor_fp_violation": 0.006839483239044163,
            "ave_precision_score": 0.8938410980923134,
            "fpr": 0.06805708013172337,
            "logloss": 0.4848995869099447,
            "mae": 0.2910631653933523,
            "precision": 0.8537735849056604,
            "recall": 0.7125984251968503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7970054133570614,
            "auditor_fn_violation": 0.009022696876720953,
            "auditor_fp_violation": 0.011073149612227995,
            "ave_precision_score": 0.7974171408711008,
            "fpr": 0.07236842105263158,
            "logloss": 0.6894411479398054,
            "mae": 0.317874200490478,
            "precision": 0.7950310559006211,
            "recall": 0.5739910313901345
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.870155163158205,
            "auditor_fn_violation": 0.013193946256169141,
            "auditor_fp_violation": 0.004518798364625354,
            "ave_precision_score": 0.8703689341152974,
            "fpr": 0.04061470911086718,
            "logloss": 0.6799979124333883,
            "mae": 0.3224820899123771,
            "precision": 0.8854489164086687,
            "recall": 0.562992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8229534046518627,
            "auditor_fn_violation": 0.000786720163637797,
            "auditor_fp_violation": 0.01643325050824486,
            "ave_precision_score": 0.8232801987340237,
            "fpr": 0.10855263157894737,
            "logloss": 0.5370211960772546,
            "mae": 0.2951423559407295,
            "precision": 0.771889400921659,
            "recall": 0.7511210762331838
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8956746168651035,
            "auditor_fn_violation": 0.005682947699594631,
            "auditor_fp_violation": 0.004477941236554603,
            "ave_precision_score": 0.8958448292016388,
            "fpr": 0.07574094401756312,
            "logloss": 0.4530979877048806,
            "mae": 0.27247455534264525,
            "precision": 0.8522483940042827,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.825207554048678,
            "auditor_fn_violation": 0.014741169066163178,
            "auditor_fp_violation": 0.007868383404864092,
            "ave_precision_score": 0.8255548447480046,
            "fpr": 0.02631578947368421,
            "logloss": 0.6848179066573485,
            "mae": 0.3508643777621042,
            "precision": 0.8787878787878788,
            "recall": 0.3901345291479821
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.8953193733811757,
            "auditor_fn_violation": 0.02067037174689059,
            "auditor_fp_violation": 0.0009778472651600378,
            "ave_precision_score": 0.8954486576512509,
            "fpr": 0.007683863885839737,
            "logloss": 0.7390152413551201,
            "mae": 0.37489102816433595,
            "precision": 0.9669811320754716,
            "recall": 0.4035433070866142
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8112095806575419,
            "auditor_fn_violation": 0.011333687357406974,
            "auditor_fp_violation": 0.008701340260522555,
            "ave_precision_score": 0.8115755320393057,
            "fpr": 0.1118421052631579,
            "logloss": 0.7391427415198212,
            "mae": 0.29854996068901674,
            "precision": 0.7687074829931972,
            "recall": 0.7600896860986547
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.9062871830485304,
            "auditor_fn_violation": 0.012091929782103257,
            "auditor_fp_violation": 0.00937534898796894,
            "ave_precision_score": 0.9063836113346108,
            "fpr": 0.0867178924259056,
            "logloss": 0.6389820080918356,
            "mae": 0.2765443018311111,
            "precision": 0.8293736501079914,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8085915730713054,
            "auditor_fn_violation": 0.006111832271261116,
            "auditor_fp_violation": 0.017529741736315038,
            "ave_precision_score": 0.8089757545649445,
            "fpr": 0.10855263157894737,
            "logloss": 0.5626726566699148,
            "mae": 0.316029070739955,
            "precision": 0.7525,
            "recall": 0.6748878923766816
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8938957167613605,
            "auditor_fn_violation": 0.006205865320621976,
            "auditor_fp_violation": 0.008005273293329666,
            "ave_precision_score": 0.8940096060594531,
            "fpr": 0.06147091108671789,
            "logloss": 0.49691683061511005,
            "mae": 0.2971153904527475,
            "precision": 0.8613861386138614,
            "recall": 0.6850393700787402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8175472137668471,
            "auditor_fn_violation": 0.0011997482495476391,
            "auditor_fp_violation": 0.011823751976507795,
            "ave_precision_score": 0.8183953100723161,
            "fpr": 0.09320175438596491,
            "logloss": 0.5499205438577118,
            "mae": 0.2920252545558461,
            "precision": 0.7853535353535354,
            "recall": 0.6973094170403588
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.9004943264012042,
            "auditor_fn_violation": 0.015961952341028728,
            "auditor_fp_violation": 0.00582077884581337,
            "ave_precision_score": 0.9006289500252209,
            "fpr": 0.054884742041712405,
            "logloss": 0.48141568198614,
            "mae": 0.27515803312608006,
            "precision": 0.8800959232613909,
            "recall": 0.7224409448818898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8135562497650217,
            "auditor_fn_violation": 0.004174533868303044,
            "auditor_fp_violation": 0.014772042767863865,
            "ave_precision_score": 0.814232598463549,
            "fpr": 0.10526315789473684,
            "logloss": 0.5327976024886303,
            "mae": 0.3043133594366832,
            "precision": 0.7664233576642335,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.894557282279034,
            "auditor_fn_violation": 0.008476883583844012,
            "auditor_fp_violation": 0.008430187425265506,
            "ave_precision_score": 0.894729840308184,
            "fpr": 0.06147091108671789,
            "logloss": 0.4739758693440052,
            "mae": 0.2881817057704232,
            "precision": 0.8669833729216152,
            "recall": 0.718503937007874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8251028526030147,
            "auditor_fn_violation": 0.004388423412792069,
            "auditor_fp_violation": 0.006689537685415256,
            "ave_precision_score": 0.8255226044964894,
            "fpr": 0.047149122807017545,
            "logloss": 0.593123682294975,
            "mae": 0.32840297447278555,
            "precision": 0.843065693430657,
            "recall": 0.5179372197309418
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8965282017514445,
            "auditor_fn_violation": 0.01962021487160428,
            "auditor_fp_violation": 0.002786456134425399,
            "ave_precision_score": 0.8966413930308968,
            "fpr": 0.015367727771679473,
            "logloss": 0.6210956043423935,
            "mae": 0.34221853761837645,
            "precision": 0.951048951048951,
            "recall": 0.5354330708661418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8359432221925961,
            "auditor_fn_violation": 0.011087837306270158,
            "auditor_fp_violation": 0.007280137037873661,
            "ave_precision_score": 0.8362564807798034,
            "fpr": 0.1524122807017544,
            "logloss": 0.6868980257509218,
            "mae": 0.30756562651572095,
            "precision": 0.7269155206286837,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8967672897666445,
            "auditor_fn_violation": 0.016649092024858033,
            "auditor_fp_violation": 0.014076642524643664,
            "ave_precision_score": 0.8968704731368035,
            "fpr": 0.12184412733260154,
            "logloss": 0.6326252221806404,
            "mae": 0.2976693138449517,
            "precision": 0.7848837209302325,
            "recall": 0.797244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7908024051246991,
            "auditor_fn_violation": 0.0017725788686964148,
            "auditor_fp_violation": 0.012494352834876894,
            "ave_precision_score": 0.7911832300977353,
            "fpr": 0.09210526315789473,
            "logloss": 0.5929275178260583,
            "mae": 0.3229244343557072,
            "precision": 0.7673130193905817,
            "recall": 0.6210762331838565
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8924120358231178,
            "auditor_fn_violation": 0.00869512606204137,
            "auditor_fp_violation": 0.007400587797882514,
            "ave_precision_score": 0.892532107903618,
            "fpr": 0.04720087815587267,
            "logloss": 0.5216377620042962,
            "mae": 0.302161729839885,
            "precision": 0.8840970350404312,
            "recall": 0.6456692913385826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8198840342867393,
            "auditor_fn_violation": 0.011613956415702934,
            "auditor_fp_violation": 0.016616783374745876,
            "ave_precision_score": 0.8212897235630553,
            "fpr": 0.20175438596491227,
            "logloss": 0.5663025479953485,
            "mae": 0.3343309069424051,
            "precision": 0.6749116607773852,
            "recall": 0.8565022421524664
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.884490869303092,
            "auditor_fn_violation": 0.0052032464108836005,
            "auditor_fp_violation": 0.01568096575355525,
            "ave_precision_score": 0.8846221203400286,
            "fpr": 0.1800219538968167,
            "logloss": 0.4950385871383917,
            "mae": 0.3127000013163925,
            "precision": 0.7307060755336617,
            "recall": 0.8759842519685039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8288131381056227,
            "auditor_fn_violation": 0.010129022106836602,
            "auditor_fp_violation": 0.01257670732625556,
            "ave_precision_score": 0.8290796059002231,
            "fpr": 0.16776315789473684,
            "logloss": 0.6883579530780773,
            "mae": 0.28428322572528586,
            "precision": 0.7074569789674953,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8899984285801735,
            "auditor_fn_violation": 0.009870610301044972,
            "auditor_fp_violation": 0.01631016552584486,
            "ave_precision_score": 0.8901577519913875,
            "fpr": 0.12294182217343579,
            "logloss": 0.584488258708425,
            "mae": 0.26662336899547373,
            "precision": 0.7846153846153846,
            "recall": 0.8031496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8264300973074337,
            "auditor_fn_violation": 0.0043122098969396614,
            "auditor_fp_violation": 0.009101347790076052,
            "ave_precision_score": 0.8268720329596477,
            "fpr": 0.09539473684210527,
            "logloss": 0.5149327260827181,
            "mae": 0.2987516547275989,
            "precision": 0.7814070351758794,
            "recall": 0.6973094170403588
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.898571462925055,
            "auditor_fn_violation": 0.012625651486209677,
            "auditor_fp_violation": 0.005807159803123121,
            "ave_precision_score": 0.8987024223227342,
            "fpr": 0.06037321624588365,
            "logloss": 0.4805690848723549,
            "mae": 0.28974154756867565,
            "precision": 0.8651960784313726,
            "recall": 0.6948818897637795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8197422395351145,
            "auditor_fn_violation": 0.008803890331209192,
            "auditor_fp_violation": 0.011906106467886458,
            "ave_precision_score": 0.8200676672113212,
            "fpr": 0.14035087719298245,
            "logloss": 0.5487573591740234,
            "mae": 0.32106428479790083,
            "precision": 0.7349896480331263,
            "recall": 0.7959641255605381
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8965926191554887,
            "auditor_fn_violation": 0.014442898260110462,
            "auditor_fp_violation": 0.00964500603323591,
            "ave_precision_score": 0.8967022692352327,
            "fpr": 0.1119648737650933,
            "logloss": 0.462542528159259,
            "mae": 0.2993667136727496,
            "precision": 0.796,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8141132290313787,
            "auditor_fn_violation": 0.011505782393202737,
            "auditor_fp_violation": 0.01711561629395377,
            "ave_precision_score": 0.8145073727935096,
            "fpr": 0.16228070175438597,
            "logloss": 0.6502018586118806,
            "mae": 0.283746667906174,
            "precision": 0.7109375,
            "recall": 0.8161434977578476
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8887092045372582,
            "auditor_fn_violation": 0.009304476347701327,
            "auditor_fp_violation": 0.023422029618694048,
            "ave_precision_score": 0.8888431861488445,
            "fpr": 0.10757409440175632,
            "logloss": 0.5505590010765536,
            "mae": 0.26816420481545117,
            "precision": 0.7995910020449898,
            "recall": 0.7696850393700787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8240252398802042,
            "auditor_fn_violation": 0.011535284399339154,
            "auditor_fp_violation": 0.023492206912130113,
            "ave_precision_score": 0.8244223363861347,
            "fpr": 0.14912280701754385,
            "logloss": 0.5121753394365066,
            "mae": 0.3161522208750268,
            "precision": 0.7258064516129032,
            "recall": 0.8071748878923767
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8907616657523193,
            "auditor_fn_violation": 0.0195813201725196,
            "auditor_fp_violation": 0.01936355489699918,
            "ave_precision_score": 0.8909018052318763,
            "fpr": 0.11086717892425905,
            "logloss": 0.46924408295963355,
            "mae": 0.3036820019163911,
            "precision": 0.8023483365949119,
            "recall": 0.8070866141732284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8176731566770945,
            "auditor_fn_violation": 0.00015734403272756376,
            "auditor_fp_violation": 0.007298960921617352,
            "ave_precision_score": 0.8180045623531058,
            "fpr": 0.07346491228070176,
            "logloss": 0.5568697127421444,
            "mae": 0.2981501636041733,
            "precision": 0.8112676056338028,
            "recall": 0.6457399103139013
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.9045226211113915,
            "auditor_fn_violation": 0.010086691962626529,
            "auditor_fp_violation": 0.005967864506868083,
            "ave_precision_score": 0.9046696168189668,
            "fpr": 0.03951701427003293,
            "logloss": 0.5068182628296981,
            "mae": 0.28704456447595045,
            "precision": 0.9002770083102493,
            "recall": 0.639763779527559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8113417803254102,
            "auditor_fn_violation": 0.004626897962394776,
            "auditor_fp_violation": 0.016110891499134104,
            "ave_precision_score": 0.8117727087110747,
            "fpr": 0.10197368421052631,
            "logloss": 0.5500161381602189,
            "mae": 0.3072215269136921,
            "precision": 0.7645569620253164,
            "recall": 0.6771300448430493
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8952913404519914,
            "auditor_fn_violation": 0.010436744254388616,
            "auditor_fp_violation": 0.00756129250162748,
            "ave_precision_score": 0.8954177087460788,
            "fpr": 0.06037321624588365,
            "logloss": 0.47983715510128616,
            "mae": 0.2904596618263196,
            "precision": 0.86810551558753,
            "recall": 0.7125984251968503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8195557754271277,
            "auditor_fn_violation": 0.001553772323184649,
            "auditor_fp_violation": 0.010141367366915144,
            "ave_precision_score": 0.819929056273325,
            "fpr": 0.08991228070175439,
            "logloss": 0.5368700712346661,
            "mae": 0.3003629646710786,
            "precision": 0.788659793814433,
            "recall": 0.6860986547085202
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.902415092724013,
            "auditor_fn_violation": 0.01069172061505484,
            "auditor_fp_violation": 0.004227350851053978,
            "ave_precision_score": 0.9025425198997665,
            "fpr": 0.054884742041712405,
            "logloss": 0.47124950619123385,
            "mae": 0.28146968502142394,
            "precision": 0.8780487804878049,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8240891795826105,
            "auditor_fn_violation": 0.006588781370466531,
            "auditor_fp_violation": 0.013463782847677137,
            "ave_precision_score": 0.8244078075136716,
            "fpr": 0.12609649122807018,
            "logloss": 0.5270807479277229,
            "mae": 0.2984761650974785,
            "precision": 0.7472527472527473,
            "recall": 0.7623318385650224
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.9023207505738922,
            "auditor_fn_violation": 0.00514274354564077,
            "auditor_fp_violation": 0.01127111973045191,
            "ave_precision_score": 0.9024270779059893,
            "fpr": 0.07903402854006586,
            "logloss": 0.45517814561835596,
            "mae": 0.2798548229774777,
            "precision": 0.8427947598253275,
            "recall": 0.7598425196850394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8118526552969939,
            "auditor_fn_violation": 0.011441861379907171,
            "auditor_fp_violation": 0.016228540772532198,
            "ave_precision_score": 0.812240042106883,
            "fpr": 0.1699561403508772,
            "logloss": 0.654969058872223,
            "mae": 0.28758621367164744,
            "precision": 0.7041984732824428,
            "recall": 0.827354260089686
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8855805398317115,
            "auditor_fn_violation": 0.00930879798093296,
            "auditor_fp_violation": 0.021678792154341885,
            "ave_precision_score": 0.8857179555358824,
            "fpr": 0.11964873765093303,
            "logloss": 0.5533522268426294,
            "mae": 0.27160454619273133,
            "precision": 0.7841584158415842,
            "recall": 0.7795275590551181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7831202199460464,
            "auditor_fn_violation": 0.008934190858311698,
            "auditor_fp_violation": 0.017967397033355925,
            "ave_precision_score": 0.7836507569359294,
            "fpr": 0.18201754385964913,
            "logloss": 0.8012833073776264,
            "mae": 0.29096832708618375,
            "precision": 0.6867924528301886,
            "recall": 0.8161434977578476
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8548100348605305,
            "auditor_fn_violation": 0.009766891103485836,
            "auditor_fp_violation": 0.02141730653468907,
            "ave_precision_score": 0.8553049571152864,
            "fpr": 0.12952799121844127,
            "logloss": 0.6763391840366817,
            "mae": 0.2700325336071709,
            "precision": 0.76953125,
            "recall": 0.7755905511811023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7984775552398791,
            "auditor_fn_violation": 0.002502753520572731,
            "auditor_fp_violation": 0.011946107220841804,
            "ave_precision_score": 0.7990926892796328,
            "fpr": 0.08881578947368421,
            "logloss": 0.5548074401103744,
            "mae": 0.316590922208362,
            "precision": 0.7862796833773087,
            "recall": 0.6681614349775785
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8905644657093551,
            "auditor_fn_violation": 0.016780901838422776,
            "auditor_fp_violation": 0.0037506843568951864,
            "ave_precision_score": 0.8906065271854843,
            "fpr": 0.052689352360043906,
            "logloss": 0.4977391412545907,
            "mae": 0.2989841941345389,
            "precision": 0.8790931989924433,
            "recall": 0.687007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8187824471719423,
            "auditor_fn_violation": 0.008442490756038085,
            "auditor_fp_violation": 0.018080340335818092,
            "ave_precision_score": 0.819425949816892,
            "fpr": 0.09429824561403509,
            "logloss": 0.5248669406304425,
            "mae": 0.3021928043941571,
            "precision": 0.783375314861461,
            "recall": 0.6973094170403588
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8910774879162391,
            "auditor_fn_violation": 0.018021210575900858,
            "auditor_fp_violation": 0.014624128040791759,
            "ave_precision_score": 0.8912224520903749,
            "fpr": 0.0570801317233809,
            "logloss": 0.5086321314380061,
            "mae": 0.29681871399121373,
            "precision": 0.8728606356968215,
            "recall": 0.702755905511811
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.824039360138513,
            "auditor_fn_violation": 0.014067539926048306,
            "auditor_fp_violation": 0.00898369851667796,
            "ave_precision_score": 0.8244397978386053,
            "fpr": 0.06140350877192982,
            "logloss": 0.559160430060762,
            "mae": 0.323923514420593,
            "precision": 0.8260869565217391,
            "recall": 0.5964125560538116
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8787339269606917,
            "auditor_fn_violation": 0.014866418316810294,
            "auditor_fp_violation": 0.007779197184671496,
            "ave_precision_score": 0.879834328523455,
            "fpr": 0.03512623490669594,
            "logloss": 0.5853426404378828,
            "mae": 0.3353246319824349,
            "precision": 0.901840490797546,
            "recall": 0.5787401574803149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8222251541689253,
            "auditor_fn_violation": 0.011999940995987734,
            "auditor_fp_violation": 0.009120171673819745,
            "ave_precision_score": 0.8226136682093452,
            "fpr": 0.14473684210526316,
            "logloss": 0.6139929263248874,
            "mae": 0.2749718017996218,
            "precision": 0.7333333333333333,
            "recall": 0.8139013452914798
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.88225590567429,
            "auditor_fn_violation": 0.013500782215614925,
            "auditor_fp_violation": 0.021330144661471456,
            "ave_precision_score": 0.8824087166096597,
            "fpr": 0.10428100987925357,
            "logloss": 0.5476107657413753,
            "mae": 0.2639125292132154,
            "precision": 0.8041237113402062,
            "recall": 0.7677165354330708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8274361295459437,
            "auditor_fn_violation": 0.010227362127291325,
            "auditor_fp_violation": 0.011513157894736847,
            "ave_precision_score": 0.8277292976899508,
            "fpr": 0.18530701754385964,
            "logloss": 0.5898840497070064,
            "mae": 0.29633622958933475,
            "precision": 0.6876155268022182,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8835564082592239,
            "auditor_fn_violation": 0.00730356016145622,
            "auditor_fp_violation": 0.0201343927132674,
            "ave_precision_score": 0.883991949816473,
            "fpr": 0.132821075740944,
            "logloss": 0.5107585444889639,
            "mae": 0.27266343862253306,
            "precision": 0.7703984819734345,
            "recall": 0.7992125984251969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8020232832295509,
            "auditor_fn_violation": 0.006298678310125094,
            "auditor_fp_violation": 0.0037977185452902676,
            "ave_precision_score": 0.8023732608970612,
            "fpr": 0.10855263157894737,
            "logloss": 0.600923192762257,
            "mae": 0.3164165243098914,
            "precision": 0.7602905569007264,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8741704747869113,
            "auditor_fn_violation": 0.010946696975721076,
            "auditor_fp_violation": 0.0028899608588713105,
            "ave_precision_score": 0.8743064068720937,
            "fpr": 0.07025246981339188,
            "logloss": 0.5729129046449658,
            "mae": 0.31071991985829894,
            "precision": 0.8423645320197044,
            "recall": 0.6732283464566929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8240231856103788,
            "auditor_fn_violation": 0.010242113130359536,
            "auditor_fp_violation": 0.019169772607484377,
            "ave_precision_score": 0.8246530657359513,
            "fpr": 0.09978070175438597,
            "logloss": 0.5127555670700515,
            "mae": 0.299004926274887,
            "precision": 0.7775061124694377,
            "recall": 0.7130044843049327
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8946794371769138,
            "auditor_fn_violation": 0.017597690519201018,
            "auditor_fp_violation": 0.013891423544056243,
            "ave_precision_score": 0.8948145647574408,
            "fpr": 0.06147091108671789,
            "logloss": 0.48977803754396365,
            "mae": 0.2933814518763091,
            "precision": 0.8679245283018868,
            "recall": 0.7244094488188977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8271236818288721,
            "auditor_fn_violation": 0.0062298402958067866,
            "auditor_fp_violation": 0.015910887734357358,
            "ave_precision_score": 0.8277445165543451,
            "fpr": 0.10964912280701754,
            "logloss": 0.5066344192931783,
            "mae": 0.2975692386333545,
            "precision": 0.7668997668997669,
            "recall": 0.7376681614349776
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.895809972038417,
            "auditor_fn_violation": 0.014473149692731882,
            "auditor_fp_violation": 0.017146374747026287,
            "ave_precision_score": 0.895945082949523,
            "fpr": 0.07025246981339188,
            "logloss": 0.4763272087121949,
            "mae": 0.28891190905525205,
            "precision": 0.8565022421524664,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 20404,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8142297203215404,
            "auditor_fn_violation": 0.013988867909684531,
            "auditor_fp_violation": 0.012367291619606958,
            "ave_precision_score": 0.8145716973742055,
            "fpr": 0.09210526315789473,
            "logloss": 0.6147214866579896,
            "mae": 0.3049291929108718,
            "precision": 0.7823834196891192,
            "recall": 0.6771300448430493
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8903982911141061,
            "auditor_fn_violation": 0.008366681936437421,
            "auditor_fp_violation": 0.013719823606159079,
            "ave_precision_score": 0.8905163545339347,
            "fpr": 0.06586169045005488,
            "logloss": 0.5759434553377378,
            "mae": 0.296989512978624,
            "precision": 0.8529411764705882,
            "recall": 0.6850393700787402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8234425795034666,
            "auditor_fn_violation": 0.016378530406734326,
            "auditor_fp_violation": 0.015541469015887354,
            "ave_precision_score": 0.8238592997559804,
            "fpr": 0.09758771929824561,
            "logloss": 0.5143542535102741,
            "mae": 0.31400260775709493,
            "precision": 0.7865707434052758,
            "recall": 0.7354260089686099
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.9001309174199459,
            "auditor_fn_violation": 0.021089570170358788,
            "auditor_fp_violation": 0.01409843299294806,
            "ave_precision_score": 0.9002323724776956,
            "fpr": 0.07025246981339188,
            "logloss": 0.4734253850351106,
            "mae": 0.30633282588496313,
            "precision": 0.8483412322274881,
            "recall": 0.7047244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8363051744963763,
            "auditor_fn_violation": 0.0133742427818425,
            "auditor_fp_violation": 0.017899160454785033,
            "ave_precision_score": 0.8366487868422509,
            "fpr": 0.24232456140350878,
            "logloss": 0.786007015220521,
            "mae": 0.32666127375947934,
            "precision": 0.644122383252818,
            "recall": 0.8968609865470852
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8984829894067199,
            "auditor_fn_violation": 0.012824446614864692,
            "auditor_fp_violation": 0.01651172735766058,
            "ave_precision_score": 0.8985868339036278,
            "fpr": 0.1877058177826564,
            "logloss": 0.680585044116187,
            "mae": 0.2977577702589047,
            "precision": 0.731974921630094,
            "recall": 0.9192913385826772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8078504577656684,
            "auditor_fn_violation": 0.0004376130910235271,
            "auditor_fp_violation": 0.01332260371959943,
            "ave_precision_score": 0.8081695821491568,
            "fpr": 0.11074561403508772,
            "logloss": 0.5764917000878549,
            "mae": 0.3274124944720442,
            "precision": 0.7481296758104738,
            "recall": 0.672645739910314
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8822493850478449,
            "auditor_fn_violation": 0.000613671918891596,
            "auditor_fp_violation": 0.002960779880860617,
            "ave_precision_score": 0.8823789772054896,
            "fpr": 0.07793633369923161,
            "logloss": 0.5264708274119838,
            "mae": 0.3083190881426351,
            "precision": 0.8337236533957846,
            "recall": 0.7007874015748031
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8168863818941301,
            "auditor_fn_violation": 0.0018979623947761837,
            "auditor_fp_violation": 0.01211316918906709,
            "ave_precision_score": 0.8172449872470042,
            "fpr": 0.08442982456140351,
            "logloss": 0.5818761822714499,
            "mae": 0.30585143870976345,
            "precision": 0.7849162011173184,
            "recall": 0.6300448430493274
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8993817795889577,
            "auditor_fn_violation": 0.009641563739768535,
            "auditor_fp_violation": 0.004336303192575986,
            "ave_precision_score": 0.8994833505523578,
            "fpr": 0.04610318331503842,
            "logloss": 0.537891757000017,
            "mae": 0.294050834684645,
            "precision": 0.8882978723404256,
            "recall": 0.65748031496063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8279167259313363,
            "auditor_fn_violation": 0.0007375501534104329,
            "auditor_fp_violation": 0.014981458474512462,
            "ave_precision_score": 0.8285525234617453,
            "fpr": 0.10635964912280702,
            "logloss": 0.5114789731072988,
            "mae": 0.29788765306033094,
            "precision": 0.7717647058823529,
            "recall": 0.7354260089686099
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.9060640135572118,
            "auditor_fn_violation": 0.011376699482268337,
            "auditor_fp_violation": 0.0018140564863414615,
            "ave_precision_score": 0.9062086422382076,
            "fpr": 0.06147091108671789,
            "logloss": 0.4450113787054335,
            "mae": 0.2752220631300029,
            "precision": 0.873015873015873,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.820892910243993,
            "auditor_fn_violation": 0.011078003304224688,
            "auditor_fp_violation": 0.02394633310744673,
            "ave_precision_score": 0.8212642435707047,
            "fpr": 0.13706140350877194,
            "logloss": 0.5149920018825882,
            "mae": 0.3172908761357815,
            "precision": 0.7373949579831933,
            "recall": 0.7869955156950673
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8862157652499036,
            "auditor_fn_violation": 0.020086951260620416,
            "auditor_fp_violation": 0.021278392299248505,
            "ave_precision_score": 0.8863603213583497,
            "fpr": 0.10208562019758508,
            "logloss": 0.4776855616235014,
            "mae": 0.30567308451773845,
            "precision": 0.8105906313645621,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 20404,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8233857954482379,
            "auditor_fn_violation": 0.018652643379749822,
            "auditor_fp_violation": 0.010386077855583167,
            "ave_precision_score": 0.8237300150881579,
            "fpr": 0.06140350877192982,
            "logloss": 0.5529675953370177,
            "mae": 0.3334887204319034,
            "precision": 0.8210862619808307,
            "recall": 0.5762331838565022
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8930942867129229,
            "auditor_fn_violation": 0.017606333785664275,
            "auditor_fp_violation": 0.005417655182181935,
            "ave_precision_score": 0.8932093786035114,
            "fpr": 0.024149286498353458,
            "logloss": 0.570366543267792,
            "mae": 0.3439303822766859,
            "precision": 0.9281045751633987,
            "recall": 0.5590551181102362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8091053660839809,
            "auditor_fn_violation": 0.020226083707025416,
            "auditor_fp_violation": 0.012263760259016642,
            "ave_precision_score": 0.8094541036726006,
            "fpr": 0.09100877192982457,
            "logloss": 0.6275610804077913,
            "mae": 0.31293730046952917,
            "precision": 0.7756756756756756,
            "recall": 0.6434977578475336
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8894303933663354,
            "auditor_fn_violation": 0.013807618175060717,
            "auditor_fp_violation": 0.003429274949405257,
            "ave_precision_score": 0.889547448748977,
            "fpr": 0.048298572996706916,
            "logloss": 0.5832547079203271,
            "mae": 0.3056640783867949,
            "precision": 0.8823529411764706,
            "recall": 0.6496062992125984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8183554100764728,
            "auditor_fn_violation": 0.008786680827629616,
            "auditor_fp_violation": 0.011680219862962127,
            "ave_precision_score": 0.8188329865809826,
            "fpr": 0.14144736842105263,
            "logloss": 0.5323761409099871,
            "mae": 0.298993591541116,
            "precision": 0.7378048780487805,
            "recall": 0.8139013452914798
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9017586229762,
            "auditor_fn_violation": 0.005911994260871071,
            "auditor_fp_violation": 0.018862374125997942,
            "ave_precision_score": 0.9018972743269995,
            "fpr": 0.10867178924259056,
            "logloss": 0.4443294676119754,
            "mae": 0.2754535542649721,
            "precision": 0.8092485549132948,
            "recall": 0.8267716535433071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.826657761733727,
            "auditor_fn_violation": 0.012599815120761549,
            "auditor_fp_violation": 0.014346152398162797,
            "ave_precision_score": 0.8270567503777038,
            "fpr": 0.12609649122807018,
            "logloss": 0.537527452871737,
            "mae": 0.2982843653076806,
            "precision": 0.7510822510822511,
            "recall": 0.7780269058295964
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.902167349730518,
            "auditor_fn_violation": 0.01896764825362801,
            "auditor_fp_violation": 0.0084083969569611,
            "ave_precision_score": 0.9022721615091773,
            "fpr": 0.09110867178924259,
            "logloss": 0.4570991152699552,
            "mae": 0.27927559298952853,
            "precision": 0.8245243128964059,
            "recall": 0.7677165354330708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8211421339808818,
            "auditor_fn_violation": 0.009076783887971063,
            "auditor_fp_violation": 0.011680219862962126,
            "ave_precision_score": 0.8214742431725023,
            "fpr": 0.1206140350877193,
            "logloss": 0.5272588901961758,
            "mae": 0.29953931930797634,
            "precision": 0.75,
            "recall": 0.7399103139013453
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.9037283577414811,
            "auditor_fn_violation": 0.009924630716440355,
            "auditor_fp_violation": 0.007117311709925288,
            "ave_precision_score": 0.9038340196129381,
            "fpr": 0.07135016465422613,
            "logloss": 0.45878608195981196,
            "mae": 0.28182677265959993,
            "precision": 0.8529411764705882,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8116243716438291,
            "auditor_fn_violation": 0.007818031626150579,
            "auditor_fp_violation": 0.010531962954596796,
            "ave_precision_score": 0.8120213776227373,
            "fpr": 0.17763157894736842,
            "logloss": 0.5789556785585567,
            "mae": 0.3268259206496735,
            "precision": 0.6925996204933587,
            "recall": 0.8183856502242153
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8958132574483482,
            "auditor_fn_violation": 0.010842977778161922,
            "auditor_fp_violation": 0.012709290638542437,
            "ave_precision_score": 0.8959233781057657,
            "fpr": 0.141602634467618,
            "logloss": 0.4737240690655786,
            "mae": 0.2961078457985151,
            "precision": 0.7628676470588235,
            "recall": 0.8169291338582677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8238896479169313,
            "auditor_fn_violation": 0.01640557391235938,
            "auditor_fp_violation": 0.007938972968902955,
            "ave_precision_score": 0.8242783084222449,
            "fpr": 0.14144736842105263,
            "logloss": 0.6146905114675306,
            "mae": 0.272547542157131,
            "precision": 0.735655737704918,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8846515862843115,
            "auditor_fn_violation": 0.012130824481187933,
            "auditor_fp_violation": 0.020807173422165818,
            "ave_precision_score": 0.8848000580318688,
            "fpr": 0.10647639956092206,
            "logloss": 0.5517247344203409,
            "mae": 0.26149336717455207,
            "precision": 0.8004115226337448,
            "recall": 0.765748031496063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8221829648631547,
            "auditor_fn_violation": 0.0070558964676264635,
            "auditor_fp_violation": 0.008510748437617649,
            "ave_precision_score": 0.8225274900237728,
            "fpr": 0.10416666666666667,
            "logloss": 0.5336911584612661,
            "mae": 0.3198914321132689,
            "precision": 0.7699757869249395,
            "recall": 0.7130044843049327
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8937538893496488,
            "auditor_fn_violation": 0.0111325272046812,
            "auditor_fp_violation": 0.008021616144557967,
            "ave_precision_score": 0.893865369063802,
            "fpr": 0.06805708013172337,
            "logloss": 0.488370268416907,
            "mae": 0.30923431005091717,
            "precision": 0.8530805687203792,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.81375173517139,
            "auditor_fn_violation": 0.010989497285815438,
            "auditor_fp_violation": 0.01886859046758528,
            "ave_precision_score": 0.8141770626929601,
            "fpr": 0.16337719298245615,
            "logloss": 0.6101162887284135,
            "mae": 0.29602237778272616,
            "precision": 0.7095516569200779,
            "recall": 0.8161434977578476
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8935416093710407,
            "auditor_fn_violation": 0.00971503150470626,
            "auditor_fp_violation": 0.022084639626511374,
            "ave_precision_score": 0.8936677415314869,
            "fpr": 0.11964873765093303,
            "logloss": 0.5183131404160889,
            "mae": 0.27773344164934133,
            "precision": 0.7875243664717348,
            "recall": 0.7952755905511811
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.813605086483565,
            "auditor_fn_violation": 0.009076783887971052,
            "auditor_fp_violation": 0.010804909268880359,
            "ave_precision_score": 0.8139697414645044,
            "fpr": 0.09649122807017543,
            "logloss": 0.5453758764439959,
            "mae": 0.3024485705751239,
            "precision": 0.7810945273631841,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8881911963281468,
            "auditor_fn_violation": 0.011460971330285143,
            "auditor_fp_violation": 0.008258587487368341,
            "ave_precision_score": 0.8883622804029934,
            "fpr": 0.06037321624588365,
            "logloss": 0.5005813676132073,
            "mae": 0.29144148358284944,
            "precision": 0.8674698795180723,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6453387690830613,
            "auditor_fn_violation": 0.009275922429391866,
            "auditor_fp_violation": 0.008011915518409761,
            "ave_precision_score": 0.6466084533575909,
            "fpr": 0.11732456140350878,
            "logloss": 0.9939460865528733,
            "mae": 0.35491237258013014,
            "precision": 0.7297979797979798,
            "recall": 0.647982062780269
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7296848878706017,
            "auditor_fn_violation": 0.011530117461991238,
            "auditor_fp_violation": 0.009309977583055733,
            "ave_precision_score": 0.7306035729565848,
            "fpr": 0.07903402854006586,
            "logloss": 0.9563868275016124,
            "mae": 0.3571109792039539,
            "precision": 0.8144329896907216,
            "recall": 0.6220472440944882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 20404,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.821239037177379,
            "auditor_fn_violation": 0.011948312485249002,
            "auditor_fp_violation": 0.01645207439198856,
            "ave_precision_score": 0.8215845212585818,
            "fpr": 0.16666666666666666,
            "logloss": 0.6049010175215799,
            "mae": 0.28536139067708927,
            "precision": 0.7088122605363985,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8825590597069766,
            "auditor_fn_violation": 0.006056768974130706,
            "auditor_fp_violation": 0.020404049758534375,
            "ave_precision_score": 0.8828693769956204,
            "fpr": 0.11745334796926454,
            "logloss": 0.5175073527267867,
            "mae": 0.26746032684746235,
            "precision": 0.7876984126984127,
            "recall": 0.781496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8092256749570856,
            "auditor_fn_violation": 0.010581386200928333,
            "auditor_fp_violation": 0.021539228973721868,
            "ave_precision_score": 0.8096484395843577,
            "fpr": 0.17763157894736842,
            "logloss": 0.633954317622103,
            "mae": 0.29730014992120785,
            "precision": 0.6966292134831461,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8885022687968518,
            "auditor_fn_violation": 0.010387045472224866,
            "auditor_fp_violation": 0.02094881146614442,
            "ave_precision_score": 0.8886346589968852,
            "fpr": 0.12733260153677278,
            "logloss": 0.5292203787534301,
            "mae": 0.2783023522492034,
            "precision": 0.7773512476007678,
            "recall": 0.797244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8263886196556887,
            "auditor_fn_violation": 0.005669302179214857,
            "auditor_fp_violation": 0.010823733152624053,
            "ave_precision_score": 0.8266875619501937,
            "fpr": 0.09758771929824561,
            "logloss": 0.5349478994185648,
            "mae": 0.30985414179431564,
            "precision": 0.7802469135802469,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8978729093110288,
            "auditor_fn_violation": 0.011728912590646257,
            "auditor_fp_violation": 0.009225539518376177,
            "ave_precision_score": 0.8979787829612056,
            "fpr": 0.07354555433589462,
            "logloss": 0.5007422432904874,
            "mae": 0.30043566211969636,
            "precision": 0.8427230046948356,
            "recall": 0.7066929133858267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8100624914579795,
            "auditor_fn_violation": 0.002404413500118015,
            "auditor_fp_violation": 0.008174271515699121,
            "ave_precision_score": 0.8103765756148655,
            "fpr": 0.10307017543859649,
            "logloss": 0.5893232564899165,
            "mae": 0.3122537677286904,
            "precision": 0.7661691542288557,
            "recall": 0.6905829596412556
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8825395500953838,
            "auditor_fn_violation": 0.01420953006560239,
            "auditor_fp_violation": 0.005684588418910857,
            "ave_precision_score": 0.8826602959514683,
            "fpr": 0.06366630076838639,
            "logloss": 0.5625721152131214,
            "mae": 0.30681396416862805,
            "precision": 0.8564356435643564,
            "recall": 0.6811023622047244
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8159723605114939,
            "auditor_fn_violation": 0.007704940602627645,
            "auditor_fp_violation": 0.012659061817634222,
            "ave_precision_score": 0.8164458440432131,
            "fpr": 0.13815789473684212,
            "logloss": 0.5319028343148356,
            "mae": 0.29931533442000374,
            "precision": 0.7418032786885246,
            "recall": 0.8116591928251121
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8998821482689144,
            "auditor_fn_violation": 0.0096221163902262,
            "auditor_fp_violation": 0.014945537448281688,
            "ave_precision_score": 0.9000316276315432,
            "fpr": 0.10208562019758508,
            "logloss": 0.4487778686322205,
            "mae": 0.2767110401437374,
            "precision": 0.8169291338582677,
            "recall": 0.8169291338582677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8249628639338245,
            "auditor_fn_violation": 0.006030701754385969,
            "auditor_fp_violation": 0.013136717867630448,
            "ave_precision_score": 0.8252826532361477,
            "fpr": 0.14144736842105263,
            "logloss": 0.5344911742486782,
            "mae": 0.3143682645272827,
            "precision": 0.7266949152542372,
            "recall": 0.7690582959641256
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8981656232310258,
            "auditor_fn_violation": 0.005151386812104028,
            "auditor_fp_violation": 0.012834585831292749,
            "ave_precision_score": 0.8982722995360594,
            "fpr": 0.10208562019758508,
            "logloss": 0.4739143151353141,
            "mae": 0.2960562787394926,
            "precision": 0.8058455114822547,
            "recall": 0.7598425196850394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8201065744575766,
            "auditor_fn_violation": 0.011938478483203526,
            "auditor_fp_violation": 0.009204879150666367,
            "ave_precision_score": 0.8205261663699832,
            "fpr": 0.11293859649122807,
            "logloss": 0.5275135978022878,
            "mae": 0.30177669353022857,
            "precision": 0.7599067599067599,
            "recall": 0.7309417040358744
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8923836038278883,
            "auditor_fn_violation": 0.0025151905408091813,
            "auditor_fp_violation": 0.0106310247240101,
            "ave_precision_score": 0.8925171107730694,
            "fpr": 0.08122941822173436,
            "logloss": 0.47735311363378086,
            "mae": 0.2925371686174278,
            "precision": 0.832579185520362,
            "recall": 0.7244094488188977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8302294194030364,
            "auditor_fn_violation": 0.012966131696955395,
            "auditor_fp_violation": 0.01907094721782998,
            "ave_precision_score": 0.8305094540463666,
            "fpr": 0.17653508771929824,
            "logloss": 0.696100838020906,
            "mae": 0.2964405961397998,
            "precision": 0.6979362101313321,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8974587044207892,
            "auditor_fn_violation": 0.009421160444955364,
            "auditor_fp_violation": 0.021229363745563598,
            "ave_precision_score": 0.8975688319160584,
            "fpr": 0.12952799121844127,
            "logloss": 0.602404215014959,
            "mae": 0.27908767619283253,
            "precision": 0.7790262172284644,
            "recall": 0.8188976377952756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7930881876128284,
            "auditor_fn_violation": 0.011977814491385417,
            "auditor_fp_violation": 0.012381409532414735,
            "ave_precision_score": 0.7935723492139587,
            "fpr": 0.21052631578947367,
            "logloss": 0.5924634783942594,
            "mae": 0.3498575831564315,
            "precision": 0.6577540106951871,
            "recall": 0.827354260089686
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8810872040141494,
            "auditor_fn_violation": 0.0183366898018099,
            "auditor_fp_violation": 0.02372437236641763,
            "ave_precision_score": 0.881221496950141,
            "fpr": 0.16245883644346873,
            "logloss": 0.4944994386807031,
            "mae": 0.3218495595865933,
            "precision": 0.7426086956521739,
            "recall": 0.8405511811023622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8232539230335929,
            "auditor_fn_violation": 0.00923412792069861,
            "auditor_fp_violation": 0.009623710563963559,
            "ave_precision_score": 0.8235497565036523,
            "fpr": 0.17324561403508773,
            "logloss": 0.6902254154005616,
            "mae": 0.29152484954025654,
            "precision": 0.7030075187969925,
            "recall": 0.8385650224215246
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8920439434025239,
            "auditor_fn_violation": 0.007294916894992957,
            "auditor_fp_violation": 0.014030337779496804,
            "ave_precision_score": 0.8921662234724076,
            "fpr": 0.12184412733260154,
            "logloss": 0.5911675120855532,
            "mae": 0.27339216133285016,
            "precision": 0.7861271676300579,
            "recall": 0.8031496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.796830907289974,
            "auditor_fn_violation": 0.011009165289906381,
            "auditor_fp_violation": 0.002585931029289967,
            "ave_precision_score": 0.7971933379321047,
            "fpr": 0.13486842105263158,
            "logloss": 0.6141778201721267,
            "mae": 0.31837340840164025,
            "precision": 0.7260579064587973,
            "recall": 0.7309417040358744
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8788184190059923,
            "auditor_fn_violation": 0.013889729206461707,
            "auditor_fp_violation": 0.0038950462094118547,
            "ave_precision_score": 0.8789507416079851,
            "fpr": 0.10647639956092206,
            "logloss": 0.5287233901893388,
            "mae": 0.2979902096013983,
            "precision": 0.7904967602591793,
            "recall": 0.7204724409448819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.8121011801223232,
            "auditor_fn_violation": 0.017949512233498575,
            "auditor_fp_violation": 0.004381258941344779,
            "ave_precision_score": 0.8124768299071176,
            "fpr": 0.007675438596491228,
            "logloss": 1.0524162337909113,
            "mae": 0.39382513986154727,
            "precision": 0.9166666666666666,
            "recall": 0.1726457399103139
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.8986167827033593,
            "auditor_fn_violation": 0.016435171179892315,
            "auditor_fp_violation": 0.000986018690774188,
            "ave_precision_score": 0.8987445187011461,
            "fpr": 0.0021953896816684962,
            "logloss": 1.1499618059644918,
            "mae": 0.434344359565211,
            "precision": 0.9736842105263158,
            "recall": 0.14566929133858267
        }
    }
]