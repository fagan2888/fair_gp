[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 10132,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.216174831087763,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 10132,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.216174831087763,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6769651379942379,
            "auditor_fn_violation": 0.04149569610095929,
            "auditor_fp_violation": 0.03041427524728295,
            "ave_precision_score": 0.606077777439429,
            "fpr": 0.07894736842105263,
            "logloss": 0.6868150277080759,
            "mae": 0.47571451850889024,
            "precision": 0.68,
            "recall": 0.3180873180873181
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6573266035637819,
            "auditor_fn_violation": 0.04904119952750387,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.6005738885703533,
            "fpr": 0.08122941822173436,
            "logloss": 0.6867628017934335,
            "mae": 0.4748461503948522,
            "precision": 0.6864406779661016,
            "recall": 0.34249471458773784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.782031795758855,
            "auditor_fn_violation": 0.01145730750993909,
            "auditor_fp_violation": 0.026300525094639152,
            "ave_precision_score": 0.728345323778732,
            "fpr": 0.2050438596491228,
            "logloss": 5.088691333952972,
            "mae": 0.29054971818484054,
            "precision": 0.684654300168634,
            "recall": 0.8440748440748441
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7967840155770869,
            "auditor_fn_violation": 0.006918030275955381,
            "auditor_fp_violation": 0.02276589026058975,
            "ave_precision_score": 0.7405796023732678,
            "fpr": 0.2305159165751921,
            "logloss": 4.594050616706466,
            "mae": 0.2858594251740116,
            "precision": 0.6656050955414012,
            "recall": 0.8837209302325582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6774033441307794,
            "auditor_fn_violation": 0.04149569610095929,
            "auditor_fp_violation": 0.03041427524728295,
            "ave_precision_score": 0.6047422320439844,
            "fpr": 0.07894736842105263,
            "logloss": 0.6896071727962241,
            "mae": 0.4755279857403876,
            "precision": 0.68,
            "recall": 0.3180873180873181
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6558680277834558,
            "auditor_fn_violation": 0.04904119952750387,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.5976701691369761,
            "fpr": 0.08122941822173436,
            "logloss": 0.6919100247701709,
            "mae": 0.4752346707751277,
            "precision": 0.6864406779661016,
            "recall": 0.34249471458773784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6774033441307794,
            "auditor_fn_violation": 0.04149569610095929,
            "auditor_fp_violation": 0.03041427524728295,
            "ave_precision_score": 0.6047422320439844,
            "fpr": 0.07894736842105263,
            "logloss": 0.6903018361286818,
            "mae": 0.47597853894950004,
            "precision": 0.68,
            "recall": 0.3180873180873181
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6558680277834558,
            "auditor_fn_violation": 0.04904119952750387,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.5976701691369761,
            "fpr": 0.08122941822173436,
            "logloss": 0.6926072975758971,
            "mae": 0.47563937761126707,
            "precision": 0.6864406779661016,
            "recall": 0.34249471458773784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.597908739237019,
            "auditor_fn_violation": 0.04504504504504506,
            "auditor_fp_violation": 0.06074459640981806,
            "ave_precision_score": 0.5916139567766501,
            "fpr": 0.2149122807017544,
            "logloss": 0.6813427572876172,
            "mae": 0.4897046080512697,
            "precision": 0.5933609958506224,
            "recall": 0.5945945945945946
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5776869418356886,
            "auditor_fn_violation": 0.04036639336463196,
            "auditor_fp_violation": 0.05311539830283347,
            "ave_precision_score": 0.5685286020685809,
            "fpr": 0.1964873765093304,
            "logloss": 0.6863264288374771,
            "mae": 0.4929799905985299,
            "precision": 0.5788235294117647,
            "recall": 0.5200845665961945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7550799771980377,
            "auditor_fn_violation": 0.010876007586533903,
            "auditor_fp_violation": 0.01697398949810721,
            "ave_precision_score": 0.7392291094154861,
            "fpr": 0.3059210526315789,
            "logloss": 2.8260304992751144,
            "mae": 0.3499585633294104,
            "precision": 0.6130374479889042,
            "recall": 0.918918918918919
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7932617353819047,
            "auditor_fn_violation": 0.006560641258009345,
            "auditor_fp_violation": 0.023389922259146212,
            "ave_precision_score": 0.7766763396042695,
            "fpr": 0.3391877058177827,
            "logloss": 2.884507347516549,
            "mae": 0.36277798765860386,
            "precision": 0.5901856763925729,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6619674019481159,
            "auditor_fn_violation": 0.01660238173396069,
            "auditor_fp_violation": 0.009105202100378554,
            "ave_precision_score": 0.6625724598447423,
            "fpr": 0.17105263157894737,
            "logloss": 1.9785741067631957,
            "mae": 0.4296076816997953,
            "precision": 0.6294536817102138,
            "recall": 0.5509355509355509
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.716546485721633,
            "auditor_fn_violation": 0.008022687240515854,
            "auditor_fp_violation": 0.00970131673257848,
            "ave_precision_score": 0.7168905255876462,
            "fpr": 0.17014270032930845,
            "logloss": 1.6844506444239304,
            "mae": 0.39831663095419123,
            "precision": 0.6493212669683258,
            "recall": 0.6067653276955602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6774033441307794,
            "auditor_fn_violation": 0.04149569610095929,
            "auditor_fp_violation": 0.03041427524728295,
            "ave_precision_score": 0.6047422320439844,
            "fpr": 0.07894736842105263,
            "logloss": 0.6900817386582333,
            "mae": 0.47583535378962233,
            "precision": 0.68,
            "recall": 0.3180873180873181
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6558680277834558,
            "auditor_fn_violation": 0.04904119952750387,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.5976701691369761,
            "fpr": 0.08122941822173436,
            "logloss": 0.6923886623583929,
            "mae": 0.4755117952758211,
            "precision": 0.6864406779661016,
            "recall": 0.34249471458773784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6746391504770802,
            "auditor_fn_violation": 0.014970182733340633,
            "auditor_fp_violation": 0.00994983107420524,
            "ave_precision_score": 0.6751913762677224,
            "fpr": 0.1787280701754386,
            "logloss": 1.642062959969353,
            "mae": 0.42117313497977255,
            "precision": 0.6270022883295194,
            "recall": 0.5696465696465697
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7214680247538996,
            "auditor_fn_violation": 0.010060268784390002,
            "auditor_fp_violation": 0.016926554691768295,
            "ave_precision_score": 0.721803665816264,
            "fpr": 0.18221734357848518,
            "logloss": 1.5061194355127687,
            "mae": 0.39711398116159513,
            "precision": 0.6406926406926406,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7816346750706926,
            "auditor_fn_violation": 0.008824360798045015,
            "auditor_fp_violation": 0.02920584523954899,
            "ave_precision_score": 0.7269118796704016,
            "fpr": 0.17653508771929824,
            "logloss": 5.085040459753187,
            "mae": 0.2865919769591748,
            "precision": 0.7040441176470589,
            "recall": 0.7962577962577962
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7958196492307728,
            "auditor_fn_violation": 0.008679447578689409,
            "auditor_fp_violation": 0.018056829516462914,
            "ave_precision_score": 0.7379585428774926,
            "fpr": 0.18331503841931943,
            "logloss": 4.602845896284864,
            "mae": 0.2703543657969329,
            "precision": 0.7075306479859895,
            "recall": 0.854122621564482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7823010343583112,
            "auditor_fn_violation": 0.009202775650144077,
            "auditor_fp_violation": 0.02158892009606383,
            "ave_precision_score": 0.728676187331753,
            "fpr": 0.19407894736842105,
            "logloss": 5.028733599273575,
            "mae": 0.28585514245456056,
            "precision": 0.6927083333333334,
            "recall": 0.8295218295218295
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7961863484504461,
            "auditor_fn_violation": 0.007533017871771605,
            "auditor_fp_violation": 0.0251793152188623,
            "ave_precision_score": 0.7406955691898058,
            "fpr": 0.22063666300768386,
            "logloss": 4.520838345361236,
            "mae": 0.2797458935233483,
            "precision": 0.6737012987012987,
            "recall": 0.8773784355179705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.599373919391449,
            "auditor_fn_violation": 0.053926396031659204,
            "auditor_fp_violation": 0.025771359954410395,
            "ave_precision_score": 0.5856719073453853,
            "fpr": 0.11403508771929824,
            "logloss": 0.6897258128152742,
            "mae": 0.49747407737008315,
            "precision": 0.6104868913857678,
            "recall": 0.3388773388773389
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.5350760077077159,
            "auditor_fn_violation": 0.07880195774919181,
            "auditor_fp_violation": 0.047466530331964976,
            "ave_precision_score": 0.5548472157117382,
            "fpr": 0.13611416026344675,
            "logloss": 0.6927775169221716,
            "mae": 0.4989779746624039,
            "precision": 0.5782312925170068,
            "recall": 0.3594080338266385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7813584049648823,
            "auditor_fn_violation": 0.008206587153955575,
            "auditor_fp_violation": 0.023214576464362764,
            "ave_precision_score": 0.7266339052951806,
            "fpr": 0.18201754385964913,
            "logloss": 5.086750549153409,
            "mae": 0.2876461418329726,
            "precision": 0.6987295825771325,
            "recall": 0.8004158004158004
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.794542378877518,
            "auditor_fn_violation": 0.0074610759266006505,
            "auditor_fp_violation": 0.023412477632588014,
            "ave_precision_score": 0.7367727701445929,
            "fpr": 0.1942919868276619,
            "logloss": 4.608016898811072,
            "mae": 0.27356929112361766,
            "precision": 0.6958762886597938,
            "recall": 0.8562367864693446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6532484004850849,
            "auditor_fn_violation": 0.09451252872305504,
            "auditor_fp_violation": 0.10288445882688162,
            "ave_precision_score": 0.606450298327782,
            "fpr": 0.28728070175438597,
            "logloss": 0.692015255455795,
            "mae": 0.47310681445033925,
            "precision": 0.5683690280065898,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6405988489968167,
            "auditor_fn_violation": 0.09163083106870921,
            "auditor_fp_violation": 0.09597311399485738,
            "ave_precision_score": 0.6095898228234992,
            "fpr": 0.2667398463227223,
            "logloss": 0.6906983333187136,
            "mae": 0.4710868603246272,
            "precision": 0.5853242320819113,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.44220050179549564,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006258395408474784,
            "ave_precision_score": 0.44126225299356425,
            "fpr": 0.03070175438596491,
            "logloss": 0.6961350638048668,
            "mae": 0.5011801029833263,
            "precision": 0.5625,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.39842330365242057,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.396252415977576,
            "fpr": 0.04061470911086718,
            "logloss": 0.6981325369152662,
            "mae": 0.5021776526871942,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6747042826619634,
            "auditor_fn_violation": 0.013228562570667842,
            "auditor_fp_violation": 0.01264908210200676,
            "ave_precision_score": 0.675255313762664,
            "fpr": 0.17763157894736842,
            "logloss": 1.6456668048320264,
            "mae": 0.41973854732362076,
            "precision": 0.625866050808314,
            "recall": 0.5634095634095634
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7218302309710575,
            "auditor_fn_violation": 0.010211114798458125,
            "auditor_fp_violation": 0.009919352009182546,
            "ave_precision_score": 0.7221584780357688,
            "fpr": 0.17892425905598244,
            "logloss": 1.506613657985974,
            "mae": 0.395815143796475,
            "precision": 0.6456521739130435,
            "recall": 0.627906976744186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7863126548587971,
            "auditor_fn_violation": 0.011468705547652915,
            "auditor_fp_violation": 0.02194763300362275,
            "ave_precision_score": 0.7839529007078352,
            "fpr": 0.125,
            "logloss": 1.1016412164250005,
            "mae": 0.3027170625488706,
            "precision": 0.7403189066059226,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8015449101626567,
            "auditor_fn_violation": 0.014137752580047023,
            "auditor_fp_violation": 0.014510623580891089,
            "ave_precision_score": 0.797182011446582,
            "fpr": 0.1207464324917673,
            "logloss": 1.0773068420348535,
            "mae": 0.2782656447857413,
            "precision": 0.7571743929359823,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6462385429139169,
            "auditor_fn_violation": 0.013855454644928331,
            "auditor_fp_violation": 0.011608560263768473,
            "ave_precision_score": 0.6473632654594867,
            "fpr": 0.10635964912280702,
            "logloss": 2.2088785133420683,
            "mae": 0.47826441709192197,
            "precision": 0.5854700854700855,
            "recall": 0.28482328482328484
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.612130361049295,
            "auditor_fn_violation": 0.015922376961868462,
            "auditor_fp_violation": 0.021798515355197008,
            "ave_precision_score": 0.6135243845033176,
            "fpr": 0.10976948408342481,
            "logloss": 2.173161309007884,
            "mae": 0.48852559618480146,
            "precision": 0.576271186440678,
            "recall": 0.28752642706131076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8143372928618863,
            "auditor_fn_violation": 0.008076649524017947,
            "auditor_fp_violation": 0.012962001872430507,
            "ave_precision_score": 0.8136750055646594,
            "fpr": 0.14473684210526316,
            "logloss": 1.2384626565045278,
            "mae": 0.3034946040801631,
            "precision": 0.7173447537473233,
            "recall": 0.6964656964656964
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8469815301501746,
            "auditor_fn_violation": 0.012438994390848985,
            "auditor_fp_violation": 0.020490303695572632,
            "ave_precision_score": 0.8462561118703548,
            "fpr": 0.1602634467618002,
            "logloss": 1.0115970835310435,
            "mae": 0.29183621531981274,
            "precision": 0.7056451612903226,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.4409460360008737,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006258395408474784,
            "ave_precision_score": 0.4394613192304676,
            "fpr": 0.03070175438596491,
            "logloss": 0.6958399897798293,
            "mae": 0.501085656417305,
            "precision": 0.5625,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.3985506701519863,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.3964360281117021,
            "fpr": 0.04061470911086718,
            "logloss": 0.6977076747396758,
            "mae": 0.5020193084665502,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6555090538397019,
            "auditor_fn_violation": 0.03371539555750085,
            "auditor_fp_violation": 0.018564028981967684,
            "ave_precision_score": 0.6477879529533198,
            "fpr": 0.044956140350877194,
            "logloss": 2.7906604846726575,
            "mae": 0.4877072213460595,
            "precision": 0.6985294117647058,
            "recall": 0.19750519750519752
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6290790029088194,
            "auditor_fn_violation": 0.034643527661677914,
            "auditor_fp_violation": 0.02508909372509511,
            "ave_precision_score": 0.620318168939008,
            "fpr": 0.06256860592755215,
            "logloss": 2.78161856662267,
            "mae": 0.4932785983350322,
            "precision": 0.6392405063291139,
            "recall": 0.2135306553911205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6609080861617427,
            "auditor_fn_violation": 0.01052038880986249,
            "auditor_fp_violation": 0.016694142548947775,
            "ave_precision_score": 0.6367296174926769,
            "fpr": 0.08771929824561403,
            "logloss": 1.8711260362843742,
            "mae": 0.4768434330594334,
            "precision": 0.6506550218340611,
            "recall": 0.3097713097713098
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5527189253798088,
            "auditor_fn_violation": 0.01271283792408036,
            "auditor_fp_violation": 0.020134430025713124,
            "ave_precision_score": 0.6000808483199633,
            "fpr": 0.1119648737650933,
            "logloss": 1.907912618601418,
            "mae": 0.4883669795811945,
            "precision": 0.5836734693877551,
            "recall": 0.3023255813953488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8227272405166287,
            "auditor_fn_violation": 0.013205766495240186,
            "auditor_fp_violation": 0.01685187446574674,
            "ave_precision_score": 0.8220579387172252,
            "fpr": 0.1611842105263158,
            "logloss": 1.1351333622219375,
            "mae": 0.29436831692457754,
            "precision": 0.712890625,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8568308013461354,
            "auditor_fn_violation": 0.0075562249508590125,
            "auditor_fp_violation": 0.020014134700690193,
            "ave_precision_score": 0.8560554003306851,
            "fpr": 0.1800219538968167,
            "logloss": 0.9396914703433004,
            "mae": 0.28320143032752937,
            "precision": 0.6968576709796673,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7734464868916804,
            "auditor_fn_violation": 0.005906463143305255,
            "auditor_fp_violation": 0.019383217324052588,
            "ave_precision_score": 0.7597753874319486,
            "fpr": 0.24780701754385964,
            "logloss": 1.6361734234899667,
            "mae": 0.3468291933313594,
            "precision": 0.6435331230283912,
            "recall": 0.8482328482328483
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7799374468955922,
            "auditor_fn_violation": 0.0069644444341301895,
            "auditor_fp_violation": 0.01677367938288499,
            "ave_precision_score": 0.7619410075657718,
            "fpr": 0.24698133918770582,
            "logloss": 1.7894840108610883,
            "mae": 0.3406486000443229,
            "precision": 0.6451104100946372,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6774033441307794,
            "auditor_fn_violation": 0.04149569610095929,
            "auditor_fp_violation": 0.03041427524728295,
            "ave_precision_score": 0.6047422320439844,
            "fpr": 0.07894736842105263,
            "logloss": 0.6898500484021773,
            "mae": 0.4756855658141145,
            "precision": 0.68,
            "recall": 0.3180873180873181
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6558680277834558,
            "auditor_fn_violation": 0.04904119952750387,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.5976701691369761,
            "fpr": 0.08122941822173436,
            "logloss": 0.692156211014572,
            "mae": 0.4753773446664067,
            "precision": 0.6864406779661016,
            "recall": 0.34249471458773784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7799881975487419,
            "auditor_fn_violation": 0.011229346755662548,
            "auditor_fp_violation": 0.024980156307241423,
            "ave_precision_score": 0.7252646373177061,
            "fpr": 0.17434210526315788,
            "logloss": 5.0898526407883145,
            "mae": 0.29147131456210806,
            "precision": 0.7055555555555556,
            "recall": 0.7920997920997921
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.793375519725799,
            "auditor_fn_violation": 0.009853725780512088,
            "auditor_fp_violation": 0.01950287956934274,
            "ave_precision_score": 0.7356059543401982,
            "fpr": 0.1877058177826564,
            "logloss": 4.60629314396532,
            "mae": 0.2728304989406721,
            "precision": 0.7015706806282722,
            "recall": 0.8498942917547568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6848781344073231,
            "auditor_fn_violation": 0.07150900900900901,
            "auditor_fp_violation": 0.062024260186428946,
            "ave_precision_score": 0.6858538372859047,
            "fpr": 0.21820175438596492,
            "logloss": 0.68876767333332,
            "mae": 0.434626569277035,
            "precision": 0.6381818181818182,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.6929681161683533,
            "auditor_fn_violation": 0.07810806608447841,
            "auditor_fp_violation": 0.06659849931582035,
            "ave_precision_score": 0.6939062746031992,
            "fpr": 0.20856201975850713,
            "logloss": 0.6818205023583224,
            "mae": 0.43339012322781767,
            "precision": 0.632495164410058,
            "recall": 0.6913319238900634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5663499465693624,
            "auditor_fn_violation": 0.006642776379618493,
            "auditor_fp_violation": 0.008130825904668864,
            "ave_precision_score": 0.5563619599661846,
            "fpr": 0.0800438596491228,
            "logloss": 0.6948878833176236,
            "mae": 0.4999920030434926,
            "precision": 0.525974025974026,
            "recall": 0.1683991683991684
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.5298073557955877,
            "auditor_fn_violation": 0.005017370498696935,
            "auditor_fp_violation": 0.012761329062849295,
            "ave_precision_score": 0.5206447846491722,
            "fpr": 0.09110867178924259,
            "logloss": 0.6986161759448283,
            "mae": 0.5018378919487334,
            "precision": 0.4195804195804196,
            "recall": 0.12684989429175475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6539727975149283,
            "auditor_fn_violation": 0.03193274245905826,
            "auditor_fp_violation": 0.015348333129808281,
            "ave_precision_score": 0.6551702523983254,
            "fpr": 0.04057017543859649,
            "logloss": 2.362788763080906,
            "mae": 0.4764082620958592,
            "precision": 0.7218045112781954,
            "recall": 0.1995841995841996
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6191908919232899,
            "auditor_fn_violation": 0.03658596018129372,
            "auditor_fp_violation": 0.022344856623009487,
            "ave_precision_score": 0.6206343152184022,
            "fpr": 0.05598243688254665,
            "logloss": 2.3143607086290428,
            "mae": 0.4863675047123146,
            "precision": 0.6577181208053692,
            "recall": 0.20718816067653276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5562687962640818,
            "auditor_fn_violation": 0.006642776379618493,
            "auditor_fp_violation": 0.008130825904668864,
            "ave_precision_score": 0.5529046897283966,
            "fpr": 0.0800438596491228,
            "logloss": 0.6948632533818228,
            "mae": 0.4999792932026219,
            "precision": 0.525974025974026,
            "recall": 0.1683991683991684
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.5178282759231287,
            "auditor_fn_violation": 0.005017370498696935,
            "auditor_fp_violation": 0.012761329062849295,
            "ave_precision_score": 0.5181234593441355,
            "fpr": 0.09110867178924259,
            "logloss": 0.6986030469455848,
            "mae": 0.5018326604470987,
            "precision": 0.4195804195804196,
            "recall": 0.12684989429175475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6466246750753548,
            "auditor_fn_violation": 0.03371539555750085,
            "auditor_fp_violation": 0.016455000610575164,
            "ave_precision_score": 0.647824850755733,
            "fpr": 0.04276315789473684,
            "logloss": 2.308525395275364,
            "mae": 0.47809401260847634,
            "precision": 0.7089552238805971,
            "recall": 0.19750519750519752
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6124584113422691,
            "auditor_fn_violation": 0.033545832820843696,
            "auditor_fp_violation": 0.024610418577608033,
            "ave_precision_score": 0.6138608312178915,
            "fpr": 0.06147091108671789,
            "logloss": 2.2620360745526487,
            "mae": 0.4882163973675513,
            "precision": 0.643312101910828,
            "recall": 0.2135306553911205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6559790707934754,
            "auditor_fn_violation": 0.03132408724513989,
            "auditor_fp_violation": 0.01575538323767656,
            "ave_precision_score": 0.6571750508432448,
            "fpr": 0.041666666666666664,
            "logloss": 3.0963110599786248,
            "mae": 0.47519163931155883,
            "precision": 0.7121212121212122,
            "recall": 0.19542619542619544
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6263297326128618,
            "auditor_fn_violation": 0.034283817935823135,
            "auditor_fp_violation": 0.021472715516593237,
            "ave_precision_score": 0.6278521648114133,
            "fpr": 0.04610318331503842,
            "logloss": 3.0688094943817035,
            "mae": 0.48284259943583985,
            "precision": 0.6865671641791045,
            "recall": 0.1945031712473573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5906422156973996,
            "auditor_fn_violation": 0.052955283218441125,
            "auditor_fp_violation": 0.024809704074571583,
            "ave_precision_score": 0.5912973709356637,
            "fpr": 0.11293859649122807,
            "logloss": 0.6875712796115053,
            "mae": 0.49561862193309425,
            "precision": 0.6098484848484849,
            "recall": 0.33471933471933474
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.596121042907731,
            "auditor_fn_violation": 0.07880195774919181,
            "auditor_fp_violation": 0.047012916710524336,
            "ave_precision_score": 0.5932222609515188,
            "fpr": 0.1350164654226125,
            "logloss": 0.6896461427912228,
            "mae": 0.49651068789244485,
            "precision": 0.5802047781569966,
            "recall": 0.3594080338266385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5868871913455662,
            "auditor_fn_violation": 0.08923523726155307,
            "auditor_fp_violation": 0.04092888834615542,
            "ave_precision_score": 0.588539590042428,
            "fpr": 0.15570175438596492,
            "logloss": 0.6860842546430757,
            "mae": 0.4947328843633857,
            "precision": 0.6022408963585434,
            "recall": 0.446985446985447
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5515107857892647,
            "auditor_fn_violation": 0.09905477566877001,
            "auditor_fp_violation": 0.054368474605155676,
            "ave_precision_score": 0.5609692463487375,
            "fpr": 0.17014270032930845,
            "logloss": 0.6884241725116702,
            "mae": 0.4957187150233925,
            "precision": 0.5844504021447721,
            "recall": 0.4608879492600423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5532079739122779,
            "auditor_fn_violation": 0.007000674763832678,
            "auditor_fp_violation": 0.00505250946391501,
            "ave_precision_score": 0.5390797292938637,
            "fpr": 0.02850877192982456,
            "logloss": 0.7000818205440699,
            "mae": 0.5020410860316795,
            "precision": 0.5873015873015873,
            "recall": 0.07692307692307693
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.4851354785257691,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00379682119603627,
            "ave_precision_score": 0.507033658100153,
            "fpr": 0.04061470911086718,
            "logloss": 0.7049523189675131,
            "mae": 0.5043794917419111,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7814720987606594,
            "auditor_fn_violation": 0.0077894189736295,
            "auditor_fp_violation": 0.028267085928277775,
            "ave_precision_score": 0.726749427524632,
            "fpr": 0.18201754385964913,
            "logloss": 5.098987662955269,
            "mae": 0.2876645813670207,
            "precision": 0.6992753623188406,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.795725979102996,
            "auditor_fn_violation": 0.0063958709964887705,
            "auditor_fp_violation": 0.022928790179891637,
            "ave_precision_score": 0.7378621623602625,
            "fpr": 0.19209659714599342,
            "logloss": 4.620178919854769,
            "mae": 0.2730326898785136,
            "precision": 0.7003424657534246,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6538526292045872,
            "auditor_fn_violation": 0.09451252872305504,
            "auditor_fp_violation": 0.10288445882688162,
            "ave_precision_score": 0.6070150473702174,
            "fpr": 0.28728070175438597,
            "logloss": 0.6913959888908393,
            "mae": 0.4727762165038209,
            "precision": 0.5683690280065898,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6417094136677078,
            "auditor_fn_violation": 0.09170741442969764,
            "auditor_fp_violation": 0.09597311399485738,
            "ave_precision_score": 0.6106319748143351,
            "fpr": 0.2667398463227223,
            "logloss": 0.690069871540372,
            "mae": 0.47079084105339847,
            "precision": 0.58603066439523,
            "recall": 0.7272727272727273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7744401667328196,
            "auditor_fn_violation": 0.012795437137542408,
            "auditor_fp_violation": 0.02652949078031505,
            "ave_precision_score": 0.7614267226742727,
            "fpr": 0.23684210526315788,
            "logloss": 1.5379570818739128,
            "mae": 0.33921693592483176,
            "precision": 0.6405990016638935,
            "recall": 0.8004158004158004
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7809894237856854,
            "auditor_fn_violation": 0.010944458497620114,
            "auditor_fp_violation": 0.021284754071244916,
            "ave_precision_score": 0.7636851600470458,
            "fpr": 0.24259055982436883,
            "logloss": 1.6823666768225307,
            "mae": 0.32824924309898124,
            "precision": 0.6429725363489499,
            "recall": 0.8414376321353065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7320469503602309,
            "auditor_fn_violation": 0.010121457489878544,
            "auditor_fp_violation": 0.01674502381243132,
            "ave_precision_score": 0.6980980210091445,
            "fpr": 0.3333333333333333,
            "logloss": 4.2409120678126175,
            "mae": 0.37161808509781324,
            "precision": 0.5935828877005348,
            "recall": 0.9230769230769231
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7754858042111915,
            "auditor_fn_violation": 0.005973502157098001,
            "auditor_fp_violation": 0.0234575883794716,
            "ave_precision_score": 0.7440092533111916,
            "fpr": 0.3556531284302964,
            "logloss": 4.263922160086429,
            "mae": 0.38546277174447857,
            "precision": 0.5792207792207792,
            "recall": 0.9429175475687104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6555090538397019,
            "auditor_fn_violation": 0.03371539555750085,
            "auditor_fp_violation": 0.018564028981967684,
            "ave_precision_score": 0.6477879529533198,
            "fpr": 0.044956140350877194,
            "logloss": 2.5092579562274766,
            "mae": 0.48777164477925045,
            "precision": 0.6985294117647058,
            "recall": 0.19750519750519752
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6290790029088194,
            "auditor_fn_violation": 0.034643527661677914,
            "auditor_fp_violation": 0.02508909372509511,
            "ave_precision_score": 0.620318168939008,
            "fpr": 0.06256860592755215,
            "logloss": 2.4987091137734154,
            "mae": 0.4932074605070505,
            "precision": 0.6392405063291139,
            "recall": 0.2135306553911205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7668913242435209,
            "auditor_fn_violation": 0.011694386694386697,
            "auditor_fp_violation": 0.017520963080555237,
            "ave_precision_score": 0.7676021424990835,
            "fpr": 0.30153508771929827,
            "logloss": 1.5094165788268468,
            "mae": 0.34217710242144284,
            "precision": 0.6185852981969486,
            "recall": 0.9272349272349273
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7737888737044988,
            "auditor_fn_violation": 0.00746339663450939,
            "auditor_fp_violation": 0.027800750843320354,
            "ave_precision_score": 0.7740608876784084,
            "fpr": 0.3150384193194292,
            "logloss": 1.5753120821622884,
            "mae": 0.3515855750302745,
            "precision": 0.6079234972677595,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6487386654150931,
            "auditor_fn_violation": 0.005441423204581097,
            "auditor_fp_violation": 0.00828346969511947,
            "ave_precision_score": 0.64952311999047,
            "fpr": 0.13706140350877194,
            "logloss": 1.1213563220025007,
            "mae": 0.45070741000815534,
            "precision": 0.5833333333333334,
            "recall": 0.36382536382536385
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.6304118048622547,
            "auditor_fn_violation": 0.009839801533059645,
            "auditor_fp_violation": 0.014593326616844354,
            "ave_precision_score": 0.6309802070189299,
            "fpr": 0.15697036223929747,
            "logloss": 1.1887728765810102,
            "mae": 0.4667305443275852,
            "precision": 0.5387096774193548,
            "recall": 0.35306553911205074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5477776505013014,
            "auditor_fn_violation": 0.014398001240106515,
            "auditor_fp_violation": 0.0015976716733829964,
            "ave_precision_score": 0.5448043148538204,
            "fpr": 0.04824561403508772,
            "logloss": 0.6945206767944384,
            "mae": 0.49995098965601964,
            "precision": 0.5686274509803921,
            "recall": 0.12058212058212059
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.529494477086162,
            "auditor_fn_violation": 0.006486378604929655,
            "auditor_fp_violation": 0.007916936078071667,
            "ave_precision_score": 0.5289725891288304,
            "fpr": 0.05159165751920966,
            "logloss": 0.6975742005595824,
            "mae": 0.5014884989426505,
            "precision": 0.4777777777777778,
            "recall": 0.09090909090909091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7800531547950185,
            "auditor_fn_violation": 0.010442882153408474,
            "auditor_fp_violation": 0.0263717588635161,
            "ave_precision_score": 0.7254106815913441,
            "fpr": 0.18530701754385964,
            "logloss": 5.094243918499508,
            "mae": 0.29209995301540215,
            "precision": 0.6960431654676259,
            "recall": 0.8045738045738046
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7933706775286037,
            "auditor_fn_violation": 0.010921251418532712,
            "auditor_fp_violation": 0.024793367717747077,
            "ave_precision_score": 0.735599358124696,
            "fpr": 0.1964873765093304,
            "logloss": 4.613419107668545,
            "mae": 0.27465353488753574,
            "precision": 0.692967409948542,
            "recall": 0.854122621564482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6376852039887859,
            "auditor_fn_violation": 0.043649925228872614,
            "auditor_fp_violation": 0.03140391582203769,
            "ave_precision_score": 0.5922183793369526,
            "fpr": 0.07785087719298246,
            "logloss": 0.6917208876243671,
            "mae": 0.47634097437063855,
            "precision": 0.6885964912280702,
            "recall": 0.3264033264033264
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6066354088711932,
            "auditor_fn_violation": 0.046400233927357225,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.5895752622524293,
            "fpr": 0.08122941822173436,
            "logloss": 0.6922640282976531,
            "mae": 0.4752617767888288,
            "precision": 0.6837606837606838,
            "recall": 0.3382663847780127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5906422156973996,
            "auditor_fn_violation": 0.052955283218441125,
            "auditor_fp_violation": 0.024809704074571583,
            "ave_precision_score": 0.5912973709356637,
            "fpr": 0.11293859649122807,
            "logloss": 0.6875712796664158,
            "mae": 0.4956186219657722,
            "precision": 0.6098484848484849,
            "recall": 0.33471933471933474
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.596121042907731,
            "auditor_fn_violation": 0.07880195774919181,
            "auditor_fp_violation": 0.047012916710524336,
            "ave_precision_score": 0.5932222609515188,
            "fpr": 0.1350164654226125,
            "logloss": 0.6896461426632047,
            "mae": 0.49651068785973096,
            "precision": 0.5802047781569966,
            "recall": 0.3594080338266385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6523258126904544,
            "auditor_fn_violation": 0.03193274245905826,
            "auditor_fp_violation": 0.017452273374852445,
            "ave_precision_score": 0.656882463412048,
            "fpr": 0.04276315789473684,
            "logloss": 2.466992012063131,
            "mae": 0.47882856056416234,
            "precision": 0.7111111111111111,
            "recall": 0.1995841995841996
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6208461213713403,
            "auditor_fn_violation": 0.03725432405901096,
            "auditor_fp_violation": 0.021577973925988307,
            "ave_precision_score": 0.622269534631571,
            "fpr": 0.05598243688254665,
            "logloss": 2.4221021631598574,
            "mae": 0.4870064110732633,
            "precision": 0.6554054054054054,
            "recall": 0.20507399577167018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7800531547950185,
            "auditor_fn_violation": 0.010442882153408474,
            "auditor_fp_violation": 0.0263717588635161,
            "ave_precision_score": 0.7254106815913441,
            "fpr": 0.18530701754385964,
            "logloss": 5.094254321583899,
            "mae": 0.2921000826465779,
            "precision": 0.6960431654676259,
            "recall": 0.8045738045738046
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7933706775286037,
            "auditor_fn_violation": 0.010921251418532712,
            "auditor_fp_violation": 0.024793367717747077,
            "ave_precision_score": 0.735599358124696,
            "fpr": 0.1964873765093304,
            "logloss": 4.613431596315723,
            "mae": 0.27465364181570356,
            "precision": 0.692967409948542,
            "recall": 0.854122621564482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5477776505013014,
            "auditor_fn_violation": 0.014398001240106515,
            "auditor_fp_violation": 0.0015976716733829964,
            "ave_precision_score": 0.5448043148538204,
            "fpr": 0.04824561403508772,
            "logloss": 0.6945206798108573,
            "mae": 0.499950990930461,
            "precision": 0.5686274509803921,
            "recall": 0.12058212058212059
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.529494477086162,
            "auditor_fn_violation": 0.006486378604929655,
            "auditor_fp_violation": 0.007916936078071667,
            "ave_precision_score": 0.5289725891288304,
            "fpr": 0.05159165751920966,
            "logloss": 0.6975742031366742,
            "mae": 0.5014884999894939,
            "precision": 0.4777777777777778,
            "recall": 0.09090909090909091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6701333651659882,
            "auditor_fn_violation": 0.03132408724513989,
            "auditor_fp_violation": 0.016350694020433917,
            "ave_precision_score": 0.6630384049971841,
            "fpr": 0.04057017543859649,
            "logloss": 3.022058728487323,
            "mae": 0.47548284892589765,
            "precision": 0.7175572519083969,
            "recall": 0.19542619542619544
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6451616562078161,
            "auditor_fn_violation": 0.034283817935823135,
            "auditor_fp_violation": 0.019728433303760732,
            "ave_precision_score": 0.6374280934313454,
            "fpr": 0.04500548847420417,
            "logloss": 2.9874347868672895,
            "mae": 0.48246843466787714,
            "precision": 0.6917293233082706,
            "recall": 0.1945031712473573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 10132,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.49689712232523203,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006749399601090895,
            "ave_precision_score": 0.5174860894423973,
            "fpr": 0.029605263157894735,
            "logloss": 0.6953320692846159,
            "mae": 0.5005262663685962,
            "precision": 0.5714285714285714,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.46245357945518195,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.002872050884922488,
            "ave_precision_score": 0.45987933348181986,
            "fpr": 0.04171240395170143,
            "logloss": 0.6986067672015852,
            "mae": 0.5021804748133691,
            "precision": 0.3968253968253968,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.755180227352799,
            "auditor_fn_violation": 0.010876007586533903,
            "auditor_fp_violation": 0.01697398949810721,
            "ave_precision_score": 0.7393271413897057,
            "fpr": 0.3059210526315789,
            "logloss": 2.826004214249124,
            "mae": 0.35000849769828224,
            "precision": 0.6130374479889042,
            "recall": 0.918918918918919
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7933033748637057,
            "auditor_fn_violation": 0.006560641258009345,
            "auditor_fp_violation": 0.023389922259146212,
            "ave_precision_score": 0.776724318405775,
            "fpr": 0.3391877058177827,
            "logloss": 2.884989917581189,
            "mae": 0.3628523425351836,
            "precision": 0.5901856763925729,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.657651644723404,
            "auditor_fn_violation": 0.00871949885107781,
            "auditor_fp_violation": 0.0023990515732486674,
            "ave_precision_score": 0.6112229304114751,
            "fpr": 0.006578947368421052,
            "logloss": 0.6866832304029781,
            "mae": 0.4951903483781375,
            "precision": 0.8723404255319149,
            "recall": 0.08523908523908524
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6512235112815652,
            "auditor_fn_violation": 0.006330891175044037,
            "auditor_fp_violation": 0.0005864397094867901,
            "ave_precision_score": 0.6019535514752314,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6888756551550987,
            "mae": 0.49681956855054743,
            "precision": 0.972972972972973,
            "recall": 0.07610993657505286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8243454533125006,
            "auditor_fn_violation": 0.013552266841740528,
            "auditor_fp_violation": 0.02496998005454472,
            "ave_precision_score": 0.8241574872217989,
            "fpr": 0.21271929824561403,
            "logloss": 1.093707262978923,
            "mae": 0.2867690330323453,
            "precision": 0.6910828025477707,
            "recall": 0.9022869022869023
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8523681014605032,
            "auditor_fn_violation": 0.008447376787815358,
            "auditor_fp_violation": 0.02323704695026291,
            "ave_precision_score": 0.8525059332586915,
            "fpr": 0.24259055982436883,
            "logloss": 1.0570630315919662,
            "mae": 0.2907657776288081,
            "precision": 0.6651515151515152,
            "recall": 0.9281183932346723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7679029092254543,
            "auditor_fn_violation": 0.009259765838713217,
            "auditor_fp_violation": 0.017500610575161803,
            "ave_precision_score": 0.7193784976586242,
            "fpr": 0.17105263157894737,
            "logloss": 5.1788767679962895,
            "mae": 0.3163201625334951,
            "precision": 0.691699604743083,
            "recall": 0.7276507276507277
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7809370780442014,
            "auditor_fn_violation": 0.011092983803779509,
            "auditor_fp_violation": 0.019537965705807764,
            "ave_precision_score": 0.7305474758461709,
            "fpr": 0.18551042810098792,
            "logloss": 4.579320836915626,
            "mae": 0.3037116167119653,
            "precision": 0.6835205992509363,
            "recall": 0.7716701902748414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6671287072129675,
            "auditor_fn_violation": 0.04124493927125507,
            "auditor_fp_violation": 0.030907823503073226,
            "ave_precision_score": 0.6283865875251216,
            "fpr": 0.07456140350877193,
            "logloss": 0.6867186200299846,
            "mae": 0.4764853930590968,
            "precision": 0.6851851851851852,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6493103145330262,
            "auditor_fn_violation": 0.04911314147267482,
            "auditor_fp_violation": 0.031557473597682316,
            "ave_precision_score": 0.6201884788286727,
            "fpr": 0.08122941822173436,
            "logloss": 0.6886723998116706,
            "mae": 0.47623733759057246,
            "precision": 0.6796536796536796,
            "recall": 0.33192389006342493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.58500694211602,
            "auditor_fn_violation": 0.08923523726155307,
            "auditor_fp_violation": 0.04092888834615542,
            "ave_precision_score": 0.5867634199183747,
            "fpr": 0.15570175438596492,
            "logloss": 0.6862002057581015,
            "mae": 0.49478218760014625,
            "precision": 0.6022408963585434,
            "recall": 0.446985446985447
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5502612573736028,
            "auditor_fn_violation": 0.09905477566877001,
            "auditor_fp_violation": 0.054368474605155676,
            "ave_precision_score": 0.5597588292933087,
            "fpr": 0.17014270032930845,
            "logloss": 0.6885128759380452,
            "mae": 0.49575684321829566,
            "precision": 0.5844504021447721,
            "recall": 0.4608879492600423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.641759961042043,
            "auditor_fn_violation": 0.07779388700441332,
            "auditor_fp_violation": 0.07499898237473034,
            "ave_precision_score": 0.6181595904869488,
            "fpr": 0.2149122807017544,
            "logloss": 0.690395131143414,
            "mae": 0.4724188975401615,
            "precision": 0.5958762886597938,
            "recall": 0.6008316008316008
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6361893482710783,
            "auditor_fn_violation": 0.07728421477687555,
            "auditor_fp_violation": 0.0789387947410894,
            "ave_precision_score": 0.6160846085084528,
            "fpr": 0.20856201975850713,
            "logloss": 0.6904448088121855,
            "mae": 0.47122109243820054,
            "precision": 0.6,
            "recall": 0.6025369978858351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7817625699781994,
            "auditor_fn_violation": 0.013454243717401615,
            "auditor_fp_violation": 0.02452222493588961,
            "ave_precision_score": 0.7280744025133887,
            "fpr": 0.19956140350877194,
            "logloss": 5.076773194363945,
            "mae": 0.2889136124993373,
            "precision": 0.6888888888888889,
            "recall": 0.8378378378378378
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7964107109323249,
            "auditor_fn_violation": 0.006725411519529919,
            "auditor_fp_violation": 0.023495180668541275,
            "ave_precision_score": 0.7402066237311857,
            "fpr": 0.22283205268935236,
            "logloss": 4.574292152434836,
            "mae": 0.2818938337252464,
            "precision": 0.6720516962843296,
            "recall": 0.879492600422833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6638882900674205,
            "auditor_fn_violation": 0.032771638034795936,
            "auditor_fp_violation": 0.020670513290186026,
            "ave_precision_score": 0.6562524088830112,
            "fpr": 0.0537280701754386,
            "logloss": 2.0040587311767997,
            "mae": 0.477649510133774,
            "precision": 0.6838709677419355,
            "recall": 0.2203742203742204
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6303630509792671,
            "auditor_fn_violation": 0.03873725641269616,
            "auditor_fp_violation": 0.029036284077410053,
            "ave_precision_score": 0.6216423794875654,
            "fpr": 0.07354555433589462,
            "logloss": 1.9556732932215874,
            "mae": 0.4888785107783899,
            "precision": 0.6104651162790697,
            "recall": 0.2219873150105708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6700709886801951,
            "auditor_fn_violation": 0.03132408724513989,
            "auditor_fp_violation": 0.016350694020433917,
            "ave_precision_score": 0.6629987567449748,
            "fpr": 0.04057017543859649,
            "logloss": 3.007560987613458,
            "mae": 0.47599138126134166,
            "precision": 0.7175572519083969,
            "recall": 0.19542619542619544
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6443708860255095,
            "auditor_fn_violation": 0.034283817935823135,
            "auditor_fp_violation": 0.019728433303760732,
            "ave_precision_score": 0.6366917083508281,
            "fpr": 0.04500548847420417,
            "logloss": 2.9713913558679863,
            "mae": 0.4823474948128423,
            "precision": 0.6917293233082706,
            "recall": 0.1945031712473573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.44261909543237676,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006258395408474784,
            "ave_precision_score": 0.44164368092195827,
            "fpr": 0.03070175438596491,
            "logloss": 0.6961231062014867,
            "mae": 0.5011704908847286,
            "precision": 0.5625,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.3985273864732457,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.3963563880614495,
            "fpr": 0.04061470911086718,
            "logloss": 0.6981263811016314,
            "mae": 0.5021709651899914,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.4428475701301676,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006258395408474784,
            "ave_precision_score": 0.44184974423316403,
            "fpr": 0.03070175438596491,
            "logloss": 0.6961023527440895,
            "mae": 0.5011539200418874,
            "precision": 0.5625,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.3990062100993635,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.396772230069369,
            "fpr": 0.04061470911086718,
            "logloss": 0.6981153841582289,
            "mae": 0.5021593145756246,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6559689962975276,
            "auditor_fn_violation": 0.03132408724513989,
            "auditor_fp_violation": 0.016350694020433917,
            "ave_precision_score": 0.6572499420539946,
            "fpr": 0.04057017543859649,
            "logloss": 3.090015882028259,
            "mae": 0.4751983695492125,
            "precision": 0.7175572519083969,
            "recall": 0.19542619542619544
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6249990250354683,
            "auditor_fn_violation": 0.034283817935823135,
            "auditor_fp_violation": 0.019728433303760732,
            "ave_precision_score": 0.6266566183874047,
            "fpr": 0.04500548847420417,
            "logloss": 3.062473455271319,
            "mae": 0.48282966444497993,
            "precision": 0.6917293233082706,
            "recall": 0.1945031712473573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6928258531986644,
            "auditor_fn_violation": 0.06259118430171062,
            "auditor_fp_violation": 0.06126104123417594,
            "ave_precision_score": 0.6936656498298517,
            "fpr": 0.23903508771929824,
            "logloss": 0.7160583211345761,
            "mae": 0.4322796563287021,
            "precision": 0.6234887737478411,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7090875151521664,
            "auditor_fn_violation": 0.06891806276586611,
            "auditor_fp_violation": 0.06470384794670919,
            "ave_precision_score": 0.7095247263668649,
            "fpr": 0.2217343578485181,
            "logloss": 0.6987002835331307,
            "mae": 0.4310445004939199,
            "precision": 0.6307129798903108,
            "recall": 0.7293868921775899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 10132,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.49689712232523203,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006749399601090895,
            "ave_precision_score": 0.5174860894423973,
            "fpr": 0.029605263157894735,
            "logloss": 0.6953320793321088,
            "mae": 0.5005262723159895,
            "precision": 0.5714285714285714,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.46245357945518206,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.002872050884922488,
            "ave_precision_score": 0.45987933348181986,
            "fpr": 0.04171240395170143,
            "logloss": 0.6986067592670816,
            "mae": 0.5021804717709806,
            "precision": 0.3968253968253968,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6941027099551095,
            "auditor_fn_violation": 0.0006337308968887916,
            "auditor_fp_violation": 0.0026560019538405337,
            "ave_precision_score": 0.6948966046326965,
            "fpr": 0.46600877192982454,
            "logloss": 2.665835551000475,
            "mae": 0.46649112128764963,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7038446336848103,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017442822128325038,
            "ave_precision_score": 0.7043045841791065,
            "fpr": 0.47420417124039516,
            "logloss": 2.6761461129375883,
            "mae": 0.4735758786629497,
            "precision": 0.5226519337016574,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6555090538397019,
            "auditor_fn_violation": 0.03371539555750085,
            "auditor_fp_violation": 0.018564028981967684,
            "ave_precision_score": 0.6477879529533198,
            "fpr": 0.044956140350877194,
            "logloss": 2.707529805814061,
            "mae": 0.48546104247999894,
            "precision": 0.6985294117647058,
            "recall": 0.19750519750519752
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6290790029088194,
            "auditor_fn_violation": 0.034643527661677914,
            "auditor_fp_violation": 0.02508909372509511,
            "ave_precision_score": 0.620318168939008,
            "fpr": 0.06256860592755215,
            "logloss": 2.697104526490819,
            "mae": 0.4912475938405589,
            "precision": 0.6392405063291139,
            "recall": 0.2135306553911205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6646401775861207,
            "auditor_fn_violation": 0.02605591421380895,
            "auditor_fp_violation": 0.018749745593682584,
            "ave_precision_score": 0.6571368820090743,
            "fpr": 0.06798245614035088,
            "logloss": 2.091377165169424,
            "mae": 0.4767644495086089,
            "precision": 0.6352941176470588,
            "recall": 0.22453222453222454
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6359608031479684,
            "auditor_fn_violation": 0.02730312854633179,
            "auditor_fp_violation": 0.021430110922314283,
            "ave_precision_score": 0.6273835386789945,
            "fpr": 0.07354555433589462,
            "logloss": 2.023477059502825,
            "mae": 0.4859319764479579,
            "precision": 0.6235955056179775,
            "recall": 0.2346723044397463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.5982439859984688,
            "auditor_fn_violation": 0.04504504504504506,
            "auditor_fp_violation": 0.06074459640981806,
            "ave_precision_score": 0.5922506674008643,
            "fpr": 0.2149122807017544,
            "logloss": 0.6813427663117291,
            "mae": 0.4897046153874774,
            "precision": 0.5933609958506224,
            "recall": 0.5945945945945946
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5776869418356886,
            "auditor_fn_violation": 0.04036639336463196,
            "auditor_fp_violation": 0.05311539830283347,
            "ave_precision_score": 0.5685286020685809,
            "fpr": 0.1964873765093304,
            "logloss": 0.686326440062454,
            "mae": 0.492979997828292,
            "precision": 0.5788235294117647,
            "recall": 0.5200845665961945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6491515367613596,
            "auditor_fn_violation": 0.04496753838859103,
            "auditor_fp_violation": 0.0285265803720438,
            "ave_precision_score": 0.5631322199351099,
            "fpr": 0.0756578947368421,
            "logloss": 0.6843159340776563,
            "mae": 0.487508460617902,
            "precision": 0.6461538461538462,
            "recall": 0.26195426195426197
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6176062825563602,
            "auditor_fn_violation": 0.05266382457304776,
            "auditor_fp_violation": 0.033136349738608295,
            "ave_precision_score": 0.5566465539481082,
            "fpr": 0.0867178924259056,
            "logloss": 0.6852171312476047,
            "mae": 0.4872269722030924,
            "precision": 0.6291079812206573,
            "recall": 0.2832980972515856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7677572716507237,
            "auditor_fn_violation": 0.008370718897034692,
            "auditor_fp_violation": 0.019602006757031793,
            "ave_precision_score": 0.7192330056803878,
            "fpr": 0.17653508771929824,
            "logloss": 5.170506191439303,
            "mae": 0.3168428772580819,
            "precision": 0.6861598440545809,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7804102858898074,
            "auditor_fn_violation": 0.011092983803779509,
            "auditor_fp_violation": 0.018397666270694554,
            "ave_precision_score": 0.7300832648509183,
            "fpr": 0.18990120746432493,
            "logloss": 4.57253137551536,
            "mae": 0.3049726158189929,
            "precision": 0.6784386617100372,
            "recall": 0.7716701902748414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7572845886373841,
            "auditor_fn_violation": 0.010876007586533903,
            "auditor_fp_violation": 0.022965258273293446,
            "ave_precision_score": 0.7396659966289238,
            "fpr": 0.3092105263157895,
            "logloss": 2.93377349487246,
            "mae": 0.3515051583890418,
            "precision": 0.6104972375690608,
            "recall": 0.918918918918919
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7925573631848779,
            "auditor_fn_violation": 0.005896918796109566,
            "auditor_fp_violation": 0.02358038985709918,
            "ave_precision_score": 0.7736899489316085,
            "fpr": 0.3413830954994512,
            "logloss": 3.0201459999594342,
            "mae": 0.3648578114540063,
            "precision": 0.5902503293807642,
            "recall": 0.9471458773784355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.786151039634005,
            "auditor_fn_violation": 0.011468705547652915,
            "auditor_fp_violation": 0.02194763300362275,
            "ave_precision_score": 0.783814607769583,
            "fpr": 0.125,
            "logloss": 1.1012734399685316,
            "mae": 0.3026937235203314,
            "precision": 0.7403189066059226,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8016316032904186,
            "auditor_fn_violation": 0.014137752580047023,
            "auditor_fp_violation": 0.014510623580891089,
            "ave_precision_score": 0.7972727261402157,
            "fpr": 0.1207464324917673,
            "logloss": 1.0765685574303068,
            "mae": 0.27822449309033237,
            "precision": 0.7571743929359823,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.4415875208435125,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006258395408474784,
            "ave_precision_score": 0.44004285202304105,
            "fpr": 0.03070175438596491,
            "logloss": 0.6958072602888277,
            "mae": 0.5010586712313326,
            "precision": 0.5625,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.39920661331851515,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.3970290454965164,
            "fpr": 0.04061470911086718,
            "logloss": 0.6976934856128656,
            "mae": 0.5020016859051425,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7799689406830556,
            "auditor_fn_violation": 0.011229346755662548,
            "auditor_fp_violation": 0.024980156307241423,
            "ave_precision_score": 0.7252453964576473,
            "fpr": 0.17434210526315788,
            "logloss": 5.08969192102306,
            "mae": 0.29150643422910105,
            "precision": 0.7055555555555556,
            "recall": 0.7920997920997921
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7933537541946156,
            "auditor_fn_violation": 0.011092983803779509,
            "auditor_fp_violation": 0.01950287956934274,
            "ave_precision_score": 0.7355842034665502,
            "fpr": 0.1877058177826564,
            "logloss": 4.606044607297619,
            "mae": 0.2728743592385627,
            "precision": 0.7020905923344948,
            "recall": 0.8520084566596194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7656541394345366,
            "auditor_fn_violation": 0.012918535944851733,
            "auditor_fp_violation": 0.019759738673830764,
            "ave_precision_score": 0.766172962252788,
            "fpr": 0.27521929824561403,
            "logloss": 1.4903434435274774,
            "mae": 0.32943585200419384,
            "precision": 0.6367583212735166,
            "recall": 0.9147609147609148
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7782098853431081,
            "auditor_fn_violation": 0.01001153391830644,
            "auditor_fp_violation": 0.0320361487451694,
            "ave_precision_score": 0.7780579489652281,
            "fpr": 0.29527991218441274,
            "logloss": 1.5402573496702952,
            "mae": 0.3380252137480081,
            "precision": 0.6184397163120567,
            "recall": 0.9217758985200846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6491515367613596,
            "auditor_fn_violation": 0.04496753838859103,
            "auditor_fp_violation": 0.0285265803720438,
            "ave_precision_score": 0.5631322199351099,
            "fpr": 0.0756578947368421,
            "logloss": 0.6843159340776563,
            "mae": 0.487508460617902,
            "precision": 0.6461538461538462,
            "recall": 0.26195426195426197
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6176062825563602,
            "auditor_fn_violation": 0.05266382457304776,
            "auditor_fp_violation": 0.033136349738608295,
            "ave_precision_score": 0.5566465539481082,
            "fpr": 0.0867178924259056,
            "logloss": 0.6852171312476047,
            "mae": 0.4872269722030924,
            "precision": 0.6291079812206573,
            "recall": 0.2832980972515856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7441930574191316,
            "auditor_fn_violation": 0.01644736842105263,
            "auditor_fp_violation": 0.008403040664305776,
            "ave_precision_score": 0.7447457472155733,
            "fpr": 0.17763157894736842,
            "logloss": 1.0546350027559777,
            "mae": 0.38578021179279876,
            "precision": 0.6582278481012658,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7971243689958777,
            "auditor_fn_violation": 0.009974402591766596,
            "auditor_fp_violation": 0.005160168212962824,
            "ave_precision_score": 0.7973680177839807,
            "fpr": 0.17014270032930845,
            "logloss": 0.8274457416753049,
            "mae": 0.356103314355566,
            "precision": 0.6750524109014675,
            "recall": 0.6807610993657506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6560717119859287,
            "auditor_fn_violation": 0.03132408724513989,
            "auditor_fp_violation": 0.01575538323767656,
            "ave_precision_score": 0.6572522336586909,
            "fpr": 0.041666666666666664,
            "logloss": 3.0905554187977438,
            "mae": 0.4752761199785336,
            "precision": 0.7121212121212122,
            "recall": 0.19542619542619544
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6262203814878579,
            "auditor_fn_violation": 0.034283817935823135,
            "auditor_fp_violation": 0.021472715516593237,
            "ave_precision_score": 0.6277415746538705,
            "fpr": 0.04610318331503842,
            "logloss": 3.06321871955116,
            "mae": 0.48292273298273125,
            "precision": 0.6865671641791045,
            "recall": 0.1945031712473573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 10132,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.529646667271833,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.00647972890462816,
            "ave_precision_score": 0.5567437243330686,
            "fpr": 0.02850877192982456,
            "logloss": 0.6943965757543904,
            "mae": 0.5001110244673073,
            "precision": 0.5806451612903226,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5369218679482195,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.5391357234959203,
            "fpr": 0.04061470911086718,
            "logloss": 0.6974546531951669,
            "mae": 0.501646836031674,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7813308340384302,
            "auditor_fn_violation": 0.008710380420906738,
            "auditor_fp_violation": 0.022853319493629672,
            "ave_precision_score": 0.7266063514106226,
            "fpr": 0.18640350877192982,
            "logloss": 5.095003948482017,
            "mae": 0.28848850846838425,
            "precision": 0.6953405017921147,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7944978824138892,
            "auditor_fn_violation": 0.0063958709964887705,
            "auditor_fp_violation": 0.025206882897513407,
            "ave_precision_score": 0.7367300230630519,
            "fpr": 0.20197585071350166,
            "logloss": 4.619573035095243,
            "mae": 0.2759414361530145,
            "precision": 0.6897133220910624,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7432347612052576,
            "auditor_fn_violation": 0.01644736842105263,
            "auditor_fp_violation": 0.008403040664305776,
            "ave_precision_score": 0.7437915396972007,
            "fpr": 0.17763157894736842,
            "logloss": 1.0587267437265966,
            "mae": 0.3859717004607981,
            "precision": 0.6582278481012658,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7958312104963152,
            "auditor_fn_violation": 0.010443185589332174,
            "auditor_fp_violation": 0.005160168212962824,
            "ave_precision_score": 0.7960778036515518,
            "fpr": 0.17014270032930845,
            "logloss": 0.8311924649505216,
            "mae": 0.3563362428827016,
            "precision": 0.6736842105263158,
            "recall": 0.6765327695560254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6593940881676367,
            "auditor_fn_violation": 0.027453313637524176,
            "auditor_fp_violation": 0.018546220539748443,
            "ave_precision_score": 0.6343945708019139,
            "fpr": 0.06469298245614036,
            "logloss": 2.014809524946696,
            "mae": 0.48073013865908715,
            "precision": 0.6685393258426966,
            "recall": 0.24740124740124741
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5482868630431622,
            "auditor_fn_violation": 0.03389393900715474,
            "auditor_fp_violation": 0.028006255356901193,
            "ave_precision_score": 0.596342968556617,
            "fpr": 0.07574094401756312,
            "logloss": 2.0461829740004256,
            "mae": 0.489429086954338,
            "precision": 0.6290322580645161,
            "recall": 0.24735729386892177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6466774585969632,
            "auditor_fn_violation": 0.044766932924827675,
            "auditor_fp_violation": 0.02862325477266251,
            "ave_precision_score": 0.5575104754671318,
            "fpr": 0.07236842105263158,
            "logloss": 0.6918281668914683,
            "mae": 0.4837845178288326,
            "precision": 0.6470588235294118,
            "recall": 0.2515592515592516
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6502212658478754,
            "auditor_fn_violation": 0.05289357465601309,
            "auditor_fp_violation": 0.033021066718794644,
            "ave_precision_score": 0.5548884961280354,
            "fpr": 0.07903402854006586,
            "logloss": 0.6912214039256359,
            "mae": 0.48205912263673434,
            "precision": 0.6470588235294118,
            "recall": 0.27906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7577369936836922,
            "auditor_fn_violation": 0.010018875150454099,
            "auditor_fp_violation": 0.016907843855578635,
            "ave_precision_score": 0.7281215901387709,
            "fpr": 0.2894736842105263,
            "logloss": 3.7219209966713893,
            "mae": 0.339715871613907,
            "precision": 0.6228571428571429,
            "recall": 0.9064449064449065
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7932195364655239,
            "auditor_fn_violation": 0.005028974038240627,
            "auditor_fp_violation": 0.0248510092276539,
            "ave_precision_score": 0.7641148564864415,
            "fpr": 0.31174533479692645,
            "logloss": 3.705317863751915,
            "mae": 0.3485566899507984,
            "precision": 0.6088154269972452,
            "recall": 0.9344608879492601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6555090538397019,
            "auditor_fn_violation": 0.03371539555750085,
            "auditor_fp_violation": 0.018564028981967684,
            "ave_precision_score": 0.6477879529533198,
            "fpr": 0.044956140350877194,
            "logloss": 2.797265922746482,
            "mae": 0.48553819169156714,
            "precision": 0.6985294117647058,
            "recall": 0.19750519750519752
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6290790029088194,
            "auditor_fn_violation": 0.034643527661677914,
            "auditor_fp_violation": 0.02508909372509511,
            "ave_precision_score": 0.620318168939008,
            "fpr": 0.06256860592755215,
            "logloss": 2.787761064461993,
            "mae": 0.4913289710494139,
            "precision": 0.6392405063291139,
            "recall": 0.2135306553911205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 10132,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.216174831087763,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6704318512407417,
            "auditor_fn_violation": 0.02411140897983003,
            "auditor_fp_violation": 0.015190601213009323,
            "ave_precision_score": 0.6633347030945576,
            "fpr": 0.06578947368421052,
            "logloss": 2.986843275671885,
            "mae": 0.47550031061273457,
            "precision": 0.6385542168674698,
            "recall": 0.2203742203742204
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6453337346307472,
            "auditor_fn_violation": 0.027518954381844665,
            "auditor_fp_violation": 0.020776005092502093,
            "ave_precision_score": 0.6375993095723642,
            "fpr": 0.05817782656421515,
            "logloss": 2.9477122196366747,
            "mae": 0.48236730579226783,
            "precision": 0.6645569620253164,
            "recall": 0.2219873150105708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6190442520733441,
            "auditor_fn_violation": 0.010075865339023249,
            "auditor_fp_violation": 0.01593601172304311,
            "ave_precision_score": 0.6345351913515938,
            "fpr": 0.08991228070175439,
            "logloss": 1.8120530228361191,
            "mae": 0.4766982531337386,
            "precision": 0.646551724137931,
            "recall": 0.31185031185031187
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5982859164540435,
            "auditor_fn_violation": 0.01271283792408036,
            "auditor_fp_violation": 0.019081845931762487,
            "ave_precision_score": 0.6015928703300589,
            "fpr": 0.11306256860592755,
            "logloss": 1.852279147986241,
            "mae": 0.48834740790220554,
            "precision": 0.5813008130081301,
            "recall": 0.3023255813953488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.785846584543231,
            "auditor_fn_violation": 0.00903408469197943,
            "auditor_fp_violation": 0.026476065453657355,
            "ave_precision_score": 0.7834419805687651,
            "fpr": 0.17982456140350878,
            "logloss": 1.0913770824900204,
            "mae": 0.3050471661396902,
            "precision": 0.6974169741697417,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7970762766985697,
            "auditor_fn_violation": 0.011926117943017341,
            "auditor_fp_violation": 0.019167055120320388,
            "ave_precision_score": 0.7927171058507161,
            "fpr": 0.18660812294182216,
            "logloss": 1.1354588068570577,
            "mae": 0.2914690071403515,
            "precision": 0.6991150442477876,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6555090538397019,
            "auditor_fn_violation": 0.03371539555750085,
            "auditor_fp_violation": 0.018564028981967684,
            "ave_precision_score": 0.6477879529533198,
            "fpr": 0.044956140350877194,
            "logloss": 2.786095326093871,
            "mae": 0.48774403291554336,
            "precision": 0.6985294117647058,
            "recall": 0.19750519750519752
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6290790029088194,
            "auditor_fn_violation": 0.034643527661677914,
            "auditor_fp_violation": 0.02508909372509511,
            "ave_precision_score": 0.620318168939008,
            "fpr": 0.06256860592755215,
            "logloss": 2.776222616034226,
            "mae": 0.4932955710278887,
            "precision": 0.6392405063291139,
            "recall": 0.2135306553911205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 10132,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.513623575453366,
            "auditor_fn_violation": 0.009417058759164017,
            "auditor_fp_violation": 0.006749399601090895,
            "ave_precision_score": 0.5352292188614832,
            "fpr": 0.029605263157894735,
            "logloss": 0.6946957994644548,
            "mae": 0.5001539165774981,
            "precision": 0.5714285714285714,
            "recall": 0.07484407484407485
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.47980655456166854,
            "auditor_fn_violation": 0.004678547144020834,
            "auditor_fp_violation": 0.00416773178152364,
            "ave_precision_score": 0.47893078457061733,
            "fpr": 0.04061470911086718,
            "logloss": 0.6987181028905005,
            "mae": 0.502181576485168,
            "precision": 0.4032258064516129,
            "recall": 0.052854122621564484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6459842239644502,
            "auditor_fn_violation": 0.09451252872305504,
            "auditor_fp_violation": 0.10288445882688162,
            "ave_precision_score": 0.6052485066549613,
            "fpr": 0.28728070175438597,
            "logloss": 0.6925710587032339,
            "mae": 0.47340588238939907,
            "precision": 0.5683690280065898,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6405797086500058,
            "auditor_fn_violation": 0.09163083106870921,
            "auditor_fp_violation": 0.09597311399485738,
            "ave_precision_score": 0.6095715974545408,
            "fpr": 0.2667398463227223,
            "logloss": 0.6912347531873485,
            "mae": 0.47134583534184193,
            "precision": 0.5853242320819113,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6652600317581634,
            "auditor_fn_violation": 0.02605591421380895,
            "auditor_fp_violation": 0.018749745593682584,
            "ave_precision_score": 0.6577506053124168,
            "fpr": 0.06798245614035088,
            "logloss": 2.076433012209054,
            "mae": 0.4766406727015585,
            "precision": 0.6352941176470588,
            "recall": 0.22453222453222454
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6364105784466167,
            "auditor_fn_violation": 0.02730312854633179,
            "auditor_fp_violation": 0.021430110922314283,
            "ave_precision_score": 0.627827736223509,
            "fpr": 0.07354555433589462,
            "logloss": 2.0069698498022657,
            "mae": 0.4857173833429113,
            "precision": 0.6235955056179775,
            "recall": 0.2346723044397463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5985291899349591,
            "auditor_fn_violation": 0.04504504504504506,
            "auditor_fp_violation": 0.05988979118329466,
            "ave_precision_score": 0.5922274812582026,
            "fpr": 0.21271929824561403,
            "logloss": 0.6811904889110745,
            "mae": 0.48960280220694186,
            "precision": 0.5958333333333333,
            "recall": 0.5945945945945946
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.577957235801548,
            "auditor_fn_violation": 0.04155923722972456,
            "auditor_fp_violation": 0.05311539830283347,
            "ave_precision_score": 0.5687803153962955,
            "fpr": 0.1964873765093304,
            "logloss": 0.6862074406976311,
            "mae": 0.4929047842417015,
            "precision": 0.5748218527315915,
            "recall": 0.5116279069767442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6927790996325007,
            "auditor_fn_violation": 0.06259118430171062,
            "auditor_fp_violation": 0.06126104123417594,
            "ave_precision_score": 0.6936200424120323,
            "fpr": 0.23903508771929824,
            "logloss": 0.7164733239465537,
            "mae": 0.43213245361530744,
            "precision": 0.6234887737478411,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7089797578340125,
            "auditor_fn_violation": 0.06891806276586611,
            "auditor_fp_violation": 0.06470384794670919,
            "ave_precision_score": 0.7094187522166411,
            "fpr": 0.2217343578485181,
            "logloss": 0.6981052547413947,
            "mae": 0.4307630282584435,
            "precision": 0.6307129798903108,
            "recall": 0.7293868921775899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7419586418019308,
            "auditor_fn_violation": 0.016953441295546573,
            "auditor_fp_violation": 0.00873885700329711,
            "ave_precision_score": 0.7425122067537897,
            "fpr": 0.18311403508771928,
            "logloss": 1.0551699396820966,
            "mae": 0.3887479325709424,
            "precision": 0.6520833333333333,
            "recall": 0.6507276507276507
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7943869170842072,
            "auditor_fn_violation": 0.010057948076481254,
            "auditor_fp_violation": 0.010921813051040306,
            "ave_precision_score": 0.7946367914585183,
            "fpr": 0.1734357848518112,
            "logloss": 0.8309054290762283,
            "mae": 0.3589551689666122,
            "precision": 0.6728778467908902,
            "recall": 0.6871035940803383
        }
    }
]