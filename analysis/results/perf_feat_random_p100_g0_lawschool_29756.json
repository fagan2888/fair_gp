[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8109610249430351,
            "auditor_fn_violation": 0.021094839609483964,
            "auditor_fp_violation": 0.022159734012450485,
            "ave_precision_score": 0.8118645881899991,
            "fpr": 0.13925438596491227,
            "logloss": 0.8721852987763463,
            "mae": 0.2750819585252576,
            "precision": 0.742914979757085,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8363439920743019,
            "auditor_fn_violation": 0.022908614598418958,
            "auditor_fp_violation": 0.029902721526174347,
            "ave_precision_score": 0.8365802492677351,
            "fpr": 0.132821075740944,
            "logloss": 0.8304911447309112,
            "mae": 0.27245983742114016,
            "precision": 0.7515400410677618,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7150280416088035,
            "auditor_fn_violation": 0.01594041327167291,
            "auditor_fp_violation": 0.01951956504163635,
            "ave_precision_score": 0.6956844935975326,
            "fpr": 0.16447368421052633,
            "logloss": 0.6141145486785119,
            "mae": 0.41458336438722254,
            "precision": 0.6868475991649269,
            "recall": 0.6882845188284519
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.711733205335729,
            "auditor_fn_violation": 0.011209862649779996,
            "auditor_fp_violation": 0.027808269301134295,
            "ave_precision_score": 0.6959095875120372,
            "fpr": 0.15916575192096596,
            "logloss": 0.6214809733855453,
            "mae": 0.4182570331313869,
            "precision": 0.6834061135371179,
            "recall": 0.657563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8473031969417395,
            "auditor_fn_violation": 0.009483043382514869,
            "auditor_fp_violation": 0.012895141078502708,
            "ave_precision_score": 0.8476370526902999,
            "fpr": 0.11732456140350878,
            "logloss": 0.49424996840342245,
            "mae": 0.3234597835904232,
            "precision": 0.7756813417190775,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8419201926521821,
            "auditor_fn_violation": 0.008490992445276695,
            "auditor_fp_violation": 0.013598798844266123,
            "ave_precision_score": 0.842241596543918,
            "fpr": 0.10647639956092206,
            "logloss": 0.5121859669358426,
            "mae": 0.33600029625554706,
            "precision": 0.7844444444444445,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6073633445209643,
            "auditor_fn_violation": 0.0021562798208911407,
            "auditor_fp_violation": 0.00732678470369473,
            "ave_precision_score": 0.5450231180218728,
            "fpr": 0.4550438596491228,
            "logloss": 0.6849886908771458,
            "mae": 0.49097727549572784,
            "precision": 0.5331833520809899,
            "recall": 0.9916317991631799
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6238185833657854,
            "auditor_fn_violation": 0.0012222232471473774,
            "auditor_fp_violation": 0.006641684646151142,
            "ave_precision_score": 0.5502594816603871,
            "fpr": 0.4522502744237102,
            "logloss": 0.6807232537859278,
            "mae": 0.48973403205332455,
            "precision": 0.5349887133182845,
            "recall": 0.9957983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8085095110083207,
            "auditor_fn_violation": 0.008363613007413936,
            "auditor_fp_violation": 0.017811666262430272,
            "ave_precision_score": 0.728189336948227,
            "fpr": 0.18092105263157895,
            "logloss": 0.57953494342147,
            "mae": 0.40441330757580307,
            "precision": 0.6944444444444444,
            "recall": 0.7845188284518828
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7839781693521565,
            "auditor_fn_violation": 0.018241105443275004,
            "auditor_fp_violation": 0.023727872616929737,
            "ave_precision_score": 0.7018597559285403,
            "fpr": 0.1734357848518112,
            "logloss": 0.6029858761938942,
            "mae": 0.415296493586803,
            "precision": 0.6920077972709552,
            "recall": 0.7457983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 29756,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8578391247835851,
            "auditor_fn_violation": 0.012084342655802686,
            "auditor_fp_violation": 0.004274799902983267,
            "ave_precision_score": 0.8571945664693411,
            "fpr": 0.08552631578947369,
            "logloss": 0.4954039741079425,
            "mae": 0.32668692052462384,
            "precision": 0.8156028368794326,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8554104386401733,
            "auditor_fn_violation": 0.0034314494184062203,
            "auditor_fp_violation": 0.007267496877247438,
            "ave_precision_score": 0.8543409886686824,
            "fpr": 0.07903402854006586,
            "logloss": 0.49749052801506827,
            "mae": 0.32579264281119263,
            "precision": 0.8230958230958231,
            "recall": 0.7037815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7713573916295007,
            "auditor_fn_violation": 0.00351886515451812,
            "auditor_fp_violation": 0.012185200905489533,
            "ave_precision_score": 0.7636670193550879,
            "fpr": 0.047149122807017545,
            "logloss": 0.6023781789371373,
            "mae": 0.39894753174545866,
            "precision": 0.8313725490196079,
            "recall": 0.4435146443514644
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7666271263703244,
            "auditor_fn_violation": 0.018453264950327,
            "auditor_fp_violation": 0.004701162042469439,
            "ave_precision_score": 0.7553390012975675,
            "fpr": 0.052689352360043906,
            "logloss": 0.6289197957850599,
            "mae": 0.4107035862529317,
            "precision": 0.8040816326530612,
            "recall": 0.41386554621848737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.695472188668832,
            "auditor_fn_violation": 0.007969059678484927,
            "auditor_fp_violation": 0.005388976473441671,
            "ave_precision_score": 0.6862541062888194,
            "fpr": 0.047149122807017545,
            "logloss": 0.9032873627483111,
            "mae": 0.4329441863473652,
            "precision": 0.7675675675675676,
            "recall": 0.29707112970711297
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6996093253123231,
            "auditor_fn_violation": 0.0053962309402356,
            "auditor_fp_violation": 0.0033839282334683384,
            "ave_precision_score": 0.691988149631603,
            "fpr": 0.042810098792535674,
            "logloss": 0.8946111575591998,
            "mae": 0.4294340821436957,
            "precision": 0.7868852459016393,
            "recall": 0.3025210084033613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5831518145366268,
            "auditor_fn_violation": 0.009175658812302727,
            "auditor_fp_violation": 0.009686514673781252,
            "ave_precision_score": 0.5604471221031124,
            "fpr": 0.3782894736842105,
            "logloss": 0.733858603888448,
            "mae": 0.48987678609984486,
            "precision": 0.5406125166444741,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5634850443265078,
            "auditor_fn_violation": 0.006865204918410836,
            "auditor_fp_violation": 0.005639880389113886,
            "ave_precision_score": 0.5508783865304075,
            "fpr": 0.3951701427003293,
            "logloss": 0.735633400921217,
            "mae": 0.4918108307863826,
            "precision": 0.530638852672751,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6955206633648425,
            "auditor_fn_violation": 0.012043052191147327,
            "auditor_fp_violation": 0.006877071711536916,
            "ave_precision_score": 0.6987946974081289,
            "fpr": 0.2050438596491228,
            "logloss": 0.6536513990154627,
            "mae": 0.38169544282075213,
            "precision": 0.6725043782837128,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7281225768928457,
            "auditor_fn_violation": 0.005820549954339586,
            "auditor_fp_violation": 0.015148188803512631,
            "ave_precision_score": 0.7139086434914113,
            "fpr": 0.19099890230515917,
            "logloss": 0.6247040822338794,
            "mae": 0.3732066112974276,
            "precision": 0.6813186813186813,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.6082284394647938,
            "auditor_fn_violation": 0.009634441752917881,
            "auditor_fp_violation": 0.013284218611043739,
            "ave_precision_score": 0.5604268297680913,
            "fpr": 0.0756578947368421,
            "logloss": 0.6919689977451106,
            "mae": 0.49136832998575347,
            "precision": 0.6290322580645161,
            "recall": 0.24476987447698745
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6004656920781508,
            "auditor_fn_violation": 0.003080925015450755,
            "auditor_fp_violation": 0.014482001589764947,
            "ave_precision_score": 0.5533707987415996,
            "fpr": 0.07574094401756312,
            "logloss": 0.6960861432935054,
            "mae": 0.4938492676003966,
            "precision": 0.6101694915254238,
            "recall": 0.226890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5335666624493663,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5826719799418301,
            "fpr": 0.4758771929824561,
            "logloss": 0.8615931329675575,
            "mae": 0.4824562702785459,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5412299905431902,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5819513550227944,
            "fpr": 0.4774972557628979,
            "logloss": 0.8691727842592479,
            "mae": 0.48359749836665217,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.767582292387132,
            "auditor_fn_violation": 0.019755193422887764,
            "auditor_fp_violation": 0.031479909451046985,
            "ave_precision_score": 0.7570022305554366,
            "fpr": 0.18421052631578946,
            "logloss": 0.6720037285734797,
            "mae": 0.3423141559587648,
            "precision": 0.708838821490468,
            "recall": 0.8556485355648535
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8009937865239641,
            "auditor_fn_violation": 0.02517318672803919,
            "auditor_fp_violation": 0.02203212334557201,
            "ave_precision_score": 0.7866962253100259,
            "fpr": 0.18221734357848518,
            "logloss": 0.6682504935416091,
            "mae": 0.34430567129830625,
            "precision": 0.7046263345195729,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.788772587078735,
            "auditor_fn_violation": 0.006253211480584308,
            "auditor_fp_violation": 0.03091903144959172,
            "ave_precision_score": 0.7892991846424655,
            "fpr": 0.33223684210526316,
            "logloss": 1.6568615287146253,
            "mae": 0.3992956224338789,
            "precision": 0.5899864682002707,
            "recall": 0.9121338912133892
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7929119702809215,
            "auditor_fn_violation": 0.012332924388196553,
            "auditor_fp_violation": 0.03568643779098378,
            "ave_precision_score": 0.7932550385113809,
            "fpr": 0.3150384193194292,
            "logloss": 1.5213790094060518,
            "mae": 0.3830006839186117,
            "precision": 0.6008344923504868,
            "recall": 0.907563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8319842076460526,
            "auditor_fn_violation": 0.011180540262790872,
            "auditor_fp_violation": 0.010262551540140673,
            "ave_precision_score": 0.8323635526766842,
            "fpr": 0.12938596491228072,
            "logloss": 0.523655988409586,
            "mae": 0.36558304651918117,
            "precision": 0.7658730158730159,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8237080976107891,
            "auditor_fn_violation": 0.005875895912700977,
            "auditor_fp_violation": 0.013881423722825744,
            "ave_precision_score": 0.8240085849416476,
            "fpr": 0.132821075740944,
            "logloss": 0.541303652774959,
            "mae": 0.3783058415767128,
            "precision": 0.7494824016563147,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.796043991284164,
            "auditor_fn_violation": 0.0030876091903398683,
            "auditor_fp_violation": 0.012728393564556559,
            "ave_precision_score": 0.7976870754957155,
            "fpr": 0.2894736842105263,
            "logloss": 0.685806539160197,
            "mae": 0.36368814918831455,
            "precision": 0.62339514978602,
            "recall": 0.9142259414225942
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.816321739927087,
            "auditor_fn_violation": 0.005919711463070413,
            "auditor_fp_violation": 0.01158257314811311,
            "ave_precision_score": 0.8165636822923404,
            "fpr": 0.29088913282107576,
            "logloss": 0.6616122838430599,
            "mae": 0.369510129391339,
            "precision": 0.6159420289855072,
            "recall": 0.8928571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7819512565906688,
            "auditor_fn_violation": 0.004229978712471555,
            "auditor_fp_violation": 0.014997170345217886,
            "ave_precision_score": 0.7276890155534519,
            "fpr": 0.13815789473684212,
            "logloss": 3.2756754699258175,
            "mae": 0.31426226260379353,
            "precision": 0.7319148936170212,
            "recall": 0.7196652719665272
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.79228388154691,
            "auditor_fn_violation": 0.02069477626396333,
            "auditor_fp_violation": 0.01644775855760375,
            "ave_precision_score": 0.7436975693509486,
            "fpr": 0.11306256860592755,
            "logloss": 2.8871312084456373,
            "mae": 0.3141079616882919,
            "precision": 0.7547619047619047,
            "recall": 0.6659663865546218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.810589990818312,
            "auditor_fn_violation": 0.0042070395654408,
            "auditor_fp_violation": 0.010007377314253373,
            "ave_precision_score": 0.8122218972626083,
            "fpr": 0.08881578947368421,
            "logloss": 0.5146218259728242,
            "mae": 0.3597862597783668,
            "precision": 0.8163265306122449,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7943842971786977,
            "auditor_fn_violation": 0.008449482976505654,
            "auditor_fp_violation": 0.009230730408670531,
            "ave_precision_score": 0.7959112603804956,
            "fpr": 0.0867178924259056,
            "logloss": 0.5317992869660397,
            "mae": 0.36534376342655145,
            "precision": 0.8105515587529976,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5579361718979383,
            "auditor_fn_violation": 0.004730052117742051,
            "auditor_fp_violation": 0.006925074783733529,
            "ave_precision_score": 0.5555894693996668,
            "fpr": 0.0756578947368421,
            "logloss": 10.192476120148003,
            "mae": 0.49618137263356843,
            "precision": 0.6057142857142858,
            "recall": 0.2217573221757322
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5536427930158507,
            "auditor_fn_violation": 0.007930614616867613,
            "auditor_fp_violation": 0.015483805846802177,
            "ave_precision_score": 0.5536574010997602,
            "fpr": 0.08122941822173436,
            "logloss": 9.815066367772555,
            "mae": 0.4953431141032763,
            "precision": 0.5771428571428572,
            "recall": 0.21218487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6032099135587625,
            "auditor_fn_violation": 0.02018874330176907,
            "auditor_fp_violation": 0.01657369229525427,
            "ave_precision_score": 0.5912462963316792,
            "fpr": 0.18859649122807018,
            "logloss": 0.6717867697690232,
            "mae": 0.4661477314994523,
            "precision": 0.6332622601279317,
            "recall": 0.6213389121338913
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6403139686607797,
            "auditor_fn_violation": 0.019301902978535006,
            "auditor_fp_violation": 0.013187478708505243,
            "ave_precision_score": 0.6145435931361241,
            "fpr": 0.17453347969264543,
            "logloss": 0.6537610517079099,
            "mae": 0.45774037463735673,
            "precision": 0.6609808102345416,
            "recall": 0.6512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.822908178377878,
            "auditor_fn_violation": 0.0190440798649343,
            "auditor_fp_violation": 0.007847239065405453,
            "ave_precision_score": 0.787899213026733,
            "fpr": 0.05701754385964912,
            "logloss": 0.5796492155305807,
            "mae": 0.3636701808049621,
            "precision": 0.8424242424242424,
            "recall": 0.5815899581589958
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7896903516495613,
            "auditor_fn_violation": 0.009335018310287903,
            "auditor_fp_violation": 0.008221355842386166,
            "ave_precision_score": 0.7536403410742745,
            "fpr": 0.06147091108671789,
            "logloss": 0.621981258915771,
            "mae": 0.38213027312811854,
            "precision": 0.8210862619808307,
            "recall": 0.5399159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6410910794630273,
            "auditor_fn_violation": 0.008069991925420253,
            "auditor_fp_violation": 0.014431239388794577,
            "ave_precision_score": 0.6524606918008209,
            "fpr": 0.16228070175438597,
            "logloss": 0.6353504377143526,
            "mae": 0.4242918518159473,
            "precision": 0.6942148760330579,
            "recall": 0.702928870292887
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6713514326052774,
            "auditor_fn_violation": 0.01383648959034767,
            "auditor_fp_violation": 0.018456413944509628,
            "ave_precision_score": 0.6750188447921661,
            "fpr": 0.15697036223929747,
            "logloss": 0.6149067210796244,
            "mae": 0.416333927984557,
            "precision": 0.7087576374745418,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.8344176743954532,
            "auditor_fn_violation": 0.009758313146883947,
            "auditor_fp_violation": 0.0015083070579675,
            "ave_precision_score": 0.7862840532815107,
            "fpr": 0.020833333333333332,
            "logloss": 0.6133844271822821,
            "mae": 0.4253771516510792,
            "precision": 0.9107981220657277,
            "recall": 0.40585774058577406
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8160283697307984,
            "auditor_fn_violation": 0.0031823926057799722,
            "auditor_fp_violation": 0.0018673429476260767,
            "ave_precision_score": 0.7615939155669453,
            "fpr": 0.021953896816684963,
            "logloss": 0.6200529373303346,
            "mae": 0.43351720405985833,
            "precision": 0.8913043478260869,
            "recall": 0.3445378151260504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8058645628586618,
            "auditor_fn_violation": 0.014102987594509285,
            "auditor_fp_violation": 0.011922447247150136,
            "ave_precision_score": 0.8073850769656012,
            "fpr": 0.11293859649122807,
            "logloss": 0.5576694584669551,
            "mae": 0.39238943173468377,
            "precision": 0.7716186252771619,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7546292731112614,
            "auditor_fn_violation": 0.01885913531164387,
            "auditor_fp_violation": 0.012281565035265028,
            "ave_precision_score": 0.7563827093155602,
            "fpr": 0.11086717892425905,
            "logloss": 0.5782217462456628,
            "mae": 0.4000836819631143,
            "precision": 0.769406392694064,
            "recall": 0.707983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8319377349164554,
            "auditor_fn_violation": 0.008416373045584681,
            "auditor_fp_violation": 0.013097259277225324,
            "ave_precision_score": 0.7951535926647799,
            "fpr": 0.08991228070175439,
            "logloss": 0.523091455635588,
            "mae": 0.36072227463387607,
            "precision": 0.8123569794050344,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8195779887745083,
            "auditor_fn_violation": 0.004736691603095688,
            "auditor_fp_violation": 0.00807499653027493,
            "ave_precision_score": 0.7806879500820636,
            "fpr": 0.08781558726673985,
            "logloss": 0.537214123026118,
            "mae": 0.3677324069056631,
            "precision": 0.8062953995157385,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8649693213281959,
            "auditor_fn_violation": 0.004294208324157676,
            "auditor_fp_violation": 0.013314536340852133,
            "ave_precision_score": 0.8653472784877769,
            "fpr": 0.14035087719298245,
            "logloss": 0.4775545969470374,
            "mae": 0.2881004723879558,
            "precision": 0.7602996254681648,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8732468925049296,
            "auditor_fn_violation": 0.01640085232775877,
            "auditor_fp_violation": 0.018474077999419608,
            "ave_precision_score": 0.8734251672558953,
            "fpr": 0.13611416026344675,
            "logloss": 0.4830726934445799,
            "mae": 0.28989634267080056,
            "precision": 0.7596899224806202,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7769150474859898,
            "auditor_fn_violation": 0.008804044630404465,
            "auditor_fp_violation": 0.030787654620422027,
            "ave_precision_score": 0.7774048637131121,
            "fpr": 0.2774122807017544,
            "logloss": 0.5958701090837262,
            "mae": 0.4282075641758479,
            "precision": 0.6251851851851852,
            "recall": 0.8828451882845189
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7649852673058379,
            "auditor_fn_violation": 0.013758082816002364,
            "auditor_fp_violation": 0.032211665846549845,
            "ave_precision_score": 0.7653412954979494,
            "fpr": 0.24478594950603733,
            "logloss": 0.5894648316032322,
            "mae": 0.42740645842947694,
            "precision": 0.6521060842433697,
            "recall": 0.8781512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7594828009000942,
            "auditor_fn_violation": 0.004273563091830007,
            "auditor_fp_violation": 0.0022915150780176306,
            "ave_precision_score": 0.761023710076558,
            "fpr": 0.0800438596491228,
            "logloss": 1.6928109148158332,
            "mae": 0.3331291374984957,
            "precision": 0.7902298850574713,
            "recall": 0.5753138075313807
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7060978178401713,
            "auditor_fn_violation": 0.006888265734394753,
            "auditor_fp_violation": 0.011635565312843033,
            "ave_precision_score": 0.7077651563757764,
            "fpr": 0.09549945115257959,
            "logloss": 2.1858842703465093,
            "mae": 0.3561640377333613,
            "precision": 0.75,
            "recall": 0.5483193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 29756,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5781205251457301,
            "auditor_fn_violation": 0.0020025875357850757,
            "auditor_fp_violation": 0.0022940415555016574,
            "ave_precision_score": 0.5478075868595348,
            "fpr": 0.0043859649122807015,
            "logloss": 16.800315248973018,
            "mae": 0.5073012636867354,
            "precision": 0.8620689655172413,
            "recall": 0.05230125523012552
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5093752498246814,
            "auditor_fn_violation": 0.0014159341014122557,
            "auditor_fp_violation": 0.003356170432895517,
            "ave_precision_score": 0.5286141826260997,
            "fpr": 0.012074643249176729,
            "logloss": 16.942990248268575,
            "mae": 0.5112725265674688,
            "precision": 0.7027027027027027,
            "recall": 0.0546218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.782183569953527,
            "auditor_fn_violation": 0.011162188945166277,
            "auditor_fp_violation": 0.003971622604899346,
            "ave_precision_score": 0.6949870083676506,
            "fpr": 0.019736842105263157,
            "logloss": 0.6048349166710062,
            "mae": 0.4220130299136304,
            "precision": 0.9021739130434783,
            "recall": 0.3472803347280335
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.787966209039442,
            "auditor_fn_violation": 0.009046758110488988,
            "auditor_fp_violation": 0.0032930845225027446,
            "ave_precision_score": 0.6935635718075607,
            "fpr": 0.010976948408342482,
            "logloss": 0.6040845175671063,
            "mae": 0.4238586750956974,
            "precision": 0.9354838709677419,
            "recall": 0.30462184873949577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5856118610579004,
            "auditor_fn_violation": 0.04112530279674081,
            "auditor_fp_violation": 0.05263157894736844,
            "ave_precision_score": 0.5700056587907245,
            "fpr": 0.3530701754385965,
            "logloss": 0.9273514384677939,
            "mae": 0.46042018514861793,
            "precision": 0.5576923076923077,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6282270362484283,
            "auditor_fn_violation": 0.04109898624652934,
            "auditor_fp_violation": 0.054168086099650514,
            "ave_precision_score": 0.6005887550201996,
            "fpr": 0.3446761800219539,
            "logloss": 0.8746872996900196,
            "mae": 0.4454183394843804,
            "precision": 0.5656984785615491,
            "recall": 0.8592436974789915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8475073456280073,
            "auditor_fn_violation": 0.011141543712838582,
            "auditor_fp_violation": 0.01542161856253537,
            "ave_precision_score": 0.8414076761698797,
            "fpr": 0.14583333333333334,
            "logloss": 0.5089677858332109,
            "mae": 0.3087648959459143,
            "precision": 0.7490566037735849,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8432142122921846,
            "auditor_fn_violation": 0.010524956415057792,
            "auditor_fp_violation": 0.018168742193118592,
            "ave_precision_score": 0.8358416032133351,
            "fpr": 0.13721185510428102,
            "logloss": 0.5076160382886172,
            "mae": 0.310417081677531,
            "precision": 0.755859375,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7238050116744869,
            "auditor_fn_violation": 0.00961609043529326,
            "auditor_fp_violation": 0.004504709354030242,
            "ave_precision_score": 0.6878577892155717,
            "fpr": 0.09539473684210527,
            "logloss": 0.6313354116298078,
            "mae": 0.4468810010636062,
            "precision": 0.7716535433070866,
            "recall": 0.6150627615062761
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6906413973205533,
            "auditor_fn_violation": 0.016772131465099767,
            "auditor_fp_violation": 0.006634114336903997,
            "ave_precision_score": 0.6550138913694278,
            "fpr": 0.10647639956092206,
            "logloss": 0.6497714688978516,
            "mae": 0.4555003260938056,
            "precision": 0.739247311827957,
            "recall": 0.5777310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7592857032158911,
            "auditor_fn_violation": 0.01503431696395801,
            "auditor_fp_violation": 0.018428126768534246,
            "ave_precision_score": 0.7503960014634001,
            "fpr": 0.13157894736842105,
            "logloss": 1.3236521241035422,
            "mae": 0.29644126756517053,
            "precision": 0.75,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7946728336772725,
            "auditor_fn_violation": 0.018967521146768262,
            "auditor_fp_violation": 0.016775805291646167,
            "ave_precision_score": 0.7910998830175664,
            "fpr": 0.12184412733260154,
            "logloss": 1.0414907414193169,
            "mae": 0.29877606693360825,
            "precision": 0.756578947368421,
            "recall": 0.7247899159663865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.7366518995704312,
            "auditor_fn_violation": 0.007395581002716002,
            "auditor_fp_violation": 0.016429683078664405,
            "ave_precision_score": 0.7735133449320296,
            "fpr": 0.08442982456140351,
            "logloss": 0.5260166231155113,
            "mae": 0.3585384336234838,
            "precision": 0.819672131147541,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7971382409272644,
            "auditor_fn_violation": 0.01354592330895037,
            "auditor_fp_violation": 0.0062707394930416275,
            "ave_precision_score": 0.7852771035089492,
            "fpr": 0.08781558726673985,
            "logloss": 0.5425413787811872,
            "mae": 0.36789657641713364,
            "precision": 0.805352798053528,
            "recall": 0.6953781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 29756,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5199716020807089,
            "auditor_fn_violation": 0.0031977170960874983,
            "auditor_fp_violation": 0.00952987306977121,
            "ave_precision_score": 0.5135201500207809,
            "fpr": 0.2894736842105263,
            "logloss": 0.6954689410287024,
            "mae": 0.5004422313680774,
            "precision": 0.5065420560747663,
            "recall": 0.5669456066945606
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5127013425053809,
            "auditor_fn_violation": 0.016730621996328722,
            "auditor_fp_violation": 0.01739152377707962,
            "ave_precision_score": 0.5069179459611733,
            "fpr": 0.2843029637760702,
            "logloss": 0.695290890484663,
            "mae": 0.5003366597920951,
            "precision": 0.509469696969697,
            "recall": 0.5651260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7421286748296873,
            "auditor_fn_violation": 0.0026288262497247313,
            "auditor_fp_violation": 0.009876000485083681,
            "ave_precision_score": 0.7420575362690114,
            "fpr": 0.40460526315789475,
            "logloss": 0.7015635335479382,
            "mae": 0.43178081228152704,
            "precision": 0.555956678700361,
            "recall": 0.9665271966527197
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7583188399251319,
            "auditor_fn_violation": 0.0012914056950991157,
            "auditor_fp_violation": 0.011151065521026543,
            "ave_precision_score": 0.7589007204500875,
            "fpr": 0.40504939626783754,
            "logloss": 0.695451773645439,
            "mae": 0.4317875367422659,
            "precision": 0.555956678700361,
            "recall": 0.9705882352941176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6584847040389329,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6608202883939358,
            "fpr": 0.4758771929824561,
            "logloss": 5.498365589538213,
            "mae": 0.47587713311638746,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6109941354660159,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6142405972750155,
            "fpr": 0.4774972557628979,
            "logloss": 5.682025972313819,
            "mae": 0.47749734140777167,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 29756,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7335058945419156,
            "auditor_fn_violation": 0.011763194597372094,
            "auditor_fp_violation": 0.011273142533753744,
            "ave_precision_score": 0.7569213642621424,
            "fpr": 0.11403508771929824,
            "logloss": 0.6116292036606482,
            "mae": 0.3535334214107223,
            "precision": 0.7758620689655172,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.76256884308408,
            "auditor_fn_violation": 0.009088267579260026,
            "auditor_fp_violation": 0.00223324122790416,
            "ave_precision_score": 0.7705016011367026,
            "fpr": 0.09769484083424808,
            "logloss": 0.5852507810038937,
            "mae": 0.3535298785353892,
            "precision": 0.7939814814814815,
            "recall": 0.7205882352941176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7184755983002832,
            "auditor_fn_violation": 0.009593151288262498,
            "auditor_fp_violation": 0.024986862317083042,
            "ave_precision_score": 0.6776268379031207,
            "fpr": 0.41885964912280704,
            "logloss": 0.7148866973776619,
            "mae": 0.4288268944477303,
            "precision": 0.5463182897862233,
            "recall": 0.9623430962343096
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7139926743425908,
            "auditor_fn_violation": 0.007780719312972171,
            "auditor_fp_violation": 0.011363034179946253,
            "ave_precision_score": 0.6743199767349387,
            "fpr": 0.4149286498353458,
            "logloss": 0.7044816406273099,
            "mae": 0.42567029891435454,
            "precision": 0.55,
            "recall": 0.9705882352941176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8190454899703605,
            "auditor_fn_violation": 0.005877009469279903,
            "auditor_fp_violation": 0.012157409653165176,
            "ave_precision_score": 0.7514430181153896,
            "fpr": 0.09320175438596491,
            "logloss": 0.5308210275466047,
            "mae": 0.3597387684541836,
            "precision": 0.8076923076923077,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.79009215526047,
            "auditor_fn_violation": 0.004104825245136477,
            "auditor_fp_violation": 0.008915300856706668,
            "ave_precision_score": 0.7228486664311699,
            "fpr": 0.09110867178924259,
            "logloss": 0.5536250301133356,
            "mae": 0.3708914736884878,
            "precision": 0.8009592326139089,
            "recall": 0.7016806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7391172495540836,
            "auditor_fn_violation": 0.01388965352712325,
            "auditor_fp_violation": 0.015568154256609278,
            "ave_precision_score": 0.7061098366145588,
            "fpr": 0.15570175438596492,
            "logloss": 0.5954649233332209,
            "mae": 0.40647752187623265,
            "precision": 0.7010526315789474,
            "recall": 0.696652719665272
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7403796131082601,
            "auditor_fn_violation": 0.004372330710549863,
            "auditor_fp_violation": 0.01799714851685025,
            "ave_precision_score": 0.70646908712708,
            "fpr": 0.1437980241492865,
            "logloss": 0.5947165556613676,
            "mae": 0.40328059792845755,
            "precision": 0.7082405345211581,
            "recall": 0.6680672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7679273230268356,
            "auditor_fn_violation": 0.0006101813110181311,
            "auditor_fp_violation": 0.001538624787775897,
            "ave_precision_score": 0.5397391849317071,
            "fpr": 0.4725877192982456,
            "logloss": 15.803714425838647,
            "mae": 0.4737191290572522,
            "precision": 0.525330396475771,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7636401613490924,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0028994284416518435,
            "ave_precision_score": 0.5379522998223679,
            "fpr": 0.4676180021953897,
            "logloss": 15.620835725479884,
            "mae": 0.46775947522105155,
            "precision": 0.5277161862527716,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 29756,
        "test": {
            "accuracy": 0.8070175438596491,
            "auc_prc": 0.884200488977362,
            "auditor_fn_violation": 0.006427548998018058,
            "auditor_fp_violation": 0.008913412563667235,
            "ave_precision_score": 0.8737521299491459,
            "fpr": 0.08771929824561403,
            "logloss": 1.7093422956580313,
            "mae": 0.2000425458832491,
            "precision": 0.8268398268398268,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8789249288319381,
            "auditor_fn_violation": 0.012268354103441601,
            "auditor_fp_violation": 0.011963612046885452,
            "ave_precision_score": 0.8748081765247546,
            "fpr": 0.09769484083424808,
            "logloss": 1.7411884163479132,
            "mae": 0.22125820725680573,
            "precision": 0.8052516411378556,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7545053091734688,
            "auditor_fn_violation": 0.013281766130808191,
            "auditor_fp_violation": 0.040198783248443705,
            "ave_precision_score": 0.7548309256241813,
            "fpr": 0.2225877192982456,
            "logloss": 1.1148498232908237,
            "mae": 0.3891369759999625,
            "precision": 0.6219739292364991,
            "recall": 0.698744769874477
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7310779582033191,
            "auditor_fn_violation": 0.026510714055106126,
            "auditor_fp_violation": 0.03882306925571243,
            "ave_precision_score": 0.7315943480763636,
            "fpr": 0.21953896816684962,
            "logloss": 1.189790777551021,
            "mae": 0.3979071342054453,
            "precision": 0.6204933586337761,
            "recall": 0.6869747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8417370074030779,
            "auditor_fn_violation": 0.010818101739704914,
            "auditor_fp_violation": 0.007923033389926433,
            "ave_precision_score": 0.7427676958732466,
            "fpr": 0.08333333333333333,
            "logloss": 0.533537033417938,
            "mae": 0.3557165703621873,
            "precision": 0.8199052132701422,
            "recall": 0.7238493723849372
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8329366913485551,
            "auditor_fn_violation": 0.005880508075897764,
            "auditor_fp_violation": 0.008703332197786953,
            "ave_precision_score": 0.7350814482373479,
            "fpr": 0.07793633369923161,
            "logloss": 0.5471915231851531,
            "mae": 0.3625244518535459,
            "precision": 0.8211586901763224,
            "recall": 0.6848739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 29756,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7099487596176479,
            "auditor_fn_violation": 0.012226565367393387,
            "auditor_fp_violation": 0.008686029590104293,
            "ave_precision_score": 0.7103783191792854,
            "fpr": 0.043859649122807015,
            "logloss": 2.7405011808864232,
            "mae": 0.4226723580400412,
            "precision": 0.7989949748743719,
            "recall": 0.33263598326359833
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6911302489224721,
            "auditor_fn_violation": 0.014371500521174457,
            "auditor_fp_violation": 0.006820848631666605,
            "ave_precision_score": 0.6917295735764187,
            "fpr": 0.04610318331503842,
            "logloss": 3.043726914231536,
            "mae": 0.4312108897112573,
            "precision": 0.7835051546391752,
            "recall": 0.31932773109243695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6843536320919648,
            "auditor_fn_violation": 0.0007891066578580347,
            "auditor_fp_violation": 0.016164402942840987,
            "ave_precision_score": 0.6730540830780006,
            "fpr": 0.3607456140350877,
            "logloss": 2.0287312920876643,
            "mae": 0.3911092837774914,
            "precision": 0.5830164765525983,
            "recall": 0.9623430962343096
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6675215454138191,
            "auditor_fn_violation": 0.005986587829423756,
            "auditor_fp_violation": 0.011822299607605651,
            "ave_precision_score": 0.6555156787141504,
            "fpr": 0.3567508232711306,
            "logloss": 2.1089020002217485,
            "mae": 0.3901548698439532,
            "precision": 0.577373211963589,
            "recall": 0.9327731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.4803115325534178,
            "auditor_fn_violation": 0.0012455956837701132,
            "auditor_fp_violation": 0.004757357102433505,
            "ave_precision_score": 0.48241761212088297,
            "fpr": 0.047149122807017545,
            "logloss": 0.7473078869960998,
            "mae": 0.5027312734082603,
            "precision": 0.6090909090909091,
            "recall": 0.1401673640167364
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.4725933917215984,
            "auditor_fn_violation": 0.0064893136178730704,
            "auditor_fp_violation": 0.006790567394678074,
            "ave_precision_score": 0.47417131182123423,
            "fpr": 0.05598243688254665,
            "logloss": 0.7515956717443525,
            "mae": 0.5052008352740274,
            "precision": 0.5526315789473685,
            "recall": 0.1323529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7841991362114742,
            "auditor_fn_violation": 0.03974666006019232,
            "auditor_fp_violation": 0.05280843237125071,
            "ave_precision_score": 0.7851433387841112,
            "fpr": 0.2149122807017544,
            "logloss": 0.73747060783076,
            "mae": 0.3330110586752639,
            "precision": 0.672787979966611,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8124608240598865,
            "auditor_fn_violation": 0.04227739394330729,
            "auditor_fp_violation": 0.05223513380521596,
            "ave_precision_score": 0.8127905730501477,
            "fpr": 0.21514818880351264,
            "logloss": 0.7084939231158456,
            "mae": 0.33787489112973185,
            "precision": 0.6638078902229846,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8177012243521842,
            "auditor_fn_violation": 0.004665822506055936,
            "auditor_fp_violation": 0.007806815425660929,
            "ave_precision_score": 0.7819812420851813,
            "fpr": 0.05043859649122807,
            "logloss": 0.5668287386347114,
            "mae": 0.40031930934964566,
            "precision": 0.85625,
            "recall": 0.5732217573221757
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7870734356255378,
            "auditor_fn_violation": 0.012655775811971333,
            "auditor_fp_violation": 0.0025865223261036913,
            "ave_precision_score": 0.7519245295204522,
            "fpr": 0.06805708013172337,
            "logloss": 0.5959746273780263,
            "mae": 0.41818499709065476,
            "precision": 0.7947019867549668,
            "recall": 0.5042016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 29756,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5571699464027634,
            "auditor_fn_violation": 0.011304411656756958,
            "auditor_fp_violation": 0.009274698843883909,
            "ave_precision_score": 0.5312111457494261,
            "fpr": 0.22039473684210525,
            "logloss": 0.7077218502493577,
            "mae": 0.49936259283046974,
            "precision": 0.5325581395348837,
            "recall": 0.4790794979079498
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5634174938702513,
            "auditor_fn_violation": 0.014140892361335332,
            "auditor_fp_violation": 0.007658629521682629,
            "ave_precision_score": 0.5306793695209115,
            "fpr": 0.2261251372118551,
            "logloss": 0.7055717886924971,
            "mae": 0.49801905310899836,
            "precision": 0.5339366515837104,
            "recall": 0.4957983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8308939644274808,
            "auditor_fn_violation": 0.008370494751523162,
            "auditor_fp_violation": 0.010030115611609674,
            "ave_precision_score": 0.8253175155220057,
            "fpr": 0.14692982456140352,
            "logloss": 0.5429132967874742,
            "mae": 0.35785204004251253,
            "precision": 0.7428023032629558,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8348338675499128,
            "auditor_fn_violation": 0.008530195832449336,
            "auditor_fp_violation": 0.009271105391321907,
            "ave_precision_score": 0.8274511384352041,
            "fpr": 0.13391877058177826,
            "logloss": 0.5422045667545915,
            "mae": 0.36256081998986156,
            "precision": 0.7515274949083504,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.5731842499258976,
            "auditor_fn_violation": 0.011322762974381567,
            "auditor_fp_violation": 0.018349805966529232,
            "ave_precision_score": 0.7459608659604986,
            "fpr": 0.17214912280701755,
            "logloss": 0.590888746514045,
            "mae": 0.406100696099824,
            "precision": 0.689108910891089,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7861827878340568,
            "auditor_fn_violation": 0.013292254333127324,
            "auditor_fp_violation": 0.02097985036022055,
            "ave_precision_score": 0.7186976951140092,
            "fpr": 0.16355653128430298,
            "logloss": 0.6090388877220502,
            "mae": 0.4127513172205141,
            "precision": 0.6908713692946058,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 29756,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8559032098607486,
            "auditor_fn_violation": 0.01840637157747927,
            "auditor_fp_violation": 0.0030545112781954894,
            "ave_precision_score": 0.8562343887330469,
            "fpr": 0.03399122807017544,
            "logloss": 0.6064441392031378,
            "mae": 0.32248866686795574,
            "precision": 0.8949152542372881,
            "recall": 0.5523012552301255
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8357371144069247,
            "auditor_fn_violation": 0.018718464334142013,
            "auditor_fp_violation": 0.008720996252696922,
            "ave_precision_score": 0.836166939783082,
            "fpr": 0.04061470911086718,
            "logloss": 0.6467013467216596,
            "mae": 0.3376759175417186,
            "precision": 0.8706293706293706,
            "recall": 0.523109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6107593432432973,
            "auditor_fn_violation": 0.010327203993246716,
            "auditor_fp_violation": 0.025603322823187002,
            "ave_precision_score": 0.5583835716189723,
            "fpr": 0.3881578947368421,
            "logloss": 0.6885642650998808,
            "mae": 0.48867088736018593,
            "precision": 0.5524652338811631,
            "recall": 0.9142259414225942
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.5985225067612342,
            "auditor_fn_violation": 0.01045116180390927,
            "auditor_fp_violation": 0.01649065697667084,
            "ave_precision_score": 0.568122460271312,
            "fpr": 0.3732162458836443,
            "logloss": 0.6848859614917006,
            "mae": 0.4870825060505244,
            "precision": 0.5641025641025641,
            "recall": 0.9243697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 29756,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.5370731163906748,
            "auditor_fn_violation": 0.00925823974161345,
            "auditor_fp_violation": 0.035049822135985134,
            "ave_precision_score": 0.5390208576035896,
            "fpr": 0.30153508771929827,
            "logloss": 0.6688394461652138,
            "mae": 0.4809519612115988,
            "precision": 0.5991253644314869,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.5572173424758444,
            "auditor_fn_violation": 0.010679463882150008,
            "auditor_fp_violation": 0.039933381278625245,
            "ave_precision_score": 0.5607759851590457,
            "fpr": 0.27991218441273324,
            "logloss": 0.6732089026797574,
            "mae": 0.4786032556048078,
            "precision": 0.6238938053097345,
            "recall": 0.8886554621848739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.751275279706491,
            "auditor_fn_violation": 0.008347555604492404,
            "auditor_fp_violation": 0.006957918991025954,
            "ave_precision_score": 0.5328103930475574,
            "fpr": 0.42872807017543857,
            "logloss": 0.691076161373681,
            "mae": 0.49865161771314187,
            "precision": 0.5334128878281623,
            "recall": 0.9351464435146444
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7501069064620235,
            "auditor_fn_violation": 0.004778201071866726,
            "auditor_fp_violation": 0.009059136732402185,
            "ave_precision_score": 0.5279607607597852,
            "fpr": 0.43907793633369924,
            "logloss": 0.6916119948137204,
            "mae": 0.49892149857448825,
            "precision": 0.5283018867924528,
            "recall": 0.9411764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8391847606064343,
            "auditor_fn_violation": 0.006457369889158037,
            "auditor_fp_violation": 0.00792303338992643,
            "ave_precision_score": 0.8388576142498633,
            "fpr": 0.05043859649122807,
            "logloss": 1.776604568257995,
            "mae": 0.3208193219361187,
            "precision": 0.8658892128279884,
            "recall": 0.6213389121338913
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8416182137595131,
            "auditor_fn_violation": 0.013633554409689233,
            "auditor_fp_violation": 0.008965769585020883,
            "ave_precision_score": 0.8411742769734043,
            "fpr": 0.050493962678375415,
            "logloss": 1.7276866890000764,
            "mae": 0.33148529435465574,
            "precision": 0.8571428571428571,
            "recall": 0.5798319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8221396327975051,
            "auditor_fn_violation": 0.013226712177934382,
            "auditor_fp_violation": 0.007076663432775492,
            "ave_precision_score": 0.8227354757866752,
            "fpr": 0.0756578947368421,
            "logloss": 0.5012713996061294,
            "mae": 0.34283090410590694,
            "precision": 0.8345323741007195,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7872687152671116,
            "auditor_fn_violation": 0.008094346410353384,
            "auditor_fp_violation": 0.0032855142132556174,
            "ave_precision_score": 0.7879286452450502,
            "fpr": 0.07574094401756312,
            "logloss": 0.541714530333913,
            "mae": 0.3594260906675906,
            "precision": 0.8221649484536082,
            "recall": 0.6701680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 29756,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.8158934262061017,
            "auditor_fn_violation": 0.000610181311018149,
            "auditor_fp_violation": 0.0015386247877758913,
            "ave_precision_score": 0.817578039069388,
            "fpr": 0.003289473684210526,
            "logloss": 5.809727908248899,
            "mae": 0.5259583536000213,
            "precision": 0.25,
            "recall": 0.0020920502092050207
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.7530842454662604,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0028994284416518413,
            "ave_precision_score": 0.754464993342478,
            "fpr": 0.009879253567508232,
            "logloss": 5.891586868859031,
            "mae": 0.5306908310180379,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8174492415066799,
            "auditor_fn_violation": 0.004842453938192765,
            "auditor_fp_violation": 0.014603039857708798,
            "ave_precision_score": 0.812960671252694,
            "fpr": 0.20285087719298245,
            "logloss": 0.5219735762033302,
            "mae": 0.32234106863963236,
            "precision": 0.6947194719471947,
            "recall": 0.8807531380753139
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8254726799998575,
            "auditor_fn_violation": 0.006802940715254273,
            "auditor_fp_violation": 0.015685680760059047,
            "ave_precision_score": 0.815951914052412,
            "fpr": 0.18331503841931943,
            "logloss": 0.5250093009687493,
            "mae": 0.3230788983551849,
            "precision": 0.7090592334494773,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 29756,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8337091826744292,
            "auditor_fn_violation": 0.014621412317404396,
            "auditor_fp_violation": 0.0030166141159350015,
            "ave_precision_score": 0.8273697090201872,
            "fpr": 0.043859649122807015,
            "logloss": 0.5410781122708854,
            "mae": 0.36948919678597075,
            "precision": 0.8765432098765432,
            "recall": 0.5941422594142259
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8186739011010111,
            "auditor_fn_violation": 0.012858710992629767,
            "auditor_fp_violation": 0.004259560669720022,
            "ave_precision_score": 0.8118071980232924,
            "fpr": 0.05378704720087816,
            "logloss": 0.5611844069627354,
            "mae": 0.38360653367838143,
            "precision": 0.839344262295082,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8497307588544819,
            "auditor_fn_violation": 0.0159220619540483,
            "auditor_fp_violation": 0.01823611447974776,
            "ave_precision_score": 0.8438795433195992,
            "fpr": 0.16557017543859648,
            "logloss": 0.5237194946302803,
            "mae": 0.3266040888643546,
            "precision": 0.7264492753623188,
            "recall": 0.8389121338912134
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8452718097706861,
            "auditor_fn_violation": 0.013942569343873671,
            "auditor_fp_violation": 0.02146435015203705,
            "ave_precision_score": 0.8353144980372853,
            "fpr": 0.1437980241492865,
            "logloss": 0.5168488597151819,
            "mae": 0.32608709013668163,
            "precision": 0.7446393762183235,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5752739714191669,
            "auditor_fn_violation": 0.0069276224032885575,
            "auditor_fp_violation": 0.011035653650254669,
            "ave_precision_score": 0.5795077365264787,
            "fpr": 0.43201754385964913,
            "logloss": 0.7107191462724906,
            "mae": 0.48065829401214916,
            "precision": 0.5391812865497077,
            "recall": 0.9644351464435147
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.5879091602497262,
            "auditor_fn_violation": 0.004529144259240469,
            "auditor_fp_violation": 0.0037498265137464355,
            "ave_precision_score": 0.5937172785320071,
            "fpr": 0.42371020856201974,
            "logloss": 0.7024381628957205,
            "mae": 0.4770741229130591,
            "precision": 0.5437352245862884,
            "recall": 0.9663865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8025099449608867,
            "auditor_fn_violation": 0.008524187036629237,
            "auditor_fp_violation": 0.017392271000080856,
            "ave_precision_score": 0.803993520243342,
            "fpr": 0.125,
            "logloss": 0.5487347004044671,
            "mae": 0.3650688871479871,
            "precision": 0.75054704595186,
            "recall": 0.7175732217573222
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7783542621217828,
            "auditor_fn_violation": 0.008115101144738918,
            "auditor_fp_violation": 0.02583494202404835,
            "ave_precision_score": 0.7793464060322789,
            "fpr": 0.11306256860592755,
            "logloss": 0.5762242212437095,
            "mae": 0.37619893763185724,
            "precision": 0.7582159624413145,
            "recall": 0.6785714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6490675118055171,
            "auditor_fn_violation": 0.011024554062981721,
            "auditor_fp_violation": 0.017387218045112802,
            "ave_precision_score": 0.6525946962365003,
            "fpr": 0.3508771929824561,
            "logloss": 0.7043697874093706,
            "mae": 0.43430000302185745,
            "precision": 0.5800524934383202,
            "recall": 0.9246861924686193
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.6712250533236886,
            "auditor_fn_violation": 0.004187844182678562,
            "auditor_fp_violation": 0.024386489521430292,
            "ave_precision_score": 0.6795903505614541,
            "fpr": 0.32821075740944017,
            "logloss": 0.6855296150148172,
            "mae": 0.4243528159738045,
            "precision": 0.5931972789115646,
            "recall": 0.9159663865546218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6749698879742916,
            "auditor_fn_violation": 0.02428796887616531,
            "auditor_fp_violation": 0.026533066537311027,
            "ave_precision_score": 0.7021733632295035,
            "fpr": 0.22916666666666666,
            "logloss": 0.9737846239999879,
            "mae": 0.3849892989657802,
            "precision": 0.6427350427350428,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.664130874179415,
            "auditor_fn_violation": 0.031044470477543377,
            "auditor_fp_violation": 0.027041144630758174,
            "ave_precision_score": 0.6846319951709787,
            "fpr": 0.2283205268935236,
            "logloss": 1.0963161780796218,
            "mae": 0.39205601016267827,
            "precision": 0.6395147313691508,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8430546196829961,
            "auditor_fn_violation": 0.00868476106584453,
            "auditor_fp_violation": 0.007281308108982134,
            "ave_precision_score": 0.8433479725494679,
            "fpr": 0.17324561403508773,
            "logloss": 0.5451498605783512,
            "mae": 0.3797160024660754,
            "precision": 0.7063197026022305,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8200451785988709,
            "auditor_fn_violation": 0.006143401378114365,
            "auditor_fp_violation": 0.0065861690450054935,
            "ave_precision_score": 0.8204129845676325,
            "fpr": 0.15916575192096596,
            "logloss": 0.5520368566534944,
            "mae": 0.38414572128202074,
            "precision": 0.7238095238095238,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7591261467949505,
            "auditor_fn_violation": 0.002133340673860383,
            "auditor_fp_violation": 0.0016523162745573673,
            "ave_precision_score": 0.5232394265554284,
            "fpr": 0.4725877192982456,
            "logloss": 0.6960833621268189,
            "mae": 0.5000735245187554,
            "precision": 0.5232300884955752,
            "recall": 0.9895397489539749
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7605862584782097,
            "auditor_fn_violation": 0.0010100637400953796,
            "auditor_fp_violation": 0.0017865929823233314,
            "ave_precision_score": 0.5231759673431966,
            "fpr": 0.47420417124039516,
            "logloss": 0.6928350151188921,
            "mae": 0.49904033082049715,
            "precision": 0.5231788079470199,
            "recall": 0.9957983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7265785642687207,
            "auditor_fn_violation": 0.011423695221316896,
            "auditor_fp_violation": 0.019357870482658263,
            "ave_precision_score": 0.7243661964897787,
            "fpr": 0.14802631578947367,
            "logloss": 1.1612160581884627,
            "mae": 0.3733673178378427,
            "precision": 0.7019867549668874,
            "recall": 0.6652719665271967
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7666506050909929,
            "auditor_fn_violation": 0.017821398592367803,
            "auditor_fp_violation": 0.016028868112595743,
            "ave_precision_score": 0.7641127421867029,
            "fpr": 0.13391877058177826,
            "logloss": 1.0271406109126582,
            "mae": 0.36870426952053764,
            "precision": 0.7162790697674418,
            "recall": 0.6470588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8304371196022987,
            "auditor_fn_violation": 0.030823331865227923,
            "auditor_fp_violation": 0.0340265987549519,
            "ave_precision_score": 0.8399782685967447,
            "fpr": 0.14692982456140352,
            "logloss": 0.49632569456463865,
            "mae": 0.33485927794684184,
            "precision": 0.7428023032629558,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.803431719320203,
            "auditor_fn_violation": 0.03135348541172781,
            "auditor_fp_violation": 0.030758166471100346,
            "ave_precision_score": 0.8142250050259299,
            "fpr": 0.13611416026344675,
            "logloss": 0.5244757589045977,
            "mae": 0.3455521895761809,
            "precision": 0.746938775510204,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6764384617249802,
            "auditor_fn_violation": 0.0035418043015488683,
            "auditor_fp_violation": 0.008044304309159998,
            "ave_precision_score": 0.6510532684565429,
            "fpr": 0.06359649122807018,
            "logloss": 0.6620740649088898,
            "mae": 0.45326570478643763,
            "precision": 0.7314814814814815,
            "recall": 0.3305439330543933
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6596598964750505,
            "auditor_fn_violation": 0.0025297715134352332,
            "auditor_fp_violation": 0.004158623213091592,
            "ave_precision_score": 0.6288677470495551,
            "fpr": 0.06476399560922064,
            "logloss": 0.68383144460213,
            "mae": 0.4617128899049026,
            "precision": 0.6989795918367347,
            "recall": 0.28781512605042014
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8617615648994175,
            "auditor_fn_violation": 0.0099234750055054,
            "auditor_fp_violation": 0.011750646778235915,
            "ave_precision_score": 0.8622210828256971,
            "fpr": 0.12828947368421054,
            "logloss": 0.7563401058231671,
            "mae": 0.24152371648075588,
            "precision": 0.7754318618042226,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8594800823247774,
            "auditor_fn_violation": 0.014396867418756752,
            "auditor_fp_violation": 0.012826627301058581,
            "ave_precision_score": 0.8596548504928458,
            "fpr": 0.13611416026344675,
            "logloss": 0.9370909894457922,
            "mae": 0.26641366822730506,
            "precision": 0.7524950099800399,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6075010137470878,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.598868227801211,
            "fpr": 0.4758771929824561,
            "logloss": 2.6171487060828023,
            "mae": 0.47207361583908397,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5681227220827739,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5590751098407898,
            "fpr": 0.4774972557628979,
            "logloss": 2.9479597395083346,
            "mae": 0.4752546756903505,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.8443593437493391,
            "auditor_fn_violation": 0.003257358878367467,
            "auditor_fp_violation": 0.010141280620907125,
            "ave_precision_score": 0.8447309696515537,
            "fpr": 0.43201754385964913,
            "logloss": 0.8560781376166277,
            "mae": 0.40265112283962307,
            "precision": 0.5439814814814815,
            "recall": 0.9832635983263598
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.8286724628711646,
            "auditor_fn_violation": 0.0015911963028899816,
            "auditor_fp_violation": 0.013841048740174382,
            "ave_precision_score": 0.8293649328098864,
            "fpr": 0.42590559824368823,
            "logloss": 0.8228034233722262,
            "mae": 0.3961701659755587,
            "precision": 0.5493612078977933,
            "recall": 0.9936974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5477312390429683,
            "auditor_fn_violation": 0.0006124752257212233,
            "auditor_fp_violation": 0.0020514997170345216,
            "ave_precision_score": 0.549452443459337,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7270743498194979,
            "mae": 0.5034295945477328,
            "precision": 0.2,
            "recall": 0.0020920502092050207
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.5293936265548058,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0008781558726673985,
            "ave_precision_score": 0.530960798016227,
            "fpr": 0.006586169045005488,
            "logloss": 0.7274469298651614,
            "mae": 0.5032294740661177,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7626964888134009,
            "auditor_fn_violation": 0.01613768993613741,
            "auditor_fp_violation": 0.02843803056027165,
            "ave_precision_score": 0.76328102127157,
            "fpr": 0.13815789473684212,
            "logloss": 1.2060097219224848,
            "mae": 0.32322283446495115,
            "precision": 0.7181208053691275,
            "recall": 0.6715481171548117
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7748223869268698,
            "auditor_fn_violation": 0.020528738388879163,
            "auditor_fp_violation": 0.02832052689352361,
            "ave_precision_score": 0.7751576129644435,
            "fpr": 0.12733260153677278,
            "logloss": 1.210256261962546,
            "mae": 0.3193701116110894,
            "precision": 0.7257683215130024,
            "recall": 0.6449579831932774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.674966532042732,
            "auditor_fn_violation": 0.023533270938853417,
            "auditor_fp_violation": 0.01833212062414101,
            "ave_precision_score": 0.6131568638957681,
            "fpr": 0.17324561403508773,
            "logloss": 0.6565935461423744,
            "mae": 0.44207293318029034,
            "precision": 0.6659619450317125,
            "recall": 0.6589958158995816
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7078535083755938,
            "auditor_fn_violation": 0.01811657703696188,
            "auditor_fp_violation": 0.011077885864970915,
            "ave_precision_score": 0.6471441873508897,
            "fpr": 0.15367727771679474,
            "logloss": 0.6237619959946713,
            "mae": 0.4277218887429075,
            "precision": 0.7021276595744681,
            "recall": 0.6932773109243697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.557116711563947,
            "auditor_fn_violation": 0.032229501578213325,
            "auditor_fp_violation": 0.024132912927479995,
            "ave_precision_score": 0.5575379420477229,
            "fpr": 0.08114035087719298,
            "logloss": 2.1785061260315834,
            "mae": 0.4901447209668113,
            "precision": 0.5697674418604651,
            "recall": 0.20502092050209206
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.5749148675078398,
            "auditor_fn_violation": 0.04205370402826334,
            "auditor_fp_violation": 0.026599543258008757,
            "ave_precision_score": 0.5763889047403321,
            "fpr": 0.07464324917672886,
            "logloss": 2.069191984096658,
            "mae": 0.4788337714678397,
            "precision": 0.6324324324324324,
            "recall": 0.24579831932773108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6253069482713847,
            "auditor_fn_violation": 0.00463370770021288,
            "auditor_fp_violation": 0.013349907025628592,
            "ave_precision_score": 0.5953160057977139,
            "fpr": 0.09649122807017543,
            "logloss": 0.9554666552787552,
            "mae": 0.4839343394218176,
            "precision": 0.6053811659192825,
            "recall": 0.2824267782426778
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6280183237699264,
            "auditor_fn_violation": 0.015296239242129361,
            "auditor_fp_violation": 0.015859797872743105,
            "ave_precision_score": 0.5964810860416937,
            "fpr": 0.09220636663007684,
            "logloss": 0.9449138032296763,
            "mae": 0.4808746145600627,
            "precision": 0.6233183856502242,
            "recall": 0.2920168067226891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.853410898158834,
            "auditor_fn_violation": 0.006698230932980989,
            "auditor_fp_violation": 0.014254385964912285,
            "ave_precision_score": 0.853734958138694,
            "fpr": 0.10307017543859649,
            "logloss": 0.4876393605140405,
            "mae": 0.326223140384332,
            "precision": 0.7947598253275109,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8392000343903874,
            "auditor_fn_violation": 0.007070446180667657,
            "auditor_fp_violation": 0.005791286574056553,
            "ave_precision_score": 0.8394848680942149,
            "fpr": 0.09879253567508232,
            "logloss": 0.5158049904984365,
            "mae": 0.34347537848137477,
            "precision": 0.7911832946635731,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.785330343285996,
            "auditor_fn_violation": 0.012935385010643766,
            "auditor_fp_violation": 0.024405772495755523,
            "ave_precision_score": 0.7858777610362626,
            "fpr": 0.16885964912280702,
            "logloss": 0.6118957733526307,
            "mae": 0.3213123941401902,
            "precision": 0.7132216014897579,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8106008097166328,
            "auditor_fn_violation": 0.016806722689075633,
            "auditor_fp_violation": 0.023909560038860918,
            "ave_precision_score": 0.8109782552661723,
            "fpr": 0.17014270032930845,
            "logloss": 0.6075042645316613,
            "mae": 0.3275201203287237,
            "precision": 0.7001934235976789,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6584375019113422,
            "auditor_fn_violation": 0.004385964912280714,
            "auditor_fp_violation": 0.018478656318214895,
            "ave_precision_score": 0.6560928161919221,
            "fpr": 0.08991228070175439,
            "logloss": 8.225485059075442,
            "mae": 0.4485960901296617,
            "precision": 0.672,
            "recall": 0.3514644351464435
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.64080021836021,
            "auditor_fn_violation": 0.006295602763608206,
            "auditor_fp_violation": 0.010156831573236434,
            "ave_precision_score": 0.6397999144656248,
            "fpr": 0.08781558726673985,
            "logloss": 8.149151414488195,
            "mae": 0.4432703419682731,
            "precision": 0.6862745098039216,
            "recall": 0.36764705882352944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7916136088067033,
            "auditor_fn_violation": 0.011875596417822811,
            "auditor_fp_violation": 0.007352049478535047,
            "ave_precision_score": 0.7482706621646735,
            "fpr": 0.03728070175438596,
            "logloss": 0.5609625457253233,
            "mae": 0.3895582866675237,
            "precision": 0.8823529411764706,
            "recall": 0.5334728033472803
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7797580616318072,
            "auditor_fn_violation": 0.010349694213580054,
            "auditor_fp_violation": 0.006101669253188993,
            "ave_precision_score": 0.7354824017390365,
            "fpr": 0.03951701427003293,
            "logloss": 0.5692952628036231,
            "mae": 0.39382005845218016,
            "precision": 0.8745644599303136,
            "recall": 0.5273109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5624685805356568,
            "auditor_fn_violation": 0.03817074065917933,
            "auditor_fp_violation": 0.03723522515967338,
            "ave_precision_score": 0.5639964581634951,
            "fpr": 0.27521929824561403,
            "logloss": 0.7221563269149986,
            "mae": 0.4861568012356497,
            "precision": 0.5672413793103448,
            "recall": 0.6882845188284519
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.5622689639790812,
            "auditor_fn_violation": 0.04320905090905737,
            "auditor_fp_violation": 0.0384924990852543,
            "ave_precision_score": 0.5640628621964631,
            "fpr": 0.25466520307354557,
            "logloss": 0.7225716637015736,
            "mae": 0.4807648808745469,
            "precision": 0.6047700170357752,
            "recall": 0.7457983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6658457906422409,
            "auditor_fn_violation": 0.011932944285399693,
            "auditor_fp_violation": 0.019443770717115373,
            "ave_precision_score": 0.6790515883434785,
            "fpr": 0.18311403508771928,
            "logloss": 0.6392424775195025,
            "mae": 0.4145799895212118,
            "precision": 0.6763565891472868,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6878334500622928,
            "auditor_fn_violation": 0.013688900368050627,
            "auditor_fp_violation": 0.01838071085203831,
            "ave_precision_score": 0.6752939587238678,
            "fpr": 0.16794731064763996,
            "logloss": 0.632135872275826,
            "mae": 0.4137463235904838,
            "precision": 0.6845360824742268,
            "recall": 0.6974789915966386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6670117742590302,
            "auditor_fn_violation": 0.03190605960507967,
            "auditor_fp_violation": 0.038746058695124916,
            "ave_precision_score": 0.629074195977547,
            "fpr": 0.1118421052631579,
            "logloss": 3.998035757030133,
            "mae": 0.3995740951824446,
            "precision": 0.6955223880597015,
            "recall": 0.4874476987447699
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6654249009272828,
            "auditor_fn_violation": 0.037690597644107045,
            "auditor_fp_violation": 0.04022357646643199,
            "ave_precision_score": 0.6245425821604693,
            "fpr": 0.11745334796926454,
            "logloss": 4.198355444303323,
            "mae": 0.4109636821938374,
            "precision": 0.664576802507837,
            "recall": 0.44537815126050423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.5480299137210127,
            "auditor_fn_violation": 0.011065844527637083,
            "auditor_fp_violation": 0.009956847764572726,
            "ave_precision_score": 0.5499141157504545,
            "fpr": 0.28618421052631576,
            "logloss": 0.7827636612469546,
            "mae": 0.49724529870220907,
            "precision": 0.5339285714285714,
            "recall": 0.6255230125523012
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5796214135629877,
            "auditor_fn_violation": 0.01791364185630345,
            "auditor_fp_violation": 0.00811032464009489,
            "ave_precision_score": 0.58151456154181,
            "fpr": 0.28210757409440174,
            "logloss": 0.7544430492784634,
            "mae": 0.49345736622462266,
            "precision": 0.5352622061482821,
            "recall": 0.6218487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7983075935980254,
            "auditor_fn_violation": 0.01381854217132791,
            "auditor_fp_violation": 0.007872503840245775,
            "ave_precision_score": 0.7787428621538164,
            "fpr": 0.03508771929824561,
            "logloss": 0.6469891935637088,
            "mae": 0.4069302227621767,
            "precision": 0.8415841584158416,
            "recall": 0.35564853556485354
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7396794793497786,
            "auditor_fn_violation": 0.001780294993958076,
            "auditor_fp_violation": 0.002674842600653569,
            "ave_precision_score": 0.7248829806192414,
            "fpr": 0.04500548847420417,
            "logloss": 0.6770120735909538,
            "mae": 0.4195077671136801,
            "precision": 0.7657142857142857,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8326919125628631,
            "auditor_fn_violation": 0.009680320046979374,
            "auditor_fp_violation": 0.016358941709111494,
            "ave_precision_score": 0.834194479365572,
            "fpr": 0.1611842105263158,
            "logloss": 0.5179900387294194,
            "mae": 0.3347388093559921,
            "precision": 0.7370304114490162,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8452088693624238,
            "auditor_fn_violation": 0.015303157486924523,
            "auditor_fp_violation": 0.021580428227159745,
            "ave_precision_score": 0.8454511267047284,
            "fpr": 0.1525795828759605,
            "logloss": 0.5164258665436917,
            "mae": 0.3441976420156764,
            "precision": 0.7382297551789078,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.8103253864444562,
            "auditor_fn_violation": 0.00397306026572708,
            "auditor_fp_violation": 0.005654256609265095,
            "ave_precision_score": 0.7578035513211486,
            "fpr": 0.3519736842105263,
            "logloss": 0.7081656963338799,
            "mae": 0.43099859814371977,
            "precision": 0.5831168831168831,
            "recall": 0.9393305439330544
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7973308494462954,
            "auditor_fn_violation": 0.01023439013366049,
            "auditor_fp_violation": 0.012251283798276502,
            "ave_precision_score": 0.742995455052784,
            "fpr": 0.3512623490669594,
            "logloss": 0.7109133270393216,
            "mae": 0.43546210846052996,
            "precision": 0.5816993464052288,
            "recall": 0.9348739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6524090093435048,
            "auditor_fn_violation": 0.008799456800998313,
            "auditor_fp_violation": 0.025810493976877683,
            "ave_precision_score": 0.6550879150302135,
            "fpr": 0.3168859649122807,
            "logloss": 0.7762283182428947,
            "mae": 0.40302605231070693,
            "precision": 0.6024759284731774,
            "recall": 0.9163179916317992
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6340273416167538,
            "auditor_fn_violation": 0.01488806279921409,
            "auditor_fp_violation": 0.007418903062190108,
            "ave_precision_score": 0.6469814926960945,
            "fpr": 0.33260153677277715,
            "logloss": 0.810053014455906,
            "mae": 0.4113191655766971,
            "precision": 0.5877551020408164,
            "recall": 0.907563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8512644936264337,
            "auditor_fn_violation": 0.0066798796153563844,
            "auditor_fp_violation": 0.013930996846956109,
            "ave_precision_score": 0.8516005148775109,
            "fpr": 0.16666666666666666,
            "logloss": 0.5537386807734576,
            "mae": 0.2864158290372998,
            "precision": 0.7190388170055453,
            "recall": 0.8138075313807531
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8475244877420158,
            "auditor_fn_violation": 0.014279257257238791,
            "auditor_fp_violation": 0.024290598937633273,
            "ave_precision_score": 0.8477408906189583,
            "fpr": 0.16575192096597147,
            "logloss": 0.5917545023041387,
            "mae": 0.30330368173620476,
            "precision": 0.7079303675048356,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6135834725611927,
            "auditor_fn_violation": 0.003615209572047277,
            "auditor_fp_violation": 0.014019423558897246,
            "ave_precision_score": 0.6152971885742446,
            "fpr": 0.11732456140350878,
            "logloss": 4.571985659278873,
            "mae": 0.431846910732588,
            "precision": 0.6491803278688525,
            "recall": 0.41422594142259417
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5933608467335838,
            "auditor_fn_violation": 0.015510704830779747,
            "auditor_fp_violation": 0.021868099978550794,
            "ave_precision_score": 0.5942882632805883,
            "fpr": 0.1141602634467618,
            "logloss": 5.1076145952234215,
            "mae": 0.44137729314494106,
            "precision": 0.6474576271186441,
            "recall": 0.4012605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.680882566600369,
            "auditor_fn_violation": 0.006422961168611909,
            "auditor_fp_violation": 0.032333858840650015,
            "ave_precision_score": 0.6827340175578449,
            "fpr": 0.27850877192982454,
            "logloss": 1.5116005242926702,
            "mae": 0.3315400992652172,
            "precision": 0.6281112737920937,
            "recall": 0.897489539748954
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7083528876733619,
            "auditor_fn_violation": 0.00790755380088369,
            "auditor_fp_violation": 0.033791337042784884,
            "ave_precision_score": 0.7093179113685728,
            "fpr": 0.2711306256860593,
            "logloss": 1.421289587881217,
            "mae": 0.32173033163265674,
            "precision": 0.6367647058823529,
            "recall": 0.9096638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8411527886074341,
            "auditor_fn_violation": 0.003567037363282692,
            "auditor_fp_violation": 0.015512571751960549,
            "ave_precision_score": 0.7947168236580979,
            "fpr": 0.08114035087719298,
            "logloss": 0.5204523280487505,
            "mae": 0.35120295981566113,
            "precision": 0.8266978922716628,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8182997592471425,
            "auditor_fn_violation": 0.007361012462064964,
            "auditor_fp_violation": 0.006682059628802506,
            "ave_precision_score": 0.7718277411160446,
            "fpr": 0.0801317233809001,
            "logloss": 0.5379623531714608,
            "mae": 0.36124994330165416,
            "precision": 0.8179551122194514,
            "recall": 0.6890756302521008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7433996332033503,
            "auditor_fn_violation": 0.011758606767965942,
            "auditor_fp_violation": 0.018349805966529232,
            "ave_precision_score": 0.649895080579843,
            "fpr": 0.17214912280701755,
            "logloss": 0.6258821023870701,
            "mae": 0.42582952843472494,
            "precision": 0.6897233201581028,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7316969657538281,
            "auditor_fn_violation": 0.01578282245938991,
            "auditor_fp_violation": 0.02079816293828937,
            "ave_precision_score": 0.6396769505075228,
            "fpr": 0.1668496158068057,
            "logloss": 0.6230408206519124,
            "mae": 0.4252944411801912,
            "precision": 0.689795918367347,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7165980445935308,
            "auditor_fn_violation": 0.005243889011231015,
            "auditor_fp_violation": 0.0020211819872261306,
            "ave_precision_score": 0.7024202086320112,
            "fpr": 0.0043859649122807015,
            "logloss": 0.8238013189212854,
            "mae": 0.4516416850075412,
            "precision": 0.9183673469387755,
            "recall": 0.09414225941422594
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7265219030546299,
            "auditor_fn_violation": 0.0033438183176673613,
            "auditor_fp_violation": 0.0006737575229948143,
            "ave_precision_score": 0.7119976575591354,
            "fpr": 0.003293084522502744,
            "logloss": 0.8181928139669269,
            "mae": 0.4506435774369338,
            "precision": 0.9166666666666666,
            "recall": 0.06932773109243698
        }
    }
]