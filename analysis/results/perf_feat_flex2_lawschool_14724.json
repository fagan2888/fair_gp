[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8452678647875057,
            "auditor_fn_violation": 0.032240415192768074,
            "auditor_fp_violation": 0.018747135058548983,
            "ave_precision_score": 0.8455350552583858,
            "fpr": 0.09978070175438597,
            "logloss": 1.3054408247239242,
            "mae": 0.2731120655415353,
            "precision": 0.7945823927765236,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7998206561656414,
            "auditor_fn_violation": 0.022546604614111662,
            "auditor_fp_violation": 0.028738533009252006,
            "ave_precision_score": 0.8005169725792982,
            "fpr": 0.12843029637760703,
            "logloss": 1.3977629894134225,
            "mae": 0.2931290797072589,
            "precision": 0.7422907488986784,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8103934635022491,
            "auditor_fn_violation": 0.018403633829992497,
            "auditor_fp_violation": 0.018114243447097556,
            "ave_precision_score": 0.8089649513706054,
            "fpr": 0.15021929824561403,
            "logloss": 0.7470447130367454,
            "mae": 0.27750969340535364,
            "precision": 0.7481617647058824,
            "recall": 0.8289205702647657
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7881318475881609,
            "auditor_fn_violation": 0.007954138641466314,
            "auditor_fp_violation": 0.020718990120746437,
            "ave_precision_score": 0.7872106967163155,
            "fpr": 0.1734357848518112,
            "logloss": 0.8069037805715141,
            "mae": 0.28502410565460484,
            "precision": 0.7057728119180633,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.842813193805455,
            "auditor_fn_violation": 0.010906849608746922,
            "auditor_fp_violation": 0.023234675167729306,
            "ave_precision_score": 0.843051333412089,
            "fpr": 0.16447368421052633,
            "logloss": 0.7943500946348602,
            "mae": 0.2805377569366501,
            "precision": 0.7282608695652174,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7898218212456292,
            "auditor_fn_violation": 0.0063941317186392435,
            "auditor_fp_violation": 0.023193703936020084,
            "ave_precision_score": 0.79144329908796,
            "fpr": 0.1942919868276619,
            "logloss": 0.918090633908468,
            "mae": 0.30251394033343765,
            "precision": 0.6816546762589928,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.782813938799862,
            "auditor_fn_violation": 0.01243881087647837,
            "auditor_fp_violation": 0.02338834020919282,
            "ave_precision_score": 0.7736155917157489,
            "fpr": 0.12938596491228072,
            "logloss": 1.348354907456215,
            "mae": 0.27197045064067976,
            "precision": 0.7586912065439673,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7670880252287209,
            "auditor_fn_violation": 0.01311306731026831,
            "auditor_fp_violation": 0.016862356907636822,
            "ave_precision_score": 0.7576027600654107,
            "fpr": 0.13721185510428102,
            "logloss": 1.346819027652012,
            "mae": 0.27761198537866144,
            "precision": 0.7395833333333334,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8580125551425237,
            "auditor_fn_violation": 0.013680458784435632,
            "auditor_fp_violation": 0.014217923073717553,
            "ave_precision_score": 0.858272523692699,
            "fpr": 0.10416666666666667,
            "logloss": 0.6583908273518265,
            "mae": 0.26569264230378375,
            "precision": 0.796137339055794,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7999354502004205,
            "auditor_fn_violation": 0.006102519482305307,
            "auditor_fp_violation": 0.02053032381997805,
            "ave_precision_score": 0.8003857691623631,
            "fpr": 0.12623490669593854,
            "logloss": 0.775053363565759,
            "mae": 0.277651514723168,
            "precision": 0.7516198704103672,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8592819835994707,
            "auditor_fn_violation": 0.011806821024046886,
            "auditor_fp_violation": 0.013361045130641331,
            "ave_precision_score": 0.8594771676393318,
            "fpr": 0.1074561403508772,
            "logloss": 0.712472031158412,
            "mae": 0.2681074792605188,
            "precision": 0.7860262008733624,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8298400897306846,
            "auditor_fn_violation": 0.006659664811886404,
            "auditor_fp_violation": 0.012143249176728873,
            "ave_precision_score": 0.8304639303196891,
            "fpr": 0.11525795828759605,
            "logloss": 0.7286251250415036,
            "mae": 0.2737755893129811,
            "precision": 0.7666666666666667,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8599716063322829,
            "auditor_fn_violation": 0.013584432057741097,
            "auditor_fp_violation": 0.019778513980914285,
            "ave_precision_score": 0.860186210106197,
            "fpr": 0.13486842105263158,
            "logloss": 0.7055270764438104,
            "mae": 0.26172164444222135,
            "precision": 0.7620889748549323,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8226340104424757,
            "auditor_fn_violation": 0.008613229712204806,
            "auditor_fp_violation": 0.018327583503214694,
            "ave_precision_score": 0.8231043000329143,
            "fpr": 0.1734357848518112,
            "logloss": 0.7770830939491911,
            "mae": 0.28488059257716847,
            "precision": 0.7001897533206831,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8488666642947199,
            "auditor_fn_violation": 0.033801407796476945,
            "auditor_fp_violation": 0.01591084302204442,
            "ave_precision_score": 0.8491151803220837,
            "fpr": 0.09539473684210527,
            "logloss": 1.2658777618524029,
            "mae": 0.27091264222382566,
            "precision": 0.8044943820224719,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8070334473264453,
            "auditor_fn_violation": 0.023494937089994387,
            "auditor_fp_violation": 0.03262211855104281,
            "ave_precision_score": 0.8077750277299071,
            "fpr": 0.12623490669593854,
            "logloss": 1.3448748313585552,
            "mae": 0.28878933937475015,
            "precision": 0.7450110864745011,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8674586492746631,
            "auditor_fn_violation": 0.018635884517811844,
            "auditor_fp_violation": 0.013473038296453722,
            "ave_precision_score": 0.8676416414668117,
            "fpr": 0.08881578947368421,
            "logloss": 0.6896146487222529,
            "mae": 0.26531629130700096,
            "precision": 0.8159090909090909,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8337392584461272,
            "auditor_fn_violation": 0.017556004959778854,
            "auditor_fp_violation": 0.014902187549004235,
            "ave_precision_score": 0.8344911185899144,
            "fpr": 0.09879253567508232,
            "logloss": 0.7130455329479527,
            "mae": 0.2701442161780696,
            "precision": 0.7867298578199052,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7398418216658269,
            "auditor_fn_violation": 0.013751920534533897,
            "auditor_fp_violation": 0.013137058799016551,
            "ave_precision_score": 0.6998077102860473,
            "fpr": 0.16337719298245615,
            "logloss": 3.1643403134353267,
            "mae": 0.29282056380052063,
            "precision": 0.7276051188299817,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7067525411051001,
            "auditor_fn_violation": 0.003501717667196946,
            "auditor_fp_violation": 0.018386388583973658,
            "ave_precision_score": 0.6576254238925219,
            "fpr": 0.18441273326015367,
            "logloss": 3.514333902041961,
            "mae": 0.3112454768796743,
            "precision": 0.685981308411215,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8142790305054279,
            "auditor_fn_violation": 0.015018133419087438,
            "auditor_fp_violation": 0.01773659207400926,
            "ave_precision_score": 0.8105374035460334,
            "fpr": 0.13157894736842105,
            "logloss": 1.0328204366083549,
            "mae": 0.26385109898189646,
            "precision": 0.7660818713450293,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.78146549404482,
            "auditor_fn_violation": 0.005429203424428577,
            "auditor_fp_violation": 0.01962129527991219,
            "ave_precision_score": 0.7730578054992296,
            "fpr": 0.1712403951701427,
            "logloss": 1.2091190348103718,
            "mae": 0.2850339144731897,
            "precision": 0.7,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8447388010103962,
            "auditor_fn_violation": 0.03382820595276379,
            "auditor_fp_violation": 0.03841886485810726,
            "ave_precision_score": 0.8449885066878995,
            "fpr": 0.20394736842105263,
            "logloss": 0.9700292360528611,
            "mae": 0.33072437258828813,
            "precision": 0.6910299003322259,
            "recall": 0.8472505091649695
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.806262173718312,
            "auditor_fn_violation": 0.032771999535317085,
            "auditor_fp_violation": 0.04635800533166066,
            "ave_precision_score": 0.8069195160889879,
            "fpr": 0.21953896816684962,
            "logloss": 0.9748430095734172,
            "mae": 0.33601601324998376,
            "precision": 0.6592844974446337,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8473569990086738,
            "auditor_fn_violation": 0.027977275163468755,
            "auditor_fp_violation": 0.020270763012043173,
            "ave_precision_score": 0.8475912811866037,
            "fpr": 0.1074561403508772,
            "logloss": 1.1224208469970534,
            "mae": 0.27283985430607066,
            "precision": 0.7846153846153846,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8126957568341937,
            "auditor_fn_violation": 0.022058213389032064,
            "auditor_fp_violation": 0.025692919868276622,
            "ave_precision_score": 0.8128959468864668,
            "fpr": 0.13062568605927552,
            "logloss": 1.137938339213231,
            "mae": 0.28592852542368125,
            "precision": 0.740174672489083,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.851264751086363,
            "auditor_fn_violation": 0.01299487261943045,
            "auditor_fp_violation": 0.02799047797641372,
            "ave_precision_score": 0.8515219055095449,
            "fpr": 0.16228070175438597,
            "logloss": 0.7573723237295947,
            "mae": 0.2605795474652818,
            "precision": 0.7371225577264654,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8227416339959849,
            "auditor_fn_violation": 0.0011640781141460446,
            "auditor_fp_violation": 0.020905206209816535,
            "ave_precision_score": 0.8230872314915654,
            "fpr": 0.1986827661909989,
            "logloss": 0.8156971264109485,
            "mae": 0.2868197579571983,
            "precision": 0.6807760141093474,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8494359423767064,
            "auditor_fn_violation": 0.03375451102297495,
            "auditor_fp_violation": 0.022841396841271833,
            "ave_precision_score": 0.8496838415298376,
            "fpr": 0.09868421052631579,
            "logloss": 1.263832357593749,
            "mae": 0.27061158509714633,
            "precision": 0.8004434589800443,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8072297108040076,
            "auditor_fn_violation": 0.023938282522469555,
            "auditor_fp_violation": 0.03351399560922064,
            "ave_precision_score": 0.8079712265409486,
            "fpr": 0.12843029637760703,
            "logloss": 1.3452579736002435,
            "mae": 0.28903517571618176,
            "precision": 0.7411504424778761,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8691996074512782,
            "auditor_fn_violation": 0.016757780398041943,
            "auditor_fp_violation": 0.019387840146685008,
            "ave_precision_score": 0.8694232292366599,
            "fpr": 0.11732456140350878,
            "logloss": 0.5579768968230288,
            "mae": 0.26703275258248477,
            "precision": 0.7838383838383839,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8425928253782518,
            "auditor_fn_violation": 0.007487084897094076,
            "auditor_fp_violation": 0.012096695154461351,
            "ave_precision_score": 0.8428966130088237,
            "fpr": 0.1394072447859495,
            "logloss": 0.5865163881629608,
            "mae": 0.27594440433527184,
            "precision": 0.7397540983606558,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8328798924083599,
            "auditor_fn_violation": 0.014267785043055708,
            "auditor_fp_violation": 0.024003000375046886,
            "ave_precision_score": 0.8332538103103194,
            "fpr": 0.12609649122807018,
            "logloss": 0.7057138456284455,
            "mae": 0.27340038949372636,
            "precision": 0.7709163346613546,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.80501600851751,
            "auditor_fn_violation": 0.010149528323134809,
            "auditor_fp_violation": 0.017019170456327424,
            "ave_precision_score": 0.8054836113151347,
            "fpr": 0.15916575192096596,
            "logloss": 0.7384248100451313,
            "mae": 0.2923127251382552,
            "precision": 0.71,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.5919954941382668,
            "auditor_fn_violation": 0.03678493586307929,
            "auditor_fp_violation": 0.02519325332333209,
            "ave_precision_score": 0.593132186934794,
            "fpr": 0.22916666666666666,
            "logloss": 2.489957381144317,
            "mae": 0.39112834207937747,
            "precision": 0.643344709897611,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.5697465157960273,
            "auditor_fn_violation": 0.02861119079738166,
            "auditor_fp_violation": 0.0499451152579583,
            "ave_precision_score": 0.5681102560151541,
            "fpr": 0.2689352360043908,
            "logloss": 2.6001031775081285,
            "mae": 0.40890578207313755,
            "precision": 0.5847457627118644,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8320310859113724,
            "auditor_fn_violation": 0.033164951584664315,
            "auditor_fp_violation": 0.02813893403342085,
            "ave_precision_score": 0.832379239946623,
            "fpr": 0.11074561403508772,
            "logloss": 1.301793893233703,
            "mae": 0.28121250338901393,
            "precision": 0.7809110629067245,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7814739134277676,
            "auditor_fn_violation": 0.0239880699774534,
            "auditor_fp_violation": 0.038321310961267056,
            "ave_precision_score": 0.7824055089450692,
            "fpr": 0.14928649835345773,
            "logloss": 1.393313401232221,
            "mae": 0.30290140759719203,
            "precision": 0.7130801687763713,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8224934988202801,
            "auditor_fn_violation": 0.006127845070925791,
            "auditor_fp_violation": 0.015468079343251251,
            "ave_precision_score": 0.8237950425987434,
            "fpr": 0.17543859649122806,
            "logloss": 0.7036865967592483,
            "mae": 0.30905194059136865,
            "precision": 0.7231833910034602,
            "recall": 0.8513238289205702
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7981016180483651,
            "auditor_fn_violation": 0.016908768044988892,
            "auditor_fp_violation": 0.014186725733103343,
            "ave_precision_score": 0.7984820956424505,
            "fpr": 0.18660812294182216,
            "logloss": 0.7534303876752602,
            "mae": 0.31726100504946303,
            "precision": 0.6964285714285714,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8449457394444337,
            "auditor_fn_violation": 0.034801872297852574,
            "auditor_fp_violation": 0.026037108805267332,
            "ave_precision_score": 0.8452204756377328,
            "fpr": 0.10416666666666667,
            "logloss": 1.3090141699639508,
            "mae": 0.26976640936076834,
            "precision": 0.7939262472885033,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7982461531020684,
            "auditor_fn_violation": 0.020991339353664006,
            "auditor_fp_violation": 0.03505517876744552,
            "ave_precision_score": 0.7991401809612171,
            "fpr": 0.141602634467618,
            "logloss": 1.3988846828312804,
            "mae": 0.29034320064067765,
            "precision": 0.7237687366167024,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8484944909477206,
            "auditor_fn_violation": 0.015330778575767317,
            "auditor_fp_violation": 0.014944576405384007,
            "ave_precision_score": 0.8487521765720363,
            "fpr": 0.12280701754385964,
            "logloss": 0.6858596905327624,
            "mae": 0.25955906490266245,
            "precision": 0.7786561264822134,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8181734522385561,
            "auditor_fn_violation": 0.0002465664437295076,
            "auditor_fp_violation": 0.021375646855888355,
            "ave_precision_score": 0.8190051450685245,
            "fpr": 0.16355653128430298,
            "logloss": 0.7185105185818997,
            "mae": 0.28022713262739646,
            "precision": 0.7106796116504854,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8761821347449621,
            "auditor_fn_violation": 0.028370314789009185,
            "auditor_fp_violation": 0.01708807350918865,
            "ave_precision_score": 0.8763366621306903,
            "fpr": 0.11074561403508772,
            "logloss": 0.5444934260620443,
            "mae": 0.29243826003145873,
            "precision": 0.7955465587044535,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8376233394531624,
            "auditor_fn_violation": 0.0213754140063965,
            "auditor_fp_violation": 0.021713776070252468,
            "ave_precision_score": 0.8379902175324383,
            "fpr": 0.13721185510428102,
            "logloss": 0.5530756348077228,
            "mae": 0.29861098074622744,
            "precision": 0.7474747474747475,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8532330795796625,
            "auditor_fn_violation": 0.029788383892521534,
            "auditor_fp_violation": 0.021544359711630625,
            "ave_precision_score": 0.8534674286999537,
            "fpr": 0.10416666666666667,
            "logloss": 1.1866848896573219,
            "mae": 0.269610283517656,
            "precision": 0.7921225382932167,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8080527908203425,
            "auditor_fn_violation": 0.02291882511089563,
            "auditor_fp_violation": 0.033411086717892426,
            "ave_precision_score": 0.8086902838459391,
            "fpr": 0.13611416026344675,
            "logloss": 1.2488183163082556,
            "mae": 0.29066392276012826,
            "precision": 0.7292576419213974,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8126792479092327,
            "auditor_fn_violation": 0.045411709007753605,
            "auditor_fp_violation": 0.025234925198983217,
            "ave_precision_score": 0.8131581771934635,
            "fpr": 0.12719298245614036,
            "logloss": 1.2249774386177652,
            "mae": 0.32355841063461555,
            "precision": 0.7603305785123967,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7540594932785316,
            "auditor_fn_violation": 0.029720739794164442,
            "auditor_fp_violation": 0.03616267445507293,
            "ave_precision_score": 0.7552009315549852,
            "fpr": 0.15697036223929747,
            "logloss": 1.2539178460177707,
            "mae": 0.33142477696646266,
            "precision": 0.7157057654075547,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8058698621001326,
            "auditor_fn_violation": 0.025489512988173084,
            "auditor_fp_violation": 0.04861024294703505,
            "ave_precision_score": 0.8064483404274101,
            "fpr": 0.22587719298245615,
            "logloss": 0.5819136890693556,
            "mae": 0.3412610977487802,
            "precision": 0.678125,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7622480061770955,
            "auditor_fn_violation": 0.021863805231476106,
            "auditor_fp_violation": 0.05659989023051592,
            "ave_precision_score": 0.7628684588742229,
            "fpr": 0.2535675082327113,
            "logloss": 0.6433307996251219,
            "mae": 0.3601410791142941,
            "precision": 0.6373626373626373,
            "recall": 0.8768898488120951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8455478951556488,
            "auditor_fn_violation": 0.03554328795512202,
            "auditor_fp_violation": 0.020260345043130398,
            "ave_precision_score": 0.8458150160452995,
            "fpr": 0.10635964912280702,
            "logloss": 1.3082631340833457,
            "mae": 0.2694324083860263,
            "precision": 0.7913978494623656,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7989725141311121,
            "auditor_fn_violation": 0.022214688247552718,
            "auditor_fp_violation": 0.03583679629920025,
            "ave_precision_score": 0.7998669200668491,
            "fpr": 0.141602634467618,
            "logloss": 1.394892687734968,
            "mae": 0.28944976838021225,
            "precision": 0.7243589743589743,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8382137940556891,
            "auditor_fn_violation": 0.033973362632650876,
            "auditor_fp_violation": 0.022453327499270745,
            "ave_precision_score": 0.8386283868843749,
            "fpr": 0.1524122807017544,
            "logloss": 1.2710487834030884,
            "mae": 0.27276343788336854,
            "precision": 0.7392120075046904,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7943835764619391,
            "auditor_fn_violation": 0.02219809242922477,
            "auditor_fp_violation": 0.04436843343264859,
            "ave_precision_score": 0.7950902760864156,
            "fpr": 0.18990120746432493,
            "logloss": 1.388314797442597,
            "mae": 0.30175746057568237,
            "precision": 0.6802218114602587,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8559242698873315,
            "auditor_fn_violation": 0.02647881159109587,
            "auditor_fp_violation": 0.023013293328332712,
            "ave_precision_score": 0.8561394609396833,
            "fpr": 0.12609649122807018,
            "logloss": 0.9109703525347468,
            "mae": 0.26785120393730805,
            "precision": 0.7686116700201208,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8118558598365966,
            "auditor_fn_violation": 0.023511532908322332,
            "auditor_fp_violation": 0.038247804610318334,
            "ave_precision_score": 0.8121238757403231,
            "fpr": 0.1690450054884742,
            "logloss": 0.9941334920956795,
            "mae": 0.29418105883964996,
            "precision": 0.6926147704590818,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8510310816938196,
            "auditor_fn_violation": 0.015996266123557368,
            "auditor_fp_violation": 0.01834083427095054,
            "ave_precision_score": 0.8513280808627998,
            "fpr": 0.13048245614035087,
            "logloss": 0.602721888802363,
            "mae": 0.2752109565774669,
            "precision": 0.7648221343873518,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8129089242404508,
            "auditor_fn_violation": 0.004194000374591328,
            "auditor_fp_violation": 0.0200672338090011,
            "ave_precision_score": 0.8139138335588422,
            "fpr": 0.1602634467618002,
            "logloss": 0.6321814966547441,
            "mae": 0.2885344481587913,
            "precision": 0.7142857142857143,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 14724,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.45319505030434837,
            "auditor_fn_violation": 0.00556061742952085,
            "auditor_fp_violation": 0.01496541234320958,
            "ave_precision_score": 0.43706355934017715,
            "fpr": 0.23574561403508773,
            "logloss": 8.212147750411859,
            "mae": 0.5713400814796554,
            "precision": 0.510250569476082,
            "recall": 0.45621181262729127
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.4471067600254522,
            "auditor_fn_violation": 0.01812500444530848,
            "auditor_fp_violation": 0.013696683393445194,
            "ave_precision_score": 0.4279992847375076,
            "fpr": 0.2513721185510428,
            "logloss": 7.780174508583861,
            "mae": 0.5494770362202368,
            "precision": 0.4989059080962801,
            "recall": 0.4924406047516199
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 14724,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8449010548376672,
            "auditor_fn_violation": 0.027157698217029336,
            "auditor_fp_violation": 0.014608596907946829,
            "ave_precision_score": 0.8451546699649148,
            "fpr": 0.09210526315789473,
            "logloss": 1.3585804080327404,
            "mae": 0.2736175648614343,
            "precision": 0.8051044083526682,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.795054068072477,
            "auditor_fn_violation": 0.023675120260412102,
            "auditor_fp_violation": 0.02389446448173122,
            "ave_precision_score": 0.7959749244078972,
            "fpr": 0.1251372118551043,
            "logloss": 1.4623495560826618,
            "mae": 0.2924360263586114,
            "precision": 0.7449664429530202,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.813983515599314,
            "auditor_fn_violation": 0.019480026440847537,
            "auditor_fp_violation": 0.013798599824978124,
            "ave_precision_score": 0.8125420948518594,
            "fpr": 0.13267543859649122,
            "logloss": 0.7299309053472336,
            "mae": 0.2758844625917702,
            "precision": 0.7627450980392156,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7914902177913445,
            "auditor_fn_violation": 0.00730690172667636,
            "auditor_fp_violation": 0.020204445664105383,
            "ave_precision_score": 0.7905501987937386,
            "fpr": 0.1602634467618002,
            "logloss": 0.7870554437723587,
            "mae": 0.28251850036807513,
            "precision": 0.7159533073929961,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8583020005840704,
            "auditor_fn_violation": 0.011806821024046886,
            "auditor_fp_violation": 0.013361045130641331,
            "ave_precision_score": 0.8585066625666871,
            "fpr": 0.1074561403508772,
            "logloss": 0.7142309393461437,
            "mae": 0.2683854952216597,
            "precision": 0.7860262008733624,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8290603574440458,
            "auditor_fn_violation": 0.00926283745818447,
            "auditor_fp_violation": 0.013378155872667406,
            "ave_precision_score": 0.8296570037657492,
            "fpr": 0.11745334796926454,
            "logloss": 0.7315698488668503,
            "mae": 0.2746427518369597,
            "precision": 0.7637969094922737,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8139418155698173,
            "auditor_fn_violation": 0.03920123628827671,
            "auditor_fp_violation": 0.027842021919406598,
            "ave_precision_score": 0.8144737526605739,
            "fpr": 0.15021929824561403,
            "logloss": 1.4401431904830932,
            "mae": 0.28340523981255916,
            "precision": 0.7434456928838952,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7563770718884293,
            "auditor_fn_violation": 0.022451771366523397,
            "auditor_fp_violation": 0.04951387799905912,
            "ave_precision_score": 0.757230107176751,
            "fpr": 0.19758507135016465,
            "logloss": 1.6355592360972009,
            "mae": 0.3153624001578281,
            "precision": 0.6715328467153284,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8447459915812474,
            "auditor_fn_violation": 0.028511005109515136,
            "auditor_fp_violation": 0.018994561820227532,
            "ave_precision_score": 0.8453163593387925,
            "fpr": 0.1074561403508772,
            "logloss": 1.1862483505217527,
            "mae": 0.2656242652386579,
            "precision": 0.7901498929336188,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8034802569631752,
            "auditor_fn_violation": 0.01896427868646469,
            "auditor_fp_violation": 0.028204386859024624,
            "ave_precision_score": 0.8042083446609791,
            "fpr": 0.1350164654226125,
            "logloss": 1.2209044431776057,
            "mae": 0.28499447334428035,
            "precision": 0.7354838709677419,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8427218490425289,
            "auditor_fn_violation": 0.01826517668917712,
            "auditor_fp_violation": 0.015137308830270447,
            "ave_precision_score": 0.8439249438434531,
            "fpr": 0.09649122807017543,
            "logloss": 0.7988626791283948,
            "mae": 0.267089482198997,
            "precision": 0.8044444444444444,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8172757804551155,
            "auditor_fn_violation": 0.01346632115753462,
            "auditor_fp_violation": 0.01852360043907794,
            "ave_precision_score": 0.8187671650442487,
            "fpr": 0.1141602634467618,
            "logloss": 0.7806186223163691,
            "mae": 0.2726745051137039,
            "precision": 0.764172335600907,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8514293496569234,
            "auditor_fn_violation": 0.026041108371744028,
            "auditor_fp_violation": 0.022502812851606453,
            "ave_precision_score": 0.851888662627801,
            "fpr": 0.15350877192982457,
            "logloss": 0.9971858252621786,
            "mae": 0.26476268744456943,
            "precision": 0.7431192660550459,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8167241262370116,
            "auditor_fn_violation": 0.02249207549674841,
            "auditor_fp_violation": 0.03887505880508076,
            "ave_precision_score": 0.8170882970104796,
            "fpr": 0.19099890230515917,
            "logloss": 1.0734529590738777,
            "mae": 0.2932015073942212,
            "precision": 0.6830601092896175,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.817678218818141,
            "auditor_fn_violation": 0.021132579411869804,
            "auditor_fp_violation": 0.007537400508396884,
            "ave_precision_score": 0.8185426444068677,
            "fpr": 0.03837719298245614,
            "logloss": 0.6699872049111988,
            "mae": 0.35654155893714407,
            "precision": 0.8771929824561403,
            "recall": 0.5091649694501018
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.772146043904469,
            "auditor_fn_violation": 0.02767471247744747,
            "auditor_fp_violation": 0.015269719303747846,
            "ave_precision_score": 0.7734570930613547,
            "fpr": 0.054884742041712405,
            "logloss": 0.7516492394875482,
            "mae": 0.3458032416133517,
            "precision": 0.8281786941580757,
            "recall": 0.5205183585313174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 14724,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6377575344026245,
            "auditor_fn_violation": 0.028839282524029012,
            "auditor_fp_violation": 0.029441180147518464,
            "ave_precision_score": 0.6385519622766158,
            "fpr": 0.2050438596491228,
            "logloss": 3.1762012091516376,
            "mae": 0.4110973256735375,
            "precision": 0.6465028355387523,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6092850191029855,
            "auditor_fn_violation": 0.026925529821500125,
            "auditor_fp_violation": 0.044321879410381064,
            "ave_precision_score": 0.610544362204981,
            "fpr": 0.22941822173435786,
            "logloss": 3.399247518340718,
            "mae": 0.4186343313197683,
            "precision": 0.6056603773584905,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8199042224707991,
            "auditor_fn_violation": 0.015728284560688897,
            "auditor_fp_violation": 0.022203296245364015,
            "ave_precision_score": 0.8164973858192941,
            "fpr": 0.12719298245614036,
            "logloss": 0.9521181232381809,
            "mae": 0.25906567460181085,
            "precision": 0.7764932562620424,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7886939251949715,
            "auditor_fn_violation": 0.00940271649837717,
            "auditor_fp_violation": 0.021718676493649055,
            "ave_precision_score": 0.7816991949678963,
            "fpr": 0.15806805708013172,
            "logloss": 1.1045158461345475,
            "mae": 0.2781219555591093,
            "precision": 0.7214700193423598,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8542062809521132,
            "auditor_fn_violation": 0.02682272126344374,
            "auditor_fp_violation": 0.020374942701170982,
            "ave_precision_score": 0.8544298700867515,
            "fpr": 0.09320175438596491,
            "logloss": 1.1877489994932715,
            "mae": 0.2677158938334547,
            "precision": 0.804147465437788,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8113444967794163,
            "auditor_fn_violation": 0.02295438757874124,
            "auditor_fp_violation": 0.027099341383095495,
            "ave_precision_score": 0.8119464866456144,
            "fpr": 0.1207464324917673,
            "logloss": 1.2334744157338005,
            "mae": 0.28648443134823015,
            "precision": 0.75,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8645575297630409,
            "auditor_fn_violation": 0.018973094651088002,
            "auditor_fp_violation": 0.015280555902821184,
            "ave_precision_score": 0.8647361362846104,
            "fpr": 0.12938596491228072,
            "logloss": 0.739107573924616,
            "mae": 0.2628470895567355,
            "precision": 0.76953125,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8399595584617252,
            "auditor_fn_violation": 0.013191304739528639,
            "auditor_fp_violation": 0.021091422298886626,
            "ave_precision_score": 0.8402623898211228,
            "fpr": 0.15806805708013172,
            "logloss": 0.7083269420317975,
            "mae": 0.2757544510031514,
            "precision": 0.71875,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8471369764710628,
            "auditor_fn_violation": 0.03353119305391789,
            "auditor_fp_violation": 0.01872890361295162,
            "ave_precision_score": 0.847381488031602,
            "fpr": 0.10526315789473684,
            "logloss": 1.293728861958521,
            "mae": 0.269957367861559,
            "precision": 0.7913043478260869,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8020098461970333,
            "auditor_fn_violation": 0.020576443895465316,
            "auditor_fp_violation": 0.03179639720871884,
            "ave_precision_score": 0.802752210300296,
            "fpr": 0.141602634467618,
            "logloss": 1.3792391452072317,
            "mae": 0.28938721993277283,
            "precision": 0.7249466950959488,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5116511063387456,
            "auditor_fn_violation": 0.0035172580126487346,
            "auditor_fp_violation": 0.009141767720965118,
            "ave_precision_score": 0.512700957075883,
            "fpr": 0.20175438596491227,
            "logloss": 2.7852746882294643,
            "mae": 0.4755041278453172,
            "precision": 0.5789473684210527,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.4979908865396212,
            "auditor_fn_violation": 0.008025263577157526,
            "auditor_fp_violation": 0.011192567037792062,
            "ave_precision_score": 0.49615404429455623,
            "fpr": 0.2261251372118551,
            "logloss": 2.650383470669965,
            "mae": 0.47249536891104915,
            "precision": 0.5541125541125541,
            "recall": 0.5529157667386609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7897658296699566,
            "auditor_fn_violation": 0.048683317254439556,
            "auditor_fp_violation": 0.0441461432679085,
            "ave_precision_score": 0.7886165034115409,
            "fpr": 0.18311403508771928,
            "logloss": 1.4208646165156693,
            "mae": 0.32591347745360244,
            "precision": 0.7070175438596491,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7086949066438288,
            "auditor_fn_violation": 0.032634491326314095,
            "auditor_fp_violation": 0.045135349694213595,
            "ave_precision_score": 0.7078448282774055,
            "fpr": 0.20087815587266739,
            "logloss": 1.6089243199883767,
            "mae": 0.3439562806927742,
            "precision": 0.6778169014084507,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.5863304151294426,
            "auditor_fn_violation": 0.010411083717440239,
            "auditor_fp_violation": 0.010832083177063802,
            "ave_precision_score": 0.5611632990256858,
            "fpr": 0.2138157894736842,
            "logloss": 6.240985721642597,
            "mae": 0.41459444635857057,
            "precision": 0.6198830409356725,
            "recall": 0.6476578411405295
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.55308442298341,
            "auditor_fn_violation": 0.006690485617352596,
            "auditor_fp_violation": 0.012192253410694683,
            "ave_precision_score": 0.5316354625322951,
            "fpr": 0.2283205268935236,
            "logloss": 6.02078286531384,
            "mae": 0.419211766972695,
            "precision": 0.59375,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8617558595052689,
            "auditor_fn_violation": 0.03140520598849466,
            "auditor_fp_violation": 0.010891986498312292,
            "ave_precision_score": 0.8619403065512328,
            "fpr": 0.07675438596491228,
            "logloss": 1.251409626283906,
            "mae": 0.2653268538428617,
            "precision": 0.8292682926829268,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8147771419143985,
            "auditor_fn_violation": 0.02446934870896388,
            "auditor_fp_violation": 0.020623431864513094,
            "ave_precision_score": 0.8154224495729849,
            "fpr": 0.10867178924259056,
            "logloss": 1.3383331499897397,
            "mae": 0.28006785084878294,
            "precision": 0.7665094339622641,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.728349792805443,
            "auditor_fn_violation": 0.005929092078465007,
            "auditor_fp_violation": 0.006680522565320666,
            "ave_precision_score": 0.7244661846422554,
            "fpr": 0.20175438596491227,
            "logloss": 1.3434943660339314,
            "mae": 0.34827586726475457,
            "precision": 0.6805555555555556,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7165246438502635,
            "auditor_fn_violation": 0.006728418916387895,
            "auditor_fp_violation": 0.011515994981966444,
            "ave_precision_score": 0.710346522452771,
            "fpr": 0.20856201975850713,
            "logloss": 1.374717363335424,
            "mae": 0.3499663998188837,
            "precision": 0.6588868940754039,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6796556341390853,
            "auditor_fn_violation": 0.005667810054668239,
            "auditor_fp_violation": 0.008167687627620119,
            "ave_precision_score": 0.68085941960555,
            "fpr": 0.20285087719298245,
            "logloss": 1.3244033572679292,
            "mae": 0.35899486458141305,
            "precision": 0.6708185053380783,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6658227766765925,
            "auditor_fn_violation": 0.005265616072338801,
            "auditor_fp_violation": 0.002905951074172812,
            "ave_precision_score": 0.6653464182063761,
            "fpr": 0.2217343578485181,
            "logloss": 1.1801443006181493,
            "mae": 0.36211780183547815,
            "precision": 0.6347197106690777,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 14724,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.459185435007891,
            "auditor_fn_violation": 0.013361114088684022,
            "auditor_fp_violation": 0.01891121806892529,
            "ave_precision_score": 0.4408703382021071,
            "fpr": 0.23355263157894737,
            "logloss": 8.578983402303885,
            "mae": 0.561549520992175,
            "precision": 0.5046511627906977,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.447263827429609,
            "auditor_fn_violation": 0.017695883999971542,
            "auditor_fp_violation": 0.014595911086717895,
            "ave_precision_score": 0.42875307188209144,
            "fpr": 0.22941822173435786,
            "logloss": 8.097255405318545,
            "mae": 0.5431086733372037,
            "precision": 0.5023809523809524,
            "recall": 0.4557235421166307
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8356791997938109,
            "auditor_fn_violation": 0.03155036266838175,
            "auditor_fp_violation": 0.023726924198858197,
            "ave_precision_score": 0.8359606549252481,
            "fpr": 0.11951754385964912,
            "logloss": 1.4251782637418682,
            "mae": 0.2778496691939939,
            "precision": 0.7724425887265136,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7829678524532379,
            "auditor_fn_violation": 0.024670869360088957,
            "auditor_fp_violation": 0.03827965736239612,
            "ave_precision_score": 0.7831959299923146,
            "fpr": 0.16355653128430298,
            "logloss": 1.6074403149380414,
            "mae": 0.30373724691237625,
            "precision": 0.6959183673469388,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8142879842117936,
            "auditor_fn_violation": 0.015018133419087438,
            "auditor_fp_violation": 0.01908571904821437,
            "ave_precision_score": 0.8105668409390268,
            "fpr": 0.12938596491228072,
            "logloss": 1.0329976401074976,
            "mae": 0.26371908573145597,
            "precision": 0.7690802348336595,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7813892443067095,
            "auditor_fn_violation": 0.004338621077163443,
            "auditor_fp_violation": 0.017798337776383878,
            "ave_precision_score": 0.7729359113870162,
            "fpr": 0.1668496158068057,
            "logloss": 1.2089835780980633,
            "mae": 0.28475326297090053,
            "precision": 0.7042801556420234,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8675973838503735,
            "auditor_fn_violation": 0.01546476935720156,
            "auditor_fp_violation": 0.019945201483518776,
            "ave_precision_score": 0.8677571950550289,
            "fpr": 0.11732456140350878,
            "logloss": 0.5802198224320034,
            "mae": 0.2676376689484817,
            "precision": 0.7829614604462475,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8301258298547354,
            "auditor_fn_violation": 0.006353827588414227,
            "auditor_fp_violation": 0.02026815116826094,
            "ave_precision_score": 0.831462360389448,
            "fpr": 0.1525795828759605,
            "logloss": 0.6076059896908181,
            "mae": 0.2798210818971723,
            "precision": 0.722,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8305477764667059,
            "auditor_fn_violation": 0.01223782470432701,
            "auditor_fp_violation": 0.01574155102721174,
            "ave_precision_score": 0.8309047290371181,
            "fpr": 0.19298245614035087,
            "logloss": 0.7866498992137483,
            "mae": 0.2953686098566099,
            "precision": 0.7147487844408428,
            "recall": 0.8981670061099797
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8031460358742297,
            "auditor_fn_violation": 0.0046823915996709285,
            "auditor_fp_violation": 0.013365904814175945,
            "ave_precision_score": 0.8033337357494521,
            "fpr": 0.21844127332601537,
            "logloss": 0.8201459882495177,
            "mae": 0.31405962150625155,
            "precision": 0.6737704918032786,
            "recall": 0.8876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.856120111081496,
            "auditor_fn_violation": 0.01660815735877372,
            "auditor_fp_violation": 0.01580926782514481,
            "ave_precision_score": 0.8564089001596481,
            "fpr": 0.09868421052631579,
            "logloss": 0.6614504478420714,
            "mae": 0.2721544026958569,
            "precision": 0.8030634573304157,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8325371794511814,
            "auditor_fn_violation": 0.00863219636172246,
            "auditor_fp_violation": 0.00776472087188333,
            "ave_precision_score": 0.8330310262158395,
            "fpr": 0.10428100987925357,
            "logloss": 0.6678159652797137,
            "mae": 0.2768311757961328,
            "precision": 0.7806004618937644,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 14724,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.848594630724413,
            "auditor_fn_violation": 0.032704916568406774,
            "auditor_fp_violation": 0.015220652581572701,
            "ave_precision_score": 0.8488455806157753,
            "fpr": 0.09758771929824561,
            "logloss": 1.2482966207350088,
            "mae": 0.2718482965976244,
            "precision": 0.8008948545861297,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8086411936676257,
            "auditor_fn_violation": 0.024988560739509676,
            "auditor_fp_violation": 0.032340344205739384,
            "ave_precision_score": 0.8093652266170657,
            "fpr": 0.12623490669593854,
            "logloss": 1.3168643808202416,
            "mae": 0.28880611366776987,
            "precision": 0.7438752783964365,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8553557227113904,
            "auditor_fn_violation": 0.006290867188337444,
            "auditor_fp_violation": 0.01053777555527774,
            "ave_precision_score": 0.8414314974081277,
            "fpr": 0.15460526315789475,
            "logloss": 1.3036343000281498,
            "mae": 0.24596360238679713,
            "precision": 0.7495559502664298,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8367137740166319,
            "auditor_fn_violation": 0.0023400103842406124,
            "auditor_fp_violation": 0.006561666928022587,
            "ave_precision_score": 0.8194699904277427,
            "fpr": 0.16465422612513722,
            "logloss": 1.4693165906753003,
            "mae": 0.25002443556590426,
            "precision": 0.7302158273381295,
            "recall": 0.8768898488120951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8275796798979603,
            "auditor_fn_violation": 0.006322131704005431,
            "auditor_fp_violation": 0.02425042713672543,
            "ave_precision_score": 0.8141861088310087,
            "fpr": 0.2631578947368421,
            "logloss": 1.45920510449311,
            "mae": 0.32660911284268335,
            "precision": 0.6556671449067432,
            "recall": 0.9307535641547862
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8028930396725231,
            "auditor_fn_violation": 0.0068801521125291315,
            "auditor_fp_violation": 0.022292026031049104,
            "ave_precision_score": 0.787027124047392,
            "fpr": 0.29527991218441274,
            "logloss": 1.6342667866737066,
            "mae": 0.34342611408175255,
            "precision": 0.6178977272727273,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.853118236332896,
            "auditor_fn_violation": 0.033881802265337484,
            "auditor_fp_violation": 0.012498958203108729,
            "ave_precision_score": 0.8533125986218777,
            "fpr": 0.08662280701754387,
            "logloss": 1.4617134778507999,
            "mae": 0.2690912156592798,
            "precision": 0.8132387706855791,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7986994748071329,
            "auditor_fn_violation": 0.022172013286137993,
            "auditor_fp_violation": 0.02287762662694057,
            "ave_precision_score": 0.7991189548815552,
            "fpr": 0.11745334796926454,
            "logloss": 1.6043933644417827,
            "mae": 0.28745855795922803,
            "precision": 0.7551487414187643,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8541645782726277,
            "auditor_fn_violation": 0.012713491978418551,
            "auditor_fp_violation": 0.015231070550485481,
            "ave_precision_score": 0.8543843928380098,
            "fpr": 0.11513157894736842,
            "logloss": 0.6959649455602184,
            "mae": 0.26651216642769554,
            "precision": 0.7789473684210526,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8198523581938912,
            "auditor_fn_violation": 0.008700950466223956,
            "auditor_fp_violation": 0.014127920652344366,
            "ave_precision_score": 0.8203314186460102,
            "fpr": 0.14270032930845225,
            "logloss": 0.7294294556546049,
            "mae": 0.28236803711918995,
            "precision": 0.7297297297297297,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.45897387580858373,
            "auditor_fn_violation": 0.00976569478686535,
            "auditor_fp_violation": 0.019437325499020722,
            "ave_precision_score": 0.43990315381021716,
            "fpr": 0.22916666666666666,
            "logloss": 8.750861990414254,
            "mae": 0.5638724350177206,
            "precision": 0.4988009592326139,
            "recall": 0.42362525458248473
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.44897144305183406,
            "auditor_fn_violation": 0.013058538192905061,
            "auditor_fp_violation": 0.016867257331033402,
            "ave_precision_score": 0.42830596784928376,
            "fpr": 0.22941822173435786,
            "logloss": 8.215232116960044,
            "mae": 0.5452704296106065,
            "precision": 0.4963855421686747,
            "recall": 0.4449244060475162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.4578131283652248,
            "auditor_fn_violation": 0.018392467931539667,
            "auditor_fp_violation": 0.014777888902779517,
            "ave_precision_score": 0.4410353570112355,
            "fpr": 0.23574561403508773,
            "logloss": 8.625650225058214,
            "mae": 0.563158871709502,
            "precision": 0.5113636363636364,
            "recall": 0.45824847250509165
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.44900073238502397,
            "auditor_fn_violation": 0.024161140654302,
            "auditor_fp_violation": 0.0252469813391877,
            "ave_precision_score": 0.4313960628828572,
            "fpr": 0.24588364434687157,
            "logloss": 8.065877225728364,
            "mae": 0.5447578185248906,
            "precision": 0.4954954954954955,
            "recall": 0.47516198704103674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8656865597211176,
            "auditor_fn_violation": 0.013870279058134143,
            "auditor_fp_violation": 0.0030394424303037894,
            "ave_precision_score": 0.8658459552393916,
            "fpr": 0.08333333333333333,
            "logloss": 0.6016857362358515,
            "mae": 0.2947756364314579,
            "precision": 0.8164251207729468,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8505869241511012,
            "auditor_fn_violation": 0.00835955077490619,
            "auditor_fp_violation": 0.0157303591030265,
            "ave_precision_score": 0.8502600269748313,
            "fpr": 0.07793633369923161,
            "logloss": 0.6118722824900983,
            "mae": 0.2757135629900898,
            "precision": 0.8211586901763224,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7721314287134651,
            "auditor_fn_violation": 0.01917631400292993,
            "auditor_fp_violation": 0.02692524065508189,
            "ave_precision_score": 0.7725666996322337,
            "fpr": 0.13706140350877194,
            "logloss": 0.8691693589751952,
            "mae": 0.282408686422747,
            "precision": 0.7529644268774703,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7370072889870249,
            "auditor_fn_violation": 0.003985367229897131,
            "auditor_fp_violation": 0.024624627567821866,
            "ave_precision_score": 0.7372846370484631,
            "fpr": 0.15587266739846323,
            "logloss": 1.040542731841114,
            "mae": 0.28974440930844736,
            "precision": 0.7199211045364892,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8526558090798945,
            "auditor_fn_violation": 0.015230285489691645,
            "auditor_fp_violation": 0.012715131058048928,
            "ave_precision_score": 0.8529171699135261,
            "fpr": 0.125,
            "logloss": 0.6608681021259053,
            "mae": 0.25737718734179466,
            "precision": 0.7782101167315175,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8227563876599746,
            "auditor_fn_violation": 0.004772483184879792,
            "auditor_fp_violation": 0.021010565312843028,
            "ave_precision_score": 0.823559537141742,
            "fpr": 0.16355653128430298,
            "logloss": 0.6963933336297291,
            "mae": 0.2781133190201078,
            "precision": 0.7117988394584139,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7122722011930898,
            "auditor_fn_violation": 0.03796405473970058,
            "auditor_fp_violation": 0.04743561695211903,
            "ave_precision_score": 0.7137312262250678,
            "fpr": 0.25109649122807015,
            "logloss": 1.529177906020722,
            "mae": 0.3999203903179625,
            "precision": 0.6336,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.665199065447398,
            "auditor_fn_violation": 0.03147752570573717,
            "auditor_fp_violation": 0.05457601536772778,
            "ave_precision_score": 0.6662560146498837,
            "fpr": 0.2667398463227223,
            "logloss": 1.5471978956276344,
            "mae": 0.4023054395811081,
            "precision": 0.6055194805194806,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8120838949021225,
            "auditor_fn_violation": 0.04896246471576089,
            "auditor_fp_violation": 0.022906509146976707,
            "ave_precision_score": 0.8125311533886219,
            "fpr": 0.09539473684210527,
            "logloss": 1.2012591434779263,
            "mae": 0.31575173520685273,
            "precision": 0.8,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7761884308251973,
            "auditor_fn_violation": 0.03288817026361272,
            "auditor_fp_violation": 0.03305335580994199,
            "ave_precision_score": 0.7771059276599174,
            "fpr": 0.13391877058177826,
            "logloss": 1.202371756461097,
            "mae": 0.31548179436709695,
            "precision": 0.7381974248927039,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 14724,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8061183465432318,
            "auditor_fn_violation": 0.014951138028370321,
            "auditor_fp_violation": 0.014483581280993462,
            "ave_precision_score": 0.7804687020262119,
            "fpr": 0.10855263157894737,
            "logloss": 2.9032929867385566,
            "mae": 0.2725054036089664,
            "precision": 0.7880085653104925,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7727564237639579,
            "auditor_fn_violation": 0.01005232424435683,
            "auditor_fp_violation": 0.00984740081543046,
            "ave_precision_score": 0.7419297197473153,
            "fpr": 0.1350164654226125,
            "logloss": 3.0091644105543396,
            "mae": 0.288573132809008,
            "precision": 0.7382978723404255,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8140167447094584,
            "auditor_fn_violation": 0.019442062386107836,
            "auditor_fp_violation": 0.014814351793974254,
            "ave_precision_score": 0.8125755638800585,
            "fpr": 0.13486842105263158,
            "logloss": 0.726763283660704,
            "mae": 0.2761148890191777,
            "precision": 0.7607003891050583,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7913528995143781,
            "auditor_fn_violation": 0.007935171991948658,
            "auditor_fp_violation": 0.021444252783440487,
            "ave_precision_score": 0.7904136823442596,
            "fpr": 0.1668496158068057,
            "logloss": 0.7853242806528798,
            "mae": 0.28342003623956163,
            "precision": 0.7099236641221374,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8127790604715117,
            "auditor_fn_violation": 0.012907778611498196,
            "auditor_fp_violation": 0.04198441471850649,
            "ave_precision_score": 0.7991269216339691,
            "fpr": 0.21929824561403508,
            "logloss": 1.6130679584571535,
            "mae": 0.29684690881787357,
            "precision": 0.6894409937888198,
            "recall": 0.9042769857433809
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7803579914323864,
            "auditor_fn_violation": 0.003591809252405802,
            "auditor_fp_violation": 0.03313666300768387,
            "ave_precision_score": 0.7569438248734793,
            "fpr": 0.2305159165751921,
            "logloss": 2.036951229277457,
            "mae": 0.3052041566303014,
            "precision": 0.6645367412140575,
            "recall": 0.8984881209503239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 14724,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8318003538218031,
            "auditor_fn_violation": 0.024891020831100157,
            "auditor_fp_violation": 0.020552048172688263,
            "ave_precision_score": 0.8321294904335768,
            "fpr": 0.10964912280701754,
            "logloss": 1.1516328208182722,
            "mae": 0.27784621129664383,
            "precision": 0.7811816192560175,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7966113507279116,
            "auditor_fn_violation": 0.016991747136628634,
            "auditor_fp_violation": 0.026741610475145054,
            "ave_precision_score": 0.7970404993528815,
            "fpr": 0.14270032930845225,
            "logloss": 1.1795238196325533,
            "mae": 0.29467246595551794,
            "precision": 0.723404255319149,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7876842368318718,
            "auditor_fn_violation": 0.041170900775359995,
            "auditor_fp_violation": 0.025935533608367718,
            "ave_precision_score": 0.7883376466981994,
            "fpr": 0.14692982456140352,
            "logloss": 1.3240064902888617,
            "mae": 0.33162709235899235,
            "precision": 0.7377690802348337,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7310774938893676,
            "auditor_fn_violation": 0.03649183367196706,
            "auditor_fp_violation": 0.03493021797083268,
            "ave_precision_score": 0.7320511547667808,
            "fpr": 0.15806805708013172,
            "logloss": 1.3894413637460876,
            "mae": 0.334882668443998,
            "precision": 0.7114228456913828,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.716253765021682,
            "auditor_fn_violation": 0.03181387787186909,
            "auditor_fp_violation": 0.025643830478809856,
            "ave_precision_score": 0.7175221286982578,
            "fpr": 0.17543859649122806,
            "logloss": 1.6503360673088883,
            "mae": 0.33610510679086675,
            "precision": 0.6934865900383141,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6756676191651839,
            "auditor_fn_violation": 0.0240923865498005,
            "auditor_fp_violation": 0.035253645915007056,
            "ave_precision_score": 0.677138486016877,
            "fpr": 0.2052689352360044,
            "logloss": 1.6920993389326615,
            "mae": 0.35567119397962266,
            "precision": 0.6451612903225806,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.767541809549265,
            "auditor_fn_violation": 0.014841712223532354,
            "auditor_fp_violation": 0.03399383256240363,
            "ave_precision_score": 0.7665813155924095,
            "fpr": 0.19517543859649122,
            "logloss": 1.7083003324778907,
            "mae": 0.31964330994558193,
            "precision": 0.6983050847457627,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7101808538612872,
            "auditor_fn_violation": 0.007610368118958826,
            "auditor_fp_violation": 0.014524854947467462,
            "ave_precision_score": 0.7089291140355705,
            "fpr": 0.21953896816684962,
            "logloss": 2.028787933048642,
            "mae": 0.33452252276536026,
            "precision": 0.6604414261460102,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8326661359721041,
            "auditor_fn_violation": 0.03733429806695966,
            "auditor_fp_violation": 0.017028170187940162,
            "ave_precision_score": 0.8330815876201427,
            "fpr": 0.1162280701754386,
            "logloss": 1.105064627743164,
            "mae": 0.3214322133643699,
            "precision": 0.7773109243697479,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7925698776222557,
            "auditor_fn_violation": 0.02835514102889332,
            "auditor_fp_violation": 0.026442684647953588,
            "ave_precision_score": 0.7932495277410572,
            "fpr": 0.12733260153677278,
            "logloss": 1.0741379078506024,
            "mae": 0.3240799916050325,
            "precision": 0.7510729613733905,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8184038911228173,
            "auditor_fn_violation": 0.019180780362311075,
            "auditor_fp_violation": 0.019687356752927453,
            "ave_precision_score": 0.8167658332534107,
            "fpr": 0.09758771929824561,
            "logloss": 1.4332096472456877,
            "mae": 0.27987224849501263,
            "precision": 0.7920560747663551,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7841601050967,
            "auditor_fn_violation": 0.018042025353668754,
            "auditor_fp_violation": 0.02146630468872511,
            "ave_precision_score": 0.7787584802931167,
            "fpr": 0.10867178924259056,
            "logloss": 1.5414230428919755,
            "mae": 0.28383776886145845,
            "precision": 0.7665094339622641,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8782504960489598,
            "auditor_fn_violation": 0.01498016936434774,
            "auditor_fp_violation": 0.017437075467766808,
            "ave_precision_score": 0.8784061381431449,
            "fpr": 0.12390350877192982,
            "logloss": 0.5087744606368829,
            "mae": 0.30580528110440985,
            "precision": 0.7775590551181102,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8292599703578063,
            "auditor_fn_violation": 0.007686234717029445,
            "auditor_fp_violation": 0.01554904343735299,
            "ave_precision_score": 0.8306867072881114,
            "fpr": 0.1350164654226125,
            "logloss": 0.5086771345832359,
            "mae": 0.3061247060337946,
            "precision": 0.7544910179640718,
            "recall": 0.816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8052964562793152,
            "auditor_fn_violation": 0.013533068924857972,
            "auditor_fp_violation": 0.014629432845772393,
            "ave_precision_score": 0.7797043438481387,
            "fpr": 0.11074561403508772,
            "logloss": 2.8930400562059804,
            "mae": 0.2726562786190486,
            "precision": 0.7851063829787234,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.772629404017777,
            "auditor_fn_violation": 0.01005232424435683,
            "auditor_fp_violation": 0.011474341383095504,
            "ave_precision_score": 0.7418010680901399,
            "fpr": 0.13721185510428102,
            "logloss": 2.99845420051131,
            "mae": 0.28872986745929874,
            "precision": 0.7351694915254238,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8085311405777242,
            "auditor_fn_violation": 0.04809375781612892,
            "auditor_fp_violation": 0.02417489686210776,
            "ave_precision_score": 0.8090771788382883,
            "fpr": 0.1162280701754386,
            "logloss": 1.236249224928851,
            "mae": 0.3187617336393215,
            "precision": 0.7749469214437368,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.74702430356886,
            "auditor_fn_violation": 0.03349984471055708,
            "auditor_fp_violation": 0.035704484867492566,
            "ave_precision_score": 0.7482009518632408,
            "fpr": 0.141602634467618,
            "logloss": 1.2793637450064719,
            "mae": 0.3294883809228807,
            "precision": 0.7318087318087318,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7213292697530798,
            "auditor_fn_violation": 0.02398881623610962,
            "auditor_fp_violation": 0.017418844022169453,
            "ave_precision_score": 0.7100654251537801,
            "fpr": 0.26096491228070173,
            "logloss": 1.8622122898977687,
            "mae": 0.35308463613805524,
            "precision": 0.6484490398818316,
            "recall": 0.8940936863543788
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7119004424492372,
            "auditor_fn_violation": 0.015194657094830876,
            "auditor_fp_violation": 0.03927689352360045,
            "ave_precision_score": 0.7016450316062208,
            "fpr": 0.29198682766191,
            "logloss": 1.8089773940454317,
            "mae": 0.36656643657690247,
            "precision": 0.6017964071856288,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8576639002749968,
            "auditor_fn_violation": 0.01176885696930718,
            "auditor_fp_violation": 0.012506771679793307,
            "ave_precision_score": 0.8578796824198989,
            "fpr": 0.10964912280701754,
            "logloss": 0.7082762824472657,
            "mae": 0.26925300693546234,
            "precision": 0.7835497835497836,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8283065300521124,
            "auditor_fn_violation": 0.006659664811886404,
            "auditor_fp_violation": 0.012633291516387018,
            "ave_precision_score": 0.8289258885175875,
            "fpr": 0.11855104281009879,
            "logloss": 0.7267662383540859,
            "mae": 0.27547519669206283,
            "precision": 0.7615894039735099,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8230379632321188,
            "auditor_fn_violation": 0.006127845070925791,
            "auditor_fp_violation": 0.016658332291536442,
            "ave_precision_score": 0.8242974381401863,
            "fpr": 0.17214912280701755,
            "logloss": 0.7025902287645178,
            "mae": 0.3077940765253611,
            "precision": 0.7269565217391304,
            "recall": 0.8513238289205702
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7984699851192166,
            "auditor_fn_violation": 0.016908768044988892,
            "auditor_fp_violation": 0.014147522345930693,
            "ave_precision_score": 0.7988504216660326,
            "fpr": 0.18660812294182216,
            "logloss": 0.7531252775913081,
            "mae": 0.3160847899729936,
            "precision": 0.6964285714285714,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.831485324522244,
            "auditor_fn_violation": 0.014147193339764892,
            "auditor_fp_violation": 0.01889819560778431,
            "ave_precision_score": 0.8189246236379466,
            "fpr": 0.14583333333333334,
            "logloss": 1.5182549062284947,
            "mae": 0.26498291054640294,
            "precision": 0.7550644567219152,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8218207823129104,
            "auditor_fn_violation": 0.003269376210605677,
            "auditor_fp_violation": 0.012937117766975072,
            "ave_precision_score": 0.8074363663608085,
            "fpr": 0.1602634467618002,
            "logloss": 1.49307563420103,
            "mae": 0.26713843216213873,
            "precision": 0.7306273062730627,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8055304987504914,
            "auditor_fn_violation": 0.014055632972451503,
            "auditor_fp_violation": 0.014108534400133352,
            "ave_precision_score": 0.7801896707829469,
            "fpr": 0.09649122807017543,
            "logloss": 2.8596938366810822,
            "mae": 0.28487575048860736,
            "precision": 0.7843137254901961,
            "recall": 0.6517311608961304
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7710969024749419,
            "auditor_fn_violation": 0.009891107723456775,
            "auditor_fp_violation": 0.007835777011133764,
            "ave_precision_score": 0.7421420036232583,
            "fpr": 0.1119648737650933,
            "logloss": 2.962518611516702,
            "mae": 0.29325699590009485,
            "precision": 0.751219512195122,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8190780574683777,
            "auditor_fn_violation": 0.016719816343302246,
            "auditor_fp_violation": 0.013585031462266115,
            "ave_precision_score": 0.8153217757544804,
            "fpr": 0.11513157894736842,
            "logloss": 0.9968053325066559,
            "mae": 0.2596506612910401,
            "precision": 0.7878787878787878,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7838715463097198,
            "auditor_fn_violation": 0.009658766266865506,
            "auditor_fp_violation": 0.019119001881762594,
            "ave_precision_score": 0.7753393943282334,
            "fpr": 0.14818880351262348,
            "logloss": 1.1764029262508258,
            "mae": 0.2811171828098726,
            "precision": 0.7261663286004056,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7943751941485907,
            "auditor_fn_violation": 0.005801800836102478,
            "auditor_fp_violation": 0.030045422344459737,
            "ave_precision_score": 0.7972989733480598,
            "fpr": 0.26973684210526316,
            "logloss": 0.8870101372782264,
            "mae": 0.3466469102208258,
            "precision": 0.6419213973799127,
            "recall": 0.8981670061099797
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7761811751144994,
            "auditor_fn_violation": 0.007506051546611726,
            "auditor_fp_violation": 0.03610631958601223,
            "ave_precision_score": 0.7766209812645541,
            "fpr": 0.29418221734357847,
            "logloss": 0.944138578606144,
            "mae": 0.3588374315931755,
            "precision": 0.60932944606414,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8590145124923143,
            "auditor_fn_violation": 0.01176885696930718,
            "auditor_fp_violation": 0.013361045130641331,
            "ave_precision_score": 0.8592240910638597,
            "fpr": 0.1074561403508772,
            "logloss": 0.697771746759756,
            "mae": 0.26842700599048586,
            "precision": 0.7869565217391304,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8295135319114566,
            "auditor_fn_violation": 0.00926283745818447,
            "auditor_fp_violation": 0.011969284146150231,
            "ave_precision_score": 0.8301138019713394,
            "fpr": 0.11745334796926454,
            "logloss": 0.7190415061689828,
            "mae": 0.2750345216799519,
            "precision": 0.7637969094922737,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8027361987780537,
            "auditor_fn_violation": 0.013258387822917786,
            "auditor_fp_violation": 0.015324832270700509,
            "ave_precision_score": 0.7774226723333088,
            "fpr": 0.10087719298245613,
            "logloss": 2.930458940077357,
            "mae": 0.2790258397931245,
            "precision": 0.7909090909090909,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7788679992933197,
            "auditor_fn_violation": 0.008053713551434015,
            "auditor_fp_violation": 0.011466990748000633,
            "ave_precision_score": 0.7505970960405822,
            "fpr": 0.1119648737650933,
            "logloss": 2.9137569980091085,
            "mae": 0.2820725831991721,
            "precision": 0.7638888888888888,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7544018011034266,
            "auditor_fn_violation": 0.05132740200807519,
            "auditor_fp_violation": 0.04681835229403675,
            "ave_precision_score": 0.7550229197219738,
            "fpr": 0.1699561403508772,
            "logloss": 1.6634655707985149,
            "mae": 0.3684483390622727,
            "precision": 0.7113594040968343,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6883112393230755,
            "auditor_fn_violation": 0.04746878208030954,
            "auditor_fp_violation": 0.0543848988552611,
            "ave_precision_score": 0.6896955210298191,
            "fpr": 0.19538968166849616,
            "logloss": 1.754403403351765,
            "mae": 0.37654450714093574,
            "precision": 0.6660412757973734,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8396491114743294,
            "auditor_fn_violation": 0.022945921320613145,
            "auditor_fp_violation": 0.014077280493395012,
            "ave_precision_score": 0.8400206604906357,
            "fpr": 0.1162280701754386,
            "logloss": 1.1613259762227908,
            "mae": 0.26205434218216705,
            "precision": 0.7827868852459017,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7996599619732015,
            "auditor_fn_violation": 0.01698937630543892,
            "auditor_fp_violation": 0.027917712090324606,
            "ave_precision_score": 0.8001705659482485,
            "fpr": 0.150384193194292,
            "logloss": 1.1868597528567082,
            "mae": 0.2857850419787432,
            "precision": 0.7198364008179959,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 14724,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8511131264649466,
            "auditor_fn_violation": 0.02082440061457106,
            "auditor_fp_violation": 0.017384985623202908,
            "ave_precision_score": 0.851338010415115,
            "fpr": 0.09429824561403509,
            "logloss": 0.9173827599389691,
            "mae": 0.2728369006291842,
            "precision": 0.8022988505747126,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8202399331428887,
            "auditor_fn_violation": 0.021209455823117028,
            "auditor_fp_violation": 0.020571977418848992,
            "ave_precision_score": 0.821007306697487,
            "fpr": 0.10976948408342481,
            "logloss": 0.9033424642426203,
            "mae": 0.2783262981092378,
            "precision": 0.76905311778291,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8597459301359994,
            "auditor_fn_violation": 0.010598670811448177,
            "auditor_fp_violation": 0.01336104513064133,
            "ave_precision_score": 0.8599134689370461,
            "fpr": 0.10526315789473684,
            "logloss": 0.7373644454011156,
            "mae": 0.2804618065727361,
            "precision": 0.7903930131004366,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.820136229693643,
            "auditor_fn_violation": 0.008890616961400507,
            "auditor_fp_violation": 0.019128802728555754,
            "ave_precision_score": 0.8204416395635235,
            "fpr": 0.141602634467618,
            "logloss": 0.7783567938656062,
            "mae": 0.2976497787198518,
            "precision": 0.7195652173913043,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8186429282150125,
            "auditor_fn_violation": 0.015728284560688897,
            "auditor_fp_violation": 0.0208515647789307,
            "ave_precision_score": 0.8150087477857635,
            "fpr": 0.13157894736842105,
            "logloss": 0.9923106580747741,
            "mae": 0.2593255772529479,
            "precision": 0.7705544933078394,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7867233679158384,
            "auditor_fn_violation": 0.006368052575552465,
            "auditor_fp_violation": 0.02097626234906696,
            "ave_precision_score": 0.779683474864153,
            "fpr": 0.16136114160263446,
            "logloss": 1.136756292516827,
            "mae": 0.27915249627674604,
            "precision": 0.7189292543021033,
            "recall": 0.8120950323974082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8456039196910252,
            "auditor_fn_violation": 0.030904973737806835,
            "auditor_fp_violation": 0.02064841438513148,
            "ave_precision_score": 0.845916645352726,
            "fpr": 0.1074561403508772,
            "logloss": 1.1044842121111342,
            "mae": 0.26379357477540055,
            "precision": 0.7910447761194029,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7993584752397886,
            "auditor_fn_violation": 0.019405253287750158,
            "auditor_fp_violation": 0.029392739532695628,
            "ave_precision_score": 0.7999879874464326,
            "fpr": 0.13611416026344675,
            "logloss": 1.1689576041050338,
            "mae": 0.2844129602896912,
            "precision": 0.734475374732334,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.827361942681176,
            "auditor_fn_violation": 0.009584807231929109,
            "auditor_fp_violation": 0.014048631078884863,
            "ave_precision_score": 0.8286006557110334,
            "fpr": 0.12609649122807018,
            "logloss": 0.8148773456641087,
            "mae": 0.2731073177958681,
            "precision": 0.766260162601626,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8069222988604955,
            "auditor_fn_violation": 0.0037198341366499717,
            "auditor_fp_violation": 0.016881958601223147,
            "ave_precision_score": 0.8085152570756118,
            "fpr": 0.141602634467618,
            "logloss": 0.7980997374260111,
            "mae": 0.2818222549707574,
            "precision": 0.7329192546583851,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8196876870222054,
            "auditor_fn_violation": 0.014926573051774042,
            "auditor_fp_violation": 0.00802183606284119,
            "ave_precision_score": 0.8198997237687454,
            "fpr": 0.07017543859649122,
            "logloss": 2.0350315707445046,
            "mae": 0.3085187339230618,
            "precision": 0.8160919540229885,
            "recall": 0.5784114052953157
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7875385896853442,
            "auditor_fn_violation": 0.009144295898699131,
            "auditor_fp_violation": 0.007850478281323509,
            "ave_precision_score": 0.7883355366088477,
            "fpr": 0.06805708013172337,
            "logloss": 1.9598167811228102,
            "mae": 0.3132080331672286,
            "precision": 0.8012820512820513,
            "recall": 0.5399568034557235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8373379008537767,
            "auditor_fn_violation": 0.03535793404080466,
            "auditor_fp_violation": 0.02714662249447848,
            "ave_precision_score": 0.8375454460975875,
            "fpr": 0.13486842105263158,
            "logloss": 1.3797514879340973,
            "mae": 0.278087519232298,
            "precision": 0.7569169960474308,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7867923488558113,
            "auditor_fn_violation": 0.022148304974240925,
            "auditor_fp_violation": 0.04503489101458367,
            "ave_precision_score": 0.7872588076321719,
            "fpr": 0.18221734357848518,
            "logloss": 1.5518739317136345,
            "mae": 0.3068389054624932,
            "precision": 0.6813819577735125,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 14724,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8318670736449788,
            "auditor_fn_violation": 0.024891020831100157,
            "auditor_fp_violation": 0.020552048172688263,
            "ave_precision_score": 0.8321880168529993,
            "fpr": 0.10964912280701754,
            "logloss": 1.1522607175071466,
            "mae": 0.277852625974928,
            "precision": 0.7811816192560175,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7966296514801969,
            "auditor_fn_violation": 0.016991747136628634,
            "auditor_fp_violation": 0.026741610475145054,
            "ave_precision_score": 0.797058527314596,
            "fpr": 0.14270032930845225,
            "logloss": 1.1804160909248338,
            "mae": 0.2947311055369928,
            "precision": 0.723404255319149,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8489482895118082,
            "auditor_fn_violation": 0.035125683352985326,
            "auditor_fp_violation": 0.019343563778805688,
            "ave_precision_score": 0.8491942217277053,
            "fpr": 0.1074561403508772,
            "logloss": 1.244380537158936,
            "mae": 0.2708182223062376,
            "precision": 0.7850877192982456,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8070509207345822,
            "auditor_fn_violation": 0.023155908229866313,
            "auditor_fp_violation": 0.029397639956092205,
            "ave_precision_score": 0.807768353350609,
            "fpr": 0.13721185510428102,
            "logloss": 1.3096681338350789,
            "mae": 0.28954835408958424,
            "precision": 0.7306034482758621,
            "recall": 0.7321814254859611
        }
    }
]