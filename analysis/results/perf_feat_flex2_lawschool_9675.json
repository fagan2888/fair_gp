[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7018757911150262,
            "auditor_fn_violation": 0.014783174010182027,
            "auditor_fp_violation": 0.016791762894534268,
            "ave_precision_score": 0.6949264302952047,
            "fpr": 0.13706140350877194,
            "logloss": 1.8395555678267232,
            "mae": 0.32819236483151726,
            "precision": 0.7139588100686499,
            "recall": 0.651356993736952
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.700589045860897,
            "auditor_fn_violation": 0.019638338436651456,
            "auditor_fp_violation": 0.009416006203486444,
            "ave_precision_score": 0.6932672871563474,
            "fpr": 0.13611416026344675,
            "logloss": 1.844920699844316,
            "mae": 0.32248170425481465,
            "precision": 0.7168949771689498,
            "recall": 0.6610526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8352776974058623,
            "auditor_fn_violation": 0.011097681573453467,
            "auditor_fp_violation": 0.004023844252663998,
            "ave_precision_score": 0.8360828448531447,
            "fpr": 0.15021929824561403,
            "logloss": 0.5370688142246437,
            "mae": 0.3173445035259615,
            "precision": 0.7410207939508506,
            "recall": 0.8183716075156576
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8624973035675625,
            "auditor_fn_violation": 0.004171240395170143,
            "auditor_fp_violation": 0.012004149085086459,
            "ave_precision_score": 0.8626906114961383,
            "fpr": 0.13172338090010977,
            "logloss": 0.49087083073588006,
            "mae": 0.306108946210895,
            "precision": 0.76,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.5822162475988883,
            "auditor_fn_violation": 0.013975112624986265,
            "auditor_fp_violation": 0.01877203111705361,
            "ave_precision_score": 0.580195856298624,
            "fpr": 0.2993421052631579,
            "logloss": 1.6947776599036102,
            "mae": 0.404899584136601,
            "precision": 0.6026200873362445,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6267073555751785,
            "auditor_fn_violation": 0.006276503553064879,
            "auditor_fp_violation": 0.01722071722776665,
            "ave_precision_score": 0.6281042711801494,
            "fpr": 0.29418221734357847,
            "logloss": 1.538787311649296,
            "mae": 0.3823760382557118,
            "precision": 0.6098981077147017,
            "recall": 0.8821052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7970731149071066,
            "auditor_fn_violation": 0.009012288026956744,
            "auditor_fp_violation": 0.022583161136096597,
            "ave_precision_score": 0.7976310164824599,
            "fpr": 0.18092105263157895,
            "logloss": 0.8592995703468579,
            "mae": 0.2749845079617553,
            "precision": 0.7125435540069687,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8129825897895759,
            "auditor_fn_violation": 0.012580738344213997,
            "auditor_fp_violation": 0.029023454415452322,
            "ave_precision_score": 0.8137811881833885,
            "fpr": 0.19319429198682767,
            "logloss": 0.8752885347726191,
            "mae": 0.29261586311613663,
            "precision": 0.6912280701754386,
            "recall": 0.8294736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7412737039458508,
            "auditor_fn_violation": 0.014057521151521816,
            "auditor_fp_violation": 0.015454701997487951,
            "ave_precision_score": 0.7409799588544908,
            "fpr": 0.11732456140350878,
            "logloss": 1.1266567317971765,
            "mae": 0.29730563377244584,
            "precision": 0.759009009009009,
            "recall": 0.7035490605427975
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7508180872308159,
            "auditor_fn_violation": 0.017232653532844186,
            "auditor_fp_violation": 0.018625565212137086,
            "ave_precision_score": 0.7505070654748617,
            "fpr": 0.1251372118551043,
            "logloss": 1.1659150258433988,
            "mae": 0.3070982252229537,
            "precision": 0.7426636568848759,
            "recall": 0.6926315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7005509916031656,
            "auditor_fn_violation": 0.012587902428304584,
            "auditor_fp_violation": 0.018830274300068887,
            "ave_precision_score": 0.6940464455410028,
            "fpr": 0.14802631578947367,
            "logloss": 1.7620647494384434,
            "mae": 0.32589440366670297,
            "precision": 0.709051724137931,
            "recall": 0.6868475991649269
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7040226205071176,
            "auditor_fn_violation": 0.013939569010341444,
            "auditor_fp_violation": 0.009234735495825739,
            "ave_precision_score": 0.696869095715801,
            "fpr": 0.1525795828759605,
            "logloss": 1.7413923166651368,
            "mae": 0.31575130346290037,
            "precision": 0.707983193277311,
            "recall": 0.7094736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8390329172930039,
            "auditor_fn_violation": 0.031633428560964,
            "auditor_fp_violation": 0.025877699444917145,
            "ave_precision_score": 0.8393865388785454,
            "fpr": 0.125,
            "logloss": 0.7493586970678341,
            "mae": 0.2660454550705986,
            "precision": 0.7639751552795031,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8444342467798875,
            "auditor_fn_violation": 0.01738979721532151,
            "auditor_fp_violation": 0.024667922134160473,
            "ave_precision_score": 0.8447248336335792,
            "fpr": 0.12843029637760703,
            "logloss": 0.7430214422370177,
            "mae": 0.271889992047684,
            "precision": 0.7547169811320755,
            "recall": 0.7578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8180754986852372,
            "auditor_fn_violation": 0.01842059480643153,
            "auditor_fp_violation": 0.019797617600583448,
            "ave_precision_score": 0.8185376322744413,
            "fpr": 0.17543859649122806,
            "logloss": 0.7954988125710039,
            "mae": 0.2728536389986094,
            "precision": 0.7183098591549296,
            "recall": 0.8517745302713987
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8273289575422276,
            "auditor_fn_violation": 0.016054075914264256,
            "auditor_fp_violation": 0.028560207051430534,
            "ave_precision_score": 0.8275911715939973,
            "fpr": 0.18660812294182216,
            "logloss": 0.8534851081271996,
            "mae": 0.28816805791625366,
            "precision": 0.697508896797153,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7521121211629681,
            "auditor_fn_violation": 0.011665384756253889,
            "auditor_fp_violation": 0.022952878732628346,
            "ave_precision_score": 0.7528085618707054,
            "fpr": 0.13706140350877194,
            "logloss": 0.9136913528794869,
            "mae": 0.2861532927766904,
            "precision": 0.745417515274949,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7631568458970229,
            "auditor_fn_violation": 0.016176555549136294,
            "auditor_fp_violation": 0.01988942486832698,
            "ave_precision_score": 0.7629872025411053,
            "fpr": 0.14928649835345773,
            "logloss": 0.961058099280004,
            "mae": 0.2993123512595933,
            "precision": 0.720164609053498,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7207022444480089,
            "auditor_fn_violation": 0.01202706662271546,
            "auditor_fp_violation": 0.017553988898342858,
            "ave_precision_score": 0.7180315141339162,
            "fpr": 0.12719298245614036,
            "logloss": 1.2750874770131433,
            "mae": 0.31402843301013916,
            "precision": 0.7339449541284404,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7160422985515378,
            "auditor_fn_violation": 0.020149055404702763,
            "auditor_fp_violation": 0.02205460276538536,
            "ave_precision_score": 0.712530760342003,
            "fpr": 0.13611416026344675,
            "logloss": 1.3480382351611573,
            "mae": 0.31881219678615735,
            "precision": 0.7274725274725274,
            "recall": 0.6968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6581626658754434,
            "auditor_fn_violation": 0.01631002087682672,
            "auditor_fp_violation": 0.017794558567318992,
            "ave_precision_score": 0.6490854523135299,
            "fpr": 0.15021929824561403,
            "logloss": 2.8274578321147814,
            "mae": 0.35960192513933276,
            "precision": 0.6828703703703703,
            "recall": 0.615866388308977
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6690126004778152,
            "auditor_fn_violation": 0.012416661852215608,
            "auditor_fp_violation": 0.013753914943755734,
            "ave_precision_score": 0.6569045428872852,
            "fpr": 0.150384193194292,
            "logloss": 2.7566277640038273,
            "mae": 0.35004388618984916,
            "precision": 0.6872146118721462,
            "recall": 0.6336842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7832101262169195,
            "auditor_fn_violation": 0.009792879903307329,
            "auditor_fp_violation": 0.022405899274745757,
            "ave_precision_score": 0.7838016873680866,
            "fpr": 0.13596491228070176,
            "logloss": 0.7511263055492157,
            "mae": 0.2838665724594227,
            "precision": 0.7529880478087649,
            "recall": 0.7891440501043842
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7991549638256934,
            "auditor_fn_violation": 0.015531804263677855,
            "auditor_fp_violation": 0.02102236679120636,
            "ave_precision_score": 0.7993084042787147,
            "fpr": 0.14709110867178923,
            "logloss": 0.7576718006705767,
            "mae": 0.2924546062143592,
            "precision": 0.7309236947791165,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8585581959334789,
            "auditor_fn_violation": 0.02081502032743655,
            "auditor_fp_violation": 0.00762985697500102,
            "ave_precision_score": 0.8588221486931858,
            "fpr": 0.10964912280701754,
            "logloss": 0.50032666858272,
            "mae": 0.314298531033401,
            "precision": 0.7844827586206896,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8656221468040595,
            "auditor_fn_violation": 0.013304061470911087,
            "auditor_fp_violation": 0.016425140233033562,
            "ave_precision_score": 0.8658102875042459,
            "fpr": 0.10428100987925357,
            "logloss": 0.48445607265930696,
            "mae": 0.3075831581324208,
            "precision": 0.7916666666666666,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8426815060911407,
            "auditor_fn_violation": 0.030106581694319307,
            "auditor_fp_violation": 0.0320970584660265,
            "ave_precision_score": 0.8431402187023894,
            "fpr": 0.14364035087719298,
            "logloss": 0.6727548201126184,
            "mae": 0.26233001747290885,
            "precision": 0.7456310679611651,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8528167931620001,
            "auditor_fn_violation": 0.01970535559535502,
            "auditor_fp_violation": 0.025866322923695104,
            "ave_precision_score": 0.8530603123966127,
            "fpr": 0.141602634467618,
            "logloss": 0.6747541474041565,
            "mae": 0.2643019263066876,
            "precision": 0.7470588235294118,
            "recall": 0.8021052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.835398316006412,
            "auditor_fn_violation": 0.022476925612570052,
            "auditor_fp_violation": 0.025682711397431224,
            "ave_precision_score": 0.8357762517027609,
            "fpr": 0.11732456140350878,
            "logloss": 0.7567662815466522,
            "mae": 0.26797131865685075,
            "precision": 0.7742616033755274,
            "recall": 0.7661795407098121
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8408921860745673,
            "auditor_fn_violation": 0.011903633947657291,
            "auditor_fp_violation": 0.0216794731064764,
            "ave_precision_score": 0.841287636242287,
            "fpr": 0.11964873765093303,
            "logloss": 0.786045503248349,
            "mae": 0.27238477794514526,
            "precision": 0.7685774946921444,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.726215700405723,
            "auditor_fn_violation": 0.01171803464820716,
            "auditor_fp_violation": 0.018174405413070794,
            "ave_precision_score": 0.7267420631216434,
            "fpr": 0.13486842105263158,
            "logloss": 1.330486025376991,
            "mae": 0.3094393265041892,
            "precision": 0.7260579064587973,
            "recall": 0.6805845511482255
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7273015385733597,
            "auditor_fn_violation": 0.014138309549945124,
            "auditor_fp_violation": 0.007135016465422622,
            "ave_precision_score": 0.7261726296674788,
            "fpr": 0.1394072447859495,
            "logloss": 1.3527716897042166,
            "mae": 0.305492510331172,
            "precision": 0.7292110874200426,
            "recall": 0.72
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7011435307742073,
            "auditor_fn_violation": 0.018924202468593207,
            "auditor_fp_violation": 0.01525718163769702,
            "ave_precision_score": 0.6943934415391202,
            "fpr": 0.1337719298245614,
            "logloss": 1.8594278833558133,
            "mae": 0.32950503232058226,
            "precision": 0.7136150234741784,
            "recall": 0.6346555323590815
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7008719116974431,
            "auditor_fn_violation": 0.021168178404298348,
            "auditor_fp_violation": 0.011100313195500462,
            "ave_precision_score": 0.6942472636988722,
            "fpr": 0.132821075740944,
            "logloss": 1.8293586488834521,
            "mae": 0.3228401073207476,
            "precision": 0.7192575406032483,
            "recall": 0.6526315789473685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 9675,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.782881661986312,
            "auditor_fn_violation": 0.011122861956561555,
            "auditor_fp_violation": 0.014218933592642117,
            "ave_precision_score": 0.7831354056059879,
            "fpr": 0.14144736842105263,
            "logloss": 0.9488068349954548,
            "mae": 0.27402427430205656,
            "precision": 0.7465618860510805,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7840810412434313,
            "auditor_fn_violation": 0.01330406147091109,
            "auditor_fp_violation": 0.02032246044773865,
            "ave_precision_score": 0.7853503651036737,
            "fpr": 0.14050493962678376,
            "logloss": 1.0105915849486728,
            "mae": 0.28542587412721243,
            "precision": 0.7382413087934561,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6662068144376311,
            "auditor_fn_violation": 0.03589349155770428,
            "auditor_fp_violation": 0.030081337871236985,
            "ave_precision_score": 0.6672926845548873,
            "fpr": 0.09649122807017543,
            "logloss": 1.0888044875560452,
            "mae": 0.4077605845957904,
            "precision": 0.707641196013289,
            "recall": 0.44467640918580376
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.66828990103543,
            "auditor_fn_violation": 0.029570743543821134,
            "auditor_fp_violation": 0.02776463005669745,
            "ave_precision_score": 0.6685778875016485,
            "fpr": 0.09001097694840834,
            "logloss": 1.0497913926797702,
            "mae": 0.4015273567290246,
            "precision": 0.722972972972973,
            "recall": 0.45052631578947366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8335114890853299,
            "auditor_fn_violation": 0.039636212137860304,
            "auditor_fp_violation": 0.03094485636724606,
            "ave_precision_score": 0.8338287690844419,
            "fpr": 0.13925438596491227,
            "logloss": 0.6123215228225412,
            "mae": 0.31866485788468013,
            "precision": 0.7413441955193483,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8498442675607439,
            "auditor_fn_violation": 0.02636547460858513,
            "auditor_fp_violation": 0.031319550045821216,
            "ave_precision_score": 0.8500515300392552,
            "fpr": 0.12294182217343579,
            "logloss": 0.5584170851226289,
            "mae": 0.30311617926891576,
            "precision": 0.7622080679405521,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8395968934035476,
            "auditor_fn_violation": 0.015044134344211257,
            "auditor_fp_violation": 0.01547749280823306,
            "ave_precision_score": 0.8400322922894774,
            "fpr": 0.12171052631578948,
            "logloss": 0.6777435775925195,
            "mae": 0.26641878937939156,
            "precision": 0.7711340206185567,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8501401748826207,
            "auditor_fn_violation": 0.015783696342942986,
            "auditor_fp_violation": 0.01711497598163124,
            "ave_precision_score": 0.8503651127444859,
            "fpr": 0.1163556531284303,
            "logloss": 0.7201056338065549,
            "mae": 0.27090776429063695,
            "precision": 0.7705627705627706,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6565528058493008,
            "auditor_fn_violation": 0.020249606270373217,
            "auditor_fp_violation": 0.012327296300798188,
            "ave_precision_score": 0.6533232416071455,
            "fpr": 0.15679824561403508,
            "logloss": 1.4746444744650034,
            "mae": 0.3860980588064573,
            "precision": 0.6658878504672897,
            "recall": 0.5949895615866388
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6781411862175997,
            "auditor_fn_violation": 0.011448379455774453,
            "auditor_fp_violation": 0.010430618636642866,
            "ave_precision_score": 0.6740218051336093,
            "fpr": 0.13062568605927552,
            "logloss": 1.49550631996318,
            "mae": 0.357059169359982,
            "precision": 0.7173396674584323,
            "recall": 0.6357894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8338448811690611,
            "auditor_fn_violation": 0.04734140936893382,
            "auditor_fp_violation": 0.02497619626433289,
            "ave_precision_score": 0.8341754445970018,
            "fpr": 0.1162280701754386,
            "logloss": 0.6019669014926486,
            "mae": 0.3150184720600504,
            "precision": 0.7690631808278867,
            "recall": 0.7369519832985386
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8543617244379653,
            "auditor_fn_violation": 0.03772603847709285,
            "auditor_fp_violation": 0.030901620358714587,
            "ave_precision_score": 0.8545463673888032,
            "fpr": 0.10647639956092206,
            "logloss": 0.5598357849773393,
            "mae": 0.30136793713401666,
            "precision": 0.7795454545454545,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8238566097292819,
            "auditor_fn_violation": 0.030713200014650405,
            "auditor_fp_violation": 0.015477492808233056,
            "ave_precision_score": 0.8246531939425601,
            "fpr": 0.10307017543859649,
            "logloss": 0.6036760119127687,
            "mae": 0.3256159591622629,
            "precision": 0.7813953488372093,
            "recall": 0.7014613778705637
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8503793603290007,
            "auditor_fn_violation": 0.022711883990987357,
            "auditor_fp_violation": 0.01887229478645304,
            "ave_precision_score": 0.8505943088381365,
            "fpr": 0.08342480790340286,
            "logloss": 0.5541913506263201,
            "mae": 0.31133185798345114,
            "precision": 0.8123456790123457,
            "recall": 0.6926315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 9675,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8358886929759036,
            "auditor_fn_violation": 0.031926436655312605,
            "auditor_fp_violation": 0.025348446173169645,
            "ave_precision_score": 0.8362745387241197,
            "fpr": 0.12171052631578948,
            "logloss": 0.7653344840900369,
            "mae": 0.26750967617181237,
            "precision": 0.7653276955602537,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8420220566750107,
            "auditor_fn_violation": 0.01839274365936796,
            "auditor_fp_violation": 0.026619099890230518,
            "ave_precision_score": 0.8423199815132995,
            "fpr": 0.11964873765093303,
            "logloss": 0.7553805758466079,
            "mae": 0.2730696185873284,
            "precision": 0.7635574837310195,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8031232913053228,
            "auditor_fn_violation": 0.017553016152071204,
            "auditor_fp_violation": 0.026460131275069892,
            "ave_precision_score": 0.8035240604816052,
            "fpr": 0.10087719298245613,
            "logloss": 1.0958427204320929,
            "mae": 0.30865820214965184,
            "precision": 0.7676767676767676,
            "recall": 0.6346555323590815
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8322774772071313,
            "auditor_fn_violation": 0.012305736899878685,
            "auditor_fp_violation": 0.014846574487154958,
            "ave_precision_score": 0.832503863438673,
            "fpr": 0.09989023051591657,
            "logloss": 0.9975906113559104,
            "mae": 0.28889745486169444,
            "precision": 0.7753086419753087,
            "recall": 0.6610526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8221183610429448,
            "auditor_fn_violation": 0.015028110464051576,
            "auditor_fp_violation": 0.017480551841497514,
            "ave_precision_score": 0.823461508293237,
            "fpr": 0.13048245614035087,
            "logloss": 0.6485896274357723,
            "mae": 0.2652778874870133,
            "precision": 0.7634194831013916,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8287212160914142,
            "auditor_fn_violation": 0.011362874805014736,
            "auditor_fp_violation": 0.014511727207726161,
            "ave_precision_score": 0.8300589917617676,
            "fpr": 0.13172338090010977,
            "logloss": 0.6923596267606325,
            "mae": 0.2752861030281489,
            "precision": 0.754601226993865,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8553042144950938,
            "auditor_fn_violation": 0.004761381533164861,
            "auditor_fp_violation": 0.011856286212065966,
            "ave_precision_score": 0.8555149986922248,
            "fpr": 0.09320175438596491,
            "logloss": 0.5186464549209767,
            "mae": 0.3222206899359211,
            "precision": 0.8032407407407407,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8394841986376173,
            "auditor_fn_violation": 0.0066762955687792525,
            "auditor_fp_violation": 0.013016243869525376,
            "ave_precision_score": 0.8398038565841908,
            "fpr": 0.10428100987925357,
            "logloss": 0.5195684597378043,
            "mae": 0.3277505835062708,
            "precision": 0.7754137115839244,
            "recall": 0.6905263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 9675,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8097528468022857,
            "auditor_fn_violation": 0.021552118814782258,
            "auditor_fp_violation": 0.018647947814108022,
            "ave_precision_score": 0.8081184266975144,
            "fpr": 0.13925438596491227,
            "logloss": 0.8541821020066803,
            "mae": 0.26739217509748414,
            "precision": 0.7514677103718199,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.818170750174541,
            "auditor_fn_violation": 0.015943150961927326,
            "auditor_fp_violation": 0.01914420084794409,
            "ave_precision_score": 0.81586709805629,
            "fpr": 0.13172338090010977,
            "logloss": 0.904790879068761,
            "mae": 0.2743478700957945,
            "precision": 0.7556008146639511,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6440307472630701,
            "auditor_fn_violation": 0.013876680218291037,
            "auditor_fp_violation": 0.01775910619504883,
            "ave_precision_score": 0.629024578743299,
            "fpr": 0.15570175438596492,
            "logloss": 3.76584173058779,
            "mae": 0.3626041308833318,
            "precision": 0.6787330316742082,
            "recall": 0.6263048016701461
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6587451928233508,
            "auditor_fn_violation": 0.00733722340978682,
            "auditor_fp_violation": 0.00971812404958762,
            "ave_precision_score": 0.6422572185858026,
            "fpr": 0.15367727771679474,
            "logloss": 3.5379406568173617,
            "mae": 0.34606239592173,
            "precision": 0.6895787139689579,
            "recall": 0.6547368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8610009210275071,
            "auditor_fn_violation": 0.01596665201626195,
            "auditor_fp_violation": 0.012474170414488877,
            "ave_precision_score": 0.861232349353152,
            "fpr": 0.11513157894736842,
            "logloss": 0.5767002090885915,
            "mae": 0.2624789877327927,
            "precision": 0.7839506172839507,
            "recall": 0.7954070981210856
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8618354579224309,
            "auditor_fn_violation": 0.012227165058640015,
            "auditor_fp_violation": 0.010795677700681782,
            "ave_precision_score": 0.8620337396178345,
            "fpr": 0.1141602634467618,
            "logloss": 0.5994211277082809,
            "mae": 0.2669238869796003,
            "precision": 0.7787234042553192,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7026174183539691,
            "auditor_fn_violation": 0.07532368237922575,
            "auditor_fp_violation": 0.021154936996069854,
            "ave_precision_score": 0.699512877557602,
            "fpr": 0.09978070175438597,
            "logloss": 7.400511357308572,
            "mae": 0.36922027636470306,
            "precision": 0.7259036144578314,
            "recall": 0.5031315240083507
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7082611286718221,
            "auditor_fn_violation": 0.06318100410191231,
            "auditor_fp_violation": 0.02119356690399702,
            "ave_precision_score": 0.7049974980542072,
            "fpr": 0.09549945115257959,
            "logloss": 7.31386751881497,
            "mae": 0.3672706245212829,
            "precision": 0.7264150943396226,
            "recall": 0.4863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7088135917322625,
            "auditor_fn_violation": 0.015701113430758532,
            "auditor_fp_violation": 0.01579403184635955,
            "ave_precision_score": 0.7039915202433439,
            "fpr": 0.13486842105263158,
            "logloss": 1.6990920418156763,
            "mae": 0.3259680375332988,
            "precision": 0.7159353348729792,
            "recall": 0.6471816283924844
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7052270161414035,
            "auditor_fn_violation": 0.021884568721474377,
            "auditor_fp_violation": 0.01383196205399854,
            "ave_precision_score": 0.6997389181888978,
            "fpr": 0.13391877058177826,
            "logloss": 1.7077611257437666,
            "mae": 0.3217245732344273,
            "precision": 0.7175925925925926,
            "recall": 0.6526315789473685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7066663382294247,
            "auditor_fn_violation": 0.018152767095191005,
            "auditor_fp_violation": 0.016551193225558126,
            "ave_precision_score": 0.7004159451057692,
            "fpr": 0.14144736842105263,
            "logloss": 1.701866791076311,
            "mae": 0.3220578896149304,
            "precision": 0.7158590308370044,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7090266699666958,
            "auditor_fn_violation": 0.011762666820729102,
            "auditor_fp_violation": 0.010730218834026528,
            "ave_precision_score": 0.7019020779830365,
            "fpr": 0.14709110867178923,
            "logloss": 1.7140400032585883,
            "mae": 0.3133470023008349,
            "precision": 0.7130620985010707,
            "recall": 0.7010526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8205646499223859,
            "auditor_fn_violation": 0.005100172142255428,
            "auditor_fp_violation": 0.0160801831368259,
            "ave_precision_score": 0.820956985608384,
            "fpr": 0.13706140350877194,
            "logloss": 0.7532279252348772,
            "mae": 0.27588496207523244,
            "precision": 0.749498997995992,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8165771375956254,
            "auditor_fn_violation": 0.010283667456236642,
            "auditor_fp_violation": 0.01572019859213084,
            "ave_precision_score": 0.8169230322039506,
            "fpr": 0.1350164654226125,
            "logloss": 0.8399266375291938,
            "mae": 0.29069019865773305,
            "precision": 0.7426778242677824,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6835176386138785,
            "auditor_fn_violation": 0.021945848441563203,
            "auditor_fp_violation": 0.023416291884445526,
            "ave_precision_score": 0.6842569705559987,
            "fpr": 0.17543859649122806,
            "logloss": 1.0309170187810803,
            "mae": 0.378496244576906,
            "precision": 0.6741344195519349,
            "recall": 0.6910229645093946
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6832337608664774,
            "auditor_fn_violation": 0.010886821884568732,
            "auditor_fp_violation": 0.027860300707962818,
            "ave_precision_score": 0.6822282050604149,
            "fpr": 0.1734357848518112,
            "logloss": 1.024155574943021,
            "mae": 0.3703665792020027,
            "precision": 0.680161943319838,
            "recall": 0.7073684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8299956030872613,
            "auditor_fn_violation": 0.011326594147163317,
            "auditor_fp_violation": 0.01632581743041206,
            "ave_precision_score": 0.8302270170832591,
            "fpr": 0.11842105263157894,
            "logloss": 0.5541875469437111,
            "mae": 0.3332230184700038,
            "precision": 0.7594654788418709,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8373864465938969,
            "auditor_fn_violation": 0.018309549945115265,
            "auditor_fp_violation": 0.018217706119900503,
            "ave_precision_score": 0.8376382694604638,
            "fpr": 0.09659714599341383,
            "logloss": 0.5324548985946297,
            "mae": 0.32464468605002605,
            "precision": 0.7858880778588808,
            "recall": 0.68
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8417056104287669,
            "auditor_fn_violation": 0.01895396110317548,
            "auditor_fp_violation": 0.009420201774644464,
            "ave_precision_score": 0.8420606394237119,
            "fpr": 0.09758771929824561,
            "logloss": 0.5340462807390877,
            "mae": 0.3157733069156325,
            "precision": 0.7995495495495496,
            "recall": 0.7411273486430062
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8551987081316073,
            "auditor_fn_violation": 0.026698249465595944,
            "auditor_fp_violation": 0.009919535946988392,
            "ave_precision_score": 0.8553865680474202,
            "fpr": 0.08342480790340286,
            "logloss": 0.5249262233927899,
            "mae": 0.3134255894577445,
            "precision": 0.81,
            "recall": 0.6821052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7400247806601699,
            "auditor_fn_violation": 0.019118778156246567,
            "auditor_fp_violation": 0.019346866010291317,
            "ave_precision_score": 0.7191004123547824,
            "fpr": 0.15899122807017543,
            "logloss": 2.1827133236860172,
            "mae": 0.31066643191554294,
            "precision": 0.7117296222664016,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7591259243206547,
            "auditor_fn_violation": 0.013012883471026637,
            "auditor_fp_violation": 0.015065609925578306,
            "ave_precision_score": 0.7371697677430795,
            "fpr": 0.1668496158068057,
            "logloss": 2.1779926996933745,
            "mae": 0.3067935464115988,
            "precision": 0.7019607843137254,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7857512525877066,
            "auditor_fn_violation": 0.010454437241328792,
            "auditor_fp_violation": 0.020980207447024026,
            "ave_precision_score": 0.7861536382361293,
            "fpr": 0.18421052631578946,
            "logloss": 0.9137934524234437,
            "mae": 0.2767209475065724,
            "precision": 0.708838821490468,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8073946925119859,
            "auditor_fn_violation": 0.00889710555202496,
            "auditor_fp_violation": 0.026989194251704457,
            "ave_precision_score": 0.8076766642240228,
            "fpr": 0.19758507135016465,
            "logloss": 0.9317802028938624,
            "mae": 0.29731656791586486,
            "precision": 0.686411149825784,
            "recall": 0.8294736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 9675,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8205837311592031,
            "auditor_fn_violation": 0.015417261839358317,
            "auditor_fp_violation": 0.02042816336453142,
            "ave_precision_score": 0.8210532242485363,
            "fpr": 0.12390350877192982,
            "logloss": 0.733102067435677,
            "mae": 0.2746225981693451,
            "precision": 0.7631027253668763,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8308281029939939,
            "auditor_fn_violation": 0.014773817089375479,
            "auditor_fp_violation": 0.019033424304373662,
            "ave_precision_score": 0.831114038538591,
            "fpr": 0.12294182217343579,
            "logloss": 0.7895222115191334,
            "mae": 0.28228989115824493,
            "precision": 0.7570498915401301,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8334876370192217,
            "auditor_fn_violation": 0.04143775409295682,
            "auditor_fp_violation": 0.03094485636724606,
            "ave_precision_score": 0.8338160284334466,
            "fpr": 0.13925438596491227,
            "logloss": 0.6118011028997079,
            "mae": 0.3187120199495626,
            "precision": 0.7408163265306122,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8496257695942,
            "auditor_fn_violation": 0.02636547460858513,
            "auditor_fp_violation": 0.031452985427849224,
            "ave_precision_score": 0.8498368998178618,
            "fpr": 0.12403951701427003,
            "logloss": 0.5581060134739703,
            "mae": 0.3032564676630169,
            "precision": 0.760593220338983,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8459267040426237,
            "auditor_fn_violation": 0.014815221770501416,
            "auditor_fp_violation": 0.00992159961103683,
            "ave_precision_score": 0.8462365471714919,
            "fpr": 0.12938596491228072,
            "logloss": 0.6194674516480788,
            "mae": 0.26586245111887835,
            "precision": 0.7630522088353414,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8517568264956151,
            "auditor_fn_violation": 0.01291813507423884,
            "auditor_fp_violation": 0.013595303074552615,
            "ave_precision_score": 0.8519848400286262,
            "fpr": 0.12733260153677278,
            "logloss": 0.6574880654587386,
            "mae": 0.27291834544485166,
            "precision": 0.7578288100208769,
            "recall": 0.7642105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7281354657900314,
            "auditor_fn_violation": 0.01609484305753947,
            "auditor_fp_violation": 0.01698675094202018,
            "ave_precision_score": 0.7261799182495634,
            "fpr": 0.12280701754385964,
            "logloss": 1.2907040512303185,
            "mae": 0.3095852828287806,
            "precision": 0.7413394919168591,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7322622166804238,
            "auditor_fn_violation": 0.02204633427696575,
            "auditor_fp_violation": 0.015194010010171299,
            "ave_precision_score": 0.7299035715754723,
            "fpr": 0.12843029637760703,
            "logloss": 1.2963954175606969,
            "mae": 0.31061458983316237,
            "precision": 0.7376681614349776,
            "recall": 0.6926315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6562325171085011,
            "auditor_fn_violation": 0.013512709226092379,
            "auditor_fp_violation": 0.009344232405494108,
            "ave_precision_score": 0.6519038915744497,
            "fpr": 0.1513157894736842,
            "logloss": 1.6190367653100908,
            "mae": 0.37809225388319234,
            "precision": 0.677570093457944,
            "recall": 0.605427974947808
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6778582126868163,
            "auditor_fn_violation": 0.008661390028308983,
            "auditor_fp_violation": 0.018046506007109844,
            "ave_precision_score": 0.6725094950306065,
            "fpr": 0.13391877058177826,
            "logloss": 1.5860201722607667,
            "mae": 0.35283089913340193,
            "precision": 0.7102137767220903,
            "recall": 0.6294736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.745597460792347,
            "auditor_fn_violation": 0.007879170787092991,
            "auditor_fp_violation": 0.02498379320124793,
            "ave_precision_score": 0.7458213775921494,
            "fpr": 0.14912280701754385,
            "logloss": 0.9831037889051629,
            "mae": 0.2982751174191204,
            "precision": 0.7333333333333333,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.767626827372139,
            "auditor_fn_violation": 0.014011208042059051,
            "auditor_fp_violation": 0.019839071893976785,
            "ave_precision_score": 0.7672668378942198,
            "fpr": 0.16245883644346873,
            "logloss": 0.9800237689138719,
            "mae": 0.3023580194275982,
            "precision": 0.7137330754352031,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.700020302404678,
            "auditor_fn_violation": 0.010772625718785483,
            "auditor_fp_violation": 0.014598780438393907,
            "ave_precision_score": 0.6940614122059852,
            "fpr": 0.13706140350877194,
            "logloss": 1.6374416467007362,
            "mae": 0.32618763904043396,
            "precision": 0.7203579418344519,
            "recall": 0.6722338204592901
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7014766564476063,
            "auditor_fn_violation": 0.012841874169507193,
            "auditor_fp_violation": 0.008779041077956488,
            "ave_precision_score": 0.6946202630870439,
            "fpr": 0.1437980241492865,
            "logloss": 1.656045961410648,
            "mae": 0.3201105047670019,
            "precision": 0.7139737991266376,
            "recall": 0.6884210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8511963745315518,
            "auditor_fn_violation": 0.01034684833168517,
            "auditor_fp_violation": 0.014697540618289377,
            "ave_precision_score": 0.8515030334412842,
            "fpr": 0.13486842105263158,
            "logloss": 0.5978796083663888,
            "mae": 0.25915254217802275,
            "precision": 0.763915547024952,
            "recall": 0.8308977035490606
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8558718294268194,
            "auditor_fn_violation": 0.009583453694609743,
            "auditor_fp_violation": 0.01529219831015419,
            "ave_precision_score": 0.8561124744447528,
            "fpr": 0.13830954994511527,
            "logloss": 0.6298074829448588,
            "mae": 0.26781433669775473,
            "precision": 0.749003984063745,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.85746022103629,
            "auditor_fn_violation": 0.0041524740870966595,
            "auditor_fp_violation": 0.012785644828005349,
            "ave_precision_score": 0.857649827119966,
            "fpr": 0.10635964912280702,
            "logloss": 0.5261475767344725,
            "mae": 0.3253506366750219,
            "precision": 0.7904967602591793,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8498372265693379,
            "auditor_fn_violation": 0.0009220636663007722,
            "auditor_fp_violation": 0.012054502059436652,
            "ave_precision_score": 0.8500478660368186,
            "fpr": 0.10976948408342481,
            "logloss": 0.5191895319269533,
            "mae": 0.32632408819479036,
            "precision": 0.7737556561085973,
            "recall": 0.72
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7465390272671208,
            "auditor_fn_violation": 0.01810698458044904,
            "auditor_fp_violation": 0.020790284024148138,
            "ave_precision_score": 0.7452785163096363,
            "fpr": 0.12609649122807018,
            "logloss": 1.1488838683925775,
            "mae": 0.2950634687022073,
            "precision": 0.7483588621444202,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7574945161580724,
            "auditor_fn_violation": 0.016745045929863075,
            "auditor_fp_violation": 0.014635091994884138,
            "ave_precision_score": 0.7571261515486499,
            "fpr": 0.132821075740944,
            "logloss": 1.1296909126918402,
            "mae": 0.3014128996348024,
            "precision": 0.7369565217391304,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7062034052985324,
            "auditor_fn_violation": 0.018152767095191005,
            "auditor_fp_violation": 0.016551193225558126,
            "ave_precision_score": 0.6999688696499484,
            "fpr": 0.14144736842105263,
            "logloss": 1.6984342330973812,
            "mae": 0.32234076417338736,
            "precision": 0.7158590308370044,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7085478322390062,
            "auditor_fn_violation": 0.011762666820729102,
            "auditor_fp_violation": 0.010730218834026528,
            "ave_precision_score": 0.701415379459623,
            "fpr": 0.14709110867178923,
            "logloss": 1.71168672134963,
            "mae": 0.31357569335565083,
            "precision": 0.7130620985010707,
            "recall": 0.7010526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6345774737069954,
            "auditor_fn_violation": 0.04800525583269238,
            "auditor_fp_violation": 0.018420039706656944,
            "ave_precision_score": 0.6312645353900174,
            "fpr": 0.12828947368421054,
            "logloss": 3.059723762823988,
            "mae": 0.40101410975533724,
            "precision": 0.6888297872340425,
            "recall": 0.5407098121085595
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6513289594294666,
            "auditor_fn_violation": 0.03914264255589577,
            "auditor_fp_violation": 0.02572533459551456,
            "ave_precision_score": 0.6474852474750665,
            "fpr": 0.10318331503841932,
            "logloss": 3.3908236749238085,
            "mae": 0.4009616253502309,
            "precision": 0.7116564417177914,
            "recall": 0.4884210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.741208553331043,
            "auditor_fn_violation": 0.0049605354722924225,
            "auditor_fp_violation": 0.015951035209270294,
            "ave_precision_score": 0.7352371597859833,
            "fpr": 0.4133771929824561,
            "logloss": 3.019775911515177,
            "mae": 0.413788470655572,
            "precision": 0.5548996458087367,
            "recall": 0.9812108559498957
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7602674466976737,
            "auditor_fn_violation": 0.004261366918943903,
            "auditor_fp_violation": 0.012880290838779854,
            "ave_precision_score": 0.7556143843678333,
            "fpr": 0.41931942919868276,
            "logloss": 3.0419030909886096,
            "mae": 0.42837310466239625,
            "precision": 0.5484633569739953,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8138831469884581,
            "auditor_fn_violation": 0.00788832729004139,
            "auditor_fp_violation": 0.014778574612049759,
            "ave_precision_score": 0.814319098483326,
            "fpr": 0.1611842105263158,
            "logloss": 0.685035859250879,
            "mae": 0.28181142424807804,
            "precision": 0.7252336448598131,
            "recall": 0.8100208768267223
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8158004538719091,
            "auditor_fn_violation": 0.014166040788029348,
            "auditor_fp_violation": 0.024698133918770578,
            "ave_precision_score": 0.8161464077186841,
            "fpr": 0.15916575192096596,
            "logloss": 0.7429208534954005,
            "mae": 0.2974162184411703,
            "precision": 0.7156862745098039,
            "recall": 0.7684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8379148660684214,
            "auditor_fn_violation": 0.014632091711533533,
            "auditor_fp_violation": 0.016029536890725667,
            "ave_precision_score": 0.8383549394414715,
            "fpr": 0.1206140350877193,
            "logloss": 0.6927406572896971,
            "mae": 0.26627079035788986,
            "precision": 0.7703549060542797,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8482288009318573,
            "auditor_fn_violation": 0.017482234675602296,
            "auditor_fp_violation": 0.01827309439168572,
            "ave_precision_score": 0.8484598810946674,
            "fpr": 0.1163556531284303,
            "logloss": 0.7395755309863622,
            "mae": 0.27147629454866845,
            "precision": 0.7690631808278867,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8225597499956224,
            "auditor_fn_violation": 0.01214610116104458,
            "auditor_fp_violation": 0.017480551841497514,
            "ave_precision_score": 0.8239040663576954,
            "fpr": 0.13048245614035087,
            "logloss": 0.6499972567607313,
            "mae": 0.2651816806292377,
            "precision": 0.7600806451612904,
            "recall": 0.7870563674321504
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8288222347748353,
            "auditor_fn_violation": 0.011362874805014736,
            "auditor_fp_violation": 0.01421464465906001,
            "ave_precision_score": 0.8301584403070912,
            "fpr": 0.132821075740944,
            "logloss": 0.6940143026974605,
            "mae": 0.27523215169621124,
            "precision": 0.753061224489796,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 9675,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7031858882436202,
            "auditor_fn_violation": 0.015595813646851999,
            "auditor_fp_violation": 0.016791762894534268,
            "ave_precision_score": 0.6964327001783802,
            "fpr": 0.13706140350877194,
            "logloss": 1.821734594372534,
            "mae": 0.327364763151773,
            "precision": 0.7146118721461188,
            "recall": 0.6534446764091858
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7035311539356345,
            "auditor_fn_violation": 0.019492749436709235,
            "auditor_fp_violation": 0.012734267213164289,
            "ave_precision_score": 0.6965681794306766,
            "fpr": 0.13391877058177826,
            "logloss": 1.8077170616546643,
            "mae": 0.32055851419610437,
            "precision": 0.7208237986270023,
            "recall": 0.6631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 9675,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8317952744820172,
            "auditor_fn_violation": 0.00024951470534373274,
            "auditor_fp_violation": 0.01598395526923545,
            "ave_precision_score": 0.8321184277095592,
            "fpr": 0.1513157894736842,
            "logloss": 0.6641083414753987,
            "mae": 0.2701074893530338,
            "precision": 0.7381404174573055,
            "recall": 0.8121085594989561
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.828462782116624,
            "auditor_fn_violation": 0.012714772661621127,
            "auditor_fp_violation": 0.020785707811760444,
            "ave_precision_score": 0.8287845398537007,
            "fpr": 0.14928649835345773,
            "logloss": 0.73294475393491,
            "mae": 0.2861439224663805,
            "precision": 0.7317554240631163,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8644556032909344,
            "auditor_fn_violation": 0.02654699117313116,
            "auditor_fp_violation": 0.02397593290385317,
            "ave_precision_score": 0.8646959377521211,
            "fpr": 0.11293859649122807,
            "logloss": 0.5391041513794963,
            "mae": 0.27342117015209816,
            "precision": 0.7919191919191919,
            "recall": 0.8183716075156576
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.875781730237385,
            "auditor_fn_violation": 0.02056271303945924,
            "auditor_fp_violation": 0.023502250777953457,
            "ave_precision_score": 0.8759439540284089,
            "fpr": 0.12623490669593854,
            "logloss": 0.5030381540277227,
            "mae": 0.27120261330175266,
            "precision": 0.7657841140529531,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.674726872675344,
            "auditor_fn_violation": 0.008520125993480569,
            "auditor_fp_violation": 0.006996778898748028,
            "ave_precision_score": 0.6721412717606017,
            "fpr": 0.1206140350877193,
            "logloss": 1.3842607637021953,
            "mae": 0.37128321051196067,
            "precision": 0.717948717948718,
            "recall": 0.5845511482254697
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6957744808730933,
            "auditor_fn_violation": 0.008654457218787914,
            "auditor_fp_violation": 0.009272500226588395,
            "ave_precision_score": 0.6934637263516883,
            "fpr": 0.12184412733260154,
            "logloss": 1.256807821200038,
            "mae": 0.3549221544166658,
            "precision": 0.7231920199501247,
            "recall": 0.6105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8110090742766428,
            "auditor_fn_violation": 0.02383437717466945,
            "auditor_fp_violation": 0.021605688586361985,
            "ave_precision_score": 0.809405535828712,
            "fpr": 0.13157894736842105,
            "logloss": 0.8909243169164244,
            "mae": 0.26425576021954983,
            "precision": 0.7614314115308151,
            "recall": 0.7995824634655533
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.822317408102242,
            "auditor_fn_violation": 0.019730775896932236,
            "auditor_fp_violation": 0.025065710631527006,
            "ave_precision_score": 0.8206177951250058,
            "fpr": 0.12403951701427003,
            "logloss": 0.8964117824261196,
            "mae": 0.26784562717865124,
            "precision": 0.7650727650727651,
            "recall": 0.7747368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7208913729044553,
            "auditor_fn_violation": 0.016401585906310672,
            "auditor_fp_violation": 0.018680867874073175,
            "ave_precision_score": 0.7196965322977397,
            "fpr": 0.12171052631578948,
            "logloss": 1.0571712116286291,
            "mae": 0.3246566747686526,
            "precision": 0.7448275862068966,
            "recall": 0.6764091858037579
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7208468626506708,
            "auditor_fn_violation": 0.01581142758102721,
            "auditor_fp_violation": 0.029008348523147265,
            "ave_precision_score": 0.7197830760420063,
            "fpr": 0.12952799121844127,
            "logloss": 1.0225877080570647,
            "mae": 0.3230648280455671,
            "precision": 0.7377777777777778,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6563204883136841,
            "auditor_fn_violation": 0.014165110061165453,
            "auditor_fp_violation": 0.0023044041975608777,
            "ave_precision_score": 0.6495715566287781,
            "fpr": 0.22587719298245615,
            "logloss": 1.6557673736710066,
            "mae": 0.3961433143188954,
            "precision": 0.6163873370577281,
            "recall": 0.6910229645093946
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6621470845099975,
            "auditor_fn_violation": 0.013750072216765849,
            "auditor_fp_violation": 0.004483932365884854,
            "ave_precision_score": 0.6554854664948816,
            "fpr": 0.21844127332601537,
            "logloss": 1.6992526197690285,
            "mae": 0.3765386715828476,
            "precision": 0.6341911764705882,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6864887424414082,
            "auditor_fn_violation": 0.011882851701278252,
            "auditor_fp_violation": 0.015409120375997737,
            "ave_precision_score": 0.6806350582662009,
            "fpr": 0.14035087719298245,
            "logloss": 1.617185969238333,
            "mae": 0.3429416067334527,
            "precision": 0.7097505668934241,
            "recall": 0.6534446764091858
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6935276452761425,
            "auditor_fn_violation": 0.01311225374082848,
            "auditor_fp_violation": 0.005480921258018715,
            "ave_precision_score": 0.6869697339625489,
            "fpr": 0.145993413830955,
            "logloss": 1.6159415385969942,
            "mae": 0.3308130087472216,
            "precision": 0.70509977827051,
            "recall": 0.6694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.806045284935495,
            "auditor_fn_violation": 0.010225524667618946,
            "auditor_fp_violation": 0.007432336615210082,
            "ave_precision_score": 0.8074092062588601,
            "fpr": 0.09978070175438597,
            "logloss": 0.5904454673372538,
            "mae": 0.33805932419612683,
            "precision": 0.7936507936507936,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7914888998541154,
            "auditor_fn_violation": 0.012814142931422972,
            "auditor_fp_violation": 0.01083596008016194,
            "ave_precision_score": 0.7930393718582258,
            "fpr": 0.10976948408342481,
            "logloss": 0.560693165070611,
            "mae": 0.33795873581766783,
            "precision": 0.7701149425287356,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6322084479548578,
            "auditor_fn_violation": 0.03516783869904406,
            "auditor_fp_violation": 0.012322231676188164,
            "ave_precision_score": 0.6290913388025214,
            "fpr": 0.11403508771929824,
            "logloss": 3.0006730696784834,
            "mae": 0.40604029726432594,
            "precision": 0.7045454545454546,
            "recall": 0.5177453027139874
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6492363913877222,
            "auditor_fn_violation": 0.03020856201975852,
            "auditor_fp_violation": 0.024350698395754242,
            "ave_precision_score": 0.6453988558471445,
            "fpr": 0.09659714599341383,
            "logloss": 3.3673629180934377,
            "mae": 0.4081754870717348,
            "precision": 0.7215189873417721,
            "recall": 0.48
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7264523342673224,
            "auditor_fn_violation": 0.01568280042486174,
            "auditor_fp_violation": 0.020921964264008754,
            "ave_precision_score": 0.7255258486882656,
            "fpr": 0.11074561403508772,
            "logloss": 1.0147546772233857,
            "mae": 0.32419618576248793,
            "precision": 0.7577937649880095,
            "recall": 0.6597077244258872
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7259288162658906,
            "auditor_fn_violation": 0.021433936102605577,
            "auditor_fp_violation": 0.02851992467195038,
            "ave_precision_score": 0.7256189165225431,
            "fpr": 0.12294182217343579,
            "logloss": 0.9568846313435125,
            "mae": 0.32319167311562264,
            "precision": 0.7437070938215103,
            "recall": 0.6842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8508280882979401,
            "auditor_fn_violation": 0.007581584441270192,
            "auditor_fp_violation": 0.013765649690044979,
            "ave_precision_score": 0.8510484342483645,
            "fpr": 0.12828947368421054,
            "logloss": 0.502419389935642,
            "mae": 0.3100864377956257,
            "precision": 0.766,
            "recall": 0.7995824634655533
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8663033017763905,
            "auditor_fn_violation": 0.005164943093188518,
            "auditor_fp_violation": 0.008524758557487992,
            "ave_precision_score": 0.866484307343743,
            "fpr": 0.1207464324917673,
            "logloss": 0.48425698032736053,
            "mae": 0.30440053346021967,
            "precision": 0.7693920335429769,
            "recall": 0.7726315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 9675,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8249529466674025,
            "auditor_fn_violation": 0.015229553528916244,
            "auditor_fp_violation": 0.017138689680320892,
            "ave_precision_score": 0.8252820560541426,
            "fpr": 0.12390350877192982,
            "logloss": 0.7506174372501541,
            "mae": 0.27843293403490876,
            "precision": 0.7600849256900213,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8267833826408715,
            "auditor_fn_violation": 0.015095037263851181,
            "auditor_fp_violation": 0.01950170696583047,
            "ave_precision_score": 0.8271510788536383,
            "fpr": 0.1207464324917673,
            "logloss": 0.8017480572960594,
            "mae": 0.2808566892728763,
            "precision": 0.7592997811816192,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8155748465700472,
            "auditor_fn_violation": 0.018260356004834638,
            "auditor_fp_violation": 0.014479761760058345,
            "ave_precision_score": 0.8168817845362071,
            "fpr": 0.09320175438596491,
            "logloss": 0.5914058910306189,
            "mae": 0.3358789311230698,
            "precision": 0.782608695652174,
            "recall": 0.6388308977035491
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8343992817132222,
            "auditor_fn_violation": 0.019800103992142826,
            "auditor_fp_violation": 0.01445633893594095,
            "ave_precision_score": 0.8347294677977426,
            "fpr": 0.08122941822173436,
            "logloss": 0.5645129072379294,
            "mae": 0.3250053416805073,
            "precision": 0.8087855297157622,
            "recall": 0.6589473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8018096422041009,
            "auditor_fn_violation": 0.030578141596161592,
            "auditor_fp_violation": 0.02053452048134193,
            "ave_precision_score": 0.7994141346050728,
            "fpr": 0.1206140350877193,
            "logloss": 0.980563927961376,
            "mae": 0.27040022683566023,
            "precision": 0.7639484978540773,
            "recall": 0.7432150313152401
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8125265861224851,
            "auditor_fn_violation": 0.02350915708590907,
            "auditor_fp_violation": 0.021324484637307538,
            "ave_precision_score": 0.8100251507973033,
            "fpr": 0.12184412733260154,
            "logloss": 1.0297370365087342,
            "mae": 0.2741540339462197,
            "precision": 0.758695652173913,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7932405141269832,
            "auditor_fn_violation": 0.028167692194996898,
            "auditor_fp_violation": 0.034036809691665657,
            "ave_precision_score": 0.793916193624655,
            "fpr": 0.10964912280701754,
            "logloss": 0.6149851269823163,
            "mae": 0.33509905550452684,
            "precision": 0.7624703087885986,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8118117843960314,
            "auditor_fn_violation": 0.028946790686925874,
            "auditor_fp_violation": 0.0324273154815255,
            "ave_precision_score": 0.8120869246437048,
            "fpr": 0.1163556531284303,
            "logloss": 0.620853470564961,
            "mae": 0.3369098975281993,
            "precision": 0.7488151658767772,
            "recall": 0.6652631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7296389080731023,
            "auditor_fn_violation": 0.011589843606929648,
            "auditor_fp_violation": 0.020894108828653623,
            "ave_precision_score": 0.7274574204611695,
            "fpr": 0.13815789473684212,
            "logloss": 1.1450928791923043,
            "mae": 0.3020598807930555,
            "precision": 0.7391304347826086,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7346467063682338,
            "auditor_fn_violation": 0.015714368247732396,
            "auditor_fp_violation": 0.02525956958277526,
            "ave_precision_score": 0.732116438336115,
            "fpr": 0.150384193194292,
            "logloss": 1.1581958124660356,
            "mae": 0.3084326066894408,
            "precision": 0.7186858316221766,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8409278746350409,
            "auditor_fn_violation": 0.01359511775262792,
            "auditor_fp_violation": 0.014925448725740453,
            "ave_precision_score": 0.8413295599155024,
            "fpr": 0.12280701754385964,
            "logloss": 0.6734155487520408,
            "mae": 0.26470313756846875,
            "precision": 0.7676348547717843,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8513355396136614,
            "auditor_fn_violation": 0.017412906580391706,
            "auditor_fp_violation": 0.017885376489189222,
            "ave_precision_score": 0.8515606355267822,
            "fpr": 0.1141602634467618,
            "logloss": 0.7179598087917255,
            "mae": 0.26967460376979463,
            "precision": 0.7744034707158352,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7931310507790647,
            "auditor_fn_violation": 0.015398948833461525,
            "auditor_fp_violation": 0.015533203678943317,
            "ave_precision_score": 0.7764760974009401,
            "fpr": 0.1524122807017544,
            "logloss": 1.5130045613072012,
            "mae": 0.27558817512615125,
            "precision": 0.7440147329650092,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8062056575267567,
            "auditor_fn_violation": 0.009313074123288462,
            "auditor_fp_violation": 0.022391967693531665,
            "ave_precision_score": 0.7878052805270714,
            "fpr": 0.1525795828759605,
            "logloss": 1.5424351213909497,
            "mae": 0.2789052262739713,
            "precision": 0.7347328244274809,
            "recall": 0.8105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.701777853915746,
            "auditor_fn_violation": 0.021623081712632313,
            "auditor_fp_violation": 0.01525718163769702,
            "ave_precision_score": 0.6953013281838286,
            "fpr": 0.1337719298245614,
            "logloss": 1.8527855689992716,
            "mae": 0.3282733268966242,
            "precision": 0.7156177156177156,
            "recall": 0.6409185803757829
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7028236912930341,
            "auditor_fn_violation": 0.02115200184874921,
            "auditor_fp_violation": 0.011470407556974394,
            "ave_precision_score": 0.6961840389505716,
            "fpr": 0.13172338090010977,
            "logloss": 1.8186971229729048,
            "mae": 0.32121704915912463,
            "precision": 0.7222222222222222,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8682574987300391,
            "auditor_fn_violation": 0.014240651210489697,
            "auditor_fp_violation": 0.016741116648434022,
            "ave_precision_score": 0.8685807654931578,
            "fpr": 0.1162280701754386,
            "logloss": 0.49195312749593556,
            "mae": 0.2715874296211381,
            "precision": 0.7862903225806451,
            "recall": 0.81419624217119
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8716003782738445,
            "auditor_fn_violation": 0.011577791900167547,
            "auditor_fp_violation": 0.018660812294182216,
            "ave_precision_score": 0.8717708058682716,
            "fpr": 0.11964873765093303,
            "logloss": 0.4911115758302825,
            "mae": 0.27666553757866963,
            "precision": 0.7733887733887734,
            "recall": 0.783157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7316875970896839,
            "auditor_fn_violation": 0.0028499615426876217,
            "auditor_fp_violation": 0.020891576516348615,
            "ave_precision_score": 0.7324263622998767,
            "fpr": 0.15021929824561403,
            "logloss": 1.2642092476047044,
            "mae": 0.2985947403758124,
            "precision": 0.7248995983935743,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7347239937515271,
            "auditor_fn_violation": 0.01377780345485008,
            "auditor_fp_violation": 0.008847017593329244,
            "ave_precision_score": 0.7336625065025137,
            "fpr": 0.16794731064763996,
            "logloss": 1.2913838104641302,
            "mae": 0.30193479160017667,
            "precision": 0.7040618955512572,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8404966653053407,
            "auditor_fn_violation": 0.015044134344211257,
            "auditor_fp_violation": 0.016029536890725667,
            "ave_precision_score": 0.840855139112437,
            "fpr": 0.1206140350877193,
            "logloss": 0.6709462209799631,
            "mae": 0.26645102299106677,
            "precision": 0.7727272727272727,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8498091204203069,
            "auditor_fn_violation": 0.015749032295337684,
            "auditor_fp_violation": 0.01597196346388181,
            "ave_precision_score": 0.8500387475763346,
            "fpr": 0.1207464324917673,
            "logloss": 0.7162263476112416,
            "mae": 0.27173208370922547,
            "precision": 0.7649572649572649,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7509463337197915,
            "auditor_fn_violation": 0.017637713804343848,
            "auditor_fp_violation": 0.02342895344597059,
            "ave_precision_score": 0.7520593718622623,
            "fpr": 0.13815789473684212,
            "logloss": 0.6370352778408853,
            "mae": 0.3507877451759493,
            "precision": 0.7290322580645161,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7581474866593363,
            "auditor_fn_violation": 0.01212086197931712,
            "auditor_fp_violation": 0.029456489994864,
            "ave_precision_score": 0.7589198613382424,
            "fpr": 0.13172338090010977,
            "logloss": 0.6080536650005883,
            "mae": 0.34638719429855813,
            "precision": 0.7391304347826086,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 9675,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7256293722613055,
            "auditor_fn_violation": 0.00947011317437644,
            "auditor_fp_violation": 0.014900125602690334,
            "ave_precision_score": 0.726954763469963,
            "fpr": 0.1118421052631579,
            "logloss": 2.1013170258984726,
            "mae": 0.3211827576842764,
            "precision": 0.7475247524752475,
            "recall": 0.6304801670146137
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7553401559577133,
            "auditor_fn_violation": 0.016356808596683807,
            "auditor_fp_violation": 0.007630993262772033,
            "ave_precision_score": 0.7563655009496077,
            "fpr": 0.11086717892425905,
            "logloss": 1.7379902281342574,
            "mae": 0.3093475370523571,
            "precision": 0.7536585365853659,
            "recall": 0.6505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6016648163993193,
            "auditor_fn_violation": 0.02852708493572135,
            "auditor_fp_violation": 0.06036019610226491,
            "ave_precision_score": 0.6015977851453005,
            "fpr": 0.2598684210526316,
            "logloss": 1.7686574008523526,
            "mae": 0.34340690612762065,
            "precision": 0.639269406392694,
            "recall": 0.8768267223382046
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6484146446262915,
            "auditor_fn_violation": 0.020694436420359355,
            "auditor_fp_violation": 0.05779010866171866,
            "ave_precision_score": 0.6489588969283635,
            "fpr": 0.23819978046103182,
            "logloss": 1.4913422898343036,
            "mae": 0.3212769892010092,
            "precision": 0.6555555555555556,
            "recall": 0.8694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7780066908013121,
            "auditor_fn_violation": 0.007954711936417246,
            "auditor_fp_violation": 0.016617033345488436,
            "ave_precision_score": 0.7787479454802504,
            "fpr": 0.13267543859649122,
            "logloss": 0.7451628264897652,
            "mae": 0.28361268750378366,
            "precision": 0.7555555555555555,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7890073230618152,
            "auditor_fn_violation": 0.008284707377664804,
            "auditor_fp_violation": 0.017230787822636692,
            "ave_precision_score": 0.7894009347025118,
            "fpr": 0.1437980241492865,
            "logloss": 0.7734616918481613,
            "mae": 0.2942328162061558,
            "precision": 0.7358870967741935,
            "recall": 0.7684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.84359549821176,
            "auditor_fn_violation": 0.02805323590814197,
            "auditor_fp_violation": 0.01988624853125887,
            "ave_precision_score": 0.8439621821279294,
            "fpr": 0.11842105263157894,
            "logloss": 0.7257910192532671,
            "mae": 0.26476783382372227,
            "precision": 0.7754677754677755,
            "recall": 0.778705636743215
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8546350483962769,
            "auditor_fn_violation": 0.01112022647177769,
            "auditor_fp_violation": 0.015992104653621893,
            "ave_precision_score": 0.8548494493548474,
            "fpr": 0.11525795828759605,
            "logloss": 0.7310437645333265,
            "mae": 0.2667812129878915,
            "precision": 0.7751605995717344,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7830392318407178,
            "auditor_fn_violation": 0.006890268468666451,
            "auditor_fp_violation": 0.017898383371824485,
            "ave_precision_score": 0.7840538979165559,
            "fpr": 0.1337719298245614,
            "logloss": 0.7693850033394826,
            "mae": 0.27012750664726837,
            "precision": 0.7579365079365079,
            "recall": 0.7974947807933194
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8043645236313701,
            "auditor_fn_violation": 0.014300075105436485,
            "auditor_fp_violation": 0.020302319257998573,
            "ave_precision_score": 0.8053659246444049,
            "fpr": 0.15367727771679474,
            "logloss": 0.8075631990826206,
            "mae": 0.28564365439997724,
            "precision": 0.7270955165692008,
            "recall": 0.7852631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7192639873794344,
            "auditor_fn_violation": 0.017385909973263013,
            "auditor_fp_violation": 0.016135894007536164,
            "ave_precision_score": 0.7150945633087116,
            "fpr": 0.12390350877192982,
            "logloss": 1.4983808056629535,
            "mae": 0.31516462536210854,
            "precision": 0.7384259259259259,
            "recall": 0.6659707724425887
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7205441804420509,
            "auditor_fn_violation": 0.016421514818880354,
            "auditor_fp_violation": 0.01548353961268492,
            "ave_precision_score": 0.7154426982561791,
            "fpr": 0.12952799121844127,
            "logloss": 1.516227775681715,
            "mae": 0.3116343605076842,
            "precision": 0.7324263038548753,
            "recall": 0.68
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 9675,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8401294178329493,
            "auditor_fn_violation": 0.02681252975863459,
            "auditor_fp_violation": 0.01680442445605932,
            "ave_precision_score": 0.8404508755856066,
            "fpr": 0.12390350877192982,
            "logloss": 0.701448868793737,
            "mae": 0.26813144980896286,
            "precision": 0.7660455486542443,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8496262802956542,
            "auditor_fn_violation": 0.014177595470564446,
            "auditor_fp_violation": 0.022812415029355788,
            "ave_precision_score": 0.8498534437996241,
            "fpr": 0.11745334796926454,
            "logloss": 0.7064470929720337,
            "mae": 0.26800624426239666,
            "precision": 0.772823779193206,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 9675,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7101953734979585,
            "auditor_fn_violation": 0.014861004285243383,
            "auditor_fp_violation": 0.01732861310319679,
            "ave_precision_score": 0.7063614055317706,
            "fpr": 0.14583333333333334,
            "logloss": 1.465718376108713,
            "mae": 0.32237263895685186,
            "precision": 0.7145922746781116,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7089832957984679,
            "auditor_fn_violation": 0.012287249407822526,
            "auditor_fp_violation": 0.009577135721407068,
            "ave_precision_score": 0.704041281011642,
            "fpr": 0.15697036223929747,
            "logloss": 1.5037532542256993,
            "mae": 0.3148771358283187,
            "precision": 0.7045454545454546,
            "recall": 0.7178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8322413704314265,
            "auditor_fn_violation": 0.0019114199904772381,
            "auditor_fp_violation": 0.018442830517402056,
            "ave_precision_score": 0.8325543305698828,
            "fpr": 0.14692982456140352,
            "logloss": 0.6575249697449191,
            "mae": 0.2708029299776407,
            "precision": 0.7423076923076923,
            "recall": 0.8058455114822547
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.82912279072147,
            "auditor_fn_violation": 0.010008666011901327,
            "auditor_fp_violation": 0.017895447084059265,
            "ave_precision_score": 0.8294433525906502,
            "fpr": 0.14489571899012074,
            "logloss": 0.7244173018312399,
            "mae": 0.285545752258218,
            "precision": 0.736,
            "recall": 0.7747368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6320970326712922,
            "auditor_fn_violation": 0.042406054279749486,
            "auditor_fp_violation": 0.014548134192293675,
            "ave_precision_score": 0.6287782263334327,
            "fpr": 0.1206140350877193,
            "logloss": 3.148530716332029,
            "mae": 0.4031418255948683,
            "precision": 0.6986301369863014,
            "recall": 0.5323590814196242
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6495711510839223,
            "auditor_fn_violation": 0.03935293777803456,
            "auditor_fp_violation": 0.02520669895970755,
            "ave_precision_score": 0.6454590345799476,
            "fpr": 0.10428100987925357,
            "logloss": 3.483844127500964,
            "mae": 0.40402469649653866,
            "precision": 0.7067901234567902,
            "recall": 0.48210526315789476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.792621863247587,
            "auditor_fn_violation": 0.016680859246236683,
            "auditor_fp_violation": 0.014943174911875532,
            "ave_precision_score": 0.7758977033124096,
            "fpr": 0.14473684210526316,
            "logloss": 1.5260749854498963,
            "mae": 0.2728044632164886,
            "precision": 0.7504725897920604,
            "recall": 0.8288100208768268
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8056684996860484,
            "auditor_fn_violation": 0.009800681726269573,
            "auditor_fp_violation": 0.018154764901962762,
            "ave_precision_score": 0.7872755628005651,
            "fpr": 0.1394072447859495,
            "logloss": 1.5644240399784193,
            "mae": 0.2736763094253347,
            "precision": 0.748015873015873,
            "recall": 0.7936842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8692847305657193,
            "auditor_fn_violation": 0.023399443284620746,
            "auditor_fp_violation": 0.013038876058506548,
            "ave_precision_score": 0.8694745778084086,
            "fpr": 0.09758771929824561,
            "logloss": 0.5146844254010993,
            "mae": 0.30691622046734873,
            "precision": 0.8008948545861297,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8699130183422412,
            "auditor_fn_violation": 0.0143023860419435,
            "auditor_fp_violation": 0.014607397858991528,
            "ave_precision_score": 0.8701069078393104,
            "fpr": 0.09549945115257959,
            "logloss": 0.4716677105071409,
            "mae": 0.3054176717956983,
            "precision": 0.8066666666666666,
            "recall": 0.7642105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8293637740721993,
            "auditor_fn_violation": 0.033446416144746006,
            "auditor_fp_violation": 0.029438130545763948,
            "ave_precision_score": 0.8298252310939094,
            "fpr": 0.13486842105263158,
            "logloss": 0.8071481810433819,
            "mae": 0.26963390010524263,
            "precision": 0.7510121457489879,
            "recall": 0.7745302713987474
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8383791295191606,
            "auditor_fn_violation": 0.021965451499220065,
            "auditor_fp_violation": 0.03106778517407024,
            "ave_precision_score": 0.8386738087829445,
            "fpr": 0.14270032930845225,
            "logloss": 0.7843053543697761,
            "mae": 0.27573910554938935,
            "precision": 0.7330595482546202,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7084130369265205,
            "auditor_fn_violation": 0.021032487272460907,
            "auditor_fp_violation": 0.012767918641870272,
            "ave_precision_score": 0.7025037888508912,
            "fpr": 0.13157894736842105,
            "logloss": 1.761215058272528,
            "mae": 0.3246966565366762,
            "precision": 0.7183098591549296,
            "recall": 0.6388308977035491
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7087716603110419,
            "auditor_fn_violation": 0.02118204402334047,
            "auditor_fp_violation": 0.013288149931016423,
            "ave_precision_score": 0.7019579051126936,
            "fpr": 0.12952799121844127,
            "logloss": 1.7744564967169767,
            "mae": 0.31770452636876717,
            "precision": 0.7268518518518519,
            "recall": 0.6610526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 9675,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7825872548701656,
            "auditor_fn_violation": 0.011122861956561555,
            "auditor_fp_violation": 0.014218933592642117,
            "ave_precision_score": 0.78284133453445,
            "fpr": 0.14144736842105263,
            "logloss": 0.9502664468636473,
            "mae": 0.27414557152039615,
            "precision": 0.7465618860510805,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7837440387609333,
            "auditor_fn_violation": 0.01330406147091109,
            "auditor_fp_violation": 0.019370789232519964,
            "ave_precision_score": 0.7850139096710274,
            "fpr": 0.14270032930845225,
            "logloss": 1.012259189506026,
            "mae": 0.2856044166294122,
            "precision": 0.7352342158859471,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.858065346587938,
            "auditor_fn_violation": 0.006947496612093916,
            "auditor_fp_violation": 0.0081565779344435,
            "ave_precision_score": 0.858283757420202,
            "fpr": 0.07017543859649122,
            "logloss": 0.509562699642335,
            "mae": 0.32066830093645604,
            "precision": 0.8341968911917098,
            "recall": 0.6722338204592901
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8489803575782411,
            "auditor_fn_violation": 0.003521867236697676,
            "auditor_fp_violation": 0.004088661517235825,
            "ave_precision_score": 0.8492504338790846,
            "fpr": 0.07025246981339188,
            "logloss": 0.5222928649656595,
            "mae": 0.3228832512304727,
            "precision": 0.8293333333333334,
            "recall": 0.6547368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6961696259364853,
            "auditor_fn_violation": 0.006748342672966344,
            "auditor_fp_violation": 0.01745269640614238,
            "ave_precision_score": 0.6923157067665828,
            "fpr": 0.14692982456140352,
            "logloss": 2.131975706936136,
            "mae": 0.3363761560778613,
            "precision": 0.7041942604856513,
            "recall": 0.6659707724425887
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7014993504159213,
            "auditor_fn_violation": 0.01989485238893062,
            "auditor_fp_violation": 0.012155208008137046,
            "ave_precision_score": 0.6965930981077297,
            "fpr": 0.15367727771679474,
            "logloss": 2.001012194747846,
            "mae": 0.3240590788151293,
            "precision": 0.7033898305084746,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7959901724230267,
            "auditor_fn_violation": 0.009303006995568254,
            "auditor_fp_violation": 0.014477229447753334,
            "ave_precision_score": 0.7807944302882758,
            "fpr": 0.17105263157894737,
            "logloss": 1.4371956298703066,
            "mae": 0.2857268846945086,
            "precision": 0.7301038062283737,
            "recall": 0.8810020876826722
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8095197521416365,
            "auditor_fn_violation": 0.004647293315616156,
            "auditor_fp_violation": 0.018187494335290388,
            "ave_precision_score": 0.7926844643070138,
            "fpr": 0.16245883644346873,
            "logloss": 1.4608972775155096,
            "mae": 0.2829052020190437,
            "precision": 0.7304189435336976,
            "recall": 0.8442105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7355638515878946,
            "auditor_fn_violation": 0.011667673881990998,
            "auditor_fp_violation": 0.01723238523560634,
            "ave_precision_score": 0.73420449387679,
            "fpr": 0.12280701754385964,
            "logloss": 1.1329108234103034,
            "mae": 0.30075362687225904,
            "precision": 0.7522123893805309,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7408833955582179,
            "auditor_fn_violation": 0.014159107978508294,
            "auditor_fp_violation": 0.0221955910935659,
            "ave_precision_score": 0.7405594484752891,
            "fpr": 0.1350164654226125,
            "logloss": 1.1305135322560858,
            "mae": 0.30763224391389443,
            "precision": 0.7296703296703296,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7059404191164356,
            "auditor_fn_violation": 0.018818902684686677,
            "auditor_fp_violation": 0.016551193225558126,
            "ave_precision_score": 0.699730667573329,
            "fpr": 0.14144736842105263,
            "logloss": 1.7078162126382255,
            "mae": 0.3224550394923275,
            "precision": 0.7152317880794702,
            "recall": 0.6764091858037579
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7086477335207088,
            "auditor_fn_violation": 0.012562250852157843,
            "auditor_fp_violation": 0.010166265521304355,
            "ave_precision_score": 0.7014896073407313,
            "fpr": 0.14818880351262348,
            "logloss": 1.7198941300713093,
            "mae": 0.31363286874005075,
            "precision": 0.7121535181236673,
            "recall": 0.7031578947368421
        }
    }
]