[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.820591873616919,
            "auditor_fn_violation": 0.016144420329173455,
            "auditor_fp_violation": 0.027432823862936037,
            "ave_precision_score": 0.8210863913094472,
            "fpr": 0.12938596491228072,
            "logloss": 0.9673985114456604,
            "mae": 0.27707253193282244,
            "precision": 0.756198347107438,
            "recall": 0.7546391752577319
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8353727400328959,
            "auditor_fn_violation": 0.02364841934283421,
            "auditor_fp_violation": 0.024325613045184304,
            "ave_precision_score": 0.8357516827701483,
            "fpr": 0.141602634467618,
            "logloss": 0.8324846128553002,
            "mae": 0.26165402298034074,
            "precision": 0.7393939393939394,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8370015835380948,
            "auditor_fn_violation": 0.011629589437511306,
            "auditor_fp_violation": 0.012115329306873746,
            "ave_precision_score": 0.8075424709261025,
            "fpr": 0.1074561403508772,
            "logloss": 0.5834024974214427,
            "mae": 0.3062260653203243,
            "precision": 0.7850877192982456,
            "recall": 0.7381443298969073
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8694296871008336,
            "auditor_fn_violation": 0.004297159334267977,
            "auditor_fp_violation": 0.018323060035463988,
            "ave_precision_score": 0.8422574502389556,
            "fpr": 0.10537870472008781,
            "logloss": 0.5168260439204343,
            "mae": 0.287878751371523,
            "precision": 0.8008298755186722,
            "recall": 0.8230277185501066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 9292,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.5530597315370513,
            "auditor_fn_violation": 0.02601284138180504,
            "auditor_fp_violation": 0.011126689675007195,
            "ave_precision_score": 0.5522188313859892,
            "fpr": 0.2741228070175439,
            "logloss": 0.9302549437665143,
            "mae": 0.502095632345963,
            "precision": 0.5201535508637236,
            "recall": 0.5587628865979382
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5188339095096941,
            "auditor_fn_violation": 0.021804104770174536,
            "auditor_fp_violation": 0.0284754955769355,
            "ave_precision_score": 0.520493477604062,
            "fpr": 0.2996706915477497,
            "logloss": 0.9591447573013162,
            "mae": 0.5123360489462385,
            "precision": 0.47093023255813954,
            "recall": 0.5181236673773987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.794709227678616,
            "auditor_fn_violation": 0.0008410200759631164,
            "auditor_fp_violation": 0.0004801963926209092,
            "ave_precision_score": 0.784648185103496,
            "fpr": 0.17543859649122806,
            "logloss": 0.585799999814273,
            "mae": 0.37296578859943047,
            "precision": 0.6917148362235067,
            "recall": 0.7402061855670103
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8158652495026968,
            "auditor_fn_violation": 0.002246880697656458,
            "auditor_fp_violation": 0.015551504735982045,
            "ave_precision_score": 0.8046938392985777,
            "fpr": 0.1525795828759605,
            "logloss": 0.5252999446310214,
            "mae": 0.34362423575343204,
            "precision": 0.7321772639691715,
            "recall": 0.8102345415778252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.637755288626468,
            "auditor_fn_violation": 0.028248779164405862,
            "auditor_fp_violation": 0.023529623238423933,
            "ave_precision_score": 0.6314524054906812,
            "fpr": 0.19517543859649122,
            "logloss": 1.2915046487207105,
            "mae": 0.4175925382785448,
            "precision": 0.664783427495292,
            "recall": 0.7278350515463917
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6204543685994609,
            "auditor_fn_violation": 0.02809303022288589,
            "auditor_fp_violation": 0.034448246916768906,
            "ave_precision_score": 0.6180322936254468,
            "fpr": 0.21405049396267836,
            "logloss": 1.1008931727007891,
            "mae": 0.4165618341919863,
            "precision": 0.6388888888888888,
            "recall": 0.7356076759061834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.44645673496687366,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.44821515171559784,
            "fpr": 0.4451754385964912,
            "logloss": 0.7083940360570572,
            "mae": 0.4871464166790247,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.43729629261761316,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.4394726234403963,
            "fpr": 0.45554335894621295,
            "logloss": 0.7155850215348568,
            "mae": 0.49056835794815246,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7029097094949457,
            "auditor_fn_violation": 0.002520799421233497,
            "auditor_fp_violation": 0.004830210772833721,
            "ave_precision_score": 0.5897279037698817,
            "fpr": 0.375,
            "logloss": 0.6898310885167649,
            "mae": 0.4756019547267147,
            "precision": 0.57356608478803,
            "recall": 0.9484536082474226
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7081546053935446,
            "auditor_fn_violation": 0.0036862886445926256,
            "auditor_fp_violation": 0.010673964764492295,
            "ave_precision_score": 0.5932920062703411,
            "fpr": 0.38199780461031835,
            "logloss": 0.691150902621042,
            "mae": 0.4745953745367394,
            "precision": 0.5628140703517588,
            "recall": 0.9552238805970149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7921149162515335,
            "auditor_fn_violation": 0.012852685838307109,
            "auditor_fp_violation": 0.022923599983565475,
            "ave_precision_score": 0.7656111217640806,
            "fpr": 0.1600877192982456,
            "logloss": 1.98519580131141,
            "mae": 0.27747452649361404,
            "precision": 0.7301293900184843,
            "recall": 0.8144329896907216
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.806836929791017,
            "auditor_fn_violation": 0.012271245310221671,
            "auditor_fp_violation": 0.029503653188033642,
            "ave_precision_score": 0.7872989756526214,
            "fpr": 0.17672886937431395,
            "logloss": 1.6035389267766642,
            "mae": 0.2713827028922321,
            "precision": 0.710431654676259,
            "recall": 0.8422174840085288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.8329495304470848,
            "auditor_fn_violation": 0.0020663772834147226,
            "auditor_fp_violation": 0.010212519002424094,
            "ave_precision_score": 0.833435361897463,
            "fpr": 0.35526315789473684,
            "logloss": 0.9791687477970953,
            "mae": 0.36722697380250074,
            "precision": 0.5914249684741488,
            "recall": 0.9670103092783505
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.8604423345830348,
            "auditor_fn_violation": 0.0018466550733864005,
            "auditor_fp_violation": 0.0210499128301156,
            "ave_precision_score": 0.8606296084610592,
            "fpr": 0.3567508232711306,
            "logloss": 0.9630429052450804,
            "mae": 0.3679546834904809,
            "precision": 0.5838668373879642,
            "recall": 0.9722814498933902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5436069501451428,
            "auditor_fn_violation": 0.008516458672454347,
            "auditor_fp_violation": 0.007611241217798598,
            "ave_precision_score": 0.5404552591443026,
            "fpr": 0.08114035087719298,
            "logloss": 1.7908987164434726,
            "mae": 0.4982969418836028,
            "precision": 0.5286624203821656,
            "recall": 0.1711340206185567
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.508893269427559,
            "auditor_fn_violation": 0.0018724005813803815,
            "auditor_fp_violation": 0.007492636504065447,
            "ave_precision_score": 0.5060021562965125,
            "fpr": 0.07793633369923161,
            "logloss": 2.016006657808393,
            "mae": 0.5097237528397621,
            "precision": 0.5170068027210885,
            "recall": 0.16204690831556504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8271520774744903,
            "auditor_fn_violation": 0.002430367155000906,
            "auditor_fp_violation": 0.009126299354944734,
            "ave_precision_score": 0.8273802798474428,
            "fpr": 0.18530701754385964,
            "logloss": 0.7547751258008861,
            "mae": 0.293039274817913,
            "precision": 0.7050610820244329,
            "recall": 0.8329896907216495
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8540397801978689,
            "auditor_fn_violation": 0.0031994644934337253,
            "auditor_fp_violation": 0.01363674744574854,
            "ave_precision_score": 0.8543031623857981,
            "fpr": 0.16794731064763996,
            "logloss": 0.6638278071602035,
            "mae": 0.26942981512625974,
            "precision": 0.71875,
            "recall": 0.8336886993603412
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6418808404171942,
            "auditor_fn_violation": 0.009999547838668849,
            "auditor_fp_violation": 0.00821212868236164,
            "ave_precision_score": 0.5564398022547778,
            "fpr": 0.09429824561403509,
            "logloss": 0.687813500527441,
            "mae": 0.4960110234260036,
            "precision": 0.6177777777777778,
            "recall": 0.2865979381443299
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.6101036880830285,
            "auditor_fn_violation": 0.0010930138393807933,
            "auditor_fp_violation": 0.020026722163998593,
            "ave_precision_score": 0.5282589550065484,
            "fpr": 0.12184412733260154,
            "logloss": 0.691409055693574,
            "mae": 0.49765493484412276,
            "precision": 0.5595238095238095,
            "recall": 0.3006396588486141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8295268606346514,
            "auditor_fn_violation": 0.015927382890215242,
            "auditor_fp_violation": 0.014788508155634992,
            "ave_precision_score": 0.8155837630100965,
            "fpr": 0.06359649122807018,
            "logloss": 0.5577339260979233,
            "mae": 0.35029420069941697,
            "precision": 0.8370786516853933,
            "recall": 0.6144329896907217
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8437819678657453,
            "auditor_fn_violation": 0.02492867324035305,
            "auditor_fp_violation": 0.009106893622939344,
            "ave_precision_score": 0.8280868477183132,
            "fpr": 0.06695938529088913,
            "logloss": 0.5234457881692306,
            "mae": 0.3368552049906141,
            "precision": 0.8291316526610645,
            "recall": 0.6311300639658849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7927921732656821,
            "auditor_fn_violation": 0.024186109603906675,
            "auditor_fp_violation": 0.02633376473971815,
            "ave_precision_score": 0.7931232738948865,
            "fpr": 0.14583333333333334,
            "logloss": 1.0276104006135387,
            "mae": 0.3070866673150231,
            "precision": 0.7194092827004219,
            "recall": 0.7030927835051546
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7994834457216599,
            "auditor_fn_violation": 0.027107679416934462,
            "auditor_fp_violation": 0.02842085918214284,
            "ave_precision_score": 0.8003341843835804,
            "fpr": 0.150384193194292,
            "logloss": 0.9098212941774884,
            "mae": 0.2891096924727456,
            "precision": 0.7204081632653061,
            "recall": 0.7526652452025586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7262323075091014,
            "auditor_fn_violation": 0.062490956773376745,
            "auditor_fp_violation": 0.09630633961954066,
            "ave_precision_score": 0.5674045626212106,
            "fpr": 0.27850877192982454,
            "logloss": 0.6856686795506974,
            "mae": 0.4952267732536584,
            "precision": 0.5808580858085809,
            "recall": 0.7257731958762886
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7004146594658693,
            "auditor_fn_violation": 0.051278030421828456,
            "auditor_fp_violation": 0.10105249564150579,
            "ave_precision_score": 0.5324143200819571,
            "fpr": 0.31394072447859495,
            "logloss": 0.6902563821788374,
            "mae": 0.4975276870732773,
            "precision": 0.5394524959742351,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.638150178979098,
            "auditor_fn_violation": 0.005450804847169486,
            "auditor_fp_violation": 0.022122416697481415,
            "ave_precision_score": 0.5571974695220518,
            "fpr": 0.13596491228070176,
            "logloss": 2.9797922681024676,
            "mae": 0.50056284722332,
            "precision": 0.5796610169491525,
            "recall": 0.3525773195876289
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.5791814515953032,
            "auditor_fn_violation": 0.010642256804420757,
            "auditor_fp_violation": 0.01639091843779647,
            "ave_precision_score": 0.5001433962199093,
            "fpr": 0.17453347969264543,
            "logloss": 2.9628477874243684,
            "mae": 0.5174745560892253,
            "precision": 0.4837662337662338,
            "recall": 0.31769722814498935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7922525641057538,
            "auditor_fn_violation": 0.04169379634653645,
            "auditor_fp_violation": 0.06455945190845967,
            "ave_precision_score": 0.7931610732368264,
            "fpr": 0.23684210526315788,
            "logloss": 0.6975580128470074,
            "mae": 0.3416629510375379,
            "precision": 0.6544,
            "recall": 0.843298969072165
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.835460236006709,
            "auditor_fn_violation": 0.04197219953236796,
            "auditor_fp_violation": 0.0668029265239829,
            "ave_precision_score": 0.8357190208059818,
            "fpr": 0.22941822173435786,
            "logloss": 0.6406541328922373,
            "mae": 0.3282372741561289,
            "precision": 0.6573770491803279,
            "recall": 0.8550106609808102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7973230518890427,
            "auditor_fn_violation": 0.007107976125881714,
            "auditor_fp_violation": 0.009203336209375907,
            "ave_precision_score": 0.7109794745396187,
            "fpr": 0.15350877192982457,
            "logloss": 0.5854315217196807,
            "mae": 0.3623958595685269,
            "precision": 0.732824427480916,
            "recall": 0.7917525773195876
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8117560637803247,
            "auditor_fn_violation": 0.004058428260141978,
            "auditor_fp_violation": 0.014140892361335313,
            "ave_precision_score": 0.7282751268150748,
            "fpr": 0.13721185510428102,
            "logloss": 0.5249328765304866,
            "mae": 0.33628603750604696,
            "precision": 0.7591522157996147,
            "recall": 0.8400852878464818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7168516355076899,
            "auditor_fn_violation": 0.06899981913546754,
            "auditor_fp_violation": 0.07571182053494391,
            "ave_precision_score": 0.5787590249073176,
            "fpr": 0.23026315789473684,
            "logloss": 0.7639265289967571,
            "mae": 0.4893455907106073,
            "precision": 0.6,
            "recall": 0.6494845360824743
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7124745888415784,
            "auditor_fn_violation": 0.06393077735050637,
            "auditor_fp_violation": 0.061701874028341396,
            "ave_precision_score": 0.566394390796651,
            "fpr": 0.23819978046103182,
            "logloss": 0.7703975913262049,
            "mae": 0.4934485706119388,
            "precision": 0.591337099811676,
            "recall": 0.6695095948827292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.8428932340601104,
            "auditor_fn_violation": 0.005973051184662688,
            "auditor_fp_violation": 0.007038600599860309,
            "ave_precision_score": 0.843380044277744,
            "fpr": 0.3848684210526316,
            "logloss": 0.8242136736865802,
            "mae": 0.37472455483951134,
            "precision": 0.5740291262135923,
            "recall": 0.9752577319587629
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.8685388350343861,
            "auditor_fn_violation": 0.008102813515923598,
            "auditor_fp_violation": 0.007726082918179519,
            "ave_precision_score": 0.8687463118464425,
            "fpr": 0.407244785949506,
            "logloss": 0.8331776490358774,
            "mae": 0.3810077485465879,
            "precision": 0.5492102065613609,
            "recall": 0.9637526652452025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.74860398680468,
            "auditor_fn_violation": 0.003942846807741003,
            "auditor_fp_violation": 0.0006830601092896191,
            "ave_precision_score": 0.5425953274262344,
            "fpr": 0.4024122807017544,
            "logloss": 0.7014705912142041,
            "mae": 0.4897405936529762,
            "precision": 0.5435323383084577,
            "recall": 0.9010309278350516
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7443616329890742,
            "auditor_fn_violation": 0.004400141366243894,
            "auditor_fp_violation": 0.011553114026155959,
            "ave_precision_score": 0.5344383829440654,
            "fpr": 0.40285400658616904,
            "logloss": 0.6962675494756836,
            "mae": 0.48702198011814957,
            "precision": 0.5354430379746835,
            "recall": 0.9019189765458422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7920651378613077,
            "auditor_fn_violation": 4.521613311630206e-05,
            "auditor_fp_violation": 0.006920477423065862,
            "ave_precision_score": 0.7876376742358502,
            "fpr": 0.09978070175438597,
            "logloss": 0.5522622451429634,
            "mae": 0.3431655105138034,
            "precision": 0.7936507936507936,
            "recall": 0.7216494845360825
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8036701470138761,
            "auditor_fn_violation": 0.008109835018103773,
            "auditor_fp_violation": 0.009879253567508238,
            "ave_precision_score": 0.8013065904545793,
            "fpr": 0.09330406147091108,
            "logloss": 0.5054490388006186,
            "mae": 0.3234857498953358,
            "precision": 0.8076923076923077,
            "recall": 0.7611940298507462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.773005269811248,
            "auditor_fn_violation": 0.015599565925122086,
            "auditor_fp_violation": 0.017027712724434044,
            "ave_precision_score": 0.6934964672108894,
            "fpr": 0.14912280701754385,
            "logloss": 0.6203520339766293,
            "mae": 0.41626992570072935,
            "precision": 0.7112526539278131,
            "recall": 0.6907216494845361
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7693395794985426,
            "auditor_fn_violation": 0.01415534839523568,
            "auditor_fp_violation": 0.027084750982213385,
            "ave_precision_score": 0.6805947421054749,
            "fpr": 0.1778265642151482,
            "logloss": 0.6093527291468447,
            "mae": 0.41480295211240303,
            "precision": 0.6798418972332015,
            "recall": 0.7334754797441365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.44948668073332937,
            "auditor_fn_violation": 0.0016820401519262018,
            "auditor_fp_violation": 0.0010271580590821318,
            "ave_precision_score": 0.5327047015503337,
            "fpr": 0.0021929824561403508,
            "logloss": 18.15402253734577,
            "mae": 0.5312179432357627,
            "precision": 0.6,
            "recall": 0.006185567010309278
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.41772976086172825,
            "auditor_fn_violation": 0.0009502432950505602,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5162155829853534,
            "fpr": 0.0,
            "logloss": 17.59753688027592,
            "mae": 0.5135677572304158,
            "precision": 1.0,
            "recall": 0.0042643923240938165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7278751788033027,
            "auditor_fn_violation": 0.018629046843913907,
            "auditor_fp_violation": 0.030989358642507913,
            "ave_precision_score": 0.6614786166117845,
            "fpr": 0.2149122807017544,
            "logloss": 0.6442888975333139,
            "mae": 0.43069844272216423,
            "precision": 0.6506238859180036,
            "recall": 0.7525773195876289
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7225202108206953,
            "auditor_fn_violation": 0.01548241230728902,
            "auditor_fp_violation": 0.031669241199815255,
            "ave_precision_score": 0.6430130807475465,
            "fpr": 0.2491767288693743,
            "logloss": 0.636607784980013,
            "mae": 0.43723213153305485,
            "precision": 0.6197654941373534,
            "recall": 0.7889125799573561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8238341385659025,
            "auditor_fn_violation": 0.03028350515463918,
            "auditor_fp_violation": 0.026249024199843873,
            "ave_precision_score": 0.8066460169220462,
            "fpr": 0.16666666666666666,
            "logloss": 0.549782596664321,
            "mae": 0.3202570111882922,
            "precision": 0.7195571955719557,
            "recall": 0.8041237113402062
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8561704680374084,
            "auditor_fn_violation": 0.024296738044137168,
            "auditor_fp_violation": 0.02534632023881072,
            "ave_precision_score": 0.8415041355881052,
            "fpr": 0.1602634467618002,
            "logloss": 0.49591214084929436,
            "mae": 0.29567311011851816,
            "precision": 0.7311233885819521,
            "recall": 0.8464818763326226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5811133594691407,
            "auditor_fn_violation": 0.0028712244528848055,
            "auditor_fp_violation": 0.011165208102222782,
            "ave_precision_score": 0.5823006313287837,
            "fpr": 0.17543859649122806,
            "logloss": 1.5394439070497175,
            "mae": 0.5102036638230308,
            "precision": 0.5675675675675675,
            "recall": 0.4329896907216495
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5354573737199622,
            "auditor_fn_violation": 0.004393119864063719,
            "auditor_fp_violation": 0.011662386815741247,
            "ave_precision_score": 0.5377559205190523,
            "fpr": 0.18441273326015367,
            "logloss": 1.3798578706032696,
            "mae": 0.511381613149627,
            "precision": 0.5459459459459459,
            "recall": 0.43070362473347545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8091352809985207,
            "auditor_fn_violation": 0.007413185024416716,
            "auditor_fp_violation": 0.014051522248243567,
            "ave_precision_score": 0.8149452657089862,
            "fpr": 0.09758771929824561,
            "logloss": 0.5193480502602553,
            "mae": 0.3249791099591867,
            "precision": 0.7990970654627539,
            "recall": 0.7298969072164948
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8364599851598049,
            "auditor_fn_violation": 0.005766993790651573,
            "auditor_fp_violation": 0.014016718736806556,
            "ave_precision_score": 0.8437861499018555,
            "fpr": 0.10318331503841932,
            "logloss": 0.46563699824602617,
            "mae": 0.30254410618239386,
            "precision": 0.7982832618025751,
            "recall": 0.7931769722814499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7647823878502766,
            "auditor_fn_violation": 0.015900253210345456,
            "auditor_fp_violation": 0.01831936398372983,
            "ave_precision_score": 0.7236340553133084,
            "fpr": 0.13267543859649122,
            "logloss": 4.04276372069785,
            "mae": 0.3235508363684207,
            "precision": 0.7274774774774775,
            "recall": 0.6659793814432989
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7786834150845858,
            "auditor_fn_violation": 0.016420953098705945,
            "auditor_fp_violation": 0.02340672822367147,
            "ave_precision_score": 0.7448366439810467,
            "fpr": 0.15697036223929747,
            "logloss": 3.3576668390209523,
            "mae": 0.313313825717814,
            "precision": 0.6989473684210527,
            "recall": 0.7078891257995735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6203475706393133,
            "auditor_fn_violation": 0.05025547115210707,
            "auditor_fp_violation": 0.015502383006697072,
            "ave_precision_score": 0.6114117776362157,
            "fpr": 0.049342105263157895,
            "logloss": 0.7309664816087604,
            "mae": 0.47583334936286537,
            "precision": 0.697986577181208,
            "recall": 0.21443298969072164
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6532549957886709,
            "auditor_fn_violation": 0.05205039566164786,
            "auditor_fp_violation": 0.007361012462064959,
            "ave_precision_score": 0.6475344089550369,
            "fpr": 0.042810098792535674,
            "logloss": 0.6910306744831728,
            "mae": 0.45684767574170027,
            "precision": 0.7291666666666666,
            "recall": 0.22388059701492538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6269118349998708,
            "auditor_fn_violation": 0.006312172183034908,
            "auditor_fp_violation": 0.003402461070709574,
            "ave_precision_score": 0.5445453194842778,
            "fpr": 0.12828947368421054,
            "logloss": 0.700859078430531,
            "mae": 0.4918970036924931,
            "precision": 0.5714285714285714,
            "recall": 0.3216494845360825
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5958832973779042,
            "auditor_fn_violation": 0.011133761957033098,
            "auditor_fp_violation": 0.006586169045005493,
            "ave_precision_score": 0.5173566893953924,
            "fpr": 0.14928649835345773,
            "logloss": 0.7135749482175797,
            "mae": 0.49739001094313534,
            "precision": 0.5228070175438596,
            "recall": 0.31769722814498935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 9292,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8216208079722624,
            "auditor_fn_violation": 0.01355805751492133,
            "auditor_fp_violation": 0.013553350589588734,
            "ave_precision_score": 0.8092522923857431,
            "fpr": 0.15350877192982457,
            "logloss": 2.6651994217498576,
            "mae": 0.2742863798540682,
            "precision": 0.7392923649906891,
            "recall": 0.8185567010309278
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8386596144829018,
            "auditor_fn_violation": 0.007800888922176012,
            "auditor_fp_violation": 0.020630205979208373,
            "ave_precision_score": 0.8258693623946035,
            "fpr": 0.15697036223929747,
            "logloss": 2.106901802719726,
            "mae": 0.2645017832467375,
            "precision": 0.7366482504604052,
            "recall": 0.8528784648187633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.6210596118379605,
            "auditor_fn_violation": 0.02280023512389221,
            "auditor_fp_violation": 0.02154207239410001,
            "ave_precision_score": 0.6223732567329087,
            "fpr": 0.08771929824561403,
            "logloss": 0.6993091684319885,
            "mae": 0.4734451566054894,
            "precision": 0.5789473684210527,
            "recall": 0.2268041237113402
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5664661094175589,
            "auditor_fn_violation": 0.024022899459110285,
            "auditor_fp_violation": 0.025892684186737264,
            "ave_precision_score": 0.5676907201845973,
            "fpr": 0.1163556531284303,
            "logloss": 0.7080734901169499,
            "mae": 0.47770876306979115,
            "precision": 0.5069767441860465,
            "recall": 0.232409381663113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7194328403875625,
            "auditor_fn_violation": 0.011891843009585821,
            "auditor_fp_violation": 0.01862237561115905,
            "ave_precision_score": 0.7073557799397462,
            "fpr": 0.2916666666666667,
            "logloss": 0.6564622385329867,
            "mae": 0.40936295305819886,
            "precision": 0.6111111111111112,
            "recall": 0.8618556701030928
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7514897650868382,
            "auditor_fn_violation": 0.0054229401838229285,
            "auditor_fp_violation": 0.019420754876298255,
            "ave_precision_score": 0.7352748589647221,
            "fpr": 0.29857299670691545,
            "logloss": 0.6472584273502963,
            "mae": 0.39825131782585127,
            "precision": 0.6075036075036075,
            "recall": 0.8976545842217484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.790876307937276,
            "auditor_fn_violation": 0.008912099837221929,
            "auditor_fp_violation": 0.0152276182258926,
            "ave_precision_score": 0.7811892326522956,
            "fpr": 0.13596491228070176,
            "logloss": 0.5616889124022558,
            "mae": 0.35108008526527046,
            "precision": 0.7459016393442623,
            "recall": 0.7505154639175258
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8300152584558379,
            "auditor_fn_violation": 0.0019987876206235588,
            "auditor_fp_violation": 0.01057710933735988,
            "ave_precision_score": 0.8181111467310835,
            "fpr": 0.12403951701427003,
            "logloss": 0.49155873507592784,
            "mae": 0.3169984326715265,
            "precision": 0.7730923694779116,
            "recall": 0.8208955223880597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 9292,
        "test": {
            "accuracy": 0.43969298245614036,
            "auc_prc": 0.5039488972190126,
            "auditor_fn_violation": 0.008550370772291562,
            "auditor_fp_violation": 0.02624388840954847,
            "ave_precision_score": 0.5135342954977813,
            "fpr": 0.2741228070175439,
            "logloss": 10.402093890723659,
            "mae": 0.5483978811830049,
            "precision": 0.47257383966244726,
            "recall": 0.4618556701030928
        },
        "train": {
            "accuracy": 0.43249176728869376,
            "auc_prc": 0.4681330538532368,
            "auditor_fn_violation": 0.013909595818929508,
            "auditor_fp_violation": 0.03194739011875966,
            "ave_precision_score": 0.4876675506415355,
            "fpr": 0.283205268935236,
            "logloss": 10.267397091326584,
            "mae": 0.5602899659683278,
            "precision": 0.44871794871794873,
            "recall": 0.44776119402985076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 9292,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6488109195135555,
            "auditor_fn_violation": 0.028703201302224642,
            "auditor_fp_violation": 0.010168864784913103,
            "ave_precision_score": 0.6072079686843777,
            "fpr": 0.019736842105263157,
            "logloss": 0.8449940640497997,
            "mae": 0.49613362787650866,
            "precision": 0.71875,
            "recall": 0.09484536082474226
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.651224402105479,
            "auditor_fn_violation": 0.032130393976487336,
            "auditor_fp_violation": 0.008414004798068853,
            "ave_precision_score": 0.5904891168665921,
            "fpr": 0.015367727771679473,
            "logloss": 0.8211927575341571,
            "mae": 0.4876174866891457,
            "precision": 0.7878787878787878,
            "recall": 0.11087420042643924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6709472184259475,
            "auditor_fn_violation": 0.017249954783866882,
            "auditor_fp_violation": 0.023580981141378042,
            "ave_precision_score": 0.6844088605129227,
            "fpr": 0.19846491228070176,
            "logloss": 0.6300024761902817,
            "mae": 0.4108023352986365,
            "precision": 0.6715063520871143,
            "recall": 0.7628865979381443
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6815751510032173,
            "auditor_fn_violation": 0.015157082706274187,
            "auditor_fp_violation": 0.025788378342133118,
            "ave_precision_score": 0.6830468577603765,
            "fpr": 0.20636663007683864,
            "logloss": 0.6173274642173757,
            "mae": 0.4078498960162884,
            "precision": 0.6642857142857143,
            "recall": 0.7931769722814499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 9292,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.5203398025735597,
            "auditor_fn_violation": 0.0019849882438053973,
            "auditor_fp_violation": 0.003846706931262583,
            "ave_precision_score": 0.5214559719438876,
            "fpr": 0.08442982456140351,
            "logloss": 0.7961233367199451,
            "mae": 0.5174376431264376,
            "precision": 0.4866666666666667,
            "recall": 0.15051546391752577
        },
        "train": {
            "accuracy": 0.4654226125137212,
            "auc_prc": 0.49496195789097147,
            "auditor_fn_violation": 0.0014323864447559893,
            "auditor_fp_violation": 0.01632883162553209,
            "ave_precision_score": 0.49601732045857483,
            "fpr": 0.09769484083424808,
            "logloss": 0.7865128201668674,
            "mae": 0.5160858268991653,
            "precision": 0.44375,
            "recall": 0.1513859275053305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8367515009722233,
            "auditor_fn_violation": 0.011324380538976313,
            "auditor_fp_violation": 0.018324499774025234,
            "ave_precision_score": 0.8380027771549063,
            "fpr": 0.11403508771929824,
            "logloss": 0.6633326188969451,
            "mae": 0.2779582360149625,
            "precision": 0.7744034707158352,
            "recall": 0.7360824742268042
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8712237593168344,
            "auditor_fn_violation": 0.018611661778920985,
            "auditor_fp_violation": 0.02451684042695859,
            "ave_precision_score": 0.8713788828431387,
            "fpr": 0.11306256860592755,
            "logloss": 0.5623266591040103,
            "mae": 0.2615406762783371,
            "precision": 0.7775377969762419,
            "recall": 0.767590618336887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8328246569790114,
            "auditor_fn_violation": 0.0055480195333695095,
            "auditor_fp_violation": 0.005972924113562598,
            "ave_precision_score": 0.8335643313911021,
            "fpr": 0.1962719298245614,
            "logloss": 0.5616411273789615,
            "mae": 0.3400542440481092,
            "precision": 0.7046204620462047,
            "recall": 0.8804123711340206
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8624170495068522,
            "auditor_fn_violation": 0.006001043863324121,
            "auditor_fp_violation": 0.020975408655398334,
            "ave_precision_score": 0.8626367895159304,
            "fpr": 0.19099890230515917,
            "logloss": 0.5348009430260222,
            "mae": 0.32455873316529965,
            "precision": 0.706081081081081,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7825912960749533,
            "auditor_fn_violation": 0.035937782600831976,
            "auditor_fp_violation": 0.052680368955174826,
            "ave_precision_score": 0.7813620490190256,
            "fpr": 0.32127192982456143,
            "logloss": 1.7503852456917506,
            "mae": 0.3763805674997723,
            "precision": 0.5964187327823691,
            "recall": 0.8927835051546392
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7962489025436352,
            "auditor_fn_violation": 0.028769434932909545,
            "auditor_fp_violation": 0.051686029473851536,
            "ave_precision_score": 0.7945676410918312,
            "fpr": 0.3227222832052689,
            "logloss": 1.6274360949824114,
            "mae": 0.36590834866398975,
            "precision": 0.5922330097087378,
            "recall": 0.9104477611940298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8179923790568512,
            "auditor_fn_violation": 0.01145550732501357,
            "auditor_fp_violation": 0.006763835819055837,
            "ave_precision_score": 0.7716749546649743,
            "fpr": 0.1699561403508772,
            "logloss": 0.5644664610633386,
            "mae": 0.36040228236826105,
            "precision": 0.7140221402214022,
            "recall": 0.797938144329897
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8378085317827044,
            "auditor_fn_violation": 0.008882200257923183,
            "auditor_fp_violation": 0.00831714937093642,
            "ave_precision_score": 0.7910685896299006,
            "fpr": 0.17014270032930845,
            "logloss": 0.5232826508910189,
            "mae": 0.34196616643804617,
            "precision": 0.7222222222222222,
            "recall": 0.8592750533049041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5139064718634547,
            "auditor_fn_violation": 0.022427202025682765,
            "auditor_fp_violation": 0.012551871481983647,
            "ave_precision_score": 0.539892051133001,
            "fpr": 0.43969298245614036,
            "logloss": 0.7152510119266019,
            "mae": 0.49138048676806584,
            "precision": 0.5260047281323877,
            "recall": 0.9175257731958762
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5352546934002473,
            "auditor_fn_violation": 0.02490292773235906,
            "auditor_fp_violation": 0.01086270867377602,
            "ave_precision_score": 0.5636338276479899,
            "fpr": 0.4456641053787047,
            "logloss": 0.7104090048683827,
            "mae": 0.4895069281827213,
            "precision": 0.5149342891278376,
            "recall": 0.9189765458422174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8478280738738888,
            "auditor_fn_violation": 0.013784138180502826,
            "auditor_fp_violation": 0.00806575865894244,
            "ave_precision_score": 0.8481196011019303,
            "fpr": 0.01864035087719298,
            "logloss": 0.8218095218786221,
            "mae": 0.3637903343703232,
            "precision": 0.9227272727272727,
            "recall": 0.41855670103092785
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8776395684037194,
            "auditor_fn_violation": 0.009125612333502632,
            "auditor_fp_violation": 0.005831193407870621,
            "ave_precision_score": 0.8778093348714187,
            "fpr": 0.01756311745334797,
            "logloss": 0.6857348757068553,
            "mae": 0.33170607141088737,
            "precision": 0.9313304721030042,
            "recall": 0.4626865671641791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7859328114665026,
            "auditor_fn_violation": 0.01611050822933623,
            "auditor_fp_violation": 0.015548605119355775,
            "ave_precision_score": 0.7864439979552992,
            "fpr": 0.17543859649122806,
            "logloss": 0.6453403961242713,
            "mae": 0.34337358910328986,
            "precision": 0.7031539888682746,
            "recall": 0.7814432989690722
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7945310518161347,
            "auditor_fn_violation": 0.011845274177957636,
            "auditor_fp_violation": 0.014235264315977174,
            "ave_precision_score": 0.7949217955132009,
            "fpr": 0.21075740944017562,
            "logloss": 0.6478644638943634,
            "mae": 0.3487385044735166,
            "precision": 0.6589698046181173,
            "recall": 0.7910447761194029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7627682177713703,
            "auditor_fn_violation": 0.0016323024054982816,
            "auditor_fp_violation": 0.001527897612884683,
            "ave_precision_score": 0.5322868316118977,
            "fpr": 0.4605263157894737,
            "logloss": 16.171483938100376,
            "mae": 0.4682017543859649,
            "precision": 0.532293986636971,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7549054226126176,
            "auditor_fn_violation": 0.0025277407848635137,
            "auditor_fp_violation": 0.0007723599445688989,
            "ave_precision_score": 0.514981598404006,
            "fpr": 0.4796926454445664,
            "logloss": 16.757945763586736,
            "mae": 0.48518111964873767,
            "precision": 0.5149833518312985,
            "recall": 0.9893390191897654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7077692703006391,
            "auditor_fn_violation": 0.012178965454874296,
            "auditor_fp_violation": 0.00790398126463701,
            "ave_precision_score": 0.7085707373234079,
            "fpr": 0.14364035087719298,
            "logloss": 0.7155177994216959,
            "mae": 0.4091270394161904,
            "precision": 0.7015945330296127,
            "recall": 0.6350515463917525
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6781975506777091,
            "auditor_fn_violation": 0.010862263872732937,
            "auditor_fp_violation": 0.012397494672951514,
            "ave_precision_score": 0.6800054147145059,
            "fpr": 0.132821075740944,
            "logloss": 0.7694623555456201,
            "mae": 0.3965807772720983,
            "precision": 0.7218390804597701,
            "recall": 0.6695095948827292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.793304797466238,
            "auditor_fn_violation": 0.01770889853499729,
            "auditor_fp_violation": 0.02662907268170426,
            "ave_precision_score": 0.7810391880622398,
            "fpr": 0.1337719298245614,
            "logloss": 2.170990191920128,
            "mae": 0.28301857278456294,
            "precision": 0.7458333333333333,
            "recall": 0.7381443298969073
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8130652098718865,
            "auditor_fn_violation": 0.02218326588790406,
            "auditor_fp_violation": 0.024966348947752712,
            "ave_precision_score": 0.8014836781350181,
            "fpr": 0.141602634467618,
            "logloss": 1.7692613517960027,
            "mae": 0.2649551509395623,
            "precision": 0.7361963190184049,
            "recall": 0.767590618336887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8614537248810221,
            "auditor_fn_violation": 0.0043317055525411464,
            "auditor_fp_violation": 0.007369859073914293,
            "ave_precision_score": 0.8617653500286353,
            "fpr": 0.09210526315789473,
            "logloss": 0.4971930393556297,
            "mae": 0.3162237748027812,
            "precision": 0.8082191780821918,
            "recall": 0.7298969072164948
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8734972082609678,
            "auditor_fn_violation": 0.004145026787030816,
            "auditor_fp_violation": 0.013147503365105227,
            "ave_precision_score": 0.8737160460585616,
            "fpr": 0.09440175631174534,
            "logloss": 0.4583892493092446,
            "mae": 0.29738604494408344,
            "precision": 0.8088888888888889,
            "recall": 0.7761194029850746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 9292,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7604300312344434,
            "auditor_fn_violation": 0.002197504069451974,
            "auditor_fp_violation": 0.0008551090841858758,
            "ave_precision_score": 0.7607777274538459,
            "fpr": 0.01644736842105263,
            "logloss": 0.6311392867783358,
            "mae": 0.4304028544820061,
            "precision": 0.9162011173184358,
            "recall": 0.33814432989690724
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7335587924167124,
            "auditor_fn_violation": 0.007913232957058836,
            "auditor_fp_violation": 0.005883346330172701,
            "ave_precision_score": 0.7338405656028975,
            "fpr": 0.020856201975850714,
            "logloss": 0.8012600032841469,
            "mae": 0.42339442459340937,
            "precision": 0.8983957219251337,
            "recall": 0.3582089552238806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8360617472880265,
            "auditor_fn_violation": 0.015974859829987347,
            "auditor_fp_violation": 0.023049426845803037,
            "ave_precision_score": 0.83680478443556,
            "fpr": 0.1425438596491228,
            "logloss": 0.7016344000969773,
            "mae": 0.2760585838076654,
            "precision": 0.7430830039525692,
            "recall": 0.7752577319587629
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8700696827706162,
            "auditor_fn_violation": 0.017485880929366034,
            "auditor_fp_violation": 0.026990379027571516,
            "ave_precision_score": 0.8702263935207548,
            "fpr": 0.145993413830955,
            "logloss": 0.6185265347251964,
            "mae": 0.25983051632114285,
            "precision": 0.7407407407407407,
            "recall": 0.8102345415778252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8544352976032759,
            "auditor_fn_violation": 0.014812805208898534,
            "auditor_fp_violation": 0.006453120506183493,
            "ave_precision_score": 0.8517996906476673,
            "fpr": 0.08223684210526316,
            "logloss": 0.5014084638068069,
            "mae": 0.31592766961425933,
            "precision": 0.8197115384615384,
            "recall": 0.7030927835051546
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8458651827433368,
            "auditor_fn_violation": 0.019880213172806187,
            "auditor_fp_violation": 0.007527405118933496,
            "ave_precision_score": 0.8599690237242797,
            "fpr": 0.0867178924259056,
            "logloss": 0.4730635156426951,
            "mae": 0.3038331020406716,
            "precision": 0.8136792452830188,
            "recall": 0.7356076759061834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7922991064978939,
            "auditor_fn_violation": 0.009122354856212706,
            "auditor_fp_violation": 0.012148711943793914,
            "ave_precision_score": 0.7936730459702435,
            "fpr": 0.13925438596491227,
            "logloss": 0.6704112496993024,
            "mae": 0.30373179405905193,
            "precision": 0.7392197125256673,
            "recall": 0.7422680412371134
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8373549865920595,
            "auditor_fn_violation": 0.00669617257916159,
            "auditor_fp_violation": 0.011011717023210533,
            "ave_precision_score": 0.8375825921062867,
            "fpr": 0.15367727771679474,
            "logloss": 0.6069001380120896,
            "mae": 0.2949916500553211,
            "precision": 0.7233201581027668,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7689480573378777,
            "auditor_fn_violation": 0.00092466992222826,
            "auditor_fp_violation": 0.007023193228974072,
            "ave_precision_score": 0.7513526846492898,
            "fpr": 0.09320175438596491,
            "logloss": 0.5798205293594486,
            "mae": 0.36073186099039095,
            "precision": 0.8018648018648019,
            "recall": 0.709278350515464
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.7814997191084834,
            "auditor_fn_violation": 0.0024200777514341437,
            "auditor_fp_violation": 0.012752631239103772,
            "ave_precision_score": 0.7594632282904714,
            "fpr": 0.09989023051591657,
            "logloss": 0.5420063044578411,
            "mae": 0.3468376571715336,
            "precision": 0.7955056179775281,
            "recall": 0.7547974413646056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5168644872490504,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5316671188279979,
            "fpr": 0.4682017543859649,
            "logloss": 0.692867559722522,
            "mae": 0.49824296343221997,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5105129441392691,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5146292997923976,
            "fpr": 0.48518111964873767,
            "logloss": 0.698169716745438,
            "mae": 0.49918117134552753,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5408345570903004,
            "auditor_fn_violation": 0.020507777174896002,
            "auditor_fp_violation": 0.021757775586507256,
            "ave_precision_score": 0.5428773867922013,
            "fpr": 0.3815789473684211,
            "logloss": 0.6854925618139207,
            "mae": 0.4885636051103734,
            "precision": 0.5549872122762148,
            "recall": 0.8948453608247423
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5298945993552102,
            "auditor_fn_violation": 0.03573476509564456,
            "auditor_fp_violation": 0.0166591334667786,
            "ave_precision_score": 0.5319412780022996,
            "fpr": 0.3995609220636663,
            "logloss": 0.6998050915258156,
            "mae": 0.49449312628035225,
            "precision": 0.5309278350515464,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6595456645518118,
            "auditor_fn_violation": 0.04372400072345813,
            "auditor_fp_violation": 0.07328772751551009,
            "ave_precision_score": 0.6474584776894113,
            "fpr": 0.26206140350877194,
            "logloss": 1.893052183674833,
            "mae": 0.37031029097022583,
            "precision": 0.6323076923076923,
            "recall": 0.8474226804123711
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6890187787100396,
            "auditor_fn_violation": 0.04344203398875156,
            "auditor_fp_violation": 0.07501577005031516,
            "ave_precision_score": 0.6734751197478654,
            "fpr": 0.265642151481888,
            "logloss": 1.8432032550871165,
            "mae": 0.36452356753329024,
            "precision": 0.6259659969088099,
            "recall": 0.8635394456289979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5474518661589389,
            "auditor_fn_violation": 0.009536082474226805,
            "auditor_fp_violation": 0.010371728501581821,
            "ave_precision_score": 0.5451302703419072,
            "fpr": 0.4298245614035088,
            "logloss": 0.7351083632112294,
            "mae": 0.4935144688607308,
            "precision": 0.5294117647058824,
            "recall": 0.9092783505154639
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.48065136538037456,
            "auditor_fn_violation": 0.017333748382128877,
            "auditor_fp_violation": 0.01358956146842763,
            "ave_precision_score": 0.48600404483774856,
            "fpr": 0.446761800219539,
            "logloss": 0.765402795099691,
            "mae": 0.5064683207172724,
            "precision": 0.5078597339782346,
            "recall": 0.8955223880597015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8222543658608057,
            "auditor_fn_violation": 0.004306836679327184,
            "auditor_fp_violation": 0.0052282345207280536,
            "ave_precision_score": 0.766180719364014,
            "fpr": 0.13706140350877194,
            "logloss": 0.5602994779761291,
            "mae": 0.3467297056473367,
            "precision": 0.749498997995992,
            "recall": 0.7711340206185567
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8355166789165412,
            "auditor_fn_violation": 0.0020198521271640856,
            "auditor_fp_violation": 0.010261708331056822,
            "ave_precision_score": 0.7785163334994936,
            "fpr": 0.12733260153677278,
            "logloss": 0.5175383172946383,
            "mae": 0.32463550870434577,
            "precision": 0.7675350701402806,
            "recall": 0.8166311300639659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7515076591203296,
            "auditor_fn_violation": 0.002222372942665948,
            "auditor_fp_violation": 0.008245511319281817,
            "ave_precision_score": 0.7521201834646761,
            "fpr": 0.13157894736842105,
            "logloss": 0.5655215719690807,
            "mae": 0.37257521656717646,
            "precision": 0.7494780793319415,
            "recall": 0.7402061855670103
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.7335126460464798,
            "auditor_fn_violation": 0.004070130763775606,
            "auditor_fp_violation": 0.007013326313384431,
            "ave_precision_score": 0.7353514854512642,
            "fpr": 0.12733260153677278,
            "logloss": 0.5508613132218134,
            "mae": 0.36412572354470857,
            "precision": 0.7593360995850622,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.5886975956367386,
            "auditor_fn_violation": 0.006260173629951167,
            "auditor_fp_violation": 0.011719873454127124,
            "ave_precision_score": 0.5904817246545366,
            "fpr": 0.26864035087719296,
            "logloss": 0.6673322275415944,
            "mae": 0.4784044518151827,
            "precision": 0.6147798742138365,
            "recall": 0.8061855670103093
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.5693605302556455,
            "auditor_fn_violation": 9.127952834229627e-05,
            "auditor_fp_violation": 0.02043649512494351,
            "ave_precision_score": 0.5711373718098225,
            "fpr": 0.2996706915477497,
            "logloss": 0.6669460940284238,
            "mae": 0.47873766574718296,
            "precision": 0.588855421686747,
            "recall": 0.8336886993603412
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 9292,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.4762507474486202,
            "auditor_fn_violation": 0.12430819316332069,
            "auditor_fp_violation": 0.11415321089609272,
            "ave_precision_score": 0.4687496547835898,
            "fpr": 0.20394736842105263,
            "logloss": 0.6999315716625768,
            "mae": 0.49967379828816966,
            "precision": 0.5550239234449761,
            "recall": 0.47835051546391755
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.4916656341524424,
            "auditor_fn_violation": 0.11866806784643508,
            "auditor_fp_violation": 0.11405347412966707,
            "ave_precision_score": 0.4710107082376268,
            "fpr": 0.18331503841931943,
            "logloss": 0.6875599319897727,
            "mae": 0.49362150413668116,
            "precision": 0.6004784688995215,
            "recall": 0.535181236673774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7942268213457231,
            "auditor_fn_violation": 0.007300144691625974,
            "auditor_fp_violation": 0.018612104030568233,
            "ave_precision_score": 0.6490681079284645,
            "fpr": 0.2565789473684211,
            "logloss": 0.7080278010588986,
            "mae": 0.42316663481311445,
            "precision": 0.6459909228441755,
            "recall": 0.8804123711340206
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7833883352085829,
            "auditor_fn_violation": 0.01153164708057642,
            "auditor_fp_violation": 0.025892684186737274,
            "ave_precision_score": 0.6221165823558663,
            "fpr": 0.2854006586169045,
            "logloss": 0.6987831068003756,
            "mae": 0.4284878767225339,
            "precision": 0.6148148148148148,
            "recall": 0.8848614072494669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7461242543226967,
            "auditor_fn_violation": 0.012823295351781514,
            "auditor_fp_violation": 0.014069497514277498,
            "ave_precision_score": 0.7335746627796963,
            "fpr": 0.2138157894736842,
            "logloss": 0.6134623399118826,
            "mae": 0.43645074693159314,
            "precision": 0.656084656084656,
            "recall": 0.7670103092783506
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7387999416405339,
            "auditor_fn_violation": 0.013815975789860487,
            "auditor_fp_violation": 0.021104549224908238,
            "ave_precision_score": 0.7242044551387696,
            "fpr": 0.2217343578485181,
            "logloss": 0.6145800086973117,
            "mae": 0.4363756693171748,
            "precision": 0.6443661971830986,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7401707503671437,
            "auditor_fn_violation": 0.015068276361005611,
            "auditor_fp_violation": 0.016491022638563623,
            "ave_precision_score": 0.7408515172587733,
            "fpr": 0.15679824561403508,
            "logloss": 0.9451993556674133,
            "mae": 0.3384215101567015,
            "precision": 0.7045454545454546,
            "recall": 0.7030927835051546
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7675137876153743,
            "auditor_fn_violation": 0.007552795845143114,
            "auditor_fp_violation": 0.026041692536171786,
            "ave_precision_score": 0.7679512354057689,
            "fpr": 0.18221734357848518,
            "logloss": 0.8898321684992722,
            "mae": 0.3396599145011177,
            "precision": 0.6738703339882122,
            "recall": 0.7313432835820896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.6784761078109347,
            "auditor_fn_violation": 0.0035336408030385387,
            "auditor_fp_violation": 0.00206715559390279,
            "ave_precision_score": 0.6804352031387336,
            "fpr": 0.01644736842105263,
            "logloss": 4.211203749082652,
            "mae": 0.5338046216227427,
            "precision": 0.34782608695652173,
            "recall": 0.016494845360824743
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.6878423070773825,
            "auditor_fn_violation": 0.0010181178161255985,
            "auditor_fp_violation": 0.0048328374666593826,
            "ave_precision_score": 0.6896533445379132,
            "fpr": 0.013172338090010977,
            "logloss": 4.0999649661486295,
            "mae": 0.5201332305623264,
            "precision": 0.25,
            "recall": 0.008528784648187633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.799759217685947,
            "auditor_fn_violation": 0.01580303852414542,
            "auditor_fp_violation": 0.01106506019146226,
            "ave_precision_score": 0.8001764358990078,
            "fpr": 0.11732456140350878,
            "logloss": 0.9722289655647546,
            "mae": 0.3357597840264093,
            "precision": 0.7584650112866818,
            "recall": 0.6927835051546392
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8110227017840379,
            "auditor_fn_violation": 0.014693663562382534,
            "auditor_fp_violation": 0.010644163094605407,
            "ave_precision_score": 0.8114807484383166,
            "fpr": 0.13172338090010977,
            "logloss": 0.8284097159160558,
            "mae": 0.31874564005721034,
            "precision": 0.7419354838709677,
            "recall": 0.7356076759061834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.725288892956525,
            "auditor_fn_violation": 0.006298607343100022,
            "auditor_fp_violation": 0.0038467069312625906,
            "ave_precision_score": 0.5882998080221047,
            "fpr": 0.20723684210526316,
            "logloss": 0.6733409235716973,
            "mae": 0.4793961216091064,
            "precision": 0.6204819277108434,
            "recall": 0.6371134020618556
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7104042129513929,
            "auditor_fn_violation": 0.0015774974898129708,
            "auditor_fp_violation": 0.0014155793196278757,
            "ave_precision_score": 0.5698340210312002,
            "fpr": 0.21185510428100987,
            "logloss": 0.6752520129115229,
            "mae": 0.48032854283156956,
            "precision": 0.602880658436214,
            "recall": 0.6247334754797441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7661806539290262,
            "auditor_fn_violation": 0.0009540604087538433,
            "auditor_fp_violation": 2.31110563293615e-05,
            "ave_precision_score": 0.5342879545830793,
            "fpr": 0.4616228070175439,
            "logloss": 15.969596988696184,
            "mae": 0.46381564308202355,
            "precision": 0.5342920353982301,
            "recall": 0.9958762886597938
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.758209600803832,
            "auditor_fn_violation": 0.0015728164883595196,
            "auditor_fp_violation": 0.003072055470841545,
            "ave_precision_score": 0.5195027969514652,
            "fpr": 0.47310647639956094,
            "logloss": 16.378184350518485,
            "mae": 0.4764019430159733,
            "precision": 0.5195094760312151,
            "recall": 0.9936034115138592
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8444075912972491,
            "auditor_fn_violation": 0.003101826731777903,
            "auditor_fp_violation": 0.0023367845844118524,
            "ave_precision_score": 0.8445530895165101,
            "fpr": 0.08333333333333333,
            "logloss": 0.522417668306579,
            "mae": 0.3305689508356808,
            "precision": 0.8155339805825242,
            "recall": 0.6927835051546392
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.854020744481629,
            "auditor_fn_violation": 0.005331660655480637,
            "auditor_fp_violation": 0.010433067932906508,
            "ave_precision_score": 0.8541858968094904,
            "fpr": 0.0867178924259056,
            "logloss": 0.4865501684271467,
            "mae": 0.3114662727363547,
            "precision": 0.8119047619047619,
            "recall": 0.7270788912579957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7943913233692729,
            "auditor_fn_violation": 0.01847757279797432,
            "auditor_fp_violation": 0.02104646863059288,
            "ave_precision_score": 0.7937761852795805,
            "fpr": 0.12719298245614036,
            "logloss": 0.9972819555886088,
            "mae": 0.31342931692039167,
            "precision": 0.7461706783369803,
            "recall": 0.7030927835051546
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.79907089146572,
            "auditor_fn_violation": 0.01290084000571083,
            "auditor_fp_violation": 0.023061525547481514,
            "ave_precision_score": 0.7982784382279843,
            "fpr": 0.15148188803512624,
            "logloss": 0.89445879234161,
            "mae": 0.30010810369087954,
            "precision": 0.7195121951219512,
            "recall": 0.7547974413646056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8622293750446663,
            "auditor_fn_violation": 0.010845089527943568,
            "auditor_fp_violation": 0.008286597641645096,
            "ave_precision_score": 0.8533509770722846,
            "fpr": 0.08662280701754387,
            "logloss": 0.5037390315492879,
            "mae": 0.30647952439418685,
            "precision": 0.8132387706855791,
            "recall": 0.709278350515464
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8775370542929057,
            "auditor_fn_violation": 0.004882284515949344,
            "auditor_fp_violation": 0.010485220855208588,
            "ave_precision_score": 0.869535548853619,
            "fpr": 0.0889132821075741,
            "logloss": 0.4629114418303936,
            "mae": 0.28503242652335753,
            "precision": 0.8163265306122449,
            "recall": 0.767590618336887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8001622512039701,
            "auditor_fn_violation": 0.006081569904141796,
            "auditor_fp_violation": 0.012264267225440658,
            "ave_precision_score": 0.7978079379318835,
            "fpr": 0.10307017543859649,
            "logloss": 0.5942015629993589,
            "mae": 0.3487257701436695,
            "precision": 0.7848970251716247,
            "recall": 0.7072164948453609
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8257628040941217,
            "auditor_fn_violation": 0.006630638558813278,
            "auditor_fp_violation": 0.0055331767090015934,
            "ave_precision_score": 0.8189028966013676,
            "fpr": 0.10318331503841932,
            "logloss": 0.5803321056218094,
            "mae": 0.33879090350532226,
            "precision": 0.7863636363636364,
            "recall": 0.7377398720682303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7984842013166332,
            "auditor_fn_violation": 0.011654458310725273,
            "auditor_fp_violation": 0.01693270060396894,
            "ave_precision_score": 0.7989200691455918,
            "fpr": 0.11403508771929824,
            "logloss": 0.8915415477720612,
            "mae": 0.3024079809801323,
            "precision": 0.7598152424942263,
            "recall": 0.6783505154639176
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8258534638216386,
            "auditor_fn_violation": 0.008737089212866206,
            "auditor_fp_violation": 0.015747699062737482,
            "ave_precision_score": 0.8261261312741737,
            "fpr": 0.13062568605927552,
            "logloss": 0.783977952943362,
            "mae": 0.29073444949811755,
            "precision": 0.741304347826087,
            "recall": 0.7270788912579957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7840413870113694,
            "auditor_fn_violation": 0.024608880448544042,
            "auditor_fp_violation": 0.04976324006738157,
            "ave_precision_score": 0.7843454979877923,
            "fpr": 0.26535087719298245,
            "logloss": 0.6055726031852979,
            "mae": 0.4369159512938687,
            "precision": 0.639344262295082,
            "recall": 0.8845360824742268
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.790683840858874,
            "auditor_fn_violation": 0.02711236041838791,
            "auditor_fp_violation": 0.05323819978046105,
            "ave_precision_score": 0.7910201063278125,
            "fpr": 0.2689352360043908,
            "logloss": 0.5981893317155108,
            "mae": 0.43356501901152716,
            "precision": 0.6287878787878788,
            "recall": 0.8848614072494669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8131279657670075,
            "auditor_fn_violation": 0.007209712425393383,
            "auditor_fp_violation": 0.018075413944697808,
            "ave_precision_score": 0.8134177132216895,
            "fpr": 0.13925438596491227,
            "logloss": 0.9068732073652227,
            "mae": 0.27996103345487844,
            "precision": 0.7449799196787149,
            "recall": 0.7649484536082474
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8257923981349996,
            "auditor_fn_violation": 0.010848220868372586,
            "auditor_fp_violation": 0.0220606861337797,
            "ave_precision_score": 0.8261868170160128,
            "fpr": 0.15916575192096596,
            "logloss": 0.8056283541588074,
            "mae": 0.27332402753577834,
            "precision": 0.7184466019417476,
            "recall": 0.7889125799573561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.8333228105928723,
            "auditor_fn_violation": 0.0014243081931633156,
            "auditor_fp_violation": 0.0043217675335880685,
            "ave_precision_score": 0.8336398761446999,
            "fpr": 0.025219298245614034,
            "logloss": 0.9228528835101035,
            "mae": 0.3549367752325811,
            "precision": 0.8954545454545455,
            "recall": 0.4061855670103093
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.84296291578573,
            "auditor_fn_violation": 0.0034639410755536986,
            "auditor_fp_violation": 0.006198747336475754,
            "ave_precision_score": 0.8431953454441878,
            "fpr": 0.02854006586169045,
            "logloss": 0.8044849184351345,
            "mae": 0.333099504798124,
            "precision": 0.8884120171673819,
            "recall": 0.44136460554371004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5778714152973825,
            "auditor_fn_violation": 0.007415445831072527,
            "auditor_fp_violation": 0.01774929126093924,
            "ave_precision_score": 0.5798192328951705,
            "fpr": 0.3958333333333333,
            "logloss": 0.7516423857976956,
            "mae": 0.46921285122567624,
            "precision": 0.558679706601467,
            "recall": 0.9422680412371134
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5447019887796345,
            "auditor_fn_violation": 0.015531562822550258,
            "auditor_fp_violation": 0.013549825908578407,
            "ave_precision_score": 0.5464349231472081,
            "fpr": 0.42151481888035125,
            "logloss": 0.7787571553912598,
            "mae": 0.48078496023014794,
            "precision": 0.5334143377885784,
            "recall": 0.9360341151385928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 9292,
        "test": {
            "accuracy": 0.35964912280701755,
            "auc_prc": 0.45843753048830915,
            "auditor_fn_violation": 0.004123711340206181,
            "auditor_fp_violation": 0.010477012202637751,
            "ave_precision_score": 0.46014613364696655,
            "fpr": 0.3201754385964912,
            "logloss": 2.556988444126034,
            "mae": 0.6382087458965671,
            "precision": 0.3979381443298969,
            "recall": 0.3979381443298969
        },
        "train": {
            "accuracy": 0.3413830954994512,
            "auc_prc": 0.4219015377765124,
            "auditor_fn_violation": 0.006349778471606235,
            "auditor_fp_violation": 0.0099934933020747,
            "ave_precision_score": 0.42369440267096264,
            "fpr": 0.3534577387486279,
            "logloss": 2.6908635188710552,
            "mae": 0.6582823071670213,
            "precision": 0.3723196881091618,
            "recall": 0.4072494669509595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7613507764729048,
            "auditor_fn_violation": 0.019002079942123353,
            "auditor_fp_violation": 0.010004519495459966,
            "ave_precision_score": 0.7468929071120036,
            "fpr": 0.17324561403508773,
            "logloss": 0.5917489490667831,
            "mae": 0.3973277200854857,
            "precision": 0.6943907156673114,
            "recall": 0.7402061855670103
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.771478536356498,
            "auditor_fn_violation": 0.019283385487491193,
            "auditor_fp_violation": 0.007860190432670578,
            "ave_precision_score": 0.758919004545638,
            "fpr": 0.150384193194292,
            "logloss": 0.5663255163039423,
            "mae": 0.3835901763621395,
            "precision": 0.7276341948310139,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7299177727128799,
            "auditor_fn_violation": 0.013189546030023515,
            "auditor_fp_violation": 0.005834257775586511,
            "ave_precision_score": 0.5498659710896596,
            "fpr": 0.34100877192982454,
            "logloss": 0.6945185453260107,
            "mae": 0.49290001000228684,
            "precision": 0.5544412607449857,
            "recall": 0.797938144329897
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7253511019272463,
            "auditor_fn_violation": 0.015957533954814297,
            "auditor_fp_violation": 0.009660707988337628,
            "ave_precision_score": 0.5442967312176767,
            "fpr": 0.33040614709110866,
            "logloss": 0.687497422346221,
            "mae": 0.48887937508613427,
            "precision": 0.5520833333333334,
            "recall": 0.7910447761194029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5828288344248463,
            "auditor_fn_violation": 0.0005425935973955488,
            "auditor_fp_violation": 0.022055651423641073,
            "ave_precision_score": 0.5453711623401556,
            "fpr": 0.0756578947368421,
            "logloss": 0.7847584572840187,
            "mae": 0.49867573971941803,
            "precision": 0.543046357615894,
            "recall": 0.16907216494845362
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5602263987009857,
            "auditor_fn_violation": 0.015166444709181088,
            "auditor_fp_violation": 0.031028505297246822,
            "ave_precision_score": 0.5250914844329253,
            "fpr": 0.08342480790340286,
            "logloss": 0.7711176547790684,
            "mae": 0.4958416089889901,
            "precision": 0.5096774193548387,
            "recall": 0.16844349680170576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.36766069246895,
            "mae": 0.5317982456140351,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.781214192330527,
            "mae": 0.5148188803512623,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.810698685473068,
            "auditor_fn_violation": 0.005446283233857839,
            "auditor_fp_violation": 0.0106002711697276,
            "ave_precision_score": 0.810205743539933,
            "fpr": 0.2050438596491228,
            "logloss": 0.9849042910385162,
            "mae": 0.30614706488855165,
            "precision": 0.6949429037520392,
            "recall": 0.8783505154639175
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8369623207881204,
            "auditor_fn_violation": 0.003723736656220232,
            "auditor_fp_violation": 0.020851235030869567,
            "ave_precision_score": 0.8371664963124333,
            "fpr": 0.20417124039517015,
            "logloss": 0.8381209921050107,
            "mae": 0.28594534023655693,
            "precision": 0.6955810147299509,
            "recall": 0.906183368869936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5235179096775913,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5252682176583159,
            "fpr": 0.4682017543859649,
            "logloss": 0.690896485607944,
            "mae": 0.4983742067819102,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.4967326514794305,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4987213032284779,
            "fpr": 0.48518111964873767,
            "logloss": 0.6922945349381243,
            "mae": 0.49907589331678187,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6920619831438001,
            "auditor_fn_violation": 0.013732139627419074,
            "auditor_fp_violation": 0.017898229179506144,
            "ave_precision_score": 0.6397623843874913,
            "fpr": 0.14364035087719298,
            "logloss": 0.6280266600499186,
            "mae": 0.4273933233660564,
            "precision": 0.7164502164502164,
            "recall": 0.6824742268041237
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6259383061779449,
            "auditor_fn_violation": 0.014740473576917046,
            "auditor_fp_violation": 0.024424951944807313,
            "ave_precision_score": 0.6195381144958988,
            "fpr": 0.16575192096597147,
            "logloss": 0.6343598173450393,
            "mae": 0.42908222461374873,
            "precision": 0.6893004115226338,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8550912245296425,
            "auditor_fn_violation": 0.00446961475854585,
            "auditor_fp_violation": 0.0052385061013188764,
            "ave_precision_score": 0.8554237980696845,
            "fpr": 0.08771929824561403,
            "logloss": 0.6601532032651017,
            "mae": 0.26537782966007045,
            "precision": 0.8113207547169812,
            "recall": 0.709278350515464
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8736130906131357,
            "auditor_fn_violation": 0.007206401737587746,
            "auditor_fp_violation": 0.014041553461712306,
            "ave_precision_score": 0.8737978928572276,
            "fpr": 0.09001097694840834,
            "logloss": 0.5898230735545917,
            "mae": 0.24118764485252556,
            "precision": 0.8136363636363636,
            "recall": 0.7633262260127932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.725934104859036,
            "auditor_fn_violation": 0.09704738650750588,
            "auditor_fp_violation": 0.09969082542421628,
            "ave_precision_score": 0.5683515734084272,
            "fpr": 0.29276315789473684,
            "logloss": 0.6840094972688565,
            "mae": 0.4931815459245914,
            "precision": 0.5728,
            "recall": 0.7381443298969073
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7166051125477475,
            "auditor_fn_violation": 0.08790920729580887,
            "auditor_fp_violation": 0.10728104464786846,
            "ave_precision_score": 0.5513903031398517,
            "fpr": 0.3062568605927552,
            "logloss": 0.6847400136700637,
            "mae": 0.49354197259922844,
            "precision": 0.5557324840764332,
            "recall": 0.744136460554371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8378820824163185,
            "auditor_fn_violation": 0.010230150117561948,
            "auditor_fp_violation": 0.008915731952832904,
            "ave_precision_score": 0.7743141967444936,
            "fpr": 0.13815789473684212,
            "logloss": 5.079897933263064,
            "mae": 0.24034992249299714,
            "precision": 0.7562862669245648,
            "recall": 0.8061855670103093
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8550230474971076,
            "auditor_fn_violation": 0.006113387898206947,
            "auditor_fp_violation": 0.005945433142437088,
            "ave_precision_score": 0.7939959464778803,
            "fpr": 0.132821075740944,
            "logloss": 4.303761309753726,
            "mae": 0.21590660657566088,
            "precision": 0.763671875,
            "recall": 0.8336886993603412
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7818971046747504,
            "auditor_fn_violation": 0.017568728522336773,
            "auditor_fp_violation": 0.0172511196022844,
            "ave_precision_score": 0.7288327704685391,
            "fpr": 0.1206140350877193,
            "logloss": 4.2968309937461076,
            "mae": 0.2851993974289455,
            "precision": 0.7674418604651163,
            "recall": 0.7484536082474227
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7984653201956482,
            "auditor_fn_violation": 0.026304887667667625,
            "auditor_fp_violation": 0.017560633980857405,
            "ave_precision_score": 0.7503815084026684,
            "fpr": 0.11525795828759605,
            "logloss": 3.9867409435902426,
            "mae": 0.2638989634925423,
            "precision": 0.776595744680851,
            "recall": 0.7782515991471215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8182901980499648,
            "auditor_fn_violation": 0.017091698317959855,
            "auditor_fp_violation": 0.014187620691071942,
            "ave_precision_score": 0.8190464154226417,
            "fpr": 0.15460526315789475,
            "logloss": 0.8735633173996147,
            "mae": 0.2794751779397453,
            "precision": 0.72568093385214,
            "recall": 0.7690721649484537
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.830013130069853,
            "auditor_fn_violation": 0.01850399874549161,
            "auditor_fp_violation": 0.024325613045184297,
            "ave_precision_score": 0.8304317574348334,
            "fpr": 0.16136114160263446,
            "logloss": 0.7842271379411582,
            "mae": 0.26971129602122507,
            "precision": 0.7210626185958254,
            "recall": 0.8102345415778252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7590944955536851,
            "auditor_fn_violation": 0.013472146862000366,
            "auditor_fp_violation": 0.03571428571428571,
            "ave_precision_score": 0.6003139573300461,
            "fpr": 0.2675438596491228,
            "logloss": 0.6979848152416469,
            "mae": 0.451663631288204,
            "precision": 0.6145339652448657,
            "recall": 0.8020618556701031
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7590606328712228,
            "auditor_fn_violation": 0.004102897773949758,
            "auditor_fp_violation": 0.04175958992902236,
            "ave_precision_score": 0.5926992990105474,
            "fpr": 0.27552140504939626,
            "logloss": 0.6904603221599654,
            "mae": 0.4481973545227106,
            "precision": 0.6078125,
            "recall": 0.8294243070362474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8419347851814464,
            "auditor_fn_violation": 0.0014695243262796177,
            "auditor_fp_violation": 0.01015859320432228,
            "ave_precision_score": 0.8402012283753333,
            "fpr": 0.11951754385964912,
            "logloss": 0.9128171989331396,
            "mae": 0.2788673393958388,
            "precision": 0.7710084033613446,
            "recall": 0.756701030927835
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8539386929260275,
            "auditor_fn_violation": 0.0005570391729606681,
            "auditor_fp_violation": 0.008235194778747438,
            "ave_precision_score": 0.8511828980837177,
            "fpr": 0.10976948408342481,
            "logloss": 0.8474565891704877,
            "mae": 0.2500457446536824,
            "precision": 0.7854077253218884,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 9292,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8434731962650058,
            "auditor_fn_violation": 0.003187737384698864,
            "auditor_fp_violation": 0.011196022843995235,
            "ave_precision_score": 0.8438202607274845,
            "fpr": 0.10307017543859649,
            "logloss": 0.5107768260169931,
            "mae": 0.32939723091967926,
            "precision": 0.7915742793791575,
            "recall": 0.7360824742268042
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.859132139594208,
            "auditor_fn_violation": 0.006700853580615041,
            "auditor_fp_violation": 0.014031619571750007,
            "ave_precision_score": 0.8594119840302052,
            "fpr": 0.10318331503841932,
            "logloss": 0.4815009851459333,
            "mae": 0.3127589610852015,
            "precision": 0.7915742793791575,
            "recall": 0.7611940298507462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 9292,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5272897538185348,
            "auditor_fn_violation": 0.007379272924579515,
            "auditor_fp_violation": 0.009960865277948974,
            "ave_precision_score": 0.5293489647038894,
            "fpr": 0.1206140350877193,
            "logloss": 0.7498684892227687,
            "mae": 0.5038366560873232,
            "precision": 0.5378151260504201,
            "recall": 0.2639175257731959
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.48518932725297337,
            "auditor_fn_violation": 0.0007255552252849135,
            "auditor_fp_violation": 0.009879253567508238,
            "ave_precision_score": 0.48731115107120604,
            "fpr": 0.12294182217343579,
            "logloss": 0.7647824754547304,
            "mae": 0.510001989443399,
            "precision": 0.46919431279620855,
            "recall": 0.21108742004264391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.4524294339634759,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00011812317679446095,
            "ave_precision_score": 0.45285453499178574,
            "fpr": 0.46381578947368424,
            "logloss": 0.8521712587605859,
            "mae": 0.5069486052451426,
            "precision": 0.5341409691629956,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.4368627231323352,
            "auditor_fn_violation": 0.0010017343110385035,
            "auditor_fp_violation": 0.002361782338537035,
            "ave_precision_score": 0.4386983651061429,
            "fpr": 0.47530186608122943,
            "logloss": 0.7810320104573013,
            "mae": 0.5029330443014298,
            "precision": 0.5188888888888888,
            "recall": 0.9957356076759062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 9292,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6194283288438721,
            "auditor_fn_violation": 0.0005832881172002176,
            "auditor_fp_violation": 0.007318501170960212,
            "ave_precision_score": 0.618764669921032,
            "fpr": 0.3980263157894737,
            "logloss": 0.7178528345257171,
            "mae": 0.4878928324763189,
            "precision": 0.5496277915632755,
            "recall": 0.9134020618556701
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5870926172004971,
            "auditor_fn_violation": 0.004430567875691328,
            "auditor_fp_violation": 0.004947077201225854,
            "ave_precision_score": 0.5867396984464559,
            "fpr": 0.41602634467618005,
            "logloss": 0.7262894522561176,
            "mae": 0.49302327423535375,
            "precision": 0.5208596713021492,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 9292,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8180924206801883,
            "auditor_fn_violation": 0.007343100018086457,
            "auditor_fp_violation": 0.012366983031348868,
            "ave_precision_score": 0.8183733156692691,
            "fpr": 0.1425438596491228,
            "logloss": 0.6735186517963724,
            "mae": 0.31117446533462817,
            "precision": 0.7485493230174082,
            "recall": 0.797938144329897
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8396605164606207,
            "auditor_fn_violation": 0.006946606156921209,
            "auditor_fp_violation": 0.016142571188738943,
            "ave_precision_score": 0.8398524286036382,
            "fpr": 0.1602634467618002,
            "logloss": 0.6526476283809876,
            "mae": 0.3054169922381252,
            "precision": 0.7286245353159851,
            "recall": 0.835820895522388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 9292,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7605778924057118,
            "auditor_fn_violation": 0.002706185567010321,
            "auditor_fp_violation": 0.006363244176013807,
            "ave_precision_score": 0.7614944646130735,
            "fpr": 0.09210526315789473,
            "logloss": 0.5474671056666021,
            "mae": 0.35703666111160265,
            "precision": 0.8051044083526682,
            "recall": 0.7154639175257732
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7251280282579095,
            "auditor_fn_violation": 0.005823165808092986,
            "auditor_fp_violation": 0.011637552090835493,
            "ave_precision_score": 0.7263455285878663,
            "fpr": 0.09220636663007684,
            "logloss": 0.5359767033067475,
            "mae": 0.3516968263294773,
            "precision": 0.8037383177570093,
            "recall": 0.7334754797441365
        }
    }
]