[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 26311,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8187266608630862,
            "auditor_fn_violation": 0.013172165772348443,
            "auditor_fp_violation": 0.029367001205897237,
            "ave_precision_score": 0.8191298891248177,
            "fpr": 0.14144736842105263,
            "logloss": 0.8171418788025144,
            "mae": 0.2661669697915524,
            "precision": 0.734020618556701,
            "recall": 0.7722342733188721
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8365271619355203,
            "auditor_fn_violation": 0.02006131950490178,
            "auditor_fp_violation": 0.0239050625265889,
            "ave_precision_score": 0.836988680061498,
            "fpr": 0.13062568605927552,
            "logloss": 0.8604417018438132,
            "mae": 0.2780819398630766,
            "precision": 0.7576374745417516,
            "recall": 0.7545638945233266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 26311,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7693963705451732,
            "auditor_fn_violation": 0.0025378658142101436,
            "auditor_fp_violation": 0.0030998366203757754,
            "ave_precision_score": 0.7465882672245122,
            "fpr": 0.0625,
            "logloss": 0.5601246662378339,
            "mae": 0.38345803091661973,
            "precision": 0.8357348703170029,
            "recall": 0.6290672451193059
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7799717909182026,
            "auditor_fn_violation": 0.00225550684333691,
            "auditor_fp_violation": 0.008802567240374164,
            "ave_precision_score": 0.7539671136774636,
            "fpr": 0.06147091108671789,
            "logloss": 0.5687275503024077,
            "mae": 0.3841457800074807,
            "precision": 0.8448753462603878,
            "recall": 0.6186612576064908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 26311,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6164914249547548,
            "auditor_fn_violation": 0.011902043612284509,
            "auditor_fp_violation": 0.023276733963511886,
            "ave_precision_score": 0.6130527210565957,
            "fpr": 0.19407894736842105,
            "logloss": 1.6040465980194971,
            "mae": 0.3546971462058361,
            "precision": 0.6549707602339181,
            "recall": 0.7288503253796096
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6460398318941918,
            "auditor_fn_violation": 0.015347688717790013,
            "auditor_fp_violation": 0.028637230237553782,
            "ave_precision_score": 0.6376440546535405,
            "fpr": 0.18331503841931943,
            "logloss": 1.816917086726887,
            "mae": 0.353536783114411,
            "precision": 0.6800766283524904,
            "recall": 0.7200811359026369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 26311,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5522551664547986,
            "auditor_fn_violation": 0.004845016554401202,
            "auditor_fp_violation": 0.030738223052086983,
            "ave_precision_score": 0.5525975828396792,
            "fpr": 0.09539473684210527,
            "logloss": 4.860379466254209,
            "mae": 0.4433938428884189,
            "precision": 0.6561264822134387,
            "recall": 0.3600867678958785
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6054342429495045,
            "auditor_fn_violation": 0.0077551138552245215,
            "auditor_fp_violation": 0.018624047395206914,
            "ave_precision_score": 0.6042234942058042,
            "fpr": 0.09220636663007684,
            "logloss": 4.504143480904757,
            "mae": 0.44906423933201994,
            "precision": 0.6911764705882353,
            "recall": 0.3813387423935091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6066218574735562,
            "auditor_fn_violation": 0.005687007649275035,
            "auditor_fp_violation": 0.0066883533667872605,
            "ave_precision_score": 0.5443181526899997,
            "fpr": 0.27521929824561403,
            "logloss": 11.17960362096171,
            "mae": 0.4574278998032066,
            "precision": 0.5402930402930403,
            "recall": 0.6399132321041214
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6288091673399617,
            "auditor_fn_violation": 0.007866441932388238,
            "auditor_fp_violation": 0.0037132547965062945,
            "ave_precision_score": 0.5753869803849921,
            "fpr": 0.2645444566410538,
            "logloss": 11.10366963905953,
            "mae": 0.4594375481181,
            "precision": 0.5688729874776386,
            "recall": 0.6450304259634888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8153511917455638,
            "auditor_fn_violation": 0.011904422118202236,
            "auditor_fp_violation": 0.007347220601392619,
            "ave_precision_score": 0.811588819642494,
            "fpr": 0.11513157894736842,
            "logloss": 1.0823987322141415,
            "mae": 0.2572571294150857,
            "precision": 0.7619047619047619,
            "recall": 0.7288503253796096
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8324946141056255,
            "auditor_fn_violation": 0.0002449217697601837,
            "auditor_fp_violation": 0.008261598012594606,
            "ave_precision_score": 0.8285609627172318,
            "fpr": 0.1207464324917673,
            "logloss": 1.1724373451597776,
            "mae": 0.2779802663737124,
            "precision": 0.7587719298245614,
            "recall": 0.7018255578093306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 26311,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6321121346696036,
            "auditor_fn_violation": 0.006928587738326316,
            "auditor_fp_violation": 0.01015287664838371,
            "ave_precision_score": 0.628094770922399,
            "fpr": 0.04057017543859649,
            "logloss": 10.099837758460806,
            "mae": 0.44316858731380054,
            "precision": 0.7581699346405228,
            "recall": 0.25162689804772237
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6562491320063107,
            "auditor_fn_violation": 0.013864798729969303,
            "auditor_fp_violation": 0.010966444151492394,
            "ave_precision_score": 0.6517800988982656,
            "fpr": 0.04610318331503842,
            "logloss": 10.79692887095298,
            "mae": 0.4715566539572091,
            "precision": 0.7454545454545455,
            "recall": 0.24949290060851928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8047389204476024,
            "auditor_fn_violation": 0.011509590135860252,
            "auditor_fp_violation": 0.001390671801454858,
            "ave_precision_score": 0.7871803846289889,
            "fpr": 0.0668859649122807,
            "logloss": 0.5381636033384608,
            "mae": 0.36415765890361446,
            "precision": 0.8267045454545454,
            "recall": 0.631236442516269
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8294165163535593,
            "auditor_fn_violation": 0.00857671506469275,
            "auditor_fp_violation": 0.009096686432176641,
            "ave_precision_score": 0.8062645637953776,
            "fpr": 0.06586169045005488,
            "logloss": 0.5459364409755324,
            "mae": 0.3687835866759166,
            "precision": 0.8342541436464088,
            "recall": 0.6125760649087221
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8128505570125992,
            "auditor_fn_violation": 0.015569699737412956,
            "auditor_fp_violation": 0.009070972886762365,
            "ave_precision_score": 0.8132989041211623,
            "fpr": 0.07894736842105263,
            "logloss": 0.5487218892404849,
            "mae": 0.34858858481605065,
            "precision": 0.7988826815642458,
            "recall": 0.6203904555314533
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8185705836462032,
            "auditor_fn_violation": 0.017730109569093544,
            "auditor_fp_violation": 0.0067857499251571755,
            "ave_precision_score": 0.8189702791789188,
            "fpr": 0.07683863885839737,
            "logloss": 0.5815373628964936,
            "mae": 0.3613904307296849,
            "precision": 0.8082191780821918,
            "recall": 0.5983772819472617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8129587039957322,
            "auditor_fn_violation": 0.021734787076150248,
            "auditor_fp_violation": 0.015611020344653212,
            "ave_precision_score": 0.8122843762894824,
            "fpr": 0.1699561403508772,
            "logloss": 0.5828712976483872,
            "mae": 0.3312590506342403,
            "precision": 0.7030651340996169,
            "recall": 0.7960954446854663
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8384977509243121,
            "auditor_fn_violation": 0.015946633772930804,
            "auditor_fp_violation": 0.014874027699725316,
            "ave_precision_score": 0.8379042993127307,
            "fpr": 0.14709110867178923,
            "logloss": 0.5420756035066202,
            "mae": 0.32208567395505755,
            "precision": 0.7442748091603053,
            "recall": 0.7910750507099391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 26311,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6501929664944648,
            "auditor_fn_violation": 0.03259980210830765,
            "auditor_fp_violation": 0.04216507177033494,
            "ave_precision_score": 0.6360132323028442,
            "fpr": 0.2543859649122807,
            "logloss": 0.6575347719766801,
            "mae": 0.4297968368291071,
            "precision": 0.6020583190394511,
            "recall": 0.7613882863340564
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6649808565724913,
            "auditor_fn_violation": 0.03770236661226435,
            "auditor_fp_violation": 0.03795713212779479,
            "ave_precision_score": 0.6590502302351408,
            "fpr": 0.21734357848518113,
            "logloss": 0.6457325597962296,
            "mae": 0.42430426558207734,
            "precision": 0.657439446366782,
            "recall": 0.77079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5554613787579659,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002990430622009575,
            "ave_precision_score": 0.5569531538948091,
            "fpr": 0.48793859649122806,
            "logloss": 0.7752151035537934,
            "mae": 0.4916310889090885,
            "precision": 0.5088300220750552,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5910012658346454,
            "auditor_fn_violation": 0.0006189841090302657,
            "auditor_fp_violation": 0.002594551441971873,
            "ave_precision_score": 0.5923954981584357,
            "fpr": 0.4544456641053787,
            "logloss": 0.7442988893204282,
            "mae": 0.4755240703649762,
            "precision": 0.543046357615894,
            "recall": 0.9979716024340771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 26311,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5860362221113018,
            "auditor_fn_violation": 0.0022072534916467035,
            "auditor_fp_violation": 0.00608297350916093,
            "ave_precision_score": 0.5871965722910355,
            "fpr": 0.03070175438596491,
            "logloss": 4.707518587509949,
            "mae": 0.5133593247577805,
            "precision": 0.391304347826087,
            "recall": 0.039045553145336226
        },
        "train": {
            "accuracy": 0.43249176728869376,
            "auc_prc": 0.5863904166502684,
            "auditor_fn_violation": 0.002273319335683105,
            "auditor_fp_violation": 0.0029175573401120803,
            "ave_precision_score": 0.5883156585039607,
            "fpr": 0.036223929747530186,
            "logloss": 5.1002247255929225,
            "mae": 0.5634855905812846,
            "precision": 0.21428571428571427,
            "recall": 0.018255578093306288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7356421174226715,
            "auditor_fn_violation": 0.059847965901739165,
            "auditor_fp_violation": 0.011217761699148093,
            "ave_precision_score": 0.6968586665673727,
            "fpr": 0.043859649122807015,
            "logloss": 0.5817646828663935,
            "mae": 0.4017757293359752,
            "precision": 0.8545454545454545,
            "recall": 0.5097613882863341
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7444878688486037,
            "auditor_fn_violation": 0.06538075315670763,
            "auditor_fp_violation": 0.011397118682346021,
            "ave_precision_score": 0.7096384492595942,
            "fpr": 0.04610318331503842,
            "logloss": 0.5920153663344241,
            "mae": 0.40527300063917326,
            "precision": 0.8571428571428571,
            "recall": 0.5111561866125761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 26311,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5604269196002176,
            "auditor_fn_violation": 0.002340449823039183,
            "auditor_fp_violation": 0.004750651573501381,
            "ave_precision_score": 0.5599012911822103,
            "fpr": 0.013157894736842105,
            "logloss": 4.946937841500279,
            "mae": 0.5156601295660983,
            "precision": 0.25,
            "recall": 0.008676789587852495
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.6146686990680454,
            "auditor_fn_violation": 0.0009952730098436412,
            "auditor_fp_violation": 0.002652324854647346,
            "ave_precision_score": 0.6137405969194006,
            "fpr": 0.007683863885839737,
            "logloss": 5.022625081297382,
            "mae": 0.5435293957220182,
            "precision": 0.36363636363636365,
            "recall": 0.008113590263691683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7097884010161337,
            "auditor_fn_violation": 0.05276715378467861,
            "auditor_fp_violation": 0.05087865172910104,
            "ave_precision_score": 0.6917154929000195,
            "fpr": 0.23026315789473684,
            "logloss": 0.6267313464880154,
            "mae": 0.4349311762816158,
            "precision": 0.6209386281588448,
            "recall": 0.7462039045553145
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7602636617779748,
            "auditor_fn_violation": 0.04542185548279647,
            "auditor_fp_violation": 0.04070924742251798,
            "ave_precision_score": 0.7460447176084021,
            "fpr": 0.18221734357848518,
            "logloss": 0.6007114589099618,
            "mae": 0.4198030856173203,
            "precision": 0.696526508226691,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6672087815038638,
            "auditor_fn_violation": 0.015500723065799006,
            "auditor_fp_violation": 0.01333780682304431,
            "ave_precision_score": 0.6677492902720883,
            "fpr": 0.07894736842105263,
            "logloss": 1.6778743091126755,
            "mae": 0.4083167687361991,
            "precision": 0.7131474103585658,
            "recall": 0.3882863340563991
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7298855915095425,
            "auditor_fn_violation": 0.02385315381309797,
            "auditor_fp_violation": 0.013033156686747305,
            "ave_precision_score": 0.7306154179984616,
            "fpr": 0.06695938529088913,
            "logloss": 1.6919128854114607,
            "mae": 0.41856472561505476,
            "precision": 0.7653846153846153,
            "recall": 0.40365111561866124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.7674365611514437,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5534151246407726,
            "fpr": 0.49451754385964913,
            "logloss": 0.6945453349485495,
            "mae": 0.4942440001065271,
            "precision": 0.5054824561403509,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7816472433625181,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5844229736987012,
            "fpr": 0.4588364434687157,
            "logloss": 0.6839673488481128,
            "mae": 0.48898939505366673,
            "precision": 0.5411635565312843,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8502574728365053,
            "auditor_fn_violation": 0.008660140046428436,
            "auditor_fp_violation": 0.0017043023301046437,
            "ave_precision_score": 0.8460809324198894,
            "fpr": 0.10416666666666667,
            "logloss": 1.4903649759719482,
            "mae": 0.23135624765799778,
            "precision": 0.7865168539325843,
            "recall": 0.7592190889370932
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8508396447947677,
            "auditor_fn_violation": 0.004116912293514248,
            "auditor_fp_violation": 0.008666011901323009,
            "ave_precision_score": 0.8471108848574919,
            "fpr": 0.1207464324917673,
            "logloss": 1.6775882407120344,
            "mae": 0.2624584863221233,
            "precision": 0.7659574468085106,
            "recall": 0.7302231237322515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8186901343981426,
            "auditor_fn_violation": 0.0102156829166191,
            "auditor_fp_violation": 0.012810226786478396,
            "ave_precision_score": 0.8190523402349793,
            "fpr": 0.12938596491228072,
            "logloss": 0.5403963208580531,
            "mae": 0.3892294976067844,
            "precision": 0.7494692144373672,
            "recall": 0.7657266811279827
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8322327637067397,
            "auditor_fn_violation": 0.009723394259479032,
            "auditor_fp_violation": 0.011000582986255182,
            "ave_precision_score": 0.832531316146391,
            "fpr": 0.11964873765093303,
            "logloss": 0.5552919923188626,
            "mae": 0.3959568944952883,
            "precision": 0.7724425887265136,
            "recall": 0.7505070993914807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7856974757029436,
            "auditor_fn_violation": 0.007777714350953301,
            "auditor_fp_violation": 0.006727253277317463,
            "ave_precision_score": 0.7910504317401915,
            "fpr": 0.029605263157894735,
            "logloss": 0.6410872245279676,
            "mae": 0.36597486116858036,
            "precision": 0.8761467889908257,
            "recall": 0.41431670281995664
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.8164669974332333,
            "auditor_fn_violation": 0.014797728016601248,
            "auditor_fp_violation": 0.004511578317113011,
            "ave_precision_score": 0.8137700517185311,
            "fpr": 0.019758507135016465,
            "logloss": 0.6881083043718854,
            "mae": 0.38323871881530325,
            "precision": 0.9178082191780822,
            "recall": 0.4077079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7811599293832804,
            "auditor_fn_violation": 0.0029517258438938997,
            "auditor_fp_violation": 0.02737581203563232,
            "ave_precision_score": 0.7817241854808941,
            "fpr": 0.2565789473684211,
            "logloss": 0.7082900738513883,
            "mae": 0.3499704104268172,
            "precision": 0.6372093023255814,
            "recall": 0.8915401301518439
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7944186373081117,
            "auditor_fn_violation": 0.016169289927258235,
            "auditor_fp_violation": 0.025013261624273243,
            "ave_precision_score": 0.7952788256610233,
            "fpr": 0.24039517014270034,
            "logloss": 0.6726927072392628,
            "mae": 0.3393716437110328,
            "precision": 0.6615146831530139,
            "recall": 0.8681541582150102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.7978256143508233,
            "auditor_fn_violation": 0.002611599497659557,
            "auditor_fp_violation": 0.007964756681059636,
            "ave_precision_score": 0.7756566128142399,
            "fpr": 0.08333333333333333,
            "logloss": 0.5594346006070824,
            "mae": 0.3629464511677884,
            "precision": 0.8155339805825242,
            "recall": 0.7288503253796096
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7967198270218953,
            "auditor_fn_violation": 0.003840818662148232,
            "auditor_fp_violation": 0.011622960204622923,
            "ave_precision_score": 0.7752892566429441,
            "fpr": 0.09440175631174534,
            "logloss": 0.5987930218429458,
            "mae": 0.38068190362594784,
            "precision": 0.8027522935779816,
            "recall": 0.7099391480730223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6669846380068725,
            "auditor_fn_violation": 0.08521235300833428,
            "auditor_fp_violation": 0.04083274983467538,
            "ave_precision_score": 0.5418235495782051,
            "fpr": 0.21929824561403508,
            "logloss": 0.72305348022859,
            "mae": 0.4832911300718,
            "precision": 0.5575221238938053,
            "recall": 0.5466377440347071
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7022634607426105,
            "auditor_fn_violation": 0.09353117074832505,
            "auditor_fp_violation": 0.03148650990814028,
            "ave_precision_score": 0.5889257290148003,
            "fpr": 0.19319429198682767,
            "logloss": 0.7143996426711995,
            "mae": 0.48061067369714394,
            "precision": 0.6071428571428571,
            "recall": 0.5517241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.5641686447351215,
            "auditor_fn_violation": 0.0010608136393043326,
            "auditor_fp_violation": 0.005701268137083285,
            "ave_precision_score": 0.5623052749101036,
            "fpr": 0.051535087719298246,
            "logloss": 11.227227965975663,
            "mae": 0.4625327949933115,
            "precision": 0.7151515151515152,
            "recall": 0.2559652928416486
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5923655096489603,
            "auditor_fn_violation": 0.01037132366857187,
            "auditor_fp_violation": 0.002263667351194073,
            "ave_precision_score": 0.5911010429100009,
            "fpr": 0.05159165751920966,
            "logloss": 11.84372157223634,
            "mae": 0.4897676326358701,
            "precision": 0.7098765432098766,
            "recall": 0.2332657200811359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8079628164324106,
            "auditor_fn_violation": 0.000197415991170985,
            "auditor_fp_violation": 0.01378272454973354,
            "ave_precision_score": 0.8082578933455514,
            "fpr": 0.11951754385964912,
            "logloss": 1.2657971227425204,
            "mae": 0.29999832692472544,
            "precision": 0.7640692640692641,
            "recall": 0.7657266811279827
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8017549370153835,
            "auditor_fn_violation": 0.00373394370807107,
            "auditor_fp_violation": 0.017132442922494343,
            "ave_precision_score": 0.8022157192173047,
            "fpr": 0.12294182217343579,
            "logloss": 1.4235343589432867,
            "mae": 0.32725013711314865,
            "precision": 0.7637130801687764,
            "recall": 0.7342799188640974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.8185249182817197,
            "auditor_fn_violation": 0.0006088975149370175,
            "auditor_fp_violation": 0.005059419613334888,
            "ave_precision_score": 0.798504489394944,
            "fpr": 0.4649122807017544,
            "logloss": 6.703361846625299,
            "mae": 0.479214264033975,
            "precision": 0.5143184421534936,
            "recall": 0.9739696312364425
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.8344466948789517,
            "auditor_fn_violation": 0.0017857023577060188,
            "auditor_fp_violation": 0.0045693517297884885,
            "ave_precision_score": 0.815051452959156,
            "fpr": 0.424807903402854,
            "logloss": 6.117230229174037,
            "mae": 0.432986654603954,
            "precision": 0.5577142857142857,
            "recall": 0.9898580121703854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8429552147972368,
            "auditor_fn_violation": 0.017857822430262207,
            "auditor_fp_violation": 0.015163671373555843,
            "ave_precision_score": 0.8432794668165511,
            "fpr": 0.07785087719298246,
            "logloss": 0.5076492852595049,
            "mae": 0.33072849547668165,
            "precision": 0.8151041666666666,
            "recall": 0.6789587852494577
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8542486010525249,
            "auditor_fn_violation": 0.014370228200292575,
            "auditor_fp_violation": 0.009501100320905047,
            "ave_precision_score": 0.8545146987608586,
            "fpr": 0.07683863885839737,
            "logloss": 0.5231343239103365,
            "mae": 0.33676040802318624,
            "precision": 0.826302729528536,
            "recall": 0.6754563894523327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.823004503166483,
            "auditor_fn_violation": 0.02877516459260951,
            "auditor_fp_violation": 0.03863490488971876,
            "ave_precision_score": 0.8146814826848876,
            "fpr": 0.10526315789473684,
            "logloss": 0.5054195315596234,
            "mae": 0.3166494262159655,
            "precision": 0.7808219178082192,
            "recall": 0.7418655097613883
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8454623131442255,
            "auditor_fn_violation": 0.03566951592325488,
            "auditor_fp_violation": 0.04312785256225086,
            "ave_precision_score": 0.8391521780180968,
            "fpr": 0.10867178924259056,
            "logloss": 0.5217947800383729,
            "mae": 0.32280276579175116,
            "precision": 0.7875536480686696,
            "recall": 0.744421906693712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.782422143903859,
            "auditor_fn_violation": 0.006935723256079467,
            "auditor_fp_violation": 0.011263955342902717,
            "ave_precision_score": 0.7830259318573795,
            "fpr": 0.13486842105263158,
            "logloss": 0.5412012072306386,
            "mae": 0.3566141806592912,
            "precision": 0.74375,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8072448001983733,
            "auditor_fn_violation": 0.009596480251512397,
            "auditor_fp_violation": 0.004073025593621815,
            "ave_precision_score": 0.8076830698851151,
            "fpr": 0.132821075740944,
            "logloss": 0.5503682280288927,
            "mae": 0.3635230304527763,
            "precision": 0.7589641434262948,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7401839565240975,
            "auditor_fn_violation": 0.044768238383377096,
            "auditor_fp_violation": 0.03502693818804217,
            "ave_precision_score": 0.7394519099353278,
            "fpr": 0.16557017543859648,
            "logloss": 0.6033819999834936,
            "mae": 0.3992628343199102,
            "precision": 0.6681318681318681,
            "recall": 0.6594360086767896
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7603184594213208,
            "auditor_fn_violation": 0.04254736453042931,
            "auditor_fp_violation": 0.03680166387428506,
            "ave_precision_score": 0.7599013020287221,
            "fpr": 0.14050493962678376,
            "logloss": 0.6031730555624788,
            "mae": 0.39570968113144456,
            "precision": 0.7235421166306696,
            "recall": 0.6795131845841785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7849197939906691,
            "auditor_fn_violation": 0.011844959470259164,
            "auditor_fp_violation": 0.02452153110047848,
            "ave_precision_score": 0.7473699139218829,
            "fpr": 0.15789473684210525,
            "logloss": 2.271315688221331,
            "mae": 0.32789484189732565,
            "precision": 0.712,
            "recall": 0.7722342733188721
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7980320274338679,
            "auditor_fn_violation": 0.02111002999178399,
            "auditor_fp_violation": 0.027610439130457624,
            "ave_precision_score": 0.7663997752390503,
            "fpr": 0.15587266739846323,
            "logloss": 2.0920064392708015,
            "mae": 0.32649443886927737,
            "precision": 0.7253384912959381,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.724747205205081,
            "auditor_fn_violation": 0.002195360962058074,
            "auditor_fp_violation": 0.017368810051736874,
            "ave_precision_score": 0.7240837106885163,
            "fpr": 0.4473684210526316,
            "logloss": 1.3719223091586998,
            "mae": 0.42030455044617776,
            "precision": 0.5239206534422404,
            "recall": 0.9739696312364425
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7450769711786922,
            "auditor_fn_violation": 0.004535505863649824,
            "auditor_fp_violation": 0.008721159249785993,
            "ave_precision_score": 0.7445972212644931,
            "fpr": 0.4094401756311745,
            "logloss": 1.2205213871132912,
            "mae": 0.396775589603624,
            "precision": 0.563231850117096,
            "recall": 0.9756592292089249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 26311,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7758955966725815,
            "auditor_fn_violation": 0.06007868097575827,
            "auditor_fp_violation": 0.06538102462364338,
            "ave_precision_score": 0.7656104978208446,
            "fpr": 0.19846491228070176,
            "logloss": 0.609379601029445,
            "mae": 0.3833217026273671,
            "precision": 0.6525911708253359,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8126159183390645,
            "auditor_fn_violation": 0.0620097389801903,
            "auditor_fp_violation": 0.05733748601620808,
            "ave_precision_score": 0.8040459687299615,
            "fpr": 0.1734357848518112,
            "logloss": 0.5820139410841807,
            "mae": 0.3749886215321973,
            "precision": 0.7035647279549718,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6291257159079903,
            "auditor_fn_violation": 0.058554058682498,
            "auditor_fp_violation": 0.03919409110359047,
            "ave_precision_score": 0.6311759965951578,
            "fpr": 0.13925438596491227,
            "logloss": 0.6694667918685148,
            "mae": 0.46500964366357056,
            "precision": 0.6666666666666666,
            "recall": 0.5509761388286334
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6535213241883504,
            "auditor_fn_violation": 0.055129663811472586,
            "auditor_fp_violation": 0.0330910351419913,
            "ave_precision_score": 0.654962214892625,
            "fpr": 0.13721185510428102,
            "logloss": 0.6642740110784794,
            "mae": 0.4672106769095399,
            "precision": 0.6753246753246753,
            "recall": 0.5273833671399595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.849879951794432,
            "auditor_fn_violation": 0.025699756440994027,
            "auditor_fp_violation": 0.008857023378846229,
            "ave_precision_score": 0.8340248299673374,
            "fpr": 0.06907894736842106,
            "logloss": 0.4980178996542573,
            "mae": 0.3144609494004072,
            "precision": 0.8346456692913385,
            "recall": 0.6898047722342733
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8696068771153761,
            "auditor_fn_violation": 0.01946905413439081,
            "auditor_fp_violation": 0.010677577088114959,
            "ave_precision_score": 0.8590139636417359,
            "fpr": 0.06256860592755215,
            "logloss": 0.5212991071442682,
            "mae": 0.325560602158079,
            "precision": 0.8527131782945736,
            "recall": 0.6693711967545639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7931145033813873,
            "auditor_fn_violation": 0.024929120523651864,
            "auditor_fp_violation": 0.013077663671373555,
            "ave_precision_score": 0.7559141174375205,
            "fpr": 0.12938596491228072,
            "logloss": 0.5779042638758642,
            "mae": 0.37222560125876936,
            "precision": 0.7462365591397849,
            "recall": 0.7527114967462039
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8048272885018862,
            "auditor_fn_violation": 0.023434560242962404,
            "auditor_fp_violation": 0.02033624126177133,
            "ave_precision_score": 0.7752161877820009,
            "fpr": 0.1207464324917673,
            "logloss": 0.5905887217199127,
            "mae": 0.38022836131727655,
            "precision": 0.7679324894514767,
            "recall": 0.7383367139959433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8255742943544484,
            "auditor_fn_violation": 0.010122921185827914,
            "auditor_fp_violation": 0.0008825417201540463,
            "ave_precision_score": 0.8195825095320918,
            "fpr": 0.09649122807017543,
            "logloss": 0.5373240313706453,
            "mae": 0.3258232789669649,
            "precision": 0.7894736842105263,
            "recall": 0.7158351409978309
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8602495258836115,
            "auditor_fn_violation": 0.010079644106402932,
            "auditor_fp_violation": 0.00863712519498527,
            "ave_precision_score": 0.8473135984733059,
            "fpr": 0.09769484083424808,
            "logloss": 0.5146368478481733,
            "mae": 0.33086206061452833,
            "precision": 0.7958715596330275,
            "recall": 0.7038539553752535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8115282284875877,
            "auditor_fn_violation": 8.800471895575076e-05,
            "auditor_fp_violation": 0.009878146030264132,
            "ave_precision_score": 0.7898788741572895,
            "fpr": 0.08771929824561403,
            "logloss": 0.5358460167963666,
            "mae": 0.34971307977021004,
            "precision": 0.8058252427184466,
            "recall": 0.720173535791757
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8297049879291318,
            "auditor_fn_violation": 0.007196246907862661,
            "auditor_fp_violation": 0.011179155352706683,
            "ave_precision_score": 0.8172010506304654,
            "fpr": 0.0845225027442371,
            "logloss": 0.5417199127088603,
            "mae": 0.35564645923649574,
            "precision": 0.8183962264150944,
            "recall": 0.7038539553752535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7886594717533699,
            "auditor_fn_violation": 0.01932060356966169,
            "auditor_fp_violation": 0.026493270315478278,
            "ave_precision_score": 0.7297438494277348,
            "fpr": 0.1118421052631579,
            "logloss": 0.5714396470601283,
            "mae": 0.399555090537066,
            "precision": 0.7424242424242424,
            "recall": 0.6377440347071583
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8005810682340848,
            "auditor_fn_violation": 0.013597611344776384,
            "auditor_fp_violation": 0.02511042600013656,
            "ave_precision_score": 0.7417108577957469,
            "fpr": 0.12403951701427003,
            "logloss": 0.5801282218103232,
            "mae": 0.403353408833661,
            "precision": 0.7396313364055299,
            "recall": 0.6511156186612576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8407548072930797,
            "auditor_fn_violation": 0.013310119115576368,
            "auditor_fp_violation": 0.024045007196483455,
            "ave_precision_score": 0.841085856412043,
            "fpr": 0.11293859649122807,
            "logloss": 0.49923042079208263,
            "mae": 0.3206742795208763,
            "precision": 0.7721238938053098,
            "recall": 0.7570498915401301
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8548947926861787,
            "auditor_fn_violation": 0.012729252342899386,
            "auditor_fp_violation": 0.019845167254029693,
            "ave_precision_score": 0.8551936274111895,
            "fpr": 0.10867178924259056,
            "logloss": 0.5113165286135438,
            "mae": 0.3252195157255647,
            "precision": 0.7928870292887029,
            "recall": 0.768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6971845379399579,
            "auditor_fn_violation": 0.00763262548997224,
            "auditor_fp_violation": 0.0012666783366398259,
            "ave_precision_score": 0.5248201193386639,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6911656100387017,
            "mae": 0.49435178429019033,
            "precision": 0.8620689655172413,
            "recall": 0.05422993492407809
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.7684132868839078,
            "auditor_fn_violation": 0.0065906221680920585,
            "auditor_fp_violation": 0.0004910740077416373,
            "ave_precision_score": 0.5671216728975675,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6947465691645623,
            "mae": 0.49615003196389695,
            "precision": 0.967741935483871,
            "recall": 0.060851926977687626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7400410869676135,
            "auditor_fn_violation": 0.0031277352818053824,
            "auditor_fp_violation": 0.023303477652001404,
            "ave_precision_score": 0.5244906871391488,
            "fpr": 0.41228070175438597,
            "logloss": 0.6962481374158868,
            "mae": 0.4922599448708066,
            "precision": 0.5264483627204031,
            "recall": 0.9067245119305857
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7549590552330683,
            "auditor_fn_violation": 0.0053660133192911545,
            "auditor_fp_violation": 0.012589351834831085,
            "ave_precision_score": 0.5583498115878543,
            "fpr": 0.37760702524698136,
            "logloss": 0.6906119084316291,
            "mae": 0.48908165735156817,
            "precision": 0.5606641123882503,
            "recall": 0.8904665314401623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.458745524181825,
            "mae": 0.5054824561403509,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.691127072108635,
            "mae": 0.5411635565312843,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7810091624327855,
            "auditor_fn_violation": 0.015888419530387804,
            "auditor_fp_violation": 0.0006442797681565371,
            "ave_precision_score": 0.7853648398110588,
            "fpr": 0.12719298245614036,
            "logloss": 0.5309369761797119,
            "mae": 0.32644272821122094,
            "precision": 0.7427937915742794,
            "recall": 0.7266811279826464
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8013322252507342,
            "auditor_fn_violation": 0.011932143310407177,
            "auditor_fp_violation": 0.018266902662303904,
            "ave_precision_score": 0.8016553126275912,
            "fpr": 0.11086717892425905,
            "logloss": 0.5418497996043021,
            "mae": 0.33072463267213953,
            "precision": 0.7789934354485777,
            "recall": 0.7221095334685599
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7428939151841608,
            "auditor_fn_violation": 0.002257202115918864,
            "auditor_fp_violation": 0.0011329598941922467,
            "ave_precision_score": 0.6545922442580564,
            "fpr": 0.48355263157894735,
            "logloss": 0.6658765093903078,
            "mae": 0.4608713646925855,
            "precision": 0.5050505050505051,
            "recall": 0.9761388286334056
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7802711240721799,
            "auditor_fn_violation": 0.002999178398790532,
            "auditor_fp_violation": 0.004285736794836117,
            "ave_precision_score": 0.682224285335761,
            "fpr": 0.4478594950603732,
            "logloss": 0.6448842440430522,
            "mae": 0.4523138712057036,
            "precision": 0.5431131019036954,
            "recall": 0.9837728194726166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.6785975409800998,
            "auditor_fn_violation": 0.014190166305133775,
            "auditor_fp_violation": 0.02661240129147703,
            "ave_precision_score": 0.6294400207857166,
            "fpr": 0.1611842105263158,
            "logloss": 0.6342513341134265,
            "mae": 0.4460422928984228,
            "precision": 0.676923076923077,
            "recall": 0.6681127982646421
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7311685410825762,
            "auditor_fn_violation": 0.020292881905402314,
            "auditor_fp_violation": 0.024737524881958416,
            "ave_precision_score": 0.6875031973119498,
            "fpr": 0.13611416026344675,
            "logloss": 0.6310761098383192,
            "mae": 0.4430248085020926,
            "precision": 0.7286652078774617,
            "recall": 0.6754563894523327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7730043692442582,
            "auditor_fn_violation": 0.011573809795638776,
            "auditor_fp_violation": 0.020395709339868527,
            "ave_precision_score": 0.7653744267743836,
            "fpr": 0.1513157894736842,
            "logloss": 1.3505559976724064,
            "mae": 0.29421613970643784,
            "precision": 0.7112970711297071,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7905152076033543,
            "auditor_fn_violation": 0.01556143862594435,
            "auditor_fp_violation": 0.02163876911118231,
            "ave_precision_score": 0.7855730204022575,
            "fpr": 0.13611416026344675,
            "logloss": 1.2599637859092372,
            "mae": 0.30093062217204203,
            "precision": 0.7411273486430062,
            "recall": 0.7200811359026369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.7743949960036391,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5837749541020794,
            "fpr": 0.49451754385964913,
            "logloss": 13.696240846492172,
            "mae": 0.49448403323951523,
            "precision": 0.5054824561403509,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.803387020385238,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6320662337308527,
            "fpr": 0.4588364434687157,
            "logloss": 12.39449399374764,
            "mae": 0.4587650598076905,
            "precision": 0.5411635565312843,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 26311,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7063449997404088,
            "auditor_fn_violation": 0.03110372188606006,
            "auditor_fp_violation": 0.04161561053409578,
            "ave_precision_score": 0.707096247848372,
            "fpr": 0.29714912280701755,
            "logloss": 1.8230281639267247,
            "mae": 0.4195526938301048,
            "precision": 0.6002949852507374,
            "recall": 0.8828633405639913
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7214146033862759,
            "auditor_fn_violation": 0.02214092798632001,
            "auditor_fp_violation": 0.034937158283394366,
            "ave_precision_score": 0.7221351805347558,
            "fpr": 0.2810098792535675,
            "logloss": 1.5921009778854949,
            "mae": 0.41332599178219154,
            "precision": 0.6268221574344023,
            "recall": 0.8722109533468559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6029176681494508,
            "auditor_fn_violation": 0.007409045933706297,
            "auditor_fp_violation": 0.020434609250398732,
            "ave_precision_score": 0.6002331598423485,
            "fpr": 0.14364035087719298,
            "logloss": 6.278836181601547,
            "mae": 0.4528428188661979,
            "precision": 0.6077844311377245,
            "recall": 0.4403470715835141
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6314979849738109,
            "auditor_fn_violation": 0.004159216962836464,
            "auditor_fp_violation": 0.019359345374713104,
            "ave_precision_score": 0.6280740961334934,
            "fpr": 0.1251372118551043,
            "logloss": 6.662334952216522,
            "mae": 0.4605282343787056,
            "precision": 0.6637168141592921,
            "recall": 0.4563894523326572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8019169287666181,
            "auditor_fn_violation": 0.006226928492598091,
            "auditor_fp_violation": 0.017086785700392897,
            "ave_precision_score": 0.6589203198532497,
            "fpr": 0.25109649122807015,
            "logloss": 0.5915743265161352,
            "mae": 0.39613349779852125,
            "precision": 0.6487730061349694,
            "recall": 0.9175704989154013
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8176952152564575,
            "auditor_fn_violation": 0.006989176684338145,
            "auditor_fp_violation": 0.01685670618017952,
            "ave_precision_score": 0.6955330638042369,
            "fpr": 0.23600439077936333,
            "logloss": 0.5862328991598985,
            "mae": 0.3943940589836217,
            "precision": 0.6757164404223228,
            "recall": 0.9087221095334685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7686778667490346,
            "auditor_fn_violation": 0.010617650416714235,
            "auditor_fp_violation": 0.02292906601314818,
            "ave_precision_score": 0.768570073615227,
            "fpr": 0.15899122807017543,
            "logloss": 1.2510356781654226,
            "mae": 0.3222496275995048,
            "precision": 0.693446088794926,
            "recall": 0.7114967462039046
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7828254567649346,
            "auditor_fn_violation": 0.021301514284505583,
            "auditor_fp_violation": 0.024947610018960193,
            "ave_precision_score": 0.7830775575599399,
            "fpr": 0.13830954994511527,
            "logloss": 1.3413396715770785,
            "mae": 0.3222343603500878,
            "precision": 0.7290322580645161,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6370228337592734,
            "auditor_fn_violation": 0.015955017696084033,
            "auditor_fp_violation": 0.013082526160189834,
            "ave_precision_score": 0.637775683208088,
            "fpr": 0.2598684210526316,
            "logloss": 0.7279712066416999,
            "mae": 0.4585707338134709,
            "precision": 0.601010101010101,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6984949384643446,
            "auditor_fn_violation": 0.012203783818686642,
            "auditor_fp_violation": 0.015372979900104526,
            "ave_precision_score": 0.6991954178581247,
            "fpr": 0.20636663007683864,
            "logloss": 0.6984059354444746,
            "mae": 0.4432988493048006,
            "precision": 0.6672566371681415,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6015626740110094,
            "auditor_fn_violation": 0.003948319823419727,
            "auditor_fp_violation": 0.016734255261212902,
            "ave_precision_score": 0.6006151163469654,
            "fpr": 0.13157894736842105,
            "logloss": 2.3859038142051805,
            "mae": 0.3878742999469134,
            "precision": 0.6858638743455497,
            "recall": 0.5683297180043384
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6280395167681256,
            "auditor_fn_violation": 0.005512966381147267,
            "auditor_fp_violation": 0.019075730439760723,
            "ave_precision_score": 0.6261583541585267,
            "fpr": 0.13391877058177826,
            "logloss": 2.585746351972839,
            "mae": 0.40214676982690434,
            "precision": 0.6839378238341969,
            "recall": 0.5354969574036511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7972387201417839,
            "auditor_fn_violation": 0.023675647905011997,
            "auditor_fp_violation": 0.02615532734274711,
            "ave_precision_score": 0.7911713329589323,
            "fpr": 0.10307017543859649,
            "logloss": 0.553788347602309,
            "mae": 0.34012084069233917,
            "precision": 0.7701711491442543,
            "recall": 0.6832971800433839
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.844673944653266,
            "auditor_fn_violation": 0.036230609432160006,
            "auditor_fp_violation": 0.017563117453347973,
            "ave_precision_score": 0.8402059705164376,
            "fpr": 0.07244785949506037,
            "logloss": 0.5692108669153495,
            "mae": 0.34082647785442166,
            "precision": 0.8324873096446701,
            "recall": 0.665314401622718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6547730209121334,
            "auditor_fn_violation": 0.011347851733455112,
            "auditor_fp_violation": 0.04979674796747969,
            "ave_precision_score": 0.6885665807822269,
            "fpr": 0.33114035087719296,
            "logloss": 0.7136804306418945,
            "mae": 0.4154341014208305,
            "precision": 0.5896739130434783,
            "recall": 0.9414316702819957
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7282488746001895,
            "auditor_fn_violation": 0.014917962339938057,
            "auditor_fp_violation": 0.038723942877851254,
            "ave_precision_score": 0.7568528962690552,
            "fpr": 0.29418221734357847,
            "logloss": 0.6437522020566823,
            "mae": 0.3886205738596414,
            "precision": 0.6323731138545954,
            "recall": 0.9350912778904665
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6703084854238782,
            "auditor_fn_violation": 0.01271549263614568,
            "auditor_fp_violation": 0.01938674291049131,
            "ave_precision_score": 0.6052347029334748,
            "fpr": 0.43859649122807015,
            "logloss": 0.6688130592096936,
            "mae": 0.474746210369886,
            "precision": 0.5209580838323353,
            "recall": 0.9436008676789588
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7287956221907659,
            "auditor_fn_violation": 0.008848355572972215,
            "auditor_fp_violation": 0.016665003492665406,
            "ave_precision_score": 0.6696584047077561,
            "fpr": 0.3940724478594951,
            "logloss": 0.6415018273005527,
            "mae": 0.4607599349171087,
            "precision": 0.5690276110444178,
            "recall": 0.9614604462474645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7982396335754164,
            "auditor_fn_violation": 0.0258852799025764,
            "auditor_fp_violation": 0.02297282841249465,
            "ave_precision_score": 0.7982511582623444,
            "fpr": 0.10635964912280702,
            "logloss": 2.3068416643507126,
            "mae": 0.3789608552793453,
            "precision": 0.7568922305764411,
            "recall": 0.6550976138828634
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.830514533634194,
            "auditor_fn_violation": 0.025529754655183548,
            "auditor_fp_violation": 0.020840445590575584,
            "ave_precision_score": 0.8305197157562298,
            "fpr": 0.09879253567508232,
            "logloss": 1.917503637044518,
            "mae": 0.36111261231416997,
            "precision": 0.7867298578199052,
            "recall": 0.6734279918864098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6844716502982134,
            "auditor_fn_violation": 0.007047513034212438,
            "auditor_fp_violation": 0.007096802427354414,
            "ave_precision_score": 0.5448565656070304,
            "fpr": 0.23464912280701755,
            "logloss": 0.6955458051449773,
            "mae": 0.4818458351992855,
            "precision": 0.5641547861507128,
            "recall": 0.6008676789587852
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7034526668972457,
            "auditor_fn_violation": 0.0026340223056935453,
            "auditor_fp_violation": 0.011812036827924524,
            "ave_precision_score": 0.5727463337136625,
            "fpr": 0.2349066959385291,
            "logloss": 0.695935028012209,
            "mae": 0.4838698900230106,
            "precision": 0.58203125,
            "recall": 0.6044624746450304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8312500686135702,
            "auditor_fn_violation": 0.00556332534155345,
            "auditor_fp_violation": 0.018837281674252155,
            "ave_precision_score": 0.8316107627098642,
            "fpr": 0.31798245614035087,
            "logloss": 0.5758920800640572,
            "mae": 0.3819059819716254,
            "precision": 0.6021947873799726,
            "recall": 0.9522776572668112
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8477711552707026,
            "auditor_fn_violation": 0.008469840110615579,
            "auditor_fp_violation": 0.01620281619126151,
            "ave_precision_score": 0.8480382203924188,
            "fpr": 0.3084522502744237,
            "logloss": 0.571322515502677,
            "mae": 0.37879780384807715,
            "precision": 0.6192411924119241,
            "recall": 0.9269776876267748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6590898759835254,
            "auditor_fn_violation": 0.013533698671842304,
            "auditor_fp_violation": 0.02376055160073132,
            "ave_precision_score": 0.6572695262543973,
            "fpr": 0.11293859649122807,
            "logloss": 2.450796519081577,
            "mae": 0.4029469050203509,
            "precision": 0.6820987654320988,
            "recall": 0.4793926247288503
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.700704621657308,
            "auditor_fn_violation": 0.015536946448968343,
            "auditor_fp_violation": 0.018503248441430895,
            "ave_precision_score": 0.698697208728722,
            "fpr": 0.09440175631174534,
            "logloss": 2.060881226161101,
            "mae": 0.40306248453573884,
            "precision": 0.7304075235109718,
            "recall": 0.4726166328600406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8401188901969465,
            "auditor_fn_violation": 0.00341315599193211,
            "auditor_fp_violation": 0.008458299295911622,
            "ave_precision_score": 0.8367843818234972,
            "fpr": 0.08114035087719298,
            "logloss": 0.5006065910224347,
            "mae": 0.27987890017398614,
            "precision": 0.8195121951219512,
            "recall": 0.7288503253796096
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8571657011183824,
            "auditor_fn_violation": 0.006937965768842841,
            "auditor_fp_violation": 0.013571499850314344,
            "ave_precision_score": 0.8584687896372342,
            "fpr": 0.08122941822173436,
            "logloss": 0.5286586800718642,
            "mae": 0.29516566862708976,
            "precision": 0.8225419664268585,
            "recall": 0.6957403651115619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8223251962205766,
            "auditor_fn_violation": 0.008607812916238534,
            "auditor_fp_violation": 0.0027716186252771608,
            "ave_precision_score": 0.8215277314359818,
            "fpr": 0.12719298245614036,
            "logloss": 0.4988463957373557,
            "mae": 0.3287311045845088,
            "precision": 0.7618069815195072,
            "recall": 0.8047722342733189
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8437427679782994,
            "auditor_fn_violation": 0.00912890232742479,
            "auditor_fp_violation": 0.015073608579877,
            "ave_precision_score": 0.8413090891121493,
            "fpr": 0.11306256860592755,
            "logloss": 0.5055945243519745,
            "mae": 0.3357481180999988,
            "precision": 0.7845188284518828,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5560820894810266,
            "auditor_fn_violation": 0.08589022719488527,
            "auditor_fp_violation": 0.09753909441008286,
            "ave_precision_score": 0.5573675073597324,
            "fpr": 0.2807017543859649,
            "logloss": 0.6920851866387424,
            "mae": 0.4816442291464722,
            "precision": 0.5547826086956522,
            "recall": 0.6919739696312365
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6247448186133356,
            "auditor_fn_violation": 0.10000378515462356,
            "auditor_fp_violation": 0.08876622251167289,
            "ave_precision_score": 0.6262542001988566,
            "fpr": 0.25905598243688255,
            "logloss": 0.6749332851329242,
            "mae": 0.47371269770694485,
            "precision": 0.6026936026936027,
            "recall": 0.7261663286004056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7951514733205852,
            "auditor_fn_violation": 0.0053635308444647525,
            "auditor_fp_violation": 0.0006588672346053606,
            "ave_precision_score": 0.6804777162695399,
            "fpr": 0.008771929824561403,
            "logloss": 0.6084569374483979,
            "mae": 0.42966972110106755,
            "precision": 0.9292035398230089,
            "recall": 0.227765726681128
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.8136829193727455,
            "auditor_fn_violation": 0.014971399816976644,
            "auditor_fp_violation": 0.0013813097757866377,
            "ave_precision_score": 0.7059463451427389,
            "fpr": 0.006586169045005488,
            "logloss": 0.6301596482711679,
            "mae": 0.4374625602845434,
            "precision": 0.9495798319327731,
            "recall": 0.22920892494929007
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8198389229363425,
            "auditor_fn_violation": 0.007121246717661839,
            "auditor_fp_violation": 0.019817073170731708,
            "ave_precision_score": 0.8074843670227795,
            "fpr": 0.13267543859649122,
            "logloss": 1.2424595035587362,
            "mae": 0.2722601955369669,
            "precision": 0.753061224489796,
            "recall": 0.8004338394793926
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8366262236396462,
            "auditor_fn_violation": 0.013615423837122572,
            "auditor_fp_violation": 0.019193903329324212,
            "ave_precision_score": 0.8311084698735522,
            "fpr": 0.13062568605927552,
            "logloss": 1.0071682760062652,
            "mae": 0.2779383545483718,
            "precision": 0.7652859960552268,
            "recall": 0.7870182555780934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6985149045557112,
            "auditor_fn_violation": 0.02115443163222591,
            "auditor_fp_violation": 0.016838798770762827,
            "ave_precision_score": 0.6869772117481037,
            "fpr": 0.1162280701754386,
            "logloss": 2.6260956911736297,
            "mae": 0.35096703213597824,
            "precision": 0.7127371273712737,
            "recall": 0.5704989154013015
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.774623274025165,
            "auditor_fn_violation": 0.027426785090053283,
            "auditor_fp_violation": 0.011003209050467703,
            "ave_precision_score": 0.7690440343888136,
            "fpr": 0.09440175631174534,
            "logloss": 2.406414173625792,
            "mae": 0.34325670131779373,
            "precision": 0.7688172043010753,
            "recall": 0.5801217038539553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.7174857084709354,
            "auditor_fn_violation": 0.006524241732313443,
            "auditor_fp_violation": 0.0076730073520830935,
            "ave_precision_score": 0.7652087493411943,
            "fpr": 0.09429824561403509,
            "logloss": 0.5302257085708991,
            "mae": 0.3464797573948377,
            "precision": 0.7985948477751756,
            "recall": 0.7396963123644251
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8127160382035545,
            "auditor_fn_violation": 0.001963827281167968,
            "auditor_fp_violation": 0.013797341372591247,
            "ave_precision_score": 0.7600454069563155,
            "fpr": 0.09879253567508232,
            "logloss": 0.5636039721441913,
            "mae": 0.3619346991344943,
            "precision": 0.7954545454545454,
            "recall": 0.7099391480730223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5662191116601218,
            "auditor_fn_violation": 0.013478993035734686,
            "auditor_fp_violation": 0.004784688995215326,
            "ave_precision_score": 0.5469799063506786,
            "fpr": 0.3530701754385965,
            "logloss": 4.1040307219236905,
            "mae": 0.48530495536921203,
            "precision": 0.5292397660818714,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5733537173162541,
            "auditor_fn_violation": 0.018983663717957,
            "auditor_fp_violation": 0.0077573936837903625,
            "ave_precision_score": 0.5545623071522767,
            "fpr": 0.33150384193194293,
            "logloss": 4.065726097542333,
            "mae": 0.4739474895552099,
            "precision": 0.5591240875912409,
            "recall": 0.7768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6734222762462279,
            "auditor_fn_violation": 0.01515108269589375,
            "auditor_fp_violation": 0.01809818337417824,
            "ave_precision_score": 0.6230605472469262,
            "fpr": 0.16447368421052633,
            "logloss": 0.6312372082144169,
            "mae": 0.4477667931075159,
            "precision": 0.6629213483146067,
            "recall": 0.6399132321041214
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6855773878226422,
            "auditor_fn_violation": 0.02330987279653903,
            "auditor_fp_violation": 0.01008933870451001,
            "ave_precision_score": 0.6395063668056705,
            "fpr": 0.1602634467618002,
            "logloss": 0.644805215649992,
            "mae": 0.4544400380582893,
            "precision": 0.6651376146788991,
            "recall": 0.5882352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7549778761061947,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003921597230326381,
            "ave_precision_score": 0.5099557522123894,
            "fpr": 0.4857456140350877,
            "logloss": 0.767086125532671,
            "mae": 0.4945390921151429,
            "precision": 0.5099557522123894,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7710578274454027,
            "auditor_fn_violation": 0.0006189841090302657,
            "auditor_fp_violation": 0.0021953896816685075,
            "ave_precision_score": 0.5430425385467569,
            "fpr": 0.4544456641053787,
            "logloss": 0.7415126572583669,
            "mae": 0.48243607039247466,
            "precision": 0.543046357615894,
            "recall": 0.9979716024340771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.639232345080418,
            "auditor_fn_violation": 0.011759333257221142,
            "auditor_fp_violation": 0.022919341035515628,
            "ave_precision_score": 0.6406033062477495,
            "fpr": 0.16776315789473684,
            "logloss": 2.448228250834689,
            "mae": 0.4575281819950444,
            "precision": 0.6231527093596059,
            "recall": 0.5488069414316703
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6575556780172168,
            "auditor_fn_violation": 0.006359059767591506,
            "auditor_fp_violation": 0.012242711358778148,
            "ave_precision_score": 0.6581927456352382,
            "fpr": 0.15148188803512624,
            "logloss": 2.2386414472102425,
            "mae": 0.4474643138854334,
            "precision": 0.6625916870415648,
            "recall": 0.5496957403651116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7969078324379144,
            "auditor_fn_violation": 0.013524184648171405,
            "auditor_fp_violation": 0.020427315517174312,
            "ave_precision_score": 0.7890150538309263,
            "fpr": 0.12390350877192982,
            "logloss": 0.5250130948734976,
            "mae": 0.33819769199921246,
            "precision": 0.7585470085470085,
            "recall": 0.7700650759219089
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.843396010450461,
            "auditor_fn_violation": 0.017146750444755676,
            "auditor_fp_violation": 0.019432875172663726,
            "ave_precision_score": 0.837338565130363,
            "fpr": 0.11306256860592755,
            "logloss": 0.5120683914238702,
            "mae": 0.33516693563005273,
            "precision": 0.7840670859538784,
            "recall": 0.7586206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6317484136396007,
            "auditor_fn_violation": 0.0104773185675686,
            "auditor_fp_violation": 0.026121289921033186,
            "ave_precision_score": 0.633073436050845,
            "fpr": 0.2719298245614035,
            "logloss": 0.6462885728668574,
            "mae": 0.43527672976957993,
            "precision": 0.6063492063492063,
            "recall": 0.8286334056399133
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7274757112514032,
            "auditor_fn_violation": 0.015287571556121596,
            "auditor_fp_violation": 0.028899836658805984,
            "ave_precision_score": 0.7280537385218275,
            "fpr": 0.22283205268935236,
            "logloss": 0.6091392176407494,
            "mae": 0.4188699897636305,
            "precision": 0.6725806451612903,
            "recall": 0.845841784989858
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8512656389324122,
            "auditor_fn_violation": 0.008063135061080032,
            "auditor_fp_violation": 0.025618022328548647,
            "ave_precision_score": 0.8515114535607067,
            "fpr": 0.14583333333333334,
            "logloss": 0.5073660764107573,
            "mae": 0.28809911825667595,
            "precision": 0.7381889763779528,
            "recall": 0.8134490238611713
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8613083092191335,
            "auditor_fn_violation": 0.017487414360876644,
            "auditor_fp_violation": 0.016045252338510188,
            "ave_precision_score": 0.8615385269703216,
            "fpr": 0.13830954994511527,
            "logloss": 0.5149865952944132,
            "mae": 0.2984301230597231,
            "precision": 0.7562862669245648,
            "recall": 0.7931034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.789507699173019,
            "auditor_fn_violation": 0.058180633253415534,
            "auditor_fp_violation": 0.019972672812852532,
            "ave_precision_score": 0.789815351526637,
            "fpr": 0.05921052631578947,
            "logloss": 0.8189817677592628,
            "mae": 0.35813395247257784,
            "precision": 0.8175675675675675,
            "recall": 0.5249457700650759
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7764279324235459,
            "auditor_fn_violation": 0.06677903380588393,
            "auditor_fp_violation": 0.020296850298583503,
            "ave_precision_score": 0.777047408223708,
            "fpr": 0.07574094401756312,
            "logloss": 0.9364758435197452,
            "mae": 0.3856272261867109,
            "precision": 0.7883435582822086,
            "recall": 0.5212981744421906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8045242732827804,
            "auditor_fn_violation": 0.011740305209879367,
            "auditor_fp_violation": 0.004113665538569263,
            "ave_precision_score": 0.7374710135439855,
            "fpr": 0.07346491228070176,
            "logloss": 0.5398459745640987,
            "mae": 0.3594072495848594,
            "precision": 0.824607329842932,
            "recall": 0.6832971800433839
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8354201882222236,
            "auditor_fn_violation": 0.0034044125996664644,
            "auditor_fp_violation": 0.010976948408342482,
            "ave_precision_score": 0.7695802005436365,
            "fpr": 0.07464324917672886,
            "logloss": 0.5368765822020698,
            "mae": 0.35843726242641977,
            "precision": 0.8287153652392947,
            "recall": 0.6673427991886409
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8507659467256228,
            "auditor_fn_violation": 0.010118164173992465,
            "auditor_fp_violation": 0.002333994631812346,
            "ave_precision_score": 0.8510109711097023,
            "fpr": 0.07675438596491228,
            "logloss": 0.4966272935810682,
            "mae": 0.3267830323791458,
            "precision": 0.8167539267015707,
            "recall": 0.6767895878524945
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8559913586240114,
            "auditor_fn_violation": 0.008135855879124425,
            "auditor_fp_violation": 0.008584603910734826,
            "ave_precision_score": 0.856311527798148,
            "fpr": 0.07574094401756312,
            "logloss": 0.5191317714233703,
            "mae": 0.33599758660778584,
            "precision": 0.8257575757575758,
            "recall": 0.6632860040567952
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.843480374936471,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8437360574153632,
            "fpr": 0.49451754385964913,
            "logloss": 3.0417436475456157,
            "mae": 0.4920233992630975,
            "precision": 0.5054824561403509,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.8443022591385303,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.844776010240145,
            "fpr": 0.4588364434687157,
            "logloss": 2.8432751083980046,
            "mae": 0.4558643018898404,
            "precision": 0.5411635565312843,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6539188619008683,
            "auditor_fn_violation": 0.009183411348327446,
            "auditor_fp_violation": 0.02954691329209943,
            "ave_precision_score": 0.652842891520547,
            "fpr": 0.14692982456140352,
            "logloss": 1.2138640566223722,
            "mae": 0.3520562623720497,
            "precision": 0.7178947368421053,
            "recall": 0.7396963123644251
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6796690622044645,
            "auditor_fn_violation": 0.001703319580604873,
            "auditor_fp_violation": 0.032179790860246124,
            "ave_precision_score": 0.6767391446606998,
            "fpr": 0.14489571899012074,
            "logloss": 1.263165228098273,
            "mae": 0.3561595620203223,
            "precision": 0.7306122448979592,
            "recall": 0.7261663286004056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7914571888545702,
            "auditor_fn_violation": 0.006759713818167987,
            "auditor_fp_violation": 0.02290961605788307,
            "ave_precision_score": 0.7917738237639715,
            "fpr": 0.13925438596491227,
            "logloss": 0.5763924561630357,
            "mae": 0.40955510359306474,
            "precision": 0.722707423580786,
            "recall": 0.7180043383947939
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8164934149419962,
            "auditor_fn_violation": 0.0030481627527425663,
            "auditor_fp_violation": 0.018398205872930014,
            "ave_precision_score": 0.8166640679894661,
            "fpr": 0.11964873765093303,
            "logloss": 0.5809478021085797,
            "mae": 0.4119236023936106,
            "precision": 0.7566964285714286,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.9303127780585062,
            "mae": 0.44682162316319973,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45993413830954993,
            "auc_prc": 0.7231390486928881,
            "auditor_fn_violation": 0.0005722263166215124,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.724271898729719,
            "fpr": 0.0,
            "logloss": 0.9985788971055862,
            "mae": 0.46831511124625036,
            "precision": 1.0,
            "recall": 0.002028397565922921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6773075409925136,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5413932392517061,
            "fpr": 0.49451754385964913,
            "logloss": 11.358169506069498,
            "mae": 0.4944725347061952,
            "precision": 0.5054824561403509,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7055613372431321,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5864556176969375,
            "fpr": 0.4588364434687157,
            "logloss": 10.162992886697934,
            "mae": 0.4588095140771206,
            "precision": 0.5411635565312843,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.678724927845952,
            "auditor_fn_violation": 0.017515317578110146,
            "auditor_fp_violation": 0.007714338507021436,
            "ave_precision_score": 0.6787368508365895,
            "fpr": 0.0625,
            "logloss": 2.3475474735577926,
            "mae": 0.407566609092978,
            "precision": 0.7106598984771574,
            "recall": 0.3036876355748373
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7199366058149286,
            "auditor_fn_violation": 0.030695377435580012,
            "auditor_fp_violation": 0.012032626221776374,
            "ave_precision_score": 0.7194722970289031,
            "fpr": 0.06805708013172337,
            "logloss": 2.1208813527581594,
            "mae": 0.41697226309491187,
            "precision": 0.7129629629629629,
            "recall": 0.31237322515212984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8374834910534872,
            "auditor_fn_violation": 0.011340716215701947,
            "auditor_fp_violation": 0.0017456334850429857,
            "ave_precision_score": 0.8377696123628217,
            "fpr": 0.04276315789473684,
            "logloss": 0.5314163877280746,
            "mae": 0.36212502146883163,
            "precision": 0.8631578947368421,
            "recall": 0.5336225596529284
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8389398044159367,
            "auditor_fn_violation": 0.007020348545943979,
            "auditor_fp_violation": 0.007135016465422615,
            "ave_precision_score": 0.8392699113664974,
            "fpr": 0.038419319429198684,
            "logloss": 0.5564576593983442,
            "mae": 0.37238312106422106,
            "precision": 0.8805460750853242,
            "recall": 0.5233265720081136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5688745690596497,
            "auditor_fn_violation": 0.014399474825893366,
            "auditor_fp_violation": 0.018120064573851482,
            "ave_precision_score": 0.5529502560237737,
            "fpr": 0.07894736842105263,
            "logloss": 0.8259777479673435,
            "mae": 0.4847580991162543,
            "precision": 0.5885714285714285,
            "recall": 0.22342733188720174
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6022334719236596,
            "auditor_fn_violation": 0.011622651255892052,
            "auditor_fp_violation": 0.018442848964542884,
            "ave_precision_score": 0.5852050911885521,
            "fpr": 0.06915477497255763,
            "logloss": 0.8421973705417436,
            "mae": 0.49686355648396696,
            "precision": 0.6480446927374302,
            "recall": 0.23529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.4848497294705714,
            "auditor_fn_violation": 0.0017862579442097654,
            "auditor_fp_violation": 0.005710993114715852,
            "ave_precision_score": 0.4946494964547443,
            "fpr": 0.48355263157894735,
            "logloss": 0.6942561459352085,
            "mae": 0.49946287218808083,
            "precision": 0.5078125,
            "recall": 0.9869848156182213
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5152497976569975,
            "auditor_fn_violation": 0.00431284970932239,
            "auditor_fp_violation": 0.004128172942084785,
            "ave_precision_score": 0.5182206127954301,
            "fpr": 0.43688254665203075,
            "logloss": 0.6912675506153972,
            "mae": 0.4975331440388044,
            "precision": 0.5487528344671202,
            "recall": 0.9817444219066938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7503115964183396,
            "auditor_fn_violation": 0.004887829660920198,
            "auditor_fp_violation": 0.000498405103668265,
            "ave_precision_score": 0.7134428630474241,
            "fpr": 0.0712719298245614,
            "logloss": 0.6008848927717664,
            "mae": 0.41534594832020894,
            "precision": 0.796875,
            "recall": 0.5531453362255966
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7467594878787146,
            "auditor_fn_violation": 0.002493748928467258,
            "auditor_fp_violation": 0.002878166376924252,
            "ave_precision_score": 0.7154279921894082,
            "fpr": 0.07025246981339188,
            "logloss": 0.6251936722812614,
            "mae": 0.42735839367697975,
            "precision": 0.8012422360248447,
            "recall": 0.5233265720081136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8347484917370009,
            "auditor_fn_violation": 0.008531700726871408,
            "auditor_fp_violation": 0.010918718636947147,
            "ave_precision_score": 0.8170791693987234,
            "fpr": 0.13157894736842105,
            "logloss": 0.5116047779197155,
            "mae": 0.3197119989424225,
            "precision": 0.7505197505197505,
            "recall": 0.7830802603036876
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8297072509368882,
            "auditor_fn_violation": 0.011128354593285138,
            "auditor_fp_violation": 0.004548343216088324,
            "ave_precision_score": 0.8253491129527768,
            "fpr": 0.11855104281009879,
            "logloss": 0.5393316902955954,
            "mae": 0.3323012475705369,
            "precision": 0.7692307692307693,
            "recall": 0.7302231237322515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7512157846891261,
            "auditor_fn_violation": 0.0018052859915515468,
            "auditor_fp_violation": 0.00590792391177501,
            "ave_precision_score": 0.5077700173150993,
            "fpr": 0.48464912280701755,
            "logloss": 0.6932121504522724,
            "mae": 0.49956103571151433,
            "precision": 0.5077951002227171,
            "recall": 0.9891540130151844
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7697849902164835,
            "auditor_fn_violation": 0.00431284970932239,
            "auditor_fp_violation": 0.004128172942084785,
            "ave_precision_score": 0.548722842204635,
            "fpr": 0.43688254665203075,
            "logloss": 0.6894150992326826,
            "mae": 0.4976617728577749,
            "precision": 0.5487528344671202,
            "recall": 0.9817444219066938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8228039691625153,
            "auditor_fn_violation": 0.006417208966015907,
            "auditor_fp_violation": 0.010998949702415687,
            "ave_precision_score": 0.8140475526519484,
            "fpr": 0.07346491228070176,
            "logloss": 0.5000399940449687,
            "mae": 0.3327991193193093,
            "precision": 0.8290816326530612,
            "recall": 0.7049891540130152
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8379927336067917,
            "auditor_fn_violation": 0.010177612814306992,
            "auditor_fp_violation": 0.008256345884169564,
            "ave_precision_score": 0.8300807018734279,
            "fpr": 0.07683863885839737,
            "logloss": 0.5229220380814462,
            "mae": 0.3426245943644175,
            "precision": 0.8267326732673267,
            "recall": 0.6774847870182555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8243819703090317,
            "auditor_fn_violation": 0.00453343227917951,
            "auditor_fp_violation": 0.01554537674563348,
            "ave_precision_score": 0.8191358649780447,
            "fpr": 0.09758771929824561,
            "logloss": 0.5123748162887602,
            "mae": 0.3351251410091655,
            "precision": 0.7939814814814815,
            "recall": 0.7440347071583514
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8506050108805231,
            "auditor_fn_violation": 0.008621246295558235,
            "auditor_fp_violation": 0.013965409482192657,
            "ave_precision_score": 0.8475593638638105,
            "fpr": 0.0801317233809001,
            "logloss": 0.5179748426309904,
            "mae": 0.337007784539206,
            "precision": 0.8270142180094787,
            "recall": 0.7079107505070994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6434584439358634,
            "auditor_fn_violation": 0.011545267724626097,
            "auditor_fp_violation": 0.022712685260823897,
            "ave_precision_score": 0.6453313437254166,
            "fpr": 0.15789473684210525,
            "logloss": 0.6186538558443072,
            "mae": 0.42076879968507247,
            "precision": 0.6876355748373102,
            "recall": 0.6876355748373102
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6236087598952763,
            "auditor_fn_violation": 0.01755421120717488,
            "auditor_fp_violation": 0.021486457386856027,
            "ave_precision_score": 0.6880340576207885,
            "fpr": 0.14050493962678376,
            "logloss": 0.6092405744222261,
            "mae": 0.4184151093928403,
            "precision": 0.7217391304347827,
            "recall": 0.6734279918864098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7666201396858183,
            "auditor_fn_violation": 0.002207253491646687,
            "auditor_fp_violation": 0.006082973509160944,
            "ave_precision_score": 0.7670037636800422,
            "fpr": 0.46381578947368424,
            "logloss": 2.2182340176043707,
            "mae": 0.48053711285945355,
            "precision": 0.5115473441108545,
            "recall": 0.9609544468546638
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.8088623857329953,
            "auditor_fn_violation": 0.002273319335683098,
            "auditor_fp_violation": 0.0029175573401120803,
            "ave_precision_score": 0.8091077017605802,
            "fpr": 0.4226125137211855,
            "logloss": 1.9816519481887611,
            "mae": 0.4322460329427939,
            "precision": 0.5569620253164557,
            "recall": 0.9817444219066938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 26311,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.4907522271543924,
            "auditor_fn_violation": 0.025580831145107914,
            "auditor_fp_violation": 0.032320963161784726,
            "ave_precision_score": 0.4848124191663047,
            "fpr": 0.07675438596491228,
            "logloss": 4.562052084112152,
            "mae": 0.5208448821405935,
            "precision": 0.44881889763779526,
            "recall": 0.12364425162689804
        },
        "train": {
            "accuracy": 0.4313940724478595,
            "auc_prc": 0.5067459403036172,
            "auditor_fn_violation": 0.021786904700939382,
            "auditor_fp_violation": 0.035693464776600715,
            "ave_precision_score": 0.49885241443756345,
            "fpr": 0.09001097694840834,
            "logloss": 4.976930142184803,
            "mae": 0.5631239393006992,
            "precision": 0.41007194244604317,
            "recall": 0.11561866125760649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8274429412670047,
            "auditor_fn_violation": 0.02407523689918941,
            "auditor_fp_violation": 0.057659392383397526,
            "ave_precision_score": 0.8276715935081204,
            "fpr": 0.2532894736842105,
            "logloss": 0.5609882741449042,
            "mae": 0.3616536744490364,
            "precision": 0.6292134831460674,
            "recall": 0.8503253796095445
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.8276413935522486,
            "auditor_fn_violation": 0.03307779828688355,
            "auditor_fp_violation": 0.051891028839437185,
            "ave_precision_score": 0.8279651953362197,
            "fpr": 0.2261251372118551,
            "logloss": 0.5614914402036172,
            "mae": 0.3617619226648831,
            "precision": 0.6688102893890675,
            "recall": 0.8438133874239351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6895601699438874,
            "auditor_fn_violation": 0.001726795296266697,
            "auditor_fp_violation": 0.01333780682304431,
            "ave_precision_score": 0.6690322122154779,
            "fpr": 0.4517543859649123,
            "logloss": 0.8014065223576101,
            "mae": 0.43573328156612423,
            "precision": 0.5264367816091954,
            "recall": 0.9934924078091106
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6917736550268788,
            "auditor_fn_violation": 0.002509334859270178,
            "auditor_fp_violation": 0.00449056980341285,
            "ave_precision_score": 0.6877422680007852,
            "fpr": 0.42041712403951703,
            "logloss": 0.7547824254380661,
            "mae": 0.41762807147432235,
            "precision": 0.5602755453501722,
            "recall": 0.9898580121703854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 26311,
        "test": {
            "accuracy": 0.40021929824561403,
            "auc_prc": 0.565054004271718,
            "auditor_fn_violation": 0.012491913079879742,
            "auditor_fp_violation": 0.028192710156766644,
            "ave_precision_score": 0.46476497059144517,
            "fpr": 0.3125,
            "logloss": 0.8159178399252763,
            "mae": 0.5324357315375093,
            "precision": 0.41115702479338845,
            "recall": 0.4316702819956616
        },
        "train": {
            "accuracy": 0.3907793633369923,
            "auc_prc": 0.5867461223740674,
            "auditor_fn_violation": 0.02240366224842638,
            "auditor_fp_violation": 0.02290453206161798,
            "ave_precision_score": 0.4961331848517339,
            "fpr": 0.2996706915477497,
            "logloss": 0.8231851469263083,
            "mae": 0.5359082556647605,
            "precision": 0.4359504132231405,
            "recall": 0.4279918864097363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5578477434214002,
            "auditor_fn_violation": 0.000720687293069985,
            "auditor_fp_violation": 0.006980102695763815,
            "ave_precision_score": 0.5193666047196622,
            "fpr": 0.46710526315789475,
            "logloss": 0.6891148156253813,
            "mae": 0.4932506151105228,
            "precision": 0.5170068027210885,
            "recall": 0.9891540130151844
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.533231084876592,
            "auditor_fn_violation": 0.000752577801626726,
            "auditor_fp_violation": 0.006772619604094568,
            "ave_precision_score": 0.5482042814120804,
            "fpr": 0.433589462129528,
            "logloss": 0.685976670224651,
            "mae": 0.4914101764281678,
            "precision": 0.5501138952164009,
            "recall": 0.9797160243407708
        }
    }
]