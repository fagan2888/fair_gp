[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 16.89067354400237,
            "mae": 0.48903508771929827,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 19.259822621969953,
            "mae": 0.557628979143798,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 16.89067354400237,
            "mae": 0.48903508771929827,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 19.259822621969953,
            "mae": 0.557628979143798,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8103860529472313,
            "auditor_fn_violation": 0.0077000236016049085,
            "auditor_fp_violation": 0.004103606656125292,
            "ave_precision_score": 0.8104635598429233,
            "fpr": 0.021929824561403508,
            "logloss": 0.6632849339038945,
            "mae": 0.42522505946725936,
            "precision": 0.900497512437811,
            "recall": 0.40582959641255606
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.8721540231583949,
            "auditor_fn_violation": 0.0018431765732905827,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8709168401710679,
            "fpr": 0.019758507135016465,
            "logloss": 0.6124336316842424,
            "mae": 0.43412235029993257,
            "precision": 0.9113300492610837,
            "recall": 0.3641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8044828193207645,
            "auditor_fn_violation": 0.006357682322397938,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.8039009453219454,
            "fpr": 0.025219298245614034,
            "logloss": 0.6561974163134137,
            "mae": 0.42415338143648657,
            "precision": 0.8935185185185185,
            "recall": 0.4327354260089686
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.8700512403685112,
            "auditor_fn_violation": 0.01178293300604165,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8690326618957694,
            "fpr": 0.024149286498353458,
            "logloss": 0.6003291247865398,
            "mae": 0.4285561871583803,
            "precision": 0.9047619047619048,
            "recall": 0.41141732283464566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8166370798000351,
            "auditor_fn_violation": 0.006805129415466922,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.8165878512020291,
            "fpr": 0.025219298245614034,
            "logloss": 0.593023986368451,
            "mae": 0.4159951758219943,
            "precision": 0.8909952606635071,
            "recall": 0.42152466367713004
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.8712279769676671,
            "auditor_fn_violation": 0.009853323768118441,
            "auditor_fp_violation": 0.003538227290927267,
            "ave_precision_score": 0.8709158920926957,
            "fpr": 0.021953896816684963,
            "logloss": 0.5945447537496792,
            "mae": 0.4261071780116673,
            "precision": 0.9090909090909091,
            "recall": 0.3937007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8117636980957632,
            "auditor_fn_violation": 0.0077000236016049085,
            "auditor_fp_violation": 0.004103606656125292,
            "ave_precision_score": 0.8115754057460561,
            "fpr": 0.021929824561403508,
            "logloss": 0.6639249206193732,
            "mae": 0.42542168403198316,
            "precision": 0.900497512437811,
            "recall": 0.40582959641255606
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.8721664644840593,
            "auditor_fn_violation": 0.0018431765732905827,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8712672439705224,
            "fpr": 0.019758507135016465,
            "logloss": 0.61279592293755,
            "mae": 0.43434098584488456,
            "precision": 0.9113300492610837,
            "recall": 0.3641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 16.89067354400237,
            "mae": 0.48903508771929827,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 19.259822621969953,
            "mae": 0.557628979143798,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8103617082291497,
            "auditor_fn_violation": 0.007567264573991049,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8100393066801633,
            "fpr": 0.023026315789473683,
            "logloss": 0.6576800625353163,
            "mae": 0.4233694579699332,
            "precision": 0.8975609756097561,
            "recall": 0.4125560538116592
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8702382305607604,
            "auditor_fn_violation": 0.0031331840929324176,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8693690328291194,
            "fpr": 0.019758507135016465,
            "logloss": 0.6077498990711843,
            "mae": 0.4311956294303925,
            "precision": 0.9150943396226415,
            "recall": 0.38188976377952755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7715472130088241,
            "auditor_fn_violation": 0.01652849893792778,
            "auditor_fp_violation": 0.01610383254273022,
            "ave_precision_score": 0.7021222993713077,
            "fpr": 0.16447368421052633,
            "logloss": 3.707194998605141,
            "mae": 0.354146244969953,
            "precision": 0.6894409937888198,
            "recall": 0.7466367713004485
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8125357825458414,
            "auditor_fn_violation": 0.001944734954233913,
            "auditor_fp_violation": 0.020643744909882796,
            "ave_precision_score": 0.7636315981103516,
            "fpr": 0.1251372118551043,
            "logloss": 2.840063307618087,
            "mae": 0.33887352273182875,
            "precision": 0.7584745762711864,
            "recall": 0.7047244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8138611770585568,
            "auditor_fn_violation": 0.004934210526315804,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.8128466634450981,
            "fpr": 0.025219298245614034,
            "logloss": 0.6373805371789356,
            "mae": 0.413353311155974,
            "precision": 0.8935185185185185,
            "recall": 0.4327354260089686
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.8720209271194037,
            "auditor_fn_violation": 0.012718566600689747,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8707734978369684,
            "fpr": 0.024149286498353458,
            "logloss": 0.5936815934659014,
            "mae": 0.42062757860593714,
            "precision": 0.9051724137931034,
            "recall": 0.41338582677165353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8125650100234627,
            "auditor_fn_violation": 0.005610298166942039,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.81206479474168,
            "fpr": 0.023026315789473683,
            "logloss": 0.6530997987687144,
            "mae": 0.42135123873772445,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.872306527962959,
            "auditor_fn_violation": 0.0031331840929324176,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8713413656536977,
            "fpr": 0.019758507135016465,
            "logloss": 0.6058186438554627,
            "mae": 0.42972421097344965,
            "precision": 0.9150943396226415,
            "recall": 0.38188976377952755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7662184212060466,
            "auditor_fn_violation": 0.013047262213830544,
            "auditor_fp_violation": 0.01569676605677284,
            "ave_precision_score": 0.7035534080466064,
            "fpr": 0.16337719298245615,
            "logloss": 3.4947005783514458,
            "mae": 0.3683929427673942,
            "precision": 0.6934156378600823,
            "recall": 0.7556053811659192
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8088957175598386,
            "auditor_fn_violation": 0.0015990042957034316,
            "auditor_fp_violation": 0.022406049034001303,
            "ave_precision_score": 0.7659851543717078,
            "fpr": 0.12294182217343579,
            "logloss": 2.63127698377212,
            "mae": 0.35019115500078507,
            "precision": 0.7627118644067796,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8123469980804745,
            "auditor_fn_violation": 0.005610298166942039,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8118521333929345,
            "fpr": 0.023026315789473683,
            "logloss": 0.6509564599002303,
            "mae": 0.42036692739643616,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8723015465025372,
            "auditor_fn_violation": 0.0031331840929324176,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8713273446213212,
            "fpr": 0.019758507135016465,
            "logloss": 0.6042373585548598,
            "mae": 0.42858337284974307,
            "precision": 0.9150943396226415,
            "recall": 0.38188976377952755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7633749774590788,
            "auditor_fn_violation": 0.015432007709857608,
            "auditor_fp_violation": 0.01610383254273022,
            "ave_precision_score": 0.7534591962037988,
            "fpr": 0.16447368421052633,
            "logloss": 0.9833498104158845,
            "mae": 0.3616719441651775,
            "precision": 0.6894409937888198,
            "recall": 0.7466367713004485
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8021748965690436,
            "auditor_fn_violation": 0.005892546911328733,
            "auditor_fp_violation": 0.020643744909882796,
            "ave_precision_score": 0.7935677526550375,
            "fpr": 0.1251372118551043,
            "logloss": 0.8468416610723011,
            "mae": 0.3465161344157092,
            "precision": 0.76,
            "recall": 0.7106299212598425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7193652627092434,
            "auditor_fn_violation": 0.010586303201951067,
            "auditor_fp_violation": 0.008621338754611853,
            "ave_precision_score": 0.7199758734004503,
            "fpr": 0.08991228070175439,
            "logloss": 0.6904945066213132,
            "mae": 0.42820552848791604,
            "precision": 0.7371794871794872,
            "recall": 0.515695067264574
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7763295831286268,
            "auditor_fn_violation": 0.01032654260698204,
            "auditor_fp_violation": 0.008206835125145386,
            "ave_precision_score": 0.7768215727612762,
            "fpr": 0.08232711306256861,
            "logloss": 0.6285886584920555,
            "mae": 0.4251912133847043,
            "precision": 0.7781065088757396,
            "recall": 0.5177165354330708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5518606417534395,
            "auditor_fn_violation": 0.006819880418535133,
            "auditor_fp_violation": 0.010480197274301634,
            "ave_precision_score": 0.5676838455495343,
            "fpr": 0.07236842105263158,
            "logloss": 8.013689136702668,
            "mae": 0.49791859775289415,
            "precision": 0.625,
            "recall": 0.24663677130044842
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.630816129429218,
            "auditor_fn_violation": 0.012022783650397158,
            "auditor_fp_violation": 0.007860911440813002,
            "ave_precision_score": 0.6440541099064703,
            "fpr": 0.0570801317233809,
            "logloss": 8.191763812006267,
            "mae": 0.5210333333057292,
            "precision": 0.7263157894736842,
            "recall": 0.27165354330708663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8135411353772348,
            "auditor_fn_violation": 0.004934210526315804,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.8126005212135075,
            "fpr": 0.025219298245614034,
            "logloss": 0.6394910394229996,
            "mae": 0.41441494058750417,
            "precision": 0.8935185185185185,
            "recall": 0.4327354260089686
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.8720920445127518,
            "auditor_fn_violation": 0.012429017174170475,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8708997887381882,
            "fpr": 0.024149286498353458,
            "logloss": 0.5952491915004815,
            "mae": 0.4217769538305734,
            "precision": 0.9047619047619048,
            "recall": 0.41141732283464566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7582833884113568,
            "auditor_fn_violation": 0.008838309338368351,
            "auditor_fp_violation": 0.00689660040659589,
            "ave_precision_score": 0.688869256436331,
            "fpr": 0.1524122807017544,
            "logloss": 3.6609349237710616,
            "mae": 0.3542865313938819,
            "precision": 0.6924778761061947,
            "recall": 0.7017937219730942
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7958004302370376,
            "auditor_fn_violation": 0.00799286066190135,
            "auditor_fp_violation": 0.016075917991572538,
            "ave_precision_score": 0.7469588869330132,
            "fpr": 0.1141602634467618,
            "logloss": 2.830904826348033,
            "mae": 0.34452154243039834,
            "precision": 0.764172335600907,
            "recall": 0.6633858267716536
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8131434279516132,
            "auditor_fn_violation": 0.004317126897962416,
            "auditor_fp_violation": 0.004757736616218659,
            "ave_precision_score": 0.8126953202768359,
            "fpr": 0.027412280701754384,
            "logloss": 0.6345035127247647,
            "mae": 0.4118818503346944,
            "precision": 0.8863636363636364,
            "recall": 0.437219730941704
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.8720517361328773,
            "auditor_fn_violation": 0.01274665721669534,
            "auditor_fp_violation": 0.002366989619565663,
            "ave_precision_score": 0.8712403522628699,
            "fpr": 0.025246981339187707,
            "logloss": 0.5918109326325763,
            "mae": 0.4191774964323378,
            "precision": 0.9033613445378151,
            "recall": 0.42322834645669294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8126663529371999,
            "auditor_fn_violation": 0.005357072614271124,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8123054221443217,
            "fpr": 0.023026315789473683,
            "logloss": 0.6566995209029758,
            "mae": 0.423063151791606,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8722857635282519,
            "auditor_fn_violation": 0.0025908191223627196,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8714153761574897,
            "fpr": 0.019758507135016465,
            "logloss": 0.6080274457650814,
            "mae": 0.4314923809699292,
            "precision": 0.9146919431279621,
            "recall": 0.3799212598425197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8125007945577299,
            "auditor_fn_violation": 0.005357072614271124,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8121426431363595,
            "fpr": 0.023026315789473683,
            "logloss": 0.6542873603772216,
            "mae": 0.4218721301199283,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8722439907737414,
            "auditor_fn_violation": 0.0025908191223627196,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8713293070055428,
            "fpr": 0.019758507135016465,
            "logloss": 0.606668494285627,
            "mae": 0.4303248498928338,
            "precision": 0.9146919431279621,
            "recall": 0.3799212598425197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8137392340687809,
            "auditor_fn_violation": 0.004934210526315804,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.8127342467960122,
            "fpr": 0.025219298245614034,
            "logloss": 0.6386002901997088,
            "mae": 0.4139604140612629,
            "precision": 0.8935185185185185,
            "recall": 0.4327354260089686
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.8720585845737634,
            "auditor_fn_violation": 0.012429017174170475,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8708106111499777,
            "fpr": 0.024149286498353458,
            "logloss": 0.5945805099471111,
            "mae": 0.4212824680014656,
            "precision": 0.9047619047619048,
            "recall": 0.41141732283464566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7597666996768236,
            "auditor_fn_violation": 0.012685862638659428,
            "auditor_fp_violation": 0.01638619079888563,
            "ave_precision_score": 0.6977499548471036,
            "fpr": 0.16228070175438597,
            "logloss": 3.5046761932315946,
            "mae": 0.3648005317765893,
            "precision": 0.6954732510288066,
            "recall": 0.757847533632287
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.803165227047851,
            "auditor_fn_violation": 0.0014758377486019589,
            "auditor_fp_violation": 0.02095425908322052,
            "ave_precision_score": 0.7610852505105195,
            "fpr": 0.1251372118551043,
            "logloss": 2.637901957862531,
            "mae": 0.34757680580854156,
            "precision": 0.7610062893081762,
            "recall": 0.7145669291338582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8037829114799268,
            "auditor_fn_violation": 0.010188026119109437,
            "auditor_fp_violation": 0.012367291619606962,
            "ave_precision_score": 0.8042554832954878,
            "fpr": 0.17105263157894737,
            "logloss": 0.5961847997433509,
            "mae": 0.3213934548833717,
            "precision": 0.6976744186046512,
            "recall": 0.8071748878923767
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8604411769193016,
            "auditor_fn_violation": 0.0033276575883557894,
            "auditor_fp_violation": 0.01407119490756756,
            "ave_precision_score": 0.8606403849104984,
            "fpr": 0.1251372118551043,
            "logloss": 0.5221243462860727,
            "mae": 0.3070257605716962,
            "precision": 0.77734375,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8125384615879595,
            "auditor_fn_violation": 0.005357072614271124,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8121772724777018,
            "fpr": 0.023026315789473683,
            "logloss": 0.6550793189359243,
            "mae": 0.42220979108236445,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.872273572117057,
            "auditor_fn_violation": 0.0025908191223627196,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8713687487966304,
            "fpr": 0.019758507135016465,
            "logloss": 0.6072243043339901,
            "mae": 0.4307128280791691,
            "precision": 0.9146919431279621,
            "recall": 0.3799212598425197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8125292741779513,
            "auditor_fn_violation": 0.005610298166942039,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8120241936294975,
            "fpr": 0.023026315789473683,
            "logloss": 0.65254881409616,
            "mae": 0.421103688577381,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8723096022160666,
            "auditor_fn_violation": 0.0031331840929324176,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8713444399068053,
            "fpr": 0.019758507135016465,
            "logloss": 0.6054179109737622,
            "mae": 0.42943791970809303,
            "precision": 0.9150943396226415,
            "recall": 0.38188976377952755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8122928159408657,
            "auditor_fn_violation": 0.005610298166942039,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8117980533455258,
            "fpr": 0.023026315789473683,
            "logloss": 0.650668240103047,
            "mae": 0.4202306005750479,
            "precision": 0.8970588235294118,
            "recall": 0.4103139013452915
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8723016022635584,
            "auditor_fn_violation": 0.0031331840929324176,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8713274053560907,
            "fpr": 0.019758507135016465,
            "logloss": 0.6040203784161117,
            "mae": 0.42842482789250713,
            "precision": 0.9150943396226415,
            "recall": 0.38188976377952755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6784632151277493,
            "auditor_fn_violation": 0.009745496027063172,
            "auditor_fp_violation": 0.008416629018899181,
            "ave_precision_score": 0.6789958223562658,
            "fpr": 0.09320175438596491,
            "logloss": 0.9989521652556194,
            "mae": 0.4111505980006673,
            "precision": 0.6996466431095406,
            "recall": 0.4439461883408072
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.766419548787043,
            "auditor_fn_violation": 0.009645885373000176,
            "auditor_fp_violation": 0.00973216790645352,
            "ave_precision_score": 0.7666846751324079,
            "fpr": 0.06476399560922064,
            "logloss": 1.0047462257542097,
            "mae": 0.41481350775913506,
            "precision": 0.8,
            "recall": 0.4645669291338583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7324127535789178,
            "auditor_fn_violation": 0.012302336558886002,
            "auditor_fp_violation": 0.015289699570815456,
            "ave_precision_score": 0.6723426468719258,
            "fpr": 0.16228070175438597,
            "logloss": 3.453596231352137,
            "mae": 0.41391817143742454,
            "precision": 0.6696428571428571,
            "recall": 0.672645739910314
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7684430425670836,
            "auditor_fn_violation": 0.014745412586324629,
            "auditor_fp_violation": 0.020714563931872106,
            "ave_precision_score": 0.7281119683432304,
            "fpr": 0.12843029637760703,
            "logloss": 2.5838259676756556,
            "mae": 0.3881639162677572,
            "precision": 0.7346938775510204,
            "recall": 0.6377952755905512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7613135601024538,
            "auditor_fn_violation": 0.015218118165368583,
            "auditor_fp_violation": 0.0165108990286876,
            "ave_precision_score": 0.7586038228263264,
            "fpr": 0.16557017543859648,
            "logloss": 0.985302772478187,
            "mae": 0.3588705813479528,
            "precision": 0.6873706004140787,
            "recall": 0.7443946188340808
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8008777482342475,
            "auditor_fn_violation": 0.007268987095603172,
            "auditor_fp_violation": 0.020790830570937505,
            "ave_precision_score": 0.7984157073625004,
            "fpr": 0.12623490669593854,
            "logloss": 0.847502080723556,
            "mae": 0.34418882071383045,
            "precision": 0.7578947368421053,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7640349719905187,
            "auditor_fn_violation": 0.013047262213830544,
            "auditor_fp_violation": 0.0165108990286876,
            "ave_precision_score": 0.7534846325231356,
            "fpr": 0.16557017543859648,
            "logloss": 0.9703963024422426,
            "mae": 0.35741634800899447,
            "precision": 0.6905737704918032,
            "recall": 0.7556053811659192
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8036798006301904,
            "auditor_fn_violation": 0.004870480652048031,
            "auditor_fp_violation": 0.020790830570937505,
            "ave_precision_score": 0.7942817271205938,
            "fpr": 0.12623490669593854,
            "logloss": 0.8306724025998765,
            "mae": 0.34179893005169054,
            "precision": 0.7589098532494759,
            "recall": 0.7125984251968503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8069146777103366,
            "auditor_fn_violation": 0.005772559200692335,
            "auditor_fp_violation": 0.0038824260221368883,
            "ave_precision_score": 0.7829761399451339,
            "fpr": 0.020833333333333332,
            "logloss": 0.6593361883790854,
            "mae": 0.42891280486174654,
            "precision": 0.9045226130653267,
            "recall": 0.40358744394618834
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.8645379840224938,
            "auditor_fn_violation": 0.002895494265192717,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8436229651609928,
            "fpr": 0.019758507135016465,
            "logloss": 0.6137595022597192,
            "mae": 0.4378742341073645,
            "precision": 0.9108910891089109,
            "recall": 0.36220472440944884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7616647874299416,
            "auditor_fn_violation": 0.015547557233891908,
            "auditor_fp_violation": 0.01610383254273022,
            "ave_precision_score": 0.7584448159243875,
            "fpr": 0.16447368421052633,
            "logloss": 0.9742033453646662,
            "mae": 0.357702203552451,
            "precision": 0.691358024691358,
            "recall": 0.7533632286995515
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8032591790367611,
            "auditor_fn_violation": 0.006283654718791328,
            "auditor_fp_violation": 0.020790830570937505,
            "ave_precision_score": 0.8007196371542473,
            "fpr": 0.12623490669593854,
            "logloss": 0.833166297537233,
            "mae": 0.3421657961495752,
            "precision": 0.7589098532494759,
            "recall": 0.7125984251968503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8114659914124848,
            "auditor_fn_violation": 0.004934210526315804,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.810597991313754,
            "fpr": 0.025219298245614034,
            "logloss": 0.6421269327395668,
            "mae": 0.41596228307169975,
            "precision": 0.8935185185185185,
            "recall": 0.4327354260089686
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.8702597548626816,
            "auditor_fn_violation": 0.012429017174170475,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8691199971841722,
            "fpr": 0.024149286498353458,
            "logloss": 0.5961859425835452,
            "mae": 0.4227190108928409,
            "precision": 0.9047619047619048,
            "recall": 0.41141732283464566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 20404,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5570841501232677,
            "auditor_fn_violation": 0.01207123751081741,
            "auditor_fp_violation": 0.014221444168360816,
            "ave_precision_score": 0.5588253183317571,
            "fpr": 0.17543859649122806,
            "logloss": 1.3532614928571014,
            "mae": 0.45193874334044026,
            "precision": 0.5833333333333334,
            "recall": 0.5022421524663677
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6453319062825312,
            "auditor_fn_violation": 0.005384755006612103,
            "auditor_fp_violation": 0.01030689150798213,
            "ave_precision_score": 0.646846606183564,
            "fpr": 0.15806805708013172,
            "logloss": 1.4000090385361206,
            "mae": 0.43914171560418236,
            "precision": 0.6587677725118484,
            "recall": 0.547244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 20404,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5431181204333926,
            "auditor_fn_violation": 0.00869817480922036,
            "auditor_fp_violation": 0.01615795120849334,
            "ave_precision_score": 0.5449005874813371,
            "fpr": 0.17653508771929824,
            "logloss": 1.3296769889832187,
            "mae": 0.4500928366026512,
            "precision": 0.5706666666666667,
            "recall": 0.4798206278026906
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6548183167160835,
            "auditor_fn_violation": 0.004459925495043086,
            "auditor_fp_violation": 0.014340851952834535,
            "ave_precision_score": 0.6562477597052268,
            "fpr": 0.14050493962678376,
            "logloss": 1.2404300165606414,
            "mae": 0.42967071415860697,
            "precision": 0.678391959798995,
            "recall": 0.531496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7736895436808642,
            "auditor_fn_violation": 0.0016963653528439943,
            "auditor_fp_violation": 0.001294142007378978,
            "ave_precision_score": 0.7741070792851101,
            "fpr": 0.17763157894736842,
            "logloss": 0.8513850979954585,
            "mae": 0.30678177651338556,
            "precision": 0.6829745596868885,
            "recall": 0.7825112107623319
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8256265243824317,
            "auditor_fn_violation": 0.0003111575926774298,
            "auditor_fp_violation": 0.00580443599458507,
            "ave_precision_score": 0.8260429404019048,
            "fpr": 0.1394072447859495,
            "logloss": 0.7094932745431172,
            "mae": 0.2894692148138696,
            "precision": 0.7590132827324478,
            "recall": 0.7874015748031497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8250466738941193,
            "auditor_fn_violation": 0.005153017071827553,
            "auditor_fp_violation": 0.017212088698140202,
            "ave_precision_score": 0.825409492904243,
            "fpr": 0.17214912280701755,
            "logloss": 0.5480699640183104,
            "mae": 0.33065702855227547,
            "precision": 0.700381679389313,
            "recall": 0.8228699551569507
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8761185137819826,
            "auditor_fn_violation": 0.006177774704616373,
            "auditor_fp_violation": 0.019505192940977793,
            "ave_precision_score": 0.8762602476030494,
            "fpr": 0.13611416026344675,
            "logloss": 0.4927122362094806,
            "mae": 0.31894000831369873,
            "precision": 0.7647058823529411,
            "recall": 0.7933070866141733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7390521917246433,
            "auditor_fn_violation": 0.012302336558886002,
            "auditor_fp_violation": 0.015289699570815456,
            "ave_precision_score": 0.6778469247610938,
            "fpr": 0.16228070175438597,
            "logloss": 3.4930965431779106,
            "mae": 0.40787803982956367,
            "precision": 0.6696428571428571,
            "recall": 0.672645739910314
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7739436850624496,
            "auditor_fn_violation": 0.014745412586324629,
            "auditor_fp_violation": 0.020899782912459516,
            "ave_precision_score": 0.7329524021211391,
            "fpr": 0.12733260153677278,
            "logloss": 2.5985600566500637,
            "mae": 0.38342086890657173,
            "precision": 0.7363636363636363,
            "recall": 0.6377952755905512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8004462145065374,
            "auditor_fn_violation": 0.006620741877114309,
            "auditor_fp_violation": 0.014404977034861835,
            "ave_precision_score": 0.7903604762573442,
            "fpr": 0.10855263157894737,
            "logloss": 0.574820173865614,
            "mae": 0.40883061240770313,
            "precision": 0.7608695652173914,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8610848371976103,
            "auditor_fn_violation": 0.004235200566998291,
            "auditor_fp_violation": 0.010680053277695004,
            "ave_precision_score": 0.8508944500788294,
            "fpr": 0.07574094401756312,
            "logloss": 0.5607388163577866,
            "mae": 0.409620441210126,
            "precision": 0.8449438202247191,
            "recall": 0.7401574803149606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 20404,
        "test": {
            "accuracy": 0.2675438596491228,
            "auc_prc": 0.33577853477967284,
            "auditor_fn_violation": 0.005693887184328538,
            "auditor_fp_violation": 0.009614298622091729,
            "ave_precision_score": 0.34176141114700764,
            "fpr": 0.3267543859649123,
            "logloss": 16.409007358041574,
            "mae": 0.735200969513367,
            "precision": 0.20320855614973263,
            "recall": 0.17040358744394618
        },
        "train": {
            "accuracy": 0.2535675082327113,
            "auc_prc": 0.40748583810954614,
            "auditor_fn_violation": 0.007288434445145513,
            "auditor_fp_violation": 0.007316149733202954,
            "ave_precision_score": 0.4025256135500004,
            "fpr": 0.29088913282107576,
            "logloss": 16.30781620922259,
            "mae": 0.7495642400720588,
            "precision": 0.25977653631284914,
            "recall": 0.1830708661417323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7865937767306711,
            "auditor_fn_violation": 0.0061855872866021615,
            "auditor_fp_violation": 0.008190742413974852,
            "ave_precision_score": 0.7870844637497143,
            "fpr": 0.16776315789473684,
            "logloss": 0.6738348558495715,
            "mae": 0.31331555545559814,
            "precision": 0.6933867735470942,
            "recall": 0.7757847533632287
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8481073897038824,
            "auditor_fn_violation": 0.0004386457730105378,
            "auditor_fp_violation": 0.010263310571373314,
            "ave_precision_score": 0.8483890301562452,
            "fpr": 0.132821075740944,
            "logloss": 0.5657872537230685,
            "mae": 0.29690590851329896,
            "precision": 0.7664092664092664,
            "recall": 0.781496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7718892130166952,
            "auditor_fn_violation": 0.0037664227834159434,
            "auditor_fp_violation": 0.01735562081168587,
            "ave_precision_score": 0.7120325027629009,
            "fpr": 0.18530701754385964,
            "logloss": 3.223674985098837,
            "mae": 0.338197475358468,
            "precision": 0.6893382352941176,
            "recall": 0.8408071748878924
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8192438635391637,
            "auditor_fn_violation": 0.0048337467695791616,
            "auditor_fp_violation": 0.018156907714642925,
            "ave_precision_score": 0.7791948613697962,
            "fpr": 0.14709110867178923,
            "logloss": 2.366807598146106,
            "mae": 0.316630746262469,
            "precision": 0.7550274223034735,
            "recall": 0.812992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7681789084966392,
            "auditor_fn_violation": 0.010006097081268192,
            "auditor_fp_violation": 0.01383084858067917,
            "ave_precision_score": 0.6987555200422279,
            "fpr": 0.19736842105263158,
            "logloss": 3.7065510690228236,
            "mae": 0.3389152433904983,
            "precision": 0.6721311475409836,
            "recall": 0.827354260089686
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8120839787605039,
            "auditor_fn_violation": 0.0073597413934674205,
            "auditor_fp_violation": 0.017653003135103634,
            "ave_precision_score": 0.7632322059619385,
            "fpr": 0.15587266739846323,
            "logloss": 2.8351629328843897,
            "mae": 0.3132732501647074,
            "precision": 0.7441441441441441,
            "recall": 0.812992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7391479367656333,
            "auditor_fn_violation": 0.012302336558886002,
            "auditor_fp_violation": 0.015289699570815456,
            "ave_precision_score": 0.6779511676847346,
            "fpr": 0.16228070175438597,
            "logloss": 3.4931649076426408,
            "mae": 0.40789154420296353,
            "precision": 0.6696428571428571,
            "recall": 0.672645739910314
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7740480178676291,
            "auditor_fn_violation": 0.014745412586324629,
            "auditor_fp_violation": 0.020899782912459516,
            "ave_precision_score": 0.7330577921366088,
            "fpr": 0.12733260153677278,
            "logloss": 2.5986080446049136,
            "mae": 0.38341854059604596,
            "precision": 0.7363636363636363,
            "recall": 0.6377952755905512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6894272196486422,
            "auditor_fn_violation": 0.015028813625993238,
            "auditor_fp_violation": 0.009750771779233496,
            "ave_precision_score": 0.6910918800754934,
            "fpr": 0.13815789473684212,
            "logloss": 0.9159585957913827,
            "mae": 0.34250307930293883,
            "precision": 0.697841726618705,
            "recall": 0.6524663677130045
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7562024938944034,
            "auditor_fn_violation": 0.006421946982203513,
            "auditor_fp_violation": 0.016909403404215918,
            "ave_precision_score": 0.7565449626516885,
            "fpr": 0.11525795828759605,
            "logloss": 0.8527073061990342,
            "mae": 0.33645990026103495,
            "precision": 0.7661469933184856,
            "recall": 0.6771653543307087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.564828934757865,
            "auditor_fn_violation": 0.009509479977971849,
            "auditor_fp_violation": 0.01344495896393345,
            "ave_precision_score": 0.5665648384161366,
            "fpr": 0.17763157894736842,
            "logloss": 1.2700912154883441,
            "mae": 0.44637499431480326,
            "precision": 0.5909090909090909,
            "recall": 0.5246636771300448
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6555027705784164,
            "auditor_fn_violation": 0.006439233515130035,
            "auditor_fp_violation": 0.012801900128836146,
            "ave_precision_score": 0.6570021349871686,
            "fpr": 0.15587266739846323,
            "logloss": 1.315343319269347,
            "mae": 0.43145165227024274,
            "precision": 0.6682242990654206,
            "recall": 0.562992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5586391238211671,
            "auditor_fn_violation": 0.01196552198882858,
            "auditor_fp_violation": 0.007920149085159249,
            "ave_precision_score": 0.5744828877510053,
            "fpr": 0.09320175438596491,
            "logloss": 8.029800497322967,
            "mae": 0.4982931909438329,
            "precision": 0.6064814814814815,
            "recall": 0.2937219730941704
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6445158047148943,
            "auditor_fn_violation": 0.017794324831240212,
            "auditor_fp_violation": 0.010854377024130226,
            "ave_precision_score": 0.6577360834011765,
            "fpr": 0.0801317233809001,
            "logloss": 8.187126760483808,
            "mae": 0.5120993607373894,
            "precision": 0.6853448275862069,
            "recall": 0.31299212598425197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7908225629050395,
            "auditor_fn_violation": 0.002842026591141533,
            "auditor_fp_violation": 0.0037836006324824937,
            "ave_precision_score": 0.7919325090923018,
            "fpr": 0.025219298245614034,
            "logloss": 0.7401110470438562,
            "mae": 0.41787861674716525,
            "precision": 0.8878048780487805,
            "recall": 0.4080717488789238
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.857757443829285,
            "auditor_fn_violation": 0.009421160444955372,
            "auditor_fp_violation": 0.005905216910492929,
            "ave_precision_score": 0.8575576324818538,
            "fpr": 0.021953896816684963,
            "logloss": 0.692131289905499,
            "mae": 0.4288080818226988,
            "precision": 0.9090909090909091,
            "recall": 0.3937007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8119961426142944,
            "auditor_fn_violation": 0.0068395484226260765,
            "auditor_fp_violation": 0.004983623221142987,
            "ave_precision_score": 0.8114426012534997,
            "fpr": 0.023026315789473683,
            "logloss": 0.6481882147873302,
            "mae": 0.41901487484470157,
            "precision": 0.8985507246376812,
            "recall": 0.4170403587443946
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.8722437222674212,
            "auditor_fn_violation": 0.009779856003180718,
            "auditor_fp_violation": 0.003538227290927267,
            "ave_precision_score": 0.8712587572763352,
            "fpr": 0.021953896816684963,
            "logloss": 0.6021129976117526,
            "mae": 0.42700888315128666,
            "precision": 0.9078341013824884,
            "recall": 0.38779527559055116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7419469681713012,
            "auditor_fn_violation": 0.00990284005979074,
            "auditor_fp_violation": 0.006183645809803481,
            "ave_precision_score": 0.7432247667461289,
            "fpr": 0.18421052631578946,
            "logloss": 0.7272317809403098,
            "mae": 0.3411224856817602,
            "precision": 0.6673267326732674,
            "recall": 0.7556053811659192
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7904651002728076,
            "auditor_fn_violation": 0.0034032861699093303,
            "auditor_fp_violation": 0.01368713790370247,
            "ave_precision_score": 0.7919470973866747,
            "fpr": 0.13830954994511527,
            "logloss": 0.6534197422054736,
            "mae": 0.3239749396121069,
            "precision": 0.7534246575342466,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.768338445698216,
            "auditor_fn_violation": 0.009922508063881683,
            "auditor_fp_violation": 0.011797869136360217,
            "ave_precision_score": 0.6989149470807601,
            "fpr": 0.19078947368421054,
            "logloss": 3.692396916751071,
            "mae": 0.33641196783170463,
            "precision": 0.6777777777777778,
            "recall": 0.820627802690583
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8121298051959998,
            "auditor_fn_violation": 0.007009689101705321,
            "auditor_fp_violation": 0.015950622798822242,
            "ave_precision_score": 0.7632779538138146,
            "fpr": 0.14709110867178923,
            "logloss": 2.8255765494878227,
            "mae": 0.3125795205034271,
            "precision": 0.7527675276752768,
            "recall": 0.8031496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7801853529531102,
            "auditor_fn_violation": 0.010758398237746838,
            "auditor_fp_violation": 0.012670826744974023,
            "ave_precision_score": 0.7807446054045454,
            "fpr": 0.13486842105263158,
            "logloss": 0.8277895463743349,
            "mae": 0.30905405749397186,
            "precision": 0.7260579064587973,
            "recall": 0.7309417040358744
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8221259539422408,
            "auditor_fn_violation": 0.0034400200523781953,
            "auditor_fp_violation": 0.010241520103068915,
            "ave_precision_score": 0.8223953367481875,
            "fpr": 0.1119648737650933,
            "logloss": 1.0360346024134592,
            "mae": 0.32327508579771436,
            "precision": 0.7723214285714286,
            "recall": 0.6811023622047244
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7648449597136304,
            "auditor_fn_violation": 0.012806329163716467,
            "auditor_fp_violation": 0.01610383254273022,
            "ave_precision_score": 0.695244227722541,
            "fpr": 0.16447368421052633,
            "logloss": 3.7083941547068564,
            "mae": 0.3700290697120261,
            "precision": 0.6945010183299389,
            "recall": 0.7645739910313901
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8065359621501489,
            "auditor_fn_violation": 0.0020700623179512054,
            "auditor_fp_violation": 0.021417306534689075,
            "ave_precision_score": 0.7578984743909558,
            "fpr": 0.12623490669593854,
            "logloss": 2.823228806823758,
            "mae": 0.35171055373389165,
            "precision": 0.7604166666666666,
            "recall": 0.718503937007874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 20404,
        "test": {
            "accuracy": 0.2598684210526316,
            "auc_prc": 0.36721307044772045,
            "auditor_fn_violation": 0.0049415860278499,
            "auditor_fp_violation": 0.013320250734131478,
            "ave_precision_score": 0.33891335894502744,
            "fpr": 0.34539473684210525,
            "logloss": 20.310059619415114,
            "mae": 0.7410769751931068,
            "precision": 0.2144638403990025,
            "recall": 0.19282511210762332
        },
        "train": {
            "accuracy": 0.2623490669593853,
            "auc_prc": 0.42805658295359944,
            "auditor_fn_violation": 0.007921553713579438,
            "auditor_fp_violation": 0.006071369231313998,
            "ave_precision_score": 0.40079066932630625,
            "fpr": 0.283205268935236,
            "logloss": 20.114385495476323,
            "mae": 0.7418461649103129,
            "precision": 0.26704545454545453,
            "recall": 0.18503937007874016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7771363010371826,
            "auditor_fn_violation": 0.001841416883014713,
            "auditor_fp_violation": 0.0127649461636925,
            "ave_precision_score": 0.7777845599652355,
            "fpr": 0.21162280701754385,
            "logloss": 0.7412166493920178,
            "mae": 0.3246676768536226,
            "precision": 0.6565836298932385,
            "recall": 0.827354260089686
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8304540049429368,
            "auditor_fn_violation": 0.0021975504982843126,
            "auditor_fp_violation": 0.010636472341086198,
            "ave_precision_score": 0.8307874274109924,
            "fpr": 0.16575192096597147,
            "logloss": 0.6143731169458956,
            "mae": 0.3004717397650256,
            "precision": 0.736013986013986,
            "recall": 0.8287401574803149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8132280594632982,
            "auditor_fn_violation": 0.0031222956494375053,
            "auditor_fp_violation": 0.004757736616218659,
            "ave_precision_score": 0.8121640928629836,
            "fpr": 0.027412280701754384,
            "logloss": 0.6317837315955673,
            "mae": 0.4107696650135082,
            "precision": 0.8868778280542986,
            "recall": 0.43946188340807174
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8718319633519936,
            "auditor_fn_violation": 0.011106597405291406,
            "auditor_fp_violation": 0.002366989619565663,
            "ave_precision_score": 0.870465549284628,
            "fpr": 0.025246981339187707,
            "logloss": 0.5897391606588945,
            "mae": 0.41787442719467904,
            "precision": 0.9037656903765691,
            "recall": 0.4251968503937008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7775561300034276,
            "auditor_fn_violation": 0.013290653764455988,
            "auditor_fp_violation": 0.004729500790603122,
            "ave_precision_score": 0.7781444073250052,
            "fpr": 0.18530701754385964,
            "logloss": 0.8649007542548344,
            "mae": 0.31963962166791876,
            "precision": 0.6762452107279694,
            "recall": 0.7914798206278026
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.820383836252083,
            "auditor_fn_violation": 0.007482907940568899,
            "auditor_fp_violation": 0.007370625903963958,
            "ave_precision_score": 0.8206504077916388,
            "fpr": 0.145993413830955,
            "logloss": 1.031766117918562,
            "mae": 0.32238149509978375,
            "precision": 0.740234375,
            "recall": 0.7460629921259843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7801829713696089,
            "auditor_fn_violation": 0.010758398237746838,
            "auditor_fp_violation": 0.012670826744974023,
            "ave_precision_score": 0.780742228119177,
            "fpr": 0.13486842105263158,
            "logloss": 0.8278038236121166,
            "mae": 0.3090512448621931,
            "precision": 0.7260579064587973,
            "recall": 0.7309417040358744
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8221118101697003,
            "auditor_fn_violation": 0.0034400200523781953,
            "auditor_fp_violation": 0.010241520103068915,
            "ave_precision_score": 0.8223812098930482,
            "fpr": 0.1119648737650933,
            "logloss": 1.0360357259829511,
            "mae": 0.32326949655892157,
            "precision": 0.7723214285714286,
            "recall": 0.6811023622047244
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8059346075463573,
            "auditor_fn_violation": 0.004317126897962416,
            "auditor_fp_violation": 0.003440064754160079,
            "ave_precision_score": 0.8049495805261535,
            "fpr": 0.03508771929824561,
            "logloss": 0.6347386308224486,
            "mae": 0.41208742870734716,
            "precision": 0.8590308370044053,
            "recall": 0.437219730941704
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8694771855099122,
            "auditor_fn_violation": 0.012921683362576387,
            "auditor_fp_violation": 0.0029389894125562126,
            "ave_precision_score": 0.8682180537367282,
            "fpr": 0.02854006586169045,
            "logloss": 0.5892413660636813,
            "mae": 0.4173979048428064,
            "precision": 0.8943089430894309,
            "recall": 0.4330708661417323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5455212142364967,
            "auditor_fn_violation": 0.00745909055149084,
            "auditor_fp_violation": 0.01624501167080793,
            "ave_precision_score": 0.5472909832849027,
            "fpr": 0.17214912280701755,
            "logloss": 1.3888620477090337,
            "mae": 0.4489438716388234,
            "precision": 0.5698630136986301,
            "recall": 0.4663677130044843
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.659487213441474,
            "auditor_fn_violation": 0.00606757305720978,
            "auditor_fp_violation": 0.013256776154690538,
            "ave_precision_score": 0.6609078063244622,
            "fpr": 0.13611416026344675,
            "logloss": 1.2676871992507062,
            "mae": 0.42787776392389354,
            "precision": 0.6787564766839378,
            "recall": 0.515748031496063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.55072609715121,
            "auditor_fn_violation": 0.006453563842341295,
            "auditor_fp_violation": 0.01805681048113847,
            "ave_precision_score": 0.5517429089181058,
            "fpr": 0.17214912280701755,
            "logloss": 1.3278742491316138,
            "mae": 0.4552700803305207,
            "precision": 0.5589887640449438,
            "recall": 0.4461883408071749
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6518660392852405,
            "auditor_fn_violation": 0.007109086666032828,
            "auditor_fp_violation": 0.011153995963315753,
            "ave_precision_score": 0.6525241997682587,
            "fpr": 0.14270032930845225,
            "logloss": 1.2807323045232615,
            "mae": 0.43827233038991215,
            "precision": 0.6649484536082474,
            "recall": 0.5078740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7704881420251642,
            "auditor_fn_violation": 0.0033484776964833643,
            "auditor_fp_violation": 0.0027859347940667203,
            "ave_precision_score": 0.7710505593294155,
            "fpr": 0.18640350877192982,
            "logloss": 0.9157841909206126,
            "mae": 0.3096382399446491,
            "precision": 0.6768060836501901,
            "recall": 0.7982062780269058
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8250822128789601,
            "auditor_fn_violation": 0.0037814290776770404,
            "auditor_fp_violation": 0.005845293122655829,
            "ave_precision_score": 0.8253239933765966,
            "fpr": 0.145993413830955,
            "logloss": 0.7176179112019636,
            "mae": 0.28831776602781667,
            "precision": 0.7532467532467533,
            "recall": 0.7992125984251969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7745307174631635,
            "auditor_fn_violation": 0.010345370151836994,
            "auditor_fp_violation": 0.011186092914690164,
            "ave_precision_score": 0.7755565194362988,
            "fpr": 0.13596491228070176,
            "logloss": 0.8317778862594459,
            "mae": 0.30987881644955056,
            "precision": 0.7232142857142857,
            "recall": 0.726457399103139
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8198736104900985,
            "auditor_fn_violation": 0.0072949168949929645,
            "auditor_fp_violation": 0.011311976858522668,
            "ave_precision_score": 0.8201497167728646,
            "fpr": 0.11306256860592755,
            "logloss": 1.0378056068987187,
            "mae": 0.323410919326115,
            "precision": 0.7721238938053098,
            "recall": 0.687007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7721597495848362,
            "auditor_fn_violation": 0.005128432066713871,
            "auditor_fp_violation": 0.01477204276786387,
            "ave_precision_score": 0.7027402929481543,
            "fpr": 0.16557017543859648,
            "logloss": 3.680981663534598,
            "mae": 0.32398759378293907,
            "precision": 0.7045009784735812,
            "recall": 0.8071748878923767
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8197234306875333,
            "auditor_fn_violation": 0.006849788672134974,
            "auditor_fp_violation": 0.01714637474702628,
            "ave_precision_score": 0.7708704864256478,
            "fpr": 0.12403951701427003,
            "logloss": 2.7759043163872152,
            "mae": 0.30216631512684106,
            "precision": 0.7784313725490196,
            "recall": 0.781496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7196069972290253,
            "auditor_fn_violation": 0.008887479348595705,
            "auditor_fp_violation": 0.008621338754611853,
            "ave_precision_score": 0.7202288946072309,
            "fpr": 0.08991228070175439,
            "logloss": 0.6898904870663408,
            "mae": 0.4279516046903346,
            "precision": 0.7380191693290735,
            "recall": 0.5179372197309418
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7765800902451838,
            "auditor_fn_violation": 0.01032654260698204,
            "auditor_fp_violation": 0.008206835125145386,
            "ave_precision_score": 0.7770716023833438,
            "fpr": 0.08232711306256861,
            "logloss": 0.6281232652238472,
            "mae": 0.42492415949590984,
            "precision": 0.7781065088757396,
            "recall": 0.5177165354330708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 20404,
        "test": {
            "accuracy": 0.3881578947368421,
            "auc_prc": 0.5660317975754537,
            "auditor_fn_violation": 0.01341112028951302,
            "auditor_fp_violation": 0.003767129734206789,
            "ave_precision_score": 0.44130449724318266,
            "fpr": 0.40021929824561403,
            "logloss": 15.47081743153075,
            "mae": 0.6107274620881319,
            "precision": 0.40938511326860844,
            "recall": 0.5672645739910314
        },
        "train": {
            "accuracy": 0.4105378704720088,
            "auc_prc": 0.5981927458488314,
            "auditor_fn_violation": 0.004611182658150165,
            "auditor_fp_violation": 0.008372987445966451,
            "ave_precision_score": 0.49161283189429894,
            "fpr": 0.33150384193194293,
            "logloss": 14.720806399031208,
            "mae": 0.5910916404085437,
            "precision": 0.4747826086956522,
            "recall": 0.5374015748031497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8166091914271876,
            "auditor_fn_violation": 0.006714164896546319,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.816561300971979,
            "fpr": 0.025219298245614034,
            "logloss": 0.5840298269207012,
            "mae": 0.4084640195612783,
            "precision": 0.8944954128440367,
            "recall": 0.437219730941704
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.8701387763840621,
            "auditor_fn_violation": 0.013561285080857773,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8698274049792867,
            "fpr": 0.024149286498353458,
            "logloss": 0.5876882052822235,
            "mae": 0.4188844939920553,
            "precision": 0.9043478260869565,
            "recall": 0.4094488188976378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.5997265630634854,
            "auditor_fn_violation": 0.009809417040358736,
            "auditor_fp_violation": 0.00628953015586176,
            "ave_precision_score": 0.6013877879196444,
            "fpr": 0.12609649122807018,
            "logloss": 1.2374748571125596,
            "mae": 0.4373814421731539,
            "precision": 0.6229508196721312,
            "recall": 0.4260089686098655
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6795584720783799,
            "auditor_fn_violation": 0.0078459251320259,
            "auditor_fp_violation": 0.006104054933770599,
            "ave_precision_score": 0.6808828358053272,
            "fpr": 0.09220636663007684,
            "logloss": 1.2088760113001258,
            "mae": 0.4361341351532177,
            "precision": 0.731629392971246,
            "recall": 0.4507874015748031
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7022813735165065,
            "auditor_fn_violation": 0.007611517583195663,
            "auditor_fp_violation": 0.01885917852571343,
            "ave_precision_score": 0.7039493293327086,
            "fpr": 0.1787280701754386,
            "logloss": 0.8489645233876206,
            "mae": 0.34169260892323156,
            "precision": 0.6713709677419355,
            "recall": 0.7466367713004485
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7673068170850937,
            "auditor_fn_violation": 0.0063506400338816035,
            "auditor_fp_violation": 0.01931997396039038,
            "ave_precision_score": 0.7676865965790989,
            "fpr": 0.13830954994511527,
            "logloss": 0.7739808573274957,
            "mae": 0.32199640736611546,
            "precision": 0.7534246575342466,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5578633030390797,
            "auditor_fn_violation": 0.008617044292345225,
            "auditor_fp_violation": 0.015388524960469848,
            "ave_precision_score": 0.5598535480254911,
            "fpr": 0.17324561403508773,
            "logloss": 1.2867514901029633,
            "mae": 0.4461121971599233,
            "precision": 0.5764075067024129,
            "recall": 0.4820627802690583
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.655266477231929,
            "auditor_fn_violation": 0.0007649290819986797,
            "auditor_fp_violation": 0.014237347228388628,
            "ave_precision_score": 0.6567283131040758,
            "fpr": 0.13830954994511527,
            "logloss": 1.229485371553851,
            "mae": 0.429421688074887,
            "precision": 0.685,
            "recall": 0.5393700787401575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.777597923710023,
            "auditor_fn_violation": 0.012587522618204706,
            "auditor_fp_violation": 0.0029247609366764645,
            "ave_precision_score": 0.7781578402160729,
            "fpr": 0.18311403508771928,
            "logloss": 0.8666407974583108,
            "mae": 0.31849149021720413,
            "precision": 0.6769825918762089,
            "recall": 0.7847533632286996
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8198615122275471,
            "auditor_fn_violation": 0.007273308728834801,
            "auditor_fp_violation": 0.008136016103156084,
            "ave_precision_score": 0.8201297087796731,
            "fpr": 0.1437980241492865,
            "logloss": 1.0419455615537294,
            "mae": 0.3223855723033268,
            "precision": 0.7421259842519685,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.5615415090825064,
            "auditor_fn_violation": 0.012668653135079862,
            "auditor_fp_violation": 0.01691796551464499,
            "ave_precision_score": 0.5632889667255012,
            "fpr": 0.17434210526315788,
            "logloss": 1.313453506390209,
            "mae": 0.44737127265479515,
            "precision": 0.5902061855670103,
            "recall": 0.5134529147982063
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6535630004613069,
            "auditor_fn_violation": 0.00888743874084895,
            "auditor_fp_violation": 0.01222990033584559,
            "ave_precision_score": 0.6550691074454879,
            "fpr": 0.15367727771679474,
            "logloss": 1.339680973352618,
            "mae": 0.43206382083020084,
            "precision": 0.667458432304038,
            "recall": 0.5531496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.5914103054624508,
            "auditor_fn_violation": 0.016683384470143975,
            "auditor_fp_violation": 0.011609630298923274,
            "ave_precision_score": 0.6070865593875531,
            "fpr": 0.10307017543859649,
            "logloss": 8.022995875741168,
            "mae": 0.4836088653257895,
            "precision": 0.6479400749063671,
            "recall": 0.38789237668161436
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6776326238606649,
            "auditor_fn_violation": 0.015897127842554263,
            "auditor_fp_violation": 0.015106242152026656,
            "ave_precision_score": 0.6907640890613751,
            "fpr": 0.09330406147091108,
            "logloss": 8.169673259003755,
            "mae": 0.49139640530168555,
            "precision": 0.7108843537414966,
            "recall": 0.41141732283464566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.768338445698216,
            "auditor_fn_violation": 0.009922508063881683,
            "auditor_fp_violation": 0.011797869136360217,
            "ave_precision_score": 0.6989149470807601,
            "fpr": 0.19078947368421054,
            "logloss": 3.6923967077809965,
            "mae": 0.3364123289385022,
            "precision": 0.6777777777777778,
            "recall": 0.820627802690583
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8121298051959998,
            "auditor_fn_violation": 0.007009689101705321,
            "auditor_fp_violation": 0.015950622798822242,
            "ave_precision_score": 0.7632779538138146,
            "fpr": 0.14709110867178923,
            "logloss": 2.825575238764882,
            "mae": 0.3125798159997612,
            "precision": 0.7527675276752768,
            "recall": 0.8031496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.56172525737516,
            "auditor_fn_violation": 0.012668653135079862,
            "auditor_fp_violation": 0.01415556057525789,
            "ave_precision_score": 0.5634722816352711,
            "fpr": 0.17543859649122806,
            "logloss": 1.3128634496103542,
            "mae": 0.4474022811089253,
            "precision": 0.5886889460154242,
            "recall": 0.5134529147982063
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6536824360319149,
            "auditor_fn_violation": 0.00830185743796296,
            "auditor_fp_violation": 0.01209098610040503,
            "ave_precision_score": 0.6551882225266882,
            "fpr": 0.1525795828759605,
            "logloss": 1.3391744252491686,
            "mae": 0.43213079536651317,
            "precision": 0.669833729216152,
            "recall": 0.5551181102362205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5349536801717569,
            "auditor_fn_violation": 0.00641176933364802,
            "auditor_fp_violation": 0.015099107747910545,
            "ave_precision_score": 0.536738727163249,
            "fpr": 0.17434210526315788,
            "logloss": 1.4272844870175982,
            "mae": 0.4564989460081243,
            "precision": 0.5595567867036011,
            "recall": 0.452914798206278
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6454884370703515,
            "auditor_fn_violation": 0.002783131801170299,
            "auditor_fp_violation": 0.014340851952834535,
            "ave_precision_score": 0.6469315700651839,
            "fpr": 0.14050493962678376,
            "logloss": 1.3177954282488322,
            "mae": 0.43741730877914886,
            "precision": 0.6701030927835051,
            "recall": 0.5118110236220472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7609084263410855,
            "auditor_fn_violation": 0.006055286759499647,
            "auditor_fp_violation": 0.01966154657028838,
            "ave_precision_score": 0.7507674440448796,
            "fpr": 0.21600877192982457,
            "logloss": 1.050967643273459,
            "mae": 0.37233467813450516,
            "precision": 0.6638225255972696,
            "recall": 0.8721973094170403
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8046317588874252,
            "auditor_fn_violation": 0.0017502614588105155,
            "auditor_fp_violation": 0.019295459683547934,
            "ave_precision_score": 0.7965700964078747,
            "fpr": 0.18111964873765093,
            "logloss": 0.8674503931832522,
            "mae": 0.34571495271082375,
            "precision": 0.7317073170731707,
            "recall": 0.8858267716535433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7720315731063608,
            "auditor_fn_violation": 0.001642278341593898,
            "auditor_fp_violation": 0.0026259317822453134,
            "ave_precision_score": 0.7727772138697867,
            "fpr": 0.18421052631578946,
            "logloss": 0.8619537049658571,
            "mae": 0.30898462296432916,
            "precision": 0.681214421252372,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8258249963251428,
            "auditor_fn_violation": 0.002580015039283648,
            "auditor_fp_violation": 0.005300531415045781,
            "ave_precision_score": 0.8262635021751348,
            "fpr": 0.14709110867178923,
            "logloss": 0.7080823076758889,
            "mae": 0.2883216973860456,
            "precision": 0.7518518518518519,
            "recall": 0.7992125984251969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5403633986636683,
            "auditor_fn_violation": 0.00920462591456219,
            "auditor_fp_violation": 0.01494145772155712,
            "ave_precision_score": 0.5421466318854334,
            "fpr": 0.17324561403508773,
            "logloss": 1.350669616560679,
            "mae": 0.4518156601592509,
            "precision": 0.5683060109289617,
            "recall": 0.4663677130044843
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6518385878197348,
            "auditor_fn_violation": 0.006542952712689181,
            "auditor_fp_violation": 0.014340851952834535,
            "ave_precision_score": 0.6532732029087315,
            "fpr": 0.14050493962678376,
            "logloss": 1.2621096157407736,
            "mae": 0.43215998225902197,
            "precision": 0.673469387755102,
            "recall": 0.5196850393700787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7799292750647384,
            "auditor_fn_violation": 0.011655750924396193,
            "auditor_fp_violation": 0.011186092914690164,
            "ave_precision_score": 0.7804901914268326,
            "fpr": 0.13596491228070176,
            "logloss": 0.8309799090104022,
            "mae": 0.3088093829439651,
            "precision": 0.7250554323725056,
            "recall": 0.7331838565022422
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8206771219758229,
            "auditor_fn_violation": 0.004740831655099098,
            "auditor_fp_violation": 0.010241520103068915,
            "ave_precision_score": 0.8209516013564415,
            "fpr": 0.1119648737650933,
            "logloss": 1.039325576812031,
            "mae": 0.32296459953166373,
            "precision": 0.7728285077951003,
            "recall": 0.6830708661417323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.5652558479904211,
            "auditor_fn_violation": 0.011092754307292908,
            "auditor_fp_violation": 0.011129621263459089,
            "ave_precision_score": 0.5669935803613793,
            "fpr": 0.1787280701754386,
            "logloss": 1.2781170377089097,
            "mae": 0.4456766151160523,
            "precision": 0.5914786967418546,
            "recall": 0.5291479820627802
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6555660045035209,
            "auditor_fn_violation": 0.005138421912409135,
            "auditor_fp_violation": 0.01030689150798213,
            "ave_precision_score": 0.6570663968019843,
            "fpr": 0.15806805708013172,
            "logloss": 1.3236611270217784,
            "mae": 0.4309549780456732,
            "precision": 0.6651162790697674,
            "recall": 0.562992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.768486532496693,
            "auditor_fn_violation": 0.004963712532452214,
            "auditor_fp_violation": 0.0034494766960319347,
            "ave_precision_score": 0.7632377549843202,
            "fpr": 0.15679824561403508,
            "logloss": 1.1796122459978453,
            "mae": 0.3044502314570571,
            "precision": 0.700836820083682,
            "recall": 0.7511210762331838
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7857399812074286,
            "auditor_fn_violation": 0.0049785214828388,
            "auditor_fp_violation": 0.005638283673764009,
            "ave_precision_score": 0.7826451919508339,
            "fpr": 0.1207464324917673,
            "logloss": 1.2559680596561829,
            "mae": 0.30968478123261317,
            "precision": 0.7659574468085106,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8136853119958818,
            "auditor_fn_violation": 0.004934210526315804,
            "auditor_fp_violation": 0.0027953467359385603,
            "ave_precision_score": 0.8126651164058765,
            "fpr": 0.025219298245614034,
            "logloss": 0.6369840984644037,
            "mae": 0.41316086963761234,
            "precision": 0.8935185185185185,
            "recall": 0.4327354260089686
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.8720209271194037,
            "auditor_fn_violation": 0.012718566600689747,
            "auditor_fp_violation": 0.0014082090141719756,
            "ave_precision_score": 0.8707734978369684,
            "fpr": 0.024149286498353458,
            "logloss": 0.5933935230072053,
            "mae": 0.420420874738278,
            "precision": 0.9051724137931034,
            "recall": 0.41338582677165353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 20404,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5503646312005708,
            "auditor_fn_violation": 0.008149929195185287,
            "auditor_fp_violation": 0.01866858670280853,
            "ave_precision_score": 0.5521385857255482,
            "fpr": 0.16885964912280702,
            "logloss": 1.3820786047197549,
            "mae": 0.44724789008782545,
            "precision": 0.5734072022160664,
            "recall": 0.4641255605381166
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6636284133515759,
            "auditor_fn_violation": 0.003344944121282327,
            "auditor_fp_violation": 0.013256776154690538,
            "ave_precision_score": 0.665118274780656,
            "fpr": 0.13611416026344675,
            "logloss": 1.264870473451235,
            "mae": 0.42655703149137464,
            "precision": 0.6770833333333334,
            "recall": 0.5118110236220472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7044286819138157,
            "auditor_fn_violation": 0.009907757060813472,
            "auditor_fp_violation": 0.018696822528424067,
            "ave_precision_score": 0.7052012446250826,
            "fpr": 0.17105263157894737,
            "logloss": 0.8397512140492694,
            "mae": 0.35145252127314736,
            "precision": 0.680327868852459,
            "recall": 0.7443946188340808
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.758772788896958,
            "auditor_fn_violation": 0.0017891561578951929,
            "auditor_fp_violation": 0.008585444511934373,
            "ave_precision_score": 0.7597930918638524,
            "fpr": 0.14709110867178923,
            "logloss": 0.7850622821407388,
            "mae": 0.3279450241461985,
            "precision": 0.7462121212121212,
            "recall": 0.7755905511811023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7704803490560255,
            "auditor_fn_violation": 0.0033484776964833643,
            "auditor_fp_violation": 0.0027859347940667203,
            "ave_precision_score": 0.771042772295886,
            "fpr": 0.18640350877192982,
            "logloss": 0.9158238529895214,
            "mae": 0.30963746696771094,
            "precision": 0.6768060836501901,
            "recall": 0.7982062780269058
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8250864016366039,
            "auditor_fn_violation": 0.0037814290776770404,
            "auditor_fp_violation": 0.005845293122655829,
            "ave_precision_score": 0.8253281803171341,
            "fpr": 0.145993413830955,
            "logloss": 0.717651801167812,
            "mae": 0.2883161189589407,
            "precision": 0.7532467532467533,
            "recall": 0.7992125984251969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8003788182311313,
            "auditor_fn_violation": 0.006620741877114309,
            "auditor_fp_violation": 0.014404977034861835,
            "ave_precision_score": 0.7902935553527536,
            "fpr": 0.10855263157894737,
            "logloss": 0.5729105259948877,
            "mae": 0.4073169577474657,
            "precision": 0.7608695652173914,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8610404305628733,
            "auditor_fn_violation": 0.004235200566998291,
            "auditor_fp_violation": 0.010680053277695004,
            "ave_precision_score": 0.8508503187415344,
            "fpr": 0.07574094401756312,
            "logloss": 0.5579474097294655,
            "mae": 0.40753703642100847,
            "precision": 0.8449438202247191,
            "recall": 0.7401574803149606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7391755087481982,
            "auditor_fn_violation": 0.012302336558886002,
            "auditor_fp_violation": 0.015289699570815456,
            "ave_precision_score": 0.6779745924247482,
            "fpr": 0.16228070175438597,
            "logloss": 3.4931878051931746,
            "mae": 0.4078962353891448,
            "precision": 0.6696428571428571,
            "recall": 0.672645739910314
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7741221571725105,
            "auditor_fn_violation": 0.014745412586324629,
            "auditor_fp_violation": 0.020899782912459516,
            "ave_precision_score": 0.733138326293197,
            "fpr": 0.12733260153677278,
            "logloss": 2.598621798038599,
            "mae": 0.38341790378813423,
            "precision": 0.7363636363636363,
            "recall": 0.6377952755905512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7683293538927618,
            "auditor_fn_violation": 0.010006097081268192,
            "auditor_fp_violation": 0.011642572095474738,
            "ave_precision_score": 0.6989058822601492,
            "fpr": 0.19517543859649122,
            "logloss": 3.706116785894893,
            "mae": 0.33848213759279533,
            "precision": 0.6745886654478976,
            "recall": 0.827354260089686
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8122059764978105,
            "auditor_fn_violation": 0.004933144333906669,
            "auditor_fp_violation": 0.016435460718595172,
            "ave_precision_score": 0.7633541220395117,
            "fpr": 0.15367727771679474,
            "logloss": 2.8346418380641767,
            "mae": 0.3128129630633267,
            "precision": 0.7459165154264973,
            "recall": 0.8090551181102362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8099708635872623,
            "auditor_fn_violation": 0.0024535835103453797,
            "auditor_fp_violation": 0.014404977034861835,
            "ave_precision_score": 0.8100329394708863,
            "fpr": 0.10855263157894737,
            "logloss": 0.6134457459540271,
            "mae": 0.4007498772706921,
            "precision": 0.7597087378640777,
            "recall": 0.7017937219730942
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8726338839640816,
            "auditor_fn_violation": 0.004049370338038161,
            "auditor_fp_violation": 0.010680053277695004,
            "ave_precision_score": 0.8713407792185869,
            "fpr": 0.07574094401756312,
            "logloss": 0.5494059624131913,
            "mae": 0.39771307926981797,
            "precision": 0.8445945945945946,
            "recall": 0.7381889763779528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7684968418147691,
            "auditor_fn_violation": 0.010030682086381873,
            "auditor_fp_violation": 0.010416666666666664,
            "ave_precision_score": 0.6990732684825868,
            "fpr": 0.19188596491228072,
            "logloss": 3.6964064015909948,
            "mae": 0.3382922165384802,
            "precision": 0.6777163904235728,
            "recall": 0.8251121076233184
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8119833367569305,
            "auditor_fn_violation": 0.007009689101705321,
            "auditor_fp_violation": 0.016293822674616557,
            "ave_precision_score": 0.7631315764842987,
            "fpr": 0.1525795828759605,
            "logloss": 2.828030623176291,
            "mae": 0.31386995769558734,
            "precision": 0.7458866544789763,
            "recall": 0.8031496062992126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7631837450694876,
            "auditor_fn_violation": 0.010795275745417365,
            "auditor_fp_violation": 0.016543840825239072,
            "ave_precision_score": 0.7018362869920978,
            "fpr": 0.15679824561403508,
            "logloss": 3.494613940619364,
            "mae": 0.4081542086052267,
            "precision": 0.675,
            "recall": 0.6659192825112108
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.8074032558941302,
            "auditor_fn_violation": 0.015281295107046853,
            "auditor_fp_violation": 0.02074180201725261,
            "ave_precision_score": 0.7662612303038205,
            "fpr": 0.12184412733260154,
            "logloss": 2.5992336261160065,
            "mae": 0.3836860405495871,
            "precision": 0.7424593967517401,
            "recall": 0.6299212598425197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7256222741900029,
            "auditor_fn_violation": 0.007124734481944778,
            "auditor_fp_violation": 0.016922671485580913,
            "ave_precision_score": 0.7180126014254871,
            "fpr": 0.21600877192982457,
            "logloss": 1.3849028410078814,
            "mae": 0.3451182861743993,
            "precision": 0.64568345323741,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7725735404246808,
            "auditor_fn_violation": 0.004356206297483945,
            "auditor_fp_violation": 0.010829862747287774,
            "ave_precision_score": 0.7668999608980116,
            "fpr": 0.16794731064763996,
            "logloss": 1.2153152810287666,
            "mae": 0.31305760144267303,
            "precision": 0.7292035398230089,
            "recall": 0.8110236220472441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7630471092278048,
            "auditor_fn_violation": 0.0037565887813704696,
            "auditor_fp_violation": 0.00669424365635118,
            "ave_precision_score": 0.7568115761110757,
            "fpr": 0.1875,
            "logloss": 1.1931171828313831,
            "mae": 0.3161919533812212,
            "precision": 0.6742857142857143,
            "recall": 0.7937219730941704
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8084920604399543,
            "auditor_fn_violation": 0.001694080226799313,
            "auditor_fp_violation": 0.006161254913069655,
            "ave_precision_score": 0.8044758786548616,
            "fpr": 0.1437980241492865,
            "logloss": 0.9930251815150529,
            "mae": 0.29360173323994726,
            "precision": 0.7560521415270018,
            "recall": 0.7992125984251969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.5926653979212011,
            "auditor_fn_violation": 0.0181781527810558,
            "auditor_fp_violation": 0.009411941871847004,
            "ave_precision_score": 0.6083403309485813,
            "fpr": 0.11074561403508772,
            "logloss": 8.031970827474455,
            "mae": 0.48783099483389697,
            "precision": 0.6353790613718412,
            "recall": 0.39461883408071746
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6763039294569262,
            "auditor_fn_violation": 0.013829226341218885,
            "auditor_fp_violation": 0.01533231826068482,
            "ave_precision_score": 0.6894342365862436,
            "fpr": 0.10428100987925357,
            "logloss": 8.176647154551121,
            "mae": 0.494827421102085,
            "precision": 0.6964856230031949,
            "recall": 0.42913385826771655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6918763137697967,
            "auditor_fn_violation": 0.01100178978837228,
            "auditor_fp_violation": 0.015506174233867938,
            "ave_precision_score": 0.6924929014120054,
            "fpr": 0.18092105263157895,
            "logloss": 0.9261230568530264,
            "mae": 0.35655041638018337,
            "precision": 0.6673387096774194,
            "recall": 0.742152466367713
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7493399398550372,
            "auditor_fn_violation": 0.006285815535407143,
            "auditor_fp_violation": 0.012216281293155348,
            "ave_precision_score": 0.7491337797115333,
            "fpr": 0.15697036223929747,
            "logloss": 0.8845774693259034,
            "mae": 0.33085179947210325,
            "precision": 0.7361623616236163,
            "recall": 0.7854330708661418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.5618909710720801,
            "auditor_fn_violation": 0.012668653135079862,
            "auditor_fp_violation": 0.01415556057525789,
            "ave_precision_score": 0.563637694983889,
            "fpr": 0.17543859649122806,
            "logloss": 1.3124280162506536,
            "mae": 0.4473600411228113,
            "precision": 0.5886889460154242,
            "recall": 0.5134529147982063
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6537280950193605,
            "auditor_fn_violation": 0.00830185743796296,
            "auditor_fp_violation": 0.01209098610040503,
            "ave_precision_score": 0.6552338382194534,
            "fpr": 0.1525795828759605,
            "logloss": 1.3388093260325842,
            "mae": 0.43208151048357296,
            "precision": 0.669833729216152,
            "recall": 0.5551181102362205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7110022774791236,
            "auditor_fn_violation": 0.007611517583195657,
            "auditor_fp_violation": 0.014564980046683234,
            "ave_precision_score": 0.712778926514906,
            "fpr": 0.18421052631578946,
            "logloss": 0.8378258095609711,
            "mae": 0.3445805052990756,
            "precision": 0.6737864077669903,
            "recall": 0.7780269058295964
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7674890325055593,
            "auditor_fn_violation": 0.0005726164031910951,
            "auditor_fp_violation": 0.003543674908003376,
            "ave_precision_score": 0.7692244478050316,
            "fpr": 0.15477497255762898,
            "logloss": 0.7612601426359022,
            "mae": 0.3202411632455321,
            "precision": 0.7408088235294118,
            "recall": 0.7933070866141733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5378194687357287,
            "auditor_fn_violation": 0.009121036897175673,
            "auditor_fp_violation": 0.016037948949627297,
            "ave_precision_score": 0.5395957792039838,
            "fpr": 0.17324561403508773,
            "logloss": 1.3855200564351813,
            "mae": 0.45310493933200696,
            "precision": 0.5671232876712329,
            "recall": 0.4641255605381166
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6498732068801232,
            "auditor_fn_violation": 0.0033665522874404817,
            "auditor_fp_violation": 0.014340851952834535,
            "ave_precision_score": 0.6512887873263558,
            "fpr": 0.14050493962678376,
            "logloss": 1.2756388836260222,
            "mae": 0.4330146489976397,
            "precision": 0.6726342710997443,
            "recall": 0.5177165354330708
        }
    }
]