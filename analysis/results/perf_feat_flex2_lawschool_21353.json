[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7733415294909483,
            "auditor_fn_violation": 0.0350333478323909,
            "auditor_fp_violation": 0.0418050090178718,
            "ave_precision_score": 0.7710672749255861,
            "fpr": 0.18640350877192982,
            "logloss": 2.5212534724939615,
            "mae": 0.3222444065963521,
            "precision": 0.6958855098389982,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7848534995348171,
            "auditor_fn_violation": 0.03521965574421375,
            "auditor_fp_violation": 0.02277032291145511,
            "ave_precision_score": 0.7836311858138255,
            "fpr": 0.18221734357848518,
            "logloss": 2.428439852043048,
            "mae": 0.3300921683641864,
            "precision": 0.6959706959706959,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7010920363966798,
            "auditor_fn_violation": 0.006540434246773955,
            "auditor_fp_violation": 0.006986288735858341,
            "ave_precision_score": 0.6768277740774867,
            "fpr": 0.06030701754385965,
            "logloss": 5.2851814445995675,
            "mae": 0.4245960164231028,
            "precision": 0.7330097087378641,
            "recall": 0.3119834710743802
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7031464912317286,
            "auditor_fn_violation": 0.015573253614218664,
            "auditor_fp_violation": 0.00703420775555008,
            "ave_precision_score": 0.68108345992059,
            "fpr": 0.043907793633369926,
            "logloss": 5.102595998819923,
            "mae": 0.40900468734173995,
            "precision": 0.7727272727272727,
            "recall": 0.28936170212765955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7705355570245324,
            "auditor_fn_violation": 0.011372698274612151,
            "auditor_fp_violation": 0.004378279226102643,
            "ave_precision_score": 0.7669663978441164,
            "fpr": 0.12609649122807018,
            "logloss": 1.068810698411033,
            "mae": 0.32418317742962754,
            "precision": 0.7638603696098563,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7731125124293456,
            "auditor_fn_violation": 0.009975009925963991,
            "auditor_fp_violation": 0.009373965466171832,
            "ave_precision_score": 0.7685013936825082,
            "fpr": 0.132821075740944,
            "logloss": 1.012644446854951,
            "mae": 0.32581944816311886,
            "precision": 0.753061224489796,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7230859941145305,
            "auditor_fn_violation": 0.003998568218065836,
            "auditor_fp_violation": 0.006235653385800953,
            "ave_precision_score": 0.7079382243059078,
            "fpr": 0.047149122807017545,
            "logloss": 4.743977453467378,
            "mae": 0.4157262285583733,
            "precision": 0.7736842105263158,
            "recall": 0.3037190082644628
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.723050849731259,
            "auditor_fn_violation": 0.014606347945909336,
            "auditor_fp_violation": 0.004512745456763019,
            "ave_precision_score": 0.7112238657101908,
            "fpr": 0.030735455543358946,
            "logloss": 4.578639502465989,
            "mae": 0.40203267882334465,
            "precision": 0.8271604938271605,
            "recall": 0.2851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7810830442061047,
            "auditor_fn_violation": 0.027888031027983182,
            "auditor_fp_violation": 0.02451221511723234,
            "ave_precision_score": 0.7758613137698243,
            "fpr": 0.125,
            "logloss": 2.5046029078593497,
            "mae": 0.28525586066088177,
            "precision": 0.7605042016806722,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7911370485438562,
            "auditor_fn_violation": 0.03650185673914567,
            "auditor_fp_violation": 0.029249460486719395,
            "ave_precision_score": 0.7889335631025551,
            "fpr": 0.1207464324917673,
            "logloss": 2.3078519595120714,
            "mae": 0.28722727910510265,
            "precision": 0.7571743929359823,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7227412551826291,
            "auditor_fn_violation": 0.004043877772944776,
            "auditor_fp_violation": 0.005784759796687982,
            "ave_precision_score": 0.7089442700485091,
            "fpr": 0.047149122807017545,
            "logloss": 4.317751848465632,
            "mae": 0.4114831737874743,
            "precision": 0.7806122448979592,
            "recall": 0.31611570247933884
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.725178829777544,
            "auditor_fn_violation": 0.014737137118434272,
            "auditor_fp_violation": 0.0039377624448974635,
            "ave_precision_score": 0.7138548904108879,
            "fpr": 0.030735455543358946,
            "logloss": 4.136670000232844,
            "mae": 0.400479354624221,
            "precision": 0.8260869565217391,
            "recall": 0.28297872340425534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7296380950591076,
            "auditor_fn_violation": 0.03154904306220096,
            "auditor_fp_violation": 0.048473622725036906,
            "ave_precision_score": 0.7243990095002772,
            "fpr": 0.24890350877192982,
            "logloss": 2.79104638058293,
            "mae": 0.3734787237284804,
            "precision": 0.6222961730449251,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7349555916158442,
            "auditor_fn_violation": 0.03687320456827896,
            "auditor_fp_violation": 0.049284258159905024,
            "ave_precision_score": 0.7311337851109048,
            "fpr": 0.23710208562019758,
            "logloss": 2.6238028725242213,
            "mae": 0.38279364707659125,
            "precision": 0.6197183098591549,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7905329597009321,
            "auditor_fn_violation": 0.022924369290996085,
            "auditor_fp_violation": 0.020262030660764062,
            "ave_precision_score": 0.7458249741154156,
            "fpr": 0.1699561403508772,
            "logloss": 2.8211784718374084,
            "mae": 0.3111096095874124,
            "precision": 0.7118959107806692,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7836700717539893,
            "auditor_fn_violation": 0.02186981806291894,
            "auditor_fp_violation": 0.02365893302070188,
            "ave_precision_score": 0.745315256845362,
            "fpr": 0.17892425905598244,
            "logloss": 2.4552429514022416,
            "mae": 0.32026395256193374,
            "precision": 0.6924528301886792,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7718575512022939,
            "auditor_fn_violation": 0.016596889952153113,
            "auditor_fp_violation": 0.018919597474995914,
            "ave_precision_score": 0.7259800926099953,
            "fpr": 0.31469298245614036,
            "logloss": 3.143154353969201,
            "mae": 0.3737996564674743,
            "precision": 0.6002785515320335,
            "recall": 0.890495867768595
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7583699472110039,
            "auditor_fn_violation": 0.012062965644487002,
            "auditor_fp_violation": 0.013924047482146904,
            "ave_precision_score": 0.721297348214516,
            "fpr": 0.32821075740944017,
            "logloss": 2.780976712422014,
            "mae": 0.39086382715447937,
            "precision": 0.5800561797752809,
            "recall": 0.8787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7929165560979988,
            "auditor_fn_violation": 0.016383935044222125,
            "auditor_fp_violation": 0.01587606574848336,
            "ave_precision_score": 0.7529254420468525,
            "fpr": 0.15899122807017543,
            "logloss": 2.645545542251319,
            "mae": 0.2973947262403251,
            "precision": 0.7253787878787878,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7917466151197945,
            "auditor_fn_violation": 0.020349393932316606,
            "auditor_fp_violation": 0.021757257604834834,
            "ave_precision_score": 0.7596039413964075,
            "fpr": 0.1525795828759605,
            "logloss": 2.221193195524967,
            "mae": 0.303645886819402,
            "precision": 0.7306201550387597,
            "recall": 0.8021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7767463646916268,
            "auditor_fn_violation": 0.029849934754240984,
            "auditor_fp_violation": 0.031331980652566004,
            "ave_precision_score": 0.7399009442301949,
            "fpr": 0.19078947368421054,
            "logloss": 3.84394618092659,
            "mae": 0.3298546257337489,
            "precision": 0.6819012797074955,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7691133688077698,
            "auditor_fn_violation": 0.03164630870915758,
            "auditor_fp_violation": 0.023121286568048367,
            "ave_precision_score": 0.7397125687083389,
            "fpr": 0.19209659714599342,
            "logloss": 3.511299676227406,
            "mae": 0.33876232019565966,
            "precision": 0.6728971962616822,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.814334404225276,
            "auditor_fn_violation": 0.013538494997825145,
            "auditor_fp_violation": 0.009683964584358102,
            "ave_precision_score": 0.8147287346268779,
            "fpr": 0.15789473684210525,
            "logloss": 0.8040363917241722,
            "mae": 0.2817492458113935,
            "precision": 0.7343173431734318,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.826527922237157,
            "auditor_fn_violation": 0.017827031319335784,
            "auditor_fp_violation": 0.02538139295235109,
            "ave_precision_score": 0.8268078472059653,
            "fpr": 0.15806805708013172,
            "logloss": 0.7228068300500738,
            "mae": 0.28888075220223935,
            "precision": 0.7257142857142858,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.774438527969699,
            "auditor_fn_violation": 0.03052051616644918,
            "auditor_fp_violation": 0.03245921462534843,
            "ave_precision_score": 0.7374221822017379,
            "fpr": 0.22149122807017543,
            "logloss": 3.8730657420167987,
            "mae": 0.34086019383547583,
            "precision": 0.6517241379310345,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7632139440096536,
            "auditor_fn_violation": 0.030039470303851283,
            "auditor_fp_violation": 0.026008647147113515,
            "ave_precision_score": 0.7336584824573342,
            "fpr": 0.22722283205268934,
            "logloss": 3.531597248974142,
            "mae": 0.3516792620801104,
            "precision": 0.6387434554973822,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7750473655906771,
            "auditor_fn_violation": 0.03188886472379296,
            "auditor_fp_violation": 0.031460075422200376,
            "ave_precision_score": 0.738025155001669,
            "fpr": 0.21929824561403508,
            "logloss": 3.868609789027266,
            "mae": 0.3392164010236927,
            "precision": 0.6527777777777778,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7642326193824065,
            "auditor_fn_violation": 0.029777891958801418,
            "auditor_fp_violation": 0.026715552668194996,
            "ave_precision_score": 0.7346765699841392,
            "fpr": 0.2261251372118551,
            "logloss": 3.5273493296240637,
            "mae": 0.34993339459251993,
            "precision": 0.6404886561954625,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7616325666466539,
            "auditor_fn_violation": 0.0013864723792953466,
            "auditor_fp_violation": 0.006010206591244478,
            "ave_precision_score": 0.7619880837807046,
            "fpr": 0.3706140350877193,
            "logloss": 1.3727104815080546,
            "mae": 0.39389745284049577,
            "precision": 0.5769712140175219,
            "recall": 0.9524793388429752
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7755846926786866,
            "auditor_fn_violation": 0.003332788378447813,
            "auditor_fp_violation": 0.013120066907114113,
            "ave_precision_score": 0.7758856949560502,
            "fpr": 0.3885839736553238,
            "logloss": 1.2696647259337348,
            "mae": 0.4032526142551726,
            "precision": 0.5591531755915318,
            "recall": 0.9553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7825844640710727,
            "auditor_fn_violation": 0.013846599971001888,
            "auditor_fp_violation": 0.027145843580914906,
            "ave_precision_score": 0.7393471446909321,
            "fpr": 0.2719298245614035,
            "logloss": 2.8665525900340536,
            "mae": 0.3474732426018403,
            "precision": 0.6265060240963856,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7745715399654157,
            "auditor_fn_violation": 0.015615292991101664,
            "auditor_fp_violation": 0.023208405206209832,
            "ave_precision_score": 0.739100638894445,
            "fpr": 0.27661909989023054,
            "logloss": 2.4977887550442586,
            "mae": 0.35902466499882246,
            "precision": 0.6129032258064516,
            "recall": 0.8489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.8237992443551436,
            "auditor_fn_violation": 0.00388755980861244,
            "auditor_fp_violation": 0.020633505492703742,
            "ave_precision_score": 0.8242375718086178,
            "fpr": 0.28399122807017546,
            "logloss": 0.8160119754067039,
            "mae": 0.35358002129125227,
            "precision": 0.6294706723891274,
            "recall": 0.9090909090909091
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.815907179908246,
            "auditor_fn_violation": 0.007151365111988231,
            "auditor_fp_violation": 0.01765521429940435,
            "ave_precision_score": 0.8161358863604403,
            "fpr": 0.3084522502744237,
            "logloss": 0.8228202912130186,
            "mae": 0.3669772459568229,
            "precision": 0.605890603085554,
            "recall": 0.9191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 21353,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7786078973005556,
            "auditor_fn_violation": 0.02997680150790199,
            "auditor_fp_violation": 0.04741043613707165,
            "ave_precision_score": 0.721174078492444,
            "fpr": 0.31359649122807015,
            "logloss": 4.624480824160111,
            "mae": 0.3690298834437368,
            "precision": 0.5994397759103641,
            "recall": 0.8842975206611571
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7725278324475655,
            "auditor_fn_violation": 0.02983861550318799,
            "auditor_fp_violation": 0.04673541571769579,
            "ave_precision_score": 0.7218050674576115,
            "fpr": 0.3172338090010977,
            "logloss": 4.249668634484267,
            "mae": 0.37542338328675184,
            "precision": 0.5912305516265912,
            "recall": 0.8893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.707231238083613,
            "auditor_fn_violation": 0.027339785413948096,
            "auditor_fp_violation": 0.013864977865223808,
            "ave_precision_score": 0.7091274357967999,
            "fpr": 0.06578947368421052,
            "logloss": 0.8473057505755417,
            "mae": 0.41077030840224643,
            "precision": 0.7619047619047619,
            "recall": 0.39669421487603307
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6771247829835507,
            "auditor_fn_violation": 0.015694700702991816,
            "auditor_fp_violation": 0.01350338891502448,
            "ave_precision_score": 0.6782108797535997,
            "fpr": 0.07464324917672886,
            "logloss": 0.863630692620421,
            "mae": 0.41544414728161244,
            "precision": 0.711864406779661,
            "recall": 0.3574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7968272312082728,
            "auditor_fn_violation": 0.020552414093083952,
            "auditor_fp_violation": 0.029251721593703883,
            "ave_precision_score": 0.7559082403816221,
            "fpr": 0.22587719298245615,
            "logloss": 2.6957106813917178,
            "mae": 0.3144186481025719,
            "precision": 0.6740506329113924,
            "recall": 0.8801652892561983
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7949884897114654,
            "auditor_fn_violation": 0.021783403788214962,
            "auditor_fp_violation": 0.033349014688202394,
            "ave_precision_score": 0.7627047716038351,
            "fpr": 0.23161361141602635,
            "logloss": 2.280155061385626,
            "mae": 0.32173294964749405,
            "precision": 0.6596774193548387,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8431676412577471,
            "auditor_fn_violation": 0.003724445411048288,
            "auditor_fp_violation": 0.007849647483193969,
            "ave_precision_score": 0.8434990990061678,
            "fpr": 0.07236842105263158,
            "logloss": 0.5239666065848365,
            "mae": 0.32121343282051384,
            "precision": 0.8307692307692308,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8449292738270118,
            "auditor_fn_violation": 0.01874022000607236,
            "auditor_fp_violation": 0.006115728398933669,
            "ave_precision_score": 0.845203137979943,
            "fpr": 0.06915477497255763,
            "logloss": 0.5126483056126541,
            "mae": 0.32665673253237876,
            "precision": 0.8292682926829268,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7518131877515429,
            "auditor_fn_violation": 0.03522817891837031,
            "auditor_fp_violation": 0.04770761600262339,
            "ave_precision_score": 0.7482469359197419,
            "fpr": 0.19846491228070176,
            "logloss": 1.1664546493467909,
            "mae": 0.35747823383770627,
            "precision": 0.6824561403508772,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7474869274326207,
            "auditor_fn_violation": 0.033012588457855534,
            "auditor_fp_violation": 0.04754437450062353,
            "ave_precision_score": 0.7429054657218064,
            "fpr": 0.19099890230515917,
            "logloss": 1.0948305588643792,
            "mae": 0.35086548699214576,
            "precision": 0.6830601092896175,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 21353,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7863115246814182,
            "auditor_fn_violation": 0.03924713643613165,
            "auditor_fp_violation": 0.040408776028857195,
            "ave_precision_score": 0.7487314946631438,
            "fpr": 0.22039473684210525,
            "logloss": 3.8347171984422865,
            "mae": 0.3245064615211115,
            "precision": 0.6688632619439868,
            "recall": 0.8388429752066116
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7843912144850703,
            "auditor_fn_violation": 0.03785879440409183,
            "auditor_fp_violation": 0.04615794360188276,
            "ave_precision_score": 0.7555531137764544,
            "fpr": 0.2283205268935236,
            "logloss": 3.429957602219855,
            "mae": 0.33083786466480003,
            "precision": 0.6521739130434783,
            "recall": 0.8297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7710812822107665,
            "auditor_fn_violation": 0.02550021748586342,
            "auditor_fp_violation": 0.04246597802918511,
            "ave_precision_score": 0.771628466267459,
            "fpr": 0.2850877192982456,
            "logloss": 1.6836084466786398,
            "mae": 0.36506549161249835,
            "precision": 0.618208516886931,
            "recall": 0.8698347107438017
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7842516734832174,
            "auditor_fn_violation": 0.03141275661536306,
            "auditor_fp_violation": 0.0436787960702027,
            "ave_precision_score": 0.7845470271842327,
            "fpr": 0.29747530186608123,
            "logloss": 1.3154072761192661,
            "mae": 0.3739593192949879,
            "precision": 0.6020558002936858,
            "recall": 0.8723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7948041789078716,
            "auditor_fn_violation": 0.024802450340727856,
            "auditor_fp_violation": 0.023966531398589938,
            "ave_precision_score": 0.7550400414372389,
            "fpr": 0.17214912280701755,
            "logloss": 2.6371228351463163,
            "mae": 0.2859916213434342,
            "precision": 0.7186379928315412,
            "recall": 0.8285123966942148
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7971176321144595,
            "auditor_fn_violation": 0.02700095756358456,
            "auditor_fp_violation": 0.0367441524725514,
            "ave_precision_score": 0.7657103598427959,
            "fpr": 0.17233809001097694,
            "logloss": 2.2078457852707367,
            "mae": 0.2896045022873193,
            "precision": 0.7124542124542125,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7866682875573603,
            "auditor_fn_violation": 0.012686675366101205,
            "auditor_fp_violation": 0.016537034759796686,
            "ave_precision_score": 0.7478432861558328,
            "fpr": 0.13267543859649122,
            "logloss": 4.007001483392427,
            "mae": 0.2763608978706249,
            "precision": 0.7505154639175258,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7849121707430644,
            "auditor_fn_violation": 0.023775603148282223,
            "auditor_fp_violation": 0.026018603562903392,
            "ave_precision_score": 0.7542490936350221,
            "fpr": 0.13611416026344675,
            "logloss": 3.4418366407820935,
            "mae": 0.28667364423776054,
            "precision": 0.734475374732334,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7698568889019302,
            "auditor_fn_violation": 0.014354066985645933,
            "auditor_fp_violation": 0.0132398753894081,
            "ave_precision_score": 0.766286948354707,
            "fpr": 0.11403508771929824,
            "logloss": 1.0733856328324045,
            "mae": 0.32498300555512843,
            "precision": 0.7739130434782608,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7710219659032672,
            "auditor_fn_violation": 0.006282551323072614,
            "auditor_fp_violation": 0.004749210331772671,
            "ave_precision_score": 0.766413780005506,
            "fpr": 0.11855104281009879,
            "logloss": 1.0149295034717838,
            "mae": 0.3277110257691719,
            "precision": 0.7672413793103449,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.775919540889616,
            "auditor_fn_violation": 0.021295490793098455,
            "auditor_fp_violation": 0.02228336612559437,
            "ave_precision_score": 0.7253112447892831,
            "fpr": 0.22149122807017543,
            "logloss": 3.088527167271062,
            "mae": 0.33616931915484977,
            "precision": 0.6605042016806723,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7648449449591861,
            "auditor_fn_violation": 0.02521661956699442,
            "auditor_fp_violation": 0.02345233739306187,
            "ave_precision_score": 0.720099593614655,
            "fpr": 0.22283205268935236,
            "logloss": 2.7353079091358694,
            "mae": 0.34598530616965134,
            "precision": 0.6451048951048951,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7643081428209642,
            "auditor_fn_violation": 0.025203439901406416,
            "auditor_fp_violation": 0.042660682079029344,
            "ave_precision_score": 0.7227754762867348,
            "fpr": 0.24671052631578946,
            "logloss": 3.816522242400841,
            "mae": 0.3481084178430126,
            "precision": 0.6359223300970874,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7542676612630823,
            "auditor_fn_violation": 0.030128220099493196,
            "auditor_fp_violation": 0.04134650567142336,
            "ave_precision_score": 0.7205157407981283,
            "fpr": 0.2524698133918771,
            "logloss": 3.2778011304931938,
            "mae": 0.36487925526631326,
            "precision": 0.6153846153846154,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7809055354712,
            "auditor_fn_violation": 0.006875724952878064,
            "auditor_fp_violation": 0.0077420478767011,
            "ave_precision_score": 0.777414772432466,
            "fpr": 0.09429824561403509,
            "logloss": 1.0236412887779285,
            "mae": 0.31361285917666853,
            "precision": 0.8032036613272311,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7797782321768932,
            "auditor_fn_violation": 0.006796365929420559,
            "auditor_fp_violation": 0.0024194090369407954,
            "ave_precision_score": 0.7751634640385141,
            "fpr": 0.10867178924259056,
            "logloss": 1.004302065794262,
            "mae": 0.3198823170344691,
            "precision": 0.7755102040816326,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7535968039876819,
            "auditor_fn_violation": 0.03061113527620705,
            "auditor_fp_violation": 0.02231923266109199,
            "ave_precision_score": 0.750054215405789,
            "fpr": 0.14035087719298245,
            "logloss": 1.1953626204578436,
            "mae": 0.30544423995212916,
            "precision": 0.7408906882591093,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7505568737160839,
            "auditor_fn_violation": 0.034315809141228955,
            "auditor_fp_violation": 0.02890596414196853,
            "ave_precision_score": 0.7459756573180409,
            "fpr": 0.13062568605927552,
            "logloss": 1.1127338921860856,
            "mae": 0.3039434860682997,
            "precision": 0.7468085106382979,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7755072372341392,
            "auditor_fn_violation": 0.03424949253298536,
            "auditor_fp_violation": 0.04577082308575176,
            "ave_precision_score": 0.7362369591515706,
            "fpr": 0.26096491228070173,
            "logloss": 3.9620295338591127,
            "mae": 0.3517349306262119,
            "precision": 0.6257861635220126,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7653198490981057,
            "auditor_fn_violation": 0.033052292313800594,
            "auditor_fp_violation": 0.0399750093963674,
            "ave_precision_score": 0.7347628124862401,
            "fpr": 0.2722283205268935,
            "logloss": 3.603793081511528,
            "mae": 0.3693352004456217,
            "precision": 0.6057233704292527,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7829014894662158,
            "auditor_fn_violation": 0.013388973466724663,
            "auditor_fp_violation": 0.02169156828988359,
            "ave_precision_score": 0.7404112505061691,
            "fpr": 0.22916666666666666,
            "logloss": 2.811433463814129,
            "mae": 0.3304575559975028,
            "precision": 0.6539735099337748,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7761071427944695,
            "auditor_fn_violation": 0.01878693042483126,
            "auditor_fp_violation": 0.024761606069431064,
            "ave_precision_score": 0.7421460076920746,
            "fpr": 0.23380900109769484,
            "logloss": 2.4142973189788064,
            "mae": 0.34187847011627404,
            "precision": 0.6444073455759599,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7422318357352047,
            "auditor_fn_violation": 0.015772256053356543,
            "auditor_fp_violation": 0.011103254631906874,
            "ave_precision_score": 0.7061441672588773,
            "fpr": 0.06469298245614036,
            "logloss": 6.601516301186961,
            "mae": 0.375412384935689,
            "precision": 0.7739463601532567,
            "recall": 0.41735537190082644
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7345879747078441,
            "auditor_fn_violation": 0.02394142513487634,
            "auditor_fp_violation": 0.012781548770258196,
            "ave_precision_score": 0.7063693277048921,
            "fpr": 0.0570801317233809,
            "logloss": 6.304463465980737,
            "mae": 0.3726236671607646,
            "precision": 0.7787234042553192,
            "recall": 0.3893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7481298717025476,
            "auditor_fn_violation": 0.008173843700159488,
            "auditor_fp_violation": 0.009732640596819152,
            "ave_precision_score": 0.7446087717131368,
            "fpr": 0.13048245614035087,
            "logloss": 1.3810126211499134,
            "mae": 0.2772651338698768,
            "precision": 0.7546391752577319,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7568180874137159,
            "auditor_fn_violation": 0.01265852348366303,
            "auditor_fp_violation": 0.019385141542895976,
            "ave_precision_score": 0.7522860324849365,
            "fpr": 0.12733260153677278,
            "logloss": 1.2952817769301401,
            "mae": 0.2858309827599521,
            "precision": 0.7483731019522777,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8005954784862275,
            "auditor_fn_violation": 0.007593881397709149,
            "auditor_fp_violation": 0.015706980652566,
            "ave_precision_score": 0.7136965940088819,
            "fpr": 0.1875,
            "logloss": 5.043312232069698,
            "mae": 0.2936125349978475,
            "precision": 0.6973451327433628,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7880122035566147,
            "auditor_fn_violation": 0.011766354485367963,
            "auditor_fp_violation": 0.034401905657982186,
            "ave_precision_score": 0.7055493115818872,
            "fpr": 0.20417124039517015,
            "logloss": 4.92953699874768,
            "mae": 0.30821047565768983,
            "precision": 0.6731107205623902,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 21353,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7736665655880047,
            "auditor_fn_violation": 0.006180223285486444,
            "auditor_fp_violation": 0.01576334235120512,
            "ave_precision_score": 0.7740768021023052,
            "fpr": 0.2993421052631579,
            "logloss": 1.0289363299488692,
            "mae": 0.37029954355175343,
            "precision": 0.6127659574468085,
            "recall": 0.8925619834710744
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7934908870214118,
            "auditor_fn_violation": 0.009234649788635356,
            "auditor_fp_violation": 0.01002113249251403,
            "ave_precision_score": 0.7937941089000593,
            "fpr": 0.3205268935236004,
            "logloss": 0.917116286539094,
            "mae": 0.37377236439651196,
            "precision": 0.5910364145658263,
            "recall": 0.8978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 21353,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7917350675248579,
            "auditor_fn_violation": 0.0119141474554154,
            "auditor_fp_violation": 0.012169003115264799,
            "ave_precision_score": 0.787086454437631,
            "fpr": 0.14583333333333334,
            "logloss": 1.1987259139128206,
            "mae": 0.27687905138845326,
            "precision": 0.7481060606060606,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8106509956161897,
            "auditor_fn_violation": 0.015110820468505504,
            "auditor_fp_violation": 0.025013005568125534,
            "ave_precision_score": 0.8098123197510111,
            "fpr": 0.1437980241492865,
            "logloss": 0.9569216935761788,
            "mae": 0.2774244297038826,
            "precision": 0.7436399217221135,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8006272822616908,
            "auditor_fn_violation": 0.013706140350877192,
            "auditor_fp_violation": 0.021104894244958188,
            "ave_precision_score": 0.8004365487124955,
            "fpr": 0.18640350877192982,
            "logloss": 0.880422192544741,
            "mae": 0.29754763320619404,
            "precision": 0.7108843537414966,
            "recall": 0.8636363636363636
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8227198741003535,
            "auditor_fn_violation": 0.01677838241819838,
            "auditor_fp_violation": 0.016333500103297816,
            "ave_precision_score": 0.8231941572096331,
            "fpr": 0.17892425905598244,
            "logloss": 0.7639682993550014,
            "mae": 0.30351183375570634,
            "precision": 0.7125220458553791,
            "recall": 0.8595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.808639558626812,
            "auditor_fn_violation": 0.008690372625779324,
            "auditor_fp_violation": 0.01864547466797836,
            "ave_precision_score": 0.8091310921136787,
            "fpr": 0.2050438596491228,
            "logloss": 1.0617100559901247,
            "mae": 0.28722027813411694,
            "precision": 0.6898839137645107,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8231011943660179,
            "auditor_fn_violation": 0.009479879487119603,
            "auditor_fp_violation": 0.02437330585362576,
            "ave_precision_score": 0.8233427296044162,
            "fpr": 0.21734357848518113,
            "logloss": 0.9866046203854407,
            "mae": 0.2931855265659388,
            "precision": 0.670549084858569,
            "recall": 0.8574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8163111264287453,
            "auditor_fn_violation": 0.0017851964622299585,
            "auditor_fp_violation": 0.018414904082636498,
            "ave_precision_score": 0.8167867874404453,
            "fpr": 0.15679824561403508,
            "logloss": 0.879074323558559,
            "mae": 0.2750702285038707,
            "precision": 0.7244701348747592,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8257750830275652,
            "auditor_fn_violation": 0.013903356143587828,
            "auditor_fp_violation": 0.026339697972127016,
            "ave_precision_score": 0.8260196397129991,
            "fpr": 0.1525795828759605,
            "logloss": 0.8404010237575446,
            "mae": 0.28097534309682715,
            "precision": 0.7263779527559056,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7754154949817056,
            "auditor_fn_violation": 0.035096781209221405,
            "auditor_fp_violation": 0.04680070503361207,
            "ave_precision_score": 0.736124653395736,
            "fpr": 0.26535087719298245,
            "logloss": 3.968285299825706,
            "mae": 0.3527679033355142,
            "precision": 0.6230529595015576,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7655139555830646,
            "auditor_fn_violation": 0.033918770581778265,
            "auditor_fp_violation": 0.042182844597773266,
            "ave_precision_score": 0.7349453624451991,
            "fpr": 0.27661909989023054,
            "logloss": 3.6123881398669178,
            "mae": 0.3704492713786372,
            "precision": 0.6031496062992125,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7766011909786086,
            "auditor_fn_violation": 0.03009460635058721,
            "auditor_fp_violation": 0.04910128709624529,
            "ave_precision_score": 0.7191683453295126,
            "fpr": 0.3048245614035088,
            "logloss": 4.632545348253187,
            "mae": 0.3697152170437691,
            "precision": 0.604551920341394,
            "recall": 0.878099173553719
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7676152695246374,
            "auditor_fn_violation": 0.031837821426069085,
            "auditor_fp_violation": 0.048604732782245724,
            "ave_precision_score": 0.7169562451586593,
            "fpr": 0.3205268935236004,
            "logloss": 4.296623107603506,
            "mae": 0.3800558832784547,
            "precision": 0.5828571428571429,
            "recall": 0.8680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 21353,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.6307884616131706,
            "auditor_fn_violation": 0.01430422647527912,
            "auditor_fp_violation": 0.022921278078373505,
            "ave_precision_score": 0.6199462934240004,
            "fpr": 0.09320175438596491,
            "logloss": 13.38857249328746,
            "mae": 0.5228730232651655,
            "precision": 0.5142857142857142,
            "recall": 0.1859504132231405
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6335348167693583,
            "auditor_fn_violation": 0.004229628418618773,
            "auditor_fp_violation": 0.015546943255897313,
            "ave_precision_score": 0.6258023330239174,
            "fpr": 0.09549945115257959,
            "logloss": 13.081581486004408,
            "mae": 0.5048719106153083,
            "precision": 0.5166666666666667,
            "recall": 0.19787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 21353,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7872374161091182,
            "auditor_fn_violation": 0.009089096708713934,
            "auditor_fp_violation": 0.012338088211182164,
            "ave_precision_score": 0.7483688757470988,
            "fpr": 0.14035087719298245,
            "logloss": 3.982450960060617,
            "mae": 0.276530682583061,
            "precision": 0.7414141414141414,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7841068276958214,
            "auditor_fn_violation": 0.02208001494733401,
            "auditor_fp_violation": 0.0260434946023781,
            "ave_precision_score": 0.7534246451304906,
            "fpr": 0.14270032930845225,
            "logloss": 3.4273408538435755,
            "mae": 0.289167222816833,
            "precision": 0.7286012526096033,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7675840131615423,
            "auditor_fn_violation": 0.01299478033927796,
            "auditor_fp_violation": 0.006740346778160359,
            "ave_precision_score": 0.7479266546783084,
            "fpr": 0.06030701754385965,
            "logloss": 2.964003826038915,
            "mae": 0.36308751605317885,
            "precision": 0.789272030651341,
            "recall": 0.4256198347107438
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7755819991877111,
            "auditor_fn_violation": 0.02323843333255482,
            "auditor_fp_violation": 0.007917839656901914,
            "ave_precision_score": 0.7612589870582548,
            "fpr": 0.04061470911086718,
            "logloss": 2.651714756624646,
            "mae": 0.3563389585772511,
            "precision": 0.8333333333333334,
            "recall": 0.39361702127659576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7412497891917142,
            "auditor_fn_violation": 0.038703421777584464,
            "auditor_fp_violation": 0.028708599770454174,
            "ave_precision_score": 0.737706059742465,
            "fpr": 0.1337719298245614,
            "logloss": 1.190338841499688,
            "mae": 0.3528128802383808,
            "precision": 0.7336244541484717,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7253686346202886,
            "auditor_fn_violation": 0.045374500782399525,
            "auditor_fp_violation": 0.03219904866447128,
            "ave_precision_score": 0.720819113001242,
            "fpr": 0.12952799121844127,
            "logloss": 1.1288923594772102,
            "mae": 0.35226392627143793,
            "precision": 0.7324263038548753,
            "recall": 0.6872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7474115507344767,
            "auditor_fn_violation": 0.008173843700159488,
            "auditor_fp_violation": 0.009732640596819152,
            "ave_precision_score": 0.7438917661729487,
            "fpr": 0.13048245614035087,
            "logloss": 1.3848273672008318,
            "mae": 0.27732232803774165,
            "precision": 0.7546391752577319,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7564200140112771,
            "auditor_fn_violation": 0.01627858093747811,
            "auditor_fp_violation": 0.019668899392907554,
            "ave_precision_score": 0.75187018976275,
            "fpr": 0.12843029637760703,
            "logloss": 1.297994061742103,
            "mae": 0.2857435211945416,
            "precision": 0.7473002159827213,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7823488238923098,
            "auditor_fn_violation": 0.014915905466144705,
            "auditor_fp_violation": 0.026361903590752585,
            "ave_precision_score": 0.7412104061288856,
            "fpr": 0.24890350877192982,
            "logloss": 2.8034009725783173,
            "mae": 0.34077581911892113,
            "precision": 0.6425196850393701,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7726483122302511,
            "auditor_fn_violation": 0.017651867248989893,
            "auditor_fp_violation": 0.026830051449778604,
            "ave_precision_score": 0.7388943127978419,
            "fpr": 0.2502744237102086,
            "logloss": 2.449612475342748,
            "mae": 0.35082205229284535,
            "precision": 0.6316639741518578,
            "recall": 0.8319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7904863257909552,
            "auditor_fn_violation": 0.0027027149485283467,
            "auditor_fp_violation": 0.01619117888178391,
            "ave_precision_score": 0.7914928889430439,
            "fpr": 0.14473684210526316,
            "logloss": 1.134983917881657,
            "mae": 0.2830824210823215,
            "precision": 0.7344064386317908,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8042595638742035,
            "auditor_fn_violation": 0.01966508629749866,
            "auditor_fp_violation": 0.028338448441945385,
            "ave_precision_score": 0.8045412131239864,
            "fpr": 0.141602634467618,
            "logloss": 1.1523783204645641,
            "mae": 0.29977490413750596,
            "precision": 0.723175965665236,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8435391089332657,
            "auditor_fn_violation": 0.003608906046107004,
            "auditor_fp_violation": 0.009635288571897035,
            "ave_precision_score": 0.8439697836653016,
            "fpr": 0.24232456140350878,
            "logloss": 0.697955146373743,
            "mae": 0.3215717884524023,
            "precision": 0.6651515151515152,
            "recall": 0.9070247933884298
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8423211337919568,
            "auditor_fn_violation": 0.0016021673634304138,
            "auditor_fp_violation": 0.019078981757357175,
            "ave_precision_score": 0.8425509810592284,
            "fpr": 0.24588364434687157,
            "logloss": 0.7037502408756754,
            "mae": 0.331727112053549,
            "precision": 0.6569678407350689,
            "recall": 0.9127659574468086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7846543720092387,
            "auditor_fn_violation": 0.010067783094098885,
            "auditor_fp_violation": 0.017415764879488444,
            "ave_precision_score": 0.7852560741356107,
            "fpr": 0.13925438596491227,
            "logloss": 1.125197602256799,
            "mae": 0.28346882453770655,
            "precision": 0.7465069860279441,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7986189562002906,
            "auditor_fn_violation": 0.026517504729429896,
            "auditor_fp_violation": 0.026434283922130875,
            "ave_precision_score": 0.7988424489620104,
            "fpr": 0.14050493962678376,
            "logloss": 1.0258560465267608,
            "mae": 0.287270295954225,
            "precision": 0.7355371900826446,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7367444787689796,
            "auditor_fn_violation": 0.00996810207336524,
            "auditor_fp_violation": 0.00688125102475816,
            "ave_precision_score": 0.7070657815627539,
            "fpr": 0.05482456140350877,
            "logloss": 5.081129926640403,
            "mae": 0.3872615131124657,
            "precision": 0.782608695652174,
            "recall": 0.371900826446281
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7362141757935796,
            "auditor_fn_violation": 0.014041151878926617,
            "auditor_fp_violation": 0.005884241731818963,
            "ave_precision_score": 0.7151387484498092,
            "fpr": 0.04061470911086718,
            "logloss": 4.681722495611596,
            "mae": 0.3810799314041488,
            "precision": 0.8102564102564103,
            "recall": 0.33617021276595743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7231832363848832,
            "auditor_fn_violation": 0.0061031970421922665,
            "auditor_fp_violation": 0.008256988850631251,
            "ave_precision_score": 0.7095561652960721,
            "fpr": 0.044956140350877194,
            "logloss": 4.6704246835853125,
            "mae": 0.41384440651172827,
            "precision": 0.7807486631016043,
            "recall": 0.30165289256198347
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7261541098313918,
            "auditor_fn_violation": 0.016670948455052906,
            "auditor_fp_violation": 0.00455754932781748,
            "ave_precision_score": 0.7147633606185738,
            "fpr": 0.027442371020856202,
            "logloss": 4.490691566087492,
            "mae": 0.4024991317377018,
            "precision": 0.8376623376623377,
            "recall": 0.274468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.751474410414348,
            "auditor_fn_violation": 0.006961813107148037,
            "auditor_fp_violation": 0.018376475651746188,
            "ave_precision_score": 0.7479323163797205,
            "fpr": 0.12828947368421054,
            "logloss": 1.3470431125955837,
            "mae": 0.2770440208182538,
            "precision": 0.7572614107883817,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7585536926920434,
            "auditor_fn_violation": 0.020319032160123318,
            "auditor_fp_violation": 0.018912211792876683,
            "ave_precision_score": 0.7540029260193103,
            "fpr": 0.132821075740944,
            "logloss": 1.2710991700908696,
            "mae": 0.2857768714599747,
            "precision": 0.7414529914529915,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7624527636031061,
            "auditor_fn_violation": 0.02832300275482094,
            "auditor_fp_violation": 0.03577430726348582,
            "ave_precision_score": 0.7329228411242479,
            "fpr": 0.17214912280701755,
            "logloss": 3.6224344138939726,
            "mae": 0.3311727927247519,
            "precision": 0.696911196911197,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7594240658400311,
            "auditor_fn_violation": 0.040986056940000466,
            "auditor_fp_violation": 0.04650641815452856,
            "ave_precision_score": 0.7389073932255883,
            "fpr": 0.1778265642151482,
            "logloss": 3.318880743317166,
            "mae": 0.3387601622205389,
            "precision": 0.6766467065868264,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7919388389903926,
            "auditor_fn_violation": 0.004560406698564596,
            "auditor_fp_violation": 0.012066527299557308,
            "ave_precision_score": 0.7622676696917252,
            "fpr": 0.09758771929824561,
            "logloss": 2.27008118168071,
            "mae": 0.27912249972730835,
            "precision": 0.7870813397129187,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7959522970655352,
            "auditor_fn_violation": 0.020856201975850718,
            "auditor_fp_violation": 0.01813312225731859,
            "ave_precision_score": 0.774841371861039,
            "fpr": 0.09769484083424808,
            "logloss": 1.832463919532986,
            "mae": 0.29614362289250074,
            "precision": 0.7601078167115903,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7360119603682945,
            "auditor_fn_violation": 0.014376721763085396,
            "auditor_fp_violation": 0.01096747417609444,
            "ave_precision_score": 0.7367622584888148,
            "fpr": 0.11951754385964912,
            "logloss": 1.2848599922302546,
            "mae": 0.3309103946403321,
            "precision": 0.7373493975903614,
            "recall": 0.6322314049586777
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.745175248466717,
            "auditor_fn_violation": 0.01910923231426771,
            "auditor_fp_violation": 0.023176046854892714,
            "ave_precision_score": 0.7457215680745226,
            "fpr": 0.11306256860592755,
            "logloss": 1.324685064881954,
            "mae": 0.3394599774352338,
            "precision": 0.7303664921465969,
            "recall": 0.5936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7763671112886033,
            "auditor_fn_violation": 0.03398669711468755,
            "auditor_fp_violation": 0.044543675192654536,
            "ave_precision_score": 0.7718616933225715,
            "fpr": 0.18311403508771928,
            "logloss": 2.683641785007482,
            "mae": 0.31669901310439325,
            "precision": 0.6980108499095841,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7865702133605472,
            "auditor_fn_violation": 0.03291916762033772,
            "auditor_fp_violation": 0.023688802268071515,
            "ave_precision_score": 0.7847706462356134,
            "fpr": 0.1756311745334797,
            "logloss": 2.5307137852852724,
            "mae": 0.32210773294226785,
            "precision": 0.7031539888682746,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7747552472001499,
            "auditor_fn_violation": 0.00828711758735682,
            "auditor_fp_violation": 0.008910272175766521,
            "ave_precision_score": 0.7551137003364881,
            "fpr": 0.06469298245614036,
            "logloss": 2.6976919264238033,
            "mae": 0.3502847631467975,
            "precision": 0.7838827838827839,
            "recall": 0.44214876033057854
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7850694299699283,
            "auditor_fn_violation": 0.01900646939299812,
            "auditor_fp_violation": 0.01308273034790206,
            "ave_precision_score": 0.7699297917134361,
            "fpr": 0.04939626783754116,
            "logloss": 2.3825783125773623,
            "mae": 0.34647728951125045,
            "precision": 0.8140495867768595,
            "recall": 0.41914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6949755231325644,
            "auditor_fn_violation": 0.010795001449905759,
            "auditor_fp_violation": 0.008182693884243326,
            "ave_precision_score": 0.6915014592869687,
            "fpr": 0.0712719298245614,
            "logloss": 2.18628936219863,
            "mae": 0.3916862547790451,
            "precision": 0.7537878787878788,
            "recall": 0.41115702479338845
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6876077517156873,
            "auditor_fn_violation": 0.01160753906158769,
            "auditor_fp_violation": 0.01361042038476569,
            "ave_precision_score": 0.6831001047018834,
            "fpr": 0.08122941822173436,
            "logloss": 2.052466097377168,
            "mae": 0.3886194732394865,
            "precision": 0.7299270072992701,
            "recall": 0.425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7518159640624098,
            "auditor_fn_violation": 0.00492061765985211,
            "auditor_fp_violation": 0.006005082800459088,
            "ave_precision_score": 0.7523294106110564,
            "fpr": 0.3442982456140351,
            "logloss": 1.0722699831001055,
            "mae": 0.3986030948969225,
            "precision": 0.5868421052631579,
            "recall": 0.9214876033057852
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7563814175423043,
            "auditor_fn_violation": 0.010077772847233575,
            "auditor_fp_violation": 0.0042688132699109736,
            "ave_precision_score": 0.7567382971219291,
            "fpr": 0.3633369923161361,
            "logloss": 1.031104452281595,
            "mae": 0.4061577128579699,
            "precision": 0.5678851174934726,
            "recall": 0.925531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8085529540507701,
            "auditor_fn_violation": 0.006379585326953748,
            "auditor_fp_violation": 0.018220200032792268,
            "ave_precision_score": 0.8089738576758583,
            "fpr": 0.24013157894736842,
            "logloss": 1.2356307164981073,
            "mae": 0.2990154256682602,
            "precision": 0.6676783004552352,
            "recall": 0.9090909090909091
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8178813175834392,
            "auditor_fn_violation": 0.015022070672863581,
            "auditor_fp_violation": 0.03886735813974328,
            "ave_precision_score": 0.8181083896964435,
            "fpr": 0.2502744237102086,
            "logloss": 1.2155630603025152,
            "mae": 0.30470115901383227,
            "precision": 0.6513761467889908,
            "recall": 0.9063829787234042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.5659734160652885,
            "auditor_fn_violation": 0.01859957227780196,
            "auditor_fp_violation": 0.028032259386784716,
            "ave_precision_score": 0.5532326844609867,
            "fpr": 0.17763157894736842,
            "logloss": 3.920453198616548,
            "mae": 0.4348677845654266,
            "precision": 0.6115107913669064,
            "recall": 0.5268595041322314
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5434152012419347,
            "auditor_fn_violation": 0.02406053670271154,
            "auditor_fp_violation": 0.010446769267531386,
            "ave_precision_score": 0.5323026267390353,
            "fpr": 0.17453347969264543,
            "logloss": 3.8839093389543007,
            "mae": 0.44193398994068644,
            "precision": 0.5943877551020408,
            "recall": 0.4957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.735371014094772,
            "auditor_fn_violation": 0.0355974517906336,
            "auditor_fp_violation": 0.05182202000327923,
            "ave_precision_score": 0.7353748125237749,
            "fpr": 0.34210526315789475,
            "logloss": 2.7986982214554286,
            "mae": 0.4031859846535896,
            "precision": 0.5800807537012113,
            "recall": 0.890495867768595
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7243051925249906,
            "auditor_fn_violation": 0.0369012308195343,
            "auditor_fp_violation": 0.054658233582492666,
            "ave_precision_score": 0.7240577590793074,
            "fpr": 0.3534577387486279,
            "logloss": 2.8011405723462066,
            "mae": 0.41367801939114146,
            "precision": 0.5630936227951153,
            "recall": 0.8829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8207612001649032,
            "auditor_fn_violation": 0.007405846744961583,
            "auditor_fp_violation": 0.005287752090506642,
            "ave_precision_score": 0.8215195870637545,
            "fpr": 0.10087719298245613,
            "logloss": 0.9064810725405728,
            "mae": 0.27030530163154926,
            "precision": 0.7932584269662921,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8322453674339922,
            "auditor_fn_violation": 0.016355653128430302,
            "auditor_fp_violation": 0.018255088350744617,
            "ave_precision_score": 0.8324787433940013,
            "fpr": 0.10318331503841932,
            "logloss": 0.8552438822081972,
            "mae": 0.27955502244466635,
            "precision": 0.7777777777777778,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7602375733194341,
            "auditor_fn_violation": 0.013799024938379012,
            "auditor_fp_violation": 0.005257009345794394,
            "ave_precision_score": 0.7232175166453118,
            "fpr": 0.07346491228070176,
            "logloss": 4.430804499231746,
            "mae": 0.35179792098886353,
            "precision": 0.7736486486486487,
            "recall": 0.4731404958677686
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7579203114880652,
            "auditor_fn_violation": 0.023864352943924146,
            "auditor_fp_violation": 0.012965742462370974,
            "ave_precision_score": 0.7300058799558113,
            "fpr": 0.06037321624588365,
            "logloss": 3.9773880034856077,
            "mae": 0.3480874101747421,
            "precision": 0.7908745247148289,
            "recall": 0.4425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7520816650530566,
            "auditor_fn_violation": 0.006286700739451939,
            "auditor_fp_violation": 0.019542138055418923,
            "ave_precision_score": 0.7485757281625425,
            "fpr": 0.14802631578947367,
            "logloss": 1.319379467704112,
            "mae": 0.2757335621838333,
            "precision": 0.7393822393822393,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7599975840426779,
            "auditor_fn_violation": 0.01609173926244249,
            "auditor_fp_violation": 0.021896647425893156,
            "ave_precision_score": 0.7554442017285086,
            "fpr": 0.14709110867178923,
            "logloss": 1.2431808998389053,
            "mae": 0.2838588466051701,
            "precision": 0.7309236947791165,
            "recall": 0.774468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.7277708781900519,
            "auditor_fn_violation": 0.0018033202841815383,
            "auditor_fp_violation": 0.005057181505164781,
            "ave_precision_score": 0.7109671627961061,
            "fpr": 0.049342105263157895,
            "logloss": 4.507084787660327,
            "mae": 0.40993105692731696,
            "precision": 0.7715736040609137,
            "recall": 0.3140495867768595
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7263156775604424,
            "auditor_fn_violation": 0.014349440642735373,
            "auditor_fp_violation": 0.0027653944856391157,
            "ave_precision_score": 0.7128280075037434,
            "fpr": 0.031833150384193196,
            "logloss": 4.33456466400074,
            "mae": 0.3973815460050507,
            "precision": 0.8263473053892215,
            "recall": 0.2936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7385347009363543,
            "auditor_fn_violation": 0.02248486660867043,
            "auditor_fp_violation": 0.022590793572716844,
            "ave_precision_score": 0.738833504379764,
            "fpr": 0.12609649122807018,
            "logloss": 3.1208887962976837,
            "mae": 0.38672143488847655,
            "precision": 0.6925133689839572,
            "recall": 0.5351239669421488
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7022010211806228,
            "auditor_fn_violation": 0.017656538290865775,
            "auditor_fp_violation": 0.03267446751843804,
            "ave_precision_score": 0.7027557185868343,
            "fpr": 0.13611416026344675,
            "logloss": 3.2585897631368788,
            "mae": 0.3838066306619945,
            "precision": 0.675392670157068,
            "recall": 0.548936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7373746801873196,
            "auditor_fn_violation": 0.014725605335653187,
            "auditor_fp_violation": 0.031529246597802936,
            "ave_precision_score": 0.7348405826192752,
            "fpr": 0.32346491228070173,
            "logloss": 1.4460146137059473,
            "mae": 0.3865350163651512,
            "precision": 0.5991847826086957,
            "recall": 0.9111570247933884
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7510919557595441,
            "auditor_fn_violation": 0.015423780274190158,
            "auditor_fp_violation": 0.029413741347252415,
            "ave_precision_score": 0.7512612640488976,
            "fpr": 0.3391877058177827,
            "logloss": 1.260374973180263,
            "mae": 0.39426408035351007,
            "precision": 0.5824324324324325,
            "recall": 0.9170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8638501146187972,
            "auditor_fn_violation": 0.007747933884297523,
            "auditor_fp_violation": 0.012760800950975577,
            "ave_precision_score": 0.8643620784024625,
            "fpr": 0.17653508771929824,
            "logloss": 0.5194052724837347,
            "mae": 0.3063270076988071,
            "precision": 0.7209705372616985,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8690850033772147,
            "auditor_fn_violation": 0.017558446411472084,
            "auditor_fp_violation": 0.020393228641621314,
            "ave_precision_score": 0.869259611371017,
            "fpr": 0.16575192096597147,
            "logloss": 0.5045450693475111,
            "mae": 0.3118237883143145,
            "precision": 0.7264492753623188,
            "recall": 0.8531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7882820488999593,
            "auditor_fn_violation": 0.007421705089169206,
            "auditor_fp_violation": 0.011039207247089686,
            "ave_precision_score": 0.7495039266083563,
            "fpr": 0.10416666666666667,
            "logloss": 2.8085994110711896,
            "mae": 0.295324952166296,
            "precision": 0.7688564476885644,
            "recall": 0.6528925619834711
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7899780192877487,
            "auditor_fn_violation": 0.02438050307121004,
            "auditor_fp_violation": 0.020542574878469506,
            "ave_precision_score": 0.7590333532150804,
            "fpr": 0.10208562019758508,
            "logloss": 2.3892713262768837,
            "mae": 0.30404094916174695,
            "precision": 0.7526595744680851,
            "recall": 0.6021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7768133989450532,
            "auditor_fn_violation": 0.03756162099463535,
            "auditor_fp_violation": 0.04049588047220856,
            "ave_precision_score": 0.7748731143336879,
            "fpr": 0.1787280701754386,
            "logloss": 2.4933983099034958,
            "mae": 0.31805043646473835,
            "precision": 0.7041742286751361,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7892939419481675,
            "auditor_fn_violation": 0.036130508910012384,
            "auditor_fp_violation": 0.025560608436568922,
            "ave_precision_score": 0.7888302943327357,
            "fpr": 0.1778265642151482,
            "logloss": 2.3833533095711386,
            "mae": 0.3248133044221411,
            "precision": 0.7022058823529411,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7760431800519162,
            "auditor_fn_violation": 0.03075612585181963,
            "auditor_fp_violation": 0.03663510411542877,
            "ave_precision_score": 0.7390815735389844,
            "fpr": 0.24561403508771928,
            "logloss": 3.9004881961269886,
            "mae": 0.34783433853233503,
            "precision": 0.6381260096930533,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7668491407582403,
            "auditor_fn_violation": 0.03221150477614032,
            "auditor_fp_violation": 0.03512623490669594,
            "ave_precision_score": 0.7372149996085992,
            "fpr": 0.25686059275521406,
            "logloss": 3.56156335078253,
            "mae": 0.35779192571733187,
            "precision": 0.6207455429497569,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 21353,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7193783781039267,
            "auditor_fn_violation": 0.009104955052921571,
            "auditor_fp_violation": 0.006522585669781933,
            "ave_precision_score": 0.7056024711716129,
            "fpr": 0.04276315789473684,
            "logloss": 5.2110867376907155,
            "mae": 0.41833259275156903,
            "precision": 0.7833333333333333,
            "recall": 0.29132231404958675
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7168821485540451,
            "auditor_fn_violation": 0.016329962398112914,
            "auditor_fp_violation": 0.005329171551533164,
            "ave_precision_score": 0.7056543001871174,
            "fpr": 0.02854006586169045,
            "logloss": 5.079348288840498,
            "mae": 0.4062697773253293,
            "precision": 0.8266666666666667,
            "recall": 0.26382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7531017145630337,
            "auditor_fn_violation": 0.029657369146005513,
            "auditor_fp_violation": 0.021724872929988523,
            "ave_precision_score": 0.7495601577213041,
            "fpr": 0.14144736842105263,
            "logloss": 1.2026658378277206,
            "mae": 0.3036230242033704,
            "precision": 0.7399193548387096,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7502557352008615,
            "auditor_fn_violation": 0.034561038839713204,
            "auditor_fp_violation": 0.029110070665661077,
            "ave_precision_score": 0.745674825434813,
            "fpr": 0.13391877058177826,
            "logloss": 1.1193891356432202,
            "mae": 0.3022237043445999,
            "precision": 0.7436974789915967,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8414469908715876,
            "auditor_fn_violation": 0.003470711903726259,
            "auditor_fp_violation": 0.0072655353336612575,
            "ave_precision_score": 0.8417411599157095,
            "fpr": 0.0712719298245614,
            "logloss": 0.7379106790311356,
            "mae": 0.3202075260188921,
            "precision": 0.8337595907928389,
            "recall": 0.6735537190082644
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8422763139944298,
            "auditor_fn_violation": 0.016493448863769068,
            "auditor_fp_violation": 0.005909132771293664,
            "ave_precision_score": 0.8425146757050597,
            "fpr": 0.06805708013172337,
            "logloss": 0.7992091823778457,
            "mae": 0.3263219347066204,
            "precision": 0.8315217391304348,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8121768553140561,
            "auditor_fn_violation": 0.0075689611425257385,
            "auditor_fp_violation": 0.00883853910477128,
            "ave_precision_score": 0.8128458225563095,
            "fpr": 0.11074561403508772,
            "logloss": 1.0743937017290608,
            "mae": 0.2687704378221329,
            "precision": 0.7804347826086957,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8244487917796575,
            "auditor_fn_violation": 0.018833640843590172,
            "auditor_fp_violation": 0.020318555523197213,
            "ave_precision_score": 0.8246967552670347,
            "fpr": 0.11855104281009879,
            "logloss": 1.0982132546978056,
            "mae": 0.28139580842053197,
            "precision": 0.7583892617449665,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 21353,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7537288977864884,
            "auditor_fn_violation": 0.032067837465564734,
            "auditor_fp_violation": 0.05368195605837023,
            "ave_precision_score": 0.7538587663811059,
            "fpr": 0.3355263157894737,
            "logloss": 2.7040385686742,
            "mae": 0.39088129761383344,
            "precision": 0.5848032564450475,
            "recall": 0.890495867768595
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7530910097444379,
            "auditor_fn_violation": 0.036887217693906627,
            "auditor_fp_violation": 0.05462836433512301,
            "ave_precision_score": 0.7529167362405569,
            "fpr": 0.3468715697036224,
            "logloss": 2.707130970381682,
            "mae": 0.4048168029645353,
            "precision": 0.5683060109289617,
            "recall": 0.8851063829787233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7801916475639628,
            "auditor_fn_violation": 0.004562672176308548,
            "auditor_fp_violation": 0.008525987866863422,
            "ave_precision_score": 0.7767016756021365,
            "fpr": 0.09649122807017543,
            "logloss": 1.0246409168477968,
            "mae": 0.3135580037906047,
            "precision": 0.800453514739229,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7790652681174433,
            "auditor_fn_violation": 0.00712800990260878,
            "auditor_fp_violation": 0.003293084522502748,
            "ave_precision_score": 0.77445283650043,
            "fpr": 0.10757409440175632,
            "logloss": 1.003854767294057,
            "mae": 0.3194565705197843,
            "precision": 0.7782805429864253,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7684650719234213,
            "auditor_fn_violation": 0.030506923299985507,
            "auditor_fp_violation": 0.03791348991637974,
            "ave_precision_score": 0.7379776315612253,
            "fpr": 0.2532894736842105,
            "logloss": 3.636164250356823,
            "mae": 0.34975631271643703,
            "precision": 0.6367924528301887,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7573756161114815,
            "auditor_fn_violation": 0.02939019548310251,
            "auditor_fp_violation": 0.03351329554873542,
            "ave_precision_score": 0.7344988805568364,
            "fpr": 0.25686059275521406,
            "logloss": 3.313203652247566,
            "mae": 0.3617508332323522,
            "precision": 0.6261980830670927,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.748463627924166,
            "auditor_fn_violation": 0.007679969551979125,
            "auditor_fp_violation": 0.008705320544351533,
            "ave_precision_score": 0.7449630359598768,
            "fpr": 0.1425438596491228,
            "logloss": 1.4092154585868168,
            "mae": 0.27453171886272854,
            "precision": 0.74609375,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7600641791332312,
            "auditor_fn_violation": 0.01683677044164701,
            "auditor_fp_violation": 0.019945189931076714,
            "ave_precision_score": 0.7554609647505015,
            "fpr": 0.14489571899012074,
            "logloss": 1.3091502746337333,
            "mae": 0.2796008555091249,
            "precision": 0.7333333333333333,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8206448581802124,
            "auditor_fn_violation": 0.007294838335508192,
            "auditor_fp_violation": 0.005310809149040826,
            "ave_precision_score": 0.8212513639652655,
            "fpr": 0.10416666666666667,
            "logloss": 0.8726470931946193,
            "mae": 0.27084138560848897,
            "precision": 0.7893569844789357,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8326352053394435,
            "auditor_fn_violation": 0.019851927972534274,
            "auditor_fp_violation": 0.018966972079721024,
            "ave_precision_score": 0.832868555346121,
            "fpr": 0.10537870472008781,
            "logloss": 0.8256302170184169,
            "mae": 0.2801006659730431,
            "precision": 0.7746478873239436,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7724895749865854,
            "auditor_fn_violation": 0.028431745686530376,
            "auditor_fp_violation": 0.03348909657320873,
            "ave_precision_score": 0.7339223859438715,
            "fpr": 0.2236842105263158,
            "logloss": 3.942320026190623,
            "mae": 0.3447992585535786,
            "precision": 0.6494845360824743,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7607587616705489,
            "auditor_fn_violation": 0.029724174977228675,
            "auditor_fp_violation": 0.031524501494706925,
            "ave_precision_score": 0.7286746880143368,
            "fpr": 0.22941822173435786,
            "logloss": 3.6286791978558073,
            "mae": 0.35552388825689374,
            "precision": 0.6346153846153846,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7189858465224732,
            "auditor_fn_violation": 0.007920110192837468,
            "auditor_fp_violation": 0.014802631578947383,
            "ave_precision_score": 0.7188685259462142,
            "fpr": 0.3519736842105263,
            "logloss": 1.6159820786139873,
            "mae": 0.4014703170587062,
            "precision": 0.5847347994825356,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7293629780504092,
            "auditor_fn_violation": 0.009365438961160289,
            "auditor_fp_violation": 0.01776971308098798,
            "ave_precision_score": 0.7292078466111718,
            "fpr": 0.3545554335894621,
            "logloss": 1.5310989068108918,
            "mae": 0.40496772667605935,
            "precision": 0.5766710353866317,
            "recall": 0.9361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7479604968297462,
            "auditor_fn_violation": 0.008173843700159488,
            "auditor_fp_violation": 0.009732640596819152,
            "ave_precision_score": 0.7444397255448678,
            "fpr": 0.13048245614035087,
            "logloss": 1.3831182126115797,
            "mae": 0.2772064054459625,
            "precision": 0.7546391752577319,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7567047307000316,
            "auditor_fn_violation": 0.01265852348366303,
            "auditor_fp_violation": 0.019385141542895976,
            "ave_precision_score": 0.7521541635763769,
            "fpr": 0.12733260153677278,
            "logloss": 1.2970412234548165,
            "mae": 0.28581677473535777,
            "precision": 0.7483731019522777,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7802829691577826,
            "auditor_fn_violation": 0.025110555313904603,
            "auditor_fp_violation": 0.019403795704213807,
            "ave_precision_score": 0.7544913680029176,
            "fpr": 0.10855263157894737,
            "logloss": 3.3323999894998404,
            "mae": 0.2843808239722127,
            "precision": 0.7765237020316027,
            "recall": 0.7107438016528925
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7841733625850318,
            "auditor_fn_violation": 0.03762524231029731,
            "auditor_fp_violation": 0.025744802128681698,
            "ave_precision_score": 0.7658663910095578,
            "fpr": 0.10428100987925357,
            "logloss": 2.9525026172489,
            "mae": 0.28604251574529066,
            "precision": 0.7748815165876777,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8081004333785149,
            "auditor_fn_violation": 0.03287661302015369,
            "auditor_fp_violation": 0.04959829480242664,
            "ave_precision_score": 0.8074870565253095,
            "fpr": 0.2631578947368421,
            "logloss": 2.4122228411214386,
            "mae": 0.329402124768995,
            "precision": 0.6390977443609023,
            "recall": 0.878099173553719
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8235655895448879,
            "auditor_fn_violation": 0.03531774762360745,
            "auditor_fp_violation": 0.05870800570502626,
            "ave_precision_score": 0.8233673435724888,
            "fpr": 0.265642151481888,
            "logloss": 2.3139823970695783,
            "mae": 0.3292977091486736,
            "precision": 0.6294027565084227,
            "recall": 0.874468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8221627499710124,
            "auditor_fn_violation": 0.009444776714513558,
            "auditor_fp_violation": 0.012911952779144123,
            "ave_precision_score": 0.8226469991002566,
            "fpr": 0.15021929824561403,
            "logloss": 0.9235343426100395,
            "mae": 0.2657118688283615,
            "precision": 0.7375478927203065,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.83289766307418,
            "auditor_fn_violation": 0.019508606394656333,
            "auditor_fp_violation": 0.02770621603928802,
            "ave_precision_score": 0.8331328276483214,
            "fpr": 0.14709110867178923,
            "logloss": 0.8642537998018398,
            "mae": 0.2714637392245902,
            "precision": 0.7325349301397206,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8157177433401863,
            "auditor_fn_violation": 0.0014952153110047877,
            "auditor_fp_violation": 0.002546524020331205,
            "ave_precision_score": 0.8160389304914074,
            "fpr": 0.10855263157894737,
            "logloss": 0.8894105825560379,
            "mae": 0.27503802488906237,
            "precision": 0.7804878048780488,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8266955331197343,
            "auditor_fn_violation": 0.01768923558399701,
            "auditor_fp_violation": 0.01870810526918415,
            "ave_precision_score": 0.8269341531348596,
            "fpr": 0.10976948408342481,
            "logloss": 0.8415806690504595,
            "mae": 0.28608998940013347,
            "precision": 0.7607655502392344,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8419732439169316,
            "auditor_fn_violation": 0.03223774829636074,
            "auditor_fp_violation": 0.009809497458599778,
            "ave_precision_score": 0.8432662348022292,
            "fpr": 0.0668859649122807,
            "logloss": 0.5876811498314548,
            "mae": 0.3075953770200291,
            "precision": 0.8423772609819121,
            "recall": 0.6735537190082644
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8439483326053063,
            "auditor_fn_violation": 0.03227689936240279,
            "auditor_fp_violation": 0.019397587062633323,
            "ave_precision_score": 0.844253838066363,
            "fpr": 0.07464324917672886,
            "logloss": 0.5473410675324957,
            "mae": 0.31458840712440406,
            "precision": 0.8247422680412371,
            "recall": 0.6808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7793653555064263,
            "auditor_fn_violation": 0.03447150935189213,
            "auditor_fp_violation": 0.03553861288735859,
            "ave_precision_score": 0.741442987743841,
            "fpr": 0.22807017543859648,
            "logloss": 3.9097827365443365,
            "mae": 0.33925769169806014,
            "precision": 0.6510067114093959,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7711232137914499,
            "auditor_fn_violation": 0.030174930518252097,
            "auditor_fp_violation": 0.03677651082386852,
            "ave_precision_score": 0.7404614434799961,
            "fpr": 0.24368825466520308,
            "logloss": 3.571880040222216,
            "mae": 0.3512608253642028,
            "precision": 0.628140703517588,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6250080252009594,
            "auditor_fn_violation": 0.003013085399449042,
            "auditor_fp_violation": 0.0010247581570749303,
            "ave_precision_score": 0.6263468983573803,
            "fpr": 0.0021929824561403508,
            "logloss": 2.4148109068141412,
            "mae": 0.5267802804445864,
            "precision": 0.7142857142857143,
            "recall": 0.010330578512396695
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5994887500453462,
            "auditor_fn_violation": 0.0020085480066328915,
            "auditor_fp_violation": 0.001202237206627986,
            "ave_precision_score": 0.600871566658973,
            "fpr": 0.003293084522502744,
            "logloss": 2.450918785857853,
            "mae": 0.5149407588615021,
            "precision": 0.5714285714285714,
            "recall": 0.00851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5821918362947957,
            "auditor_fn_violation": 0.025217032767870115,
            "auditor_fp_violation": 0.020812838170191836,
            "ave_precision_score": 0.5836874765229949,
            "fpr": 0.09649122807017543,
            "logloss": 1.1718918907207667,
            "mae": 0.48571367748633365,
            "precision": 0.6223175965665236,
            "recall": 0.29958677685950413
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5695009319619766,
            "auditor_fn_violation": 0.019515612957470157,
            "auditor_fp_violation": 0.018347185196801008,
            "ave_precision_score": 0.570850279986217,
            "fpr": 0.10428100987925357,
            "logloss": 1.13508109620296,
            "mae": 0.48066664764911127,
            "precision": 0.602510460251046,
            "recall": 0.30638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 21353,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.79621775124256,
            "auditor_fn_violation": 0.012969860084094535,
            "auditor_fp_violation": 0.013173266109198233,
            "ave_precision_score": 0.774085003995484,
            "fpr": 0.12171052631578948,
            "logloss": 1.9596391419435413,
            "mae": 0.2644856649157482,
            "precision": 0.7677824267782427,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7972728818286324,
            "auditor_fn_violation": 0.023189387392857978,
            "auditor_fp_violation": 0.023835659400972244,
            "ave_precision_score": 0.7786461070461621,
            "fpr": 0.1251372118551043,
            "logloss": 1.6560366329018186,
            "mae": 0.2771984913996686,
            "precision": 0.7494505494505495,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7928650430113551,
            "auditor_fn_violation": 0.020479918805277664,
            "auditor_fp_violation": 0.02619281849483522,
            "ave_precision_score": 0.7501941615953166,
            "fpr": 0.19956140350877194,
            "logloss": 2.755093111276655,
            "mae": 0.31492473894875955,
            "precision": 0.6856649395509499,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.791378646354352,
            "auditor_fn_violation": 0.018371207697877017,
            "auditor_fp_violation": 0.015673887557218286,
            "ave_precision_score": 0.7587561437514525,
            "fpr": 0.1964873765093304,
            "logloss": 2.284057350654074,
            "mae": 0.32079984217002583,
            "precision": 0.6848591549295775,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.786919920803066,
            "auditor_fn_violation": 0.009279396839205452,
            "auditor_fp_violation": 0.011487538940809974,
            "ave_precision_score": 0.7747710461835893,
            "fpr": 0.21929824561403508,
            "logloss": 1.6957180941331278,
            "mae": 0.3039491230186908,
            "precision": 0.6850393700787402,
            "recall": 0.8987603305785123
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7992192731428618,
            "auditor_fn_violation": 0.011897143657892895,
            "auditor_fp_violation": 0.025926506716847014,
            "ave_precision_score": 0.7909252760091968,
            "fpr": 0.22283205268935236,
            "logloss": 1.4326570529849192,
            "mae": 0.30253468455622046,
            "precision": 0.6752,
            "recall": 0.8978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4309210526315789,
            "auc_prc": 0.5349565068490476,
            "auditor_fn_violation": 0.008436639118457299,
            "auditor_fp_violation": 0.02224237579931137,
            "ave_precision_score": 0.5584918203312095,
            "fpr": 0.2576754385964912,
            "logloss": 9.711495847177854,
            "mae": 0.5713496945071798,
            "precision": 0.45977011494252873,
            "recall": 0.4132231404958678
        },
        "train": {
            "accuracy": 0.43907793633369924,
            "auc_prc": 0.5343760287251812,
            "auditor_fn_violation": 0.013349837681294822,
            "auditor_fp_violation": 0.01867823602181452,
            "ave_precision_score": 0.5553208720343461,
            "fpr": 0.27442371020856204,
            "logloss": 9.017986008995264,
            "mae": 0.5620220081389443,
            "precision": 0.4553376906318083,
            "recall": 0.44468085106382976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8060689485009935,
            "auditor_fn_violation": 0.007711686240394379,
            "auditor_fp_violation": 0.013967453680931299,
            "ave_precision_score": 0.8064832517880651,
            "fpr": 0.19736842105263158,
            "logloss": 1.0594887791899548,
            "mae": 0.2861819392197536,
            "precision": 0.6964586846543002,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8156057571262699,
            "auditor_fn_violation": 0.016839105962584956,
            "auditor_fp_violation": 0.03700799749098323,
            "ave_precision_score": 0.8158879414855216,
            "fpr": 0.20417124039517015,
            "logloss": 1.0340076171000625,
            "mae": 0.2899302380458551,
            "precision": 0.6825938566552902,
            "recall": 0.851063829787234
        }
    }
]