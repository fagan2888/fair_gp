[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 16695,
        "test": {
            "accuracy": 0.4451754385964912,
            "auc_prc": 0.7867330287339808,
            "auditor_fn_violation": 0.0006206140350877199,
            "auditor_fp_violation": 0.003169711292795095,
            "ave_precision_score": 0.7879515504572073,
            "fpr": 0.007675438596491228,
            "logloss": 0.6933699551337976,
            "mae": 0.5001103060091274,
            "precision": 0.125,
            "recall": 0.002
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.8130730495122034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018831351317594102,
            "ave_precision_score": 0.8140504641776295,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6931331233200311,
            "mae": 0.4999919636123921,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 16695,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.9357326726484,
            "mae": 0.5482456140350878,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.21251864246921,
            "mae": 0.4983534577387486,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6677732793522266,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.557085020242915,
            "fpr": 0.4517543859649123,
            "logloss": 0.6883758739039469,
            "mae": 0.49532708408016907,
            "precision": 0.5482456140350878,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6127354563493024,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5062161403050657,
            "fpr": 0.5016465422612514,
            "logloss": 0.6913659842103834,
            "mae": 0.4968638314112089,
            "precision": 0.4983534577387486,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 16695,
        "test": {
            "accuracy": 0.4451754385964912,
            "auc_prc": 0.7867330287339808,
            "auditor_fn_violation": 0.0006206140350877199,
            "auditor_fp_violation": 0.003169711292795095,
            "ave_precision_score": 0.7879515504572073,
            "fpr": 0.007675438596491228,
            "logloss": 0.6933699553313548,
            "mae": 0.5001103061071613,
            "precision": 0.125,
            "recall": 0.002
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.8130730495122034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018831351317594102,
            "ave_precision_score": 0.8140504641776295,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6931331234516634,
            "mae": 0.49999196367781984,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7755468416659571,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.5519909209009749,
            "fpr": 0.4440789473684211,
            "logloss": 0.6977987304442316,
            "mae": 0.4960252096018583,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.750551876379691,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.5011037527593819,
            "fpr": 0.4961580680570801,
            "logloss": 0.6894017279834819,
            "mae": 0.4972412680470881,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7700233397732373,
            "auditor_fn_violation": 0.0020526315789473684,
            "auditor_fp_violation": 0.0005748594787940791,
            "ave_precision_score": 0.547290283550924,
            "fpr": 0.44627192982456143,
            "logloss": 0.6929904023840353,
            "mae": 0.49992084441085655,
            "precision": 0.5472747497219133,
            "recall": 0.984
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.7477901033380562,
            "auditor_fn_violation": 0.0011750654023027413,
            "auditor_fp_violation": 3.6029371143356984e-05,
            "ave_precision_score": 0.49998549301972467,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931435731727604,
            "mae": 0.49999742937794633,
            "precision": 0.5,
            "recall": 0.9911894273127754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6370178213886798,
            "auditor_fn_violation": 0.008903508771929834,
            "auditor_fp_violation": 0.00039388519843297986,
            "ave_precision_score": 0.5548734368201591,
            "fpr": 0.3333333333333333,
            "logloss": 0.6893895485722801,
            "mae": 0.4975278701698571,
            "precision": 0.55359765051395,
            "recall": 0.754
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.583225244668131,
            "auditor_fn_violation": 0.002296938543595898,
            "auditor_fp_violation": 0.011630281005075353,
            "ave_precision_score": 0.49994416753734805,
            "fpr": 0.3699231613611416,
            "logloss": 0.6925677447793148,
            "mae": 0.49912727592281925,
            "precision": 0.4947526236881559,
            "recall": 0.7268722466960352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7872127044578205,
            "auditor_fn_violation": 0.013809210526315792,
            "auditor_fp_violation": 0.02354794753874979,
            "ave_precision_score": 0.7866604245159716,
            "fpr": 0.16885964912280702,
            "logloss": 1.2739751141594735,
            "mae": 0.30831791643204254,
            "precision": 0.7121495327102804,
            "recall": 0.762
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7799690017645744,
            "auditor_fn_violation": 0.015261343249660293,
            "auditor_fp_violation": 0.020620810084380787,
            "ave_precision_score": 0.7797431939788474,
            "fpr": 0.15697036223929747,
            "logloss": 1.073921258412745,
            "mae": 0.2712896515936143,
            "precision": 0.7157057654075547,
            "recall": 0.7929515418502202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7178944678030367,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.7180690766252221,
            "fpr": 0.4440789473684211,
            "logloss": 0.6945808303347923,
            "mae": 0.4491150073233273,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.7317256056511486,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.7319917013169073,
            "fpr": 0.4961580680570801,
            "logloss": 0.6916276712010488,
            "mae": 0.4549261591776502,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7700233397732373,
            "auditor_fn_violation": 0.0020526315789473684,
            "auditor_fp_violation": 0.0005748594787940791,
            "ave_precision_score": 0.547290283550924,
            "fpr": 0.44627192982456143,
            "logloss": 0.6929904023840353,
            "mae": 0.49992084441085655,
            "precision": 0.5472747497219133,
            "recall": 0.984
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.7477901033380562,
            "auditor_fn_violation": 0.0011750654023027413,
            "auditor_fp_violation": 3.6029371143356984e-05,
            "ave_precision_score": 0.49998549301972467,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931435731727604,
            "mae": 0.49999742937794633,
            "precision": 0.5,
            "recall": 0.9911894273127754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5449696580990273,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5468295024421984,
            "fpr": 0.4517543859649123,
            "logloss": 0.6913320706511203,
            "mae": 0.4989625567799075,
            "precision": 0.5482456140350878,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5012532927725569,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5010495957910793,
            "fpr": 0.5016465422612514,
            "logloss": 0.6933822558318493,
            "mae": 0.4999879748447012,
            "precision": 0.4983534577387486,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7755468416659571,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.5519909209009749,
            "fpr": 0.4440789473684211,
            "logloss": 0.6977987304442316,
            "mae": 0.4960252096018583,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.750551876379691,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.5011037527593819,
            "fpr": 0.4961580680570801,
            "logloss": 0.6894017279834819,
            "mae": 0.4972412680470881,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.714546768948875,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.7153944724410266,
            "fpr": 0.4440789473684211,
            "logloss": 0.8798231086135077,
            "mae": 0.45474853855149266,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6943377341603769,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.6953105981836937,
            "fpr": 0.4961580680570801,
            "logloss": 0.9399337196756546,
            "mae": 0.4854932078267688,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6896785744703908,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.6900542710104918,
            "fpr": 0.4440789473684211,
            "logloss": 1.2148733760918886,
            "mae": 0.4477294010453318,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6870255613622848,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.6875204087882778,
            "fpr": 0.4961580680570801,
            "logloss": 1.3397963585467934,
            "mae": 0.4905038218859391,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7386873795134637,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.7385488374352469,
            "fpr": 0.4440789473684211,
            "logloss": 0.6939203769694792,
            "mae": 0.4491474057421121,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.7294441011367144,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.730814986172446,
            "fpr": 0.4961580680570801,
            "logloss": 0.6943686239663879,
            "mae": 0.4563594080331918,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.8141426547641537,
            "auditor_fn_violation": 0.0034561403508771927,
            "auditor_fp_violation": 0.020814703628002047,
            "ave_precision_score": 0.8157065364066207,
            "fpr": 0.37390350877192985,
            "logloss": 0.6474522493774066,
            "mae": 0.4542153586758118,
            "precision": 0.5866666666666667,
            "recall": 0.968
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.831246090209798,
            "auditor_fn_violation": 0.004896105842928089,
            "auditor_fp_violation": 0.02535506945261778,
            "ave_precision_score": 0.8328987204599356,
            "fpr": 0.40285400658616904,
            "logloss": 0.6199044571841643,
            "mae": 0.4473412033516646,
            "precision": 0.5480295566502463,
            "recall": 0.9801762114537445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7897148827980233,
            "auditor_fn_violation": 0.02064035087719298,
            "auditor_fp_violation": 0.02656595980241868,
            "ave_precision_score": 0.7861515738868066,
            "fpr": 0.23355263157894737,
            "logloss": 1.9391752113636067,
            "mae": 0.31169697012701003,
            "precision": 0.6677067082683308,
            "recall": 0.856
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8053953925662509,
            "auditor_fn_violation": 0.016675773826506188,
            "auditor_fp_violation": 0.031326337230109996,
            "ave_precision_score": 0.8044066087386846,
            "fpr": 0.23380900109769484,
            "logloss": 1.6389545754317087,
            "mae": 0.29618223511162145,
            "precision": 0.6519607843137255,
            "recall": 0.8788546255506607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.719934495636386,
            "auditor_fn_violation": 0.0063815789473684265,
            "auditor_fp_violation": 0.0016873190257196387,
            "ave_precision_score": 0.7199878814062863,
            "fpr": 0.010964912280701754,
            "logloss": 0.9026250660113279,
            "mae": 0.4536238470903062,
            "precision": 0.9074074074074074,
            "recall": 0.196
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7336092343559918,
            "auditor_fn_violation": 0.0029207386954356223,
            "auditor_fp_violation": 0.0024331835312146467,
            "ave_precision_score": 0.7413944636426588,
            "fpr": 0.006586169045005488,
            "logloss": 0.7628418580622154,
            "mae": 0.4140635550602136,
            "precision": 0.9491525423728814,
            "recall": 0.24669603524229075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7564113628565206,
            "auditor_fn_violation": 0.014250000000000006,
            "auditor_fp_violation": 0.010837165729858628,
            "ave_precision_score": 0.7574074001894164,
            "fpr": 0.17214912280701755,
            "logloss": 0.6236781495064785,
            "mae": 0.4407892541943543,
            "precision": 0.685370741482966,
            "recall": 0.684
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.761899981994149,
            "auditor_fn_violation": 0.017696098105871947,
            "auditor_fp_violation": 0.015504639382024234,
            "ave_precision_score": 0.7634293673413599,
            "fpr": 0.19319429198682767,
            "logloss": 0.6018868140806725,
            "mae": 0.4313929959902648,
            "precision": 0.6400817995910021,
            "recall": 0.6894273127753304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7428029615470438,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0031697112927951037,
            "ave_precision_score": 0.7433323266832691,
            "fpr": 0.4440789473684211,
            "logloss": 0.6670614856546627,
            "mae": 0.4498247803973132,
            "precision": 0.5519911504424779,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.7373997201041738,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015804884141552462,
            "ave_precision_score": 0.738671941789538,
            "fpr": 0.4961580680570801,
            "logloss": 0.650851165732297,
            "mae": 0.4487054057411122,
            "precision": 0.5011037527593819,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7905816635699735,
            "auditor_fn_violation": 0.03439473684210527,
            "auditor_fp_violation": 0.03643970362800205,
            "ave_precision_score": 0.7880141087219037,
            "fpr": 0.20394736842105263,
            "logloss": 2.2991554151851457,
            "mae": 0.3083047926759277,
            "precision": 0.6889632107023411,
            "recall": 0.824
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8066839481096109,
            "auditor_fn_violation": 0.027340822158928805,
            "auditor_fp_violation": 0.03522231322974489,
            "ave_precision_score": 0.8066758255663361,
            "fpr": 0.21734357848518113,
            "logloss": 1.9199256393236401,
            "mae": 0.2899992811079348,
            "precision": 0.6638370118845501,
            "recall": 0.8612334801762115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5713871166839815,
            "auditor_fn_violation": 0.0006206140350877193,
            "auditor_fp_violation": 0.0028476835292113745,
            "ave_precision_score": 0.5707584240962159,
            "fpr": 0.4451754385964912,
            "logloss": 0.6921696607780786,
            "mae": 0.4994925841231618,
            "precision": 0.5513812154696133,
            "recall": 0.998
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5013601990207184,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002010438909799274,
            "ave_precision_score": 0.4957762673009996,
            "fpr": 0.4983534577387486,
            "logloss": 0.6931472030801956,
            "mae": 0.49998240822233037,
            "precision": 0.5,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7849963676525806,
            "auditor_fn_violation": 0.04012061403508773,
            "auditor_fp_violation": 0.026166751831033893,
            "ave_precision_score": 0.7856975910588473,
            "fpr": 0.1074561403508772,
            "logloss": 1.9423592867429649,
            "mae": 0.31486469470540074,
            "precision": 0.7672209026128266,
            "recall": 0.646
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7938017518744842,
            "auditor_fn_violation": 0.029889215027297307,
            "auditor_fp_violation": 0.023536787188916407,
            "ave_precision_score": 0.7943184274223939,
            "fpr": 0.11306256860592755,
            "logloss": 1.5335113230326112,
            "mae": 0.2729511645186452,
            "precision": 0.7541766109785203,
            "recall": 0.6960352422907489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7202517524600208,
            "auditor_fn_violation": 0.0780701754385965,
            "auditor_fp_violation": 0.03991015159257367,
            "ave_precision_score": 0.6191716280864125,
            "fpr": 0.07675438596491228,
            "logloss": 0.6771815540087088,
            "mae": 0.48500027316377353,
            "precision": 0.7244094488188977,
            "recall": 0.368
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6780902140945847,
            "auditor_fn_violation": 0.0699913441684357,
            "auditor_fp_violation": 0.048750141115036984,
            "ave_precision_score": 0.5709473915134003,
            "fpr": 0.09440175631174534,
            "logloss": 0.6705393767854373,
            "mae": 0.4815763124192193,
            "precision": 0.6627450980392157,
            "recall": 0.3722466960352423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 16695,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.5630106332924207,
            "auditor_fn_violation": 0.03596929824561404,
            "auditor_fp_violation": 0.013290964060637041,
            "ave_precision_score": 0.547758849509464,
            "fpr": 0.23026315789473684,
            "logloss": 5.383638051446864,
            "mae": 0.3853548672351951,
            "precision": 0.6328671328671329,
            "recall": 0.724
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.542289458594677,
            "auditor_fn_violation": 0.028750417075682926,
            "auditor_fp_violation": 0.02817737019218067,
            "ave_precision_score": 0.5270082446422933,
            "fpr": 0.2349066959385291,
            "logloss": 5.237122603421762,
            "mae": 0.3634926232499471,
            "precision": 0.6130198915009042,
            "recall": 0.7466960352422908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7582124468037454,
            "auditor_fn_violation": 0.014250000000000006,
            "auditor_fp_violation": 0.010837165729858628,
            "ave_precision_score": 0.7592412051845643,
            "fpr": 0.17214912280701755,
            "logloss": 0.6240991706134338,
            "mae": 0.4408746040467042,
            "precision": 0.685370741482966,
            "recall": 0.684
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7630351530581265,
            "auditor_fn_violation": 0.017696098105871947,
            "auditor_fp_violation": 0.015504639382024234,
            "ave_precision_score": 0.7645474970058642,
            "fpr": 0.19319429198682767,
            "logloss": 0.6011956138429294,
            "mae": 0.43112320948543453,
            "precision": 0.6400817995910021,
            "recall": 0.6894273127753304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 16695,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7437301123472788,
            "auditor_fn_violation": 0.004484649122807026,
            "auditor_fp_violation": 0.0023899250553568395,
            "ave_precision_score": 0.744045779712607,
            "fpr": 0.01206140350877193,
            "logloss": 0.6492293017595724,
            "mae": 0.4442406472374211,
            "precision": 0.8962264150943396,
            "recall": 0.19
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7491329077332338,
            "auditor_fn_violation": 0.005249109029628097,
            "auditor_fp_violation": 0.0012466162415601199,
            "ave_precision_score": 0.7503854670089054,
            "fpr": 0.0043907793633369925,
            "logloss": 0.5917339308376723,
            "mae": 0.41912970929912624,
            "precision": 0.9646017699115044,
            "recall": 0.24008810572687225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7052896853548477,
            "auditor_fn_violation": 0.10685745614035087,
            "auditor_fp_violation": 0.0991739056378811,
            "ave_precision_score": 0.697261180808795,
            "fpr": 0.26096491228070173,
            "logloss": 1.003627453862285,
            "mae": 0.4532088278149451,
            "precision": 0.5711711711711712,
            "recall": 0.634
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7389598339556431,
            "auditor_fn_violation": 0.09136496177410698,
            "auditor_fp_violation": 0.1157479577351457,
            "ave_precision_score": 0.7277472677466903,
            "fpr": 0.2711306256860593,
            "logloss": 0.9518160234748027,
            "mae": 0.4335663197132729,
            "precision": 0.5589285714285714,
            "recall": 0.6894273127753304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7767028821866548,
            "auditor_fn_violation": 0.05060307017543861,
            "auditor_fp_violation": 0.026518054845852495,
            "ave_precision_score": 0.771911448769639,
            "fpr": 0.11074561403508772,
            "logloss": 2.2548077877699524,
            "mae": 0.30787574201842377,
            "precision": 0.7651162790697674,
            "recall": 0.658
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7889768040985554,
            "auditor_fn_violation": 0.037737491356257584,
            "auditor_fp_violation": 0.02866736963973031,
            "ave_precision_score": 0.7862334503521011,
            "fpr": 0.11964873765093303,
            "logloss": 1.7554405304556058,
            "mae": 0.26665016419828647,
            "precision": 0.7488479262672811,
            "recall": 0.7158590308370044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7806389108752994,
            "auditor_fn_violation": 0.042324561403508786,
            "auditor_fp_violation": 0.026166751831033893,
            "ave_precision_score": 0.7815372354391983,
            "fpr": 0.1074561403508772,
            "logloss": 1.9563141259925088,
            "mae": 0.31641822504878536,
            "precision": 0.7655502392344498,
            "recall": 0.64
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7875916716445331,
            "auditor_fn_violation": 0.032132961309883606,
            "auditor_fp_violation": 0.023969139642636687,
            "ave_precision_score": 0.7881374101090344,
            "fpr": 0.1119648737650933,
            "logloss": 1.540500735946407,
            "mae": 0.27582639004316745,
            "precision": 0.7530266343825666,
            "recall": 0.6850220264317181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7716959208028513,
            "auditor_fn_violation": 0.053399122807017536,
            "auditor_fp_violation": 0.02847683529211379,
            "ave_precision_score": 0.7723821604548161,
            "fpr": 0.13706140350877194,
            "logloss": 2.2176619874695067,
            "mae": 0.3034714841907108,
            "precision": 0.7368421052631579,
            "recall": 0.7
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7974232518216698,
            "auditor_fn_violation": 0.040486564118434994,
            "auditor_fp_violation": 0.03081231820179811,
            "ave_precision_score": 0.7977082292399298,
            "fpr": 0.132821075740944,
            "logloss": 1.713853815661465,
            "mae": 0.26942316153423707,
            "precision": 0.7414529914529915,
            "recall": 0.76431718061674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7806682229109767,
            "auditor_fn_violation": 0.03206140350877193,
            "auditor_fp_violation": 0.016809316981774836,
            "ave_precision_score": 0.7811269095132052,
            "fpr": 0.13815789473684212,
            "logloss": 1.0490004038140388,
            "mae": 0.2994724536535407,
            "precision": 0.7459677419354839,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8195593364239632,
            "auditor_fn_violation": 0.022098966619438394,
            "auditor_fp_violation": 0.01315312242540119,
            "ave_precision_score": 0.8198929042419203,
            "fpr": 0.132821075740944,
            "logloss": 0.8294710445761928,
            "mae": 0.2600860119289795,
            "precision": 0.7463312368972747,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7223131581721851,
            "auditor_fn_violation": 0.05600877192982457,
            "auditor_fp_violation": 0.05614194770907854,
            "ave_precision_score": 0.7170288756769374,
            "fpr": 0.26206140350877194,
            "logloss": 0.6377183320208666,
            "mae": 0.4527981530817781,
            "precision": 0.6151368760064412,
            "recall": 0.764
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7414235712260393,
            "auditor_fn_violation": 0.04629419188866376,
            "auditor_fp_violation": 0.0676727668395276,
            "ave_precision_score": 0.733816251013338,
            "fpr": 0.2601536772777168,
            "logloss": 0.6140071600711194,
            "mae": 0.44285233889662473,
            "precision": 0.6023489932885906,
            "recall": 0.7907488986784141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7218904780904654,
            "auditor_fn_violation": 0.04179824561403509,
            "auditor_fp_violation": 0.05858776188042923,
            "ave_precision_score": 0.7166370629224954,
            "fpr": 0.31469298245614036,
            "logloss": 0.6402731898455613,
            "mae": 0.45507099894447284,
            "precision": 0.5957746478873239,
            "recall": 0.846
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7394867603277742,
            "auditor_fn_violation": 0.029055063661465107,
            "auditor_fp_violation": 0.07179452689832753,
            "ave_precision_score": 0.7319481476773944,
            "fpr": 0.3227222832052689,
            "logloss": 0.6220894535500691,
            "mae": 0.4470005948771237,
            "precision": 0.5757575757575758,
            "recall": 0.8788546255506607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7857447392250791,
            "auditor_fn_violation": 0.003364035087719303,
            "auditor_fp_violation": 0.004633473854539261,
            "ave_precision_score": 0.786777296370804,
            "fpr": 0.0581140350877193,
            "logloss": 0.5889804682793944,
            "mae": 0.39035391415420334,
            "precision": 0.8393939393939394,
            "recall": 0.554
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8260288552437649,
            "auditor_fn_violation": 0.005851148711054809,
            "auditor_fp_violation": 0.007429256329760023,
            "ave_precision_score": 0.8264552712126831,
            "fpr": 0.04939626783754116,
            "logloss": 0.5341837284321093,
            "mae": 0.37249234917396773,
            "precision": 0.8557692307692307,
            "recall": 0.5881057268722467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 16695,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7151885519803745,
            "auditor_fn_violation": 0.03991228070175439,
            "auditor_fp_violation": 0.04727953074433658,
            "ave_precision_score": 0.7155046818215514,
            "fpr": 0.3475877192982456,
            "logloss": 0.6424855345211753,
            "mae": 0.4566365046459332,
            "precision": 0.5784574468085106,
            "recall": 0.87
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7298056383611582,
            "auditor_fn_violation": 0.026704932856859626,
            "auditor_fp_violation": 0.0607118923346312,
            "ave_precision_score": 0.7298569224550723,
            "fpr": 0.3534577387486279,
            "logloss": 0.6259465979957555,
            "mae": 0.4492999962669042,
            "precision": 0.5582990397805213,
            "recall": 0.8964757709251101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6677732793522266,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.557085020242915,
            "fpr": 0.4517543859649123,
            "logloss": 0.6883758739039469,
            "mae": 0.49532708408016907,
            "precision": 0.5482456140350878,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6127354563493024,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5062161403050657,
            "fpr": 0.5016465422612514,
            "logloss": 0.6913659842103834,
            "mae": 0.4968638314112089,
            "precision": 0.4983534577387486,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7757188485137813,
            "auditor_fn_violation": 0.05293421052631579,
            "auditor_fp_violation": 0.023957801056038154,
            "ave_precision_score": 0.7771617485823021,
            "fpr": 0.10855263157894737,
            "logloss": 1.7409496438482581,
            "mae": 0.3115988027701374,
            "precision": 0.7648456057007126,
            "recall": 0.644
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8022392415648836,
            "auditor_fn_violation": 0.04192033733564801,
            "auditor_fp_violation": 0.02227575919889894,
            "ave_precision_score": 0.8025607547760991,
            "fpr": 0.10976948408342481,
            "logloss": 1.4105083772185314,
            "mae": 0.2713534504658727,
            "precision": 0.7596153846153846,
            "recall": 0.6960352422907489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7811384205411209,
            "auditor_fn_violation": 0.042324561403508786,
            "auditor_fp_violation": 0.02569834781127576,
            "ave_precision_score": 0.78227846335546,
            "fpr": 0.10635964912280702,
            "logloss": 1.9533739804949353,
            "mae": 0.31630087773868093,
            "precision": 0.7673860911270983,
            "recall": 0.64
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7897553621227569,
            "auditor_fn_violation": 0.033690043859437045,
            "auditor_fp_violation": 0.0242141393664115,
            "ave_precision_score": 0.7902726107736117,
            "fpr": 0.1119648737650933,
            "logloss": 1.5372555337744287,
            "mae": 0.27601048911114695,
            "precision": 0.7524271844660194,
            "recall": 0.6828193832599119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7808547045653011,
            "auditor_fn_violation": 0.042324561403508786,
            "auditor_fp_violation": 0.02569834781127576,
            "ave_precision_score": 0.7818112030638918,
            "fpr": 0.10635964912280702,
            "logloss": 1.9568791139824364,
            "mae": 0.3166043724098659,
            "precision": 0.7673860911270983,
            "recall": 0.64
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7894607711785455,
            "auditor_fn_violation": 0.03527372253949526,
            "auditor_fp_violation": 0.026486391706519157,
            "ave_precision_score": 0.7899856198735411,
            "fpr": 0.11086717892425905,
            "logloss": 1.5365976085461024,
            "mae": 0.2758944140823479,
            "precision": 0.7536585365853659,
            "recall": 0.6806167400881057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8206909814255793,
            "auditor_fn_violation": 0.02692763157894737,
            "auditor_fp_violation": 0.0018070814171350716,
            "ave_precision_score": 0.8210858666640716,
            "fpr": 0.01425438596491228,
            "logloss": 0.5949093878360019,
            "mae": 0.405450872439695,
            "precision": 0.9244186046511628,
            "recall": 0.318
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8306124978426556,
            "auditor_fn_violation": 0.019630362142584276,
            "auditor_fp_violation": 0.003417986342466378,
            "ave_precision_score": 0.830995683846772,
            "fpr": 0.010976948408342482,
            "logloss": 0.5535031050974712,
            "mae": 0.3888163636269868,
            "precision": 0.9408284023668639,
            "recall": 0.3502202643171806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7279006973315639,
            "auditor_fn_violation": 0.0063815789473684265,
            "auditor_fp_violation": 0.0016873190257196387,
            "ave_precision_score": 0.7275809435106159,
            "fpr": 0.010964912280701754,
            "logloss": 0.9396096340544973,
            "mae": 0.4517018422850219,
            "precision": 0.9074074074074074,
            "recall": 0.196
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7427312012616524,
            "auditor_fn_violation": 0.0029207386954356223,
            "auditor_fp_violation": 0.0024331835312146467,
            "ave_precision_score": 0.747015727543346,
            "fpr": 0.006586169045005488,
            "logloss": 0.7796002093067785,
            "mae": 0.4141891802765445,
            "precision": 0.9491525423728814,
            "recall": 0.24669603524229075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7807776459376325,
            "auditor_fn_violation": 0.042324561403508786,
            "auditor_fp_violation": 0.02569834781127576,
            "ave_precision_score": 0.7816870266101761,
            "fpr": 0.10635964912280702,
            "logloss": 1.950980002838749,
            "mae": 0.3165245931332719,
            "precision": 0.7673860911270983,
            "recall": 0.64
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7893456394854009,
            "auditor_fn_violation": 0.033690043859437045,
            "auditor_fp_violation": 0.026486391706519157,
            "ave_precision_score": 0.7898708608672855,
            "fpr": 0.11086717892425905,
            "logloss": 1.5328477181770945,
            "mae": 0.27580528036840635,
            "precision": 0.754257907542579,
            "recall": 0.6828193832599119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.7840962285954406,
            "auditor_fn_violation": 0.007991228070175455,
            "auditor_fp_violation": 0.003044626128427866,
            "ave_precision_score": 0.6482882655741149,
            "fpr": 0.020833333333333332,
            "logloss": 0.6744772760348788,
            "mae": 0.4299993724153753,
            "precision": 0.8862275449101796,
            "recall": 0.296
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.789672398284196,
            "auditor_fn_violation": 0.011085750760407558,
            "auditor_fp_violation": 0.005080141331213205,
            "ave_precision_score": 0.6398474575650562,
            "fpr": 0.01756311745334797,
            "logloss": 0.6525077212365649,
            "mae": 0.4231872346607966,
            "precision": 0.9075144508670521,
            "recall": 0.3458149779735683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7859103500424702,
            "auditor_fn_violation": 0.03478728070175438,
            "auditor_fp_violation": 0.024963805143927785,
            "ave_precision_score": 0.7862715057043104,
            "fpr": 0.15789473684210525,
            "logloss": 2.2597617352418515,
            "mae": 0.3148785430203113,
            "precision": 0.710261569416499,
            "recall": 0.706
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8086333951646721,
            "auditor_fn_violation": 0.023037084677243868,
            "auditor_fp_violation": 0.028165360401799556,
            "ave_precision_score": 0.8089316390379665,
            "fpr": 0.150384193194292,
            "logloss": 1.8298504425649178,
            "mae": 0.2730223026150341,
            "precision": 0.7157676348547718,
            "recall": 0.7599118942731278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5461805577150224,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.547998083279073,
            "fpr": 0.4517543859649123,
            "logloss": 0.6916904242150819,
            "mae": 0.49920066334960755,
            "precision": 0.5482456140350878,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5060924092941947,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.505776321425212,
            "fpr": 0.5016465422612514,
            "logloss": 0.6932462538985341,
            "mae": 0.49997929239116046,
            "precision": 0.4983534577387486,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 16695,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 5.915183788568398,
            "mae": 0.5482221555940798,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 5.295610863600436,
            "mae": 0.49832397591425637,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7698166783237163,
            "auditor_fn_violation": 0.003453947368421053,
            "auditor_fp_violation": 0.0010592318174076029,
            "ave_precision_score": 0.5459899457947194,
            "fpr": 0.44956140350877194,
            "logloss": 0.6939358397554607,
            "mae": 0.4997495501383878,
            "precision": 0.5459579180509413,
            "recall": 0.986
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7488968650415625,
            "auditor_fn_violation": 0.00052466911995822,
            "auditor_fp_violation": 0.0012201947027216712,
            "ave_precision_score": 0.49889747748749924,
            "fpr": 0.4994511525795829,
            "logloss": 0.6934324603255415,
            "mae": 0.49982182048547413,
            "precision": 0.4988986784140969,
            "recall": 0.9977973568281938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7748353381730376,
            "auditor_fn_violation": 0.03910087719298246,
            "auditor_fp_violation": 0.02158916709248851,
            "ave_precision_score": 0.7753904569415444,
            "fpr": 0.14364035087719298,
            "logloss": 1.50491310142102,
            "mae": 0.2999755865402354,
            "precision": 0.7385229540918163,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8106863728707858,
            "auditor_fn_violation": 0.03350145311585758,
            "auditor_fp_violation": 0.021093995825396877,
            "ave_precision_score": 0.8109945877419635,
            "fpr": 0.14050493962678376,
            "logloss": 1.1649131578858036,
            "mae": 0.2698200816976799,
            "precision": 0.7338877338877339,
            "recall": 0.7775330396475771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7642032305088525,
            "auditor_fn_violation": 0.022192982456140358,
            "auditor_fp_violation": 0.01990717083972067,
            "ave_precision_score": 0.7640704700732852,
            "fpr": 0.12828947368421054,
            "logloss": 0.6315758118561556,
            "mae": 0.4277547574723333,
            "precision": 0.7167070217917676,
            "recall": 0.592
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7652362387156605,
            "auditor_fn_violation": 0.013933954554466457,
            "auditor_fp_violation": 0.025383892949532468,
            "ave_precision_score": 0.7684024338270709,
            "fpr": 0.12952799121844127,
            "logloss": 0.5776847791600649,
            "mae": 0.404840089977769,
            "precision": 0.6997455470737913,
            "recall": 0.6057268722466961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6677732793522266,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.557085020242915,
            "fpr": 0.4517543859649123,
            "logloss": 0.6881265702933866,
            "mae": 0.49500878678079235,
            "precision": 0.5482456140350878,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6127354563493024,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5062161403050657,
            "fpr": 0.5016465422612514,
            "logloss": 0.6915944190567527,
            "mae": 0.49678056987266245,
            "precision": 0.4983534577387486,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7177193587254006,
            "auditor_fn_violation": 0.004767543859649133,
            "auditor_fp_violation": 0.0011656872764435361,
            "ave_precision_score": 0.7178946844106892,
            "fpr": 0.009868421052631578,
            "logloss": 0.6643790630716259,
            "mae": 0.4546464797958993,
            "precision": 0.912621359223301,
            "recall": 0.188
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7308488508101221,
            "auditor_fn_violation": 0.005249109029628097,
            "auditor_fp_violation": 0.0012466162415601199,
            "ave_precision_score": 0.7311128795180671,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6153765231038557,
            "mae": 0.43400482906991644,
            "precision": 0.9646017699115044,
            "recall": 0.24008810572687225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8167011469539639,
            "auditor_fn_violation": 0.006798245614035092,
            "auditor_fp_violation": 0.0137061403508772,
            "ave_precision_score": 0.8182660240065361,
            "fpr": 0.15679824561403508,
            "logloss": 0.647976979619719,
            "mae": 0.4550359394039637,
            "precision": 0.7390510948905109,
            "recall": 0.81
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8334257594895642,
            "auditor_fn_violation": 0.005304719120683573,
            "auditor_fp_violation": 0.02046948672557869,
            "ave_precision_score": 0.8351285835495332,
            "fpr": 0.18331503841931943,
            "logloss": 0.6166237862383311,
            "mae": 0.44660851435630733,
            "precision": 0.6913123844731978,
            "recall": 0.8237885462555066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5922454547309084,
            "auditor_fn_violation": 0.008421052631578949,
            "auditor_fp_violation": 0.004769204564810092,
            "ave_precision_score": 0.556610386286533,
            "fpr": 0.32894736842105265,
            "logloss": 0.6938614324447692,
            "mae": 0.49766859595190016,
            "precision": 0.5575221238938053,
            "recall": 0.756
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5689111705207262,
            "auditor_fn_violation": 0.004874345372515078,
            "auditor_fp_violation": 0.013986601877850832,
            "ave_precision_score": 0.5075081948177197,
            "fpr": 0.3611416026344676,
            "logloss": 0.6915634784367396,
            "mae": 0.49586114287376404,
            "precision": 0.5,
            "recall": 0.724669603524229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.776178811364584,
            "auditor_fn_violation": 0.047763157894736855,
            "auditor_fp_violation": 0.025964486458865614,
            "ave_precision_score": 0.7769711509227624,
            "fpr": 0.11403508771929824,
            "logloss": 2.1921254816776767,
            "mae": 0.3080546046923582,
            "precision": 0.7614678899082569,
            "recall": 0.664
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7974206487197266,
            "auditor_fn_violation": 0.040764614573712395,
            "auditor_fp_violation": 0.02346953236278214,
            "ave_precision_score": 0.797776504926305,
            "fpr": 0.1119648737650933,
            "logloss": 1.7333570676271632,
            "mae": 0.2665944166886132,
            "precision": 0.7582938388625592,
            "recall": 0.7048458149779736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8206227446877581,
            "auditor_fn_violation": 0.02692763157894737,
            "auditor_fp_violation": 0.0018070814171350716,
            "ave_precision_score": 0.8210176402779296,
            "fpr": 0.01425438596491228,
            "logloss": 0.595119833547287,
            "mae": 0.40488136585867196,
            "precision": 0.9244186046511628,
            "recall": 0.318
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8309469329071322,
            "auditor_fn_violation": 0.019630362142584276,
            "auditor_fp_violation": 0.003417986342466378,
            "ave_precision_score": 0.8313296370873012,
            "fpr": 0.010976948408342482,
            "logloss": 0.5521235428091622,
            "mae": 0.3874779812885299,
            "precision": 0.9408284023668639,
            "recall": 0.3502202643171806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7984521280057401,
            "auditor_fn_violation": 0.02903728070175439,
            "auditor_fp_violation": 0.02873232839380004,
            "ave_precision_score": 0.7962405255554775,
            "fpr": 0.2149122807017544,
            "logloss": 2.094324738040816,
            "mae": 0.3157124296039898,
            "precision": 0.672787979966611,
            "recall": 0.806
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8100258826311992,
            "auditor_fn_violation": 0.02086829112608016,
            "auditor_fp_violation": 0.035748342048437895,
            "ave_precision_score": 0.8099640559333221,
            "fpr": 0.20636663007683864,
            "logloss": 1.7402233590110738,
            "mae": 0.28746552968280964,
            "precision": 0.670753064798599,
            "recall": 0.8436123348017621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.798267336806971,
            "auditor_fn_violation": 0.02871491228070176,
            "auditor_fp_violation": 0.027832779764946344,
            "ave_precision_score": 0.7956078887006234,
            "fpr": 0.21162280701754385,
            "logloss": 2.115427211466316,
            "mae": 0.3154235988808824,
            "precision": 0.6756302521008404,
            "recall": 0.804
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8100252497618945,
            "auditor_fn_violation": 0.020333950685938382,
            "auditor_fp_violation": 0.035359224840089645,
            "ave_precision_score": 0.809756975792622,
            "fpr": 0.20636663007683864,
            "logloss": 1.7554989258034088,
            "mae": 0.2873545108255993,
            "precision": 0.6695957820738138,
            "recall": 0.8392070484581498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.777231250665465,
            "auditor_fn_violation": 0.053949561403508775,
            "auditor_fp_violation": 0.028987821495486295,
            "ave_precision_score": 0.7786150812300889,
            "fpr": 0.10635964912280702,
            "logloss": 1.9613236793106155,
            "mae": 0.31139278325124,
            "precision": 0.7668269230769231,
            "recall": 0.638
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8038141927250114,
            "auditor_fn_violation": 0.04111761776041239,
            "auditor_fp_violation": 0.022198896540459784,
            "ave_precision_score": 0.8041361005924539,
            "fpr": 0.10208562019758508,
            "logloss": 1.5736391992761944,
            "mae": 0.26896952041253597,
            "precision": 0.7703703703703704,
            "recall": 0.6872246696035242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7614911504802429,
            "auditor_fn_violation": 0.018802631578947366,
            "auditor_fp_violation": 0.011252342020098791,
            "ave_precision_score": 0.7625128858063466,
            "fpr": 0.17543859649122806,
            "logloss": 0.6222122380425134,
            "mae": 0.4391390234313644,
            "precision": 0.6837944664031621,
            "recall": 0.692
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7648617791412355,
            "auditor_fn_violation": 0.01812888968408634,
            "auditor_fp_violation": 0.021098799741549313,
            "ave_precision_score": 0.7663614927261007,
            "fpr": 0.18880351262349068,
            "logloss": 0.6003003427737217,
            "mae": 0.42952312572432927,
            "precision": 0.6424116424116424,
            "recall": 0.6806167400881057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7915941824538573,
            "auditor_fn_violation": 0.03327850877192983,
            "auditor_fp_violation": 0.035588059955714534,
            "ave_precision_score": 0.7889135917594323,
            "fpr": 0.20175438596491227,
            "logloss": 2.2939498027698684,
            "mae": 0.30777118850659174,
            "precision": 0.6928213689482471,
            "recall": 0.83
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8074196493762476,
            "auditor_fn_violation": 0.0266106374850699,
            "auditor_fp_violation": 0.03632000807057914,
            "ave_precision_score": 0.8073846325368222,
            "fpr": 0.21734357848518113,
            "logloss": 1.9171156955018271,
            "mae": 0.2891145712983413,
            "precision": 0.6644067796610169,
            "recall": 0.8634361233480177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7571155131406253,
            "auditor_fn_violation": 0.021035087719298243,
            "auditor_fp_violation": 0.020750830352580477,
            "ave_precision_score": 0.7576776646700321,
            "fpr": 0.16337719298245615,
            "logloss": 1.140166729253164,
            "mae": 0.3145383750134532,
            "precision": 0.7161904761904762,
            "recall": 0.752
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7429759124555195,
            "auditor_fn_violation": 0.01002432337026166,
            "auditor_fp_violation": 0.0112411637967271,
            "ave_precision_score": 0.7438266334078162,
            "fpr": 0.16245883644346873,
            "logloss": 1.0423671426790504,
            "mae": 0.28134245658144763,
            "precision": 0.7075098814229249,
            "recall": 0.788546255506608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7837079481881106,
            "auditor_fn_violation": 0.01719298245614035,
            "auditor_fp_violation": 0.025889967637540454,
            "ave_precision_score": 0.7682863387339345,
            "fpr": 0.23684210526315788,
            "logloss": 2.344339308401086,
            "mae": 0.31132031004130656,
            "precision": 0.6687116564417178,
            "recall": 0.872
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7974288264097654,
            "auditor_fn_violation": 0.01685227541985619,
            "auditor_fp_violation": 0.03051687735842258,
            "ave_precision_score": 0.7875088655740936,
            "fpr": 0.2491767288693743,
            "logloss": 1.9991872127943782,
            "mae": 0.30331204422700286,
            "precision": 0.641390205371248,
            "recall": 0.8942731277533039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7298103198834598,
            "auditor_fn_violation": 0.019846491228070164,
            "auditor_fp_violation": 0.01424107903253279,
            "ave_precision_score": 0.7305301123601959,
            "fpr": 0.11513157894736842,
            "logloss": 1.416414581674356,
            "mae": 0.35472175874848944,
            "precision": 0.7307692307692307,
            "recall": 0.57
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6951606480904002,
            "auditor_fn_violation": 9.913103188150739e-05,
            "auditor_fp_violation": 0.016830520240099733,
            "ave_precision_score": 0.6956819479835967,
            "fpr": 0.10757409440175632,
            "logloss": 1.3744715830822105,
            "mae": 0.3174825476002823,
            "precision": 0.7344173441734417,
            "recall": 0.5969162995594713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 16695,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7777320250039523,
            "auditor_fn_violation": 0.05277192982456141,
            "auditor_fp_violation": 0.027545350025549312,
            "ave_precision_score": 0.7791040346392637,
            "fpr": 0.10416666666666667,
            "logloss": 1.9214567778310787,
            "mae": 0.3111140275461826,
            "precision": 0.7688564476885644,
            "recall": 0.632
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8042551557858097,
            "auditor_fn_violation": 0.042215312601246634,
            "auditor_fp_violation": 0.021886641990550706,
            "ave_precision_score": 0.8045702288507278,
            "fpr": 0.09769484083424808,
            "logloss": 1.5475422791430047,
            "mae": 0.26965839114920753,
            "precision": 0.7780548628428927,
            "recall": 0.6872246696035242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.7191407379883953,
            "auditor_fn_violation": 0.00769298245614035,
            "auditor_fp_violation": 0.00982317748254131,
            "ave_precision_score": 0.7118575566760927,
            "fpr": 0.3826754385964912,
            "logloss": 0.6876510758836616,
            "mae": 0.44845509493167984,
            "precision": 0.5749086479902558,
            "recall": 0.944
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7471438682311236,
            "auditor_fn_violation": 0.00104933823991644,
            "auditor_fp_violation": 0.013138710676943848,
            "ave_precision_score": 0.7366672310760015,
            "fpr": 0.42151481888035125,
            "logloss": 0.6224917596765586,
            "mae": 0.43947259605781436,
            "precision": 0.5339805825242718,
            "recall": 0.9691629955947136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7400272376908821,
            "auditor_fn_violation": 0.014440789473684216,
            "auditor_fp_violation": 0.020186616419690002,
            "ave_precision_score": 0.7407491943397617,
            "fpr": 0.13048245614035087,
            "logloss": 1.3540877487924827,
            "mae": 0.33281690411556797,
            "precision": 0.728310502283105,
            "recall": 0.638
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7114604967852463,
            "auditor_fn_violation": 0.0028336968137835663,
            "auditor_fp_violation": 0.015024247766779481,
            "ave_precision_score": 0.7119248813050394,
            "fpr": 0.12952799121844127,
            "logloss": 1.30235513214478,
            "mae": 0.2963544682031638,
            "precision": 0.7230046948356808,
            "recall": 0.6784140969162996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7667089764326067,
            "auditor_fn_violation": 0.0374342105263158,
            "auditor_fp_violation": 0.021192620507579633,
            "ave_precision_score": 0.7668150676388877,
            "fpr": 0.09978070175438597,
            "logloss": 1.8435306803198324,
            "mae": 0.3305012956999472,
            "precision": 0.7611548556430446,
            "recall": 0.58
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7918296267065118,
            "auditor_fn_violation": 0.0278969230694836,
            "auditor_fp_violation": 0.013054642144276015,
            "ave_precision_score": 0.7922461413340095,
            "fpr": 0.08562019758507135,
            "logloss": 1.4139175894480356,
            "mae": 0.2840985746141998,
            "precision": 0.7833333333333333,
            "recall": 0.6211453744493393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6927848210608217,
            "auditor_fn_violation": 0.006850877192982461,
            "auditor_fp_violation": 0.02922202350536536,
            "ave_precision_score": 0.6834029997156357,
            "fpr": 0.05921052631578947,
            "logloss": 3.407745257373166,
            "mae": 0.4457171944976855,
            "precision": 0.7326732673267327,
            "recall": 0.296
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6993855194422692,
            "auditor_fn_violation": 0.0006238001518397471,
            "auditor_fp_violation": 0.026479185832290485,
            "ave_precision_score": 0.6880874253059599,
            "fpr": 0.04610318331503842,
            "logloss": 3.1012230689135403,
            "mae": 0.4092653894988513,
            "precision": 0.732484076433121,
            "recall": 0.2533039647577093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7790746848668743,
            "auditor_fn_violation": 0.03420833333333334,
            "auditor_fp_violation": 0.01964369357860671,
            "ave_precision_score": 0.7830101616827863,
            "fpr": 0.13706140350877194,
            "logloss": 1.234482423255366,
            "mae": 0.298520469852426,
            "precision": 0.7469635627530364,
            "recall": 0.738
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8165381869674253,
            "auditor_fn_violation": 0.028868890747931548,
            "auditor_fp_violation": 0.017077921921950776,
            "ave_precision_score": 0.8168862392542888,
            "fpr": 0.13830954994511527,
            "logloss": 0.9392610273064268,
            "mae": 0.25927109677349497,
            "precision": 0.7375,
            "recall": 0.7797356828193832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7633809852888341,
            "auditor_fn_violation": 0.024627192982456147,
            "auditor_fp_violation": 0.0045137114631238285,
            "ave_precision_score": 0.7643874140642941,
            "fpr": 0.020833333333333332,
            "logloss": 3.2085257817415784,
            "mae": 0.4408061940501701,
            "precision": 0.8623188405797102,
            "recall": 0.238
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7951675161929244,
            "auditor_fn_violation": 0.014313553871671254,
            "auditor_fp_violation": 0.0034972509589817624,
            "ave_precision_score": 0.7955420722246267,
            "fpr": 0.01646542261251372,
            "logloss": 2.5815842983013235,
            "mae": 0.3953802237829323,
            "precision": 0.8706896551724138,
            "recall": 0.22246696035242292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7202917218572991,
            "auditor_fn_violation": 0.0063815789473684265,
            "auditor_fp_violation": 0.0016873190257196387,
            "ave_precision_score": 0.7207629774335285,
            "fpr": 0.010964912280701754,
            "logloss": 0.9048000994550519,
            "mae": 0.4536678247265078,
            "precision": 0.9074074074074074,
            "recall": 0.196
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7374641555075193,
            "auditor_fn_violation": 0.0029207386954356223,
            "auditor_fp_violation": 0.0024331835312146467,
            "ave_precision_score": 0.7407426887247595,
            "fpr": 0.006586169045005488,
            "logloss": 0.7641865468551011,
            "mae": 0.4139278871893728,
            "precision": 0.9491525423728814,
            "recall": 0.24669603524229075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.770423201991071,
            "auditor_fn_violation": 0.051464912280701755,
            "auditor_fp_violation": 0.02751607477431443,
            "ave_precision_score": 0.7717851343616742,
            "fpr": 0.09978070175438597,
            "logloss": 1.8546483868195625,
            "mae": 0.3218445039057877,
            "precision": 0.7736318407960199,
            "recall": 0.622
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7967615174954842,
            "auditor_fn_violation": 0.03671716707689183,
            "auditor_fp_violation": 0.01875208670107872,
            "ave_precision_score": 0.7971082178241586,
            "fpr": 0.09659714599341383,
            "logloss": 1.4941993698970488,
            "mae": 0.27746717099726226,
            "precision": 0.7766497461928934,
            "recall": 0.6740088105726872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6971190109544334,
            "auditor_fn_violation": 0.016282894736842118,
            "auditor_fp_violation": 0.02922202350536536,
            "ave_precision_score": 0.6877318744835825,
            "fpr": 0.05921052631578947,
            "logloss": 3.1626079919537973,
            "mae": 0.42831036266704814,
            "precision": 0.755656108597285,
            "recall": 0.334
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7052192441361711,
            "auditor_fn_violation": 0.0006310536419774081,
            "auditor_fp_violation": 0.025763402325575807,
            "ave_precision_score": 0.6940866395125708,
            "fpr": 0.05159165751920966,
            "logloss": 2.84193097526996,
            "mae": 0.38861372157904805,
            "precision": 0.75,
            "recall": 0.31057268722466963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6553850648999671,
            "auditor_fn_violation": 0.07273026315789473,
            "auditor_fp_violation": 0.063889243740419,
            "ave_precision_score": 0.6529294983571833,
            "fpr": 0.16337719298245615,
            "logloss": 5.47166771839445,
            "mae": 0.4712098047106522,
            "precision": 0.5906593406593407,
            "recall": 0.43
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6639549563797934,
            "auditor_fn_violation": 0.06001537739909187,
            "auditor_fp_violation": 0.07937270462881342,
            "ave_precision_score": 0.6602211762501171,
            "fpr": 0.1800219538968167,
            "logloss": 4.413105171743968,
            "mae": 0.4429158025159484,
            "precision": 0.5661375661375662,
            "recall": 0.4713656387665198
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7551292183094998,
            "auditor_fn_violation": 0.021655701754385973,
            "auditor_fp_violation": 0.016319621870209508,
            "ave_precision_score": 0.7567358149137551,
            "fpr": 0.12719298245614036,
            "logloss": 1.1563534965264841,
            "mae": 0.3298734111291379,
            "precision": 0.7369614512471655,
            "recall": 0.65
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7508308766492473,
            "auditor_fn_violation": 0.016895796360682214,
            "auditor_fp_violation": 0.01398179796169838,
            "ave_precision_score": 0.7515795475717024,
            "fpr": 0.12623490669593854,
            "logloss": 0.9745844128526502,
            "mae": 0.29313332587640595,
            "precision": 0.7331786542923434,
            "recall": 0.6960352422907489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.728584645054653,
            "auditor_fn_violation": 0.019846491228070164,
            "auditor_fp_violation": 0.01424107903253279,
            "ave_precision_score": 0.7292673010111628,
            "fpr": 0.11513157894736842,
            "logloss": 1.419795661665759,
            "mae": 0.3549819097621908,
            "precision": 0.7307692307692307,
            "recall": 0.57
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6936817058566368,
            "auditor_fn_violation": 0.0002949752655986254,
            "auditor_fp_violation": 0.016830520240099733,
            "ave_precision_score": 0.6941949394302821,
            "fpr": 0.10757409440175632,
            "logloss": 1.381355339531038,
            "mae": 0.31755118431777946,
            "precision": 0.7351351351351352,
            "recall": 0.5991189427312775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 16695,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.692542385321706,
            "mae": 0.49962122444259494,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5245904164275862,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005692640640650258,
            "ave_precision_score": 0.5286587348761459,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6927174163917345,
            "mae": 0.4997638003690052,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7860494793046559,
            "auditor_fn_violation": 0.03478728070175438,
            "auditor_fp_violation": 0.024963805143927785,
            "ave_precision_score": 0.7863447482207182,
            "fpr": 0.15789473684210525,
            "logloss": 2.263217428577327,
            "mae": 0.3149037956473513,
            "precision": 0.710261569416499,
            "recall": 0.706
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8085732593637185,
            "auditor_fn_violation": 0.023037084677243868,
            "auditor_fp_violation": 0.028165360401799556,
            "ave_precision_score": 0.8088730264951645,
            "fpr": 0.150384193194292,
            "logloss": 1.8329191507008324,
            "mae": 0.2730287675447343,
            "precision": 0.7157676348547718,
            "recall": 0.7599118942731278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5395392239811224,
            "auditor_fn_violation": 0.0018201754385964919,
            "auditor_fp_violation": 0.003874978708908192,
            "ave_precision_score": 0.5601978527509351,
            "fpr": 0.4440789473684211,
            "logloss": 0.6947183818096007,
            "mae": 0.4985003116164814,
            "precision": 0.55,
            "recall": 0.99
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5198091339327502,
            "auditor_fn_violation": 0.0013273886951938373,
            "auditor_fp_violation": 0.003893574041558697,
            "ave_precision_score": 0.5289521609232092,
            "fpr": 0.4818880351262349,
            "logloss": 0.6923485394049627,
            "mae": 0.49665611920189257,
            "precision": 0.5045146726862303,
            "recall": 0.9845814977973568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7753042221472657,
            "auditor_fn_violation": 0.053800438596491224,
            "auditor_fp_violation": 0.02820005109862034,
            "ave_precision_score": 0.7767043105441509,
            "fpr": 0.10964912280701754,
            "logloss": 1.7622125497531806,
            "mae": 0.31270441239502506,
            "precision": 0.765807962529274,
            "recall": 0.654
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8013151147928924,
            "auditor_fn_violation": 0.042002543557208276,
            "auditor_fp_violation": 0.022220514163145796,
            "ave_precision_score": 0.8016488510854998,
            "fpr": 0.10757409440175632,
            "logloss": 1.4279101492102608,
            "mae": 0.2717383363088374,
            "precision": 0.7644230769230769,
            "recall": 0.7004405286343612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7430126061701492,
            "auditor_fn_violation": 0.02073684210526316,
            "auditor_fp_violation": 0.024237246636007494,
            "ave_precision_score": 0.7446578882711186,
            "fpr": 0.18092105263157895,
            "logloss": 1.2152630284677397,
            "mae": 0.3104655787733655,
            "precision": 0.7032374100719424,
            "recall": 0.782
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7321055784821286,
            "auditor_fn_violation": 0.007717713506482202,
            "auditor_fp_violation": 0.017755274099445873,
            "ave_precision_score": 0.732911200251546,
            "fpr": 0.18551042810098792,
            "logloss": 1.1124216376413611,
            "mae": 0.293205427536693,
            "precision": 0.689908256880734,
            "recall": 0.8281938325991189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7568306683592382,
            "auditor_fn_violation": 0.023035087719298252,
            "auditor_fp_violation": 0.016319621870209508,
            "ave_precision_score": 0.7582623640264284,
            "fpr": 0.12719298245614036,
            "logloss": 1.1430111120224753,
            "mae": 0.329095462319033,
            "precision": 0.7375565610859729,
            "recall": 0.652
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7558792482465903,
            "auditor_fn_violation": 0.017449479441191126,
            "auditor_fp_violation": 0.013652729705255726,
            "ave_precision_score": 0.7565831177083095,
            "fpr": 0.12403951701427003,
            "logloss": 0.95699284822206,
            "mae": 0.2909742223765287,
            "precision": 0.7372093023255814,
            "recall": 0.698237885462555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7684303262233977,
            "auditor_fn_violation": 0.035921052631578944,
            "auditor_fp_violation": 0.022014988928632264,
            "ave_precision_score": 0.7679686975245147,
            "fpr": 0.10087719298245613,
            "logloss": 1.9320357872390401,
            "mae": 0.3293065073284859,
            "precision": 0.7597911227154047,
            "recall": 0.582
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7885868151009445,
            "auditor_fn_violation": 0.0278969230694836,
            "auditor_fp_violation": 0.014627924684202561,
            "ave_precision_score": 0.7891019416415241,
            "fpr": 0.0867178924259056,
            "logloss": 1.4589768647982844,
            "mae": 0.2826655870280331,
            "precision": 0.7811634349030471,
            "recall": 0.6211453744493393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7434315016976689,
            "auditor_fn_violation": 0.01892543859649123,
            "auditor_fp_violation": 0.014611011752682682,
            "ave_precision_score": 0.7450634729046665,
            "fpr": 0.1074561403508772,
            "logloss": 1.3345076255184656,
            "mae": 0.3508880335995894,
            "precision": 0.7421052631578947,
            "recall": 0.564
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7201100249795936,
            "auditor_fn_violation": 8.94597116979481e-05,
            "auditor_fp_violation": 0.01576645281233261,
            "ave_precision_score": 0.7207531228468333,
            "fpr": 0.10428100987925357,
            "logloss": 1.2080900485956663,
            "mae": 0.31444997037242994,
            "precision": 0.7404371584699454,
            "recall": 0.5969162995594713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7812324814781568,
            "auditor_fn_violation": 0.042324561403508786,
            "auditor_fp_violation": 0.02569834781127576,
            "ave_precision_score": 0.7815765812491092,
            "fpr": 0.10635964912280702,
            "logloss": 1.970050970575013,
            "mae": 0.31673809576820533,
            "precision": 0.7673860911270983,
            "recall": 0.64
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7899362365704866,
            "auditor_fn_violation": 0.033690043859437045,
            "auditor_fp_violation": 0.0242141393664115,
            "ave_precision_score": 0.79046106586288,
            "fpr": 0.1119648737650933,
            "logloss": 1.5470427306559744,
            "mae": 0.2760066421008053,
            "precision": 0.7524271844660194,
            "recall": 0.6828193832599119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7710281904717532,
            "auditor_fn_violation": 0.051464912280701755,
            "auditor_fp_violation": 0.024766862544711294,
            "ave_precision_score": 0.7723890525050708,
            "fpr": 0.09758771929824561,
            "logloss": 1.9096350549738923,
            "mae": 0.32149466715375125,
            "precision": 0.7775,
            "recall": 0.622
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7968715015901499,
            "auditor_fn_violation": 0.03634965690991648,
            "auditor_fp_violation": 0.01927090964554305,
            "ave_precision_score": 0.797217084278999,
            "fpr": 0.09440175631174534,
            "logloss": 1.5311793569900296,
            "mae": 0.27712314825222295,
            "precision": 0.7800511508951407,
            "recall": 0.6718061674008811
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 16695,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7712024803758906,
            "auditor_fn_violation": 0.0531140350877193,
            "auditor_fp_violation": 0.02751607477431443,
            "ave_precision_score": 0.772565776023602,
            "fpr": 0.09978070175438597,
            "logloss": 1.8233397208215694,
            "mae": 0.3222138850919608,
            "precision": 0.7741935483870968,
            "recall": 0.624
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7987592704860071,
            "auditor_fn_violation": 0.03817753642460965,
            "auditor_fp_violation": 0.01824287158891929,
            "ave_precision_score": 0.7990928743470089,
            "fpr": 0.09330406147091108,
            "logloss": 1.4722549271062093,
            "mae": 0.278499077401321,
            "precision": 0.781491002570694,
            "recall": 0.6696035242290749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7859294444728507,
            "auditor_fn_violation": 0.03478728070175438,
            "auditor_fp_violation": 0.024963805143927785,
            "ave_precision_score": 0.7862407701017373,
            "fpr": 0.15789473684210525,
            "logloss": 2.2599836944033522,
            "mae": 0.3148799973570255,
            "precision": 0.710261569416499,
            "recall": 0.706
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8085979325301036,
            "auditor_fn_violation": 0.023037084677243868,
            "auditor_fp_violation": 0.028165360401799556,
            "ave_precision_score": 0.808900965807215,
            "fpr": 0.150384193194292,
            "logloss": 1.8299090364134087,
            "mae": 0.2730132193986375,
            "precision": 0.7157676348547718,
            "recall": 0.7599118942731278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5922454547309084,
            "auditor_fn_violation": 0.008421052631578949,
            "auditor_fp_violation": 0.004769204564810092,
            "ave_precision_score": 0.556610386286533,
            "fpr": 0.32894736842105265,
            "logloss": 0.6938614476982522,
            "mae": 0.49766859921969864,
            "precision": 0.5575221238938053,
            "recall": 0.756
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5689111705207262,
            "auditor_fn_violation": 0.004874345372515078,
            "auditor_fp_violation": 0.013986601877850832,
            "ave_precision_score": 0.5075081948177197,
            "fpr": 0.3611416026344676,
            "logloss": 0.6915634881921183,
            "mae": 0.4958611432663303,
            "precision": 0.5,
            "recall": 0.724669603524229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7728304813932902,
            "auditor_fn_violation": 0.055831140350877204,
            "auditor_fp_violation": 0.027678419349344233,
            "ave_precision_score": 0.7743453206564928,
            "fpr": 0.10526315789473684,
            "logloss": 1.8538022712237252,
            "mae": 0.314812529404923,
            "precision": 0.7697841726618705,
            "recall": 0.642
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7984742193385606,
            "auditor_fn_violation": 0.0399812376388439,
            "auditor_fp_violation": 0.022098014301258385,
            "ave_precision_score": 0.798812436753692,
            "fpr": 0.10537870472008781,
            "logloss": 1.4952692534742202,
            "mae": 0.2740506411729189,
            "precision": 0.7635467980295566,
            "recall": 0.6828193832599119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7859107715541072,
            "auditor_fn_violation": 0.03478728070175438,
            "auditor_fp_violation": 0.024963805143927785,
            "ave_precision_score": 0.7862830539643587,
            "fpr": 0.15789473684210525,
            "logloss": 2.2624286391095456,
            "mae": 0.3149018067851982,
            "precision": 0.710261569416499,
            "recall": 0.706
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8086100171291069,
            "auditor_fn_violation": 0.023037084677243868,
            "auditor_fp_violation": 0.028165360401799556,
            "ave_precision_score": 0.8089068119835059,
            "fpr": 0.150384193194292,
            "logloss": 1.831407967937103,
            "mae": 0.27304577926665513,
            "precision": 0.7157676348547718,
            "recall": 0.7599118942731278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7774211176833276,
            "auditor_fn_violation": 0.046664473684210526,
            "auditor_fp_violation": 0.027721001532958606,
            "ave_precision_score": 0.7786564724596436,
            "fpr": 0.1162280701754386,
            "logloss": 2.204997689770843,
            "mae": 0.30754655111718315,
            "precision": 0.7607223476297968,
            "recall": 0.674
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7989835558175864,
            "auditor_fn_violation": 0.037672209945018555,
            "auditor_fp_violation": 0.022299778779661182,
            "ave_precision_score": 0.7993188372717591,
            "fpr": 0.11306256860592755,
            "logloss": 1.7388848863930517,
            "mae": 0.2655605696926667,
            "precision": 0.7604651162790698,
            "recall": 0.7202643171806168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.774118324469082,
            "auditor_fn_violation": 0.04129385964912281,
            "auditor_fp_violation": 0.026384985522057574,
            "ave_precision_score": 0.7756802133913583,
            "fpr": 0.1425438596491228,
            "logloss": 1.5673106276041806,
            "mae": 0.2999644083550128,
            "precision": 0.74,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8104056984482358,
            "auditor_fn_violation": 0.034354947122056896,
            "auditor_fp_violation": 0.019114782370588508,
            "ave_precision_score": 0.8107118927943788,
            "fpr": 0.14489571899012074,
            "logloss": 1.2396821863733598,
            "mae": 0.270529280107404,
            "precision": 0.7278350515463917,
            "recall": 0.7775330396475771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7138086370051313,
            "auditor_fn_violation": 0.0007521929824561338,
            "auditor_fp_violation": 0.004447176801226368,
            "ave_precision_score": 0.7155293790470737,
            "fpr": 0.08223684210526316,
            "logloss": 0.6417786295935284,
            "mae": 0.45717182167266546,
            "precision": 0.7242647058823529,
            "recall": 0.394
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.711863031258943,
            "auditor_fn_violation": 0.005863237861284257,
            "auditor_fp_violation": 0.012365280176399806,
            "ave_precision_score": 0.714201475080428,
            "fpr": 0.10208562019758508,
            "logloss": 0.6190568781646364,
            "mae": 0.44659561916580576,
            "precision": 0.6725352112676056,
            "recall": 0.42070484581497797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7766101099611544,
            "auditor_fn_violation": 0.05060307017543861,
            "auditor_fp_violation": 0.02607094191790155,
            "ave_precision_score": 0.7718380255411991,
            "fpr": 0.10964912280701754,
            "logloss": 2.250750734974284,
            "mae": 0.3080725078075684,
            "precision": 0.7668997668997669,
            "recall": 0.658
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.789076294854135,
            "auditor_fn_violation": 0.03711369120441786,
            "auditor_fp_violation": 0.026995606818678592,
            "ave_precision_score": 0.7863761082034897,
            "fpr": 0.11964873765093303,
            "logloss": 1.7513282002703503,
            "mae": 0.2663873194434141,
            "precision": 0.7488479262672811,
            "recall": 0.7158590308370044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.731950748039683,
            "auditor_fn_violation": 0.00744736842105263,
            "auditor_fp_violation": 0.03333918838358031,
            "ave_precision_score": 0.7104573121064716,
            "fpr": 0.2642543859649123,
            "logloss": 0.6385553017343414,
            "mae": 0.45378135522549745,
            "precision": 0.6286594761171033,
            "recall": 0.816
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7560030367063876,
            "auditor_fn_violation": 0.014226511990019196,
            "auditor_fp_violation": 0.04099181652883432,
            "ave_precision_score": 0.7281833218411587,
            "fpr": 0.28210757409440174,
            "logloss": 0.616435864623173,
            "mae": 0.4446384305610811,
            "precision": 0.6076335877862595,
            "recall": 0.8766519823788547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.777394793810648,
            "auditor_fn_violation": 0.04570175438596492,
            "auditor_fp_violation": 0.02659789644012945,
            "ave_precision_score": 0.7780586949373505,
            "fpr": 0.1206140350877193,
            "logloss": 2.255598904565529,
            "mae": 0.30628880745872167,
            "precision": 0.7555555555555555,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7990039426650006,
            "auditor_fn_violation": 0.03693477178102198,
            "auditor_fp_violation": 0.02234541598310943,
            "ave_precision_score": 0.799267242183398,
            "fpr": 0.11525795828759605,
            "logloss": 1.7654598462887305,
            "mae": 0.2649461181131572,
            "precision": 0.7575057736720554,
            "recall": 0.7224669603524229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7658573979580389,
            "auditor_fn_violation": 0.03414912280701755,
            "auditor_fp_violation": 0.016319621870209515,
            "ave_precision_score": 0.7677547560421859,
            "fpr": 0.09649122807017543,
            "logloss": 1.6508672967416727,
            "mae": 0.33532201420927427,
            "precision": 0.7628032345013477,
            "recall": 0.566
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7932898138571283,
            "auditor_fn_violation": 0.02034845766621373,
            "auditor_fp_violation": 0.008221902494913854,
            "ave_precision_score": 0.7937275432208908,
            "fpr": 0.07683863885839737,
            "logloss": 1.2633097212765783,
            "mae": 0.28925437811259735,
            "precision": 0.7947214076246334,
            "recall": 0.5969162995594713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.71520161695574,
            "auditor_fn_violation": 0.10605263157894737,
            "auditor_fp_violation": 0.09570345767330947,
            "ave_precision_score": 0.7101628717055064,
            "fpr": 0.18311403508771928,
            "logloss": 0.6422749340199462,
            "mae": 0.45348256631149797,
            "precision": 0.6520833333333333,
            "recall": 0.626
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7394757108654637,
            "auditor_fn_violation": 0.09053564606836656,
            "auditor_fp_violation": 0.10464130359068714,
            "ave_precision_score": 0.7322441912501829,
            "fpr": 0.1800219538968167,
            "logloss": 0.613070191862887,
            "mae": 0.44240834237240934,
            "precision": 0.6347438752783965,
            "recall": 0.6277533039647577
        }
    }
]