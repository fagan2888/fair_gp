[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6288243947028519,
            "auditor_fn_violation": 0.010149454518649568,
            "auditor_fp_violation": 0.009971531466280381,
            "ave_precision_score": 0.6259432216677967,
            "fpr": 0.14802631578947367,
            "logloss": 0.6684516672383076,
            "mae": 0.4774033979823192,
            "precision": 0.6520618556701031,
            "recall": 0.5315126050420168
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6062001518321145,
            "auditor_fn_violation": 0.01709923804362304,
            "auditor_fp_violation": 0.015818974149666768,
            "ave_precision_score": 0.6046781216648929,
            "fpr": 0.1778265642151482,
            "logloss": 0.6742850969130774,
            "mae": 0.4798083701850816,
            "precision": 0.6206088992974239,
            "recall": 0.5543933054393305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5901317948033244,
            "auditor_fn_violation": 0.10481166150670795,
            "auditor_fp_violation": 0.08817700788668921,
            "ave_precision_score": 0.5884340807632821,
            "fpr": 0.19956140350877194,
            "logloss": 0.6894359279695956,
            "mae": 0.4943310256655279,
            "precision": 0.5806451612903226,
            "recall": 0.5294117647058824
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5760496309046776,
            "auditor_fn_violation": 0.11136780125752656,
            "auditor_fp_violation": 0.09931983481340456,
            "ave_precision_score": 0.5743155109084072,
            "fpr": 0.20636663007683864,
            "logloss": 0.684808112926583,
            "mae": 0.49334789297321624,
            "precision": 0.5607476635514018,
            "recall": 0.502092050209205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6919524552443286,
            "auditor_fn_violation": 0.07963152366209643,
            "auditor_fp_violation": 0.01301203122485112,
            "ave_precision_score": 0.6852980470643601,
            "fpr": 0.02850877192982456,
            "logloss": 1.663879689180857,
            "mae": 0.44506405844884134,
            "precision": 0.8652849740932642,
            "recall": 0.35084033613445376
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6951124091312235,
            "auditor_fn_violation": 0.07426663421041754,
            "auditor_fp_violation": 0.008031171491369279,
            "ave_precision_score": 0.6849836567054374,
            "fpr": 0.01756311745334797,
            "logloss": 1.7591408463454292,
            "mae": 0.4424004823377019,
            "precision": 0.9058823529411765,
            "recall": 0.32217573221757323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 18313,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7227802390564304,
            "auditor_fn_violation": 0.006611197110423128,
            "auditor_fp_violation": 0.0030782230806373737,
            "ave_precision_score": 0.6643819751587628,
            "fpr": 0.015350877192982455,
            "logloss": 0.6452862600688171,
            "mae": 0.46387225768545215,
            "precision": 0.9166666666666666,
            "recall": 0.3235294117647059
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.731934451699906,
            "auditor_fn_violation": 0.00414046819670325,
            "auditor_fp_violation": 0.002256231889936446,
            "ave_precision_score": 0.6708221393310827,
            "fpr": 0.014270032930845226,
            "logloss": 0.6447800649348027,
            "mae": 0.45925654609954447,
            "precision": 0.9285714285714286,
            "recall": 0.35355648535564854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7208072334786333,
            "auditor_fn_violation": 0.066234059413239,
            "auditor_fp_violation": 0.01582619105102205,
            "ave_precision_score": 0.7210692971404307,
            "fpr": 0.03399122807017544,
            "logloss": 0.6346600203803958,
            "mae": 0.44733237880363796,
            "precision": 0.8333333333333334,
            "recall": 0.32563025210084034
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7460611648912087,
            "auditor_fn_violation": 0.06122748921824838,
            "auditor_fp_violation": 0.007336556280310195,
            "ave_precision_score": 0.7461565887187778,
            "fpr": 0.021953896816684963,
            "logloss": 0.6190700967549764,
            "mae": 0.43992114063806254,
            "precision": 0.8837209302325582,
            "recall": 0.3179916317991632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6656101729516111,
            "auditor_fn_violation": 0.0030683325961963627,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.6659602827450557,
            "fpr": 0.0010964912280701754,
            "logloss": 0.668060689958373,
            "mae": 0.4837615206641586,
            "precision": 0.9887640449438202,
            "recall": 0.18487394957983194
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6818122534803256,
            "auditor_fn_violation": 0.002989955403276564,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.6822255829860608,
            "fpr": 0.005488474204171241,
            "logloss": 0.6721828589971849,
            "mae": 0.48115711524248383,
            "precision": 0.95,
            "recall": 0.19874476987447698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7646841349033402,
            "auditor_fn_violation": 0.000870743034055728,
            "auditor_fp_violation": 0.004199863190085313,
            "ave_precision_score": 0.5420207405972826,
            "fpr": 0.4451754385964912,
            "logloss": 14.982724271199851,
            "mae": 0.4490723438434184,
            "precision": 0.5370581527936146,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.76765500742952,
            "auditor_fn_violation": 0.0020415286893339887,
            "auditor_fp_violation": 0.006915731006456877,
            "ave_precision_score": 0.5488219023027114,
            "fpr": 0.43907793633369924,
            "logloss": 14.662665684851955,
            "mae": 0.44942300370845584,
            "precision": 0.5397008055235903,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 18313,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5519974301967516,
            "auditor_fn_violation": 0.01190706545776207,
            "auditor_fp_violation": 0.003923225494929985,
            "ave_precision_score": 0.5530642878308791,
            "fpr": 0.046052631578947366,
            "logloss": 0.6930480320643796,
            "mae": 0.4996771303315957,
            "precision": 0.5757575757575758,
            "recall": 0.11974789915966387
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.5385416072027968,
            "auditor_fn_violation": 0.00938552053240496,
            "auditor_fp_violation": 0.009227734920638945,
            "ave_precision_score": 0.54045395095866,
            "fpr": 0.06586169045005488,
            "logloss": 0.6942347317689248,
            "mae": 0.5002607525245549,
            "precision": 0.4957983193277311,
            "recall": 0.12343096234309624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6714044812763256,
            "auditor_fn_violation": 0.0032894736842105474,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.671804073203735,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6632946899389333,
            "mae": 0.4808017114798228,
            "precision": 0.98989898989899,
            "recall": 0.20588235294117646
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6861419399007611,
            "auditor_fn_violation": 0.0034354633512302018,
            "auditor_fp_violation": 0.0025680482073096845,
            "ave_precision_score": 0.686531267858556,
            "fpr": 0.006586169045005488,
            "logloss": 0.6667452746674972,
            "mae": 0.4779757470972059,
            "precision": 0.9464285714285714,
            "recall": 0.2217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7215922712861966,
            "auditor_fn_violation": 0.00021192687601357497,
            "auditor_fp_violation": 0.0003319652341863835,
            "ave_precision_score": 0.72189237912602,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6711262343084569,
            "mae": 0.4858148808411339,
            "precision": 0.9743589743589743,
            "recall": 0.15966386554621848
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.735640204589319,
            "auditor_fn_violation": 0.0069995269348594015,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.7361665611848802,
            "fpr": 0.005488474204171241,
            "logloss": 0.674210747081036,
            "mae": 0.48318824109863634,
            "precision": 0.9473684210526315,
            "recall": 0.18828451882845187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7686589374246989,
            "auditor_fn_violation": 0.0022298393041427105,
            "auditor_fp_violation": 0.009010844197650088,
            "ave_precision_score": 0.5517725037532996,
            "fpr": 0.4331140350877193,
            "logloss": 14.488254570451662,
            "mae": 0.44143360653227787,
            "precision": 0.5422943221320974,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7748214296399514,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.01433594532313551,
            "ave_precision_score": 0.5619175573467441,
            "fpr": 0.41602634467618005,
            "logloss": 13.952874371397053,
            "mae": 0.426033748030609,
            "precision": 0.5525383707201889,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 18313,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.669712345585655,
            "auditor_fn_violation": 0.003579721362229101,
            "auditor_fp_violation": 0.0018207790117495575,
            "ave_precision_score": 0.6702144231387738,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6607546293953281,
            "mae": 0.4787833632476497,
            "precision": 0.9607843137254902,
            "recall": 0.20588235294117646
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6739788516104512,
            "auditor_fn_violation": 0.003306863118831226,
            "auditor_fp_violation": 0.0031206982657435564,
            "ave_precision_score": 0.6743849392542971,
            "fpr": 0.009879253567508232,
            "logloss": 0.6646296508534182,
            "mae": 0.47653704283004533,
            "precision": 0.9203539823008849,
            "recall": 0.2175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5419492262638894,
            "auditor_fn_violation": 0.0037179345422379603,
            "auditor_fp_violation": 0.01157854498631901,
            "ave_precision_score": 0.5416422760386305,
            "fpr": 0.06798245614035088,
            "logloss": 0.6920794072335102,
            "mae": 0.4977425615907761,
            "precision": 0.5474452554744526,
            "recall": 0.15756302521008403
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.524542555329397,
            "auditor_fn_violation": 0.003488281303822668,
            "auditor_fp_violation": 0.002218205509768978,
            "ave_precision_score": 0.5239874962778751,
            "fpr": 0.0801317233809001,
            "logloss": 0.6937498972218611,
            "mae": 0.49887603315249757,
            "precision": 0.5133333333333333,
            "recall": 0.16108786610878661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6616711406165058,
            "auditor_fn_violation": 0.001094187675070043,
            "auditor_fp_violation": 0.0009305086109769838,
            "ave_precision_score": 0.6620991153562449,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6732654267268322,
            "mae": 0.4871409483123244,
            "precision": 0.9753086419753086,
            "recall": 0.16596638655462184
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6790198574503932,
            "auditor_fn_violation": 0.00675610506638988,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.6793911872369831,
            "fpr": 0.005488474204171241,
            "logloss": 0.6755528982031961,
            "mae": 0.4848727208002993,
            "precision": 0.945054945054945,
            "recall": 0.1799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 18313,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7954347672818799,
            "auditor_fn_violation": 0.011271284829721362,
            "auditor_fp_violation": 0.0075899323998068575,
            "ave_precision_score": 0.7961229094464088,
            "fpr": 0.14802631578947367,
            "logloss": 0.5647714699702754,
            "mae": 0.3798457324717259,
            "precision": 0.7175732217573222,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7940002816198437,
            "auditor_fn_violation": 0.010046893156171213,
            "auditor_fp_violation": 0.01426749783883406,
            "ave_precision_score": 0.7950234205148734,
            "fpr": 0.15587266739846323,
            "logloss": 0.5556410386064534,
            "mae": 0.3771928118216743,
            "precision": 0.7084188911704312,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7647039087682448,
            "auditor_fn_violation": 0.000870743034055728,
            "auditor_fp_violation": 0.005135401577337841,
            "ave_precision_score": 0.542040512718499,
            "fpr": 0.4418859649122807,
            "logloss": 14.962697332742444,
            "mae": 0.4477364821275544,
            "precision": 0.5389016018306636,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7680080862627592,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.009519270501922873,
            "ave_precision_score": 0.5494900731820476,
            "fpr": 0.43688254665203075,
            "logloss": 14.613105683705433,
            "mae": 0.4466445382699552,
            "precision": 0.5404157043879908,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6288243947028519,
            "auditor_fn_violation": 0.010149454518649568,
            "auditor_fp_violation": 0.009971531466280381,
            "ave_precision_score": 0.6259432216677967,
            "fpr": 0.14802631578947367,
            "logloss": 0.6684818365100916,
            "mae": 0.4774945347259442,
            "precision": 0.6520618556701031,
            "recall": 0.5315126050420168
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6062001518321145,
            "auditor_fn_violation": 0.01709923804362304,
            "auditor_fp_violation": 0.015818974149666768,
            "ave_precision_score": 0.6046781216648929,
            "fpr": 0.1778265642151482,
            "logloss": 0.6743114328729455,
            "mae": 0.4798994604109671,
            "precision": 0.6206088992974239,
            "recall": 0.5543933054393305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8379768926911788,
            "auditor_fn_violation": 0.003920647206250929,
            "auditor_fp_violation": 0.023795871559633024,
            "ave_precision_score": 0.838157502962873,
            "fpr": 0.1425438596491228,
            "logloss": 1.5980000942504595,
            "mae": 0.3238637002509041,
            "precision": 0.74,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8483035652044104,
            "auditor_fn_violation": 0.009208695212856355,
            "auditor_fp_violation": 0.01909177793608019,
            "ave_precision_score": 0.8484422554858919,
            "fpr": 0.14050493962678376,
            "logloss": 1.7137276503370897,
            "mae": 0.31846232693747645,
            "precision": 0.7450199203187251,
            "recall": 0.7824267782426778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 18313,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6917399684321831,
            "auditor_fn_violation": 0.07963152366209643,
            "auditor_fp_violation": 0.013376690004828586,
            "ave_precision_score": 0.66643754882452,
            "fpr": 0.029605263157894735,
            "logloss": 1.661744709222526,
            "mae": 0.4449589799390689,
            "precision": 0.8608247422680413,
            "recall": 0.35084033613445376
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6979423981169198,
            "auditor_fn_violation": 0.07523113595340998,
            "auditor_fp_violation": 0.008031171491369279,
            "ave_precision_score": 0.6650021734324354,
            "fpr": 0.01756311745334797,
            "logloss": 1.755069812395184,
            "mae": 0.44228976836138534,
            "precision": 0.9069767441860465,
            "recall": 0.3263598326359833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 18313,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6644918827908475,
            "auditor_fn_violation": 0.008302005012531337,
            "auditor_fp_violation": 0.037693143408981174,
            "ave_precision_score": 0.6521144961373012,
            "fpr": 0.14473684210526316,
            "logloss": 1.8423044140251499,
            "mae": 0.37437787800700517,
            "precision": 0.7203389830508474,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.688571629627925,
            "auditor_fn_violation": 0.014439968952229612,
            "auditor_fp_violation": 0.030689823887157984,
            "ave_precision_score": 0.6762516050095544,
            "fpr": 0.12733260153677278,
            "logloss": 1.8270229686753645,
            "mae": 0.3585102068409569,
            "precision": 0.75,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5948796185654848,
            "auditor_fn_violation": 0.009536709420610358,
            "auditor_fp_violation": 0.004971933848382424,
            "ave_precision_score": 0.5947521072792701,
            "fpr": 0.16776315789473684,
            "logloss": 0.6877487820582094,
            "mae": 0.4804920761666277,
            "precision": 0.6106870229007634,
            "recall": 0.5042016806722689
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5680557403003966,
            "auditor_fn_violation": 0.019087948780364586,
            "auditor_fp_violation": 0.01429031366693455,
            "ave_precision_score": 0.570815839138672,
            "fpr": 0.19209659714599342,
            "logloss": 0.6954498536313314,
            "mae": 0.4840197626636266,
            "precision": 0.5833333333333334,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6608544074347831,
            "auditor_fn_violation": 0.010338345864661654,
            "auditor_fp_violation": 0.03932530581039756,
            "ave_precision_score": 0.6484622978329863,
            "fpr": 0.14802631578947367,
            "logloss": 1.859348570681882,
            "mae": 0.37628005656389224,
            "precision": 0.7157894736842105,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6859126815304629,
            "auditor_fn_violation": 0.01473391234057016,
            "auditor_fp_violation": 0.03380798706089038,
            "ave_precision_score": 0.6736021886513468,
            "fpr": 0.13062568605927552,
            "logloss": 1.8406631713931905,
            "mae": 0.3603710849839953,
            "precision": 0.7440860215053764,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7201099117708379,
            "auditor_fn_violation": 0.005705900781365193,
            "auditor_fp_violation": 0.0030782230806373737,
            "ave_precision_score": 0.6611774856880024,
            "fpr": 0.015350877192982455,
            "logloss": 0.6467925833936129,
            "mae": 0.4645690428779313,
            "precision": 0.9141104294478528,
            "recall": 0.3130252100840336
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.729654581505304,
            "auditor_fn_violation": 0.003674292354256896,
            "auditor_fp_violation": 0.002256231889936446,
            "ave_precision_score": 0.6674350060438388,
            "fpr": 0.014270032930845226,
            "logloss": 0.6461439043813706,
            "mae": 0.4599999027116108,
            "precision": 0.9281767955801105,
            "recall": 0.3514644351464435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6797769363644683,
            "auditor_fn_violation": 0.007772187822497421,
            "auditor_fp_violation": 0.03569129245131177,
            "ave_precision_score": 0.6701084895894586,
            "fpr": 0.14035087719298245,
            "logloss": 1.5420301373533216,
            "mae": 0.36241252206903146,
            "precision": 0.7322175732217573,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7087099089707736,
            "auditor_fn_violation": 0.008767780130345532,
            "auditor_fp_violation": 0.0290445491719122,
            "ave_precision_score": 0.6979646043509887,
            "fpr": 0.12294182217343579,
            "logloss": 1.6278399853415249,
            "mae": 0.34826807234882,
            "precision": 0.7606837606837606,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 18313,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6642305168012015,
            "auditor_fn_violation": 0.009260283060592664,
            "auditor_fp_violation": 0.03866892000643811,
            "ave_precision_score": 0.6526156961904351,
            "fpr": 0.1524122807017544,
            "logloss": 1.8510168610069317,
            "mae": 0.3705249632373779,
            "precision": 0.7139917695473251,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.6883997321514297,
            "auditor_fn_violation": 0.01141097419268909,
            "auditor_fp_violation": 0.03282183626854737,
            "ave_precision_score": 0.6768307989936538,
            "fpr": 0.12843029637760703,
            "logloss": 1.8296581191996428,
            "mae": 0.35460591847414374,
            "precision": 0.7510638297872341,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7191565622910654,
            "auditor_fn_violation": 0.000193498452012392,
            "auditor_fp_violation": 0.0002816674714308711,
            "ave_precision_score": 0.7194254274817634,
            "fpr": 0.008771929824561403,
            "logloss": 0.6495686175885086,
            "mae": 0.47179277646437023,
            "precision": 0.9432624113475178,
            "recall": 0.27941176470588236
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7375642982037112,
            "auditor_fn_violation": 0.006044210922752602,
            "auditor_fp_violation": 0.003348856546748364,
            "ave_precision_score": 0.7380758087614141,
            "fpr": 0.009879253567508232,
            "logloss": 0.6511105205232344,
            "mae": 0.4672898855612385,
            "precision": 0.9423076923076923,
            "recall": 0.3075313807531381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7297014367220265,
            "auditor_fn_violation": 0.07009481424148607,
            "auditor_fp_violation": 0.01582619105102205,
            "ave_precision_score": 0.729177832622623,
            "fpr": 0.03399122807017544,
            "logloss": 0.6381194751746195,
            "mae": 0.4488395099985626,
            "precision": 0.8258426966292135,
            "recall": 0.3088235294117647
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7503283648683805,
            "auditor_fn_violation": 0.06703287113797428,
            "auditor_fp_violation": 0.008670014678182745,
            "ave_precision_score": 0.7496125401601315,
            "fpr": 0.019758507135016465,
            "logloss": 0.6239271329047295,
            "mae": 0.4421325582851432,
            "precision": 0.8853503184713376,
            "recall": 0.2907949790794979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 18313,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7190170450015175,
            "auditor_fn_violation": 0.005086245024325537,
            "auditor_fp_violation": 0.0030782230806373737,
            "ave_precision_score": 0.6600470477627683,
            "fpr": 0.015350877192982455,
            "logloss": 0.6476568995043455,
            "mae": 0.46523866295945226,
            "precision": 0.9135802469135802,
            "recall": 0.31092436974789917
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7274635497898786,
            "auditor_fn_violation": 0.003674292354256896,
            "auditor_fp_violation": 0.002256231889936446,
            "ave_precision_score": 0.6651502538656238,
            "fpr": 0.014270032930845226,
            "logloss": 0.6469562123809961,
            "mae": 0.4607079810944399,
            "precision": 0.9281767955801105,
            "recall": 0.3514644351464435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.7056339548810566,
            "auditor_fn_violation": 0.07295582706766918,
            "auditor_fp_violation": 0.01625623692258169,
            "ave_precision_score": 0.6825304372722585,
            "fpr": 0.03508771929824561,
            "logloss": 0.6365776976364262,
            "mae": 0.44811401044410704,
            "precision": 0.827027027027027,
            "recall": 0.32142857142857145
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7169475491592243,
            "auditor_fn_violation": 0.07378438333892133,
            "auditor_fp_violation": 0.009103515412091883,
            "ave_precision_score": 0.693385464874605,
            "fpr": 0.020856201975850714,
            "logloss": 0.6248985422248938,
            "mae": 0.4411928206477744,
            "precision": 0.8895348837209303,
            "recall": 0.3200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6772288048683849,
            "auditor_fn_violation": 0.007772187822497421,
            "auditor_fp_violation": 0.03569129245131177,
            "ave_precision_score": 0.6673948538840171,
            "fpr": 0.14035087719298245,
            "logloss": 1.5950545860390857,
            "mae": 0.36310179746840476,
            "precision": 0.7322175732217573,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7068214744489094,
            "auditor_fn_violation": 0.009541677957460883,
            "auditor_fp_violation": 0.0290445491719122,
            "ave_precision_score": 0.6952151445686364,
            "fpr": 0.12294182217343579,
            "logloss": 1.7026106035987878,
            "mae": 0.34861510366397686,
            "precision": 0.7611940298507462,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7473753116880866,
            "auditor_fn_violation": 0.002202196668140941,
            "auditor_fp_violation": 0.003601319813294709,
            "ave_precision_score": 0.5323969462117337,
            "fpr": 0.42105263157894735,
            "logloss": 15.468407176253953,
            "mae": 0.4579093464276012,
            "precision": 0.5373493975903615,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7513338587873759,
            "auditor_fn_violation": 0.0023308792122317197,
            "auditor_fp_violation": 0.0018632926282059399,
            "ave_precision_score": 0.5389779626023762,
            "fpr": 0.4127332601536773,
            "logloss": 15.22611630660026,
            "mae": 0.45261069758499756,
            "precision": 0.5420219244823387,
            "recall": 0.9309623430962343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.6825974360586229,
            "auditor_fn_violation": 0.01170204924074894,
            "auditor_fp_violation": 0.03583715596330276,
            "ave_precision_score": 0.67275786409483,
            "fpr": 0.13486842105263158,
            "logloss": 1.5581673948563135,
            "mae": 0.3556085458237743,
            "precision": 0.7388535031847133,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7104720285844736,
            "auditor_fn_violation": 0.011601578108566157,
            "auditor_fp_violation": 0.029688462542747995,
            "ave_precision_score": 0.6994254756057713,
            "fpr": 0.12294182217343579,
            "logloss": 1.6652575986903824,
            "mae": 0.3419766575813653,
            "precision": 0.7601713062098501,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.706148521873516,
            "auditor_fn_violation": 0.03970403951054106,
            "auditor_fp_violation": 0.02697217527764366,
            "ave_precision_score": 0.7069860796231193,
            "fpr": 0.13048245614035087,
            "logloss": 0.9181114384836614,
            "mae": 0.39481432496182955,
            "precision": 0.7076167076167076,
            "recall": 0.6050420168067226
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.746570815591009,
            "auditor_fn_violation": 0.03886023451170951,
            "auditor_fp_violation": 0.03545579686814734,
            "ave_precision_score": 0.7471049140005459,
            "fpr": 0.13391877058177826,
            "logloss": 0.7893331547985203,
            "mae": 0.38568722884488027,
            "precision": 0.6995073891625616,
            "recall": 0.5941422594142259
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8449399614490131,
            "auditor_fn_violation": 0.005867149491375502,
            "auditor_fp_violation": 0.021112485916626428,
            "ave_precision_score": 0.8451036072801398,
            "fpr": 0.19846491228070176,
            "logloss": 1.6231724255468707,
            "mae": 0.3372324175297161,
            "precision": 0.6857638888888888,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8492996068114471,
            "auditor_fn_violation": 0.011247927469468929,
            "auditor_fp_violation": 0.019512603209933508,
            "ave_precision_score": 0.8494846015753933,
            "fpr": 0.19978046103183314,
            "logloss": 1.7502041002465267,
            "mae": 0.3347766196978497,
            "precision": 0.6872852233676976,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7055765918816002,
            "auditor_fn_violation": 0.07247899159663866,
            "auditor_fp_violation": 0.01625623692258169,
            "ave_precision_score": 0.6824819926760564,
            "fpr": 0.03508771929824561,
            "logloss": 0.637290649345482,
            "mae": 0.4483891903063315,
            "precision": 0.8260869565217391,
            "recall": 0.31932773109243695
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7174391782799587,
            "auditor_fn_violation": 0.07426663421041754,
            "auditor_fp_violation": 0.009103515412091883,
            "ave_precision_score": 0.6932969172988808,
            "fpr": 0.020856201975850714,
            "logloss": 0.6219070813691596,
            "mae": 0.4415924864546135,
            "precision": 0.8901734104046243,
            "recall": 0.32217573221757323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8301060558318551,
            "auditor_fn_violation": 0.010322220993660623,
            "auditor_fp_violation": 0.02726893207790118,
            "ave_precision_score": 0.8302777038641023,
            "fpr": 0.17653508771929824,
            "logloss": 1.6190978358029664,
            "mae": 0.339220375940423,
            "precision": 0.6996268656716418,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8431304965240725,
            "auditor_fn_violation": 0.009013498431536454,
            "auditor_fp_violation": 0.016315852183855017,
            "ave_precision_score": 0.8432694057223107,
            "fpr": 0.1712403951701427,
            "logloss": 1.7274570604436161,
            "mae": 0.3309679993157431,
            "precision": 0.7094972067039106,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7583147607642157,
            "auditor_fn_violation": 0.002031733746130031,
            "auditor_fp_violation": 0.0027940407210687375,
            "ave_precision_score": 0.5304404877276707,
            "fpr": 0.45285087719298245,
            "logloss": 15.522892449923484,
            "mae": 0.46239891722552384,
            "precision": 0.5317460317460317,
            "recall": 0.9852941176470589
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7627958634360665,
            "auditor_fn_violation": 0.0023102113177390243,
            "auditor_fp_violation": 0.002228345877813649,
            "ave_precision_score": 0.5381800382961073,
            "fpr": 0.44127332601536773,
            "logloss": 15.152366303969947,
            "mae": 0.452948380238714,
            "precision": 0.5395189003436426,
            "recall": 0.9853556485355649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.63673919894751,
            "auditor_fn_violation": 0.011596085802742167,
            "auditor_fp_violation": 0.0065638580395943995,
            "ave_precision_score": 0.6362428339276704,
            "fpr": 0.1425438596491228,
            "logloss": 0.6684387370797126,
            "mae": 0.4771609120724494,
            "precision": 0.6578947368421053,
            "recall": 0.5252100840336135
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6097994124938624,
            "auditor_fn_violation": 0.011560242319580756,
            "auditor_fp_violation": 0.006066475182716752,
            "ave_precision_score": 0.6092027834410594,
            "fpr": 0.16465422612513722,
            "logloss": 0.6743555540949456,
            "mae": 0.479644943408987,
            "precision": 0.6305418719211823,
            "recall": 0.5355648535564853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7058374360088747,
            "auditor_fn_violation": 0.07438633348076074,
            "auditor_fp_violation": 0.01625623692258169,
            "ave_precision_score": 0.6827248996298191,
            "fpr": 0.03508771929824561,
            "logloss": 0.637240684138372,
            "mae": 0.44816079219443755,
            "precision": 0.8297872340425532,
            "recall": 0.3277310924369748
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7174391844683528,
            "auditor_fn_violation": 0.07426663421041754,
            "auditor_fp_violation": 0.009103515412091883,
            "ave_precision_score": 0.6932968669208277,
            "fpr": 0.020856201975850714,
            "logloss": 0.6216916983109535,
            "mae": 0.4413839266620143,
            "precision": 0.8901734104046243,
            "recall": 0.32217573221757323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6669603989917794,
            "auditor_fn_violation": 0.01376603272888103,
            "auditor_fp_violation": 0.03901848945758892,
            "ave_precision_score": 0.654505933466603,
            "fpr": 0.1524122807017544,
            "logloss": 1.8433033071051366,
            "mae": 0.3687406114441457,
            "precision": 0.7145790554414785,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.6908430735740582,
            "auditor_fn_violation": 0.010386765198939966,
            "auditor_fp_violation": 0.03380798706089038,
            "ave_precision_score": 0.6783987268367746,
            "fpr": 0.13062568605927552,
            "logloss": 1.8270880216793464,
            "mae": 0.35405275507796347,
            "precision": 0.7468085106382979,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.765013088737814,
            "auditor_fn_violation": 0.0014973094500958278,
            "auditor_fp_violation": 0.005799332045710607,
            "ave_precision_score": 0.5426588062724949,
            "fpr": 0.4418859649122807,
            "logloss": 14.919757400372243,
            "mae": 0.4482838645293925,
            "precision": 0.5383734249713631,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7696067103535966,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.009519270501922873,
            "ave_precision_score": 0.5526795474178967,
            "fpr": 0.43688254665203075,
            "logloss": 14.47198764689146,
            "mae": 0.44556978532213465,
            "precision": 0.5404157043879908,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 18313,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5519938997282152,
            "auditor_fn_violation": 0.01190706545776207,
            "auditor_fp_violation": 0.003923225494929985,
            "ave_precision_score": 0.5530669250128051,
            "fpr": 0.046052631578947366,
            "logloss": 0.6930868540180294,
            "mae": 0.499649305158017,
            "precision": 0.5757575757575758,
            "recall": 0.11974789915966387
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.5385423887289775,
            "auditor_fn_violation": 0.00938552053240496,
            "auditor_fp_violation": 0.009227734920638945,
            "ave_precision_score": 0.54045395095866,
            "fpr": 0.06586169045005488,
            "logloss": 0.6943784038234707,
            "mae": 0.5002837155247363,
            "precision": 0.4957983193277311,
            "recall": 0.12343096234309624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6254258592923978,
            "auditor_fn_violation": 0.10890737874097009,
            "auditor_fp_violation": 0.08631096088845969,
            "ave_precision_score": 0.6211555219006955,
            "fpr": 0.17105263157894737,
            "logloss": 0.6762070005011336,
            "mae": 0.4886104698832098,
            "precision": 0.6070528967254408,
            "recall": 0.5063025210084033
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6123694685390881,
            "auditor_fn_violation": 0.1026344676180022,
            "auditor_fp_violation": 0.09165878675566531,
            "ave_precision_score": 0.6086894480994203,
            "fpr": 0.18990120746432493,
            "logloss": 0.6749563229987189,
            "mae": 0.4861056499763849,
            "precision": 0.5800970873786407,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.728369190031694,
            "auditor_fn_violation": 0.009594298245614035,
            "auditor_fp_violation": 0.03480102205053919,
            "ave_precision_score": 0.7083935110076247,
            "fpr": 0.16447368421052633,
            "logloss": 2.398085681164662,
            "mae": 0.29474020618540964,
            "precision": 0.7120921305182342,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7292064830856472,
            "auditor_fn_violation": 0.018417390425712703,
            "auditor_fp_violation": 0.027586871265492578,
            "ave_precision_score": 0.708749580027264,
            "fpr": 0.15806805708013172,
            "logloss": 2.348099362103603,
            "mae": 0.2992575373775671,
            "precision": 0.71875,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6629633705640494,
            "auditor_fn_violation": 0.008838732861565685,
            "auditor_fp_violation": 0.04081411958796073,
            "ave_precision_score": 0.6504198595792454,
            "fpr": 0.1524122807017544,
            "logloss": 1.8424397925897846,
            "mae": 0.37907562068696216,
            "precision": 0.7128099173553719,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.6884616819364333,
            "auditor_fn_violation": 0.01020075414850572,
            "auditor_fp_violation": 0.033237591358378366,
            "ave_precision_score": 0.6759326718814824,
            "fpr": 0.12843029637760703,
            "logloss": 1.8275254168609745,
            "mae": 0.3633944700736835,
            "precision": 0.7494646680942184,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 18313,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8150285298863091,
            "auditor_fn_violation": 0.026336521450685546,
            "auditor_fp_violation": 0.00977034041525833,
            "ave_precision_score": 0.815316721070833,
            "fpr": 0.03618421052631579,
            "logloss": 0.6155573212961608,
            "mae": 0.3784426078772205,
            "precision": 0.8625,
            "recall": 0.43487394957983194
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8291585252778934,
            "auditor_fn_violation": 0.03230162265936095,
            "auditor_fp_violation": 0.005587342792606657,
            "ave_precision_score": 0.8293819672099594,
            "fpr": 0.02854006586169045,
            "logloss": 0.603556442780439,
            "mae": 0.374479743184851,
            "precision": 0.8844444444444445,
            "recall": 0.41631799163179917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7046144209857755,
            "auditor_fn_violation": 0.07200215612560813,
            "auditor_fp_violation": 0.01625623692258169,
            "ave_precision_score": 0.6833813038143023,
            "fpr": 0.03508771929824561,
            "logloss": 0.6374563683066823,
            "mae": 0.4487281787013145,
            "precision": 0.825136612021858,
            "recall": 0.3172268907563025
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.715178605897262,
            "auditor_fn_violation": 0.07426663421041754,
            "auditor_fp_violation": 0.009103515412091883,
            "ave_precision_score": 0.6923310586801602,
            "fpr": 0.020856201975850714,
            "logloss": 0.622269106273027,
            "mae": 0.4418720104511823,
            "precision": 0.8901734104046243,
            "recall": 0.32217573221757323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 18313,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7954366473078421,
            "auditor_fn_violation": 0.011271284829721362,
            "auditor_fp_violation": 0.0075899323998068575,
            "ave_precision_score": 0.7961247889396103,
            "fpr": 0.14802631578947367,
            "logloss": 0.5647727480351292,
            "mae": 0.37984675654259165,
            "precision": 0.7175732217573222,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7940002141122775,
            "auditor_fn_violation": 0.010046893156171213,
            "auditor_fp_violation": 0.01426749783883406,
            "ave_precision_score": 0.7950233545209309,
            "fpr": 0.15587266739846323,
            "logloss": 0.555640758532486,
            "mae": 0.3771928237540531,
            "precision": 0.7084188911704312,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7170498611137877,
            "auditor_fn_violation": 0.06952353309744952,
            "auditor_fp_violation": 0.01582619105102205,
            "ave_precision_score": 0.7172679128520678,
            "fpr": 0.03399122807017544,
            "logloss": 0.6373022547378008,
            "mae": 0.44739188436876265,
            "precision": 0.8333333333333334,
            "recall": 0.32563025210084034
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7356574358572225,
            "auditor_fn_violation": 0.06596732635523977,
            "auditor_fp_violation": 0.00828214560047457,
            "ave_precision_score": 0.7348139329277079,
            "fpr": 0.021953896816684963,
            "logloss": 0.6194022716950581,
            "mae": 0.44006603426258073,
            "precision": 0.8857142857142857,
            "recall": 0.32426778242677823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8233969011291107,
            "auditor_fn_violation": 0.010269239274657236,
            "auditor_fp_violation": 0.02655721873491067,
            "ave_precision_score": 0.8236463544053692,
            "fpr": 0.18640350877192982,
            "logloss": 1.6338518186142732,
            "mae": 0.3418214120627782,
            "precision": 0.6920289855072463,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8447884618823267,
            "auditor_fn_violation": 0.004119800302210548,
            "auditor_fp_violation": 0.022493871415063014,
            "ave_precision_score": 0.8449239042871052,
            "fpr": 0.18331503841931943,
            "logloss": 1.739044789322807,
            "mae": 0.3340828976705345,
            "precision": 0.6969147005444646,
            "recall": 0.803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 18313,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6688053631684445,
            "auditor_fn_violation": 0.00486971104231167,
            "auditor_fp_violation": 0.0018207790117495575,
            "ave_precision_score": 0.6694046871662205,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6598627126114839,
            "mae": 0.4781175799863903,
            "precision": 0.9607843137254902,
            "recall": 0.20588235294117646
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.675205498573717,
            "auditor_fn_violation": 0.003306863118831226,
            "auditor_fp_violation": 0.0023855215825058372,
            "ave_precision_score": 0.6756416932666398,
            "fpr": 0.010976948408342482,
            "logloss": 0.6630395777849447,
            "mae": 0.4754993924717741,
            "precision": 0.9122807017543859,
            "recall": 0.2175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8388723035831654,
            "auditor_fn_violation": 0.007783705587498163,
            "auditor_fp_violation": 0.02337840012876228,
            "ave_precision_score": 0.8390484460672551,
            "fpr": 0.15350877192982457,
            "logloss": 1.6025840798003086,
            "mae": 0.325368251862713,
            "precision": 0.7292069632495164,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8473559622348659,
            "auditor_fn_violation": 0.007936471485194904,
            "auditor_fp_violation": 0.019537954130045155,
            "ave_precision_score": 0.8475032984126569,
            "fpr": 0.14709110867178923,
            "logloss": 1.720324213177273,
            "mae": 0.32057567925889324,
            "precision": 0.7413127413127413,
            "recall": 0.803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.765322927969975,
            "auditor_fn_violation": 0.0014973094500958278,
            "auditor_fp_violation": 0.005799332045710607,
            "ave_precision_score": 0.5432784847368168,
            "fpr": 0.4418859649122807,
            "logloss": 14.896828617442305,
            "mae": 0.4482488998919766,
            "precision": 0.5383734249713631,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7696093503925154,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.009519270501922873,
            "ave_precision_score": 0.5526821872056106,
            "fpr": 0.43688254665203075,
            "logloss": 14.466422320566371,
            "mae": 0.4453085070079583,
            "precision": 0.5404157043879908,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7681987736530572,
            "auditor_fn_violation": 4.146395400265401e-05,
            "auditor_fp_violation": 0.010059552551102545,
            "ave_precision_score": 0.5489759575310735,
            "fpr": 0.43640350877192985,
            "logloss": 14.662835954528479,
            "mae": 0.4420480128245938,
            "precision": 0.5414746543778802,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.771951096822983,
            "auditor_fn_violation": 0.0020415286893339887,
            "auditor_fp_violation": 0.010943992212197346,
            "ave_precision_score": 0.5572815722688251,
            "fpr": 0.4313940724478595,
            "logloss": 14.233699394646406,
            "mae": 0.4403169279802272,
            "precision": 0.5440835266821346,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7685186104923478,
            "auditor_fn_violation": 0.0022298393041427105,
            "auditor_fp_violation": 0.010079671656204724,
            "ave_precision_score": 0.5496091618144027,
            "fpr": 0.43201754385964913,
            "logloss": 14.672170298927373,
            "mae": 0.44165488681051224,
            "precision": 0.54292343387471,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7731485153007671,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.013195153918111473,
            "ave_precision_score": 0.5586003709229009,
            "fpr": 0.41822173435784854,
            "logloss": 14.117188750497073,
            "mae": 0.4290963909824168,
            "precision": 0.5512367491166078,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6262786529815841,
            "auditor_fn_violation": 0.10890737874097009,
            "auditor_fp_violation": 0.08631096088845969,
            "ave_precision_score": 0.6213091344865446,
            "fpr": 0.17105263157894737,
            "logloss": 0.6762070439511052,
            "mae": 0.4886105008946176,
            "precision": 0.6070528967254408,
            "recall": 0.5063025210084033
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6141863815675763,
            "auditor_fn_violation": 0.1026344676180022,
            "auditor_fp_violation": 0.09165878675566531,
            "ave_precision_score": 0.609308598637492,
            "fpr": 0.18990120746432493,
            "logloss": 0.6749563570012687,
            "mae": 0.4861056803348428,
            "precision": 0.5800970873786407,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7345731605251928,
            "auditor_fn_violation": 0.017064720625092143,
            "auditor_fp_violation": 0.03565859890552068,
            "ave_precision_score": 0.7353419819293366,
            "fpr": 0.3300438596491228,
            "logloss": 0.9395780612518728,
            "mae": 0.3931601721822844,
            "precision": 0.5848275862068966,
            "recall": 0.8907563025210085
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.776364321550205,
            "auditor_fn_violation": 0.013438724285694603,
            "auditor_fp_violation": 0.03256072179139742,
            "ave_precision_score": 0.7769877793698856,
            "fpr": 0.33479692645444564,
            "logloss": 0.8630900457872768,
            "mae": 0.3890322665940201,
            "precision": 0.5889487870619946,
            "recall": 0.9142259414225942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 18313,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.659694638125025,
            "auditor_fn_violation": 0.008357290284534875,
            "auditor_fp_violation": 0.043854619346531475,
            "ave_precision_score": 0.6479133326548989,
            "fpr": 0.125,
            "logloss": 1.9013832681021758,
            "mae": 0.38429415282760665,
            "precision": 0.731764705882353,
            "recall": 0.6533613445378151
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6798180595948728,
            "auditor_fn_violation": 0.022856394876199313,
            "auditor_fp_violation": 0.03535185809568958,
            "ave_precision_score": 0.6680451029587033,
            "fpr": 0.10976948408342481,
            "logloss": 1.878141750547477,
            "mae": 0.3679193270021618,
            "precision": 0.7624703087885986,
            "recall": 0.6715481171548117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.660652928661881,
            "auditor_fn_violation": 0.01009877635264632,
            "auditor_fp_violation": 0.021768871720585874,
            "ave_precision_score": 0.6620783947069279,
            "fpr": 0.40789473684210525,
            "logloss": 1.2039737681450178,
            "mae": 0.43601212602649153,
            "precision": 0.5441176470588235,
            "recall": 0.9327731092436975
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6900798867575926,
            "auditor_fn_violation": 0.008297011422456355,
            "auditor_fp_violation": 0.01608515881083904,
            "ave_precision_score": 0.6911338219665637,
            "fpr": 0.4083424807903403,
            "logloss": 1.0928322880341395,
            "mae": 0.4348087084324308,
            "precision": 0.5468940316686967,
            "recall": 0.9393305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.765013088737814,
            "auditor_fn_violation": 0.0014973094500958278,
            "auditor_fp_violation": 0.005799332045710607,
            "ave_precision_score": 0.5426588062724949,
            "fpr": 0.4418859649122807,
            "logloss": 14.917611701219856,
            "mae": 0.4482528526103562,
            "precision": 0.5383734249713631,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7696079862084128,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.009519270501922873,
            "ave_precision_score": 0.5526808231693963,
            "fpr": 0.43688254665203075,
            "logloss": 14.468080093556297,
            "mae": 0.44534903715199897,
            "precision": 0.5404157043879908,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7291590303349289,
            "auditor_fn_violation": 0.0064960194604157485,
            "auditor_fp_violation": 0.03366932238854016,
            "ave_precision_score": 0.710662401228904,
            "fpr": 0.16447368421052633,
            "logloss": 2.3477957219260532,
            "mae": 0.29340887669672405,
            "precision": 0.715370018975332,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7304444315438676,
            "auditor_fn_violation": 0.016738698106361576,
            "auditor_fp_violation": 0.02924735653280536,
            "ave_precision_score": 0.7107490706649506,
            "fpr": 0.16136114160263446,
            "logloss": 2.3156254513296637,
            "mae": 0.2984635133069461,
            "precision": 0.7140077821011673,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.756829045095261,
            "auditor_fn_violation": 0.07152532065457763,
            "auditor_fp_violation": 0.016417189763399325,
            "ave_precision_score": 0.7561182823694782,
            "fpr": 0.03508771929824561,
            "logloss": 0.6276555675417118,
            "mae": 0.44212583289073226,
            "precision": 0.8241758241758241,
            "recall": 0.31512605042016806
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.7612689517581741,
            "auditor_fn_violation": 0.06992637636695158,
            "auditor_fp_violation": 0.009103515412091883,
            "ave_precision_score": 0.7601867472793881,
            "fpr": 0.020856201975850714,
            "logloss": 0.6192427012885151,
            "mae": 0.4384999436323258,
            "precision": 0.8841463414634146,
            "recall": 0.303347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5552144554000007,
            "auditor_fn_violation": 0.005095459236326118,
            "auditor_fp_violation": 0.01677681876710124,
            "ave_precision_score": 0.5562303426873878,
            "fpr": 0.10197368421052631,
            "logloss": 0.6927406221665241,
            "mae": 0.499503346584868,
            "precision": 0.5181347150259067,
            "recall": 0.21008403361344538
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5429822318830582,
            "auditor_fn_violation": 0.010421211689761133,
            "auditor_fp_violation": 0.013542461523641006,
            "ave_precision_score": 0.5441010907140901,
            "fpr": 0.10537870472008781,
            "logloss": 0.694079994261343,
            "mae": 0.5001560692991305,
            "precision": 0.5076923076923077,
            "recall": 0.20711297071129708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5513220293660249,
            "auditor_fn_violation": 0.006684910806427851,
            "auditor_fp_violation": 0.009365443425076454,
            "ave_precision_score": 0.5523933240190253,
            "fpr": 0.06140350877192982,
            "logloss": 0.6928012858655775,
            "mae": 0.4995299535231632,
            "precision": 0.5912408759124088,
            "recall": 0.17016806722689076
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.538127460894464,
            "auditor_fn_violation": 0.010173196955848788,
            "auditor_fp_violation": 0.010421763257897449,
            "ave_precision_score": 0.5400472395196192,
            "fpr": 0.07354555433589462,
            "logloss": 0.6941302351575174,
            "mae": 0.5001776894282561,
            "precision": 0.5379310344827586,
            "recall": 0.16317991631799164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6777316805269415,
            "auditor_fn_violation": 0.012535935426802315,
            "auditor_fp_violation": 0.03600062369225818,
            "ave_precision_score": 0.6686780487505459,
            "fpr": 0.14364035087719298,
            "logloss": 1.6075779262523562,
            "mae": 0.3605170450295861,
            "precision": 0.7253668763102725,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7024182781795516,
            "auditor_fn_violation": 0.01055440478760294,
            "auditor_fp_violation": 0.030238577509170698,
            "ave_precision_score": 0.6916982597098361,
            "fpr": 0.12184412733260154,
            "logloss": 1.713949649687195,
            "mae": 0.3449655625024559,
            "precision": 0.7612903225806451,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7433184059590515,
            "auditor_fn_violation": 0.01910566858322276,
            "auditor_fp_violation": 0.027693948173185268,
            "ave_precision_score": 0.7440585778882001,
            "fpr": 0.20614035087719298,
            "logloss": 0.8176505585729112,
            "mae": 0.36886785546108464,
            "precision": 0.6684303350970018,
            "recall": 0.7962184873949579
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.788789795414661,
            "auditor_fn_violation": 0.011383417000032151,
            "auditor_fp_violation": 0.03216778252966692,
            "ave_precision_score": 0.7894517688002823,
            "fpr": 0.21624588364434688,
            "logloss": 0.7021644432667923,
            "mae": 0.3599457465457007,
            "precision": 0.6638225255972696,
            "recall": 0.8138075313807531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7028368958611109,
            "auditor_fn_violation": 0.0008223684210526346,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.7030743917454003,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6751479006810929,
            "mae": 0.4886030260342778,
            "precision": 0.9883720930232558,
            "recall": 0.17857142857142858
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7197615359405934,
            "auditor_fn_violation": 0.00636341507102866,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.7201891245717911,
            "fpr": 0.005488474204171241,
            "logloss": 0.6781746182839955,
            "mae": 0.4866681320083652,
            "precision": 0.9468085106382979,
            "recall": 0.18619246861924685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7034572729697542,
            "auditor_fn_violation": 0.0008223684210526346,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.7036605316292183,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6740418318305995,
            "mae": 0.4878736842554389,
            "precision": 0.9883720930232558,
            "recall": 0.17857142857142858
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7202742156068949,
            "auditor_fn_violation": 0.006558611852348575,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.7206679797296529,
            "fpr": 0.005488474204171241,
            "logloss": 0.677276507485338,
            "mae": 0.4857736114743774,
            "precision": 0.9473684210526315,
            "recall": 0.18828451882845187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8298598915444748,
            "auditor_fn_violation": 0.015949800973020792,
            "auditor_fp_violation": 0.025870654273297936,
            "ave_precision_score": 0.8300132435334059,
            "fpr": 0.17434210526315788,
            "logloss": 1.64592903925652,
            "mae": 0.3413679672042243,
            "precision": 0.7050092764378478,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8433522703322267,
            "auditor_fn_violation": 0.005502252800499707,
            "auditor_fp_violation": 0.015035630718216923,
            "ave_precision_score": 0.8434670322705552,
            "fpr": 0.1778265642151482,
            "logloss": 1.749927732273381,
            "mae": 0.3332046246975658,
            "precision": 0.7022058823529411,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.703659262975811,
            "auditor_fn_violation": 0.0008223684210526346,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.7038983327310845,
            "fpr": 0.0010964912280701754,
            "logloss": 0.673129948463428,
            "mae": 0.4872672005246083,
            "precision": 0.9883720930232558,
            "recall": 0.17857142857142858
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7205320990277408,
            "auditor_fn_violation": 0.00688700173151029,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.7209664378187532,
            "fpr": 0.005488474204171241,
            "logloss": 0.6765243020831417,
            "mae": 0.4850331565158689,
            "precision": 0.9489795918367347,
            "recall": 0.19456066945606695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6782297536321966,
            "auditor_fn_violation": 0.009352425180598556,
            "auditor_fp_violation": 0.005288809753742158,
            "ave_precision_score": 0.6785961005549611,
            "fpr": 0.15460526315789475,
            "logloss": 0.6673767981966896,
            "mae": 0.47131018562797916,
            "precision": 0.6492537313432836,
            "recall": 0.5483193277310925
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6898995848747823,
            "auditor_fn_violation": 0.02192174675858523,
            "auditor_fp_violation": 0.017892679414799374,
            "ave_precision_score": 0.6902275110621543,
            "fpr": 0.16575192096597147,
            "logloss": 0.6758491000795982,
            "mae": 0.47224818632971705,
            "precision": 0.639618138424821,
            "recall": 0.5606694560669456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6892786575231937,
            "auditor_fn_violation": 0.038027052926433734,
            "auditor_fp_violation": 0.015039031063898277,
            "ave_precision_score": 0.6905317711348365,
            "fpr": 0.11842105263157894,
            "logloss": 0.962120414425562,
            "mae": 0.4079880955423989,
            "precision": 0.7081081081081081,
            "recall": 0.5504201680672269
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7247637662597721,
            "auditor_fn_violation": 0.028944238020658705,
            "auditor_fp_violation": 0.019773717687083456,
            "ave_precision_score": 0.725490885848397,
            "fpr": 0.1163556531284303,
            "logloss": 0.8279837179029149,
            "mae": 0.4006787313207351,
            "precision": 0.7095890410958904,
            "recall": 0.5418410041841004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7487884051634328,
            "auditor_fn_violation": 0.03467768686421938,
            "auditor_fp_violation": 0.011603693867696765,
            "ave_precision_score": 0.7491018828036515,
            "fpr": 0.027412280701754384,
            "logloss": 0.6168729177167702,
            "mae": 0.4361930420916331,
            "precision": 0.8837209302325582,
            "recall": 0.39915966386554624
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7738644931312535,
            "auditor_fn_violation": 0.03034046911527634,
            "auditor_fp_violation": 0.003924322433282715,
            "ave_precision_score": 0.774133955045634,
            "fpr": 0.01756311745334797,
            "logloss": 0.6084119686905919,
            "mae": 0.4286779384123638,
            "precision": 0.9179487179487179,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 18313,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7135848024919504,
            "auditor_fn_violation": 0.0039344685242518095,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.713817620923586,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6719318559158624,
            "mae": 0.48641525797153773,
            "precision": 0.9882352941176471,
            "recall": 0.17647058823529413
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7273389171149587,
            "auditor_fn_violation": 0.005447138415185855,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.7277332441242217,
            "fpr": 0.005488474204171241,
            "logloss": 0.6751364812520328,
            "mae": 0.48401651836514603,
            "precision": 0.9468085106382979,
            "recall": 0.18619246861924685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7676625284424211,
            "auditor_fn_violation": 0.0022298393041427105,
            "auditor_fp_violation": 0.010079671656204724,
            "ave_precision_score": 0.5469584104133322,
            "fpr": 0.43201754385964913,
            "logloss": 14.802574185913222,
            "mae": 0.44203882838777175,
            "precision": 0.54292343387471,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7731202464474288,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.012771793552246983,
            "ave_precision_score": 0.5585721051050905,
            "fpr": 0.42041712403951703,
            "logloss": 14.153261227831832,
            "mae": 0.4310921449411284,
            "precision": 0.5499412455934195,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6697950291275514,
            "auditor_fn_violation": 0.003123617868199926,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.6700238018644231,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6642194333859731,
            "mae": 0.4813015724679357,
            "precision": 0.9896907216494846,
            "recall": 0.20168067226890757
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6842268197182471,
            "auditor_fn_violation": 0.0043356649780231515,
            "auditor_fp_violation": 0.0025680482073096845,
            "ave_precision_score": 0.6847504722033952,
            "fpr": 0.006586169045005488,
            "logloss": 0.6688947354462965,
            "mae": 0.47845759591993464,
            "precision": 0.9454545454545454,
            "recall": 0.2175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7431819385712439,
            "auditor_fn_violation": 0.01910566858322276,
            "auditor_fp_violation": 0.027693948173185268,
            "ave_precision_score": 0.7439237468250105,
            "fpr": 0.20614035087719298,
            "logloss": 0.8176171066710437,
            "mae": 0.3689178529050337,
            "precision": 0.6684303350970018,
            "recall": 0.7962184873949579
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7886210719685298,
            "auditor_fn_violation": 0.011383417000032151,
            "auditor_fp_violation": 0.03216778252966692,
            "ave_precision_score": 0.7892835794654894,
            "fpr": 0.21624588364434688,
            "logloss": 0.7019899503386923,
            "mae": 0.36002794947012695,
            "precision": 0.6638225255972696,
            "recall": 0.8138075313807531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6532031625820489,
            "auditor_fn_violation": 0.01658788515406163,
            "auditor_fp_violation": 0.03664694994366651,
            "ave_precision_score": 0.640860268559103,
            "fpr": 0.13048245614035087,
            "logloss": 1.8442117295550837,
            "mae": 0.38726577161108716,
            "precision": 0.7319819819819819,
            "recall": 0.6827731092436975
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.6862030715347638,
            "auditor_fn_violation": 0.012956473414198389,
            "auditor_fp_violation": 0.03230974768229213,
            "ave_precision_score": 0.6738663825077733,
            "fpr": 0.1207464324917673,
            "logloss": 1.8343857732768323,
            "mae": 0.3719098911764822,
            "precision": 0.7522522522522522,
            "recall": 0.698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8283180935144876,
            "auditor_fn_violation": 0.003883790358248581,
            "auditor_fp_violation": 0.00029927168839530017,
            "ave_precision_score": 0.8252809839898294,
            "fpr": 0.003289473684210526,
            "logloss": 0.6538168601351867,
            "mae": 0.47464135560419474,
            "precision": 0.9734513274336283,
            "recall": 0.23109243697478993
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.8287521100091608,
            "auditor_fn_violation": 0.0076218602023616615,
            "auditor_fp_violation": 0.0022410213378694583,
            "ave_precision_score": 0.8255012184031874,
            "fpr": 0.007683863885839737,
            "logloss": 0.6566968019567317,
            "mae": 0.4712951803246654,
            "precision": 0.9453125,
            "recall": 0.25313807531380755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8124886681035189,
            "auditor_fn_violation": 0.014779596048945895,
            "auditor_fp_violation": 0.008485232576854986,
            "ave_precision_score": 0.8138139597329318,
            "fpr": 0.14583333333333334,
            "logloss": 1.1254991254075322,
            "mae": 0.3056307376420323,
            "precision": 0.7302231237322515,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8432756117451182,
            "auditor_fn_violation": 0.011849592842478492,
            "auditor_fp_violation": 0.018703908858372018,
            "ave_precision_score": 0.8434740939225681,
            "fpr": 0.13830954994511527,
            "logloss": 1.0160876664658338,
            "mae": 0.30143113988942966,
            "precision": 0.7439024390243902,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.6833841700548818,
            "auditor_fn_violation": 0.01170204924074894,
            "auditor_fp_violation": 0.03583715596330276,
            "ave_precision_score": 0.6737029219088982,
            "fpr": 0.13486842105263158,
            "logloss": 1.5364241607908622,
            "mae": 0.3555333769243014,
            "precision": 0.7388535031847133,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7107390334802337,
            "auditor_fn_violation": 0.012386958099288567,
            "auditor_fp_violation": 0.030040840332299864,
            "ave_precision_score": 0.6998353160547239,
            "fpr": 0.12184412733260154,
            "logloss": 1.644578214107473,
            "mae": 0.3419744798833858,
            "precision": 0.7623126338329764,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7684389627245892,
            "auditor_fn_violation": 0.0022298393041427105,
            "auditor_fp_violation": 0.010079671656204724,
            "ave_precision_score": 0.5503811532762553,
            "fpr": 0.43201754385964913,
            "logloss": 14.613259787448403,
            "mae": 0.4416159002654447,
            "precision": 0.54292343387471,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7731410459941036,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.01275404790816883,
            "ave_precision_score": 0.5585936041802709,
            "fpr": 0.41931942919868276,
            "logloss": 14.123189273893345,
            "mae": 0.42969748017246195,
            "precision": 0.5505882352941176,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7065941811830105,
            "auditor_fn_violation": 0.017831803774141237,
            "auditor_fp_violation": 0.04258711572509255,
            "ave_precision_score": 0.7075116404843254,
            "fpr": 0.2949561403508772,
            "logloss": 0.985917147163824,
            "mae": 0.401549103414008,
            "precision": 0.6008902077151336,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7468350830997358,
            "auditor_fn_violation": 0.015080673681503152,
            "auditor_fp_violation": 0.03895422384355441,
            "ave_precision_score": 0.7475117817312784,
            "fpr": 0.300768386388584,
            "logloss": 0.8657701263068694,
            "mae": 0.3936101434001066,
            "precision": 0.6080114449213162,
            "recall": 0.8891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6691666226406849,
            "auditor_fn_violation": 0.002186071797139928,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.6694627035660676,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6651182193092727,
            "mae": 0.48189437556031506,
            "precision": 0.9893617021276596,
            "recall": 0.1953781512605042
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6859332996005445,
            "auditor_fn_violation": 0.005206012979437752,
            "auditor_fp_violation": 0.0025680482073096845,
            "ave_precision_score": 0.6863482560636845,
            "fpr": 0.006586169045005488,
            "logloss": 0.6690588868978705,
            "mae": 0.4791310444621433,
            "precision": 0.944954128440367,
            "recall": 0.21548117154811716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7219618886973632,
            "auditor_fn_violation": 0.024620374465575703,
            "auditor_fp_violation": 0.04431232898760663,
            "ave_precision_score": 0.7226787637642128,
            "fpr": 0.23793859649122806,
            "logloss": 0.8801417764653193,
            "mae": 0.38667116735707246,
            "precision": 0.6284246575342466,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7623439205053146,
            "auditor_fn_violation": 0.018986905740622523,
            "auditor_fp_violation": 0.042371527874604215,
            "ave_precision_score": 0.7627836940052686,
            "fpr": 0.2327113062568606,
            "logloss": 0.7571409446935442,
            "mae": 0.380831697356437,
            "precision": 0.6313043478260869,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6742723919713681,
            "auditor_fn_violation": 0.003469150818222032,
            "auditor_fp_violation": 0.0009154192821503301,
            "ave_precision_score": 0.6745149431944952,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6567103335224378,
            "mae": 0.4765632354507321,
            "precision": 0.9649122807017544,
            "recall": 0.23109243697478993
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6888972986597143,
            "auditor_fn_violation": 0.007020194829352094,
            "auditor_fp_violation": 0.0023272144662490526,
            "ave_precision_score": 0.6894770623900073,
            "fpr": 0.008781558726673985,
            "logloss": 0.660854481113608,
            "mae": 0.47435525772862064,
            "precision": 0.936,
            "recall": 0.24476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8101173128751163,
            "auditor_fn_violation": 0.01552134011499337,
            "auditor_fp_violation": 0.013356570899726396,
            "ave_precision_score": 0.8114511666755928,
            "fpr": 0.14364035087719298,
            "logloss": 1.1481707444892737,
            "mae": 0.3070766544386897,
            "precision": 0.7321063394683026,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8419931250437909,
            "auditor_fn_violation": 0.00801455019772286,
            "auditor_fp_violation": 0.018528987509601663,
            "ave_precision_score": 0.8422114540646344,
            "fpr": 0.13611416026344675,
            "logloss": 1.0354357457032421,
            "mae": 0.3023903365106749,
            "precision": 0.7459016393442623,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6652557671296264,
            "auditor_fn_violation": 0.0030683325961963627,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.66557239566801,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6683514018424457,
            "mae": 0.4839619022647017,
            "precision": 0.9887640449438202,
            "recall": 0.18487394957983194
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6814715703305166,
            "auditor_fn_violation": 0.002989955403276564,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.6818546694037991,
            "fpr": 0.005488474204171241,
            "logloss": 0.6724171800484252,
            "mae": 0.4813797506294188,
            "precision": 0.95,
            "recall": 0.19874476987447698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8167222167781242,
            "auditor_fn_violation": 0.0020916261241338712,
            "auditor_fp_violation": 0.005434673265733141,
            "ave_precision_score": 0.8169917663589634,
            "fpr": 0.05592105263157895,
            "logloss": 1.659391563808825,
            "mae": 0.33139792601049645,
            "precision": 0.8538681948424068,
            "recall": 0.6260504201680672
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8377183762430369,
            "auditor_fn_violation": 0.00562626016745588,
            "auditor_fp_violation": 0.005267921199199927,
            "ave_precision_score": 0.8378514332086707,
            "fpr": 0.048298572996706916,
            "logloss": 1.754145425155709,
            "mae": 0.32682586308137723,
            "precision": 0.8713450292397661,
            "recall": 0.6234309623430963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8334296964695901,
            "auditor_fn_violation": 0.007654706619489904,
            "auditor_fp_violation": 0.01951301706100113,
            "ave_precision_score": 0.8336624547987677,
            "fpr": 0.14144736842105263,
            "logloss": 1.6020251076311711,
            "mae": 0.3217656312678434,
            "precision": 0.7378048780487805,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.848346319717166,
            "auditor_fn_violation": 0.00829930785517777,
            "auditor_fp_violation": 0.01800929364731294,
            "ave_precision_score": 0.8484652865567164,
            "fpr": 0.13721185510428102,
            "logloss": 1.7144871514554538,
            "mae": 0.31618554340907196,
            "precision": 0.75,
            "recall": 0.7845188284518828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6231849433937657,
            "auditor_fn_violation": 0.009509066784608581,
            "auditor_fp_violation": 0.02217125382262997,
            "ave_precision_score": 0.625049737524503,
            "fpr": 0.41118421052631576,
            "logloss": 1.3445716448335143,
            "mae": 0.4386640932716938,
            "precision": 0.5426829268292683,
            "recall": 0.9348739495798319
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6439823983249842,
            "auditor_fn_violation": 0.007821649849124371,
            "auditor_fp_violation": 0.01608515881083904,
            "ave_precision_score": 0.6454875507807365,
            "fpr": 0.4083424807903403,
            "logloss": 1.195878290917393,
            "mae": 0.4361899650205354,
            "precision": 0.5474452554744526,
            "recall": 0.9414225941422594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7689763599485459,
            "auditor_fn_violation": 0.0022298393041427105,
            "auditor_fp_violation": 0.009010844197650088,
            "ave_precision_score": 0.5524097984234402,
            "fpr": 0.4331140350877193,
            "logloss": 14.496505633162203,
            "mae": 0.4418704479431865,
            "precision": 0.5422943221320974,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7744939358250544,
            "auditor_fn_violation": 0.0027189763421501044,
            "auditor_fp_violation": 0.015167455502797472,
            "ave_precision_score": 0.5612597604521462,
            "fpr": 0.4149286498353458,
            "logloss": 13.974130293602666,
            "mae": 0.42553019123457786,
            "precision": 0.5531914893617021,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 18313,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6918830630631239,
            "auditor_fn_violation": 0.07963152366209643,
            "auditor_fp_violation": 0.013376690004828586,
            "ave_precision_score": 0.6665584931773224,
            "fpr": 0.029605263157894735,
            "logloss": 1.6617453837301424,
            "mae": 0.4449621251927734,
            "precision": 0.8608247422680413,
            "recall": 0.35084033613445376
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6979430987444557,
            "auditor_fn_violation": 0.07523113595340998,
            "auditor_fp_violation": 0.008031171491369279,
            "ave_precision_score": 0.6650086439158021,
            "fpr": 0.01756311745334797,
            "logloss": 1.7550690865534015,
            "mae": 0.4422924980753369,
            "precision": 0.9069767441860465,
            "recall": 0.3263598326359833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5891671648317253,
            "auditor_fn_violation": 0.10481166150670795,
            "auditor_fp_violation": 0.08817700788668921,
            "ave_precision_score": 0.5879567798736317,
            "fpr": 0.19956140350877194,
            "logloss": 0.6894360121187858,
            "mae": 0.49433268039699707,
            "precision": 0.5806451612903226,
            "recall": 0.5294117647058824
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5747866389110007,
            "auditor_fn_violation": 0.11136780125752656,
            "auditor_fp_violation": 0.09931983481340456,
            "ave_precision_score": 0.5741147789550641,
            "fpr": 0.20636663007683864,
            "logloss": 0.684807571382784,
            "mae": 0.49335064476460183,
            "precision": 0.5607476635514018,
            "recall": 0.502092050209205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7048359867628444,
            "auditor_fn_violation": 0.07200215612560813,
            "auditor_fp_violation": 0.01625623692258169,
            "ave_precision_score": 0.6836040142446997,
            "fpr": 0.03508771929824561,
            "logloss": 0.637369214219389,
            "mae": 0.44849726373917964,
            "precision": 0.825136612021858,
            "recall": 0.3172268907563025
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7153583213545543,
            "auditor_fn_violation": 0.07426663421041754,
            "auditor_fp_violation": 0.009103515412091883,
            "ave_precision_score": 0.6925104715190479,
            "fpr": 0.020856201975850714,
            "logloss": 0.6220749815328445,
            "mae": 0.44168402535102763,
            "precision": 0.8901734104046243,
            "recall": 0.32217573221757323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6837913019200981,
            "auditor_fn_violation": 0.07076284461152882,
            "auditor_fp_violation": 0.019802229196845326,
            "ave_precision_score": 0.6801714064627756,
            "fpr": 0.046052631578947366,
            "logloss": 0.6443164613133538,
            "mae": 0.4533430109159988,
            "precision": 0.7846153846153846,
            "recall": 0.32142857142857145
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7053992928227992,
            "auditor_fn_violation": 0.0697977761345526,
            "auditor_fp_violation": 0.01458945452425196,
            "ave_precision_score": 0.7013179443333644,
            "fpr": 0.03293084522502744,
            "logloss": 0.6279540163818468,
            "mae": 0.4466215185616595,
            "precision": 0.8333333333333334,
            "recall": 0.3138075313807531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.70280596410417,
            "auditor_fn_violation": 0.0008223684210526346,
            "auditor_fp_violation": 0.0005683647191372928,
            "ave_precision_score": 0.703049547791456,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6750949890556719,
            "mae": 0.48856829116611106,
            "precision": 0.9883720930232558,
            "recall": 0.17857142857142858
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7197263626737034,
            "auditor_fn_violation": 0.006558611852348575,
            "auditor_fp_violation": 0.0019190646524515607,
            "ave_precision_score": 0.720150289719756,
            "fpr": 0.005488474204171241,
            "logloss": 0.6781317452022707,
            "mae": 0.4866256097211011,
            "precision": 0.9473684210526315,
            "recall": 0.18828451882845187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6743413024608524,
            "auditor_fn_violation": 0.0039459862892525475,
            "auditor_fp_violation": 0.0009154192821503301,
            "ave_precision_score": 0.6745767403917582,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6562116951387947,
            "mae": 0.47616479954306495,
            "precision": 0.9646017699115044,
            "recall": 0.22899159663865545
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6885952704382815,
            "auditor_fn_violation": 0.007020194829352094,
            "auditor_fp_violation": 0.0023272144662490526,
            "ave_precision_score": 0.6892828021826622,
            "fpr": 0.008781558726673985,
            "logloss": 0.6605501055301983,
            "mae": 0.4739341016135022,
            "precision": 0.936,
            "recall": 0.24476987447698745
        }
    }
]