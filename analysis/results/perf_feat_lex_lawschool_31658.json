[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8546872239575904,
            "auditor_fn_violation": 0.017949133614323286,
            "auditor_fp_violation": 0.01315789473684211,
            "ave_precision_score": 0.8550891011974715,
            "fpr": 0.09320175438596491,
            "logloss": 0.5456219317312884,
            "mae": 0.2840073647888754,
            "precision": 0.8068181818181818,
            "recall": 0.728952772073922
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8759206702487579,
            "auditor_fn_violation": 0.0016853259119446675,
            "auditor_fp_violation": 0.012682825525855167,
            "ave_precision_score": 0.8763454015762223,
            "fpr": 0.09440175631174534,
            "logloss": 0.4534283395128206,
            "mae": 0.2567279982817135,
            "precision": 0.8114035087719298,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8176762113921815,
            "auditor_fn_violation": 0.016015076191505457,
            "auditor_fp_violation": 0.005394736842105267,
            "ave_precision_score": 0.8182463817547825,
            "fpr": 0.11403508771929824,
            "logloss": 0.5782522849430012,
            "mae": 0.3088707960127149,
            "precision": 0.7787234042553192,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.877151182688534,
            "auditor_fn_violation": 0.011660950975115002,
            "auditor_fp_violation": 0.01866822915121489,
            "ave_precision_score": 0.8774044595249395,
            "fpr": 0.11525795828759605,
            "logloss": 0.4708163373084211,
            "mae": 0.27320149947253036,
            "precision": 0.7848360655737705,
            "recall": 0.8201284796573876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.85996220603552,
            "auditor_fn_violation": 0.018415198674303832,
            "auditor_fp_violation": 0.017786377708978344,
            "ave_precision_score": 0.8603087761865225,
            "fpr": 0.12828947368421054,
            "logloss": 0.5238251943741946,
            "mae": 0.2817090862667771,
            "precision": 0.7728155339805826,
            "recall": 0.8172484599589322
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8833703704716058,
            "auditor_fn_violation": 0.001875718378984433,
            "auditor_fp_violation": 0.015610011768079827,
            "ave_precision_score": 0.8835478977203794,
            "fpr": 0.14270032930845225,
            "logloss": 0.46979355941024775,
            "mae": 0.2632966192825631,
            "precision": 0.7565543071161048,
            "recall": 0.8650963597430407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7682905991693509,
            "auditor_fn_violation": 0.015992560971216548,
            "auditor_fp_violation": 0.01672084623323013,
            "ave_precision_score": 0.7289821245108417,
            "fpr": 0.2149122807017544,
            "logloss": 2.7817781645330486,
            "mae": 0.3083528763708544,
            "precision": 0.6818181818181818,
            "recall": 0.8624229979466119
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7602233602818531,
            "auditor_fn_violation": 0.014352301280800684,
            "auditor_fp_violation": 0.037146092305258054,
            "ave_precision_score": 0.7181656323740563,
            "fpr": 0.22283205268935236,
            "logloss": 2.9132545906604226,
            "mae": 0.29815630051619185,
            "precision": 0.6793048973143759,
            "recall": 0.9207708779443254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6490340317886668,
            "auditor_fn_violation": 0.005651320292517746,
            "auditor_fp_violation": 0.003998968008255934,
            "ave_precision_score": 0.6406056678079488,
            "fpr": 0.04276315789473684,
            "logloss": 10.297713615087135,
            "mae": 0.45443315870670487,
            "precision": 0.7650602409638554,
            "recall": 0.26078028747433263
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6571188780860189,
            "auditor_fn_violation": 0.013649494519752633,
            "auditor_fp_violation": 0.004709704215741539,
            "ave_precision_score": 0.6528315158348249,
            "fpr": 0.042810098792535674,
            "logloss": 10.215641807941049,
            "mae": 0.4232231249608153,
            "precision": 0.7808988764044944,
            "recall": 0.29764453961456105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8381600619645513,
            "auditor_fn_violation": 0.0030530638711769157,
            "auditor_fp_violation": 0.004486584107327142,
            "ave_precision_score": 0.8385740878195926,
            "fpr": 0.08114035087719298,
            "logloss": 0.5505800657225219,
            "mae": 0.3248852332722061,
            "precision": 0.8092783505154639,
            "recall": 0.6447638603696099
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.881167474479362,
            "auditor_fn_violation": 0.008212731849839115,
            "auditor_fp_violation": 0.0026453456749834362,
            "ave_precision_score": 0.8813553221127883,
            "fpr": 0.06476399560922064,
            "logloss": 0.45325327145256195,
            "mae": 0.2838517724312474,
            "precision": 0.8539603960396039,
            "recall": 0.7387580299785867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7354450627102997,
            "auditor_fn_violation": 0.017039518714651113,
            "auditor_fp_violation": 0.01688080495356038,
            "ave_precision_score": 0.7365879520016071,
            "fpr": 0.12280701754385964,
            "logloss": 0.662262970378476,
            "mae": 0.33621203872424205,
            "precision": 0.7611940298507462,
            "recall": 0.7330595482546202
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8356896217867936,
            "auditor_fn_violation": 0.0008532403152523198,
            "auditor_fp_violation": 0.01865092315147201,
            "ave_precision_score": 0.8365271434537052,
            "fpr": 0.11964873765093303,
            "logloss": 0.4899600050649048,
            "mae": 0.29164981416760893,
            "precision": 0.7811244979919679,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8537329895648215,
            "auditor_fn_violation": 0.0085085017471811,
            "auditor_fp_violation": 0.009757481940144478,
            "ave_precision_score": 0.8539669523789027,
            "fpr": 0.07894736842105263,
            "logloss": 0.5248579538276703,
            "mae": 0.3061367883900969,
            "precision": 0.828978622327791,
            "recall": 0.7166324435318275
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8703800863676545,
            "auditor_fn_violation": 0.00100132334517214,
            "auditor_fp_violation": 0.00561703305940408,
            "ave_precision_score": 0.8708141944194294,
            "fpr": 0.09330406147091108,
            "logloss": 0.4524380351126242,
            "mae": 0.27955301389819914,
            "precision": 0.8094170403587444,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8490791812885399,
            "auditor_fn_violation": 0.014173331171872186,
            "auditor_fp_violation": 0.014922600619195047,
            "ave_precision_score": 0.8495117198195414,
            "fpr": 0.09978070175438597,
            "logloss": 0.5090681466671088,
            "mae": 0.3114716510570265,
            "precision": 0.7986725663716814,
            "recall": 0.7412731006160165
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8909325435517995,
            "auditor_fn_violation": 0.0032578266582361224,
            "auditor_fp_violation": 0.017474115168956007,
            "ave_precision_score": 0.8910944927095159,
            "fpr": 0.10537870472008781,
            "logloss": 0.42788432100645807,
            "mae": 0.2762258850185264,
            "precision": 0.7983193277310925,
            "recall": 0.8137044967880086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8436929603523472,
            "auditor_fn_violation": 0.012239273749054366,
            "auditor_fp_violation": 0.010033539731682152,
            "ave_precision_score": 0.8441245674796753,
            "fpr": 0.0800438596491228,
            "logloss": 0.5301289380159591,
            "mae": 0.3166598271795042,
            "precision": 0.8132992327365729,
            "recall": 0.6529774127310062
        },
        "train": {
            "accuracy": 0.8111964873765093,
            "auc_prc": 0.8890435047861789,
            "auditor_fn_violation": 0.009895707237499328,
            "auditor_fp_violation": 0.010077036421712609,
            "ave_precision_score": 0.8892147347266914,
            "fpr": 0.06805708013172337,
            "logloss": 0.4381427968045006,
            "mae": 0.27812125183985403,
            "precision": 0.8520286396181385,
            "recall": 0.7644539614561028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8114903124353209,
            "auditor_fn_violation": 0.023733293706545627,
            "auditor_fp_violation": 0.012603199174406606,
            "ave_precision_score": 0.8125179061425561,
            "fpr": 0.09210526315789473,
            "logloss": 0.5616160301788427,
            "mae": 0.3258986881662218,
            "precision": 0.8041958041958042,
            "recall": 0.7084188911704312
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8637365902366744,
            "auditor_fn_violation": 0.00897900276656708,
            "auditor_fp_violation": 0.01796857230446693,
            "ave_precision_score": 0.8639609033669698,
            "fpr": 0.10428100987925357,
            "logloss": 0.4725716758489041,
            "mae": 0.2961752919020767,
            "precision": 0.7921225382932167,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7513937565801554,
            "auditor_fn_violation": 0.008839475485428157,
            "auditor_fp_violation": 0.004770381836945305,
            "ave_precision_score": 0.7529078935962119,
            "fpr": 0.1162280701754386,
            "logloss": 0.6812908922604677,
            "mae": 0.35596862227652964,
            "precision": 0.7458033573141487,
            "recall": 0.6386036960985626
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8227441712273456,
            "auditor_fn_violation": 0.013649494519752633,
            "auditor_fp_violation": 0.011414542973269647,
            "ave_precision_score": 0.8232812626803502,
            "fpr": 0.09549945115257959,
            "logloss": 0.5364277517832949,
            "mae": 0.307539375968279,
            "precision": 0.7888349514563107,
            "recall": 0.69593147751606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7791987698713371,
            "auditor_fn_violation": 0.015229295003422313,
            "auditor_fp_violation": 0.01668472652218782,
            "ave_precision_score": 0.7806612484424749,
            "fpr": 0.08333333333333333,
            "logloss": 0.6694306484694925,
            "mae": 0.3598243787886244,
            "precision": 0.7840909090909091,
            "recall": 0.5667351129363449
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8505286814174926,
            "auditor_fn_violation": 0.013334524265637453,
            "auditor_fp_violation": 0.01557539976859406,
            "ave_precision_score": 0.850787697339684,
            "fpr": 0.06586169045005488,
            "logloss": 0.5295613743535537,
            "mae": 0.30858650846349567,
            "precision": 0.84,
            "recall": 0.6745182012847966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7098663602975652,
            "auditor_fn_violation": 0.017055279368853347,
            "auditor_fp_violation": 0.011197110423116618,
            "ave_precision_score": 0.71015775076663,
            "fpr": 0.12609649122807018,
            "logloss": 0.9537961418207197,
            "mae": 0.34663538028600444,
            "precision": 0.7472527472527473,
            "recall": 0.6981519507186859
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8123723511337388,
            "auditor_fn_violation": 0.00578228973972645,
            "auditor_fp_violation": 0.01950138942455079,
            "ave_precision_score": 0.8116816782836334,
            "fpr": 0.1141602634467618,
            "logloss": 0.6078889246324245,
            "mae": 0.29530406436186724,
            "precision": 0.7828810020876826,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7318903536040877,
            "auditor_fn_violation": 0.016958463921611017,
            "auditor_fp_violation": 0.014690402476780186,
            "ave_precision_score": 0.7330383320042024,
            "fpr": 0.11951754385964912,
            "logloss": 0.6879257875499836,
            "mae": 0.3330674203962349,
            "precision": 0.7640692640692641,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.83699222345286,
            "auditor_fn_violation": 0.0028206291413299745,
            "auditor_fp_violation": 0.014403536357433177,
            "ave_precision_score": 0.8377740663935354,
            "fpr": 0.1119648737650933,
            "logloss": 0.4955440738570282,
            "mae": 0.2859687833595943,
            "precision": 0.7905544147843943,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8066978332201773,
            "auditor_fn_violation": 0.008445459130372129,
            "auditor_fp_violation": 0.01070433436532508,
            "ave_precision_score": 0.8082148833951528,
            "fpr": 0.08991228070175439,
            "logloss": 0.5788044491967831,
            "mae": 0.3173490323828978,
            "precision": 0.8042959427207638,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8481390861327963,
            "auditor_fn_violation": 0.010215378540183387,
            "auditor_fp_violation": 0.008781558726673985,
            "ave_precision_score": 0.8495569821606326,
            "fpr": 0.08122941822173436,
            "logloss": 0.4669471987471643,
            "mae": 0.2827688828056614,
            "precision": 0.8275058275058275,
            "recall": 0.7601713062098501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.611996247200159,
            "auditor_fn_violation": 0.010332234590583236,
            "auditor_fp_violation": 0.011403508771929832,
            "ave_precision_score": 0.5663243399511587,
            "fpr": 0.37280701754385964,
            "logloss": 4.965202612198873,
            "mae": 0.41594079482009666,
            "precision": 0.5690747782002535,
            "recall": 0.9219712525667351
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6034919719000975,
            "auditor_fn_violation": 0.008271494956950148,
            "auditor_fp_violation": 0.023842723074336693,
            "ave_precision_score": 0.5516054285551615,
            "fpr": 0.3896816684961581,
            "logloss": 5.381608277979431,
            "mae": 0.4230792175683997,
            "precision": 0.5568039950062422,
            "recall": 0.9550321199143469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6526515126313959,
            "auditor_fn_violation": 0.004316167729385063,
            "auditor_fp_violation": 0.0075309597523219845,
            "ave_precision_score": 0.6442092903548284,
            "fpr": 0.06907894736842106,
            "logloss": 10.25868140818388,
            "mae": 0.44886174199790285,
            "precision": 0.7,
            "recall": 0.30184804928131415
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6622862238225458,
            "auditor_fn_violation": 0.016714578186664542,
            "auditor_fp_violation": 0.008455217017236775,
            "ave_precision_score": 0.657982779495659,
            "fpr": 0.06476399560922064,
            "logloss": 10.195288857606661,
            "mae": 0.4261164264176736,
            "precision": 0.730593607305936,
            "recall": 0.3426124197002141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8202346005430814,
            "auditor_fn_violation": 0.010969415324759547,
            "auditor_fp_violation": 0.012512899896800827,
            "ave_precision_score": 0.8190762983016493,
            "fpr": 0.0712719298245614,
            "logloss": 2.209856525947182,
            "mae": 0.3175219083693395,
            "precision": 0.8337595907928389,
            "recall": 0.6694045174537988
        },
        "train": {
            "accuracy": 0.8057080131723381,
            "auc_prc": 0.8325610644588042,
            "auditor_fn_violation": 0.009007209057980392,
            "auditor_fp_violation": 0.010690163269746146,
            "ave_precision_score": 0.8317362801422514,
            "fpr": 0.07793633369923161,
            "logloss": 1.6728996243761358,
            "mae": 0.2724255498884021,
            "precision": 0.8356481481481481,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7839278271431216,
            "auditor_fn_violation": 0.01056639288158796,
            "auditor_fp_violation": 0.0016589267285861738,
            "ave_precision_score": 0.7850978104827055,
            "fpr": 0.08333333333333333,
            "logloss": 0.5816167813535743,
            "mae": 0.3480828569572942,
            "precision": 0.8036175710594315,
            "recall": 0.6386036960985626
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8517513815757224,
            "auditor_fn_violation": 0.009378591894922163,
            "auditor_fp_violation": 0.008870561011065954,
            "ave_precision_score": 0.8520537386201466,
            "fpr": 0.07464324917672886,
            "logloss": 0.47792369663663403,
            "mae": 0.31185550837236753,
            "precision": 0.837708830548926,
            "recall": 0.7516059957173448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.817843167639507,
            "auditor_fn_violation": 0.012327083108181135,
            "auditor_fp_violation": 0.014899380804953566,
            "ave_precision_score": 0.8180377327672657,
            "fpr": 0.10964912280701754,
            "logloss": 0.7322821444761447,
            "mae": 0.28509163413617533,
            "precision": 0.7863247863247863,
            "recall": 0.75564681724846
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8276237627849121,
            "auditor_fn_violation": 0.0018287078932956045,
            "auditor_fp_violation": 0.006667754472364792,
            "ave_precision_score": 0.8268952848473021,
            "fpr": 0.11964873765093303,
            "logloss": 0.7493397217220459,
            "mae": 0.2536523968238705,
            "precision": 0.7780040733197556,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8544802759124743,
            "auditor_fn_violation": 0.01803243992939228,
            "auditor_fp_violation": 0.014809081527347783,
            "ave_precision_score": 0.854876542513451,
            "fpr": 0.09210526315789473,
            "logloss": 0.5559257449585713,
            "mae": 0.28425170569922553,
            "precision": 0.8068965517241379,
            "recall": 0.7207392197125256
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.880259064030488,
            "auditor_fn_violation": 0.00538505113565581,
            "auditor_fp_violation": 0.00726851989201056,
            "ave_precision_score": 0.880675319857668,
            "fpr": 0.0845225027442371,
            "logloss": 0.44853552434376975,
            "mae": 0.2530407039863632,
            "precision": 0.8269662921348314,
            "recall": 0.7880085653104925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7686035564019355,
            "auditor_fn_violation": 0.015873230303685294,
            "auditor_fp_violation": 0.017902476780185774,
            "ave_precision_score": 0.7299792960638745,
            "fpr": 0.2149122807017544,
            "logloss": 2.756700060647392,
            "mae": 0.3071230239002034,
            "precision": 0.6833602584814217,
            "recall": 0.8685831622176592
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7599929848684429,
            "auditor_fn_violation": 0.014415765436480607,
            "auditor_fp_violation": 0.03870363228211747,
            "ave_precision_score": 0.7190901637620596,
            "fpr": 0.22941822173435786,
            "logloss": 2.878533929772975,
            "mae": 0.30125590191789087,
            "precision": 0.6724137931034483,
            "recall": 0.9186295503211992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7893344712031065,
            "auditor_fn_violation": 0.015783169422529636,
            "auditor_fp_violation": 0.024401444788441695,
            "ave_precision_score": 0.7908151331806346,
            "fpr": 0.09429824561403509,
            "logloss": 0.5880059130148984,
            "mae": 0.3320389071522457,
            "precision": 0.7937649880095923,
            "recall": 0.6796714579055442
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8345921426139289,
            "auditor_fn_violation": 0.01727635349064609,
            "auditor_fp_violation": 0.02520742476834683,
            "ave_precision_score": 0.8348765642455594,
            "fpr": 0.1141602634467618,
            "logloss": 0.5097263503715392,
            "mae": 0.3073476219068524,
            "precision": 0.7694013303769401,
            "recall": 0.7430406852248393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6637764081736266,
            "auditor_fn_violation": 0.010314222414352104,
            "auditor_fp_violation": 0.00793859649122807,
            "ave_precision_score": 0.660837836409363,
            "fpr": 0.03728070175438596,
            "logloss": 8.905156798673124,
            "mae": 0.44851203175305904,
            "precision": 0.7806451612903226,
            "recall": 0.24845995893223818
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6583733520121858,
            "auditor_fn_violation": 0.011978271753514624,
            "auditor_fp_violation": 0.006299383906409154,
            "ave_precision_score": 0.655719680617169,
            "fpr": 0.03512623490669594,
            "logloss": 8.639787515974142,
            "mae": 0.4283061162994531,
            "precision": 0.7974683544303798,
            "recall": 0.2698072805139186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8525028504536889,
            "auditor_fn_violation": 0.00933481033178429,
            "auditor_fp_violation": 0.005485036119711044,
            "ave_precision_score": 0.8528571828641553,
            "fpr": 0.07236842105263158,
            "logloss": 0.521465134188428,
            "mae": 0.31089606286198096,
            "precision": 0.8276762402088773,
            "recall": 0.6509240246406571
        },
        "train": {
            "accuracy": 0.8046103183315039,
            "auc_prc": 0.885948806462664,
            "auditor_fn_violation": 0.008560609443936476,
            "auditor_fp_violation": 0.007224018749814582,
            "ave_precision_score": 0.8861374572549574,
            "fpr": 0.06805708013172337,
            "logloss": 0.43869181792334117,
            "mae": 0.27372624073177576,
            "precision": 0.8498789346246973,
            "recall": 0.7516059957173448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 31658,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8410682896628676,
            "auditor_fn_violation": 0.008621077848625671,
            "auditor_fp_violation": 0.01991228070175439,
            "ave_precision_score": 0.8417804735838352,
            "fpr": 0.11842105263157894,
            "logloss": 0.706910814270979,
            "mae": 0.2713644842412711,
            "precision": 0.7754677754677755,
            "recall": 0.7659137577002053
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8444930860267038,
            "auditor_fn_violation": 0.008953146999438227,
            "auditor_fp_violation": 0.015340532629226376,
            "ave_precision_score": 0.8447644172796921,
            "fpr": 0.13721185510428102,
            "logloss": 0.6775703367924653,
            "mae": 0.2632549552790666,
            "precision": 0.7504990019960079,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 31658,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6513081695833303,
            "auditor_fn_violation": 0.010595662667963543,
            "auditor_fp_violation": 0.02630804953560372,
            "ave_precision_score": 0.6304479896342658,
            "fpr": 0.22807017543859648,
            "logloss": 2.706085959162393,
            "mae": 0.34522339416026515,
            "precision": 0.6724409448818898,
            "recall": 0.8767967145790554
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6755189993787591,
            "auditor_fn_violation": 0.005622454088384414,
            "auditor_fp_violation": 0.020055181416323026,
            "ave_precision_score": 0.6553382084715235,
            "fpr": 0.2502744237102086,
            "logloss": 2.3125979028992054,
            "mae": 0.33217628240282726,
            "precision": 0.6529680365296804,
            "recall": 0.9186295503211992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.827956482362372,
            "auditor_fn_violation": 0.009217731186281927,
            "auditor_fp_violation": 0.009362745098039218,
            "ave_precision_score": 0.8283196028109298,
            "fpr": 0.05043859649122807,
            "logloss": 0.6608302148889347,
            "mae": 0.3356645225035742,
            "precision": 0.8544303797468354,
            "recall": 0.5544147843942505
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8504611891494003,
            "auditor_fn_violation": 0.003883066117897601,
            "auditor_fp_violation": 0.010902779838015842,
            "ave_precision_score": 0.8507087597970062,
            "fpr": 0.05817782656421515,
            "logloss": 0.5743214725679754,
            "mae": 0.30625542132356093,
            "precision": 0.8413173652694611,
            "recall": 0.6017130620985011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8243386409869845,
            "auditor_fn_violation": 0.024379480528837504,
            "auditor_fp_violation": 0.012489680082559344,
            "ave_precision_score": 0.8246198462435995,
            "fpr": 0.0800438596491228,
            "logloss": 1.084400205232127,
            "mae": 0.32386534768685343,
            "precision": 0.8147208121827412,
            "recall": 0.6591375770020534
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8258868567385893,
            "auditor_fn_violation": 0.024870897453677047,
            "auditor_fp_violation": 0.010662968127293048,
            "ave_precision_score": 0.827240658671737,
            "fpr": 0.09110867178924259,
            "logloss": 0.9753260562430451,
            "mae": 0.2923544041735795,
            "precision": 0.8051643192488263,
            "recall": 0.734475374732334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7956041174384725,
            "auditor_fn_violation": 0.0011550308008213557,
            "auditor_fp_violation": 0.008604231166150672,
            "ave_precision_score": 0.7803035148031974,
            "fpr": 0.12171052631578948,
            "logloss": 2.902738835467426,
            "mae": 0.29383771215882765,
            "precision": 0.7672955974842768,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8164811108567644,
            "auditor_fn_violation": 0.0025949788100235764,
            "auditor_fp_violation": 0.013113003233749672,
            "ave_precision_score": 0.8029838865245227,
            "fpr": 0.12623490669593854,
            "logloss": 2.2061782622531094,
            "mae": 0.26123352006122774,
            "precision": 0.77,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7017268423571668,
            "auditor_fn_violation": 0.01658245974278612,
            "auditor_fp_violation": 0.027639318885448922,
            "ave_precision_score": 0.7012429063561727,
            "fpr": 0.17105263157894737,
            "logloss": 1.1658253972415273,
            "mae": 0.3122565799119337,
            "precision": 0.7209302325581395,
            "recall": 0.8275154004106776
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7423358210828319,
            "auditor_fn_violation": 0.004430738276172503,
            "auditor_fp_violation": 0.023578188506838342,
            "ave_precision_score": 0.7421225934815203,
            "fpr": 0.18111964873765093,
            "logloss": 0.875517168307414,
            "mae": 0.29312165085142977,
            "precision": 0.7120418848167539,
            "recall": 0.8736616702355461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8556085289036164,
            "auditor_fn_violation": 0.004775478223278939,
            "auditor_fp_violation": 0.013452012383900931,
            "ave_precision_score": 0.8558483633224314,
            "fpr": 0.08333333333333333,
            "logloss": 0.5188700130050278,
            "mae": 0.30658426018648277,
            "precision": 0.8220140515222483,
            "recall": 0.7207392197125256
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8726581030202034,
            "auditor_fn_violation": 0.003814900913648795,
            "auditor_fp_violation": 0.009960838994867535,
            "ave_precision_score": 0.8730865572037552,
            "fpr": 0.09330406147091108,
            "logloss": 0.44918931505636783,
            "mae": 0.279815076682185,
            "precision": 0.8098434004474273,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8609865942725365,
            "auditor_fn_violation": 0.010913127274037253,
            "auditor_fp_violation": 0.013039215686274511,
            "ave_precision_score": 0.8613096550584918,
            "fpr": 0.09978070175438597,
            "logloss": 0.5048147798296972,
            "mae": 0.29462623083561895,
            "precision": 0.8043010752688172,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.8898513334391054,
            "auditor_fn_violation": 0.0013727061821139223,
            "auditor_fp_violation": 0.012816328952443112,
            "ave_precision_score": 0.8900105150983497,
            "fpr": 0.10976948408342481,
            "logloss": 0.43204360835607014,
            "mae": 0.26715287878183813,
            "precision": 0.7942386831275721,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6413756325431302,
            "auditor_fn_violation": 0.007317446593897498,
            "auditor_fp_violation": 0.009383384932920536,
            "ave_precision_score": 0.6323853606079117,
            "fpr": 0.14364035087719298,
            "logloss": 10.377540166888984,
            "mae": 0.47428420615699163,
            "precision": 0.5760517799352751,
            "recall": 0.3655030800821355
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6532432294386888,
            "auditor_fn_violation": 0.014321744465102964,
            "auditor_fp_violation": 0.024520129349986652,
            "ave_precision_score": 0.6489611604149008,
            "fpr": 0.16465422612513722,
            "logloss": 10.339251501738573,
            "mae": 0.45994131897087026,
            "precision": 0.5495495495495496,
            "recall": 0.39186295503211993
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8431915929494015,
            "auditor_fn_violation": 0.013025054937137516,
            "auditor_fp_violation": 0.009197626418988651,
            "ave_precision_score": 0.8436540318155752,
            "fpr": 0.0712719298245614,
            "logloss": 0.5812521951520341,
            "mae": 0.307777529490496,
            "precision": 0.8271276595744681,
            "recall": 0.6386036960985626
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8790617565383748,
            "auditor_fn_violation": 0.006085507372419416,
            "auditor_fp_violation": 0.010635772984839946,
            "ave_precision_score": 0.879277467272881,
            "fpr": 0.054884742041712405,
            "logloss": 0.45800194870628513,
            "mae": 0.2664521226498705,
            "precision": 0.8691099476439791,
            "recall": 0.7109207708779444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8555444168710371,
            "auditor_fn_violation": 0.0216956662703988,
            "auditor_fp_violation": 0.012141382868937053,
            "ave_precision_score": 0.8559060446274043,
            "fpr": 0.06798245614035088,
            "logloss": 0.5086608315991975,
            "mae": 0.32708272794588356,
            "precision": 0.8442211055276382,
            "recall": 0.6899383983572895
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8852186041634598,
            "auditor_fn_violation": 0.004668141228901114,
            "auditor_fp_violation": 0.010035007565194175,
            "ave_precision_score": 0.8853840681887432,
            "fpr": 0.07354555433589462,
            "logloss": 0.44541936916426544,
            "mae": 0.29957306499538777,
            "precision": 0.837772397094431,
            "recall": 0.7408993576017131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6058200337926417,
            "auditor_fn_violation": 0.012901221225548471,
            "auditor_fp_violation": 0.011744066047471623,
            "ave_precision_score": 0.5693516804746759,
            "fpr": 0.3475877192982456,
            "logloss": 4.269446800099866,
            "mae": 0.4114975457576027,
            "precision": 0.5806878306878307,
            "recall": 0.9014373716632443
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.5947670392474129,
            "auditor_fn_violation": 0.008828569212362818,
            "auditor_fp_violation": 0.02626556303834022,
            "ave_precision_score": 0.5535298019367317,
            "fpr": 0.3600439077936334,
            "logloss": 4.56565277915313,
            "mae": 0.4101469889968381,
            "precision": 0.5706806282722513,
            "recall": 0.9336188436830836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7348052160264009,
            "auditor_fn_violation": 0.01734797723260924,
            "auditor_fp_violation": 0.017961816305469558,
            "ave_precision_score": 0.7359477547939003,
            "fpr": 0.11842105263157894,
            "logloss": 0.6780575040750382,
            "mae": 0.33128848264255284,
            "precision": 0.7672413793103449,
            "recall": 0.731006160164271
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8366578589344236,
            "auditor_fn_violation": 0.0032037645996939655,
            "auditor_fp_violation": 0.017093383174612602,
            "ave_precision_score": 0.8374438949479582,
            "fpr": 0.11306256860592755,
            "logloss": 0.4912863933453001,
            "mae": 0.28501918730780923,
            "precision": 0.7885010266940452,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8444363229486026,
            "auditor_fn_violation": 0.013677996325516062,
            "auditor_fp_violation": 0.0017492260061919545,
            "ave_precision_score": 0.8448129308193101,
            "fpr": 0.08881578947368421,
            "logloss": 0.5513103791901277,
            "mae": 0.29701487769805107,
            "precision": 0.8085106382978723,
            "recall": 0.702258726899384
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8867740326978175,
            "auditor_fn_violation": 0.0036973746994267078,
            "auditor_fp_violation": 0.01403269350579998,
            "ave_precision_score": 0.8869460756257073,
            "fpr": 0.0889132821075741,
            "logloss": 0.4477450482177854,
            "mae": 0.2549073459454286,
            "precision": 0.8187919463087249,
            "recall": 0.7837259100642399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8018808018935781,
            "auditor_fn_violation": 0.02012860693829029,
            "auditor_fp_violation": 0.010784313725490198,
            "ave_precision_score": 0.8026638440736658,
            "fpr": 0.09758771929824561,
            "logloss": 0.5784131266541824,
            "mae": 0.3310377647485898,
            "precision": 0.7939814814814815,
            "recall": 0.704312114989733
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8729327965201081,
            "auditor_fn_violation": 0.011585734198012876,
            "auditor_fp_violation": 0.009226570148633819,
            "ave_precision_score": 0.8731250304044766,
            "fpr": 0.08781558726673985,
            "logloss": 0.45842221535753014,
            "mae": 0.28961538139742465,
            "precision": 0.817351598173516,
            "recall": 0.7665952890792291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8421818571833338,
            "auditor_fn_violation": 0.009093897474692898,
            "auditor_fp_violation": 0.01042311661506708,
            "ave_precision_score": 0.8414492150838524,
            "fpr": 0.03289473684210526,
            "logloss": 0.8074821860419514,
            "mae": 0.3063302120262422,
            "precision": 0.8947368421052632,
            "recall": 0.5236139630390144
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8489414050114956,
            "auditor_fn_violation": 0.0022376991187884466,
            "auditor_fp_violation": 0.0070559033237408645,
            "ave_precision_score": 0.8480297246936939,
            "fpr": 0.04171240395170143,
            "logloss": 0.7877079253022824,
            "mae": 0.2744885615872847,
            "precision": 0.8844984802431611,
            "recall": 0.6231263383297645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8322860105295711,
            "auditor_fn_violation": 0.022524226377030877,
            "auditor_fp_violation": 0.013854489164086691,
            "ave_precision_score": 0.8327201128396502,
            "fpr": 0.11842105263157894,
            "logloss": 0.5617094219772005,
            "mae": 0.3123079167164274,
            "precision": 0.7786885245901639,
            "recall": 0.7802874743326489
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8905186728483656,
            "auditor_fn_violation": 0.007486419845946639,
            "auditor_fp_violation": 0.01920965971459935,
            "ave_precision_score": 0.8906773071324372,
            "fpr": 0.12623490669593854,
            "logloss": 0.460291525163793,
            "mae": 0.2748977613106828,
            "precision": 0.775390625,
            "recall": 0.8501070663811563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8526814626082493,
            "auditor_fn_violation": 0.01910641593717353,
            "auditor_fp_violation": 0.01892414860681115,
            "ave_precision_score": 0.8530874558790156,
            "fpr": 0.10416666666666667,
            "logloss": 0.5365554414698466,
            "mae": 0.2884872980818202,
            "precision": 0.7930283224400871,
            "recall": 0.7474332648870636
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8747850490667968,
            "auditor_fn_violation": 0.005881011759672997,
            "auditor_fp_violation": 0.01667309460942831,
            "ave_precision_score": 0.8752099595799053,
            "fpr": 0.10867178924259056,
            "logloss": 0.4508987719954442,
            "mae": 0.2643673937600786,
            "precision": 0.7911392405063291,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7501800438219849,
            "auditor_fn_violation": 0.016695035844230696,
            "auditor_fp_violation": 0.020745614035087723,
            "ave_precision_score": 0.7517588437993089,
            "fpr": 0.1118421052631579,
            "logloss": 0.6748584248594615,
            "mae": 0.35908868124355203,
            "precision": 0.7443609022556391,
            "recall": 0.6098562628336756
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8318441511559819,
            "auditor_fn_violation": 0.014944633400479978,
            "auditor_fp_violation": 0.02429267906765163,
            "ave_precision_score": 0.8321127933507799,
            "fpr": 0.09769484083424808,
            "logloss": 0.5391339548663083,
            "mae": 0.3118485108556678,
            "precision": 0.7890995260663507,
            "recall": 0.7130620985010707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7697504804366606,
            "auditor_fn_violation": 0.015963291184840956,
            "auditor_fp_violation": 0.02187306501547988,
            "ave_precision_score": 0.7317261501585586,
            "fpr": 0.22149122807017543,
            "logloss": 2.782449685095146,
            "mae": 0.3091176600987199,
            "precision": 0.6752411575562701,
            "recall": 0.8624229979466119
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7638644475870009,
            "auditor_fn_violation": 0.012039385384910105,
            "auditor_fp_violation": 0.03907200284807311,
            "ave_precision_score": 0.7223875604276762,
            "fpr": 0.23710208562019758,
            "logloss": 2.91413177198806,
            "mae": 0.300763823586117,
            "precision": 0.6645962732919255,
            "recall": 0.9164882226980728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.853737788539399,
            "auditor_fn_violation": 0.014168828127814405,
            "auditor_fp_violation": 0.01496904024767803,
            "ave_precision_score": 0.8549388007282046,
            "fpr": 0.11842105263157894,
            "logloss": 0.5390095002011751,
            "mae": 0.2817176149353799,
            "precision": 0.7809330628803245,
            "recall": 0.7905544147843943
        },
        "train": {
            "accuracy": 0.8046103183315039,
            "auc_prc": 0.8864388561580617,
            "auditor_fn_violation": 0.005394453232793578,
            "auditor_fp_violation": 0.010415739559537581,
            "ave_precision_score": 0.8866333651881934,
            "fpr": 0.11745334796926454,
            "logloss": 0.44950410325474033,
            "mae": 0.2518334531103993,
            "precision": 0.7872763419483101,
            "recall": 0.8479657387580299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8583785936461935,
            "auditor_fn_violation": 0.020106091718001366,
            "auditor_fp_violation": 0.026480908152734784,
            "ave_precision_score": 0.8588971148469194,
            "fpr": 0.11732456140350878,
            "logloss": 0.5228935049549848,
            "mae": 0.28200991653406304,
            "precision": 0.7829614604462475,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8784707420952558,
            "auditor_fn_violation": 0.00825269076267462,
            "auditor_fp_violation": 0.017125522888420813,
            "ave_precision_score": 0.8788882023023481,
            "fpr": 0.12623490669593854,
            "logloss": 0.45690798205840766,
            "mae": 0.2611532097461011,
            "precision": 0.7762645914396887,
            "recall": 0.854389721627409
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.838898442536176,
            "auditor_fn_violation": 0.01453132317446594,
            "auditor_fp_violation": 0.015642414860681117,
            "ave_precision_score": 0.8392966007183635,
            "fpr": 0.10197368421052631,
            "logloss": 0.5701535849361132,
            "mae": 0.3121230283774039,
            "precision": 0.7852193995381063,
            "recall": 0.6981519507186859
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8744864796199476,
            "auditor_fn_violation": 0.006809468852027444,
            "auditor_fp_violation": 0.008870561011065954,
            "ave_precision_score": 0.8746740945980009,
            "fpr": 0.10318331503841932,
            "logloss": 0.48007930650292874,
            "mae": 0.27267153524925564,
            "precision": 0.7956521739130434,
            "recall": 0.7837259100642399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8583951112664603,
            "auditor_fn_violation": 0.015794427032674092,
            "auditor_fp_violation": 0.013467492260061921,
            "ave_precision_score": 0.8590716518847726,
            "fpr": 0.11732456140350878,
            "logloss": 0.5356775830865825,
            "mae": 0.2874516789301548,
            "precision": 0.7780082987551867,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8741258615993617,
            "auditor_fn_violation": 0.008351412782621161,
            "auditor_fp_violation": 0.012284787531768869,
            "ave_precision_score": 0.8742781936050251,
            "fpr": 0.13062568605927552,
            "logloss": 0.5104969488157138,
            "mae": 0.2738916394599784,
            "precision": 0.7629482071713147,
            "recall": 0.8201284796573876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8409779712041232,
            "auditor_fn_violation": 0.011791220865304949,
            "auditor_fp_violation": 0.015828173374613005,
            "ave_precision_score": 0.8412745006149609,
            "fpr": 0.08114035087719298,
            "logloss": 0.570906521371728,
            "mae": 0.31150653729797306,
            "precision": 0.8168316831683168,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8704528479045163,
            "auditor_fn_violation": 0.0024022358186993687,
            "auditor_fp_violation": 0.008774141869641325,
            "ave_precision_score": 0.8706746458829016,
            "fpr": 0.08232711306256861,
            "logloss": 0.4589756285208775,
            "mae": 0.2709082029555582,
            "precision": 0.8267898383371824,
            "recall": 0.7665952890792291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.831771954832395,
            "auditor_fn_violation": 0.009562214056702332,
            "auditor_fp_violation": 0.0179592363261094,
            "ave_precision_score": 0.832138337588269,
            "fpr": 0.17214912280701755,
            "logloss": 0.60056356262955,
            "mae": 0.3279289668262528,
            "precision": 0.70817843866171,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.874725435312049,
            "auditor_fn_violation": 0.0018545636604244571,
            "auditor_fp_violation": 0.01630719632915023,
            "ave_precision_score": 0.8749080732329587,
            "fpr": 0.15697036223929747,
            "logloss": 0.5161705913398797,
            "mae": 0.29052640458939005,
            "precision": 0.7342007434944238,
            "recall": 0.8458244111349036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 31658,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7561347346931133,
            "auditor_fn_violation": 0.019572480997154078,
            "auditor_fp_violation": 0.021217750257997943,
            "ave_precision_score": 0.7308794325240232,
            "fpr": 0.1787280701754386,
            "logloss": 2.2163497387644324,
            "mae": 0.2817828779847524,
            "precision": 0.7130281690140845,
            "recall": 0.8316221765913757
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7425288646908543,
            "auditor_fn_violation": 0.006447488112223432,
            "auditor_fp_violation": 0.03373186578455514,
            "ave_precision_score": 0.7112983285523699,
            "fpr": 0.19758507135016465,
            "logloss": 2.4841193338663237,
            "mae": 0.277600718292854,
            "precision": 0.6943972835314092,
            "recall": 0.8758029978586723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8397638043671124,
            "auditor_fn_violation": 0.012932742533952954,
            "auditor_fp_violation": 0.015069659442724462,
            "ave_precision_score": 0.8048106739339808,
            "fpr": 0.16337719298245615,
            "logloss": 2.088751057716791,
            "mae": 0.27857879402213975,
            "precision": 0.7276051188299817,
            "recall": 0.8172484599589322
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8809425202431448,
            "auditor_fn_violation": 0.003998241807835239,
            "auditor_fp_violation": 0.02251263337981231,
            "ave_precision_score": 0.8477528261420259,
            "fpr": 0.1602634467618002,
            "logloss": 1.8353130854305115,
            "mae": 0.24540230856838297,
            "precision": 0.738819320214669,
            "recall": 0.8843683083511777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 31658,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8347084698263546,
            "auditor_fn_violation": 0.013569923268129265,
            "auditor_fp_violation": 0.003611971104231167,
            "ave_precision_score": 0.7990667035868746,
            "fpr": 0.09868421052631579,
            "logloss": 2.1038230592133873,
            "mae": 0.2844646617386229,
            "precision": 0.7949886104783599,
            "recall": 0.7166324435318275
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8795844004684791,
            "auditor_fn_violation": 0.0007874256352879594,
            "auditor_fp_violation": 0.01163952096992712,
            "ave_precision_score": 0.8464426634173473,
            "fpr": 0.09659714599341383,
            "logloss": 1.7867483872603884,
            "mae": 0.232214197435679,
            "precision": 0.8099352051835853,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8477208789009497,
            "auditor_fn_violation": 0.005401401347310785,
            "auditor_fp_violation": 0.013214654282765737,
            "ave_precision_score": 0.8479890901300654,
            "fpr": 0.06798245614035088,
            "logloss": 0.569936124821742,
            "mae": 0.30270068814979023,
            "precision": 0.8453865336658354,
            "recall": 0.6960985626283368
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.841304695853348,
            "auditor_fn_violation": 0.006680190016383165,
            "auditor_fp_violation": 0.005518141632301899,
            "ave_precision_score": 0.842684515999891,
            "fpr": 0.09659714599341383,
            "logloss": 0.5155258314054599,
            "mae": 0.2907957313140153,
            "precision": 0.7939110070257611,
            "recall": 0.7259100642398287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.8234840929953741,
            "auditor_fn_violation": 0.000839817716776541,
            "auditor_fp_violation": 0.004321465428276588,
            "ave_precision_score": 0.823983504821969,
            "fpr": 0.44956140350877194,
            "logloss": 1.9330227174581698,
            "mae": 0.4445652604204122,
            "precision": 0.5393258426966292,
            "recall": 0.9856262833675564
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.8645553170067896,
            "auditor_fn_violation": 0.002750113412796725,
            "auditor_fp_violation": 0.003105190811008584,
            "ave_precision_score": 0.8647909534461126,
            "fpr": 0.4654226125137212,
            "logloss": 1.9468342327571626,
            "mae": 0.4577311488627748,
            "precision": 0.5198187995469988,
            "recall": 0.9828693790149893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8282765618436295,
            "auditor_fn_violation": 0.013173655391044354,
            "auditor_fp_violation": 0.015180598555211557,
            "ave_precision_score": 0.8285696740363828,
            "fpr": 0.13925438596491227,
            "logloss": 0.5884778063745429,
            "mae": 0.3185966413027991,
            "precision": 0.7470119521912351,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8722953100183239,
            "auditor_fn_violation": 0.003532837999515797,
            "auditor_fp_violation": 0.012430652386744599,
            "ave_precision_score": 0.8725271187305915,
            "fpr": 0.15148188803512624,
            "logloss": 0.49899605557397236,
            "mae": 0.2807071278343012,
            "precision": 0.7463235294117647,
            "recall": 0.8693790149892934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8318458545527893,
            "auditor_fn_violation": 0.015355380237040245,
            "auditor_fp_violation": 0.005869453044375652,
            "ave_precision_score": 0.7969420914870662,
            "fpr": 0.10964912280701754,
            "logloss": 2.0976886785090003,
            "mae": 0.28929778620786556,
            "precision": 0.7782705099778271,
            "recall": 0.7207392197125256
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8767631400966492,
            "auditor_fn_violation": 0.0030321763269297217,
            "auditor_fp_violation": 0.01025256870481898,
            "ave_precision_score": 0.8436367069742621,
            "fpr": 0.10647639956092206,
            "logloss": 1.7954067192503462,
            "mae": 0.2367993190771625,
            "precision": 0.7949260042283298,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 31658,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8275723709010632,
            "auditor_fn_violation": 0.017311952880146978,
            "auditor_fp_violation": 0.017321981424148605,
            "ave_precision_score": 0.8278783183483809,
            "fpr": 0.15789473684210525,
            "logloss": 0.5921948252207527,
            "mae": 0.31971125381798565,
            "precision": 0.7283018867924528,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8755526830197631,
            "auditor_fn_violation": 0.00025385662271969954,
            "auditor_fp_violation": 0.015367727771679475,
            "ave_precision_score": 0.8757648319581526,
            "fpr": 0.16245883644346873,
            "logloss": 0.5070960736706623,
            "mae": 0.28353006561807104,
            "precision": 0.7342908438061041,
            "recall": 0.8758029978586723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8466004790979205,
            "auditor_fn_violation": 0.017352480276667033,
            "auditor_fp_violation": 0.020534055727554186,
            "ave_precision_score": 0.8469993209613043,
            "fpr": 0.13486842105263158,
            "logloss": 0.543222357029273,
            "mae": 0.3000607711372649,
            "precision": 0.7588235294117647,
            "recall": 0.7946611909650924
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8792509747361414,
            "auditor_fn_violation": 0.0020919666131530633,
            "auditor_fp_violation": 0.015701486338149353,
            "ave_precision_score": 0.8796675580219945,
            "fpr": 0.1350164654226125,
            "logloss": 0.4576908386245234,
            "mae": 0.27003525985188465,
            "precision": 0.7648183556405354,
            "recall": 0.8565310492505354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5885161991500194,
            "auditor_fn_violation": 0.0028864512410389483,
            "auditor_fp_violation": 0.002386480908152736,
            "ave_precision_score": 0.580858159168577,
            "fpr": 0.027412280701754384,
            "logloss": 10.334549946314903,
            "mae": 0.5012025786195243,
            "precision": 0.6951219512195121,
            "recall": 0.11704312114989733
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5554636817489891,
            "auditor_fn_violation": 0.010617318192822923,
            "auditor_fp_violation": 0.0021953896816684962,
            "ave_precision_score": 0.5519051499022404,
            "fpr": 0.04061470911086718,
            "logloss": 10.309017570374044,
            "mae": 0.4914248241220905,
            "precision": 0.6336633663366337,
            "recall": 0.13704496788008566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8100832119607377,
            "auditor_fn_violation": 0.014283655751287875,
            "auditor_fp_violation": 0.009631062951496391,
            "ave_precision_score": 0.8105954968513222,
            "fpr": 0.09539473684210527,
            "logloss": 0.5739278334529332,
            "mae": 0.3281065735493923,
            "precision": 0.7923627684964201,
            "recall": 0.6817248459958932
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8756885581104792,
            "auditor_fn_violation": 0.011256660798191032,
            "auditor_fp_violation": 0.012556738956299877,
            "ave_precision_score": 0.8758596150591855,
            "fpr": 0.0867178924259056,
            "logloss": 0.4564156064706851,
            "mae": 0.2843863841445384,
            "precision": 0.8216704288939052,
            "recall": 0.7794432548179872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6223296840352088,
            "auditor_fn_violation": 0.011336413415468857,
            "auditor_fp_violation": 0.009963880288957694,
            "ave_precision_score": 0.5772333822006023,
            "fpr": 0.3574561403508772,
            "logloss": 4.8118795218202,
            "mae": 0.40894615568277803,
            "precision": 0.5771725032425421,
            "recall": 0.9137577002053389
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6088112720059198,
            "auditor_fn_violation": 0.004954905191602987,
            "auditor_fp_violation": 0.026579543319389647,
            "ave_precision_score": 0.5561374742340994,
            "fpr": 0.3809001097694841,
            "logloss": 5.408705757055883,
            "mae": 0.41787427194768195,
            "precision": 0.561314791403287,
            "recall": 0.9507494646680942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 31658,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8377073554092584,
            "auditor_fn_violation": 0.008877751359919308,
            "auditor_fp_violation": 0.01769607843137255,
            "ave_precision_score": 0.8381719318375721,
            "fpr": 0.12938596491228072,
            "logloss": 0.7091945480853976,
            "mae": 0.27341002113968865,
            "precision": 0.7644710578842315,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8455998234909939,
            "auditor_fn_violation": 0.008915538610887163,
            "auditor_fp_violation": 0.013464067799962426,
            "ave_precision_score": 0.8458729615268316,
            "fpr": 0.1525795828759605,
            "logloss": 0.6563263673824791,
            "mae": 0.2609523371481329,
            "precision": 0.734225621414914,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7415547432012745,
            "auditor_fn_violation": 0.01495460931589755,
            "auditor_fp_violation": 0.014473684210526324,
            "ave_precision_score": 0.7427547531974655,
            "fpr": 0.1206140350877193,
            "logloss": 0.6070842510960444,
            "mae": 0.3356846144480075,
            "precision": 0.7649572649572649,
            "recall": 0.7351129363449692
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8381367026230119,
            "auditor_fn_violation": 0.0004677543326038894,
            "auditor_fp_violation": 0.019268994570860648,
            "ave_precision_score": 0.838962501340912,
            "fpr": 0.11525795828759605,
            "logloss": 0.46675121008232584,
            "mae": 0.2903658883680889,
            "precision": 0.7870182555780934,
            "recall": 0.8308351177730193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.8575399862935394,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005159958720330383,
            "ave_precision_score": 0.8579379266437572,
            "fpr": 0.4649122807017544,
            "logloss": 2.298030172567085,
            "mae": 0.45616019399542557,
            "precision": 0.5345773874862788,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.884992754525426,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8851515929143907,
            "fpr": 0.48737650933040616,
            "logloss": 2.406691165250146,
            "mae": 0.476338927164821,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 31658,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8254877640096885,
            "auditor_fn_violation": 0.03586224287618431,
            "auditor_fp_violation": 0.022092363261093914,
            "ave_precision_score": 0.8257702564770659,
            "fpr": 0.09429824561403509,
            "logloss": 0.5833333756833626,
            "mae": 0.3230991099180915,
            "precision": 0.7922705314009661,
            "recall": 0.6735112936344969
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8578119240886071,
            "auditor_fn_violation": 0.03007025717086196,
            "auditor_fp_violation": 0.03245616637493696,
            "ave_precision_score": 0.8580762062699333,
            "fpr": 0.10537870472008781,
            "logloss": 0.4817921566229416,
            "mae": 0.2819530434536407,
            "precision": 0.7926565874730022,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6787708463194552,
            "auditor_fn_violation": 0.01012059151986744,
            "auditor_fp_violation": 0.00969298245614035,
            "ave_precision_score": 0.6794884564859076,
            "fpr": 0.23464912280701755,
            "logloss": 1.4197154329131825,
            "mae": 0.43910463537857486,
            "precision": 0.6073394495412844,
            "recall": 0.6796714579055442
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7163903611196765,
            "auditor_fn_violation": 0.010358760521534338,
            "auditor_fp_violation": 0.009871836710475578,
            "ave_precision_score": 0.7168477054742928,
            "fpr": 0.24039517014270034,
            "logloss": 1.4459824536064514,
            "mae": 0.4291957293200927,
            "precision": 0.5974264705882353,
            "recall": 0.69593147751606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8623257756298031,
            "auditor_fn_violation": 0.01816302820706798,
            "auditor_fp_violation": 0.010601135190918471,
            "ave_precision_score": 0.8628330514372428,
            "fpr": 0.10197368421052631,
            "logloss": 0.5193186163089806,
            "mae": 0.2785110522884663,
            "precision": 0.8012820512820513,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8870442847944162,
            "auditor_fn_violation": 0.0064004776265346,
            "auditor_fp_violation": 0.011985640964784765,
            "ave_precision_score": 0.8872022217844627,
            "fpr": 0.11855104281009879,
            "logloss": 0.4510673735869245,
            "mae": 0.25587719265764125,
            "precision": 0.7813765182186235,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8448559730795465,
            "auditor_fn_violation": 0.0005246046327317247,
            "auditor_fp_violation": 0.005660474716202275,
            "ave_precision_score": 0.8451558772145049,
            "fpr": 0.0800438596491228,
            "logloss": 0.5302164123856342,
            "mae": 0.31312079812306093,
            "precision": 0.8165829145728644,
            "recall": 0.6673511293634496
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8841802427160723,
            "auditor_fn_violation": 0.007484069321662197,
            "auditor_fp_violation": 0.002096498254566313,
            "ave_precision_score": 0.8843584572041717,
            "fpr": 0.07464324917672886,
            "logloss": 0.43918024687933976,
            "mae": 0.2782232622134486,
            "precision": 0.837708830548926,
            "recall": 0.7516059957173448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8548089714382406,
            "auditor_fn_violation": 0.006916675672754792,
            "auditor_fp_violation": 0.0085061919504644,
            "ave_precision_score": 0.8550306176667337,
            "fpr": 0.06907894736842106,
            "logloss": 0.5694845085634856,
            "mae": 0.3021653181609796,
            "precision": 0.8401015228426396,
            "recall": 0.6796714579055442
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8568429485185006,
            "auditor_fn_violation": 0.005128843988651667,
            "auditor_fp_violation": 0.005629394487791857,
            "ave_precision_score": 0.8571177690137104,
            "fpr": 0.09549945115257959,
            "logloss": 0.5089004419004145,
            "mae": 0.2883976543433126,
            "precision": 0.7962529274004684,
            "recall": 0.728051391862955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8079792024421876,
            "auditor_fn_violation": 0.010843330091141613,
            "auditor_fp_violation": 0.013826109391124873,
            "ave_precision_score": 0.8068295447278031,
            "fpr": 0.08114035087719298,
            "logloss": 2.2093561821717667,
            "mae": 0.3181143031951495,
            "precision": 0.8159203980099502,
            "recall": 0.6735112936344969
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.8297400270078485,
            "auditor_fn_violation": 0.005845753895406371,
            "auditor_fp_violation": 0.0145222060699558,
            "ave_precision_score": 0.8288478063655058,
            "fpr": 0.0889132821075741,
            "logloss": 1.6728593825696407,
            "mae": 0.2741123083229262,
            "precision": 0.8191964285714286,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7518958464120669,
            "auditor_fn_violation": 0.012083918729060845,
            "auditor_fp_violation": 0.01545665634674923,
            "ave_precision_score": 0.7365445128022481,
            "fpr": 0.19078947368421054,
            "logloss": 1.7624406629937335,
            "mae": 0.2915232463039278,
            "precision": 0.7040816326530612,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7522534530673668,
            "auditor_fn_violation": 0.0077990395757773796,
            "auditor_fp_violation": 0.033034681223484755,
            "ave_precision_score": 0.7348724244324321,
            "fpr": 0.19978046103183314,
            "logloss": 1.8468829856739843,
            "mae": 0.2811021722063962,
            "precision": 0.6976744186046512,
            "recall": 0.8993576017130621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8497746953032188,
            "auditor_fn_violation": 0.01396619114521417,
            "auditor_fp_violation": 0.011777605779153766,
            "ave_precision_score": 0.8501183728246668,
            "fpr": 0.09868421052631579,
            "logloss": 0.6034455298225412,
            "mae": 0.29740092341248753,
            "precision": 0.7963800904977375,
            "recall": 0.7227926078028748
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8894416006608628,
            "auditor_fn_violation": 0.002052007700317556,
            "auditor_fp_violation": 0.013686573510942341,
            "ave_precision_score": 0.8896174278934033,
            "fpr": 0.10098792535675083,
            "logloss": 0.45067818689923794,
            "mae": 0.25786246386116923,
            "precision": 0.8050847457627118,
            "recall": 0.8137044967880086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8084078005460195,
            "auditor_fn_violation": 0.01208617025108974,
            "auditor_fp_violation": 0.02476264189886481,
            "ave_precision_score": 0.779014995500637,
            "fpr": 0.17324561403508773,
            "logloss": 2.004282224937931,
            "mae": 0.29691768614034036,
            "precision": 0.7237762237762237,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7965402806229842,
            "auditor_fn_violation": 0.002350524284441645,
            "auditor_fp_violation": 0.01637642032812175,
            "ave_precision_score": 0.7626067732997277,
            "fpr": 0.18551042810098792,
            "logloss": 2.228508921201343,
            "mae": 0.29356692253042554,
            "precision": 0.7111111111111111,
            "recall": 0.8907922912205567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8229453441764958,
            "auditor_fn_violation": 0.027686966389279158,
            "auditor_fp_violation": 0.011215170278637776,
            "ave_precision_score": 0.8233764032383218,
            "fpr": 0.07785087719298246,
            "logloss": 0.5948549216259225,
            "mae": 0.3256260449041675,
            "precision": 0.8126649076517151,
            "recall": 0.6324435318275154
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8748891626617473,
            "auditor_fn_violation": 0.026657295909852694,
            "auditor_fp_violation": 0.00901889815171923,
            "ave_precision_score": 0.8750511132312675,
            "fpr": 0.07903402854006586,
            "logloss": 0.48789731391163066,
            "mae": 0.28356352800023177,
            "precision": 0.8309859154929577,
            "recall": 0.7580299785867237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8409648795982146,
            "auditor_fn_violation": 0.012394628769047879,
            "auditor_fp_violation": 0.012776057791537666,
            "ave_precision_score": 0.8020211840867104,
            "fpr": 0.14144736842105263,
            "logloss": 2.252981730518953,
            "mae": 0.2676865005916242,
            "precision": 0.7523992322456814,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8779874074286098,
            "auditor_fn_violation": 0.005248720727158195,
            "auditor_fp_violation": 0.01663353803858744,
            "ave_precision_score": 0.8396481553500624,
            "fpr": 0.14050493962678376,
            "logloss": 2.0036139087078064,
            "mae": 0.2345169489236158,
            "precision": 0.7593984962406015,
            "recall": 0.8650963597430407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8508991406163406,
            "auditor_fn_violation": 0.004503044057783062,
            "auditor_fp_violation": 0.015000000000000015,
            "ave_precision_score": 0.8512556560483991,
            "fpr": 0.40789473684210525,
            "logloss": 0.9323331623253325,
            "mae": 0.3832906335633117,
            "precision": 0.5628672150411281,
            "recall": 0.9835728952772074
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.8921363024736809,
            "auditor_fn_violation": 0.00013868093278205713,
            "auditor_fp_violation": 0.01839875001236145,
            "ave_precision_score": 0.8922931271457089,
            "fpr": 0.43688254665203075,
            "logloss": 0.9315282642121998,
            "mae": 0.38718428005158706,
            "precision": 0.5388180764774044,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8389196696897931,
            "auditor_fn_violation": 0.015303595230375734,
            "auditor_fp_violation": 0.013513931888544897,
            "ave_precision_score": 0.8031914347181526,
            "fpr": 0.16228070175438597,
            "logloss": 2.1311433914736444,
            "mae": 0.2828261775563046,
            "precision": 0.7323688969258589,
            "recall": 0.8316221765913757
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8816718291821435,
            "auditor_fn_violation": 0.005389752184224691,
            "auditor_fp_violation": 0.02077956111984652,
            "ave_precision_score": 0.8484341627265122,
            "fpr": 0.15916575192096596,
            "logloss": 1.8657561219595953,
            "mae": 0.25001678852575016,
            "precision": 0.7419928825622776,
            "recall": 0.892933618843683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8614255337331089,
            "auditor_fn_violation": 0.01936534097049606,
            "auditor_fp_violation": 0.021955624355005168,
            "ave_precision_score": 0.8620994929340453,
            "fpr": 0.1425438596491228,
            "logloss": 0.5163961309109333,
            "mae": 0.2875893642061815,
            "precision": 0.7504798464491362,
            "recall": 0.8028747433264887
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8871341933601135,
            "auditor_fn_violation": 0.007164398018978137,
            "auditor_fp_violation": 0.02009968255851901,
            "ave_precision_score": 0.8873007742906338,
            "fpr": 0.15477497255762898,
            "logloss": 0.470379306521142,
            "mae": 0.27015170390164617,
            "precision": 0.7412844036697248,
            "recall": 0.8650963597430407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7355841569589014,
            "auditor_fn_violation": 0.01628976187903023,
            "auditor_fp_violation": 0.014169246646026838,
            "ave_precision_score": 0.7367253789884248,
            "fpr": 0.12280701754385964,
            "logloss": 0.6614348900520595,
            "mae": 0.3364112437866105,
            "precision": 0.7622080679405521,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8358773860727767,
            "auditor_fn_violation": 0.00030321763269297336,
            "auditor_fp_violation": 0.01883881686296615,
            "ave_precision_score": 0.8367141840476698,
            "fpr": 0.11855104281009879,
            "logloss": 0.48997183388136556,
            "mae": 0.29185003495716894,
            "precision": 0.7818181818181819,
            "recall": 0.828693790149893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8367775032061731,
            "auditor_fn_violation": 0.0105821535357902,
            "auditor_fp_violation": 0.0052941176470588285,
            "ave_precision_score": 0.8382064255277286,
            "fpr": 0.08114035087719298,
            "logloss": 0.5197796862566324,
            "mae": 0.3069623558590058,
            "precision": 0.821256038647343,
            "recall": 0.6981519507186859
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8773657786640243,
            "auditor_fn_violation": 0.006212435683779272,
            "auditor_fp_violation": 0.007664085600419304,
            "ave_precision_score": 0.8775635990706935,
            "fpr": 0.08781558726673985,
            "logloss": 0.44559914915841387,
            "mae": 0.2775368287926284,
            "precision": 0.8190045248868778,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8618874704006294,
            "auditor_fn_violation": 0.009523938182211178,
            "auditor_fp_violation": 0.015448916408668734,
            "ave_precision_score": 0.8622635054259274,
            "fpr": 0.11951754385964912,
            "logloss": 0.5623306613232435,
            "mae": 0.269436728746944,
            "precision": 0.7770961145194274,
            "recall": 0.7802874743326489
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8706640937034624,
            "auditor_fn_violation": 0.006264147218036984,
            "auditor_fp_violation": 0.014339256929816755,
            "ave_precision_score": 0.8708716761896671,
            "fpr": 0.13721185510428102,
            "logloss": 0.5239327966669629,
            "mae": 0.2598505995648447,
            "precision": 0.7549019607843137,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8467862913229713,
            "auditor_fn_violation": 0.006675762815663393,
            "auditor_fp_violation": 0.016434468524251813,
            "ave_precision_score": 0.8472000125055676,
            "fpr": 0.1206140350877193,
            "logloss": 0.6892415127084892,
            "mae": 0.26794582909746767,
            "precision": 0.7745901639344263,
            "recall": 0.7761806981519507
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8451934184834469,
            "auditor_fn_violation": 0.00574468135117538,
            "auditor_fp_violation": 0.006022487910523045,
            "ave_precision_score": 0.8456924390616753,
            "fpr": 0.1394072447859495,
            "logloss": 0.6636268538266836,
            "mae": 0.2565842926773689,
            "precision": 0.75049115913556,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8095947017822005,
            "auditor_fn_violation": 0.014306170971576793,
            "auditor_fp_violation": 0.006240970072239425,
            "ave_precision_score": 0.8102217879476221,
            "fpr": 0.08333333333333333,
            "logloss": 0.6025878594535469,
            "mae": 0.33154360543281436,
            "precision": 0.8036175710594315,
            "recall": 0.6386036960985626
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8725213281946846,
            "auditor_fn_violation": 0.006191280965219295,
            "auditor_fp_violation": 0.010146260420684134,
            "ave_precision_score": 0.8727185702742479,
            "fpr": 0.06256860592755215,
            "logloss": 0.4730183919736259,
            "mae": 0.282310726962112,
            "precision": 0.8567839195979899,
            "recall": 0.7301927194860813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 31658,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8486159695695726,
            "auditor_fn_violation": 0.016366313628012538,
            "auditor_fp_violation": 0.01838235294117647,
            "ave_precision_score": 0.8491569213533859,
            "fpr": 0.08771929824561403,
            "logloss": 0.5818667374656897,
            "mae": 0.2896139256184251,
            "precision": 0.8090692124105012,
            "recall": 0.6960985626283368
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8792452284348873,
            "auditor_fn_violation": 0.005580144651264468,
            "auditor_fp_violation": 0.005792565342510459,
            "ave_precision_score": 0.8795009110091128,
            "fpr": 0.07574094401756312,
            "logloss": 0.45892854649280285,
            "mae": 0.25400891382810536,
            "precision": 0.8364928909952607,
            "recall": 0.7558886509635975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.8270936364225611,
            "auditor_fn_violation": 0.01746280485608271,
            "auditor_fp_violation": 0.017835397316821475,
            "ave_precision_score": 0.8274092915633563,
            "fpr": 0.23793859649122806,
            "logloss": 0.6354900345582507,
            "mae": 0.34300582261609014,
            "precision": 0.6571879936808847,
            "recall": 0.8542094455852156
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.874873210918047,
            "auditor_fn_violation": 0.00015278407848870796,
            "auditor_fp_violation": 0.023318598510695124,
            "ave_precision_score": 0.8750867815954945,
            "fpr": 0.23710208562019758,
            "logloss": 0.5815659692709433,
            "mae": 0.3179438156060441,
            "precision": 0.6671802773497689,
            "recall": 0.9271948608137045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8152089594290848,
            "auditor_fn_violation": 0.008936290932670484,
            "auditor_fp_violation": 0.0017466460268317882,
            "ave_precision_score": 0.8162463240310857,
            "fpr": 0.08662280701754387,
            "logloss": 0.5493470967479498,
            "mae": 0.3317853892671369,
            "precision": 0.8058968058968059,
            "recall": 0.6735112936344969
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8750321680934475,
            "auditor_fn_violation": 0.009242261486424548,
            "auditor_fp_violation": 0.010793999268203439,
            "ave_precision_score": 0.8752472785047146,
            "fpr": 0.08122941822173436,
            "logloss": 0.45157146227580386,
            "mae": 0.29428590942709887,
            "precision": 0.8298850574712644,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 31658,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7648449544754354,
            "auditor_fn_violation": 0.017521344428833893,
            "auditor_fp_violation": 0.019912280701754385,
            "ave_precision_score": 0.7257606000583605,
            "fpr": 0.2236842105263158,
            "logloss": 2.82482691260621,
            "mae": 0.3128483546445655,
            "precision": 0.6746411483253588,
            "recall": 0.8685831622176592
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7558121506993408,
            "auditor_fn_violation": 0.014824756661973455,
            "auditor_fp_violation": 0.03165514581540928,
            "ave_precision_score": 0.7140264512103791,
            "fpr": 0.23161361141602635,
            "logloss": 2.922644297633655,
            "mae": 0.3006964706821934,
            "precision": 0.6713395638629284,
            "recall": 0.9229122055674518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7909053108002336,
            "auditor_fn_violation": 0.011136027954897522,
            "auditor_fp_violation": 0.02057533539731682,
            "ave_precision_score": 0.7913526428386667,
            "fpr": 0.12171052631578948,
            "logloss": 0.6474424709693796,
            "mae": 0.34493736148017395,
            "precision": 0.74364896073903,
            "recall": 0.6611909650924025
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.851825552680356,
            "auditor_fn_violation": 0.005067730357256192,
            "auditor_fp_violation": 0.021093541400895956,
            "ave_precision_score": 0.8520710325875632,
            "fpr": 0.10428100987925357,
            "logloss": 0.5275568140450392,
            "mae": 0.298945697673119,
            "precision": 0.7902869757174393,
            "recall": 0.7665952890792291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8562261467433153,
            "auditor_fn_violation": 0.013522641305522536,
            "auditor_fp_violation": 0.0065273477812177495,
            "ave_precision_score": 0.8565091599553054,
            "fpr": 0.08442982456140351,
            "logloss": 0.5187216918446833,
            "mae": 0.30499065402545966,
            "precision": 0.8157894736842105,
            "recall": 0.7002053388090349
        },
        "train": {
            "accuracy": 0.8111964873765093,
            "auc_prc": 0.8918531982537251,
            "auditor_fn_violation": 0.006771860463476378,
            "auditor_fp_violation": 0.010591271842643963,
            "ave_precision_score": 0.8920105898017637,
            "fpr": 0.07903402854006586,
            "logloss": 0.4230574027784964,
            "mae": 0.2652639187003448,
            "precision": 0.835990888382688,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8568497613459918,
            "auditor_fn_violation": 0.005531989624986496,
            "auditor_fp_violation": 0.009071207430340558,
            "ave_precision_score": 0.8572022166674367,
            "fpr": 0.0800438596491228,
            "logloss": 0.5253258243519932,
            "mae": 0.29632082033959595,
            "precision": 0.8236714975845411,
            "recall": 0.7002053388090349
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.885975577406875,
            "auditor_fn_violation": 0.0030110216083697487,
            "auditor_fp_violation": 0.005330247920807746,
            "ave_precision_score": 0.8861451975039217,
            "fpr": 0.08342480790340286,
            "logloss": 0.44009053321745334,
            "mae": 0.2651418503023721,
            "precision": 0.8256880733944955,
            "recall": 0.7708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8195326330897216,
            "auditor_fn_violation": 0.006297507114809614,
            "auditor_fp_violation": 0.0009520123839009296,
            "ave_precision_score": 0.8198864036665363,
            "fpr": 0.08114035087719298,
            "logloss": 0.5839795489754182,
            "mae": 0.33080285613648713,
            "precision": 0.8047493403693932,
            "recall": 0.6262833675564682
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8809353994831556,
            "auditor_fn_violation": 0.004973709385878524,
            "auditor_fp_violation": 0.00906834386527032,
            "ave_precision_score": 0.8810921791131572,
            "fpr": 0.06366630076838639,
            "logloss": 0.457747678926794,
            "mae": 0.27898976305023276,
            "precision": 0.8542713567839196,
            "recall": 0.728051391862955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7705348372131373,
            "auditor_fn_violation": 0.01692469109117764,
            "auditor_fp_violation": 0.02800567595459237,
            "ave_precision_score": 0.7295091741365958,
            "fpr": 0.23026315789473684,
            "logloss": 2.8970258124644857,
            "mae": 0.3130310879195461,
            "precision": 0.670846394984326,
            "recall": 0.8788501026694046
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7632953423110497,
            "auditor_fn_violation": 0.012213324181958786,
            "auditor_fp_violation": 0.044016574203182335,
            "ave_precision_score": 0.7206236012669457,
            "fpr": 0.2524698133918771,
            "logloss": 3.0063368100973147,
            "mae": 0.30696441234576566,
            "precision": 0.6520423600605144,
            "recall": 0.9229122055674518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8536933841812268,
            "auditor_fn_violation": 0.01026468892971649,
            "auditor_fp_violation": 0.0046904024767801915,
            "ave_precision_score": 0.8540742804708688,
            "fpr": 0.22039473684210525,
            "logloss": 0.6001409272716622,
            "mae": 0.3272393722191306,
            "precision": 0.6854460093896714,
            "recall": 0.8993839835728953
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8881500175023396,
            "auditor_fn_violation": 0.007709719652968596,
            "auditor_fp_violation": 0.01501171863411161,
            "ave_precision_score": 0.8883268691620141,
            "fpr": 0.23710208562019758,
            "logloss": 0.5654848125643028,
            "mae": 0.31058816660837596,
            "precision": 0.669218989280245,
            "recall": 0.9357601713062098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7585282977670635,
            "auditor_fn_violation": 0.011104506646493033,
            "auditor_fp_violation": 0.014641382868937052,
            "ave_precision_score": 0.7600422057722793,
            "fpr": 0.09868421052631579,
            "logloss": 0.6673816521624203,
            "mae": 0.3570212842928493,
            "precision": 0.7674418604651163,
            "recall": 0.6098562628336756
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8331409067141518,
            "auditor_fn_violation": 0.014284136076551879,
            "auditor_fp_violation": 0.016551952611228136,
            "ave_precision_score": 0.8335306535201013,
            "fpr": 0.0845225027442371,
            "logloss": 0.5246862633341624,
            "mae": 0.3063217025438301,
            "precision": 0.8079800498753117,
            "recall": 0.6937901498929336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7973608290274505,
            "auditor_fn_violation": 0.011345419503584425,
            "auditor_fp_violation": 0.011545407636738909,
            "ave_precision_score": 0.7979649081079389,
            "fpr": 0.2741228070175439,
            "logloss": 0.7522597522510768,
            "mae": 0.3548524470026933,
            "precision": 0.6328928046989721,
            "recall": 0.8850102669404517
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8537816717957483,
            "auditor_fn_violation": 0.0012011179093496807,
            "auditor_fp_violation": 0.02166711167808863,
            "ave_precision_score": 0.8541631500184336,
            "fpr": 0.287596048298573,
            "logloss": 0.6968025714718117,
            "mae": 0.33456944036026587,
            "precision": 0.6273115220483642,
            "recall": 0.9443254817987152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8454499345549393,
            "auditor_fn_violation": 0.015510735257033755,
            "auditor_fp_violation": 0.021746646026831788,
            "ave_precision_score": 0.8458171760082679,
            "fpr": 0.15570175438596492,
            "logloss": 0.5926703704948664,
            "mae": 0.30366179366172763,
            "precision": 0.7404021937842779,
            "recall": 0.8316221765913757
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8944465934354312,
            "auditor_fn_violation": 0.0021742349631085228,
            "auditor_fp_violation": 0.017563117453347966,
            "ave_precision_score": 0.8946068387851419,
            "fpr": 0.16465422612513722,
            "logloss": 0.5043521914864667,
            "mae": 0.2734975943264667,
            "precision": 0.7377622377622378,
            "recall": 0.9036402569593148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8142531405073364,
            "auditor_fn_violation": 0.007459292481717645,
            "auditor_fp_violation": 0.004357585139318889,
            "ave_precision_score": 0.815019904699334,
            "fpr": 0.08442982456140351,
            "logloss": 0.5539800243166542,
            "mae": 0.33511907049646733,
            "precision": 0.8065326633165829,
            "recall": 0.6591375770020534
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.8727760309153021,
            "auditor_fn_violation": 0.007921266838568346,
            "auditor_fp_violation": 0.008606026443567609,
            "ave_precision_score": 0.8729964314491798,
            "fpr": 0.07135016465422613,
            "logloss": 0.4551648768110486,
            "mae": 0.29692160580348137,
            "precision": 0.8456057007125891,
            "recall": 0.7623126338329764
        }
    }
]