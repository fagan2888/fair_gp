[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.98894603901598,
            "mae": 0.5208333333333334,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.16034455890474,
            "mae": 0.5257958287596048,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.98894603901598,
            "mae": 0.5208333333333334,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.16034455890474,
            "mae": 0.5257958287596048,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.768789949667295,
            "auditor_fn_violation": 0.010526315789473693,
            "auditor_fp_violation": 0.023480468906820828,
            "ave_precision_score": 0.6790057586550377,
            "fpr": 0.15789473684210525,
            "logloss": 4.923911028068268,
            "mae": 0.40078034497013215,
            "precision": 0.6923076923076923,
            "recall": 0.6821052631578948
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7747922422376764,
            "auditor_fn_violation": 0.023507627718742628,
            "auditor_fp_violation": 0.02611598975484816,
            "ave_precision_score": 0.6907166360074715,
            "fpr": 0.150384193194292,
            "logloss": 4.595348439743964,
            "mae": 0.39690631961717826,
            "precision": 0.6989010989010989,
            "recall": 0.6638830897703549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7703318843960281,
            "auditor_fn_violation": 0.010526315789473693,
            "auditor_fp_violation": 0.023480468906820828,
            "ave_precision_score": 0.6805846012783294,
            "fpr": 0.15789473684210525,
            "logloss": 4.922863580344656,
            "mae": 0.39998180121836957,
            "precision": 0.6923076923076923,
            "recall": 0.6821052631578948
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7758667798717996,
            "auditor_fn_violation": 0.024124078474868756,
            "auditor_fp_violation": 0.02611598975484816,
            "ave_precision_score": 0.6918869462341277,
            "fpr": 0.150384193194292,
            "logloss": 4.59450956974111,
            "mae": 0.39622826172543935,
            "precision": 0.698237885462555,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.769952899662443,
            "auditor_fn_violation": 0.005794090489381348,
            "auditor_fp_violation": 0.021959934160343662,
            "ave_precision_score": 0.6803644688497403,
            "fpr": 0.1699561403508772,
            "logloss": 4.960022384970024,
            "mae": 0.388630891914296,
            "precision": 0.6868686868686869,
            "recall": 0.7157894736842105
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7765935129756123,
            "auditor_fn_violation": 0.016777085448324704,
            "auditor_fp_violation": 0.024987803390657395,
            "ave_precision_score": 0.6927552811174482,
            "fpr": 0.1602634467618002,
            "logloss": 4.605692780516494,
            "mae": 0.38360784684365173,
            "precision": 0.6958333333333333,
            "recall": 0.697286012526096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7704801653694979,
            "auditor_fn_violation": 0.015350877192982464,
            "auditor_fp_violation": 0.023480468906820828,
            "ave_precision_score": 0.680730259919223,
            "fpr": 0.15789473684210525,
            "logloss": 4.988793861872942,
            "mae": 0.3998944602867392,
            "precision": 0.6916488222698073,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7759787773099008,
            "auditor_fn_violation": 0.023498461164748182,
            "auditor_fp_violation": 0.025612879619465793,
            "ave_precision_score": 0.6920643383857411,
            "fpr": 0.14928649835345773,
            "logloss": 4.6630861542801,
            "mae": 0.39602423297763795,
            "precision": 0.7004405286343612,
            "recall": 0.6638830897703549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7767590931951791,
            "auditor_fn_violation": 0.019561403508771925,
            "auditor_fp_violation": 0.03389588100686499,
            "ave_precision_score": 0.688245917635669,
            "fpr": 0.18640350877192982,
            "logloss": 5.056300037584367,
            "mae": 0.3352568713254731,
            "precision": 0.6846011131725418,
            "recall": 0.7768421052631579
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7845356080865366,
            "auditor_fn_violation": 0.0244976155501422,
            "auditor_fp_violation": 0.026654673334146447,
            "ave_precision_score": 0.7012213996973687,
            "fpr": 0.17672886937431395,
            "logloss": 4.941414616383286,
            "mae": 0.3236235438891624,
            "precision": 0.6973684210526315,
            "recall": 0.7745302713987474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7747887196332836,
            "auditor_fn_violation": 0.010489381348107122,
            "auditor_fp_violation": 0.026137641013288374,
            "ave_precision_score": 0.6997785316640287,
            "fpr": 0.1524122807017544,
            "logloss": 4.274567157236467,
            "mae": 0.3909755316299303,
            "precision": 0.6997840172786177,
            "recall": 0.6821052631578948
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7748416320543503,
            "auditor_fn_violation": 0.025040733874312805,
            "auditor_fp_violation": 0.02521903077611091,
            "ave_precision_score": 0.7022254344424202,
            "fpr": 0.1394072447859495,
            "logloss": 4.103932185696293,
            "mae": 0.3848580136304492,
            "precision": 0.7107061503416856,
            "recall": 0.651356993736952
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7654672160629944,
            "auditor_fn_violation": 0.012472299168975076,
            "auditor_fp_violation": 0.02219328355212976,
            "ave_precision_score": 0.6788223683087251,
            "fpr": 0.15021929824561403,
            "logloss": 5.386429811752885,
            "mae": 0.38455805231501067,
            "precision": 0.6995614035087719,
            "recall": 0.671578947368421
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7736535163435689,
            "auditor_fn_violation": 0.019792881712495613,
            "auditor_fp_violation": 0.026382790584217587,
            "ave_precision_score": 0.6922604606353076,
            "fpr": 0.141602634467618,
            "logloss": 5.044505322924427,
            "mae": 0.37783711005535764,
            "precision": 0.7101123595505618,
            "recall": 0.6597077244258872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7754120855747691,
            "auditor_fn_violation": 0.008504155124653745,
            "auditor_fp_violation": 0.025670942229716175,
            "ave_precision_score": 0.700995523935221,
            "fpr": 0.15350877192982457,
            "logloss": 4.214795781047649,
            "mae": 0.39042319559725974,
            "precision": 0.6963123644251626,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7739765698477958,
            "auditor_fn_violation": 0.025040733874312805,
            "auditor_fp_violation": 0.02521903077611091,
            "ave_precision_score": 0.7014950614900447,
            "fpr": 0.1394072447859495,
            "logloss": 4.085598201728254,
            "mae": 0.3844111089785656,
            "precision": 0.7107061503416856,
            "recall": 0.651356993736952
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.775862695248019,
            "auditor_fn_violation": 0.008504155124653745,
            "auditor_fp_violation": 0.025041149785218198,
            "ave_precision_score": 0.7013836182488626,
            "fpr": 0.1524122807017544,
            "logloss": 4.207412264229444,
            "mae": 0.3902089027342685,
            "precision": 0.6978260869565217,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7748019610269664,
            "auditor_fn_violation": 0.02522635659270022,
            "auditor_fp_violation": 0.02521903077611091,
            "ave_precision_score": 0.7029059394856942,
            "fpr": 0.1394072447859495,
            "logloss": 4.061988752883244,
            "mae": 0.38425940225494826,
            "precision": 0.7100456621004566,
            "recall": 0.6492693110647182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 27690,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.6046736719751897,
            "auditor_fn_violation": 0.0033264081255771046,
            "auditor_fp_violation": 0.0037913003332128957,
            "ave_precision_score": 0.601465316277783,
            "fpr": 0.009868421052631578,
            "logloss": 0.8644447802302082,
            "mae": 0.49982105552716943,
            "precision": 0.7906976744186046,
            "recall": 0.07157894736842105
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5926295805633068,
            "auditor_fn_violation": 0.005460974542187949,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.58810282987966,
            "fpr": 0.006586169045005488,
            "logloss": 0.9845517150674873,
            "mae": 0.49836385035846764,
            "precision": 0.8333333333333334,
            "recall": 0.06263048016701461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.47133590356965793,
            "auditor_fn_violation": 0.004963065558633431,
            "auditor_fp_violation": 0.012164277971817416,
            "ave_precision_score": 0.5194668024445656,
            "fpr": 0.049342105263157895,
            "logloss": 12.26491291818404,
            "mae": 0.5507822834664247,
            "precision": 0.5833333333333334,
            "recall": 0.13263157894736843
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.4650062192669731,
            "auditor_fn_violation": 0.01718270546257869,
            "auditor_fp_violation": 0.011134487945684434,
            "ave_precision_score": 0.518942796813533,
            "fpr": 0.050493962678375415,
            "logloss": 12.590923539384109,
            "mae": 0.5542726814562842,
            "precision": 0.5818181818181818,
            "recall": 0.1336116910229645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.805499480701483,
            "auditor_fn_violation": 0.00999538319482918,
            "auditor_fp_violation": 0.01159470472519973,
            "ave_precision_score": 0.7673901671284838,
            "fpr": 0.09868421052631579,
            "logloss": 4.185265397205671,
            "mae": 0.31581840507933157,
            "precision": 0.775,
            "recall": 0.6526315789473685
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8096648163357658,
            "auditor_fn_violation": 0.018516439068769784,
            "auditor_fp_violation": 0.006672561694515593,
            "ave_precision_score": 0.7764328302940564,
            "fpr": 0.10757409440175632,
            "logloss": 4.347701399447694,
            "mae": 0.31488272034027526,
            "precision": 0.7644230769230769,
            "recall": 0.6638830897703549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 27690,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7800691250786539,
            "auditor_fn_violation": 0.010431671283471847,
            "auditor_fp_violation": 0.021440543578626205,
            "ave_precision_score": 0.6924586152235168,
            "fpr": 0.15021929824561403,
            "logloss": 4.83694442019842,
            "mae": 0.3907909924751597,
            "precision": 0.7008733624454149,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7838311509779278,
            "auditor_fn_violation": 0.017948112721114472,
            "auditor_fp_violation": 0.02497255762897915,
            "ave_precision_score": 0.7020410951960268,
            "fpr": 0.14489571899012074,
            "logloss": 4.5525167582278385,
            "mae": 0.3905869646470188,
            "precision": 0.7053571428571429,
            "recall": 0.6597077244258872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.45722278016044104,
            "auditor_fn_violation": 0.010145429362880883,
            "auditor_fp_violation": 0.0077783130595367135,
            "ave_precision_score": 0.5042881207362127,
            "fpr": 0.02631578947368421,
            "logloss": 11.943197089993136,
            "mae": 0.5883718746943072,
            "precision": 0.48936170212765956,
            "recall": 0.04842105263157895
        },
        "train": {
            "accuracy": 0.4654226125137212,
            "auc_prc": 0.45438735790517726,
            "auditor_fn_violation": 0.01074549291998286,
            "auditor_fp_violation": 0.007013050371996586,
            "ave_precision_score": 0.5005867379074198,
            "fpr": 0.03293084522502744,
            "logloss": 11.868317826342311,
            "mae": 0.5955069188237593,
            "precision": 0.4230769230769231,
            "recall": 0.04592901878914405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7823357843286103,
            "auditor_fn_violation": 0.011488919667590032,
            "auditor_fp_violation": 0.024034987353968452,
            "ave_precision_score": 0.6924684283353368,
            "fpr": 0.15460526315789475,
            "logloss": 4.928442510058674,
            "mae": 0.3955494505070532,
            "precision": 0.6954643628509719,
            "recall": 0.6778947368421052
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7861319081460489,
            "auditor_fn_violation": 0.020574330440521676,
            "auditor_fp_violation": 0.026121071675407576,
            "ave_precision_score": 0.7021264611928358,
            "fpr": 0.14709110867178923,
            "logloss": 4.630847110313082,
            "mae": 0.3941149404888378,
            "precision": 0.7035398230088495,
            "recall": 0.6638830897703549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7800842208498561,
            "auditor_fn_violation": 0.012280701754385972,
            "auditor_fp_violation": 0.020722931470552812,
            "ave_precision_score": 0.6902475655046361,
            "fpr": 0.15679824561403508,
            "logloss": 4.91447125401935,
            "mae": 0.39651910846301336,
            "precision": 0.6931330472103004,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7860470896324849,
            "auditor_fn_violation": 0.021914938962208596,
            "auditor_fp_violation": 0.025673862666178802,
            "ave_precision_score": 0.702023691805252,
            "fpr": 0.14928649835345773,
            "logloss": 4.589641417225671,
            "mae": 0.39352640467077393,
            "precision": 0.7017543859649122,
            "recall": 0.6680584551148225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.770534315642749,
            "auditor_fn_violation": 0.00629501385041552,
            "auditor_fp_violation": 0.021330141715845678,
            "ave_precision_score": 0.680943881476412,
            "fpr": 0.16885964912280702,
            "logloss": 4.959025877508123,
            "mae": 0.3870857920788805,
            "precision": 0.6876267748478702,
            "recall": 0.7136842105263158
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7775633990267425,
            "auditor_fn_violation": 0.016777085448324704,
            "auditor_fp_violation": 0.024987803390657395,
            "ave_precision_score": 0.6936463609610142,
            "fpr": 0.1602634467618002,
            "logloss": 4.605042564597876,
            "mae": 0.3821703629371111,
            "precision": 0.6958333333333333,
            "recall": 0.697286012526096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.709773365825429,
            "auditor_fn_violation": 0.010327793167128355,
            "auditor_fp_violation": 0.00831024930747924,
            "ave_precision_score": 0.590400712084564,
            "fpr": 0.33223684210526316,
            "logloss": 9.209694784184027,
            "mae": 0.4454029200178179,
            "precision": 0.5544117647058824,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7166635764351963,
            "auditor_fn_violation": 0.009498841576738956,
            "auditor_fp_violation": 0.010252774728625447,
            "ave_precision_score": 0.5941584842241705,
            "fpr": 0.33260153677277715,
            "logloss": 8.958302285734762,
            "mae": 0.4319090990468507,
            "precision": 0.5671428571428572,
            "recall": 0.8288100208768268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.599478927298418,
            "auditor_fn_violation": 0.004365189289012015,
            "auditor_fp_violation": 0.0037913003332128957,
            "ave_precision_score": 0.5962307278145962,
            "fpr": 0.009868421052631578,
            "logloss": 0.8653241083901667,
            "mae": 0.4999627516542232,
            "precision": 0.7631578947368421,
            "recall": 0.061052631578947365
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5876496017073635,
            "auditor_fn_violation": 0.004026408842057993,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.5831821731237986,
            "fpr": 0.006586169045005488,
            "logloss": 0.9854837840339686,
            "mae": 0.4985724862001063,
            "precision": 0.8181818181818182,
            "recall": 0.05636743215031315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7815227157885761,
            "auditor_fn_violation": 0.011488919667590032,
            "auditor_fp_violation": 0.021586073306836893,
            "ave_precision_score": 0.6915146691467418,
            "fpr": 0.15570175438596492,
            "logloss": 4.914176721367951,
            "mae": 0.39632378153404907,
            "precision": 0.6939655172413793,
            "recall": 0.6778947368421052
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7855485634006629,
            "auditor_fn_violation": 0.020331416759668996,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7014102599681524,
            "fpr": 0.14818880351262348,
            "logloss": 4.625843048069675,
            "mae": 0.3944705097591576,
            "precision": 0.7013274336283186,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7804248944873757,
            "auditor_fn_violation": 0.009120498614958445,
            "auditor_fp_violation": 0.022973623991328438,
            "ave_precision_score": 0.7021851568022781,
            "fpr": 0.14364035087719298,
            "logloss": 5.210847687623356,
            "mae": 0.30929741235451347,
            "precision": 0.7182795698924731,
            "recall": 0.7031578947368421
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8004689927941838,
            "auditor_fn_violation": 0.015878763156869532,
            "auditor_fp_violation": 0.018442289710127256,
            "ave_precision_score": 0.7267069357395868,
            "fpr": 0.12952799121844127,
            "logloss": 4.497055055584835,
            "mae": 0.28777678967313775,
            "precision": 0.7489361702127659,
            "recall": 0.7348643006263048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7806318950188582,
            "auditor_fn_violation": 0.014111265004616807,
            "auditor_fp_violation": 0.015619354450198724,
            "ave_precision_score": 0.6825481511566526,
            "fpr": 0.21929824561403508,
            "logloss": 5.566615627702739,
            "mae": 0.37479512774990026,
            "precision": 0.66996699669967,
            "recall": 0.8547368421052631
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7850530729713954,
            "auditor_fn_violation": 0.020922659492310407,
            "auditor_fp_violation": 0.018752286864251733,
            "ave_precision_score": 0.6937537486229665,
            "fpr": 0.20636663007683864,
            "logloss": 5.239034993001545,
            "mae": 0.37310602906270307,
            "precision": 0.6818950930626058,
            "recall": 0.8413361169102297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.6067046206482487,
            "auditor_fn_violation": 0.0025392428439520026,
            "auditor_fp_violation": 0.0037913003332128957,
            "ave_precision_score": 0.6047328298603141,
            "fpr": 0.009868421052631578,
            "logloss": 0.8668579083694963,
            "mae": 0.5001190325487582,
            "precision": 0.71875,
            "recall": 0.04842105263157895
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5927363417003746,
            "auditor_fn_violation": 0.0012901924747175074,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.5906170442610699,
            "fpr": 0.006586169045005488,
            "logloss": 0.9870791212492442,
            "mae": 0.498841541634097,
            "precision": 0.8125,
            "recall": 0.054279749478079335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 27690,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7887631766832397,
            "auditor_fn_violation": 0.011759002770083104,
            "auditor_fp_violation": 0.021440543578626205,
            "ave_precision_score": 0.7020041750698148,
            "fpr": 0.15021929824561403,
            "logloss": 4.787741049760947,
            "mae": 0.38886209885675815,
            "precision": 0.7008733624454149,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7896216222213457,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7088346160989438,
            "fpr": 0.1437980241492865,
            "logloss": 4.498551884820344,
            "mae": 0.38854782343826755,
            "precision": 0.7075892857142857,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7936602801206423,
            "auditor_fn_violation": 0.0074445983379501385,
            "auditor_fp_violation": 0.008021698984302862,
            "ave_precision_score": 0.7237395817428984,
            "fpr": 0.3256578947368421,
            "logloss": 4.954757843897229,
            "mae": 0.3616246527648658,
            "precision": 0.592032967032967,
            "recall": 0.9073684210526316
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.8062660490055752,
            "auditor_fn_violation": 0.010871533037406416,
            "auditor_fp_violation": 0.004045208765296582,
            "ave_precision_score": 0.7411370910863625,
            "fpr": 0.3380900109769484,
            "logloss": 4.620481066578969,
            "mae": 0.3598558072294172,
            "precision": 0.5871313672922251,
            "recall": 0.9144050104384134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8269792103895921,
            "auditor_fn_violation": 0.008527239150507848,
            "auditor_fp_violation": 0.01916475972540046,
            "ave_precision_score": 0.7862379923704375,
            "fpr": 0.10416666666666667,
            "logloss": 3.391622385076853,
            "mae": 0.28792766346378057,
            "precision": 0.7780373831775701,
            "recall": 0.7010526315789474
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8273829188223395,
            "auditor_fn_violation": 0.02119307283514641,
            "auditor_fp_violation": 0.007996402000243936,
            "ave_precision_score": 0.7859538577811267,
            "fpr": 0.09989023051591657,
            "logloss": 3.564440728458948,
            "mae": 0.2876200115901908,
            "precision": 0.7873831775700935,
            "recall": 0.7035490605427975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7770657601030458,
            "auditor_fn_violation": 0.017728531855955684,
            "auditor_fp_violation": 0.03150718615761373,
            "ave_precision_score": 0.6885524470219264,
            "fpr": 0.17543859649122806,
            "logloss": 5.056267421698946,
            "mae": 0.33301087132873314,
            "precision": 0.6952380952380952,
            "recall": 0.7684210526315789
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7853282321689713,
            "auditor_fn_violation": 0.02062703812598971,
            "auditor_fp_violation": 0.02203520754563565,
            "ave_precision_score": 0.702562883806556,
            "fpr": 0.1668496158068057,
            "logloss": 4.9231206170906,
            "mae": 0.3218529187073364,
            "precision": 0.703125,
            "recall": 0.7515657620041754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8147653155930432,
            "auditor_fn_violation": 0.011542012927054474,
            "auditor_fp_violation": 0.015654482315628892,
            "ave_precision_score": 0.7796471135862493,
            "fpr": 0.07456140350877193,
            "logloss": 4.105508457907198,
            "mae": 0.30144046955005577,
            "precision": 0.8176943699731903,
            "recall": 0.6421052631578947
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8184726073164643,
            "auditor_fn_violation": 0.012631511404338991,
            "auditor_fp_violation": 0.006921575801927066,
            "ave_precision_score": 0.7867777025670335,
            "fpr": 0.07244785949506037,
            "logloss": 4.258499791298588,
            "mae": 0.2993299003388749,
            "precision": 0.8206521739130435,
            "recall": 0.6304801670146137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7117334830850245,
            "auditor_fn_violation": 0.010427054478301022,
            "auditor_fp_violation": 0.026983218916857368,
            "ave_precision_score": 0.6454048008696072,
            "fpr": 0.14473684210526316,
            "logloss": 3.902304792327947,
            "mae": 0.432789819119008,
            "precision": 0.6641221374045801,
            "recall": 0.5494736842105263
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.712162229089957,
            "auditor_fn_violation": 0.02383074874704666,
            "auditor_fp_violation": 0.017761312355165267,
            "ave_precision_score": 0.6509981299756809,
            "fpr": 0.1251372118551043,
            "logloss": 3.6532147646539688,
            "mae": 0.4316912580988933,
            "precision": 0.680672268907563,
            "recall": 0.5073068893528184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.607726714269262,
            "auditor_fn_violation": 0.003647276084949239,
            "auditor_fp_violation": 0.0037913003332128957,
            "ave_precision_score": 0.605680252510513,
            "fpr": 0.009868421052631578,
            "logloss": 0.8665307722242708,
            "mae": 0.5000773084580253,
            "precision": 0.7428571428571429,
            "recall": 0.05473684210526316
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.594590909469652,
            "auditor_fn_violation": 0.004026408842057993,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.5924263560096081,
            "fpr": 0.006586169045005488,
            "logloss": 0.9867316498571997,
            "mae": 0.49877596935956825,
            "precision": 0.8181818181818182,
            "recall": 0.05636743215031315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7769675968876224,
            "auditor_fn_violation": 0.014866112650046167,
            "auditor_fp_violation": 0.02994650527921635,
            "ave_precision_score": 0.6890766343321537,
            "fpr": 0.17324561403508773,
            "logloss": 5.004920189088773,
            "mae": 0.3325106307353362,
            "precision": 0.6961538461538461,
            "recall": 0.7621052631578947
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7838419389214061,
            "auditor_fn_violation": 0.01906872394693482,
            "auditor_fp_violation": 0.021593080456966306,
            "ave_precision_score": 0.7018642199389513,
            "fpr": 0.16355653128430298,
            "logloss": 4.906683740814417,
            "mae": 0.32262150847479426,
            "precision": 0.7055335968379447,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7806335526545495,
            "auditor_fn_violation": 0.009175900277008316,
            "auditor_fp_violation": 0.021844514031073115,
            "ave_precision_score": 0.7023938236249213,
            "fpr": 0.14473684210526316,
            "logloss": 5.199972338753714,
            "mae": 0.31166430631323666,
            "precision": 0.7173447537473233,
            "recall": 0.7052631578947368
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8004566532731836,
            "auditor_fn_violation": 0.01697187472070657,
            "auditor_fp_violation": 0.019301134284668873,
            "ave_precision_score": 0.7266946676119235,
            "fpr": 0.12843029637760703,
            "logloss": 4.489031283677172,
            "mae": 0.2905207074133966,
            "precision": 0.7515923566878981,
            "recall": 0.7390396659707724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7829170915533796,
            "auditor_fn_violation": 0.011488919667590032,
            "auditor_fp_violation": 0.020722931470552812,
            "ave_precision_score": 0.6930794086999436,
            "fpr": 0.15679824561403508,
            "logloss": 4.914181418123357,
            "mae": 0.3965177523919888,
            "precision": 0.6924731182795699,
            "recall": 0.6778947368421052
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.786222731537982,
            "auditor_fn_violation": 0.020574330440521676,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7022776401044796,
            "fpr": 0.14818880351262348,
            "logloss": 4.6266033682756955,
            "mae": 0.3944907665383541,
            "precision": 0.7019867549668874,
            "recall": 0.6638830897703549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.49696110440953944,
            "auditor_fn_violation": 0.007910895660203143,
            "auditor_fp_violation": 0.0002935685896663879,
            "ave_precision_score": 0.528767861307488,
            "fpr": 0.03179824561403509,
            "logloss": 11.650813000557116,
            "mae": 0.5205715751441669,
            "precision": 0.6133333333333333,
            "recall": 0.0968421052631579
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5068803230785912,
            "auditor_fn_violation": 0.012510054563912664,
            "auditor_fp_violation": 0.003193987071594098,
            "ave_precision_score": 0.5457034717897276,
            "fpr": 0.02305159165751921,
            "logloss": 12.0050851972907,
            "mae": 0.5171351788374151,
            "precision": 0.7123287671232876,
            "recall": 0.10855949895615867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7735872582547221,
            "auditor_fn_violation": 0.008993536472760858,
            "auditor_fp_violation": 0.023480468906820828,
            "ave_precision_score": 0.683804408939031,
            "fpr": 0.15789473684210525,
            "logloss": 4.918967252013249,
            "mae": 0.3982784574884072,
            "precision": 0.6923076923076923,
            "recall": 0.6821052631578948
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7796360680689535,
            "auditor_fn_violation": 0.022524514802838885,
            "auditor_fp_violation": 0.025673862666178802,
            "ave_precision_score": 0.6956521607429247,
            "fpr": 0.14928649835345773,
            "logloss": 4.591402054338238,
            "mae": 0.39487134389636547,
            "precision": 0.701098901098901,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7757162001279974,
            "auditor_fn_violation": 0.009879963065558635,
            "auditor_fp_violation": 0.025041149785218198,
            "ave_precision_score": 0.7012371848563266,
            "fpr": 0.1524122807017544,
            "logloss": 4.199359511003559,
            "mae": 0.39002964468010665,
            "precision": 0.6971677559912854,
            "recall": 0.6736842105263158
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7749381715644104,
            "auditor_fn_violation": 0.02522635659270022,
            "auditor_fp_violation": 0.024743871203805348,
            "ave_precision_score": 0.7030420715826731,
            "fpr": 0.13830954994511527,
            "logloss": 4.058215945774276,
            "mae": 0.38413208625743395,
            "precision": 0.7116704805491991,
            "recall": 0.6492693110647182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8083977885684436,
            "auditor_fn_violation": 0.0027123730378578103,
            "auditor_fp_violation": 0.018258962623951182,
            "ave_precision_score": 0.7501501306852733,
            "fpr": 0.08662280701754387,
            "logloss": 3.6813604807922244,
            "mae": 0.35265527369448507,
            "precision": 0.7915567282321899,
            "recall": 0.631578947368421
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8165237416077804,
            "auditor_fn_violation": 0.015697723715479332,
            "auditor_fp_violation": 0.013446761800219538,
            "ave_precision_score": 0.7629632031380361,
            "fpr": 0.08232711306256861,
            "logloss": 3.297389462858991,
            "mae": 0.34851250501399117,
            "precision": 0.800531914893617,
            "recall": 0.6283924843423799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7748454854876721,
            "auditor_fn_violation": 0.019875346260387814,
            "auditor_fp_violation": 0.034794150708579226,
            "ave_precision_score": 0.6850913571775342,
            "fpr": 0.18201754385964913,
            "logloss": 5.236690619549183,
            "mae": 0.3358702009466135,
            "precision": 0.683206106870229,
            "recall": 0.7536842105263157
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7817265233267463,
            "auditor_fn_violation": 0.026947377105156416,
            "auditor_fp_violation": 0.03277838760824491,
            "ave_precision_score": 0.6977789334166719,
            "fpr": 0.1690450054884742,
            "logloss": 5.040369020331537,
            "mae": 0.32568848917426085,
            "precision": 0.7003891050583657,
            "recall": 0.7515657620041754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7952766611048993,
            "auditor_fn_violation": 0.0021121883656509697,
            "auditor_fp_violation": 0.012583303223734408,
            "ave_precision_score": 0.7073676749071999,
            "fpr": 0.39035087719298245,
            "logloss": 5.0651521171720715,
            "mae": 0.3728012566791467,
            "precision": 0.5669099756690997,
            "recall": 0.9810526315789474
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.8004605215779315,
            "auditor_fn_violation": 0.004076824889027406,
            "auditor_fp_violation": 0.009373602471846173,
            "ave_precision_score": 0.7178708346140743,
            "fpr": 0.3896816684961581,
            "logloss": 4.7911444457719,
            "mae": 0.37792476085659654,
            "precision": 0.5681265206812652,
            "recall": 0.9749478079331941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7227033105658951,
            "auditor_fn_violation": 0.008021698984302862,
            "auditor_fp_violation": 0.003731081135332618,
            "ave_precision_score": 0.6142876265119692,
            "fpr": 0.2982456140350877,
            "logloss": 8.459220814079542,
            "mae": 0.41422596107374876,
            "precision": 0.5891238670694864,
            "recall": 0.8210526315789474
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7291088161251553,
            "auditor_fn_violation": 0.014006494503505067,
            "auditor_fp_violation": 0.013975281538399,
            "ave_precision_score": 0.6190394221751812,
            "fpr": 0.300768386388584,
            "logloss": 8.271290202351148,
            "mae": 0.4020101675500894,
            "precision": 0.5922619047619048,
            "recall": 0.8308977035490606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7784465358799387,
            "auditor_fn_violation": 0.012280701754385972,
            "auditor_fp_violation": 0.020722931470552812,
            "ave_precision_score": 0.6885332096039176,
            "fpr": 0.15679824561403508,
            "logloss": 4.913900747430878,
            "mae": 0.39626344332569524,
            "precision": 0.6931330472103004,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7846833607359134,
            "auditor_fn_violation": 0.021914938962208596,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.700550728699219,
            "fpr": 0.14818880351262348,
            "logloss": 4.588345677886063,
            "mae": 0.3935565545124489,
            "precision": 0.7032967032967034,
            "recall": 0.6680584551148225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7804143260764181,
            "auditor_fn_violation": 0.00955678670360111,
            "auditor_fp_violation": 0.02183447749809306,
            "ave_precision_score": 0.7021745762741303,
            "fpr": 0.14583333333333334,
            "logloss": 5.209728311936393,
            "mae": 0.3094016307178655,
            "precision": 0.7164179104477612,
            "recall": 0.7073684210526315
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8007120223416945,
            "auditor_fn_violation": 0.016027719659279193,
            "auditor_fp_violation": 0.019301134284668873,
            "ave_precision_score": 0.7269497964119183,
            "fpr": 0.12843029637760703,
            "logloss": 4.500042044116661,
            "mae": 0.28726849714990343,
            "precision": 0.7510638297872341,
            "recall": 0.7369519832985386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7123311439006682,
            "auditor_fn_violation": 0.011542012927054479,
            "auditor_fp_violation": 0.02713125777831307,
            "ave_precision_score": 0.6456988137953594,
            "fpr": 0.14364035087719298,
            "logloss": 3.896435139522696,
            "mae": 0.4323165735001104,
            "precision": 0.6666666666666666,
            "recall": 0.5515789473684211
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7142672589334664,
            "auditor_fn_violation": 0.02383074874704666,
            "auditor_fp_violation": 0.017761312355165267,
            "ave_precision_score": 0.6538880113226085,
            "fpr": 0.1251372118551043,
            "logloss": 3.610108816023914,
            "mae": 0.43130280412774447,
            "precision": 0.680672268907563,
            "recall": 0.5073068893528184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4199561403508772,
            "auc_prc": 0.6483940310064419,
            "auditor_fn_violation": 0.012970914127423822,
            "auditor_fp_violation": 0.01790015656991449,
            "ave_precision_score": 0.632768671130064,
            "fpr": 0.3815789473684211,
            "logloss": 9.455348527200885,
            "mae": 0.5676880257475695,
            "precision": 0.45794392523364486,
            "recall": 0.6189473684210526
        },
        "train": {
            "accuracy": 0.4445664105378705,
            "auc_prc": 0.6708351926429077,
            "auditor_fn_violation": 0.016277508255627685,
            "auditor_fp_violation": 0.014102329552384453,
            "ave_precision_score": 0.6508367747539738,
            "fpr": 0.37980241492864986,
            "logloss": 8.621864007310759,
            "mae": 0.5487409275716435,
            "precision": 0.47969924812030074,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7821067446338941,
            "auditor_fn_violation": 0.012280701754385972,
            "auditor_fp_violation": 0.020722931470552812,
            "ave_precision_score": 0.6922239759635064,
            "fpr": 0.15679824561403508,
            "logloss": 4.916503799176832,
            "mae": 0.3974157957719606,
            "precision": 0.6931330472103004,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.786378452761014,
            "auditor_fn_violation": 0.02142681996200464,
            "auditor_fp_violation": 0.025673862666178802,
            "ave_precision_score": 0.7023105781057253,
            "fpr": 0.14928649835345773,
            "logloss": 4.5906492480953816,
            "mae": 0.39418912529291095,
            "precision": 0.701098901098901,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7831353691567817,
            "auditor_fn_violation": 0.009032779316712836,
            "auditor_fp_violation": 0.021440543578626205,
            "ave_precision_score": 0.6953275295830041,
            "fpr": 0.15021929824561403,
            "logloss": 4.83423931603992,
            "mae": 0.3898534304771282,
            "precision": 0.7015250544662309,
            "recall": 0.6778947368421052
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7859467396203763,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7041008910828294,
            "fpr": 0.1437980241492865,
            "logloss": 4.550998162879784,
            "mae": 0.38974197354458034,
            "precision": 0.7075892857142857,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6073967564277294,
            "auditor_fn_violation": 0.0020083102493074862,
            "auditor_fp_violation": 0.0028052109679232405,
            "ave_precision_score": 0.6055580281721464,
            "fpr": 0.008771929824561403,
            "logloss": 0.8694899874576507,
            "mae": 0.5003984106549054,
            "precision": 0.7241379310344828,
            "recall": 0.04421052631578947
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5930324258074028,
            "auditor_fn_violation": 0.0012901924747175074,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.5908923308740565,
            "fpr": 0.006586169045005488,
            "logloss": 0.9896410958768944,
            "mae": 0.49922217138871905,
            "precision": 0.8125,
            "recall": 0.054279749478079335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 27690,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7858384769129569,
            "auditor_fn_violation": 0.010999538319482919,
            "auditor_fp_violation": 0.0225420530731864,
            "ave_precision_score": 0.699703301595469,
            "fpr": 0.14912280701754385,
            "logloss": 4.7398226175555696,
            "mae": 0.3882457938746308,
            "precision": 0.7017543859649122,
            "recall": 0.6736842105263158
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7878376924830903,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7071287369153413,
            "fpr": 0.1437980241492865,
            "logloss": 4.4883621809789025,
            "mae": 0.38884160087804764,
            "precision": 0.7075892857142857,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7837820573680303,
            "auditor_fn_violation": 0.012280701754385972,
            "auditor_fp_violation": 0.020722931470552812,
            "ave_precision_score": 0.6939926914279468,
            "fpr": 0.15679824561403508,
            "logloss": 4.915289518699152,
            "mae": 0.3969964901998378,
            "precision": 0.6931330472103004,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7879051862546185,
            "auditor_fn_violation": 0.021914938962208596,
            "auditor_fp_violation": 0.025673862666178802,
            "ave_precision_score": 0.703937050788588,
            "fpr": 0.14928649835345773,
            "logloss": 4.589975521082309,
            "mae": 0.3939583254109099,
            "precision": 0.7017543859649122,
            "recall": 0.6680584551148225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7867444251652018,
            "auditor_fn_violation": 0.011759002770083104,
            "auditor_fp_violation": 0.021591091573326913,
            "ave_precision_score": 0.6990597002541608,
            "fpr": 0.14912280701754385,
            "logloss": 4.8304575194263295,
            "mae": 0.3883701666604075,
            "precision": 0.7024070021881839,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.787947729242358,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7062043105769991,
            "fpr": 0.1437980241492865,
            "logloss": 4.546639056130505,
            "mae": 0.3883164856586969,
            "precision": 0.7075892857142857,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7858334767053927,
            "auditor_fn_violation": 0.011759002770083104,
            "auditor_fp_violation": 0.021591091573326913,
            "ave_precision_score": 0.6981703629055579,
            "fpr": 0.14912280701754385,
            "logloss": 4.826733330577146,
            "mae": 0.38713856696467064,
            "precision": 0.7024070021881839,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7877722583686408,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.025285095743383338,
            "ave_precision_score": 0.706054224789538,
            "fpr": 0.141602634467618,
            "logloss": 4.5459096443947145,
            "mae": 0.38744299709142627,
            "precision": 0.7107623318385651,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7714288246594536,
            "auditor_fn_violation": 0.010526315789473693,
            "auditor_fp_violation": 0.023480468906820828,
            "ave_precision_score": 0.6816188336433056,
            "fpr": 0.15789473684210525,
            "logloss": 4.922193162452501,
            "mae": 0.39937207622355536,
            "precision": 0.6923076923076923,
            "recall": 0.6821052631578948
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7768787047741875,
            "auditor_fn_violation": 0.022524514802838885,
            "auditor_fp_violation": 0.02611598975484816,
            "ave_precision_score": 0.6929432023127049,
            "fpr": 0.150384193194292,
            "logloss": 4.594755082278769,
            "mae": 0.3957014380904113,
            "precision": 0.6995614035087719,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7596368419342038,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016786101409129177,
            "ave_precision_score": 0.6952049816918398,
            "fpr": 0.4758771929824561,
            "logloss": 4.8924188473353185,
            "mae": 0.4667534693225957,
            "precision": 0.5225522552255225,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7549744683187708,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6970224932813827,
            "fpr": 0.47420417124039516,
            "logloss": 4.643631976590982,
            "mae": 0.46427352152331336,
            "precision": 0.5257958287596048,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7783483380120357,
            "auditor_fn_violation": 0.012504616805170822,
            "auditor_fp_violation": 0.009695290858725756,
            "ave_precision_score": 0.6916347776963379,
            "fpr": 0.3607456140350877,
            "logloss": 5.552360204896536,
            "mae": 0.3829177866079817,
            "precision": 0.574385510996119,
            "recall": 0.9347368421052632
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7867947486692087,
            "auditor_fn_violation": 0.010649244103041234,
            "auditor_fp_violation": 0.002927186242224676,
            "ave_precision_score": 0.7053916288113288,
            "fpr": 0.36882546652030734,
            "logloss": 5.297147754487443,
            "mae": 0.38382293348707325,
            "precision": 0.5703324808184144,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7769866331659687,
            "auditor_fn_violation": 0.015258541089566022,
            "auditor_fp_violation": 0.028654301658035255,
            "ave_precision_score": 0.6884733598852772,
            "fpr": 0.17434210526315788,
            "logloss": 5.059159056073716,
            "mae": 0.33248361257267395,
            "precision": 0.6954022988505747,
            "recall": 0.7642105263157895
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.784578655400406,
            "auditor_fn_violation": 0.019925796745415007,
            "auditor_fp_violation": 0.022106354433467496,
            "ave_precision_score": 0.7012643838998389,
            "fpr": 0.16465422612513722,
            "logloss": 4.94460500616773,
            "mae": 0.32132577716858857,
            "precision": 0.7053045186640472,
            "recall": 0.7494780793319415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7951949294718933,
            "auditor_fn_violation": 0.0035549399815327795,
            "auditor_fp_violation": 0.012789052149825371,
            "ave_precision_score": 0.7071157402882143,
            "fpr": 0.3618421052631579,
            "logloss": 5.082265130761287,
            "mae": 0.3580309114897554,
            "precision": 0.5822784810126582,
            "recall": 0.968421052631579
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.8005352087798948,
            "auditor_fn_violation": 0.006180549030751498,
            "auditor_fp_violation": 0.01487732243769566,
            "ave_precision_score": 0.7183442852930795,
            "fpr": 0.3611416026344676,
            "logloss": 4.739348782366118,
            "mae": 0.35999994151582626,
            "precision": 0.5830164765525983,
            "recall": 0.9603340292275574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7855219861721996,
            "auditor_fn_violation": 0.012719298245614038,
            "auditor_fp_violation": 0.021618692039022037,
            "ave_precision_score": 0.6988788373761406,
            "fpr": 0.3168859649122807,
            "logloss": 5.33626601909759,
            "mae": 0.3536562681470196,
            "precision": 0.6035665294924554,
            "recall": 0.9263157894736842
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7931760857639033,
            "auditor_fn_violation": 0.010649244103041234,
            "auditor_fp_violation": 0.017014270032930854,
            "ave_precision_score": 0.7117689958366726,
            "fpr": 0.3062568605927552,
            "logloss": 5.034529284358613,
            "mae": 0.349987103460706,
            "precision": 0.6151724137931035,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7588386529615775,
            "auditor_fn_violation": 0.005394736842105288,
            "auditor_fp_violation": 0.0045791681721466145,
            "ave_precision_score": 0.7436474638014245,
            "fpr": 0.03837719298245614,
            "logloss": 6.21133825221199,
            "mae": 0.3584815670203296,
            "precision": 0.8565573770491803,
            "recall": 0.44
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7490597590078335,
            "auditor_fn_violation": 0.0008479062444857453,
            "auditor_fp_violation": 0.00028966947188681553,
            "ave_precision_score": 0.7355148152615331,
            "fpr": 0.036223929747530186,
            "logloss": 6.756984624625244,
            "mae": 0.36554239525838333,
            "precision": 0.8589743589743589,
            "recall": 0.4196242171189979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7767476694519257,
            "auditor_fn_violation": 0.009824561403508772,
            "auditor_fp_violation": 0.01111295114215745,
            "ave_precision_score": 0.6900362508863903,
            "fpr": 0.3300438596491228,
            "logloss": 5.493969459380114,
            "mae": 0.37503763197663237,
            "precision": 0.592140921409214,
            "recall": 0.92
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.785286705698619,
            "auditor_fn_violation": 0.009475925191752853,
            "auditor_fp_violation": 0.01677033784607881,
            "ave_precision_score": 0.7038893810134208,
            "fpr": 0.32930845225027444,
            "logloss": 5.236847666949157,
            "mae": 0.3730775074104843,
            "precision": 0.5956873315363881,
            "recall": 0.9227557411273486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7947573028529505,
            "auditor_fn_violation": 0.008201754385964913,
            "auditor_fp_violation": 0.010207154040708183,
            "ave_precision_score": 0.7066783185444183,
            "fpr": 0.3574561403508772,
            "logloss": 5.0835394457937015,
            "mae": 0.35703123976736906,
            "precision": 0.5831202046035806,
            "recall": 0.96
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.8000801865540113,
            "auditor_fn_violation": 0.006556377744523558,
            "auditor_fp_violation": 0.019880473228442504,
            "ave_precision_score": 0.7178894981716128,
            "fpr": 0.3512623490669594,
            "logloss": 4.73105812457554,
            "mae": 0.35709591095208487,
            "precision": 0.5902688860435339,
            "recall": 0.9624217118997912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7881888836673031,
            "auditor_fn_violation": 0.010951061865189292,
            "auditor_fp_violation": 0.005858826127102664,
            "ave_precision_score": 0.7164503500407347,
            "fpr": 0.3267543859649123,
            "logloss": 5.067257697175153,
            "mae": 0.3644678662808021,
            "precision": 0.5900962861072903,
            "recall": 0.9031578947368422
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.8030653186300357,
            "auditor_fn_violation": 0.00884572460463507,
            "auditor_fp_violation": 0.005780684636337764,
            "ave_precision_score": 0.7373072831593812,
            "fpr": 0.33699231613611413,
            "logloss": 4.661604077108427,
            "mae": 0.3618798205469669,
            "precision": 0.5873655913978495,
            "recall": 0.9123173277661796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5672078066660518,
            "auditor_fn_violation": 0.07916204986149585,
            "auditor_fp_violation": 0.10277409771568509,
            "ave_precision_score": 0.5566962867472054,
            "fpr": 0.2807017543859649,
            "logloss": 0.6869598901087876,
            "mae": 0.49629110025993567,
            "precision": 0.5754560530679934,
            "recall": 0.7305263157894737
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5443637764757681,
            "auditor_fn_violation": 0.0980821277405132,
            "auditor_fp_violation": 0.1005839126722771,
            "ave_precision_score": 0.5372020528405713,
            "fpr": 0.2996706915477497,
            "logloss": 0.6908302074398077,
            "mae": 0.4982407821912797,
            "precision": 0.545,
            "recall": 0.6826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.567182138183771,
            "auditor_fn_violation": 0.07949445983379502,
            "auditor_fp_violation": 0.10317555903488698,
            "ave_precision_score": 0.5566706237235939,
            "fpr": 0.2817982456140351,
            "logloss": 0.687340515144651,
            "mae": 0.4965433751216583,
            "precision": 0.5752066115702479,
            "recall": 0.7326315789473684
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5443637764757681,
            "auditor_fn_violation": 0.0980821277405132,
            "auditor_fp_violation": 0.1009523519128349,
            "ave_precision_score": 0.5372020528405713,
            "fpr": 0.300768386388584,
            "logloss": 0.6910239040782087,
            "mae": 0.4983998176884049,
            "precision": 0.5440931780366056,
            "recall": 0.6826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.4713697783214896,
            "auditor_fn_violation": 0.004963065558633431,
            "auditor_fp_violation": 0.012164277971817416,
            "ave_precision_score": 0.5195007838273824,
            "fpr": 0.049342105263157895,
            "logloss": 12.264908194018531,
            "mae": 0.5507855894074166,
            "precision": 0.5833333333333334,
            "recall": 0.13263157894736843
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.46506065760458326,
            "auditor_fn_violation": 0.01718270546257869,
            "auditor_fp_violation": 0.011134487945684434,
            "ave_precision_score": 0.5189971811906697,
            "fpr": 0.050493962678375415,
            "logloss": 12.590898562567979,
            "mae": 0.5542639954757809,
            "precision": 0.5818181818181818,
            "recall": 0.1336116910229645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7597493766579109,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016786101409129177,
            "ave_precision_score": 0.6953158605996884,
            "fpr": 0.4758771929824561,
            "logloss": 4.9007912508951055,
            "mae": 0.46709715150165976,
            "precision": 0.5225522552255225,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7550448202631934,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6970928690316716,
            "fpr": 0.47420417124039516,
            "logloss": 4.650787743870181,
            "mae": 0.4644242490424021,
            "precision": 0.5257958287596048,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4199561403508772,
            "auc_prc": 0.6479754008039483,
            "auditor_fn_violation": 0.012970914127423822,
            "auditor_fp_violation": 0.01790015656991449,
            "ave_precision_score": 0.6324070310566196,
            "fpr": 0.3815789473684211,
            "logloss": 9.455824436654307,
            "mae": 0.5676014978973769,
            "precision": 0.45794392523364486,
            "recall": 0.6189473684210526
        },
        "train": {
            "accuracy": 0.4445664105378705,
            "auc_prc": 0.6702714859241123,
            "auditor_fn_violation": 0.016277508255627685,
            "auditor_fp_violation": 0.014102329552384453,
            "ave_precision_score": 0.6503186199461943,
            "fpr": 0.37980241492864986,
            "logloss": 8.623008745875275,
            "mae": 0.5487400860415645,
            "precision": 0.47969924812030074,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 27690,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7769710638055103,
            "auditor_fn_violation": 0.009753000923361045,
            "auditor_fp_violation": 0.028062146212212462,
            "ave_precision_score": 0.6884578119321018,
            "fpr": 0.17543859649122806,
            "logloss": 5.049317965469607,
            "mae": 0.33287452639823895,
            "precision": 0.689922480620155,
            "recall": 0.7494736842105263
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7849101360694214,
            "auditor_fn_violation": 0.012638386319834828,
            "auditor_fp_violation": 0.020269240151237964,
            "ave_precision_score": 0.7015957158155699,
            "fpr": 0.15916575192096596,
            "logloss": 4.943922374388422,
            "mae": 0.3214084536604895,
            "precision": 0.7111553784860558,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.5644220756105665,
            "auditor_fn_violation": 0.08020083102493075,
            "auditor_fp_violation": 0.10550152555301297,
            "ave_precision_score": 0.559330355972817,
            "fpr": 0.2916666666666667,
            "logloss": 0.6824907387771899,
            "mae": 0.49260447043598743,
            "precision": 0.5777777777777777,
            "recall": 0.7663157894736842
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.5377145138011183,
            "auditor_fn_violation": 0.09784838061365496,
            "auditor_fp_violation": 0.10133603691507097,
            "ave_precision_score": 0.535883994454394,
            "fpr": 0.3084522502744237,
            "logloss": 0.6894752678612587,
            "mae": 0.49609581283758813,
            "precision": 0.5496794871794872,
            "recall": 0.7160751565762005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5677616472735599,
            "auditor_fn_violation": 0.0727954755309326,
            "auditor_fp_violation": 0.10105283230960697,
            "ave_precision_score": 0.5572508351344023,
            "fpr": 0.27850877192982454,
            "logloss": 0.6864852199656288,
            "mae": 0.4959339933763993,
            "precision": 0.5759599332220368,
            "recall": 0.7263157894736842
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5444753001415727,
            "auditor_fn_violation": 0.0980821277405132,
            "auditor_fp_violation": 0.0980124608692117,
            "ave_precision_score": 0.5373136215526642,
            "fpr": 0.29527991218441274,
            "logloss": 0.690776821872686,
            "mae": 0.4980953744358079,
            "precision": 0.5486577181208053,
            "recall": 0.6826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7748433850935965,
            "auditor_fn_violation": 0.019875346260387814,
            "auditor_fp_violation": 0.034794150708579226,
            "ave_precision_score": 0.6850892574714931,
            "fpr": 0.18201754385964913,
            "logloss": 5.236647113500253,
            "mae": 0.33587006166750616,
            "precision": 0.683206106870229,
            "recall": 0.7536842105263157
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7817265233267463,
            "auditor_fn_violation": 0.026947377105156416,
            "auditor_fp_violation": 0.03277838760824491,
            "ave_precision_score": 0.6977789334166719,
            "fpr": 0.1690450054884742,
            "logloss": 5.040325304683939,
            "mae": 0.325689757852317,
            "precision": 0.7003891050583657,
            "recall": 0.7515657620041754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7780874826555292,
            "auditor_fn_violation": 0.01436749769159742,
            "auditor_fp_violation": 0.025041149785218198,
            "ave_precision_score": 0.7036077836500019,
            "fpr": 0.1524122807017544,
            "logloss": 4.222919400942059,
            "mae": 0.3867365078091902,
            "precision": 0.6997840172786177,
            "recall": 0.6821052631578948
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7742751539863066,
            "auditor_fn_violation": 0.022632221812273565,
            "auditor_fp_violation": 0.025246981339187707,
            "ave_precision_score": 0.7017920104356301,
            "fpr": 0.13830954994511527,
            "logloss": 4.0879570062408765,
            "mae": 0.3834021790425744,
            "precision": 0.7212389380530974,
            "recall": 0.6805845511482255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7854859713989647,
            "auditor_fn_violation": 0.011759002770083104,
            "auditor_fp_violation": 0.021591091573326913,
            "ave_precision_score": 0.6987069960462673,
            "fpr": 0.14912280701754385,
            "logloss": 4.778872807755186,
            "mae": 0.3881920482335294,
            "precision": 0.7024070021881839,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.787023284864751,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.02368174980688702,
            "ave_precision_score": 0.706219631278836,
            "fpr": 0.14270032930845225,
            "logloss": 4.490758462151146,
            "mae": 0.3878961249809757,
            "precision": 0.70917225950783,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7594940253813658,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005495001806575918,
            "ave_precision_score": 0.6950613136078674,
            "fpr": 0.4780701754385965,
            "logloss": 4.936674553386009,
            "mae": 0.46891511378711775,
            "precision": 0.5214050493962679,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7551371965367575,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6971829718529468,
            "fpr": 0.47420417124039516,
            "logloss": 4.674442878722695,
            "mae": 0.46503655885629414,
            "precision": 0.5257958287596048,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5675175743188177,
            "auditor_fn_violation": 0.0727954755309326,
            "auditor_fp_violation": 0.10105283230960697,
            "ave_precision_score": 0.5570065717232011,
            "fpr": 0.27850877192982454,
            "logloss": 0.686758079106941,
            "mae": 0.49614813090547133,
            "precision": 0.5759599332220368,
            "recall": 0.7263157894736842
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5442857385379458,
            "auditor_fn_violation": 0.0980821277405132,
            "auditor_fp_violation": 0.0980124608692117,
            "ave_precision_score": 0.5371241351949352,
            "fpr": 0.29527991218441274,
            "logloss": 0.6906855419741824,
            "mae": 0.49812637130463033,
            "precision": 0.5486577181208053,
            "recall": 0.6826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7775080381467216,
            "auditor_fn_violation": 0.011865189289012004,
            "auditor_fp_violation": 0.011396483198843803,
            "ave_precision_score": 0.6907948955478213,
            "fpr": 0.3684210526315789,
            "logloss": 5.598503481602758,
            "mae": 0.38815392174343405,
            "precision": 0.5697823303457106,
            "recall": 0.9368421052631579
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7860487463864689,
            "auditor_fn_violation": 0.007812195641761905,
            "auditor_fp_violation": 0.005346180428507541,
            "ave_precision_score": 0.7046491302039658,
            "fpr": 0.3743139407244786,
            "logloss": 5.339591086838336,
            "mae": 0.38987710068602627,
            "precision": 0.5667090216010165,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7852115896310989,
            "auditor_fn_violation": 0.010000000000000005,
            "auditor_fp_violation": 0.0214831988437914,
            "ave_precision_score": 0.6976685411760832,
            "fpr": 0.14692982456140352,
            "logloss": 4.825880803308574,
            "mae": 0.38666464395440636,
            "precision": 0.7041942604856513,
            "recall": 0.671578947368421
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7872702390655089,
            "auditor_fn_violation": 0.018695186871661364,
            "auditor_fp_violation": 0.024123876895556368,
            "ave_precision_score": 0.7056216891907573,
            "fpr": 0.13721185510428102,
            "logloss": 4.5441473737813505,
            "mae": 0.3870450401541692,
            "precision": 0.7165532879818595,
            "recall": 0.6597077244258872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5951912843699172,
            "auditor_fn_violation": 0.003795013850415532,
            "auditor_fp_violation": 0.0037913003332128957,
            "ave_precision_score": 0.5933824136982536,
            "fpr": 0.009868421052631578,
            "logloss": 0.8652950825339384,
            "mae": 0.5001032653923406,
            "precision": 0.75,
            "recall": 0.056842105263157895
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5858739638163685,
            "auditor_fn_violation": 0.004026408842057993,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.5824367030498974,
            "fpr": 0.006586169045005488,
            "logloss": 0.9854033787126995,
            "mae": 0.49878380081844803,
            "precision": 0.8181818181818182,
            "recall": 0.05636743215031315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7774311975051109,
            "auditor_fn_violation": 0.011202677746999077,
            "auditor_fp_violation": 0.011815508450760787,
            "ave_precision_score": 0.6900843433548315,
            "fpr": 0.37390350877192985,
            "logloss": 5.650683842243696,
            "mae": 0.391523480785964,
            "precision": 0.5667090216010165,
            "recall": 0.9389473684210526
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7882674656725388,
            "auditor_fn_violation": 0.008002401637146543,
            "auditor_fp_violation": 0.006936821563605325,
            "ave_precision_score": 0.7066353258226558,
            "fpr": 0.3787047200878156,
            "logloss": 5.320885868620399,
            "mae": 0.39223339194220813,
            "precision": 0.5654911838790933,
            "recall": 0.9373695198329853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8187453665497132,
            "auditor_fn_violation": 0.0027123730378578103,
            "auditor_fp_violation": 0.017021959934160346,
            "ave_precision_score": 0.7596303011692978,
            "fpr": 0.08881578947368421,
            "logloss": 3.7565209468036316,
            "mae": 0.3567280198544668,
            "precision": 0.7874015748031497,
            "recall": 0.631578947368421
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8287943951680355,
            "auditor_fn_violation": 0.015697723715479332,
            "auditor_fp_violation": 0.014290360613082899,
            "ave_precision_score": 0.77559695846065,
            "fpr": 0.08342480790340286,
            "logloss": 3.2930344911206317,
            "mae": 0.35194299682936137,
            "precision": 0.7984084880636605,
            "recall": 0.6283924843423799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7189734038531881,
            "auditor_fn_violation": 0.007652354570637122,
            "auditor_fp_violation": 0.0034450399454012577,
            "ave_precision_score": 0.5937611391611417,
            "fpr": 0.31469298245614036,
            "logloss": 9.219016036013075,
            "mae": 0.4172017545969345,
            "precision": 0.5804093567251462,
            "recall": 0.8357894736842105
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7242692033873127,
            "auditor_fn_violation": 0.007981776890659055,
            "auditor_fp_violation": 0.013538236370289069,
            "ave_precision_score": 0.6005131705838895,
            "fpr": 0.3194291986827662,
            "logloss": 9.02762975608125,
            "mae": 0.416096787591878,
            "precision": 0.5788712011577424,
            "recall": 0.8350730688935282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7770678380299456,
            "auditor_fn_violation": 0.017728531855955684,
            "auditor_fp_violation": 0.03150718615761373,
            "ave_precision_score": 0.688554524280939,
            "fpr": 0.17543859649122806,
            "logloss": 5.056262589572573,
            "mae": 0.3330126073781413,
            "precision": 0.6952380952380952,
            "recall": 0.7684210526315789
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7853087302081712,
            "auditor_fn_violation": 0.02062703812598971,
            "auditor_fp_violation": 0.02203520754563565,
            "ave_precision_score": 0.7025433925668739,
            "fpr": 0.1668496158068057,
            "logloss": 4.923123706073019,
            "mae": 0.32185701123165644,
            "precision": 0.703125,
            "recall": 0.7515657620041754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7781904045654648,
            "auditor_fn_violation": 0.012504616805170822,
            "auditor_fp_violation": 0.009195973342968419,
            "ave_precision_score": 0.6914769128534031,
            "fpr": 0.36403508771929827,
            "logloss": 5.563640297131239,
            "mae": 0.38473982124129547,
            "precision": 0.5721649484536082,
            "recall": 0.9347368421052632
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7866079921790693,
            "auditor_fn_violation": 0.009414050952290377,
            "auditor_fp_violation": 0.00374029353173152,
            "ave_precision_score": 0.7052049648853476,
            "fpr": 0.3732162458836443,
            "logloss": 5.30929649058246,
            "mae": 0.38592311495413206,
            "precision": 0.567979669631512,
            "recall": 0.9331941544885177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7870952838616174,
            "auditor_fn_violation": 0.010000000000000005,
            "auditor_fp_violation": 0.025929382953952383,
            "ave_precision_score": 0.7000589715811835,
            "fpr": 0.14364035087719298,
            "logloss": 4.805198632064026,
            "mae": 0.3860931961384459,
            "precision": 0.7088888888888889,
            "recall": 0.671578947368421
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7884439875939486,
            "auditor_fn_violation": 0.017780823110715938,
            "auditor_fp_violation": 0.023295523844371273,
            "ave_precision_score": 0.7073616309533809,
            "fpr": 0.13391877058177826,
            "logloss": 4.523760846279347,
            "mae": 0.386607212551208,
            "precision": 0.7208237986270023,
            "recall": 0.6576200417536534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.785727367488498,
            "auditor_fn_violation": 0.009032779316712836,
            "auditor_fp_violation": 0.021440543578626205,
            "ave_precision_score": 0.697805255077471,
            "fpr": 0.15021929824561403,
            "logloss": 4.82954167556798,
            "mae": 0.38799873615215275,
            "precision": 0.7015250544662309,
            "recall": 0.6778947368421052
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7867888970576579,
            "auditor_fn_violation": 0.018136027078000497,
            "auditor_fp_violation": 0.024492316136114165,
            "ave_precision_score": 0.7048486359872825,
            "fpr": 0.1437980241492865,
            "logloss": 4.548213659805297,
            "mae": 0.3880023238720407,
            "precision": 0.7075892857142857,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7854576499706828,
            "auditor_fn_violation": 0.016059556786703604,
            "auditor_fp_violation": 0.020657694006182514,
            "ave_precision_score": 0.6988145450346838,
            "fpr": 0.31359649122807015,
            "logloss": 5.324947889293781,
            "mae": 0.35291687922118486,
            "precision": 0.6055172413793104,
            "recall": 0.9242105263157895
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7931181824790056,
            "auditor_fn_violation": 0.010649244103041234,
            "auditor_fp_violation": 0.013863479286091796,
            "ave_precision_score": 0.7117111339738403,
            "fpr": 0.3040614709110867,
            "logloss": 5.027303310488302,
            "mae": 0.34877117271154223,
            "precision": 0.6168741355463347,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7944354481351357,
            "auditor_fn_violation": 0.003404893813481073,
            "auditor_fp_violation": 0.008819603356216624,
            "ave_precision_score": 0.7245143353476471,
            "fpr": 0.3125,
            "logloss": 4.91074106477364,
            "mae": 0.354546722337715,
            "precision": 0.5985915492957746,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8069401805152264,
            "auditor_fn_violation": 0.010463621384653813,
            "auditor_fp_violation": 0.009261800219538971,
            "ave_precision_score": 0.7418093504922115,
            "fpr": 0.31284302963776073,
            "logloss": 4.5825771387204615,
            "mae": 0.3536559638436705,
            "precision": 0.6036161335187761,
            "recall": 0.906054279749478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7852228351893804,
            "auditor_fn_violation": 0.016608956602031395,
            "auditor_fp_violation": 0.015207856598016793,
            "ave_precision_score": 0.6985798016614543,
            "fpr": 0.3125,
            "logloss": 5.3409552252117285,
            "mae": 0.3525533267823499,
            "precision": 0.6058091286307054,
            "recall": 0.9221052631578948
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7929142255855673,
            "auditor_fn_violation": 0.010649244103041234,
            "auditor_fp_violation": 0.014823962271821782,
            "ave_precision_score": 0.7115072626152252,
            "fpr": 0.305159165751921,
            "logloss": 5.040790221255107,
            "mae": 0.3487362104584166,
            "precision": 0.6160220994475138,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7766920607022864,
            "auditor_fn_violation": 0.012211449676823638,
            "auditor_fp_violation": 0.011253462603878118,
            "ave_precision_score": 0.6899806681348337,
            "fpr": 0.32785087719298245,
            "logloss": 5.489726135437535,
            "mae": 0.37414817211474066,
            "precision": 0.5926430517711172,
            "recall": 0.9157894736842105
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7852152521877445,
            "auditor_fn_violation": 0.008394271820408876,
            "auditor_fp_violation": 0.013279058421758775,
            "ave_precision_score": 0.7038179677479893,
            "fpr": 0.32711306256860595,
            "logloss": 5.232292842069908,
            "mae": 0.3720322873928257,
            "precision": 0.5962059620596206,
            "recall": 0.918580375782881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7740679679731578,
            "auditor_fn_violation": 0.024609879963065562,
            "auditor_fp_violation": 0.03287717290939018,
            "ave_precision_score": 0.6843140514785484,
            "fpr": 0.18092105263157895,
            "logloss": 5.239884924589211,
            "mae": 0.33748775081007015,
            "precision": 0.6875,
            "recall": 0.7642105263157895
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7816266046321575,
            "auditor_fn_violation": 0.02566176790743614,
            "auditor_fp_violation": 0.028357116721551414,
            "ave_precision_score": 0.697679058470298,
            "fpr": 0.1712403951701427,
            "logloss": 5.034634520603115,
            "mae": 0.3257886659522073,
            "precision": 0.6994219653179191,
            "recall": 0.7578288100208769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7762222467305077,
            "auditor_fn_violation": 0.01375577100646353,
            "auditor_fp_violation": 0.022266048416235106,
            "ave_precision_score": 0.6866461813561087,
            "fpr": 0.17982456140350878,
            "logloss": 5.180083229849057,
            "mae": 0.3298233626626314,
            "precision": 0.685823754789272,
            "recall": 0.7536842105263157
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7835832554025762,
            "auditor_fn_violation": 0.022925551540095655,
            "auditor_fp_violation": 0.025018294914013906,
            "ave_precision_score": 0.6997227794917448,
            "fpr": 0.16465422612513722,
            "logloss": 4.992241598537476,
            "mae": 0.3201503467887893,
            "precision": 0.7093023255813954,
            "recall": 0.7640918580375783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.47241329470552534,
            "auditor_fn_violation": 0.07419436749769161,
            "auditor_fp_violation": 0.099785720020876,
            "ave_precision_score": 0.47246547920816506,
            "fpr": 0.2850877192982456,
            "logloss": 0.6947229676444666,
            "mae": 0.4994661253795289,
            "precision": 0.5524956970740104,
            "recall": 0.6757894736842105
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.45309937823221447,
            "auditor_fn_violation": 0.0849945802749508,
            "auditor_fp_violation": 0.09948621783144287,
            "ave_precision_score": 0.45884771739597185,
            "fpr": 0.2996706915477497,
            "logloss": 0.6984204554717438,
            "mae": 0.5012930620514863,
            "precision": 0.521891418563923,
            "recall": 0.6221294363256785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 27690,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.6061334180281231,
            "auditor_fn_violation": 0.0025392428439520026,
            "auditor_fp_violation": 0.0037913003332128957,
            "ave_precision_score": 0.6042721202578532,
            "fpr": 0.009868421052631578,
            "logloss": 0.8674658244549203,
            "mae": 0.5001908539457318,
            "precision": 0.71875,
            "recall": 0.04842105263157895
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5917077355486577,
            "auditor_fn_violation": 0.0012901924747175074,
            "auditor_fp_violation": 0.002866203195511648,
            "ave_precision_score": 0.5896618159443974,
            "fpr": 0.006586169045005488,
            "logloss": 0.9877306264508096,
            "mae": 0.4989586313437524,
            "precision": 0.8125,
            "recall": 0.054279749478079335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.4960989278752436,
            "auditor_fn_violation": 0.08020083102493075,
            "auditor_fp_violation": 0.10550152555301297,
            "ave_precision_score": 0.5601042884990254,
            "fpr": 0.2916666666666667,
            "logloss": 0.6824740975750931,
            "mae": 0.49257062172941996,
            "precision": 0.5777777777777777,
            "recall": 0.7663157894736842
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.47336703209863057,
            "auditor_fn_violation": 0.09784838061365496,
            "auditor_fp_violation": 0.10133603691507097,
            "ave_precision_score": 0.5394485869744143,
            "fpr": 0.3084522502744237,
            "logloss": 0.6894543659025294,
            "mae": 0.4960620924094375,
            "precision": 0.5496794871794872,
            "recall": 0.7160751565762005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7533480050204581,
            "auditor_fn_violation": 0.0011218836565096953,
            "auditor_fp_violation": 0.0005495001806575918,
            "ave_precision_score": 0.6889166420519175,
            "fpr": 0.4780701754385965,
            "logloss": 5.352951370332367,
            "mae": 0.47147575280580084,
            "precision": 0.5203520352035204,
            "recall": 0.9957894736842106
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.749090037398449,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0014839208033500086,
            "ave_precision_score": 0.6900264614687458,
            "fpr": 0.47200878155872666,
            "logloss": 5.072920020718883,
            "mae": 0.4630355451227412,
            "precision": 0.5269526952695269,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7785353962410548,
            "auditor_fn_violation": 0.016719759926131117,
            "auditor_fp_violation": 0.026122586213818303,
            "ave_precision_score": 0.691084533006666,
            "fpr": 0.20723684210526316,
            "logloss": 4.825129360481424,
            "mae": 0.36547908894199443,
            "precision": 0.6672535211267606,
            "recall": 0.7978947368421052
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7826863409897252,
            "auditor_fn_violation": 0.027029876091106388,
            "auditor_fp_violation": 0.0298943976907753,
            "ave_precision_score": 0.7011334314063129,
            "fpr": 0.19209659714599342,
            "logloss": 4.524405247485195,
            "mae": 0.35814712006592575,
            "precision": 0.6846846846846847,
            "recall": 0.7933194154488518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.774065444809793,
            "auditor_fn_violation": 0.024609879963065562,
            "auditor_fp_violation": 0.03287717290939018,
            "ave_precision_score": 0.6843115294481712,
            "fpr": 0.18092105263157895,
            "logloss": 5.239782253290608,
            "mae": 0.33748395825906796,
            "precision": 0.6875,
            "recall": 0.7642105263157895
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.781627092436424,
            "auditor_fn_violation": 0.02566176790743614,
            "auditor_fp_violation": 0.028357116721551414,
            "ave_precision_score": 0.6976795457517733,
            "fpr": 0.1712403951701427,
            "logloss": 5.034526895066734,
            "mae": 0.32578523898568595,
            "precision": 0.6994219653179191,
            "recall": 0.7578288100208769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7029867248266978,
            "auditor_fn_violation": 0.0050230840258541085,
            "auditor_fp_violation": 0.009002770083102499,
            "ave_precision_score": 0.5732815196807769,
            "fpr": 0.32785087719298245,
            "logloss": 9.837359432057333,
            "mae": 0.44605445587818204,
            "precision": 0.5503759398496241,
            "recall": 0.7705263157894737
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.715791083621928,
            "auditor_fn_violation": 0.01020466623431087,
            "auditor_fp_violation": 0.010804163109322279,
            "ave_precision_score": 0.5869948715165109,
            "fpr": 0.33040614709110866,
            "logloss": 9.352125748280338,
            "mae": 0.434697554340692,
            "precision": 0.565028901734104,
            "recall": 0.8162839248434238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.79712127896909,
            "auditor_fn_violation": 0.0021121883656509697,
            "auditor_fp_violation": 0.011464229796459119,
            "ave_precision_score": 0.709752297743363,
            "fpr": 0.3826754385964912,
            "logloss": 4.995136817146062,
            "mae": 0.36707595968363393,
            "precision": 0.5717791411042945,
            "recall": 0.9810526315789474
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.8019203832485409,
            "auditor_fn_violation": 0.004610776659203565,
            "auditor_fp_violation": 0.010900719599951217,
            "ave_precision_score": 0.7198830230656517,
            "fpr": 0.3885839736553238,
            "logloss": 4.736316956483108,
            "mae": 0.37419440250214614,
            "precision": 0.5693430656934306,
            "recall": 0.9770354906054279
        }
    }
]