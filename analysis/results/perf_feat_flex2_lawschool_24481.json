[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 24481,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.8021323679028307,
            "auditor_fn_violation": 0.0007796257796257999,
            "auditor_fp_violation": 0.002058147107908984,
            "ave_precision_score": 0.803039374838565,
            "fpr": 0.005482456140350877,
            "logloss": 4.991468033147943,
            "mae": 0.5191310334606447,
            "precision": 0.5833333333333334,
            "recall": 0.014553014553014554
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.8067541706871788,
            "auditor_fn_violation": 0.0019053011930759518,
            "auditor_fp_violation": 0.0005789212516728569,
            "ave_precision_score": 0.8071654299119945,
            "fpr": 0.0010976948408342481,
            "logloss": 4.871349366805475,
            "mae": 0.5052338519168564,
            "precision": 0.9090909090909091,
            "recall": 0.021141649048625793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 24481,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.835035310340504,
            "auditor_fn_violation": 0.0011466425940110125,
            "auditor_fp_violation": 0.0010914031017218218,
            "ave_precision_score": 0.8358411627463205,
            "fpr": 0.0043859649122807015,
            "logloss": 2.882563476231341,
            "mae": 0.49558868361071917,
            "precision": 0.8181818181818182,
            "recall": 0.037422037422037424
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.8417434106981234,
            "auditor_fn_violation": 0.004520739006226474,
            "auditor_fp_violation": 0.0012480639971129122,
            "ave_precision_score": 0.8421399378742855,
            "fpr": 0.0021953896816684962,
            "logloss": 2.807646892137679,
            "mae": 0.48485889609572497,
            "precision": 0.9047619047619048,
            "recall": 0.040169133192389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7751589088006556,
            "auditor_fn_violation": 0.015211821132873777,
            "auditor_fp_violation": 0.012468453616640209,
            "ave_precision_score": 0.7766584569089404,
            "fpr": 0.09320175438596491,
            "logloss": 0.891557474158407,
            "mae": 0.35886690313893105,
            "precision": 0.7763157894736842,
            "recall": 0.6133056133056133
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7733296684163087,
            "auditor_fn_violation": 0.008920801201198413,
            "auditor_fp_violation": 0.018127001789392964,
            "ave_precision_score": 0.7741002121363127,
            "fpr": 0.10647639956092206,
            "logloss": 0.7951103013083279,
            "mae": 0.36371996653626787,
            "precision": 0.7493540051679587,
            "recall": 0.6131078224101479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8635734283227561,
            "auditor_fn_violation": 0.033906882591093125,
            "auditor_fp_violation": 0.007983270240566618,
            "ave_precision_score": 0.8635322941844088,
            "fpr": 0.06359649122807018,
            "logloss": 1.206034950269578,
            "mae": 0.298068980085398,
            "precision": 0.8516624040920716,
            "recall": 0.6923076923076923
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8665907882252011,
            "auditor_fn_violation": 0.03446019173688743,
            "auditor_fp_violation": 0.012590910685733477,
            "ave_precision_score": 0.8661975539275348,
            "fpr": 0.06805708013172337,
            "logloss": 1.011965578106981,
            "mae": 0.296282045805927,
            "precision": 0.8434343434343434,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8599306437034397,
            "auditor_fn_violation": 0.006795510084983774,
            "auditor_fp_violation": 0.01898379940570685,
            "ave_precision_score": 0.8601182033058566,
            "fpr": 0.1513157894736842,
            "logloss": 0.776571148528894,
            "mae": 0.2652339113789728,
            "precision": 0.7406015037593985,
            "recall": 0.8191268191268192
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8345605699255849,
            "auditor_fn_violation": 0.01447889664263187,
            "auditor_fp_violation": 0.02676069751239293,
            "ave_precision_score": 0.8348081164343991,
            "fpr": 0.1734357848518112,
            "logloss": 0.8349647929376949,
            "mae": 0.2790571834672849,
            "precision": 0.7158273381294964,
            "recall": 0.8414376321353065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8505319387423715,
            "auditor_fn_violation": 0.010467957836378888,
            "auditor_fp_violation": 0.02060436764765743,
            "ave_precision_score": 0.8506963565037771,
            "fpr": 0.12828947368421054,
            "logloss": 0.8539022308666545,
            "mae": 0.2633028486165442,
            "precision": 0.766,
            "recall": 0.7962577962577962
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8210176296183892,
            "auditor_fn_violation": 0.009853725780512088,
            "auditor_fp_violation": 0.02055546366329339,
            "ave_precision_score": 0.8213754173983931,
            "fpr": 0.14928649835345773,
            "logloss": 0.9050387393648328,
            "mae": 0.2751519681235536,
            "precision": 0.7348927875243665,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7169248168782265,
            "auditor_fn_violation": 0.021264179158916,
            "auditor_fp_violation": 0.025165872918956337,
            "ave_precision_score": 0.7134294310115915,
            "fpr": 0.26864035087719296,
            "logloss": 1.9873949599832492,
            "mae": 0.31889703804537217,
            "precision": 0.6375739644970414,
            "recall": 0.896049896049896
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.70483257412402,
            "auditor_fn_violation": 0.013105037560657505,
            "auditor_fp_violation": 0.01864577537855435,
            "ave_precision_score": 0.7012441023538778,
            "fpr": 0.25905598243688255,
            "logloss": 2.060022940223791,
            "mae": 0.3162383242087984,
            "precision": 0.6498516320474778,
            "recall": 0.9260042283298098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8416627132645758,
            "auditor_fn_violation": 0.01054318488529015,
            "auditor_fp_violation": 0.030098811413685016,
            "ave_precision_score": 0.8419327700480547,
            "fpr": 0.2236842105263158,
            "logloss": 1.0378324934867589,
            "mae": 0.2881484097984812,
            "precision": 0.6772151898734177,
            "recall": 0.8898128898128899
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8196547518993742,
            "auditor_fn_violation": 0.012007342719823256,
            "auditor_fp_violation": 0.02698374509420627,
            "ave_precision_score": 0.8199298184030637,
            "fpr": 0.23380900109769484,
            "logloss": 1.140887877669271,
            "mae": 0.2921758942779902,
            "precision": 0.6671875,
            "recall": 0.9027484143763214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6732541760369722,
            "auditor_fn_violation": 0.006202812123864758,
            "auditor_fp_violation": 0.004546240892253834,
            "ave_precision_score": 0.674608304394034,
            "fpr": 0.39473684210526316,
            "logloss": 0.9186297187129894,
            "mae": 0.4300468360316907,
            "precision": 0.5488721804511278,
            "recall": 0.9106029106029107
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6837241510872101,
            "auditor_fn_violation": 0.0038523751285092023,
            "auditor_fp_violation": 0.01626994270935147,
            "ave_precision_score": 0.6854851043384638,
            "fpr": 0.3885839736553238,
            "logloss": 0.8993821261762288,
            "mae": 0.424354290660485,
            "precision": 0.5569461827284106,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 24481,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.8125743534836269,
            "auditor_fn_violation": 0.0007568297041981301,
            "auditor_fp_violation": 0.001946208328245207,
            "ave_precision_score": 0.8134785275176102,
            "fpr": 0.003289473684210526,
            "logloss": 5.619793753822485,
            "mae": 0.5270197640590617,
            "precision": 0.5,
            "recall": 0.006237006237006237
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.8236702859778422,
            "auditor_fn_violation": 0.0022650109189307423,
            "auditor_fp_violation": 0.0005789212516728569,
            "ave_precision_score": 0.8240833949675084,
            "fpr": 0.0010976948408342481,
            "logloss": 5.466917528337134,
            "mae": 0.5120406975905456,
            "precision": 0.875,
            "recall": 0.014799154334038054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 24481,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8470142479531481,
            "auditor_fn_violation": 0.01586606849764745,
            "auditor_fp_violation": 0.02265742662921806,
            "ave_precision_score": 0.847279375705299,
            "fpr": 0.1524122807017544,
            "logloss": 0.9310491630777431,
            "mae": 0.2616995118721467,
            "precision": 0.7382297551789078,
            "recall": 0.814968814968815
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8242898285459498,
            "auditor_fn_violation": 0.014912869021566345,
            "auditor_fp_violation": 0.025567768872582195,
            "ave_precision_score": 0.8245039550747261,
            "fpr": 0.1734357848518112,
            "logloss": 1.0111428471208077,
            "mae": 0.27803276902732244,
            "precision": 0.7111517367458866,
            "recall": 0.8224101479915433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8000237195798956,
            "auditor_fn_violation": 0.027781577123682392,
            "auditor_fp_violation": 0.022797350103797784,
            "ave_precision_score": 0.8011367041247579,
            "fpr": 0.1524122807017544,
            "logloss": 1.3540157365023897,
            "mae": 0.3188001941723405,
            "precision": 0.7098121085594989,
            "recall": 0.7068607068607069
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7855403447376557,
            "auditor_fn_violation": 0.028514538074694316,
            "auditor_fp_violation": 0.023397440716960146,
            "ave_precision_score": 0.7857583521313114,
            "fpr": 0.15148188803512624,
            "logloss": 1.4437489623329318,
            "mae": 0.3199374835862475,
            "precision": 0.7051282051282052,
            "recall": 0.6976744186046512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8518962491790518,
            "auditor_fn_violation": 0.006720283036072513,
            "auditor_fp_violation": 0.018938006268571665,
            "ave_precision_score": 0.8521372248241057,
            "fpr": 0.1337719298245614,
            "logloss": 0.5781377648585577,
            "mae": 0.27166026257078846,
            "precision": 0.7640232108317214,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.825227063866357,
            "auditor_fn_violation": 0.014251467267575308,
            "auditor_fp_violation": 0.0179991880065561,
            "ave_precision_score": 0.8255589386396279,
            "fpr": 0.14489571899012074,
            "logloss": 0.6347650901742914,
            "mae": 0.2901159000136244,
            "precision": 0.7431906614785992,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8413214254326178,
            "auditor_fn_violation": 0.019223930408140938,
            "auditor_fp_violation": 0.02620130663084626,
            "ave_precision_score": 0.841583195039098,
            "fpr": 0.1611842105263158,
            "logloss": 0.8328170849486316,
            "mae": 0.26584460837841895,
            "precision": 0.7287822878228782,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.816643566995847,
            "auditor_fn_violation": 0.01271747933989785,
            "auditor_fp_violation": 0.027705517044343868,
            "ave_precision_score": 0.8169796704455281,
            "fpr": 0.17453347969264543,
            "logloss": 0.8972434608159605,
            "mae": 0.2778497891582384,
            "precision": 0.7098540145985401,
            "recall": 0.8224101479915433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 24481,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8432287947055721,
            "auditor_fn_violation": 0.008217985191669407,
            "auditor_fp_violation": 0.021784812960475432,
            "ave_precision_score": 0.8447236206429576,
            "fpr": 0.11074561403508772,
            "logloss": 0.7657995243783727,
            "mae": 0.2582246216309614,
            "precision": 0.7860169491525424,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8224039943400994,
            "auditor_fn_violation": 0.013221072956094527,
            "auditor_fp_violation": 0.013653519390102705,
            "ave_precision_score": 0.8227575225287233,
            "fpr": 0.141602634467618,
            "logloss": 0.8266810434771393,
            "mae": 0.2758645540157543,
            "precision": 0.7372708757637475,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8508156908580002,
            "auditor_fn_violation": 0.012002133712660032,
            "auditor_fp_violation": 0.020474620425774415,
            "ave_precision_score": 0.8510838193284151,
            "fpr": 0.12280701754385964,
            "logloss": 0.826594338194924,
            "mae": 0.26136609231771574,
            "precision": 0.7709611451942741,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8270652931807435,
            "auditor_fn_violation": 0.01582722793761009,
            "auditor_fp_violation": 0.024921181500583943,
            "ave_precision_score": 0.8274195749063199,
            "fpr": 0.14270032930845225,
            "logloss": 0.8733769448524336,
            "mae": 0.2751922395061032,
            "precision": 0.7410358565737052,
            "recall": 0.7864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7954335527465513,
            "auditor_fn_violation": 0.012510486194696727,
            "auditor_fp_violation": 0.026244555704807267,
            "ave_precision_score": 0.7970438658225263,
            "fpr": 0.1699561403508772,
            "logloss": 0.9504449699953068,
            "mae": 0.2827930647413716,
            "precision": 0.7140221402214022,
            "recall": 0.8045738045738046
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7736848921570456,
            "auditor_fn_violation": 0.01918297157364883,
            "auditor_fp_violation": 0.020650697462269878,
            "ave_precision_score": 0.7750879452398352,
            "fpr": 0.1756311745334797,
            "logloss": 1.0375222587032151,
            "mae": 0.2907972787261934,
            "precision": 0.7026022304832714,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.852110258416856,
            "auditor_fn_violation": 0.012002133712660032,
            "auditor_fp_violation": 0.019978528106809956,
            "ave_precision_score": 0.8523606266721113,
            "fpr": 0.12171052631578948,
            "logloss": 0.822087777797001,
            "mae": 0.2609920827397247,
            "precision": 0.7725409836065574,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8278425128383959,
            "auditor_fn_violation": 0.014218977356852939,
            "auditor_fp_violation": 0.025472535073605706,
            "ave_precision_score": 0.8282074271697322,
            "fpr": 0.141602634467618,
            "logloss": 0.8695334279092366,
            "mae": 0.2742683010909897,
            "precision": 0.7435387673956262,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.8578777035521354,
            "auditor_fn_violation": 0.003460444249917935,
            "auditor_fp_violation": 0.011634000895510262,
            "ave_precision_score": 0.8581694091509768,
            "fpr": 0.4155701754385965,
            "logloss": 1.966618548837214,
            "mae": 0.4091899671414132,
            "precision": 0.5551643192488263,
            "recall": 0.9833679833679834
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.855777318478477,
            "auditor_fn_violation": 0.0046251708621197814,
            "auditor_fp_violation": 0.01163356039075933,
            "ave_precision_score": 0.8559668630396514,
            "fpr": 0.4270032930845225,
            "logloss": 2.090654086627465,
            "mae": 0.42185080138931685,
            "precision": 0.5439624853458382,
            "recall": 0.9809725158562368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8401428946016468,
            "auditor_fn_violation": 0.01120199146514936,
            "auditor_fp_violation": 0.019507876419587254,
            "ave_precision_score": 0.8404113807633862,
            "fpr": 0.12828947368421054,
            "logloss": 0.8948592623404317,
            "mae": 0.26860726662502765,
            "precision": 0.7631578947368421,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8206788356570507,
            "auditor_fn_violation": 0.011285602560204968,
            "auditor_fp_violation": 0.022061661378684674,
            "ave_precision_score": 0.8209645222569851,
            "fpr": 0.1437980241492865,
            "logloss": 0.9430942004822521,
            "mae": 0.2776080046316448,
            "precision": 0.7390438247011952,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.7988323566704253,
            "auditor_fn_violation": 0.015031732136995301,
            "auditor_fp_violation": 0.021767004518256198,
            "ave_precision_score": 0.7985391023012001,
            "fpr": 0.12938596491228072,
            "logloss": 0.9399353959472929,
            "mae": 0.2666925482124163,
            "precision": 0.76953125,
            "recall": 0.8191268191268192
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8006916085271458,
            "auditor_fn_violation": 0.02160346992246515,
            "auditor_fp_violation": 0.027322075695833274,
            "ave_precision_score": 0.8019149140305891,
            "fpr": 0.16245883644346873,
            "logloss": 0.9682467734279221,
            "mae": 0.28308918947935974,
            "precision": 0.720754716981132,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6619234630442168,
            "auditor_fn_violation": 0.025287686471897,
            "auditor_fp_violation": 0.05071844344038751,
            "ave_precision_score": 0.6635484607888615,
            "fpr": 0.3256578947368421,
            "logloss": 1.001831829672114,
            "mae": 0.4233033467027931,
            "precision": 0.5744985673352435,
            "recall": 0.8336798336798337
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6978673151976698,
            "auditor_fn_violation": 0.02907382868070076,
            "auditor_fp_violation": 0.0438777198021142,
            "ave_precision_score": 0.6983750318573622,
            "fpr": 0.3358946212952799,
            "logloss": 0.9547742095777553,
            "mae": 0.4157147102772298,
            "precision": 0.5720279720279721,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.716726625701209,
            "auditor_fn_violation": 0.013832658569500684,
            "auditor_fp_violation": 0.022224935889608013,
            "ave_precision_score": 0.7159940959378058,
            "fpr": 0.17543859649122806,
            "logloss": 1.4484840090676032,
            "mae": 0.29796199795131906,
            "precision": 0.7101449275362319,
            "recall": 0.814968814968815
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7271843263299174,
            "auditor_fn_violation": 0.01720804914331068,
            "auditor_fp_violation": 0.02607902400392965,
            "ave_precision_score": 0.7286684498319465,
            "fpr": 0.18880351262349068,
            "logloss": 1.1585357854219471,
            "mae": 0.30755208895370006,
            "precision": 0.6872727272727273,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8494377886959976,
            "auditor_fn_violation": 0.009109311740890696,
            "auditor_fp_violation": 0.019858957137623645,
            "ave_precision_score": 0.8496230963119342,
            "fpr": 0.1206140350877193,
            "logloss": 0.872830584554963,
            "mae": 0.26169946484817513,
            "precision": 0.7708333333333334,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8247052441330778,
            "auditor_fn_violation": 0.004042673177025923,
            "auditor_fp_violation": 0.020009122395480913,
            "ave_precision_score": 0.8250455893611177,
            "fpr": 0.14050493962678376,
            "logloss": 0.9128546269467883,
            "mae": 0.2722104153529629,
            "precision": 0.7429718875502008,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8502489760932286,
            "auditor_fn_violation": 0.013486158223000332,
            "auditor_fp_violation": 0.02144136443196158,
            "ave_precision_score": 0.8503682386196644,
            "fpr": 0.1206140350877193,
            "logloss": 1.0224470099522316,
            "mae": 0.25935790239794004,
            "precision": 0.7731958762886598,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8206059628394577,
            "auditor_fn_violation": 0.01804118328254851,
            "auditor_fp_violation": 0.023658080587843158,
            "ave_precision_score": 0.8208737810539891,
            "fpr": 0.150384193194292,
            "logloss": 1.0368604913163295,
            "mae": 0.27436460504492693,
            "precision": 0.7270916334661355,
            "recall": 0.7716701902748414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.848348280934292,
            "auditor_fn_violation": 0.015852390852390853,
            "auditor_fp_violation": 0.021298896894207685,
            "ave_precision_score": 0.8486550889821849,
            "fpr": 0.14912280701754385,
            "logloss": 0.7311115303163768,
            "mae": 0.2606836972596008,
            "precision": 0.7453183520599251,
            "recall": 0.8274428274428275
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8243730746015743,
            "auditor_fn_violation": 0.014571724958981491,
            "auditor_fp_violation": 0.02529961054388524,
            "ave_precision_score": 0.8247130158708733,
            "fpr": 0.17233809001097694,
            "logloss": 0.7851687578652574,
            "mae": 0.2724275587239516,
            "precision": 0.7155797101449275,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8064208370249739,
            "auditor_fn_violation": 0.024300616405879567,
            "auditor_fp_violation": 0.009830260105018938,
            "ave_precision_score": 0.8072681509075025,
            "fpr": 0.1118421052631579,
            "logloss": 0.6163080510846364,
            "mae": 0.3389294508689617,
            "precision": 0.7611241217798594,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8012777819104143,
            "auditor_fn_violation": 0.016354028632894188,
            "auditor_fp_violation": 0.019307399666180475,
            "ave_precision_score": 0.8017625252130445,
            "fpr": 0.11855104281009879,
            "logloss": 0.5952839470078445,
            "mae": 0.3386200362906927,
            "precision": 0.7551020408163265,
            "recall": 0.7040169133192389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.87442351880348,
            "auditor_fn_violation": 0.014101652259546996,
            "auditor_fp_violation": 0.029363577156347943,
            "ave_precision_score": 0.8750002681577751,
            "fpr": 0.16228070175438597,
            "logloss": 0.729715367106863,
            "mae": 0.26612137263977703,
            "precision": 0.7389770723104057,
            "recall": 0.8711018711018711
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8590766723923935,
            "auditor_fn_violation": 0.02019247951395094,
            "auditor_fp_violation": 0.031006120024660543,
            "ave_precision_score": 0.8592251527411757,
            "fpr": 0.20087815587266739,
            "logloss": 0.7775246376366495,
            "mae": 0.2798846025664513,
            "precision": 0.6955074875207987,
            "recall": 0.8837209302325582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7195220207425435,
            "auditor_fn_violation": 0.007493069993069993,
            "auditor_fp_violation": 0.033098261896039406,
            "ave_precision_score": 0.6765810468284807,
            "fpr": 0.2993421052631579,
            "logloss": 4.4645573436538974,
            "mae": 0.3397667773889273,
            "precision": 0.6208333333333333,
            "recall": 0.9293139293139293
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7221192824579706,
            "auditor_fn_violation": 0.012852080398604793,
            "auditor_fp_violation": 0.02939717005247884,
            "ave_precision_score": 0.679705233719412,
            "fpr": 0.27552140504939626,
            "logloss": 4.240726694621063,
            "mae": 0.32878084060630464,
            "precision": 0.6319648093841642,
            "recall": 0.9112050739957717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8041968564939376,
            "auditor_fn_violation": 0.01375971112813219,
            "auditor_fp_violation": 0.02754711604998575,
            "ave_precision_score": 0.7121020625759037,
            "fpr": 0.15021929824561403,
            "logloss": 5.187373371437369,
            "mae": 0.2697721555417986,
            "precision": 0.7365384615384616,
            "recall": 0.7962577962577962
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7888339089617773,
            "auditor_fn_violation": 0.014469613810996915,
            "auditor_fp_violation": 0.01810444641595116,
            "ave_precision_score": 0.691491701482411,
            "fpr": 0.1668496158068057,
            "logloss": 5.5019195924145725,
            "mae": 0.2903173798648951,
            "precision": 0.708253358925144,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8581511664179748,
            "auditor_fn_violation": 0.010866889156362854,
            "auditor_fp_violation": 0.008838075467090003,
            "ave_precision_score": 0.8583919644190152,
            "fpr": 0.05263157894736842,
            "logloss": 0.7761708853134537,
            "mae": 0.29559280801548654,
            "precision": 0.8558558558558559,
            "recall": 0.5925155925155925
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8341992396731513,
            "auditor_fn_violation": 0.009062364383631593,
            "auditor_fp_violation": 0.008831681778766871,
            "ave_precision_score": 0.834508314703754,
            "fpr": 0.06147091108671789,
            "logloss": 0.7684835969858296,
            "mae": 0.3010019886286024,
            "precision": 0.8308157099697885,
            "recall": 0.5813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 24481,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.8097133195784063,
            "auditor_fn_violation": 0.0007568297041981301,
            "auditor_fp_violation": 0.002058147107908984,
            "ave_precision_score": 0.8106115554126753,
            "fpr": 0.005482456140350877,
            "logloss": 5.877116169939654,
            "mae": 0.5277881699577461,
            "precision": 0.375,
            "recall": 0.006237006237006237
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.8184372525300899,
            "auditor_fn_violation": 0.0022650109189307423,
            "auditor_fp_violation": 0.0005789212516728569,
            "ave_precision_score": 0.8188954891529754,
            "fpr": 0.0010976948408342481,
            "logloss": 5.711506322217538,
            "mae": 0.5126450614809257,
            "precision": 0.875,
            "recall": 0.014799154334038054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8524942981109882,
            "auditor_fn_violation": 0.010445161760951243,
            "auditor_fp_violation": 0.02091474335490699,
            "ave_precision_score": 0.8527442289311096,
            "fpr": 0.11951754385964912,
            "logloss": 0.8216111093034065,
            "mae": 0.260667777910476,
            "precision": 0.7761806981519507,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8277679436840049,
            "auditor_fn_violation": 0.013986906565978894,
            "auditor_fp_violation": 0.026344676180021953,
            "ave_precision_score": 0.8281359997663964,
            "fpr": 0.14489571899012074,
            "logloss": 0.8694523316578772,
            "mae": 0.2740840336682695,
            "precision": 0.7396449704142012,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.8355329595438659,
            "auditor_fn_violation": 0.006341868183973449,
            "auditor_fp_violation": 0.0022896568567590675,
            "ave_precision_score": 0.8360518279132183,
            "fpr": 0.006578947368421052,
            "logloss": 1.9362861731966776,
            "mae": 0.4347980039296262,
            "precision": 0.9285714285714286,
            "recall": 0.16216216216216217
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.8378669732523467,
            "auditor_fn_violation": 0.013376560385980134,
            "auditor_fp_violation": 0.0007819196126490535,
            "ave_precision_score": 0.838131286504143,
            "fpr": 0.006586169045005488,
            "logloss": 1.8817841599263516,
            "mae": 0.42254024717829347,
            "precision": 0.9368421052631579,
            "recall": 0.18816067653276955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 24481,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.7950447433577562,
            "auditor_fn_violation": 0.0007568297041981301,
            "auditor_fp_violation": 0.0015595107257703423,
            "ave_precision_score": 0.7959040322738853,
            "fpr": 0.0043859649122807015,
            "logloss": 7.597774370277755,
            "mae": 0.5286015572206743,
            "precision": 0.42857142857142855,
            "recall": 0.006237006237006237
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.8050036403172538,
            "auditor_fn_violation": 0.0022650109189307423,
            "auditor_fp_violation": 0.0005789212516728569,
            "ave_precision_score": 0.8055584742627667,
            "fpr": 0.0010976948408342481,
            "logloss": 7.366033437481278,
            "mae": 0.5137480509904723,
            "precision": 0.875,
            "recall": 0.014799154334038054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6548840703990589,
            "auditor_fn_violation": 0.008290932633037897,
            "auditor_fp_violation": 0.01641938372613668,
            "ave_precision_score": 0.6559865202096961,
            "fpr": 0.38596491228070173,
            "logloss": 0.9596248126564244,
            "mae": 0.4375105154965575,
            "precision": 0.5527318932655655,
            "recall": 0.9043659043659044
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6682066688862074,
            "auditor_fn_violation": 0.010949099913437595,
            "auditor_fp_violation": 0.016039376669724194,
            "ave_precision_score": 0.6700152910596292,
            "fpr": 0.3907793633369923,
            "logloss": 0.9303733779828931,
            "mae": 0.4319783530509075,
            "precision": 0.549367088607595,
            "recall": 0.9175475687103594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8572656905653403,
            "auditor_fn_violation": 0.013009720246562353,
            "auditor_fp_violation": 0.02135995441038792,
            "ave_precision_score": 0.8576089254121715,
            "fpr": 0.10855263157894737,
            "logloss": 0.8168054803994031,
            "mae": 0.2596278192226033,
            "precision": 0.7875536480686696,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.847986202711694,
            "auditor_fn_violation": 0.017456364889545908,
            "auditor_fp_violation": 0.02074593126124636,
            "ave_precision_score": 0.8481098731364263,
            "fpr": 0.13391877058177826,
            "logloss": 0.8232335950581354,
            "mae": 0.26861619159394806,
            "precision": 0.7474120082815735,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 24481,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.810862503248396,
            "auditor_fn_violation": 0.0007568297041981301,
            "auditor_fp_violation": 0.002058147107908984,
            "ave_precision_score": 0.8117602822443016,
            "fpr": 0.005482456140350877,
            "logloss": 5.601538289327097,
            "mae": 0.5274228026080096,
            "precision": 0.375,
            "recall": 0.006237006237006237
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.8203490043416843,
            "auditor_fn_violation": 0.0022650109189307423,
            "auditor_fp_violation": 0.0005789212516728569,
            "ave_precision_score": 0.8207895785977062,
            "fpr": 0.0010976948408342481,
            "logloss": 5.444804707769973,
            "mae": 0.5123618920274727,
            "precision": 0.875,
            "recall": 0.014799154334038054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8501248004483427,
            "auditor_fn_violation": 0.016951161688003796,
            "auditor_fp_violation": 0.02245390157528392,
            "ave_precision_score": 0.8502874318962901,
            "fpr": 0.12828947368421054,
            "logloss": 0.899328247280841,
            "mae": 0.26011741856055015,
            "precision": 0.7631578947368421,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8216682562969335,
            "auditor_fn_violation": 0.012824231903699907,
            "auditor_fp_violation": 0.026344676180021953,
            "ave_precision_score": 0.821979855211351,
            "fpr": 0.14928649835345773,
            "logloss": 0.9567303753864451,
            "mae": 0.2737647101030935,
            "precision": 0.7312252964426877,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.8385392167438849,
            "auditor_fn_violation": 0.004381405697195176,
            "auditor_fp_violation": 0.00033836040216550663,
            "ave_precision_score": 0.8389427286140059,
            "fpr": 0.0043859649122807015,
            "logloss": 2.010310565426868,
            "mae": 0.44978396394438286,
            "precision": 0.9344262295081968,
            "recall": 0.11850311850311851
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.8335793502392872,
            "auditor_fn_violation": 0.0031561627558870644,
            "auditor_fp_violation": 0.00019046759795297472,
            "ave_precision_score": 0.8339045825619045,
            "fpr": 0.0043907793633369925,
            "logloss": 1.9511686564268131,
            "mae": 0.44326342818579767,
            "precision": 0.9333333333333333,
            "recall": 0.11839323467230443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8349836819488919,
            "auditor_fn_violation": 0.008033336980705403,
            "auditor_fp_violation": 0.008530243823014615,
            "ave_precision_score": 0.835249902686405,
            "fpr": 0.07346491228070176,
            "logloss": 1.05761824873553,
            "mae": 0.29766801532906934,
            "precision": 0.8080229226361032,
            "recall": 0.5862785862785863
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.819340198686295,
            "auditor_fn_violation": 0.009823556577698463,
            "auditor_fp_violation": 0.005533584951054839,
            "ave_precision_score": 0.819667893097516,
            "fpr": 0.08342480790340286,
            "logloss": 0.979019859855758,
            "mae": 0.29933604159647287,
            "precision": 0.790633608815427,
            "recall": 0.6067653276955602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.8470417648425203,
            "auditor_fn_violation": 0.01452110004741584,
            "auditor_fp_violation": 0.0038262710139618187,
            "ave_precision_score": 0.8475946584655694,
            "fpr": 0.009868421052631578,
            "logloss": 1.4216588060849995,
            "mae": 0.3885860774142285,
            "precision": 0.935251798561151,
            "recall": 0.2702702702702703
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.8416342321269686,
            "auditor_fn_violation": 0.010891082215719088,
            "auditor_fp_violation": 0.002428461873900426,
            "ave_precision_score": 0.8418923290055775,
            "fpr": 0.009879253567508232,
            "logloss": 1.3816170012727393,
            "mae": 0.3830822434804373,
            "precision": 0.935251798561151,
            "recall": 0.2748414376321353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8573507733587067,
            "auditor_fn_violation": 0.01329239158186527,
            "auditor_fp_violation": 0.015908027028127165,
            "ave_precision_score": 0.857952135512931,
            "fpr": 0.09539473684210527,
            "logloss": 0.7857022645964001,
            "mae": 0.26017095459839235,
            "precision": 0.8087912087912088,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.846489195209433,
            "auditor_fn_violation": 0.017704680635781143,
            "auditor_fp_violation": 0.019969023953806595,
            "ave_precision_score": 0.8466194198608493,
            "fpr": 0.12184412733260154,
            "logloss": 0.8066446600863665,
            "mae": 0.2722027800004456,
            "precision": 0.7663157894736842,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8591823984438133,
            "auditor_fn_violation": 0.015177627019732288,
            "auditor_fp_violation": 0.014147535311596859,
            "ave_precision_score": 0.8597808857438719,
            "fpr": 0.09539473684210527,
            "logloss": 0.7794186980341801,
            "mae": 0.26032964795575353,
            "precision": 0.8058035714285714,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8494512555054958,
            "auditor_fn_violation": 0.01831734752368863,
            "auditor_fp_violation": 0.018798650687437662,
            "ave_precision_score": 0.8495683556052891,
            "fpr": 0.11745334796926454,
            "logloss": 0.7969641587568767,
            "mae": 0.27173047904522113,
            "precision": 0.7718550106609808,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8453262954960918,
            "auditor_fn_violation": 0.02065552394499763,
            "auditor_fp_violation": 0.024079557943582863,
            "ave_precision_score": 0.8454903124954871,
            "fpr": 0.16228070175438597,
            "logloss": 0.9440571389852512,
            "mae": 0.260609774647655,
            "precision": 0.7313974591651543,
            "recall": 0.8378378378378378
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8190824140263211,
            "auditor_fn_violation": 0.020672866051060217,
            "auditor_fp_violation": 0.027023843535880585,
            "ave_precision_score": 0.8193338844418332,
            "fpr": 0.17672886937431395,
            "logloss": 1.018501458981233,
            "mae": 0.27329987425090274,
            "precision": 0.7140319715808171,
            "recall": 0.8498942917547568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8049689572484157,
            "auditor_fn_violation": 0.007964948754422442,
            "auditor_fp_violation": 0.023331603370374907,
            "ave_precision_score": 0.8053186203191425,
            "fpr": 0.24013157894736842,
            "logloss": 1.06077671939262,
            "mae": 0.30384234580872005,
            "precision": 0.662557781201849,
            "recall": 0.893970893970894
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.769053507842886,
            "auditor_fn_violation": 0.00763512901975619,
            "auditor_fp_violation": 0.031291821421590024,
            "ave_precision_score": 0.7711809499728313,
            "fpr": 0.23929747530186607,
            "logloss": 1.1492944719955651,
            "mae": 0.302702640338951,
            "precision": 0.659375,
            "recall": 0.8921775898520085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8552737178038667,
            "auditor_fn_violation": 0.01578856184119342,
            "auditor_fp_violation": 0.019378129197704243,
            "ave_precision_score": 0.8559602863626345,
            "fpr": 0.12280701754385964,
            "logloss": 0.6191617501700187,
            "mae": 0.26605152959501,
            "precision": 0.7695473251028807,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8367622194481694,
            "auditor_fn_violation": 0.014372144078829812,
            "auditor_fp_violation": 0.022826037923101224,
            "ave_precision_score": 0.837078964372545,
            "fpr": 0.14270032930845225,
            "logloss": 0.6496601692788861,
            "mae": 0.27482577516385337,
            "precision": 0.7420634920634921,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8505025857786933,
            "auditor_fn_violation": 0.012964128095707047,
            "auditor_fp_violation": 0.020698497985101965,
            "ave_precision_score": 0.8506867092016259,
            "fpr": 0.12280701754385964,
            "logloss": 0.8609804333025955,
            "mae": 0.261839185951215,
            "precision": 0.7700205338809035,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8210242055271334,
            "auditor_fn_violation": 0.010733274077924732,
            "auditor_fp_violation": 0.017086948458465537,
            "ave_precision_score": 0.8213783023543701,
            "fpr": 0.1437980241492865,
            "logloss": 0.9150753002034336,
            "mae": 0.2750215409126366,
            "precision": 0.738,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7909802967365945,
            "auditor_fn_violation": 0.01786984352773827,
            "auditor_fp_violation": 0.016617820653722477,
            "ave_precision_score": 0.791673041367702,
            "fpr": 0.10197368421052631,
            "logloss": 1.026979814620163,
            "mae": 0.31102472319681485,
            "precision": 0.7639593908629442,
            "recall": 0.6257796257796258
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.769040032686385,
            "auditor_fn_violation": 0.0227870309559228,
            "auditor_fp_violation": 0.01550306001233027,
            "ave_precision_score": 0.7699203862443652,
            "fpr": 0.1141602634467618,
            "logloss": 1.0465032594752377,
            "mae": 0.320033125273887,
            "precision": 0.7450980392156863,
            "recall": 0.642706131078224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8431132016296499,
            "auditor_fn_violation": 0.01612822336506548,
            "auditor_fp_violation": 0.025260003256400862,
            "ave_precision_score": 0.8442845872023091,
            "fpr": 0.13815789473684212,
            "logloss": 0.8516078028613626,
            "mae": 0.2583883744258706,
            "precision": 0.7576923076923077,
            "recall": 0.8191268191268192
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8140053181047378,
            "auditor_fn_violation": 0.02179376797098187,
            "auditor_fp_violation": 0.022537830373567113,
            "ave_precision_score": 0.8152097227540422,
            "fpr": 0.16355653128430298,
            "logloss": 0.9338025275564907,
            "mae": 0.273648481748619,
            "precision": 0.7245841035120147,
            "recall": 0.828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8438602817438685,
            "auditor_fn_violation": 0.013461082540029912,
            "auditor_fp_violation": 0.022609089428908696,
            "ave_precision_score": 0.8444009211374598,
            "fpr": 0.10307017543859649,
            "logloss": 0.8028700828773643,
            "mae": 0.2629876275768092,
            "precision": 0.7915742793791575,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8250526125161429,
            "auditor_fn_violation": 0.01266178235008807,
            "auditor_fp_violation": 0.017924003428416768,
            "ave_precision_score": 0.8253822642093425,
            "fpr": 0.12733260153677278,
            "logloss": 0.8383680282596979,
            "mae": 0.2756854229005431,
            "precision": 0.7521367521367521,
            "recall": 0.7441860465116279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8506860849954363,
            "auditor_fn_violation": 0.016951161688003796,
            "auditor_fp_violation": 0.02245390157528392,
            "ave_precision_score": 0.850847203813665,
            "fpr": 0.12828947368421054,
            "logloss": 0.8979486141131354,
            "mae": 0.25965644604308846,
            "precision": 0.7631578947368421,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8219175630687872,
            "auditor_fn_violation": 0.010779688236099542,
            "auditor_fp_violation": 0.024565307830724428,
            "ave_precision_score": 0.8222179614483649,
            "fpr": 0.14928649835345773,
            "logloss": 0.95561985391061,
            "mae": 0.27342527351631785,
            "precision": 0.7306930693069307,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8603208020225392,
            "auditor_fn_violation": 0.015617591275486021,
            "auditor_fp_violation": 0.01657965970610982,
            "ave_precision_score": 0.8604599185602122,
            "fpr": 0.09429824561403509,
            "logloss": 0.8231511967093429,
            "mae": 0.2511517037744062,
            "precision": 0.8105726872246696,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8439538573275633,
            "auditor_fn_violation": 0.02428620826496915,
            "auditor_fp_violation": 0.01455573432777469,
            "ave_precision_score": 0.8441282241278849,
            "fpr": 0.12623490669593854,
            "logloss": 0.848677119594066,
            "mae": 0.26884043381013006,
            "precision": 0.7573839662447257,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8437030896715962,
            "auditor_fn_violation": 0.016832622095779994,
            "auditor_fp_violation": 0.025893474986770873,
            "ave_precision_score": 0.8439973781186777,
            "fpr": 0.15350877192982457,
            "logloss": 0.9044498318729375,
            "mae": 0.2645932473368601,
            "precision": 0.7397769516728625,
            "recall": 0.8274428274428275
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8205257916876465,
            "auditor_fn_violation": 0.014372144078829812,
            "auditor_fp_violation": 0.026068999393511077,
            "ave_precision_score": 0.8208257836074306,
            "fpr": 0.1800219538968167,
            "logloss": 0.9642556146011527,
            "mae": 0.2780672257713097,
            "precision": 0.7071428571428572,
            "recall": 0.8372093023255814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 24481,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8565125688276011,
            "auditor_fn_violation": 0.01320348688769742,
            "auditor_fp_violation": 0.022036675214718936,
            "ave_precision_score": 0.8567347014205621,
            "fpr": 0.12719298245614036,
            "logloss": 0.8490941603891204,
            "mae": 0.2539579093327391,
            "precision": 0.7689243027888446,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8325092598791151,
            "auditor_fn_violation": 0.02094206816847411,
            "auditor_fp_violation": 0.02586850718513952,
            "ave_precision_score": 0.8327756987266537,
            "fpr": 0.15367727771679474,
            "logloss": 0.8978532120052203,
            "mae": 0.2701281252343452,
            "precision": 0.7323135755258127,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 24481,
        "test": {
            "accuracy": 0.8048245614035088,
            "auc_prc": 0.8806890413784351,
            "auditor_fn_violation": 0.0037887077360761576,
            "auditor_fp_violation": 0.004482639312899422,
            "ave_precision_score": 0.880896422497357,
            "fpr": 0.09210526315789473,
            "logloss": 0.5844511417769209,
            "mae": 0.2282433868041834,
            "precision": 0.821656050955414,
            "recall": 0.8045738045738046
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.854642105422392,
            "auditor_fn_violation": 0.011554804677618866,
            "auditor_fp_violation": 0.0139241838714043,
            "ave_precision_score": 0.8548709033119883,
            "fpr": 0.10537870472008781,
            "logloss": 0.6428299815011831,
            "mae": 0.25678259043673585,
            "precision": 0.7961783439490446,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 24481,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8615529671973985,
            "auditor_fn_violation": 0.015499051683262212,
            "auditor_fp_violation": 0.01989966214841047,
            "ave_precision_score": 0.8618866846982722,
            "fpr": 0.11732456140350878,
            "logloss": 0.6241876980507391,
            "mae": 0.26081110002911145,
            "precision": 0.7789256198347108,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.844951764116704,
            "auditor_fn_violation": 0.020932785336839153,
            "auditor_fp_violation": 0.019833691713155802,
            "ave_precision_score": 0.8452496951099691,
            "fpr": 0.13721185510428102,
            "logloss": 0.6443978687040497,
            "mae": 0.26888517446887356,
            "precision": 0.749498997995992,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8504972846583851,
            "auditor_fn_violation": 0.019869059342743557,
            "auditor_fp_violation": 0.0258909309235967,
            "ave_precision_score": 0.8506847121048562,
            "fpr": 0.15899122807017543,
            "logloss": 0.9308093978317689,
            "mae": 0.26010499600999953,
            "precision": 0.7334558823529411,
            "recall": 0.8295218295218295
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8249374189473885,
            "auditor_fn_violation": 0.014613497701338816,
            "auditor_fp_violation": 0.02720178037081034,
            "ave_precision_score": 0.8251610866383525,
            "fpr": 0.17672886937431395,
            "logloss": 0.9994680478736981,
            "mae": 0.2740512963105514,
            "precision": 0.7119856887298748,
            "recall": 0.8414376321353065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8499281151900162,
            "auditor_fn_violation": 0.016951161688003796,
            "auditor_fp_violation": 0.02245390157528392,
            "ave_precision_score": 0.8500911977026414,
            "fpr": 0.12828947368421054,
            "logloss": 0.9000214914955181,
            "mae": 0.26018517624886245,
            "precision": 0.7631578947368421,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8215053435707116,
            "auditor_fn_violation": 0.012824231903699907,
            "auditor_fp_violation": 0.02682585748011368,
            "ave_precision_score": 0.8218066556043621,
            "fpr": 0.150384193194292,
            "logloss": 0.9576487393560418,
            "mae": 0.27383299428402763,
            "precision": 0.7297830374753451,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7913700351347401,
            "auditor_fn_violation": 0.006868457526352267,
            "auditor_fp_violation": 0.024964891928196363,
            "ave_precision_score": 0.7928407528287618,
            "fpr": 0.16776315789473684,
            "logloss": 0.9392441359981047,
            "mae": 0.28453048040906564,
            "precision": 0.7161410018552876,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7650829195685088,
            "auditor_fn_violation": 0.014137752580047024,
            "auditor_fp_violation": 0.024856021532863176,
            "ave_precision_score": 0.7664731693612853,
            "fpr": 0.18441273326015367,
            "logloss": 1.0497738425821168,
            "mae": 0.29546266819583905,
            "precision": 0.6939890710382514,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8437371549734447,
            "auditor_fn_violation": 0.01300744063901959,
            "auditor_fp_violation": 0.02215370212073106,
            "ave_precision_score": 0.844198657408943,
            "fpr": 0.1162280701754386,
            "logloss": 0.9022931083236468,
            "mae": 0.2621443802112826,
            "precision": 0.7777777777777778,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8213623398172669,
            "auditor_fn_violation": 0.01461581840924756,
            "auditor_fp_violation": 0.02382348665974969,
            "ave_precision_score": 0.8216297858279689,
            "fpr": 0.14270032930845225,
            "logloss": 0.9503176320498588,
            "mae": 0.2759607724038527,
            "precision": 0.7346938775510204,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8583184349482541,
            "auditor_fn_violation": 0.010577378998431633,
            "auditor_fp_violation": 0.011369418325395859,
            "ave_precision_score": 0.8589186153995039,
            "fpr": 0.09210526315789473,
            "logloss": 0.7711072749300162,
            "mae": 0.2627024610539372,
            "precision": 0.8090909090909091,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8419808729309459,
            "auditor_fn_violation": 0.021568659303834045,
            "auditor_fp_violation": 0.016204782741630713,
            "ave_precision_score": 0.8421272759409048,
            "fpr": 0.1141602634467618,
            "logloss": 0.805685720699129,
            "mae": 0.27603218831995174,
            "precision": 0.7694013303769401,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8433368347893204,
            "auditor_fn_violation": 0.01360241820768137,
            "auditor_fp_violation": 0.025527129889689425,
            "ave_precision_score": 0.8436665907844189,
            "fpr": 0.18640350877192982,
            "logloss": 0.9803103184881222,
            "mae": 0.2736587878337691,
            "precision": 0.7098976109215017,
            "recall": 0.8648648648648649
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8199974519911448,
            "auditor_fn_violation": 0.01896018361440974,
            "auditor_fp_violation": 0.02827942599080744,
            "ave_precision_score": 0.8203068340612295,
            "fpr": 0.21514818880351264,
            "logloss": 1.0579690581831829,
            "mae": 0.2849205575646223,
            "precision": 0.6797385620915033,
            "recall": 0.879492600422833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6484457428671666,
            "auditor_fn_violation": 0.038958492905861335,
            "auditor_fp_violation": 0.0585516139536777,
            "ave_precision_score": 0.6501437985527359,
            "fpr": 0.3201754385964912,
            "logloss": 0.9263945370057411,
            "mae": 0.42249818676812045,
            "precision": 0.5774240231548481,
            "recall": 0.8295218295218295
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.67878673434612,
            "auditor_fn_violation": 0.03188188525027675,
            "auditor_fp_violation": 0.05796730974542502,
            "ave_precision_score": 0.679303423698032,
            "fpr": 0.3380900109769484,
            "logloss": 0.8940188804147982,
            "mae": 0.420485426357635,
            "precision": 0.5686274509803921,
            "recall": 0.8583509513742071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6821399879282349,
            "auditor_fn_violation": 0.025574917022285447,
            "auditor_fp_violation": 0.012259840436357717,
            "ave_precision_score": 0.6839944129895883,
            "fpr": 0.11074561403508772,
            "logloss": 0.9925607404888493,
            "mae": 0.38569003696167375,
            "precision": 0.7299465240641712,
            "recall": 0.5675675675675675
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.656914377513026,
            "auditor_fn_violation": 0.013286052777539262,
            "auditor_fp_violation": 0.017357612939767127,
            "ave_precision_score": 0.6585488749849091,
            "fpr": 0.12952799121844127,
            "logloss": 0.908224343295908,
            "mae": 0.39063956785256965,
            "precision": 0.6982097186700768,
            "recall": 0.5771670190274841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8410693812171051,
            "auditor_fn_violation": 0.019223930408140938,
            "auditor_fp_violation": 0.02620130663084626,
            "ave_precision_score": 0.8413407763070686,
            "fpr": 0.1611842105263158,
            "logloss": 0.8347769350265587,
            "mae": 0.26575730110277773,
            "precision": 0.7287822878228782,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8164897523474628,
            "auditor_fn_violation": 0.013643441795485297,
            "auditor_fp_violation": 0.027206792676019633,
            "ave_precision_score": 0.8168274240561917,
            "fpr": 0.1734357848518112,
            "logloss": 0.8958514363560043,
            "mae": 0.2769074295946969,
            "precision": 0.7127272727272728,
            "recall": 0.828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8526230982651137,
            "auditor_fn_violation": 0.016399496662654563,
            "auditor_fp_violation": 0.020853685838726748,
            "ave_precision_score": 0.8528253825634722,
            "fpr": 0.11513157894736842,
            "logloss": 0.8747597431981016,
            "mae": 0.25983427387189767,
            "precision": 0.7807933194154488,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8344456766878393,
            "auditor_fn_violation": 0.014601894161795118,
            "auditor_fp_violation": 0.026690525239462883,
            "ave_precision_score": 0.8347466017870832,
            "fpr": 0.13830954994511527,
            "logloss": 0.9087291797591808,
            "mae": 0.2701253377365764,
            "precision": 0.7454545454545455,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8770599908825899,
            "auditor_fn_violation": 0.029970000364737216,
            "auditor_fp_violation": 0.015556946310090771,
            "ave_precision_score": 0.8782410178003845,
            "fpr": 0.08114035087719298,
            "logloss": 0.656133886078982,
            "mae": 0.27032507003841283,
            "precision": 0.8306636155606407,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8757502144622052,
            "auditor_fn_violation": 0.028644497717583775,
            "auditor_fp_violation": 0.026384774621696264,
            "ave_precision_score": 0.8759155654864943,
            "fpr": 0.09440175631174534,
            "logloss": 0.6552329899331897,
            "mae": 0.27666597971876694,
            "precision": 0.8080357142857143,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8498422642988254,
            "auditor_fn_violation": 0.011425393004340374,
            "auditor_fp_violation": 0.020716306427321207,
            "ave_precision_score": 0.8503705928645258,
            "fpr": 0.11732456140350878,
            "logloss": 0.6612622404845121,
            "mae": 0.2674445200330605,
            "precision": 0.7742616033755274,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8332196572300866,
            "auditor_fn_violation": 0.01303773703130403,
            "auditor_fp_violation": 0.019553002621435632,
            "ave_precision_score": 0.8335183042911675,
            "fpr": 0.12952799121844127,
            "logloss": 0.6957007804376457,
            "mae": 0.2762308562135252,
            "precision": 0.7536534446764092,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.842654176379854,
            "auditor_fn_violation": 0.012850147718568775,
            "auditor_fp_violation": 0.02180516546586885,
            "ave_precision_score": 0.8438916617029255,
            "fpr": 0.09758771929824561,
            "logloss": 0.7807944332322267,
            "mae": 0.2594941983616521,
            "precision": 0.8017817371937639,
            "recall": 0.7484407484407485
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8247112272165421,
            "auditor_fn_violation": 0.011612822375337385,
            "auditor_fp_violation": 0.018044298753439696,
            "ave_precision_score": 0.8250641840128993,
            "fpr": 0.12843029637760703,
            "logloss": 0.8263439987614778,
            "mae": 0.27669973418176763,
            "precision": 0.7489270386266095,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8415273333417477,
            "auditor_fn_violation": 0.013894207973155343,
            "auditor_fp_violation": 0.02370558065697887,
            "ave_precision_score": 0.8417811239495414,
            "fpr": 0.15021929824561403,
            "logloss": 0.8088531965233576,
            "mae": 0.2665739083916336,
            "precision": 0.7380497131931166,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8155348596644783,
            "auditor_fn_violation": 0.013056302694573956,
            "auditor_fp_violation": 0.020435168338270457,
            "ave_precision_score": 0.8158762043295522,
            "fpr": 0.1712403951701427,
            "logloss": 0.8693231110740736,
            "mae": 0.2767118782549044,
            "precision": 0.7111111111111111,
            "recall": 0.8118393234672304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.848879556834279,
            "auditor_fn_violation": 0.012132071342597665,
            "auditor_fp_violation": 0.024298347376562054,
            "ave_precision_score": 0.8494980410749282,
            "fpr": 0.14144736842105263,
            "logloss": 0.8208540563166193,
            "mae": 0.2682593245433738,
            "precision": 0.75,
            "recall": 0.8045738045738046
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8320544972421301,
            "auditor_fn_violation": 0.018602794596463707,
            "auditor_fp_violation": 0.023502699126355206,
            "ave_precision_score": 0.8322151345119941,
            "fpr": 0.15916575192096596,
            "logloss": 0.8712690053083445,
            "mae": 0.28183045297226655,
            "precision": 0.7248576850094877,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 24481,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8372097620958913,
            "auditor_fn_violation": 0.011480103585366748,
            "auditor_fp_violation": 0.02692890869866081,
            "ave_precision_score": 0.8378009097712822,
            "fpr": 0.14473684210526316,
            "logloss": 0.8344357992223095,
            "mae": 0.2625151276141049,
            "precision": 0.7446808510638298,
            "recall": 0.8004158004158004
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8170118439242149,
            "auditor_fn_violation": 0.013831419136093278,
            "auditor_fp_violation": 0.023500192973750555,
            "ave_precision_score": 0.8173586555914075,
            "fpr": 0.17014270032930845,
            "logloss": 0.9080935556786018,
            "mae": 0.2786778923143874,
            "precision": 0.7097378277153558,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 24481,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.7496198609494695,
            "auditor_fn_violation": 0.002003775030090835,
            "auditor_fp_violation": 0.0035387918752798468,
            "ave_precision_score": 0.7361827970730939,
            "fpr": 0.03070175438596491,
            "logloss": 6.525183942316531,
            "mae": 0.5173748932948263,
            "precision": 0.5555555555555556,
            "recall": 0.07276507276507277
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.7475473808033954,
            "auditor_fn_violation": 0.009354773580132892,
            "auditor_fp_violation": 0.0009247703111137848,
            "ave_precision_score": 0.735370459607322,
            "fpr": 0.02305159165751921,
            "logloss": 6.311104995721622,
            "mae": 0.5008810711503686,
            "precision": 0.6379310344827587,
            "recall": 0.07822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8611037690304479,
            "auditor_fn_violation": 0.009784075573549263,
            "auditor_fp_violation": 0.02015661252900233,
            "ave_precision_score": 0.8615264469356148,
            "fpr": 0.1074561403508772,
            "logloss": 0.7626159783685764,
            "mae": 0.2612628630867053,
            "precision": 0.7905982905982906,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.841219278689479,
            "auditor_fn_violation": 0.013529727107957015,
            "auditor_fp_violation": 0.01592910595511982,
            "ave_precision_score": 0.8413907161119972,
            "fpr": 0.12294182217343579,
            "logloss": 0.7974861371399549,
            "mae": 0.27433870040040226,
            "precision": 0.7627118644067796,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8273724442430543,
            "auditor_fn_violation": 0.010960353065616227,
            "auditor_fp_violation": 0.02170849106525014,
            "ave_precision_score": 0.8275997866794338,
            "fpr": 0.13157894736842105,
            "logloss": 0.8747663854018521,
            "mae": 0.26325803704976514,
            "precision": 0.7660818713450293,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8064338746734483,
            "auditor_fn_violation": 0.024316377467782774,
            "auditor_fp_violation": 0.025587818093419347,
            "ave_precision_score": 0.8076517058943491,
            "fpr": 0.16245883644346873,
            "logloss": 0.945434759609406,
            "mae": 0.2784738055829596,
            "precision": 0.7218045112781954,
            "recall": 0.8118393234672304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6682777787261078,
            "auditor_fn_violation": 0.015407867381551595,
            "auditor_fp_violation": 0.030393922741889522,
            "ave_precision_score": 0.6693291712024347,
            "fpr": 0.37609649122807015,
            "logloss": 1.026843379454708,
            "mae": 0.41535006887447945,
            "precision": 0.5647208121827412,
            "recall": 0.9251559251559252
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6628010762242272,
            "auditor_fn_violation": 0.010301622406899002,
            "auditor_fp_violation": 0.032043667202983336,
            "ave_precision_score": 0.6638542610075449,
            "fpr": 0.37980241492864986,
            "logloss": 1.040547113556283,
            "mae": 0.4182522459386676,
            "precision": 0.5642317380352645,
            "recall": 0.9471458773784355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.8736725409023984,
            "auditor_fn_violation": 0.004356330014224751,
            "auditor_fp_violation": 0.017948365693816904,
            "ave_precision_score": 0.8733393664815706,
            "fpr": 0.35635964912280704,
            "logloss": 2.1540147315556424,
            "mae": 0.36589522300035743,
            "precision": 0.5901639344262295,
            "recall": 0.972972972972973
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.8583343330260378,
            "auditor_fn_violation": 0.005546491901889753,
            "auditor_fp_violation": 0.01947029958548238,
            "ave_precision_score": 0.858373627464452,
            "fpr": 0.3699231613611416,
            "logloss": 2.260288295021545,
            "mae": 0.3767089343658338,
            "precision": 0.57875,
            "recall": 0.9788583509513742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 24481,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7616059777726822,
            "auditor_fn_violation": 0.027382645803698438,
            "auditor_fp_violation": 0.017073207961900115,
            "ave_precision_score": 0.7630888167625752,
            "fpr": 0.08114035087719298,
            "logloss": 0.9357624680454903,
            "mae": 0.36965878263585494,
            "precision": 0.7810650887573964,
            "recall": 0.5488565488565489
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7445264253529362,
            "auditor_fn_violation": 0.013420653836246214,
            "auditor_fp_violation": 0.024116706514493085,
            "ave_precision_score": 0.7454542000333013,
            "fpr": 0.09769484083424808,
            "logloss": 0.8343282457075463,
            "mae": 0.372363973923782,
            "precision": 0.7457142857142857,
            "recall": 0.5517970401691332
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.841211845601805,
            "auditor_fn_violation": 0.01127949812160339,
            "auditor_fp_violation": 0.020431371351813412,
            "ave_precision_score": 0.8414152130970933,
            "fpr": 0.11074561403508772,
            "logloss": 0.7925470095861481,
            "mae": 0.2592733683356034,
            "precision": 0.7841880341880342,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8227605845816308,
            "auditor_fn_violation": 0.013597027637310485,
            "auditor_fp_violation": 0.012801427504523611,
            "ave_precision_score": 0.8231044757694852,
            "fpr": 0.14050493962678376,
            "logloss": 0.8459013857632519,
            "mae": 0.2767095872861273,
            "precision": 0.7377049180327869,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7520697379778086,
            "auditor_fn_violation": 0.012252890542364232,
            "auditor_fp_violation": 0.020665425163837674,
            "ave_precision_score": 0.7514299030673691,
            "fpr": 0.15899122807017543,
            "logloss": 1.3303854524275618,
            "mae": 0.28655466826560433,
            "precision": 0.7238095238095238,
            "recall": 0.7900207900207901
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7535624210952659,
            "auditor_fn_violation": 0.008412566169184248,
            "auditor_fp_violation": 0.014044479196427236,
            "ave_precision_score": 0.7548223220220132,
            "fpr": 0.1712403951701427,
            "logloss": 1.2220303842424103,
            "mae": 0.2912615567750083,
            "precision": 0.7078651685393258,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8528573053373961,
            "auditor_fn_violation": 0.012991483386220234,
            "auditor_fp_violation": 0.01996835185411324,
            "ave_precision_score": 0.8530597339575764,
            "fpr": 0.11513157894736842,
            "logloss": 0.8755270404635,
            "mae": 0.25951374210817174,
            "precision": 0.7807933194154488,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8338802057644107,
            "auditor_fn_violation": 0.014780588670768131,
            "auditor_fp_violation": 0.02493120611100252,
            "ave_precision_score": 0.8341836702676724,
            "fpr": 0.13830954994511527,
            "logloss": 0.9112936695929392,
            "mae": 0.27030456540127323,
            "precision": 0.7459677419354839,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 24481,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.8085696692124499,
            "auditor_fn_violation": 0.0007568297041981301,
            "auditor_fp_violation": 0.0008471730370008549,
            "ave_precision_score": 0.8094832793556548,
            "fpr": 0.006578947368421052,
            "logloss": 6.369100981943176,
            "mae": 0.528635603641628,
            "precision": 0.3333333333333333,
            "recall": 0.006237006237006237
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.8114611945838582,
            "auditor_fn_violation": 0.0022650109189307423,
            "auditor_fp_violation": 0.0005789212516728569,
            "ave_precision_score": 0.8119583616218017,
            "fpr": 0.0010976948408342481,
            "logloss": 6.228907459074947,
            "mae": 0.5128847317423738,
            "precision": 0.875,
            "recall": 0.014799154334038054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8795769604947357,
            "auditor_fn_violation": 0.029411496516759682,
            "auditor_fp_violation": 0.013221496316196523,
            "ave_precision_score": 0.8800260246768649,
            "fpr": 0.07894736842105263,
            "logloss": 0.6571636461434615,
            "mae": 0.2706110809841177,
            "precision": 0.8329466357308585,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8763850219991998,
            "auditor_fn_violation": 0.029185222660320302,
            "auditor_fp_violation": 0.025703101113232988,
            "ave_precision_score": 0.8765186725449836,
            "fpr": 0.09110867178924259,
            "logloss": 0.6562159670651158,
            "mae": 0.2772882926465921,
            "precision": 0.8130630630630631,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.868596765758603,
            "auditor_fn_violation": 0.007146569646569647,
            "auditor_fp_violation": 0.027246916595432907,
            "ave_precision_score": 0.8698750211349862,
            "fpr": 0.2993421052631579,
            "logloss": 1.5566445822370538,
            "mae": 0.3232874586482075,
            "precision": 0.6280653950953679,
            "recall": 0.9584199584199584
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8565499932919045,
            "auditor_fn_violation": 0.008837255716483756,
            "auditor_fp_violation": 0.02426206336556246,
            "ave_precision_score": 0.8567227056953326,
            "fpr": 0.31284302963776073,
            "logloss": 1.6249487633742903,
            "mae": 0.3320770005744369,
            "precision": 0.6138211382113821,
            "recall": 0.9577167019027484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.862017785813172,
            "auditor_fn_violation": 0.013326585695006754,
            "auditor_fp_violation": 0.01546536003582041,
            "ave_precision_score": 0.8621493059283925,
            "fpr": 0.09758771929824561,
            "logloss": 0.8156890699126695,
            "mae": 0.24933437475813527,
            "precision": 0.8061002178649237,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8465964528865446,
            "auditor_fn_violation": 0.026469994407093946,
            "auditor_fp_violation": 0.01613962277390996,
            "ave_precision_score": 0.8467629752820134,
            "fpr": 0.12733260153677278,
            "logloss": 0.8400523646438058,
            "mae": 0.2665174500713857,
            "precision": 0.7568134171907757,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 24481,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8411626494183024,
            "auditor_fn_violation": 0.033539865776707894,
            "auditor_fp_violation": 0.010038873285301427,
            "ave_precision_score": 0.8419073471326521,
            "fpr": 0.05263157894736842,
            "logloss": 0.5592020724504789,
            "mae": 0.348578703718407,
            "precision": 0.8647887323943662,
            "recall": 0.6382536382536382
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8396268703082539,
            "auditor_fn_violation": 0.03883472614486323,
            "auditor_fp_violation": 0.019001649048413855,
            "ave_precision_score": 0.8398369541814055,
            "fpr": 0.06805708013172337,
            "logloss": 0.5642562220309059,
            "mae": 0.35503489871813,
            "precision": 0.8268156424581006,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.8718149220567432,
            "auditor_fn_violation": 0.006088831746726485,
            "auditor_fp_violation": 0.024865673464403475,
            "ave_precision_score": 0.8723564942385034,
            "fpr": 0.32346491228070173,
            "logloss": 1.7720080273038332,
            "mae": 0.34090238258582267,
            "precision": 0.6108179419525066,
            "recall": 0.9625779625779626
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8583782255166689,
            "auditor_fn_violation": 0.007570149198311454,
            "auditor_fp_violation": 0.021121854151943016,
            "ave_precision_score": 0.8584764441156956,
            "fpr": 0.3446761800219539,
            "logloss": 1.8567728455511887,
            "mae": 0.35122494741282173,
            "precision": 0.5927367055771725,
            "recall": 0.9661733615221987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8688238615092908,
            "auditor_fn_violation": 0.00749534960061276,
            "auditor_fp_violation": 0.026567651727927705,
            "ave_precision_score": 0.8697241625469161,
            "fpr": 0.3059210526315789,
            "logloss": 1.6133591371990836,
            "mae": 0.3288331226802071,
            "precision": 0.6224627875507442,
            "recall": 0.9563409563409564
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.8530412747853731,
            "auditor_fn_violation": 0.008083025646143101,
            "auditor_fp_violation": 0.024324717180678582,
            "ave_precision_score": 0.8532185718713381,
            "fpr": 0.31833150384193193,
            "logloss": 1.688386626371976,
            "mae": 0.3362608073584792,
            "precision": 0.6091644204851752,
            "recall": 0.9556025369978859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8575573253809062,
            "auditor_fn_violation": 0.012337236021446553,
            "auditor_fp_violation": 0.01414499124842268,
            "ave_precision_score": 0.8577123754442639,
            "fpr": 0.09100877192982457,
            "logloss": 0.8421403142868479,
            "mae": 0.2598469420745801,
            "precision": 0.8105022831050228,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8283400067979221,
            "auditor_fn_violation": 0.017354253741561337,
            "auditor_fp_violation": 0.014826398809076284,
            "ave_precision_score": 0.8286607662977062,
            "fpr": 0.10867178924259056,
            "logloss": 0.8837758751398188,
            "mae": 0.2751951245221393,
            "precision": 0.7755102040816326,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.8209351441279871,
            "auditor_fn_violation": 0.0019445052339789183,
            "auditor_fp_violation": 0.006487361094150704,
            "ave_precision_score": 0.6990647889072402,
            "fpr": 0.43201754385964913,
            "logloss": 10.024319949350314,
            "mae": 0.44157840801822884,
            "precision": 0.5455594002306805,
            "recall": 0.9833679833679834
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.8096170350436015,
            "auditor_fn_violation": 0.005309779695198223,
            "auditor_fp_violation": 0.006904450425795324,
            "ave_precision_score": 0.6805640517535831,
            "fpr": 0.44017563117453345,
            "logloss": 10.39985929609169,
            "mae": 0.45044698522154447,
            "precision": 0.5353418308227115,
            "recall": 0.9767441860465116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.769629279879462,
            "auditor_fn_violation": 0.01835084071926178,
            "auditor_fp_violation": 0.029584910652501333,
            "ave_precision_score": 0.7701893006828204,
            "fpr": 0.2631578947368421,
            "logloss": 0.822248699105264,
            "mae": 0.3833009966837013,
            "precision": 0.6135265700483091,
            "recall": 0.7920997920997921
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.769344901739687,
            "auditor_fn_violation": 0.01912031246011284,
            "auditor_fp_violation": 0.021567949315569726,
            "ave_precision_score": 0.769641110014176,
            "fpr": 0.2579582875960483,
            "logloss": 0.8023283461835111,
            "mae": 0.38491403244018685,
            "precision": 0.6070234113712375,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 24481,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8377730175021416,
            "auditor_fn_violation": 0.016166976693292485,
            "auditor_fp_violation": 0.017961086009687804,
            "ave_precision_score": 0.8379614365413295,
            "fpr": 0.14912280701754385,
            "logloss": 0.9170374591493087,
            "mae": 0.27033840790562225,
            "precision": 0.743879472693032,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8114782441543023,
            "auditor_fn_violation": 0.017409950731371096,
            "auditor_fp_violation": 0.017743560440882364,
            "ave_precision_score": 0.8117341556522425,
            "fpr": 0.17672886937431395,
            "logloss": 0.9803038548331061,
            "mae": 0.2852539237057442,
            "precision": 0.7051282051282052,
            "recall": 0.813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8560269083133637,
            "auditor_fn_violation": 0.010365375496954453,
            "auditor_fp_violation": 0.018128994179183462,
            "ave_precision_score": 0.8562787289338447,
            "fpr": 0.1206140350877193,
            "logloss": 0.7874061177902956,
            "mae": 0.25901546177139706,
            "precision": 0.7736625514403292,
            "recall": 0.7817047817047817
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8319514737610078,
            "auditor_fn_violation": 0.017131465782322247,
            "auditor_fp_violation": 0.023828498964958984,
            "ave_precision_score": 0.8322875007022175,
            "fpr": 0.14050493962678376,
            "logloss": 0.8359014087499237,
            "mae": 0.2735227615583598,
            "precision": 0.7455268389662028,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8390488175963177,
            "auditor_fn_violation": 0.010436043330780173,
            "auditor_fp_violation": 0.02526000325640087,
            "ave_precision_score": 0.8392789327113352,
            "fpr": 0.1513157894736842,
            "logloss": 0.8253787749411011,
            "mae": 0.26529561288012304,
            "precision": 0.7376425855513308,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8113408595566222,
            "auditor_fn_violation": 0.014975528135102334,
            "auditor_fp_violation": 0.027367186442716872,
            "ave_precision_score": 0.8118010001678451,
            "fpr": 0.1712403951701427,
            "logloss": 0.9154449429406948,
            "mae": 0.2832106303377617,
            "precision": 0.7062146892655368,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.8607103846041815,
            "auditor_fn_violation": 0.0007841849947113107,
            "auditor_fp_violation": 0.00199454552855458,
            "ave_precision_score": 0.8563880146216297,
            "fpr": 0.4594298245614035,
            "logloss": 4.232310108011337,
            "mae": 0.45944706997533635,
            "precision": 0.5328874024526199,
            "recall": 0.9937629937629938
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8406855674824877,
            "auditor_fn_violation": 0.0015595157146736042,
            "auditor_fp_violation": 0.002275586565017124,
            "ave_precision_score": 0.8347311178274941,
            "fpr": 0.47200878155872666,
            "logloss": 4.4594800385485485,
            "mae": 0.47267065568894073,
            "precision": 0.5222222222222223,
            "recall": 0.9936575052854123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7298253258785251,
            "auditor_fn_violation": 0.01102418207681366,
            "auditor_fp_violation": 0.021774636707778728,
            "ave_precision_score": 0.7248427608906505,
            "fpr": 0.17653508771929824,
            "logloss": 1.642639324839432,
            "mae": 0.2843197765391155,
            "precision": 0.7145390070921985,
            "recall": 0.8378378378378378
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7414012627382809,
            "auditor_fn_violation": 0.008493790945990167,
            "auditor_fp_violation": 0.02966783453378044,
            "ave_precision_score": 0.7359140805306484,
            "fpr": 0.18551042810098792,
            "logloss": 1.4577837211248046,
            "mae": 0.2783178422849825,
            "precision": 0.7045454545454546,
            "recall": 0.8520084566596194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8625043163876945,
            "auditor_fn_violation": 0.012494528941897365,
            "auditor_fp_violation": 0.027552204176334107,
            "ave_precision_score": 0.8627216309091088,
            "fpr": 0.22478070175438597,
            "logloss": 0.9131392552611257,
            "mae": 0.2825569640109286,
            "precision": 0.6796875,
            "recall": 0.9043659043659044
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8470829559262625,
            "auditor_fn_violation": 0.01009972081883858,
            "auditor_fp_violation": 0.026893523600439086,
            "ave_precision_score": 0.8473142620101038,
            "fpr": 0.24039517014270034,
            "logloss": 0.9773805564330904,
            "mae": 0.2900328174119544,
            "precision": 0.6641104294478528,
            "recall": 0.9154334038054969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8409826077271707,
            "auditor_fn_violation": 0.011974778422146849,
            "auditor_fp_violation": 0.021863678918874915,
            "ave_precision_score": 0.8422227280263015,
            "fpr": 0.10855263157894737,
            "logloss": 0.7933866814994833,
            "mae": 0.2588101116212877,
            "precision": 0.7870967741935484,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8230662460991502,
            "auditor_fn_violation": 0.014383747618373514,
            "auditor_fp_violation": 0.01174383110536367,
            "ave_precision_score": 0.823410679915094,
            "fpr": 0.13830954994511527,
            "logloss": 0.8468696109878205,
            "mae": 0.27617551065640966,
            "precision": 0.7407407407407407,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8652573204154719,
            "auditor_fn_violation": 0.0174458365247839,
            "auditor_fp_violation": 0.023586009687792574,
            "ave_precision_score": 0.8654877573379505,
            "fpr": 0.11951754385964912,
            "logloss": 0.7597705398358735,
            "mae": 0.2545050292636294,
            "precision": 0.7811244979919679,
            "recall": 0.8087318087318087
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8506419892945388,
            "auditor_fn_violation": 0.022928594138355966,
            "auditor_fp_violation": 0.022036599852638224,
            "ave_precision_score": 0.850833376066699,
            "fpr": 0.1525795828759605,
            "logloss": 0.7858471586432029,
            "mae": 0.2686216433894345,
            "precision": 0.7337164750957854,
            "recall": 0.8097251585623678
        }
    }
]