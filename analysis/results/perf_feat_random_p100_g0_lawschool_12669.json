[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8153231181607088,
            "auditor_fn_violation": 0.0146623827009384,
            "auditor_fp_violation": 0.02235193621867882,
            "ave_precision_score": 0.8157112120169393,
            "fpr": 0.13706140350877194,
            "logloss": 1.0170168217524087,
            "mae": 0.27942151570983753,
            "precision": 0.7379454926624738,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8435159512979428,
            "auditor_fn_violation": 0.02136054825407186,
            "auditor_fp_violation": 0.019115206902713608,
            "ave_precision_score": 0.8440248793254574,
            "fpr": 0.12733260153677278,
            "logloss": 0.8586372805976008,
            "mae": 0.25455478167676887,
            "precision": 0.7651821862348178,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7600048503746004,
            "auditor_fn_violation": 0.01534624086643671,
            "auditor_fp_violation": 0.012281201294808778,
            "ave_precision_score": 0.719460435806286,
            "fpr": 0.06798245614035088,
            "logloss": 0.6589691429255381,
            "mae": 0.3773425362448682,
            "precision": 0.7876712328767124,
            "recall": 0.48625792811839325
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7948572127883362,
            "auditor_fn_violation": 0.010091489784135228,
            "auditor_fp_violation": 0.002208153575166572,
            "ave_precision_score": 0.7622424603256811,
            "fpr": 0.06037321624588365,
            "logloss": 0.6301299663494109,
            "mae": 0.36930720555942614,
            "precision": 0.8070175438596491,
            "recall": 0.4781704781704782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7748336360693922,
            "auditor_fn_violation": 0.015937372501019998,
            "auditor_fp_violation": 0.005484953842464934,
            "ave_precision_score": 0.7341917722204025,
            "fpr": 0.03289473684210526,
            "logloss": 0.6344424721485871,
            "mae": 0.43130599027662947,
            "precision": 0.8536585365853658,
            "recall": 0.3699788583509514
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.8382525791225758,
            "auditor_fn_violation": 0.010618657160918437,
            "auditor_fp_violation": 0.004990682357746408,
            "ave_precision_score": 0.7998545779019476,
            "fpr": 0.031833150384193196,
            "logloss": 0.5927004026225811,
            "mae": 0.4133577553880463,
            "precision": 0.875,
            "recall": 0.42203742203742206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.74244270386081,
            "auditor_fn_violation": 0.0036997885835095253,
            "auditor_fp_violation": 0.014978719577988254,
            "ave_precision_score": 0.7500162570866474,
            "fpr": 0.09320175438596491,
            "logloss": 0.5650590610139219,
            "mae": 0.36404274065831776,
            "precision": 0.7906403940886699,
            "recall": 0.678646934460888
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7921140144869734,
            "auditor_fn_violation": 0.004210492684696864,
            "auditor_fp_violation": 0.006381946749036332,
            "ave_precision_score": 0.7941175234906428,
            "fpr": 0.0845225027442371,
            "logloss": 0.539851685217903,
            "mae": 0.3514775229264235,
            "precision": 0.8094059405940595,
            "recall": 0.6798336798336798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7370792841465643,
            "auditor_fn_violation": 0.0016922591891992138,
            "auditor_fp_violation": 0.02294389161970989,
            "ave_precision_score": 0.5454348747329976,
            "fpr": 0.35635964912280704,
            "logloss": 0.7128468470865964,
            "mae": 0.4827250271643463,
            "precision": 0.5504840940525588,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7340971625711536,
            "auditor_fn_violation": 0.004835790785296827,
            "auditor_fp_violation": 0.008720292037883236,
            "ave_precision_score": 0.5466716075030846,
            "fpr": 0.3556531284302964,
            "logloss": 0.727609491525108,
            "mae": 0.4887652280040159,
            "precision": 0.550624133148405,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.7546523886275649,
            "auditor_fn_violation": 0.004951596750862357,
            "auditor_fp_violation": 0.0018957559045678113,
            "ave_precision_score": 0.5282571841179728,
            "fpr": 0.4440789473684211,
            "logloss": 0.7014461685714078,
            "mae": 0.49144915351010504,
            "precision": 0.5285215366705471,
            "recall": 0.959830866807611
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7677774422386383,
            "auditor_fn_violation": 0.004240160112827512,
            "auditor_fp_violation": 0.006397263421234016,
            "ave_precision_score": 0.5468499062740487,
            "fpr": 0.42590559824368823,
            "logloss": 0.6778620026217177,
            "mae": 0.4858144138213115,
            "precision": 0.5472578763127188,
            "recall": 0.975051975051975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6333571456843425,
            "auditor_fn_violation": 0.0022509365379622423,
            "auditor_fp_violation": 0.0030971506214282885,
            "ave_precision_score": 0.6353755943688302,
            "fpr": 0.45723684210526316,
            "logloss": 0.7336197824365822,
            "mae": 0.4707381349841231,
            "precision": 0.5261363636363636,
            "recall": 0.9788583509513742
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6784972298267159,
            "auditor_fn_violation": 0.0027910203541378076,
            "auditor_fp_violation": 0.0028744288157659696,
            "ave_precision_score": 0.679479786432575,
            "fpr": 0.43688254665203075,
            "logloss": 0.718386488047003,
            "mae": 0.46265097276504946,
            "precision": 0.5430539609644087,
            "recall": 0.9833679833679834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8342188260878143,
            "auditor_fn_violation": 0.0007024034716813222,
            "auditor_fp_violation": 0.02401041042241138,
            "ave_precision_score": 0.8344838906641517,
            "fpr": 0.14035087719298245,
            "logloss": 0.6469910897039718,
            "mae": 0.2887223792410958,
            "precision": 0.7403651115618661,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8707253613321856,
            "auditor_fn_violation": 0.018213518762366186,
            "auditor_fp_violation": 0.01891609016414367,
            "ave_precision_score": 0.8709191367252421,
            "fpr": 0.13611416026344675,
            "logloss": 0.5327436446661247,
            "mae": 0.26054995217394805,
            "precision": 0.7615384615384615,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8402013753507691,
            "auditor_fn_violation": 0.016693093727977455,
            "auditor_fp_violation": 0.014878811493426049,
            "ave_precision_score": 0.8314867017614284,
            "fpr": 0.11951754385964912,
            "logloss": 0.5458778026588091,
            "mae": 0.3069901171093398,
            "precision": 0.7630434782608696,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.885938703329588,
            "auditor_fn_violation": 0.015682658931835663,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.8813245630131917,
            "fpr": 0.09659714599341383,
            "logloss": 0.4528397060042458,
            "mae": 0.2801654491283237,
            "precision": 0.8095238095238095,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5814283843396603,
            "auditor_fn_violation": 0.001766440413931235,
            "auditor_fp_violation": 0.012488510570275353,
            "ave_precision_score": 0.5827788036250205,
            "fpr": 0.4100877192982456,
            "logloss": 0.8304143719946349,
            "mae": 0.45555574262285964,
            "precision": 0.548854041013269,
            "recall": 0.9619450317124736
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6036903472527084,
            "auditor_fn_violation": 0.0027362497175889055,
            "auditor_fp_violation": 0.0029612232915528633,
            "ave_precision_score": 0.605575358497444,
            "fpr": 0.3896816684961581,
            "logloss": 0.7859806272781158,
            "mae": 0.43853664780945467,
            "precision": 0.5665445665445665,
            "recall": 0.9646569646569647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8135923955685732,
            "auditor_fn_violation": 0.004798597974852569,
            "auditor_fp_violation": 0.015825440594652924,
            "ave_precision_score": 0.8139181963049408,
            "fpr": 0.12719298245614036,
            "logloss": 0.7976031481840729,
            "mae": 0.28780489366974094,
            "precision": 0.7472766884531591,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8445309231804358,
            "auditor_fn_violation": 0.012371317530483289,
            "auditor_fp_violation": 0.0171291450744135,
            "ave_precision_score": 0.8448245209544045,
            "fpr": 0.1207464324917673,
            "logloss": 0.6691495554196447,
            "mae": 0.2618857461851461,
            "precision": 0.7741273100616016,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6799138134629474,
            "auditor_fn_violation": 0.008146025740884985,
            "auditor_fp_violation": 0.018263197857970672,
            "ave_precision_score": 0.6467782510994091,
            "fpr": 0.4298245614035088,
            "logloss": 2.493565224902538,
            "mae": 0.45080795519772854,
            "precision": 0.5355450236966824,
            "recall": 0.9556025369978859
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6878492862017083,
            "auditor_fn_violation": 0.011657017145491352,
            "auditor_fp_violation": 0.010836545579863684,
            "ave_precision_score": 0.6528377805554735,
            "fpr": 0.411635565312843,
            "logloss": 2.479277039682827,
            "mae": 0.44275658715896626,
            "precision": 0.5465538089480049,
            "recall": 0.9397089397089398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6871585046957739,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6876050679683912,
            "fpr": 0.47368421052631576,
            "logloss": 1.6375526968647678,
            "mae": 0.47419109693235767,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6436750267472329,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.6444215888336824,
            "fpr": 0.4665203073545554,
            "logloss": 1.614750725411148,
            "mae": 0.46672341109632165,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5228826093458313,
            "auditor_fn_violation": 0.02137810170245911,
            "auditor_fp_violation": 0.03733065579666708,
            "ave_precision_score": 0.5253154256070653,
            "fpr": 0.4232456140350877,
            "logloss": 0.9203423047962098,
            "mae": 0.4768377120740377,
            "precision": 0.5349397590361445,
            "recall": 0.9386892177589852
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5062014271666255,
            "auditor_fn_violation": 0.030689813346234864,
            "auditor_fp_violation": 0.029714344063513153,
            "ave_precision_score": 0.5086837724971607,
            "fpr": 0.4281009879253567,
            "logloss": 0.9243577742148232,
            "mae": 0.48298571635401605,
            "precision": 0.5301204819277109,
            "recall": 0.9147609147609148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 12669,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.7449420044179988,
            "auditor_fn_violation": 0.0006444493898594339,
            "auditor_fp_violation": 0.002085581265235983,
            "ave_precision_score": 0.7451795396402401,
            "fpr": 0.007675438596491228,
            "logloss": 3.387041878182571,
            "mae": 0.5199256558089019,
            "precision": 0.125,
            "recall": 0.0021141649048625794
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7937697093661483,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111202,
            "ave_precision_score": 0.795021666865792,
            "fpr": 0.005488474204171241,
            "logloss": 3.2259271809939163,
            "mae": 0.5264901962327997,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7235125812018324,
            "auditor_fn_violation": 0.0229961796669263,
            "auditor_fp_violation": 0.0723009830955521,
            "ave_precision_score": 0.5843652315959701,
            "fpr": 0.3168859649122807,
            "logloss": 8.868817467117147,
            "mae": 0.3814746596209149,
            "precision": 0.6002766251728907,
            "recall": 0.9175475687103594
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.734042796691644,
            "auditor_fn_violation": 0.017426190861975714,
            "auditor_fp_violation": 0.058279937712199754,
            "ave_precision_score": 0.5962839889676754,
            "fpr": 0.31833150384193193,
            "logloss": 8.747508814720128,
            "mae": 0.37437430922755754,
            "precision": 0.6122994652406417,
            "recall": 0.9521829521829522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6457001991847812,
            "auditor_fn_violation": 0.06730787062794408,
            "auditor_fp_violation": 0.08497931902649562,
            "ave_precision_score": 0.6129389299821986,
            "fpr": 0.3223684210526316,
            "logloss": 0.6724841478706604,
            "mae": 0.4694341275710286,
            "precision": 0.5592203898050975,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6469266619699177,
            "auditor_fn_violation": 0.07041221750332619,
            "auditor_fp_violation": 0.08066525412911955,
            "ave_precision_score": 0.621123754023176,
            "fpr": 0.3172338090010977,
            "logloss": 0.6728924822917335,
            "mae": 0.4695255152807539,
            "precision": 0.5705794947994056,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6130727972892795,
            "auditor_fn_violation": 0.004223693483179422,
            "auditor_fp_violation": 0.0223419454102226,
            "ave_precision_score": 0.5280176181050444,
            "fpr": 0.14364035087719298,
            "logloss": 1.185302244372323,
            "mae": 0.5023575341737453,
            "precision": 0.5467128027681661,
            "recall": 0.33403805496828753
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6276469678557852,
            "auditor_fn_violation": 0.001038359984572936,
            "auditor_fp_violation": 0.011604931968447661,
            "ave_precision_score": 0.5397511504013431,
            "fpr": 0.14489571899012074,
            "logloss": 1.185293834948041,
            "mae": 0.5053388959064703,
            "precision": 0.5614617940199336,
            "recall": 0.35135135135135137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605561309647144,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221237905524183,
            "fpr": 0.47368421052631576,
            "logloss": 16.365505888929984,
            "mae": 0.47486638808990583,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.113498335931297,
            "mae": 0.4666043397358135,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 12669,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8092030875697424,
            "auditor_fn_violation": 0.017054727198546046,
            "auditor_fp_violation": 0.0479583782919714,
            "ave_precision_score": 0.7696194314056239,
            "fpr": 0.2236842105263158,
            "logloss": 0.5603218790598824,
            "mae": 0.3782300786442009,
            "precision": 0.6611295681063123,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8248952621064178,
            "auditor_fn_violation": 0.01542249840822838,
            "auditor_fp_violation": 0.04291220994052026,
            "ave_precision_score": 0.7843256876529088,
            "fpr": 0.2030735455543359,
            "logloss": 0.5366455549963901,
            "mae": 0.3688344592606786,
            "precision": 0.6916666666666667,
            "recall": 0.8627858627858628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7974039187531401,
            "auditor_fn_violation": 0.00508836838396202,
            "auditor_fp_violation": 0.023890520720936736,
            "ave_precision_score": 0.7893643268238687,
            "fpr": 0.13706140350877194,
            "logloss": 0.5980170567821677,
            "mae": 0.34885380077980666,
            "precision": 0.7306034482758621,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8380876118544909,
            "auditor_fn_violation": 0.01934316314118729,
            "auditor_fp_violation": 0.017626936920838335,
            "ave_precision_score": 0.830906125561603,
            "fpr": 0.132821075740944,
            "logloss": 0.5381839169121014,
            "mae": 0.3299700423964477,
            "precision": 0.7520491803278688,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7814865728115957,
            "auditor_fn_violation": 0.028309409888357256,
            "auditor_fp_violation": 0.030084821963793317,
            "ave_precision_score": 0.7823921716759888,
            "fpr": 0.13048245614035087,
            "logloss": 1.7402151597547029,
            "mae": 0.2877112355152634,
            "precision": 0.7429805615550756,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8144786096073557,
            "auditor_fn_violation": 0.03197692330513407,
            "auditor_fp_violation": 0.028126515712352897,
            "ave_precision_score": 0.814819481367667,
            "fpr": 0.12733260153677278,
            "logloss": 1.6627978963181487,
            "mae": 0.27818390196353654,
            "precision": 0.7531914893617021,
            "recall": 0.735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.798645540549666,
            "auditor_fn_violation": 0.0006977671451355699,
            "auditor_fp_violation": 0.01621258442233146,
            "ave_precision_score": 0.7977932026968465,
            "fpr": 0.10964912280701754,
            "logloss": 0.5459940869223278,
            "mae": 0.33069375239868176,
            "precision": 0.7747747747747747,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8719031247034509,
            "auditor_fn_violation": 0.010819482828264393,
            "auditor_fp_violation": 0.011895948740203714,
            "ave_precision_score": 0.869428122453611,
            "fpr": 0.10428100987925357,
            "logloss": 0.46926399367751276,
            "mae": 0.30418173417563493,
            "precision": 0.7978723404255319,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.8031405889472427,
            "auditor_fn_violation": 0.025063981306331373,
            "auditor_fp_violation": 0.06629900491547776,
            "ave_precision_score": 0.8033694444968906,
            "fpr": 0.3717105263157895,
            "logloss": 1.030119124349604,
            "mae": 0.39580901369079124,
            "precision": 0.5642673521850899,
            "recall": 0.9281183932346723
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.8210601877536181,
            "auditor_fn_violation": 0.02560527258661178,
            "auditor_fp_violation": 0.05090240727031373,
            "ave_precision_score": 0.8211751608632303,
            "fpr": 0.3885839736553238,
            "logloss": 1.0063759011962756,
            "mae": 0.3996689482059219,
            "precision": 0.5580524344569289,
            "recall": 0.9293139293139293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6823001634264648,
            "auditor_fn_violation": 0.002793386743815144,
            "auditor_fp_violation": 0.021460256563961156,
            "ave_precision_score": 0.6833211858201546,
            "fpr": 0.19407894736842105,
            "logloss": 0.9557260895270029,
            "mae": 0.4226695137214023,
            "precision": 0.650197628458498,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6808303259091288,
            "auditor_fn_violation": 0.0007918921201028768,
            "auditor_fp_violation": 0.021106374288412933,
            "ave_precision_score": 0.6818596452306717,
            "fpr": 0.19978046103183314,
            "logloss": 1.078078970441929,
            "mae": 0.43468806816392375,
            "precision": 0.6338028169014085,
            "recall": 0.6548856548856549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7476135538388371,
            "auditor_fn_violation": 0.0008391751047809805,
            "auditor_fp_violation": 0.0042485912960076875,
            "ave_precision_score": 0.5403307581294349,
            "fpr": 0.47039473684210525,
            "logloss": 14.399946418677162,
            "mae": 0.48437320359992403,
            "precision": 0.5158013544018059,
            "recall": 0.9661733615221987
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7515235295497296,
            "auditor_fn_violation": 0.003964024820226796,
            "auditor_fp_violation": 0.0012329921119138244,
            "ave_precision_score": 0.5485652271189114,
            "fpr": 0.46871569703622395,
            "logloss": 14.106887827683698,
            "mae": 0.48036283303558486,
            "precision": 0.5218365061590146,
            "recall": 0.9688149688149689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8269175465736291,
            "auditor_fn_violation": 0.0063216312451318596,
            "auditor_fp_violation": 0.03029462894137394,
            "ave_precision_score": 0.8272326032962698,
            "fpr": 0.20614035087719298,
            "logloss": 0.7772448834345022,
            "mae": 0.3032562170732215,
            "precision": 0.68561872909699,
            "recall": 0.8668076109936576
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8587280107090853,
            "auditor_fn_violation": 0.013158645430873753,
            "auditor_fp_violation": 0.0205013657366043,
            "ave_precision_score": 0.859157356502994,
            "fpr": 0.1942919868276619,
            "logloss": 0.7203657340490842,
            "mae": 0.27765055466013067,
            "precision": 0.7088815789473685,
            "recall": 0.896049896049896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.654662207070065,
            "auditor_fn_violation": 0.0021721189866844705,
            "auditor_fp_violation": 0.008264896295408237,
            "ave_precision_score": 0.6532066460537713,
            "fpr": 0.42214912280701755,
            "logloss": 1.7028695393612112,
            "mae": 0.410593741066374,
            "precision": 0.5486518171160609,
            "recall": 0.9894291754756871
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.638417526354281,
            "auditor_fn_violation": 0.0012642888603371588,
            "auditor_fp_violation": 0.006139432772572959,
            "ave_precision_score": 0.6359252925438956,
            "fpr": 0.42041712403951703,
            "logloss": 2.0324527805965786,
            "mae": 0.4004719572716304,
            "precision": 0.5556844547563805,
            "recall": 0.9958419958419958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6544809989988395,
            "auditor_fn_violation": 0.009221653499499279,
            "auditor_fp_violation": 0.02263667425968111,
            "ave_precision_score": 0.6559981408984185,
            "fpr": 0.3201754385964912,
            "logloss": 0.7059370769398136,
            "mae": 0.4492633278377956,
            "precision": 0.5938803894297635,
            "recall": 0.9027484143763214
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.6671305803022235,
            "auditor_fn_violation": 0.01038131773587317,
            "auditor_fp_violation": 0.021014474255226817,
            "ave_precision_score": 0.6689771507746728,
            "fpr": 0.3040614709110867,
            "logloss": 0.8297327494323342,
            "mae": 0.4422442349151051,
            "precision": 0.6136680613668062,
            "recall": 0.9147609147609148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7271649869753203,
            "auditor_fn_violation": 0.0184108527131783,
            "auditor_fp_violation": 0.01964942253127124,
            "ave_precision_score": 0.7278099227135832,
            "fpr": 0.11951754385964912,
            "logloss": 1.8876384180544885,
            "mae": 0.36525740170094506,
            "precision": 0.7093333333333334,
            "recall": 0.5623678646934461
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7506557847771141,
            "auditor_fn_violation": 0.026741763295001515,
            "auditor_fp_violation": 0.01321573532790443,
            "ave_precision_score": 0.7512086777124458,
            "fpr": 0.10208562019758508,
            "logloss": 2.1707624491163307,
            "mae": 0.36340154309564654,
            "precision": 0.7372881355932204,
            "recall": 0.5426195426195426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 12669,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6584431402975892,
            "auditor_fn_violation": 0.00012286265346240902,
            "auditor_fp_violation": 0.018715281940614642,
            "ave_precision_score": 0.6612716325093023,
            "fpr": 0.3925438596491228,
            "logloss": 1.5384874209195156,
            "mae": 0.42442871508109786,
            "precision": 0.5563816604708798,
            "recall": 0.9492600422832981
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7039537678506602,
            "auditor_fn_violation": 0.0034984744095611286,
            "auditor_fp_violation": 0.01973297934802033,
            "ave_precision_score": 0.7051539026154015,
            "fpr": 0.37980241492864986,
            "logloss": 1.4128637278849927,
            "mae": 0.40122927420181337,
            "precision": 0.5712515489467163,
            "recall": 0.9584199584199584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5646000756536177,
            "auditor_fn_violation": 0.006126905530210307,
            "auditor_fp_violation": 0.0013087959077648565,
            "ave_precision_score": 0.5575638078039247,
            "fpr": 0.023026315789473683,
            "logloss": 0.7089688471962365,
            "mae": 0.4924216902945773,
            "precision": 0.5625,
            "recall": 0.05708245243128964
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.5624718048070144,
            "auditor_fn_violation": 0.001234621432206515,
            "auditor_fp_violation": 0.004786460061777245,
            "ave_precision_score": 0.562451892918421,
            "fpr": 0.025246981339187707,
            "logloss": 0.6977045791666072,
            "mae": 0.4912782860214441,
            "precision": 0.54,
            "recall": 0.056133056133056136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8385507766677256,
            "auditor_fn_violation": 0.014991561885686734,
            "auditor_fp_violation": 0.014354294049474487,
            "ave_precision_score": 0.8264247312645838,
            "fpr": 0.125,
            "logloss": 0.5156028295984958,
            "mae": 0.31762524306561735,
            "precision": 0.7625,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.877212195648706,
            "auditor_fn_violation": 0.015951947894867768,
            "auditor_fp_violation": 0.012878768539555309,
            "ave_precision_score": 0.8661189186231866,
            "fpr": 0.10428100987925357,
            "logloss": 0.45443527036288284,
            "mae": 0.29732489658255873,
            "precision": 0.7991543340380549,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5874493829557828,
            "auditor_fn_violation": 0.01721931679092023,
            "auditor_fp_violation": 0.027954282060504338,
            "ave_precision_score": 0.5887278056489871,
            "fpr": 0.16557017543859648,
            "logloss": 4.014623327229826,
            "mae": 0.47430869330322223,
            "precision": 0.5648414985590778,
            "recall": 0.4143763213530655
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.603772577701819,
            "auditor_fn_violation": 0.01403725772551239,
            "auditor_fp_violation": 0.016677303244581727,
            "ave_precision_score": 0.604524753518718,
            "fpr": 0.16136114160263446,
            "logloss": 4.394472110538612,
            "mae": 0.48563755730549724,
            "precision": 0.5650887573964497,
            "recall": 0.3970893970893971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.8286396629619561,
            "auditor_fn_violation": 0.003569971440228478,
            "auditor_fp_violation": 0.011127262918115336,
            "ave_precision_score": 0.8287680258925245,
            "fpr": 0.4166666666666667,
            "logloss": 0.7794261007297048,
            "mae": 0.4102343284937792,
            "precision": 0.5486935866983373,
            "recall": 0.9767441860465116
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.8515228604683871,
            "auditor_fn_violation": 0.0011821329055138057,
            "auditor_fp_violation": 0.005212774104612871,
            "ave_precision_score": 0.8517167353851478,
            "fpr": 0.42151481888035125,
            "logloss": 0.7456410405948313,
            "mae": 0.39774461123489435,
            "precision": 0.5550405561993047,
            "recall": 0.9958419958419958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6081104005743738,
            "auditor_fn_violation": 0.05185731241422795,
            "auditor_fp_violation": 0.011931522998841067,
            "ave_precision_score": 0.6753291917440797,
            "fpr": 0.05263157894736842,
            "logloss": 0.6639559318737396,
            "mae": 0.441206868786953,
            "precision": 0.8291814946619217,
            "recall": 0.492600422832981
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.612912431808321,
            "auditor_fn_violation": 0.060359523586746434,
            "auditor_fp_violation": 0.00552676588466546,
            "ave_precision_score": 0.6940833508170889,
            "fpr": 0.05159165751920966,
            "logloss": 0.6536423168157677,
            "mae": 0.4396891912893197,
            "precision": 0.839041095890411,
            "recall": 0.5093555093555093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 12669,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7593201754385965,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.518640350877193,
            "fpr": 0.48135964912280704,
            "logloss": 0.6925698025535306,
            "mae": 0.4990193948411105,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7639956092206366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5279912184412733,
            "fpr": 0.47200878155872666,
            "logloss": 0.6915850590973422,
            "mae": 0.49852747765383004,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.725561132638401,
            "auditor_fn_violation": 0.01098113942361189,
            "auditor_fp_violation": 0.020069036486432486,
            "ave_precision_score": 0.7173796095441314,
            "fpr": 0.18421052631578946,
            "logloss": 0.6786262835182185,
            "mae": 0.3942572757585532,
            "precision": 0.6692913385826772,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7585437352140395,
            "auditor_fn_violation": 0.011930870328235865,
            "auditor_fp_violation": 0.010645087177392591,
            "ave_precision_score": 0.7525244588776887,
            "fpr": 0.1756311745334797,
            "logloss": 0.6267496951921577,
            "mae": 0.3698126597736964,
            "precision": 0.7014925373134329,
            "recall": 0.7817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7589516347857655,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.002777444750829247,
            "ave_precision_score": 0.6612706258765252,
            "fpr": 0.4769736842105263,
            "logloss": 6.231235016244454,
            "mae": 0.4657237836600919,
            "precision": 0.5203969128996693,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7785479127746694,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0009292114466596908,
            "ave_precision_score": 0.6808775916852411,
            "fpr": 0.4698133918770582,
            "logloss": 6.199828518189724,
            "mae": 0.45851278285425395,
            "precision": 0.5291529152915292,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7727856483110218,
            "auditor_fn_violation": 0.011400726976002376,
            "auditor_fp_violation": 0.022926407704911486,
            "ave_precision_score": 0.7742180916138931,
            "fpr": 0.16885964912280702,
            "logloss": 1.015808119720438,
            "mae": 0.3019174913975038,
            "precision": 0.69921875,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8178392032555398,
            "auditor_fn_violation": 0.016109413474945863,
            "auditor_fp_violation": 0.017256784009394236,
            "ave_precision_score": 0.8181426964969698,
            "fpr": 0.16245883644346873,
            "logloss": 0.8656667529863258,
            "mae": 0.2789694471275883,
            "precision": 0.7186311787072244,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7275307938713874,
            "auditor_fn_violation": 0.014861744742405696,
            "auditor_fp_violation": 0.01157435159653119,
            "ave_precision_score": 0.7282493691145188,
            "fpr": 0.1513157894736842,
            "logloss": 0.6326774287069056,
            "mae": 0.446408260417612,
            "precision": 0.6812933025404158,
            "recall": 0.6236786469344608
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7371719414782651,
            "auditor_fn_violation": 0.009226570148633824,
            "auditor_fp_violation": 0.010793148341970241,
            "ave_precision_score": 0.7377081086067409,
            "fpr": 0.1602634467618002,
            "logloss": 0.6288178229119651,
            "mae": 0.4446265931792238,
            "precision": 0.6741071428571429,
            "recall": 0.6278586278586279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7371666507946277,
            "auditor_fn_violation": 0.043894421571900155,
            "auditor_fp_violation": 0.034460796067617795,
            "ave_precision_score": 0.7045814319811987,
            "fpr": 0.10197368421052631,
            "logloss": 0.602525390503006,
            "mae": 0.4323971257339221,
            "precision": 0.7785714285714286,
            "recall": 0.6913319238900634
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7131535928076634,
            "auditor_fn_violation": 0.05208231113829358,
            "auditor_fp_violation": 0.036198401960534046,
            "ave_precision_score": 0.7050863337273624,
            "fpr": 0.10976948408342481,
            "logloss": 0.5947504662229166,
            "mae": 0.43236252777650924,
            "precision": 0.7737556561085973,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7912935931657903,
            "auditor_fn_violation": 0.008832202069656177,
            "auditor_fp_violation": 0.009783499180753712,
            "ave_precision_score": 0.7606653647634054,
            "fpr": 0.09868421052631579,
            "logloss": 0.5725264447266615,
            "mae": 0.35851023910697877,
            "precision": 0.7862232779097387,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8149271404829872,
            "auditor_fn_violation": 0.00743283180165727,
            "auditor_fp_violation": 0.0075817527378551595,
            "ave_precision_score": 0.7875643773339358,
            "fpr": 0.08562019758507135,
            "logloss": 0.5275050787284883,
            "mae": 0.33698314498255333,
            "precision": 0.8215102974828375,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.842728905073796,
            "auditor_fn_violation": 0.0003894514298431151,
            "auditor_fp_violation": 0.012710806058426252,
            "ave_precision_score": 0.8429828652594791,
            "fpr": 0.11403508771929824,
            "logloss": 0.516263587614306,
            "mae": 0.3263931100342521,
            "precision": 0.7714285714285715,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8581864664755554,
            "auditor_fn_violation": 0.006417292915646379,
            "auditor_fp_violation": 0.009327853368391491,
            "ave_precision_score": 0.8587581716390212,
            "fpr": 0.10098792535675083,
            "logloss": 0.47578423952576754,
            "mae": 0.3095596150789537,
            "precision": 0.8008658008658008,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 12669,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7593201754385965,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.518640350877193,
            "fpr": 0.48135964912280704,
            "logloss": 0.7155099636699487,
            "mae": 0.49537164168922526,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7639956092206366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5279912184412733,
            "fpr": 0.47200878155872666,
            "logloss": 0.7107672417006387,
            "mae": 0.49304984174627897,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5439551728087084,
            "auditor_fn_violation": 0.0093908794184192,
            "auditor_fp_violation": 0.0159603165088119,
            "ave_precision_score": 0.5487169423451496,
            "fpr": 0.3991228070175439,
            "logloss": 0.6892024072656966,
            "mae": 0.48984537653526977,
            "precision": 0.5432873274780426,
            "recall": 0.9154334038054969
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5794226059522753,
            "auditor_fn_violation": 0.013742865554062043,
            "auditor_fp_violation": 0.023802108595205908,
            "ave_precision_score": 0.5821998726820108,
            "fpr": 0.3929747530186608,
            "logloss": 0.6741943466273079,
            "mae": 0.4827486948896318,
            "precision": 0.554726368159204,
            "recall": 0.9272349272349273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7347539717130365,
            "auditor_fn_violation": 0.0048009161381254465,
            "auditor_fp_violation": 0.034258482196379336,
            "ave_precision_score": 0.7286539907427316,
            "fpr": 0.24013157894736842,
            "logloss": 1.6900710288511984,
            "mae": 0.3436292515085497,
            "precision": 0.6473429951690821,
            "recall": 0.8498942917547568
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7738686207625156,
            "auditor_fn_violation": 0.00876786606753676,
            "auditor_fp_violation": 0.021953896816684967,
            "ave_precision_score": 0.7693912390112055,
            "fpr": 0.23600439077936333,
            "logloss": 1.518202268516818,
            "mae": 0.32622305733468904,
            "precision": 0.6614173228346457,
            "recall": 0.8731808731808732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8420433515460506,
            "auditor_fn_violation": 0.005310912058158086,
            "auditor_fp_violation": 0.01139451704431923,
            "ave_precision_score": 0.8090132446935414,
            "fpr": 0.09539473684210527,
            "logloss": 0.5329997630351001,
            "mae": 0.320505563766091,
            "precision": 0.7918660287081339,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8795330433796396,
            "auditor_fn_violation": 0.009644196252319197,
            "auditor_fp_violation": 0.0025144870191203114,
            "ave_precision_score": 0.8516382918060763,
            "fpr": 0.08232711306256861,
            "logloss": 0.46371224940294337,
            "mae": 0.2964771706958503,
            "precision": 0.8271889400921659,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.83853506266531,
            "auditor_fn_violation": 0.002561570416527577,
            "auditor_fp_violation": 0.017349038884226512,
            "ave_precision_score": 0.8324588349834434,
            "fpr": 0.0756578947368421,
            "logloss": 0.5407654611581818,
            "mae": 0.3185514275928175,
            "precision": 0.8145161290322581,
            "recall": 0.6405919661733616
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8658937529120055,
            "auditor_fn_violation": 0.014940973228569288,
            "auditor_fp_violation": 0.011847445944911036,
            "ave_precision_score": 0.8623892635214622,
            "fpr": 0.06915477497255763,
            "logloss": 0.48097469573308477,
            "mae": 0.30349610398731036,
            "precision": 0.8405063291139241,
            "recall": 0.6902286902286903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 12669,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.7649125853306924,
            "auditor_fn_violation": 0.0014279885760913969,
            "auditor_fp_violation": 0.0005494944650921152,
            "ave_precision_score": 0.7656139267464059,
            "fpr": 0.0010964912280701754,
            "logloss": 5.071593803665688,
            "mae": 0.5026149777890508,
            "precision": 0.9230769230769231,
            "recall": 0.02536997885835095
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.8084043483559348,
            "auditor_fn_violation": 0.006709402977240528,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8087686962327256,
            "fpr": 0.0,
            "logloss": 4.879316458244786,
            "mae": 0.5050659294273651,
            "precision": 1.0,
            "recall": 0.0395010395010395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 12669,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8439995006201616,
            "auditor_fn_violation": 0.007063443492452063,
            "auditor_fp_violation": 0.016799544419134404,
            "ave_precision_score": 0.8442587346044297,
            "fpr": 0.16557017543859648,
            "logloss": 0.576376026040859,
            "mae": 0.3236319136849392,
            "precision": 0.7239488117001828,
            "recall": 0.8372093023255814
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8767072153683653,
            "auditor_fn_violation": 0.007747762961813457,
            "auditor_fp_violation": 0.012866004646057243,
            "ave_precision_score": 0.8769387507820047,
            "fpr": 0.15367727771679474,
            "logloss": 0.5633585245203669,
            "mae": 0.3051185160425492,
            "precision": 0.750445632798574,
            "recall": 0.8752598752598753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7976869625324895,
            "auditor_fn_violation": 0.02283854456437076,
            "auditor_fp_violation": 0.0412770251368741,
            "ave_precision_score": 0.7987471572635956,
            "fpr": 0.3333333333333333,
            "logloss": 2.5704301772485767,
            "mae": 0.38525595778077715,
            "precision": 0.5841313269493844,
            "recall": 0.9027484143763214
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.842190321020387,
            "auditor_fn_violation": 0.02945975613374077,
            "auditor_fp_violation": 0.035090496004901335,
            "ave_precision_score": 0.8422636429033183,
            "fpr": 0.33150384193194293,
            "logloss": 2.70435212494247,
            "mae": 0.3918023994875685,
            "precision": 0.587431693989071,
            "recall": 0.893970893970894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 12669,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5622806086101604,
            "auditor_fn_violation": 0.0033312006231222976,
            "auditor_fp_violation": 0.00836979978419854,
            "ave_precision_score": 0.5504285715705826,
            "fpr": 0.05921052631578947,
            "logloss": 0.755887891218579,
            "mae": 0.49421303347161594,
            "precision": 0.5645161290322581,
            "recall": 0.14799154334038056
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5480380078342465,
            "auditor_fn_violation": 0.006469781442339074,
            "auditor_fp_violation": 0.004176345952569373,
            "ave_precision_score": 0.540252399260233,
            "fpr": 0.05598243688254665,
            "logloss": 0.7785416921574412,
            "mae": 0.5029193045352672,
            "precision": 0.5233644859813084,
            "recall": 0.11642411642411643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.3900369866719057,
            "auditor_fn_violation": 0.003041430214012834,
            "auditor_fp_violation": 0.008886824121807942,
            "ave_precision_score": 0.3990835390108386,
            "fpr": 0.4550438596491228,
            "logloss": 0.6899197516937438,
            "mae": 0.4980297836948905,
            "precision": 0.52894438138479,
            "recall": 0.985200845665962
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.3869628765602115,
            "auditor_fn_violation": 0.0022410318787925813,
            "auditor_fp_violation": 0.00713501646542263,
            "ave_precision_score": 0.39692467739079434,
            "fpr": 0.45334796926454446,
            "logloss": 0.6912600009219775,
            "mae": 0.4988022278483168,
            "precision": 0.5338600451467269,
            "recall": 0.9833679833679834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7216838785040387,
            "auditor_fn_violation": 0.01418715922999889,
            "auditor_fp_violation": 7.493106342166418e-05,
            "ave_precision_score": 0.7195785207706673,
            "fpr": 0.29714912280701755,
            "logloss": 1.4506931150141003,
            "mae": 0.3766465421858719,
            "precision": 0.6049562682215743,
            "recall": 0.8773784355179705
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7466395876776918,
            "auditor_fn_violation": 0.009190056390934547,
            "auditor_fp_violation": 0.01306512138462718,
            "ave_precision_score": 0.7418451190524744,
            "fpr": 0.27661909989023054,
            "logloss": 1.445825980270805,
            "mae": 0.345664691848938,
            "precision": 0.6347826086956522,
            "recall": 0.9106029106029107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7641272827688776,
            "auditor_fn_violation": 0.012455491265160792,
            "auditor_fp_violation": 0.030389541621708028,
            "ave_precision_score": 0.6264944802836256,
            "fpr": 0.17653508771929824,
            "logloss": 0.6383694934087238,
            "mae": 0.4335056725039817,
            "precision": 0.6727642276422764,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7892597294353607,
            "auditor_fn_violation": 0.01845314029726763,
            "auditor_fp_violation": 0.01723125622239809,
            "ave_precision_score": 0.6582985386498009,
            "fpr": 0.15916575192096596,
            "logloss": 0.613308801153556,
            "mae": 0.4216467630850104,
            "precision": 0.7070707070707071,
            "recall": 0.7276507276507277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8065096496526012,
            "auditor_fn_violation": 0.0039014687882496933,
            "auditor_fp_violation": 0.015390840426807339,
            "ave_precision_score": 0.7622733435518816,
            "fpr": 0.0756578947368421,
            "logloss": 0.5761668403820074,
            "mae": 0.35268535863775596,
            "precision": 0.8050847457627118,
            "recall": 0.6025369978858351
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8240540900200546,
            "auditor_fn_violation": 0.007384907494676991,
            "auditor_fp_violation": 0.00950910065606413,
            "ave_precision_score": 0.7857319831138043,
            "fpr": 0.06695938529088913,
            "logloss": 0.5430068665905644,
            "mae": 0.3459273955153974,
            "precision": 0.8262108262108262,
            "recall": 0.6029106029106029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7085076554962707,
            "auditor_fn_violation": 0.031649883164571055,
            "auditor_fp_violation": 0.02962274707269313,
            "ave_precision_score": 0.7092482433594849,
            "fpr": 0.12280701754385964,
            "logloss": 2.8584308277644697,
            "mae": 0.3738417134420136,
            "precision": 0.6906077348066298,
            "recall": 0.5285412262156448
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.759641961301284,
            "auditor_fn_violation": 0.05165099237547099,
            "auditor_fp_violation": 0.024282030990733415,
            "ave_precision_score": 0.759940747809253,
            "fpr": 0.11964873765093303,
            "logloss": 3.0076355444631595,
            "mae": 0.35639205735247564,
            "precision": 0.712401055408971,
            "recall": 0.5613305613305614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7117932696450833,
            "auditor_fn_violation": 0.022465320277437792,
            "auditor_fp_violation": 0.011699236702233946,
            "ave_precision_score": 0.687373008353729,
            "fpr": 0.08662280701754387,
            "logloss": 0.6654035464387945,
            "mae": 0.4424103546291263,
            "precision": 0.7366666666666667,
            "recall": 0.46723044397463004
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7297461330670347,
            "auditor_fn_violation": 0.009183210061365944,
            "auditor_fp_violation": 0.008546703086309448,
            "ave_precision_score": 0.7167316309389433,
            "fpr": 0.10098792535675083,
            "logloss": 0.6416545269329639,
            "mae": 0.4334775457806828,
            "precision": 0.7169230769230769,
            "recall": 0.48440748440748443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6816475211252309,
            "auditor_fn_violation": 0.008108935128518976,
            "auditor_fp_violation": 0.014434220517124247,
            "ave_precision_score": 0.6755142520979917,
            "fpr": 0.13267543859649122,
            "logloss": 5.443999257014531,
            "mae": 0.36204373212084834,
            "precision": 0.6944444444444444,
            "recall": 0.5813953488372093
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6907407208758092,
            "auditor_fn_violation": 0.008389035831406854,
            "auditor_fp_violation": 0.019472595920659645,
            "ave_precision_score": 0.6945586854965984,
            "fpr": 0.11964873765093303,
            "logloss": 6.066067847883036,
            "mae": 0.36749167076598555,
            "precision": 0.707774798927614,
            "recall": 0.5488565488565489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7848077656553125,
            "auditor_fn_violation": 0.05036209710322317,
            "auditor_fp_violation": 0.05889581584941854,
            "ave_precision_score": 0.7679010409922652,
            "fpr": 0.17653508771929824,
            "logloss": 0.6071910221517893,
            "mae": 0.346035772918217,
            "precision": 0.6915708812260536,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8197346440544746,
            "auditor_fn_violation": 0.05190202445965344,
            "auditor_fp_violation": 0.04782630893727823,
            "ave_precision_score": 0.7993681062581691,
            "fpr": 0.16136114160263446,
            "logloss": 0.5566570710840051,
            "mae": 0.3299609559836555,
            "precision": 0.7183908045977011,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.49215162174930593,
            "auditor_fn_violation": 0.00039176959311598247,
            "auditor_fp_violation": 0.0026275826239859417,
            "ave_precision_score": 0.49348429441725217,
            "fpr": 0.46710526315789475,
            "logloss": 0.6951609979996524,
            "mae": 0.4980629572416084,
            "precision": 0.5245535714285714,
            "recall": 0.9936575052854123
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.5152977061835834,
            "auditor_fn_violation": 0.0005317315964955921,
            "auditor_fp_violation": 0.002537462027416845,
            "ave_precision_score": 0.5169799182700232,
            "fpr": 0.4621295279912184,
            "logloss": 0.6921346577628997,
            "mae": 0.49658175242980934,
            "precision": 0.532741398446171,
            "recall": 0.997920997920998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6899725067136078,
            "auditor_fn_violation": 0.0003361336745669714,
            "auditor_fp_violation": 0.013934680094313237,
            "ave_precision_score": 0.6905007991296785,
            "fpr": 0.25877192982456143,
            "logloss": 0.9152111397997497,
            "mae": 0.39113638916342897,
            "precision": 0.6230031948881789,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7422790827697159,
            "auditor_fn_violation": 0.0024053437884392925,
            "auditor_fp_violation": 0.010466392668419573,
            "ave_precision_score": 0.7436566344462703,
            "fpr": 0.2414928649835346,
            "logloss": 0.821684873636796,
            "mae": 0.3671539027497385,
            "precision": 0.6496815286624203,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 12669,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6779973255456655,
            "auditor_fn_violation": 0.021716553540298947,
            "auditor_fp_violation": 0.024774707269312232,
            "ave_precision_score": 0.6717555188546,
            "fpr": 0.19736842105263158,
            "logloss": 2.3975721074889615,
            "mae": 0.3739105128019784,
            "precision": 0.6288659793814433,
            "recall": 0.6448202959830867
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7344842753110562,
            "auditor_fn_violation": 0.025751327617408847,
            "auditor_fp_violation": 0.014305771832639836,
            "ave_precision_score": 0.7303442972590097,
            "fpr": 0.1800219538968167,
            "logloss": 2.0477832487493175,
            "mae": 0.334846034749375,
            "precision": 0.6706827309236948,
            "recall": 0.6943866943866944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7802155605762,
            "auditor_fn_violation": 0.01754617781239569,
            "auditor_fp_violation": 0.012905626823322545,
            "ave_precision_score": 0.7597102087059941,
            "fpr": 0.08114035087719298,
            "logloss": 4.5602001648875135,
            "mae": 0.36554981977676737,
            "precision": 0.7817109144542773,
            "recall": 0.5602536997885835
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.780856500845472,
            "auditor_fn_violation": 0.031541040322599065,
            "auditor_fp_violation": 0.011906159855002173,
            "ave_precision_score": 0.7604421375611918,
            "fpr": 0.06695938529088913,
            "logloss": 4.331499616118252,
            "mae": 0.3701142286732179,
            "precision": 0.8105590062111802,
            "recall": 0.5426195426195426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7113429122832506,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.7127786974300195,
            "fpr": 0.47368421052631576,
            "logloss": 0.8452291089352794,
            "mae": 0.48519997919599217,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7079510223150467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.7094133799223801,
            "fpr": 0.4665203073545554,
            "logloss": 0.837940142321869,
            "mae": 0.4807409311426981,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7160490853932702,
            "auditor_fn_violation": 0.0030947479692889743,
            "auditor_fp_violation": 0.014978719577988258,
            "ave_precision_score": 0.6653567840429034,
            "fpr": 0.22807017543859648,
            "logloss": 0.7757391816336078,
            "mae": 0.38832100591900054,
            "precision": 0.6655948553054662,
            "recall": 0.8752642706131079
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7508066222543802,
            "auditor_fn_violation": 0.0031744148099801233,
            "auditor_fp_violation": 0.010698695530084507,
            "ave_precision_score": 0.6994602921553671,
            "fpr": 0.21624588364434688,
            "logloss": 0.7394195832366791,
            "mae": 0.37641339345899555,
            "precision": 0.688783570300158,
            "recall": 0.9064449064449065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7182060705559365,
            "auditor_fn_violation": 0.012455491265160792,
            "auditor_fp_violation": 0.030389541621708028,
            "ave_precision_score": 0.6443518346198558,
            "fpr": 0.17653508771929824,
            "logloss": 0.6350347958277074,
            "mae": 0.4302681560644455,
            "precision": 0.6727642276422764,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7533361302552166,
            "auditor_fn_violation": 0.01845314029726763,
            "auditor_fp_violation": 0.01723125622239809,
            "ave_precision_score": 0.6803245903271466,
            "fpr": 0.15916575192096596,
            "logloss": 0.6127250528384772,
            "mae": 0.41945344765806564,
            "precision": 0.7070707070707071,
            "recall": 0.7276507276507277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 12669,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8038566221073976,
            "auditor_fn_violation": 0.017866084344052534,
            "auditor_fp_violation": 0.012371118570914759,
            "ave_precision_score": 0.7981449398900745,
            "fpr": 0.044956140350877194,
            "logloss": 0.6452063811510897,
            "mae": 0.39936626177248463,
            "precision": 0.8379446640316206,
            "recall": 0.44820295983086683
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8334697286243009,
            "auditor_fn_violation": 0.028948563525951022,
            "auditor_fp_violation": 0.010951420621346334,
            "ave_precision_score": 0.8329661302999478,
            "fpr": 0.043907793633369926,
            "logloss": 0.601651467958784,
            "mae": 0.3894559973983746,
            "precision": 0.8518518518518519,
            "recall": 0.4781704781704782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5933632685369516,
            "auditor_fn_violation": 0.059632432031452846,
            "auditor_fp_violation": 0.03122627182991648,
            "ave_precision_score": 0.5589845089991949,
            "fpr": 0.051535087719298246,
            "logloss": 0.7462785289475662,
            "mae": 0.4951826173714117,
            "precision": 0.7151515151515152,
            "recall": 0.24947145877378435
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6450020688256655,
            "auditor_fn_violation": 0.07212151778562317,
            "auditor_fp_violation": 0.021177852092002146,
            "ave_precision_score": 0.6047232296737894,
            "fpr": 0.03732162458836443,
            "logloss": 0.7282684854343364,
            "mae": 0.48713983493958296,
            "precision": 0.807909604519774,
            "recall": 0.2972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 12669,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8359865332493012,
            "auditor_fn_violation": 0.0030854753161974726,
            "auditor_fp_violation": 0.016252547656156337,
            "ave_precision_score": 0.8363018526753364,
            "fpr": 0.12938596491228072,
            "logloss": 0.5221451818484467,
            "mae": 0.33354248431625594,
            "precision": 0.7546777546777547,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8621457172082084,
            "auditor_fn_violation": 0.0075811689423105465,
            "auditor_fp_violation": 0.0076608888775432085,
            "ave_precision_score": 0.8623872638242219,
            "fpr": 0.11306256860592755,
            "logloss": 0.47674317713190145,
            "mae": 0.3147262006540068,
            "precision": 0.7871900826446281,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7996672857077656,
            "auditor_fn_violation": 0.01012110084937503,
            "auditor_fp_violation": 0.02789183950765296,
            "ave_precision_score": 0.7999492275355228,
            "fpr": 0.16228070175438597,
            "logloss": 0.8104570530573273,
            "mae": 0.32434092045150464,
            "precision": 0.6942148760330579,
            "recall": 0.7103594080338267
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8256579419791205,
            "auditor_fn_violation": 0.018008128875307804,
            "auditor_fp_violation": 0.018305976054935797,
            "ave_precision_score": 0.8261141587166227,
            "fpr": 0.150384193194292,
            "logloss": 0.7241034820848865,
            "mae": 0.3023791863928313,
            "precision": 0.7243460764587525,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6655095534969161,
            "auditor_fn_violation": 0.0138069804532473,
            "auditor_fp_violation": 0.004081245254365985,
            "ave_precision_score": 0.6552647821467606,
            "fpr": 0.02412280701754386,
            "logloss": 10.131405607838696,
            "mae": 0.4376185637478964,
            "precision": 0.8253968253968254,
            "recall": 0.21987315010570824
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6665142744040313,
            "auditor_fn_violation": 0.011917177669098656,
            "auditor_fp_violation": 0.0029867510785490004,
            "ave_precision_score": 0.6637345158970058,
            "fpr": 0.026344676180021953,
            "logloss": 10.337026745220557,
            "mae": 0.4348775473569478,
            "precision": 0.8367346938775511,
            "recall": 0.25571725571725573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7934892173454194,
            "auditor_fn_violation": 0.008261933904528774,
            "auditor_fp_violation": 0.0074731247252527696,
            "ave_precision_score": 0.7677579853508462,
            "fpr": 0.08771929824561403,
            "logloss": 0.5774547529449792,
            "mae": 0.3742352624101107,
            "precision": 0.7894736842105263,
            "recall": 0.6342494714587738
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8176520869144972,
            "auditor_fn_violation": 0.0048357907852968314,
            "auditor_fp_violation": 0.008398641921731809,
            "ave_precision_score": 0.798409644492158,
            "fpr": 0.09879253567508232,
            "logloss": 0.5760507177814287,
            "mae": 0.3781095152285306,
            "precision": 0.7686375321336761,
            "recall": 0.6216216216216216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5058368761704755,
            "auditor_fn_violation": 0.010753959422870073,
            "auditor_fp_violation": 0.021260440394836762,
            "ave_precision_score": 0.5329151712068343,
            "fpr": 0.4232456140350877,
            "logloss": 0.6882533880688455,
            "mae": 0.4962346155784632,
            "precision": 0.5371702637889688,
            "recall": 0.9471458773784355
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.4531839471439985,
            "auditor_fn_violation": 0.012903049126978875,
            "auditor_fp_violation": 0.014757613662471598,
            "ave_precision_score": 0.5422418829447133,
            "fpr": 0.40504939626783754,
            "logloss": 0.6870595825400179,
            "mae": 0.49564933050607873,
            "precision": 0.5488997555012225,
            "recall": 0.9334719334719335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7796012004269041,
            "auditor_fn_violation": 0.0014048069433626347,
            "auditor_fp_violation": 0.024172761059824965,
            "ave_precision_score": 0.7516228681388817,
            "fpr": 0.17653508771929824,
            "logloss": 0.5871100818650864,
            "mae": 0.37176797555334734,
            "precision": 0.6933333333333334,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.825918500852601,
            "auditor_fn_violation": 0.01877948200670484,
            "auditor_fp_violation": 0.015794041814515103,
            "ave_precision_score": 0.8006433188086417,
            "fpr": 0.17233809001097694,
            "logloss": 0.5320888758153725,
            "mae": 0.35102958283688707,
            "precision": 0.7171171171171171,
            "recall": 0.8274428274428275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8081366336176823,
            "auditor_fn_violation": 0.00907560921330811,
            "auditor_fp_violation": 0.020368760740119098,
            "ave_precision_score": 0.7685110539207193,
            "fpr": 0.17324561403508773,
            "logloss": 0.5450685167592677,
            "mae": 0.3484106800077777,
            "precision": 0.7084870848708487,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8575683569035428,
            "auditor_fn_violation": 0.011125285548995759,
            "auditor_fp_violation": 0.010747198325377178,
            "ave_precision_score": 0.8242524819882625,
            "fpr": 0.16136114160263446,
            "logloss": 0.4903130020843762,
            "mae": 0.32868518717955025,
            "precision": 0.738898756660746,
            "recall": 0.8648648648648649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5718182939321703,
            "auditor_fn_violation": 0.0004219057156633658,
            "auditor_fp_violation": 0.0045757902729489115,
            "ave_precision_score": 0.4682142048535897,
            "fpr": 0.45723684210526316,
            "logloss": 9.936028020741809,
            "mae": 0.4628047207789087,
            "precision": 0.5293453724604966,
            "recall": 0.9915433403805497
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.550194260280194,
            "auditor_fn_violation": 0.0026472474331969394,
            "auditor_fp_violation": 0.0015035866540729628,
            "ave_precision_score": 0.452898894702099,
            "fpr": 0.45334796926454446,
            "logloss": 10.32837008687169,
            "mae": 0.4648906430505568,
            "precision": 0.5359550561797752,
            "recall": 0.9916839916839917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8295967353122371,
            "auditor_fn_violation": 0.005113868179963651,
            "auditor_fp_violation": 0.024245194421132567,
            "ave_precision_score": 0.8298395354465912,
            "fpr": 0.3168859649122807,
            "logloss": 0.9817132948067081,
            "mae": 0.3619110818630782,
            "precision": 0.6089309878213802,
            "recall": 0.9513742071881607
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8314629844630734,
            "auditor_fn_violation": 0.001944357597486028,
            "auditor_fp_violation": 0.00991499246930285,
            "ave_precision_score": 0.8315597671662625,
            "fpr": 0.30954994511525796,
            "logloss": 0.9318408292641848,
            "mae": 0.34190677374969725,
            "precision": 0.6259946949602122,
            "recall": 0.9812889812889813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7494143285986969,
            "auditor_fn_violation": 0.007381031860836028,
            "auditor_fp_violation": 0.011014866322982866,
            "ave_precision_score": 0.7506602934983911,
            "fpr": 0.19736842105263158,
            "logloss": 0.6110218234407815,
            "mae": 0.39395271235144447,
            "precision": 0.6709323583180987,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7964367234319091,
            "auditor_fn_violation": 0.009760583854985615,
            "auditor_fp_violation": 0.010772726112373322,
            "ave_precision_score": 0.7955748480977541,
            "fpr": 0.1756311745334797,
            "logloss": 0.5812534532651861,
            "mae": 0.3816797818140557,
            "precision": 0.6946564885496184,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7997074380724638,
            "auditor_fn_violation": 0.0035491079707725966,
            "auditor_fp_violation": 0.007917715701554572,
            "ave_precision_score": 0.6862152376304905,
            "fpr": 0.16447368421052633,
            "logloss": 0.5984080220353284,
            "mae": 0.37684962127292365,
            "precision": 0.708171206225681,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8373081181699844,
            "auditor_fn_violation": 0.006314597972117183,
            "auditor_fp_violation": 0.005427207515380493,
            "ave_precision_score": 0.7348110641549341,
            "fpr": 0.1525795828759605,
            "logloss": 0.5402632885876834,
            "mae": 0.3520929213740038,
            "precision": 0.7425925925925926,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6069964886994431,
            "auditor_fn_violation": 0.0027052965394458663,
            "auditor_fp_violation": 0.003634156575950122,
            "ave_precision_score": 0.5318050408698337,
            "fpr": 0.4682017543859649,
            "logloss": 0.7359562322660025,
            "mae": 0.4942816299299011,
            "precision": 0.5213004484304933,
            "recall": 0.9830866807610994
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6226356747392479,
            "auditor_fn_violation": 0.0008147132186649202,
            "auditor_fp_violation": 0.0018380006637224615,
            "ave_precision_score": 0.5436037421879067,
            "fpr": 0.4610318331503842,
            "logloss": 0.7372023743008717,
            "mae": 0.4940776284445439,
            "precision": 0.5296752519596865,
            "recall": 0.9833679833679834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 12669,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7209639700451984,
            "auditor_fn_violation": 0.010791050035236104,
            "auditor_fp_violation": 0.011881568956559964,
            "ave_precision_score": 0.7226752634119509,
            "fpr": 0.05263157894736842,
            "logloss": 0.8355966176130714,
            "mae": 0.4044773635911968,
            "precision": 0.7272727272727273,
            "recall": 0.27061310782241016
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7423649073530945,
            "auditor_fn_violation": 0.014343060446243765,
            "auditor_fp_violation": 0.009478467311668752,
            "ave_precision_score": 0.7483275509481582,
            "fpr": 0.05598243688254665,
            "logloss": 0.8117338560409323,
            "mae": 0.3909948091446928,
            "precision": 0.75,
            "recall": 0.3180873180873181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7582027729690858,
            "auditor_fn_violation": 0.010763232075961578,
            "auditor_fp_violation": 0.033609079646725014,
            "ave_precision_score": 0.7034246231066332,
            "fpr": 0.20614035087719298,
            "logloss": 5.116372250973999,
            "mae": 0.32602401256030666,
            "precision": 0.6612612612612613,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7828610332742931,
            "auditor_fn_violation": 0.01629654648315461,
            "auditor_fp_violation": 0.017009164475531614,
            "ave_precision_score": 0.7338159038204627,
            "fpr": 0.18551042810098792,
            "logloss": 4.600771149414401,
            "mae": 0.30335718494090996,
            "precision": 0.6927272727272727,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7262370099910286,
            "auditor_fn_violation": 0.008554022476911102,
            "auditor_fp_violation": 0.006504016304999404,
            "ave_precision_score": 0.6589426999076557,
            "fpr": 0.16776315789473684,
            "logloss": 0.6330078627819513,
            "mae": 0.42847347078158665,
            "precision": 0.6569506726457399,
            "recall": 0.6194503171247357
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7384001784022877,
            "auditor_fn_violation": 0.007035744686677728,
            "auditor_fp_violation": 0.011308809639292372,
            "ave_precision_score": 0.6713347633438077,
            "fpr": 0.15587266739846323,
            "logloss": 0.6269465468379174,
            "mae": 0.42527598752737306,
            "precision": 0.6830357142857143,
            "recall": 0.6361746361746362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7168799600404834,
            "auditor_fn_violation": 0.013213530655391133,
            "auditor_fp_violation": 0.03126873276585542,
            "ave_precision_score": 0.713913786482245,
            "fpr": 0.1787280701754386,
            "logloss": 0.9652973319268141,
            "mae": 0.3617398418266748,
            "precision": 0.6713709677419355,
            "recall": 0.7040169133192389
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7606358587633844,
            "auditor_fn_violation": 0.019648965861918662,
            "auditor_fp_violation": 0.017318050698184973,
            "ave_precision_score": 0.758954362937335,
            "fpr": 0.1602634467618002,
            "logloss": 0.9002365024446082,
            "mae": 0.3390636273177176,
            "precision": 0.7056451612903226,
            "recall": 0.7276507276507277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8574960523401789,
            "auditor_fn_violation": 0.003785560624605911,
            "auditor_fp_violation": 0.012393597889941255,
            "ave_precision_score": 0.8576859951753543,
            "fpr": 0.09649122807017543,
            "logloss": 0.5753597171277066,
            "mae": 0.2983348225288014,
            "precision": 0.794392523364486,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8753424438441122,
            "auditor_fn_violation": 0.006627247022417172,
            "auditor_fp_violation": 0.0028591121435682766,
            "ave_precision_score": 0.8765596475719344,
            "fpr": 0.08781558726673985,
            "logloss": 0.47620925546349024,
            "mae": 0.27592500108650675,
            "precision": 0.8210290827740492,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8179091535537073,
            "auditor_fn_violation": 0.01079336819850896,
            "auditor_fp_violation": 0.0167995444191344,
            "ave_precision_score": 0.7790667536479402,
            "fpr": 0.19188596491228072,
            "logloss": 0.5558559779824988,
            "mae": 0.35795637845927686,
            "precision": 0.6929824561403509,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8423899161556783,
            "auditor_fn_violation": 0.01374058344420584,
            "auditor_fp_violation": 0.018622520613687996,
            "ave_precision_score": 0.810044524367719,
            "fpr": 0.19209659714599342,
            "logloss": 0.5340793825207909,
            "mae": 0.3532556699411013,
            "precision": 0.7033898305084746,
            "recall": 0.8627858627858628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7682308217105649,
            "auditor_fn_violation": 0.009205426356589146,
            "auditor_fp_violation": 0.027047616193102347,
            "ave_precision_score": 0.7298453361502968,
            "fpr": 0.15460526315789475,
            "logloss": 2.6636146643009595,
            "mae": 0.34268033652030244,
            "precision": 0.7116564417177914,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8030833561360671,
            "auditor_fn_violation": 0.01694010146260421,
            "auditor_fp_violation": 0.01615908916855998,
            "ave_precision_score": 0.7706391506854233,
            "fpr": 0.14489571899012074,
            "logloss": 2.3300381856174037,
            "mae": 0.32439132977599777,
            "precision": 0.7441860465116279,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8272077756043527,
            "auditor_fn_violation": 0.0033914728682170573,
            "auditor_fp_violation": 0.014166966390920353,
            "ave_precision_score": 0.8180470399949552,
            "fpr": 0.0800438596491228,
            "logloss": 0.5347533543307393,
            "mae": 0.32234581279682745,
            "precision": 0.8137755102040817,
            "recall": 0.6744186046511628
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8672699768488764,
            "auditor_fn_violation": 0.013448473382611697,
            "auditor_fp_violation": 0.010425548209225746,
            "ave_precision_score": 0.8594622004301828,
            "fpr": 0.059275521405049394,
            "logloss": 0.464594196081664,
            "mae": 0.29878798702938236,
            "precision": 0.8629441624365483,
            "recall": 0.7068607068607069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8316197018745686,
            "auditor_fn_violation": 0.005586773487630283,
            "auditor_fp_violation": 0.01371488230827639,
            "ave_precision_score": 0.8318959788841093,
            "fpr": 0.19407894736842105,
            "logloss": 0.5643493768793663,
            "mae": 0.33704970171675086,
            "precision": 0.6963979416809606,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8602182702589014,
            "auditor_fn_violation": 0.0008329700975145549,
            "auditor_fp_violation": 0.005570163122558907,
            "ave_precision_score": 0.8606014675621078,
            "fpr": 0.18331503841931943,
            "logloss": 0.5238567768979695,
            "mae": 0.32167068107460517,
            "precision": 0.7235099337748344,
            "recall": 0.9085239085239085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8333464034516281,
            "auditor_fn_violation": 0.013030395756833948,
            "auditor_fp_violation": 0.013477600607441154,
            "ave_precision_score": 0.8227720188230859,
            "fpr": 0.15789473684210525,
            "logloss": 0.538910366323343,
            "mae": 0.3254989340509239,
            "precision": 0.7277882797731569,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.84892434954807,
            "auditor_fn_violation": 0.008660606904295164,
            "auditor_fp_violation": 0.018390217752023083,
            "ave_precision_score": 0.8564554461948283,
            "fpr": 0.15148188803512624,
            "logloss": 0.4827451755180616,
            "mae": 0.30462857665397985,
            "precision": 0.7463235294117647,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.800548506423354,
            "auditor_fn_violation": 0.005354957160342718,
            "auditor_fp_violation": 0.01337019941653679,
            "ave_precision_score": 0.748131791374639,
            "fpr": 0.09539473684210527,
            "logloss": 0.561010674821251,
            "mae": 0.3579903084359932,
            "precision": 0.7913669064748201,
            "recall": 0.6976744186046512
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8524504628191287,
            "auditor_fn_violation": 0.007941742299590824,
            "auditor_fp_violation": 0.002131570214178134,
            "ave_precision_score": 0.7901324414927422,
            "fpr": 0.08232711306256861,
            "logloss": 0.5175081446645288,
            "mae": 0.3395754539547846,
            "precision": 0.8267898383371824,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7552792019687684,
            "auditor_fn_violation": 0.03428563480583065,
            "auditor_fp_violation": 0.03433341325980099,
            "ave_precision_score": 0.7557625518479774,
            "fpr": 0.39473684210526316,
            "logloss": 0.6671898098598003,
            "mae": 0.4757776338803141,
            "precision": 0.535483870967742,
            "recall": 0.8773784355179705
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.754573710453994,
            "auditor_fn_violation": 0.03856765656985196,
            "auditor_fp_violation": 0.03949148648303679,
            "ave_precision_score": 0.7550282577446548,
            "fpr": 0.3787047200878156,
            "logloss": 0.6690998336310164,
            "mae": 0.47654018686055877,
            "precision": 0.5466491458607096,
            "recall": 0.8648648648648649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8171662543949958,
            "auditor_fn_violation": 0.009631968398798266,
            "auditor_fp_violation": 0.01337019941653679,
            "ave_precision_score": 0.7519080384867152,
            "fpr": 0.09539473684210527,
            "logloss": 0.5553875993345078,
            "mae": 0.3492961625400836,
            "precision": 0.7903614457831325,
            "recall": 0.693446088794926
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.859478156778744,
            "auditor_fn_violation": 0.008434678028530944,
            "auditor_fp_violation": 0.003706634671840299,
            "ave_precision_score": 0.8024664921765052,
            "fpr": 0.08122941822173436,
            "logloss": 0.5000785941148759,
            "mae": 0.3266887613014893,
            "precision": 0.8283062645011601,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6609967712717943,
            "auditor_fn_violation": 0.004606190423203887,
            "auditor_fp_violation": 0.02689275866203093,
            "ave_precision_score": 0.6519054761033081,
            "fpr": 0.21820175438596492,
            "logloss": 8.75419449435133,
            "mae": 0.4337785753159646,
            "precision": 0.5810526315789474,
            "recall": 0.5835095137420718
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6843475895518087,
            "auditor_fn_violation": 0.0063282906312544076,
            "auditor_fp_violation": 0.023682127996324014,
            "ave_precision_score": 0.678220156915146,
            "fpr": 0.23161361141602635,
            "logloss": 9.315875074084227,
            "mae": 0.4592737674895542,
            "precision": 0.5631469979296067,
            "recall": 0.5654885654885655
        }
    }
]