[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7544675221110627,
            "auditor_fn_violation": 0.03559971726837757,
            "auditor_fp_violation": 0.015788961305131993,
            "ave_precision_score": 0.6299955843779245,
            "fpr": 0.04276315789473684,
            "logloss": 0.6433633801808252,
            "mae": 0.45690618406393024,
            "precision": 0.8133971291866029,
            "recall": 0.3512396694214876
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7223111485645288,
            "auditor_fn_violation": 0.031099796809678407,
            "auditor_fp_violation": 0.011337868480725623,
            "ave_precision_score": 0.5966976372057929,
            "fpr": 0.043907793633369926,
            "logloss": 0.6580289086950438,
            "mae": 0.4659152098335367,
            "precision": 0.7814207650273224,
            "recall": 0.30425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5378418961336016,
            "auditor_fn_violation": 0.00648832825866319,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5329820951217923,
            "fpr": 0.3048245614035088,
            "logloss": 0.9823488724400722,
            "mae": 0.4846448889819154,
            "precision": 0.5304054054054054,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.496984499791403,
            "auditor_fn_violation": 0.006997220730083849,
            "auditor_fp_violation": 0.015743582467747434,
            "ave_precision_score": 0.4986799616515124,
            "fpr": 0.3040614709110867,
            "logloss": 0.9990926108862873,
            "mae": 0.49646031120475115,
            "precision": 0.5079928952042628,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6951745656868483,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.6755365778160268,
            "fpr": 0.3048245614035088,
            "logloss": 0.8977549630359363,
            "mae": 0.46731129987982284,
            "precision": 0.5435139573070608,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6792337585902782,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015235805262463565,
            "ave_precision_score": 0.6592349383015276,
            "fpr": 0.3084522502744237,
            "logloss": 0.916861073571611,
            "mae": 0.4798385282379343,
            "precision": 0.5212947189097104,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6274697427187608,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.546220828354198,
            "fpr": 0.0,
            "logloss": 0.6901780985494735,
            "mae": 0.4959599408402778,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5946144281250665,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5401476183391078,
            "fpr": 0.005488474204171241,
            "logloss": 0.6916165550928721,
            "mae": 0.4947120451115881,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.539523508404708,
            "auditor_fn_violation": 0.00648832825866319,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5357784560287212,
            "fpr": 0.3048245614035088,
            "logloss": 0.9820042331484606,
            "mae": 0.4846571745318279,
            "precision": 0.5304054054054054,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.503667680039944,
            "auditor_fn_violation": 0.006997220730083849,
            "auditor_fp_violation": 0.015743582467747434,
            "ave_precision_score": 0.5017321346291275,
            "fpr": 0.3040614709110867,
            "logloss": 0.9987557382444173,
            "mae": 0.4964668079474624,
            "precision": 0.5079928952042628,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7647766102698955,
            "auditor_fn_violation": 0.0021522038567493114,
            "auditor_fp_violation": 0.010224524512215116,
            "ave_precision_score": 0.5675470534974667,
            "fpr": 0.4418859649122807,
            "logloss": 0.6837116441118346,
            "mae": 0.47749958664440273,
            "precision": 0.5420454545454545,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7032860816233635,
            "auditor_fn_violation": 0.004390779363336992,
            "auditor_fp_violation": 0.004219031190961568,
            "ave_precision_score": 0.5580613795437234,
            "fpr": 0.4566410537870472,
            "logloss": 0.6953947076163303,
            "mae": 0.47976397044964864,
            "precision": 0.5261958997722096,
            "recall": 0.9829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7584923809607095,
            "auditor_fn_violation": 0.0021522038567493114,
            "auditor_fp_violation": 0.010224524512215116,
            "ave_precision_score": 0.5723384977354095,
            "fpr": 0.4418859649122807,
            "logloss": 0.679460991054497,
            "mae": 0.4757546824321412,
            "precision": 0.5420454545454545,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7072781679417609,
            "auditor_fn_violation": 0.004390779363336992,
            "auditor_fp_violation": 0.004219031190961568,
            "ave_precision_score": 0.5601054069968422,
            "fpr": 0.4566410537870472,
            "logloss": 0.6909936883307973,
            "mae": 0.4789970091551248,
            "precision": 0.5261958997722096,
            "recall": 0.9829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 2917,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.726034221096286,
            "auditor_fn_violation": 0.015833423952443092,
            "auditor_fp_violation": 0.02172487292998852,
            "ave_precision_score": 0.7104337157376768,
            "fpr": 0.18530701754385964,
            "logloss": 2.3773863982766055,
            "mae": 0.36392154551139017,
            "precision": 0.6479166666666667,
            "recall": 0.6425619834710744
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7229645962956309,
            "auditor_fn_violation": 0.02538944811640237,
            "auditor_fp_violation": 0.024821344564170345,
            "ave_precision_score": 0.7115124134269278,
            "fpr": 0.18331503841931943,
            "logloss": 2.142761386983582,
            "mae": 0.36095478156754723,
            "precision": 0.6476793248945147,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5810162524856493,
            "auditor_fn_violation": 0.0070229810062346085,
            "auditor_fp_violation": 0.008285169699950811,
            "ave_precision_score": 0.55339588124878,
            "fpr": 0.041666666666666664,
            "logloss": 0.688918730079035,
            "mae": 0.4955801951551908,
            "precision": 0.6122448979591837,
            "recall": 0.12396694214876033
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5559836461078348,
            "auditor_fn_violation": 0.005381040241025773,
            "auditor_fp_violation": 0.006708135138431517,
            "ave_precision_score": 0.541287555466536,
            "fpr": 0.05378704720087816,
            "logloss": 0.6922646907031373,
            "mae": 0.4952800326564571,
            "precision": 0.5663716814159292,
            "recall": 0.13617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7764061741698788,
            "auditor_fn_violation": 0.001644736842105263,
            "auditor_fp_violation": 0.00890771028037384,
            "ave_precision_score": 0.6733062523005984,
            "fpr": 0.4440789473684211,
            "logloss": 0.64342920337125,
            "mae": 0.4398500785362302,
            "precision": 0.5428893905191874,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7364836801671144,
            "auditor_fn_violation": 0.003613050891001238,
            "auditor_fp_violation": 0.00384317649489361,
            "ave_precision_score": 0.6428512259659314,
            "fpr": 0.4588364434687157,
            "logloss": 0.6660761151985118,
            "mae": 0.45019519227658095,
            "precision": 0.5255391600454029,
            "recall": 0.9851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6289905560024208,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5482614171876473,
            "fpr": 0.0,
            "logloss": 0.6889051705689312,
            "mae": 0.4954331373763189,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.592479707890397,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5388182960331185,
            "fpr": 0.005488474204171241,
            "logloss": 0.6913871130744069,
            "mae": 0.4947872708186622,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6231306154616079,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5557786929333464,
            "fpr": 0.0,
            "logloss": 0.6885474623353367,
            "mae": 0.4955264992293036,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5468302016272216,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5210652155131341,
            "fpr": 0.005488474204171241,
            "logloss": 0.6929183348466829,
            "mae": 0.4957343379176671,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6231306154616079,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5557786929333464,
            "fpr": 0.0,
            "logloss": 0.6885474623353367,
            "mae": 0.4955264992293036,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5468302016272216,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5210652155131341,
            "fpr": 0.005488474204171241,
            "logloss": 0.6929183348466829,
            "mae": 0.4957343379176671,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6289905560024208,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5482614171876473,
            "fpr": 0.0,
            "logloss": 0.6889051705689312,
            "mae": 0.4954331373763189,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.592479707890397,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5388182960331185,
            "fpr": 0.005488474204171241,
            "logloss": 0.6913871130744069,
            "mae": 0.4947872708186622,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.6176349779427048,
            "auditor_fn_violation": 0.002217902711323782,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5375539961835973,
            "fpr": 0.0,
            "logloss": 0.689380441926027,
            "mae": 0.49685574019033657,
            "precision": 1.0,
            "recall": 0.022727272727272728
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6022592873246553,
            "auditor_fn_violation": 0.002349534063572875,
            "auditor_fp_violation": 0.0011848134789956965,
            "ave_precision_score": 0.5362034906049263,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6899843449999936,
            "mae": 0.49556747513989846,
            "precision": 0.8666666666666667,
            "recall": 0.027659574468085105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8554855743808596,
            "auditor_fn_violation": 0.013946280991735536,
            "auditor_fp_violation": 0.022780373831775703,
            "ave_precision_score": 0.8557119181277375,
            "fpr": 0.21271929824561403,
            "logloss": 1.3270670240750604,
            "mae": 0.312929866655468,
            "precision": 0.686084142394822,
            "recall": 0.8760330578512396
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8495125761795369,
            "auditor_fn_violation": 0.013996776981105635,
            "auditor_fp_violation": 0.01783194067967472,
            "ave_precision_score": 0.849558339642152,
            "fpr": 0.22063666300768386,
            "logloss": 1.07188370651745,
            "mae": 0.3236774385906979,
            "precision": 0.665,
            "recall": 0.8489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 2917,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7928229390832576,
            "auditor_fn_violation": 0.058870704654197484,
            "auditor_fp_violation": 0.0661583866207575,
            "ave_precision_score": 0.7671778635252038,
            "fpr": 0.13157894736842105,
            "logloss": 0.5663960562032904,
            "mae": 0.39117276526399347,
            "precision": 0.7156398104265402,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7586554387639469,
            "auditor_fn_violation": 0.04653759020949623,
            "auditor_fp_violation": 0.06623007783428045,
            "ave_precision_score": 0.7285065972343249,
            "fpr": 0.15697036223929747,
            "logloss": 0.602865344085654,
            "mae": 0.40166401403468477,
            "precision": 0.6720183486238532,
            "recall": 0.6234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6984216144114689,
            "auditor_fn_violation": 0.03524630274032188,
            "auditor_fp_violation": 0.06624036727332351,
            "ave_precision_score": 0.6140896183951644,
            "fpr": 0.2236842105263158,
            "logloss": 6.090586804755622,
            "mae": 0.3662150647066234,
            "precision": 0.6616915422885572,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6958893658557712,
            "auditor_fn_violation": 0.028656841908587714,
            "auditor_fp_violation": 0.05430975902984687,
            "ave_precision_score": 0.6037369441746079,
            "fpr": 0.24039517014270034,
            "logloss": 6.5554627024953085,
            "mae": 0.3735273691455105,
            "precision": 0.6433224755700325,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7584923809607095,
            "auditor_fn_violation": 0.0021522038567493114,
            "auditor_fp_violation": 0.010224524512215116,
            "ave_precision_score": 0.5723384977354095,
            "fpr": 0.4418859649122807,
            "logloss": 0.6794612085939461,
            "mae": 0.47575462740241437,
            "precision": 0.5420454545454545,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7072781679417609,
            "auditor_fn_violation": 0.004390779363336992,
            "auditor_fp_violation": 0.004219031190961568,
            "ave_precision_score": 0.5601054069968422,
            "fpr": 0.4566410537870472,
            "logloss": 0.6909939568195285,
            "mae": 0.4789969746420072,
            "precision": 0.5261958997722096,
            "recall": 0.9829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.594750415317334,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5655078753196386,
            "fpr": 0.3048245614035088,
            "logloss": 0.9468623469005867,
            "mae": 0.47592278220282314,
            "precision": 0.5435139573070608,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5910987946998475,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015873015873015883,
            "ave_precision_score": 0.5688504802203928,
            "fpr": 0.30735455543358947,
            "logloss": 0.9644573759700956,
            "mae": 0.4872574480056239,
            "precision": 0.5221843003412969,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8554935556546515,
            "auditor_fn_violation": 0.013946280991735536,
            "auditor_fp_violation": 0.022780373831775703,
            "ave_precision_score": 0.8557198920255149,
            "fpr": 0.21271929824561403,
            "logloss": 1.3270448476346768,
            "mae": 0.3129263104299718,
            "precision": 0.686084142394822,
            "recall": 0.8760330578512396
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8495125663265242,
            "auditor_fn_violation": 0.013996776981105635,
            "auditor_fp_violation": 0.01783194067967472,
            "ave_precision_score": 0.8495589209699046,
            "fpr": 0.22063666300768386,
            "logloss": 1.0718588407171028,
            "mae": 0.32367324670916553,
            "precision": 0.665,
            "recall": 0.8489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6319593599782191,
            "auditor_fn_violation": 0.018585979411338268,
            "auditor_fp_violation": 0.004934210526315797,
            "ave_precision_score": 0.6331094836672639,
            "fpr": 0.2949561403508772,
            "logloss": 1.0617469226636926,
            "mae": 0.4468639434826241,
            "precision": 0.5440677966101695,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6348199566881154,
            "auditor_fn_violation": 0.01687880981853003,
            "auditor_fp_violation": 0.010314846758315474,
            "ave_precision_score": 0.6367286677385706,
            "fpr": 0.29198682766191,
            "logloss": 1.011617679218732,
            "mae": 0.44086032078916293,
            "precision": 0.5468483816013628,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8079258945771017,
            "auditor_fn_violation": 0.04876214296070756,
            "auditor_fp_violation": 0.013560112313494015,
            "ave_precision_score": 0.7874575157020396,
            "fpr": 0.09100877192982457,
            "logloss": 0.5526848328055286,
            "mae": 0.3830332629333593,
            "precision": 0.7810026385224275,
            "recall": 0.6115702479338843
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7677550855625135,
            "auditor_fn_violation": 0.04810472475885747,
            "auditor_fp_violation": 0.01601738390196913,
            "ave_precision_score": 0.7476184331606285,
            "fpr": 0.10647639956092206,
            "logloss": 0.5961595699235405,
            "mae": 0.3982543035949101,
            "precision": 0.7335164835164835,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7181702600712834,
            "auditor_fn_violation": 0.0065245759025663345,
            "auditor_fp_violation": 0.009653221839645842,
            "ave_precision_score": 0.6669566874940249,
            "fpr": 0.3059210526315789,
            "logloss": 0.7718293405364118,
            "mae": 0.45180694994173554,
            "precision": 0.5318791946308725,
            "recall": 0.6549586776859504
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6849775817239749,
            "auditor_fn_violation": 0.008127612864049324,
            "auditor_fp_violation": 0.013911601962409549,
            "ave_precision_score": 0.6358484667677032,
            "fpr": 0.3062568605927552,
            "logloss": 0.7898036808033484,
            "mae": 0.4642573694169979,
            "precision": 0.5070671378091873,
            "recall": 0.6106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 2917,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7928229390832576,
            "auditor_fn_violation": 0.058870704654197484,
            "auditor_fp_violation": 0.0661583866207575,
            "ave_precision_score": 0.7671778635252038,
            "fpr": 0.13157894736842105,
            "logloss": 0.5663891812503998,
            "mae": 0.39117252639609207,
            "precision": 0.7156398104265402,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7586554387639469,
            "auditor_fn_violation": 0.04653759020949623,
            "auditor_fp_violation": 0.06623007783428045,
            "ave_precision_score": 0.7285065972343249,
            "fpr": 0.15697036223929747,
            "logloss": 0.6028394322212968,
            "mae": 0.40165550325732396,
            "precision": 0.6720183486238532,
            "recall": 0.6234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5672482757175078,
            "auditor_fn_violation": 0.006868928519646228,
            "auditor_fp_violation": 0.008285169699950811,
            "ave_precision_score": 0.5422689080290454,
            "fpr": 0.041666666666666664,
            "logloss": 0.6892176430063127,
            "mae": 0.49679683387410223,
            "precision": 0.5869565217391305,
            "recall": 0.1115702479338843
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5516847552864448,
            "auditor_fn_violation": 0.006773010720041115,
            "auditor_fp_violation": 0.005600483881807387,
            "ave_precision_score": 0.5360542436248733,
            "fpr": 0.050493962678375415,
            "logloss": 0.6901165477292985,
            "mae": 0.49565592090855837,
            "precision": 0.5533980582524272,
            "recall": 0.12127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.544609973704087,
            "auditor_fn_violation": 0.007530448020878659,
            "auditor_fp_violation": 0.009630164781111658,
            "ave_precision_score": 0.5376135046993555,
            "fpr": 0.0537280701754386,
            "logloss": 0.6938349115897556,
            "mae": 0.500279419973754,
            "precision": 0.5462962962962963,
            "recall": 0.12190082644628099
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.49418221315456745,
            "auditor_fn_violation": 0.008010836817152069,
            "auditor_fp_violation": 0.00897321973062917,
            "ave_precision_score": 0.517507154280259,
            "fpr": 0.06147091108671789,
            "logloss": 0.6937191347701533,
            "mae": 0.500218650250482,
            "precision": 0.5087719298245614,
            "recall": 0.12340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6274697427187608,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.546220828354198,
            "fpr": 0.0,
            "logloss": 0.6902578509032921,
            "mae": 0.49595614583149816,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5946144281250665,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5401476183391078,
            "fpr": 0.005488474204171241,
            "logloss": 0.6917390716041457,
            "mae": 0.49472285344231665,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6231306154616079,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5557786929333464,
            "fpr": 0.0,
            "logloss": 0.6886284335495534,
            "mae": 0.49569663059031754,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5468302016272216,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5210652155131341,
            "fpr": 0.005488474204171241,
            "logloss": 0.692726239627443,
            "mae": 0.4958847884812549,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8079258945771017,
            "auditor_fn_violation": 0.04876214296070756,
            "auditor_fp_violation": 0.013560112313494015,
            "ave_precision_score": 0.7874575157020396,
            "fpr": 0.09100877192982457,
            "logloss": 0.5526589536737719,
            "mae": 0.3830232490671047,
            "precision": 0.7810026385224275,
            "recall": 0.6115702479338843
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7677550855625135,
            "auditor_fn_violation": 0.04810472475885747,
            "auditor_fp_violation": 0.01601738390196913,
            "ave_precision_score": 0.7476184331606285,
            "fpr": 0.10647639956092206,
            "logloss": 0.5960999481287093,
            "mae": 0.3982312689104928,
            "precision": 0.7335164835164835,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5415906625523308,
            "auditor_fn_violation": 0.00648832825866319,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5374347583779586,
            "fpr": 0.3048245614035088,
            "logloss": 0.9779349911389384,
            "mae": 0.4841647292895798,
            "precision": 0.5304054054054054,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.501317606739371,
            "auditor_fn_violation": 0.006997220730083849,
            "auditor_fp_violation": 0.015743582467747434,
            "ave_precision_score": 0.5024257511217656,
            "fpr": 0.3040614709110867,
            "logloss": 0.9949192101295598,
            "mae": 0.49618089912228214,
            "precision": 0.5079928952042628,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7018084373419402,
            "auditor_fn_violation": 0.012473720458170226,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6514178197262827,
            "fpr": 0.09868421052631579,
            "logloss": 0.7063682234203716,
            "mae": 0.4215221275624476,
            "precision": 0.7383720930232558,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6855574065333851,
            "auditor_fn_violation": 0.014092533339561392,
            "auditor_fp_violation": 0.008082120517434933,
            "ave_precision_score": 0.6335603618049269,
            "fpr": 0.09769484083424808,
            "logloss": 0.7184023962640328,
            "mae": 0.4310983838482824,
            "precision": 0.721875,
            "recall": 0.49148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.544609973704087,
            "auditor_fn_violation": 0.007530448020878659,
            "auditor_fp_violation": 0.009630164781111658,
            "ave_precision_score": 0.5376135046993555,
            "fpr": 0.0537280701754386,
            "logloss": 0.6938367245713672,
            "mae": 0.5002801200015503,
            "precision": 0.5462962962962963,
            "recall": 0.12190082644628099
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.49418221315456745,
            "auditor_fn_violation": 0.008010836817152069,
            "auditor_fp_violation": 0.00897321973062917,
            "ave_precision_score": 0.517507154280259,
            "fpr": 0.06147091108671789,
            "logloss": 0.6937205007284307,
            "mae": 0.5002191232928329,
            "precision": 0.5087719298245614,
            "recall": 0.12340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8317218175800946,
            "auditor_fn_violation": 0.006155303030303032,
            "auditor_fp_violation": 0.028570257419249054,
            "ave_precision_score": 0.8319242880015462,
            "fpr": 0.2565789473684211,
            "logloss": 0.951671299690368,
            "mae": 0.326619248490029,
            "precision": 0.6593886462882096,
            "recall": 0.9359504132231405
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8224960412070398,
            "auditor_fn_violation": 0.00927668916551837,
            "auditor_fp_violation": 0.024062167860192024,
            "ave_precision_score": 0.8225279467810432,
            "fpr": 0.278814489571899,
            "logloss": 0.9703303853834628,
            "mae": 0.346353877127236,
            "precision": 0.6308139534883721,
            "recall": 0.9234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6259900847388215,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5671757941776401,
            "fpr": 0.3048245614035088,
            "logloss": 0.9473158967912613,
            "mae": 0.47591113073653296,
            "precision": 0.5435139573070608,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6302365722448832,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015873015873015883,
            "ave_precision_score": 0.5775286371698264,
            "fpr": 0.30735455543358947,
            "logloss": 0.9649032938049159,
            "mae": 0.4872547505846662,
            "precision": 0.5221843003412969,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7211624009890583,
            "auditor_fn_violation": 0.03559971726837757,
            "auditor_fp_violation": 0.015788961305131993,
            "ave_precision_score": 0.653870736934717,
            "fpr": 0.04276315789473684,
            "logloss": 0.6430750075762455,
            "mae": 0.4568808586254977,
            "precision": 0.8133971291866029,
            "recall": 0.3512396694214876
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.683645602564236,
            "auditor_fn_violation": 0.031099796809678407,
            "auditor_fp_violation": 0.011337868480725623,
            "ave_precision_score": 0.6153369292300508,
            "fpr": 0.043907793633369926,
            "logloss": 0.6578259306682314,
            "mae": 0.46593733800883874,
            "precision": 0.7814207650273224,
            "recall": 0.30425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7144488110402295,
            "auditor_fn_violation": 0.09041974771639844,
            "auditor_fp_violation": 0.09275342269224462,
            "ave_precision_score": 0.5596507159743305,
            "fpr": 0.27521929824561403,
            "logloss": 0.6871803797296079,
            "mae": 0.4960643757592168,
            "precision": 0.5724020442930153,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7059244067211773,
            "auditor_fn_violation": 0.08539832309596657,
            "auditor_fp_violation": 0.09403585803146726,
            "ave_precision_score": 0.5381734531129103,
            "fpr": 0.3084522502744237,
            "logloss": 0.6894055453406012,
            "mae": 0.49713715187935353,
            "precision": 0.5467741935483871,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8308817411455319,
            "auditor_fn_violation": 0.004503769754965928,
            "auditor_fp_violation": 0.020738543203803916,
            "ave_precision_score": 0.8310090052929728,
            "fpr": 0.2576754385964912,
            "logloss": 0.9255802403174933,
            "mae": 0.32199804429291634,
            "precision": 0.6589259796806967,
            "recall": 0.9380165289256198
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8181127709614366,
            "auditor_fn_violation": 0.007116332297919052,
            "auditor_fp_violation": 0.0212967733745529,
            "ave_precision_score": 0.8182179261282655,
            "fpr": 0.27552140504939626,
            "logloss": 0.9562437252471708,
            "mae": 0.3438855552172818,
            "precision": 0.6319648093841642,
            "recall": 0.9170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7056326869036473,
            "auditor_fn_violation": 0.013318743656662324,
            "auditor_fp_violation": 0.023267133956386306,
            "ave_precision_score": 0.6896818770266462,
            "fpr": 0.19956140350877194,
            "logloss": 2.539998924759563,
            "mae": 0.39373407063667293,
            "precision": 0.6231884057971014,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.7010033928075858,
            "auditor_fn_violation": 0.021426069084709357,
            "auditor_fp_violation": 0.02943614328277964,
            "ave_precision_score": 0.6896786812850395,
            "fpr": 0.20856201975850713,
            "logloss": 2.2948999455843064,
            "mae": 0.3885968702938089,
            "precision": 0.6098562628336756,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7899305140426506,
            "auditor_fn_violation": 0.06304824561403508,
            "auditor_fp_violation": 0.01148753894080997,
            "ave_precision_score": 0.7597587048206682,
            "fpr": 0.03508771929824561,
            "logloss": 0.5661881402309327,
            "mae": 0.392799051788946,
            "precision": 0.8832116788321168,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7221427567060457,
            "auditor_fn_violation": 0.05246280682906324,
            "auditor_fp_violation": 0.013734875582139186,
            "ave_precision_score": 0.7080818502882524,
            "fpr": 0.0570801317233809,
            "logloss": 0.6001694866334009,
            "mae": 0.4053922837966098,
            "precision": 0.8136200716845878,
            "recall": 0.4829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6963554323092155,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.6711446228269994,
            "fpr": 0.3048245614035088,
            "logloss": 0.8975784633317034,
            "mae": 0.46731408538394853,
            "precision": 0.5435139573070608,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.683015940550933,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015235805262463565,
            "ave_precision_score": 0.6569197196126508,
            "fpr": 0.3084522502744237,
            "logloss": 0.916686545151286,
            "mae": 0.4798374091296505,
            "precision": 0.5212947189097104,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6370814917132763,
            "auditor_fn_violation": 0.018391148325358854,
            "auditor_fp_violation": 0.005718150516478118,
            "ave_precision_score": 0.6382290035264949,
            "fpr": 0.2916666666666667,
            "logloss": 1.0432962687583598,
            "mae": 0.4423855347511307,
            "precision": 0.5452991452991452,
            "recall": 0.6590909090909091
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6400063404864335,
            "auditor_fn_violation": 0.02108975406964524,
            "auditor_fp_violation": 0.012462943464982053,
            "ave_precision_score": 0.6418911029184429,
            "fpr": 0.2854006586169045,
            "logloss": 0.996170396497469,
            "mae": 0.4372398501676615,
            "precision": 0.5547945205479452,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7302041543946111,
            "auditor_fn_violation": 0.013243982891112088,
            "auditor_fp_violation": 0.012307345466469914,
            "ave_precision_score": 0.7113788761698,
            "fpr": 0.09978070175438597,
            "logloss": 0.6268418361360659,
            "mae": 0.4089649512285465,
            "precision": 0.7579787234042553,
            "recall": 0.5888429752066116
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.736168385762943,
            "auditor_fn_violation": 0.010299647336338381,
            "auditor_fp_violation": 0.011153674788612847,
            "ave_precision_score": 0.7171002388457504,
            "fpr": 0.10428100987925357,
            "logloss": 0.6401178820399382,
            "mae": 0.4185743505946891,
            "precision": 0.7331460674157303,
            "recall": 0.5553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7159909003743379,
            "auditor_fn_violation": 0.013316478178918375,
            "auditor_fp_violation": 0.012307345466469914,
            "ave_precision_score": 0.6856510216203774,
            "fpr": 0.09978070175438597,
            "logloss": 0.6293857363387239,
            "mae": 0.4116406682715343,
            "precision": 0.7566844919786097,
            "recall": 0.5847107438016529
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7246515664049968,
            "auditor_fn_violation": 0.010299647336338381,
            "auditor_fp_violation": 0.011153674788612847,
            "ave_precision_score": 0.6978102148573582,
            "fpr": 0.10428100987925357,
            "logloss": 0.643619126384208,
            "mae": 0.4203950811492363,
            "precision": 0.7331460674157303,
            "recall": 0.5553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5366777131463217,
            "auditor_fn_violation": 0.00648832825866319,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.533082322494747,
            "fpr": 0.3048245614035088,
            "logloss": 0.9829664544847609,
            "mae": 0.4846228853586996,
            "precision": 0.5304054054054054,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.49614778914878865,
            "auditor_fn_violation": 0.006997220730083849,
            "auditor_fp_violation": 0.015743582467747434,
            "ave_precision_score": 0.4978031731040506,
            "fpr": 0.3040614709110867,
            "logloss": 0.9996965395665258,
            "mae": 0.49644878958111666,
            "precision": 0.5079928952042628,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8073121699797212,
            "auditor_fn_violation": 0.049167663476874006,
            "auditor_fp_violation": 0.014374795048368593,
            "ave_precision_score": 0.7854073523304561,
            "fpr": 0.09320175438596491,
            "logloss": 0.5536888489392335,
            "mae": 0.38330372249331784,
            "precision": 0.7774869109947644,
            "recall": 0.6136363636363636
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7669581876279433,
            "auditor_fn_violation": 0.04810472475885747,
            "auditor_fp_violation": 0.015711224116430327,
            "ave_precision_score": 0.7450524938027183,
            "fpr": 0.1119648737650933,
            "logloss": 0.5978842567059269,
            "mae": 0.39875912798811913,
            "precision": 0.7235772357723578,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5179984332172406,
            "auditor_fn_violation": 0.007530448020878659,
            "auditor_fp_violation": 0.009630164781111658,
            "ave_precision_score": 0.5356921582828769,
            "fpr": 0.0537280701754386,
            "logloss": 0.6943377662662895,
            "mae": 0.5005010189651921,
            "precision": 0.5462962962962963,
            "recall": 0.12190082644628099
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.49275848953398865,
            "auditor_fn_violation": 0.00546979003666769,
            "auditor_fp_violation": 0.00897321973062917,
            "ave_precision_score": 0.5162115583548404,
            "fpr": 0.06147091108671789,
            "logloss": 0.6941011556026492,
            "mae": 0.5003790663050244,
            "precision": 0.504424778761062,
            "recall": 0.12127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5366777131463217,
            "auditor_fn_violation": 0.00648832825866319,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.533082322494747,
            "fpr": 0.3048245614035088,
            "logloss": 0.9817577363662666,
            "mae": 0.4846659681122554,
            "precision": 0.5304054054054054,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.49614778914878865,
            "auditor_fn_violation": 0.006997220730083849,
            "auditor_fp_violation": 0.015743582467747434,
            "ave_precision_score": 0.4978031731040506,
            "fpr": 0.3040614709110867,
            "logloss": 0.9985148548997539,
            "mae": 0.49647148691207726,
            "precision": 0.5079928952042628,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.7738737288058712,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5477474576117425,
            "fpr": 0.0,
            "logloss": 0.6892324442647616,
            "mae": 0.49559618738528927,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6655054874203811,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5282063326744179,
            "fpr": 0.005488474204171241,
            "logloss": 0.6920741096201838,
            "mae": 0.49503990055831676,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8302538192884937,
            "auditor_fn_violation": 0.005296686965347254,
            "auditor_fp_violation": 0.01704941383833416,
            "ave_precision_score": 0.830390291243413,
            "fpr": 0.2532894736842105,
            "logloss": 0.9257730509000494,
            "mae": 0.3211601609527542,
            "precision": 0.6622807017543859,
            "recall": 0.9359504132231405
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8162891061637492,
            "auditor_fn_violation": 0.008739519349790973,
            "auditor_fp_violation": 0.020413141473201075,
            "ave_precision_score": 0.8162750474444893,
            "fpr": 0.2722283205268935,
            "logloss": 0.9561837322316186,
            "mae": 0.3426694011419979,
            "precision": 0.6336779911373708,
            "recall": 0.9127659574468086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8310075981864259,
            "auditor_fn_violation": 0.004503769754965928,
            "auditor_fp_violation": 0.023128791605181182,
            "ave_precision_score": 0.8314396496370913,
            "fpr": 0.2675438596491228,
            "logloss": 0.9639978608003362,
            "mae": 0.3235112080685468,
            "precision": 0.6504297994269341,
            "recall": 0.9380165289256198
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.8189843846049334,
            "auditor_fn_violation": 0.003694794123829321,
            "auditor_fp_violation": 0.022984385850937525,
            "ave_precision_score": 0.8192377469077586,
            "fpr": 0.2810098792535675,
            "logloss": 0.9833269278664164,
            "mae": 0.3438874651789338,
            "precision": 0.6289855072463768,
            "recall": 0.9234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.850480679379582,
            "auditor_fn_violation": 0.00917291938523996,
            "auditor_fp_violation": 0.021422569273651423,
            "ave_precision_score": 0.851038727890713,
            "fpr": 0.20723684210526316,
            "logloss": 1.2884212256112657,
            "mae": 0.3097648470343085,
            "precision": 0.6911764705882353,
            "recall": 0.8739669421487604
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8418048353003378,
            "auditor_fn_violation": 0.007464324917672886,
            "auditor_fp_violation": 0.013339108054491471,
            "ave_precision_score": 0.8419113836442995,
            "fpr": 0.20856201975850713,
            "logloss": 1.0162979340390772,
            "mae": 0.32081365691574876,
            "precision": 0.6817420435510888,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6252511862833195,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.011082759468765373,
            "ave_precision_score": 0.5662278384958611,
            "fpr": 0.3059210526315789,
            "logloss": 0.947656917269122,
            "mae": 0.4764271305972024,
            "precision": 0.5426229508196722,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6271160048689968,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015873015873015883,
            "ave_precision_score": 0.5743658543261925,
            "fpr": 0.30735455543358947,
            "logloss": 0.965714186365625,
            "mae": 0.4872975894111964,
            "precision": 0.5221843003412969,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7576792319545741,
            "auditor_fn_violation": 0.012473720458170226,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6396857750757828,
            "fpr": 0.09868421052631579,
            "logloss": 0.7058349125093297,
            "mae": 0.42091665626095054,
            "precision": 0.7383720930232558,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7378567143307565,
            "auditor_fn_violation": 0.014092533339561392,
            "auditor_fp_violation": 0.008082120517434933,
            "ave_precision_score": 0.6171429499381087,
            "fpr": 0.09769484083424808,
            "logloss": 0.7191066587043567,
            "mae": 0.43100742951575277,
            "precision": 0.721875,
            "recall": 0.49148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7211624009890583,
            "auditor_fn_violation": 0.03559971726837757,
            "auditor_fp_violation": 0.015788961305131993,
            "ave_precision_score": 0.653870736934717,
            "fpr": 0.04276315789473684,
            "logloss": 0.643075010216099,
            "mae": 0.4568808615011604,
            "precision": 0.8133971291866029,
            "recall": 0.3512396694214876
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.683645602564236,
            "auditor_fn_violation": 0.031099796809678407,
            "auditor_fp_violation": 0.011337868480725623,
            "ave_precision_score": 0.6153369292300508,
            "fpr": 0.043907793633369926,
            "logloss": 0.6578259309735676,
            "mae": 0.46593733938282067,
            "precision": 0.7814207650273224,
            "recall": 0.30425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8079258945771017,
            "auditor_fn_violation": 0.04876214296070756,
            "auditor_fp_violation": 0.013560112313494015,
            "ave_precision_score": 0.7874575157020396,
            "fpr": 0.09100877192982457,
            "logloss": 0.5526907894169848,
            "mae": 0.38303556497486535,
            "precision": 0.7810026385224275,
            "recall": 0.6115702479338843
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7677550855625135,
            "auditor_fn_violation": 0.04810472475885747,
            "auditor_fp_violation": 0.01601738390196913,
            "ave_precision_score": 0.7476184331606285,
            "fpr": 0.10647639956092206,
            "logloss": 0.5961732249563358,
            "mae": 0.3982595675977603,
            "precision": 0.7335164835164835,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5368554124821596,
            "auditor_fn_violation": 0.00648832825866319,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5317357338275841,
            "fpr": 0.3048245614035088,
            "logloss": 0.9828554506420434,
            "mae": 0.48462683946024954,
            "precision": 0.5304054054054054,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.49610775436644705,
            "auditor_fn_violation": 0.006997220730083849,
            "auditor_fp_violation": 0.015743582467747434,
            "ave_precision_score": 0.49731617029421377,
            "fpr": 0.3040614709110867,
            "logloss": 0.9995879659084561,
            "mae": 0.49645084901646386,
            "precision": 0.5079928952042628,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8288307413130798,
            "auditor_fn_violation": 0.00417301000434972,
            "auditor_fp_violation": 0.024353377602885733,
            "ave_precision_score": 0.8289714070452088,
            "fpr": 0.26644736842105265,
            "logloss": 0.9758130883336318,
            "mae": 0.3231700595525469,
            "precision": 0.6508620689655172,
            "recall": 0.9359504132231405
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.816870858181391,
            "auditor_fn_violation": 0.004063806432024664,
            "auditor_fp_violation": 0.02351456499174862,
            "ave_precision_score": 0.8171546229409361,
            "fpr": 0.283205268935236,
            "logloss": 0.9937034975618753,
            "mae": 0.3436784105810912,
            "precision": 0.6277056277056277,
            "recall": 0.925531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8321315857956699,
            "auditor_fn_violation": 0.003135421197622156,
            "auditor_fp_violation": 0.023502828332513527,
            "ave_precision_score": 0.8323713423590995,
            "fpr": 0.2598684210526316,
            "logloss": 0.9510723628189742,
            "mae": 0.32102258772621944,
            "precision": 0.6570188133140377,
            "recall": 0.9380165289256198
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8202563723062339,
            "auditor_fn_violation": 0.0034262092159656203,
            "auditor_fp_violation": 0.024306100047044074,
            "ave_precision_score": 0.8204898739728634,
            "fpr": 0.27661909989023054,
            "logloss": 0.9696251948767352,
            "mae": 0.341805414633026,
            "precision": 0.6321167883211679,
            "recall": 0.9212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8356475575555339,
            "auditor_fn_violation": 0.005978595766275193,
            "auditor_fp_violation": 0.02620818986719135,
            "ave_precision_score": 0.8360252451197069,
            "fpr": 0.25109649122807015,
            "logloss": 0.9190100216799649,
            "mae": 0.318825623567886,
            "precision": 0.6661807580174927,
            "recall": 0.9442148760330579
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8256192726262698,
            "auditor_fn_violation": 0.004248312586122336,
            "auditor_fp_violation": 0.027270622848480783,
            "ave_precision_score": 0.8258650838313777,
            "fpr": 0.2722283205268935,
            "logloss": 0.9307570378437292,
            "mae": 0.3372850532711992,
            "precision": 0.637956204379562,
            "recall": 0.9297872340425531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7546157783589582,
            "auditor_fn_violation": 0.012455596636218647,
            "auditor_fp_violation": 0.010977721757665199,
            "ave_precision_score": 0.667223784108518,
            "fpr": 0.09978070175438597,
            "logloss": 0.6618636368431318,
            "mae": 0.4252542493897572,
            "precision": 0.74,
            "recall": 0.5351239669421488
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7267895446773518,
            "auditor_fn_violation": 0.014227993553962226,
            "auditor_fp_violation": 0.010976948408342482,
            "ave_precision_score": 0.6365081525686297,
            "fpr": 0.09879253567508232,
            "logloss": 0.6778192392879406,
            "mae": 0.4360108269229286,
            "precision": 0.7204968944099379,
            "recall": 0.49361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7902083951953212,
            "auditor_fn_violation": 0.005695411048281863,
            "auditor_fp_violation": 0.016127131496966724,
            "ave_precision_score": 0.6919387459589168,
            "fpr": 0.3717105263157895,
            "logloss": 0.6275628085067742,
            "mae": 0.42610392156628923,
            "precision": 0.5773067331670823,
            "recall": 0.9566115702479339
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7457958691007384,
            "auditor_fn_violation": 0.006656234673143845,
            "auditor_fp_violation": 0.012069665041281786,
            "ave_precision_score": 0.6612483748627632,
            "fpr": 0.38638858397365533,
            "logloss": 0.6483367850800575,
            "mae": 0.4354035750636678,
            "precision": 0.5583437892095358,
            "recall": 0.9468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6231306154616079,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5557786929333464,
            "fpr": 0.0,
            "logloss": 0.6886284335495534,
            "mae": 0.49569663059031754,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5468302016272216,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5210652155131341,
            "fpr": 0.005488474204171241,
            "logloss": 0.692726239627443,
            "mae": 0.4958847884812549,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8363060490704493,
            "auditor_fn_violation": 0.010869762215455995,
            "auditor_fp_violation": 0.018286809313002132,
            "ave_precision_score": 0.8363253752798974,
            "fpr": 0.2774122807017544,
            "logloss": 1.2324766061460106,
            "mae": 0.34173424103920713,
            "precision": 0.6268436578171092,
            "recall": 0.878099173553719
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8273652714349187,
            "auditor_fn_violation": 0.004657028750262749,
            "auditor_fp_violation": 0.0003210944092236187,
            "ave_precision_score": 0.8272972721802261,
            "fpr": 0.2897914379802415,
            "logloss": 0.9575675556918153,
            "mae": 0.3533377203442035,
            "precision": 0.6071428571428571,
            "recall": 0.8680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6370044315470913,
            "auditor_fn_violation": 0.018391148325358854,
            "auditor_fp_violation": 0.005718150516478118,
            "ave_precision_score": 0.63815169850447,
            "fpr": 0.2916666666666667,
            "logloss": 1.0466043042821365,
            "mae": 0.4426786947443249,
            "precision": 0.5452991452991452,
            "recall": 0.6590909090909091
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6394320678270847,
            "auditor_fn_violation": 0.02108975406964524,
            "auditor_fp_violation": 0.01010327292278053,
            "ave_precision_score": 0.6413174412591094,
            "fpr": 0.2864983534577388,
            "logloss": 1.0003592605211569,
            "mae": 0.43762547117565953,
            "precision": 0.5538461538461539,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6926647079544549,
            "auditor_fn_violation": 0.01599653835000725,
            "auditor_fp_violation": 0.03704500737825874,
            "ave_precision_score": 0.6079891065526304,
            "fpr": 0.3432017543859649,
            "logloss": 6.27341815602254,
            "mae": 0.39817765671481076,
            "precision": 0.5837765957446809,
            "recall": 0.9070247933884298
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.692960190120384,
            "auditor_fn_violation": 0.016171146974332626,
            "auditor_fp_violation": 0.023051591657519233,
            "ave_precision_score": 0.6000941499314925,
            "fpr": 0.3721185510428101,
            "logloss": 6.750224895129631,
            "mae": 0.41867642218916357,
            "precision": 0.5557011795543906,
            "recall": 0.902127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7511022556942495,
            "auditor_fn_violation": 0.03443979266347689,
            "auditor_fp_violation": 0.016631824889326123,
            "ave_precision_score": 0.7347644409726404,
            "fpr": 0.043859649122807015,
            "logloss": 0.6202055840699707,
            "mae": 0.44214440666531263,
            "precision": 0.8319327731092437,
            "recall": 0.4090909090909091
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7144318693233803,
            "auditor_fn_violation": 0.026533853375995533,
            "auditor_fp_violation": 0.013022991853162781,
            "ave_precision_score": 0.7039654554951358,
            "fpr": 0.05159165751920966,
            "logloss": 0.6388929528070891,
            "mae": 0.44946495846780804,
            "precision": 0.7920353982300885,
            "recall": 0.38085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6252511862833195,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.011082759468765373,
            "ave_precision_score": 0.5662278384958611,
            "fpr": 0.3059210526315789,
            "logloss": 0.9480320261040912,
            "mae": 0.47641703535459545,
            "precision": 0.5426229508196722,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6271160048689968,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015873015873015883,
            "ave_precision_score": 0.5743658543261925,
            "fpr": 0.30735455543358947,
            "logloss": 0.9660826743122832,
            "mae": 0.48729537115008065,
            "precision": 0.5221843003412969,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6148981455207573,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.5663837581541112,
            "fpr": 0.3048245614035088,
            "logloss": 0.945518864072121,
            "mae": 0.47598480299245893,
            "precision": 0.5435139573070608,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6217039686096347,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015873015873015883,
            "ave_precision_score": 0.5770017020944535,
            "fpr": 0.30735455543358947,
            "logloss": 0.9631050806354017,
            "mae": 0.48728528468328824,
            "precision": 0.5221843003412969,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7318687132134539,
            "auditor_fn_violation": 0.012523560968537044,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.7262610875314977,
            "fpr": 0.09868421052631579,
            "logloss": 0.6520929313346201,
            "mae": 0.37004775841508,
            "precision": 0.7506925207756233,
            "recall": 0.5599173553719008
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7210974986926388,
            "auditor_fn_violation": 0.014319078870542082,
            "auditor_fp_violation": 0.0095506918464422,
            "ave_precision_score": 0.7138979188144854,
            "fpr": 0.10208562019758508,
            "logloss": 0.6644197395915524,
            "mae": 0.3789364965111181,
            "precision": 0.7296511627906976,
            "recall": 0.5340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5611403407916175,
            "auditor_fn_violation": 0.006735265332753402,
            "auditor_fp_violation": 0.008285169699950811,
            "ave_precision_score": 0.536686653666844,
            "fpr": 0.041666666666666664,
            "logloss": 0.6911189658314885,
            "mae": 0.4979907744155641,
            "precision": 0.5730337078651685,
            "recall": 0.10537190082644628
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5437175175488959,
            "auditor_fn_violation": 0.006394656328093998,
            "auditor_fp_violation": 0.006060968112089332,
            "ave_precision_score": 0.5301059845055656,
            "fpr": 0.05159165751920966,
            "logloss": 0.6909038600117938,
            "mae": 0.4968143513121537,
            "precision": 0.5346534653465347,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 2917,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.726034221096286,
            "auditor_fn_violation": 0.015833423952443092,
            "auditor_fp_violation": 0.02172487292998852,
            "ave_precision_score": 0.7104337157376768,
            "fpr": 0.18530701754385964,
            "logloss": 2.377386439421866,
            "mae": 0.36392156448967766,
            "precision": 0.6479166666666667,
            "recall": 0.6425619834710744
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7229645962956309,
            "auditor_fn_violation": 0.02538944811640237,
            "auditor_fp_violation": 0.024821344564170345,
            "ave_precision_score": 0.7115124134269278,
            "fpr": 0.18331503841931943,
            "logloss": 2.1427614339741887,
            "mae": 0.36095479849554357,
            "precision": 0.6476793248945147,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5460861009225817,
            "auditor_fn_violation": 0.007530448020878659,
            "auditor_fp_violation": 0.00578988358747336,
            "ave_precision_score": 0.538592276340988,
            "fpr": 0.051535087719298246,
            "logloss": 0.6938142724939106,
            "mae": 0.500231619793595,
            "precision": 0.5566037735849056,
            "recall": 0.12190082644628099
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5275121879210027,
            "auditor_fn_violation": 0.00546979003666769,
            "auditor_fp_violation": 0.008851253637203148,
            "ave_precision_score": 0.5181221152603569,
            "fpr": 0.06037321624588365,
            "logloss": 0.6938091923484176,
            "mae": 0.5002239578445448,
            "precision": 0.5089285714285714,
            "recall": 0.12127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6984179021364048,
            "auditor_fn_violation": 0.03524630274032188,
            "auditor_fp_violation": 0.06624036727332351,
            "ave_precision_score": 0.6140859097055642,
            "fpr": 0.2236842105263158,
            "logloss": 6.090626313768745,
            "mae": 0.3662019955200709,
            "precision": 0.6616915422885572,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6958979621300635,
            "auditor_fn_violation": 0.028656841908587714,
            "auditor_fp_violation": 0.05430975902984687,
            "ave_precision_score": 0.603745538799657,
            "fpr": 0.24039517014270034,
            "logloss": 6.555498537724589,
            "mae": 0.3735177812631124,
            "precision": 0.6433224755700325,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7052476542981772,
            "auditor_fn_violation": 0.012482782369146017,
            "auditor_fp_violation": 0.022501127233972792,
            "ave_precision_score": 0.6892191446032637,
            "fpr": 0.20065789473684212,
            "logloss": 2.52534359067783,
            "mae": 0.394132055495352,
            "precision": 0.622680412371134,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7002140403069228,
            "auditor_fn_violation": 0.021426069084709357,
            "auditor_fp_violation": 0.02901050650776228,
            "ave_precision_score": 0.688922042875491,
            "fpr": 0.2074643249176729,
            "logloss": 2.280411798540385,
            "mae": 0.3889407697233604,
            "precision": 0.6111111111111112,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7018084373419402,
            "auditor_fn_violation": 0.012473720458170226,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6514178197262827,
            "fpr": 0.09868421052631579,
            "logloss": 0.7063682234203716,
            "mae": 0.4215221275624476,
            "precision": 0.7383720930232558,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6855574065333851,
            "auditor_fn_violation": 0.014092533339561392,
            "auditor_fp_violation": 0.008082120517434933,
            "ave_precision_score": 0.6335603618049269,
            "fpr": 0.09769484083424808,
            "logloss": 0.7184023962640328,
            "mae": 0.4310983838482824,
            "precision": 0.721875,
            "recall": 0.49148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.54430411681357,
            "auditor_fn_violation": 0.009737023343482682,
            "auditor_fp_violation": 0.0028283325135268285,
            "ave_precision_score": 0.5462058522409865,
            "fpr": 0.32346491228070173,
            "logloss": 1.3563377360256827,
            "mae": 0.5053389971601359,
            "precision": 0.5058626465661642,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5450584855186065,
            "auditor_fn_violation": 0.010663988602657822,
            "auditor_fp_violation": 0.01148223650967889,
            "ave_precision_score": 0.5469848519635181,
            "fpr": 0.32491767288693746,
            "logloss": 1.2976965553914601,
            "mae": 0.49598405337982565,
            "precision": 0.5050167224080268,
            "recall": 0.6425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8306635460566176,
            "auditor_fn_violation": 0.006234594751341164,
            "auditor_fp_violation": 0.02021847843908839,
            "ave_precision_score": 0.8305580577180707,
            "fpr": 0.2719298245614035,
            "logloss": 0.9559604754608695,
            "mae": 0.3268232982434136,
            "precision": 0.6487252124645893,
            "recall": 0.9462809917355371
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.8198446871384012,
            "auditor_fn_violation": 0.00614709110867179,
            "auditor_fp_violation": 0.024811388148380468,
            "ave_precision_score": 0.8196285870107258,
            "fpr": 0.287596048298573,
            "logloss": 0.9735317894387595,
            "mae": 0.34564842534395657,
            "precision": 0.6262482168330956,
            "recall": 0.9340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 2917,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6274697427187608,
            "auditor_fn_violation": 0.0009515006524576024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.546220828354198,
            "fpr": 0.0,
            "logloss": 0.6902578509248456,
            "mae": 0.49595614584783715,
            "precision": 1.0,
            "recall": 0.03512396694214876
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5946144281250665,
            "auditor_fn_violation": 0.003643412663194553,
            "auditor_fp_violation": 0.0019016754158670422,
            "ave_precision_score": 0.5401476183391078,
            "fpr": 0.005488474204171241,
            "logloss": 0.6917390716041457,
            "mae": 0.49472285344231665,
            "precision": 0.8,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 2917,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7928229390832576,
            "auditor_fn_violation": 0.058870704654197484,
            "auditor_fp_violation": 0.0661583866207575,
            "ave_precision_score": 0.7671778635252038,
            "fpr": 0.13157894736842105,
            "logloss": 0.5663840037875908,
            "mae": 0.3911724108099741,
            "precision": 0.7156398104265402,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7586554387639469,
            "auditor_fn_violation": 0.04653759020949623,
            "auditor_fp_violation": 0.06623007783428045,
            "ave_precision_score": 0.7285065972343249,
            "fpr": 0.15697036223929747,
            "logloss": 0.6028194274295731,
            "mae": 0.401648938694701,
            "precision": 0.6720183486238532,
            "recall": 0.6234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8323535455408404,
            "auditor_fn_violation": 0.0036610120342177757,
            "auditor_fp_violation": 0.022864916379734403,
            "ave_precision_score": 0.832533756643,
            "fpr": 0.27521929824561403,
            "logloss": 0.995328733540146,
            "mae": 0.32963166309095787,
            "precision": 0.6469760900140648,
            "recall": 0.9504132231404959
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.8217671848148713,
            "auditor_fn_violation": 0.0045589368708690466,
            "auditor_fp_violation": 0.02403727682071731,
            "ave_precision_score": 0.8220283217763865,
            "fpr": 0.3062568605927552,
            "logloss": 1.0107926460529109,
            "mae": 0.3492450897922304,
            "precision": 0.6125,
            "recall": 0.9382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8252562625533336,
            "auditor_fn_violation": 0.004737113962592435,
            "auditor_fp_violation": 0.028923798983439906,
            "ave_precision_score": 0.8255067517068819,
            "fpr": 0.19956140350877194,
            "logloss": 1.4659105751671575,
            "mae": 0.2843717370897526,
            "precision": 0.697171381031614,
            "recall": 0.8657024793388429
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8233882881067844,
            "auditor_fn_violation": 0.014933320877221667,
            "auditor_fp_violation": 0.020475369071887815,
            "ave_precision_score": 0.8235208752789617,
            "fpr": 0.1986827661909989,
            "logloss": 1.1743025024848617,
            "mae": 0.2939400947211753,
            "precision": 0.687392055267703,
            "recall": 0.8468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5505087323577862,
            "auditor_fn_violation": 0.014200014499057565,
            "auditor_fp_violation": 0.006404738481718317,
            "ave_precision_score": 0.5524019807205925,
            "fpr": 0.32456140350877194,
            "logloss": 1.332649864934623,
            "mae": 0.5018870349105639,
            "precision": 0.5066666666666667,
            "recall": 0.628099173553719
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5519175618967247,
            "auditor_fn_violation": 0.010976948408342482,
            "auditor_fp_violation": 0.010148076793835007,
            "ave_precision_score": 0.5538310310826409,
            "fpr": 0.3260153677277717,
            "logloss": 1.2815821146153246,
            "mae": 0.4937905455093448,
            "precision": 0.5041736227045075,
            "recall": 0.6425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8235494844081465,
            "auditor_fn_violation": 0.004657822241554299,
            "auditor_fp_violation": 0.028923798983439906,
            "ave_precision_score": 0.8238162310105774,
            "fpr": 0.19956140350877194,
            "logloss": 1.4652727405093973,
            "mae": 0.28510191875273405,
            "precision": 0.6976744186046512,
            "recall": 0.8677685950413223
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8227813879840284,
            "auditor_fn_violation": 0.014933320877221667,
            "auditor_fp_violation": 0.021102623266650238,
            "ave_precision_score": 0.8229446821030293,
            "fpr": 0.19758507135016465,
            "logloss": 1.1763533549763283,
            "mae": 0.29470678786774485,
            "precision": 0.6885813148788927,
            "recall": 0.8468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6922334300773719,
            "auditor_fn_violation": 0.01599653835000725,
            "auditor_fp_violation": 0.02791185030332842,
            "ave_precision_score": 0.607726000620347,
            "fpr": 0.33881578947368424,
            "logloss": 6.22330624475957,
            "mae": 0.39386576722596583,
            "precision": 0.5868983957219251,
            "recall": 0.9070247933884298
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6923366838904542,
            "auditor_fn_violation": 0.016432725319382488,
            "auditor_fp_violation": 0.021319175310080134,
            "ave_precision_score": 0.5996442305312658,
            "fpr": 0.36663007683863885,
            "logloss": 6.70831668035941,
            "mae": 0.4161020030397932,
            "precision": 0.5558510638297872,
            "recall": 0.8893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7647930518444873,
            "auditor_fn_violation": 0.0021522038567493114,
            "auditor_fp_violation": 0.00937909903262831,
            "ave_precision_score": 0.5670811843658734,
            "fpr": 0.4440789473684211,
            "logloss": 0.6841390989241437,
            "mae": 0.479986806971985,
            "precision": 0.5408163265306123,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7056716510751904,
            "auditor_fn_violation": 0.003874629236051102,
            "auditor_fp_violation": 0.00499812072651966,
            "ave_precision_score": 0.5530748136998263,
            "fpr": 0.4588364434687157,
            "logloss": 0.693146118678952,
            "mae": 0.4819779804980323,
            "precision": 0.5255391600454029,
            "recall": 0.9851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7144488110402295,
            "auditor_fn_violation": 0.09041974771639844,
            "auditor_fp_violation": 0.09275342269224462,
            "ave_precision_score": 0.5596507159743305,
            "fpr": 0.27521929824561403,
            "logloss": 0.6871803797296079,
            "mae": 0.4960643757592168,
            "precision": 0.5724020442930153,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7059244067211773,
            "auditor_fn_violation": 0.08539832309596657,
            "auditor_fp_violation": 0.09403585803146726,
            "ave_precision_score": 0.5381734531129103,
            "fpr": 0.3084522502744237,
            "logloss": 0.6894055453406012,
            "mae": 0.49713715187935353,
            "precision": 0.5467741935483871,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8284869226555829,
            "auditor_fn_violation": 0.06269256560823548,
            "auditor_fp_violation": 0.010416666666666668,
            "ave_precision_score": 0.7108994651458767,
            "fpr": 0.03179824561403509,
            "logloss": 0.5697976767817434,
            "mae": 0.3985962951392458,
            "precision": 0.8925925925925926,
            "recall": 0.49793388429752067
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7881291525778529,
            "auditor_fn_violation": 0.05422145409533596,
            "auditor_fp_violation": 0.015848124833541175,
            "ave_precision_score": 0.6654308819878569,
            "fpr": 0.050493962678375415,
            "logloss": 0.6054646669934661,
            "mae": 0.41278371460220553,
            "precision": 0.8296296296296296,
            "recall": 0.4765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 2917,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7699495529334314,
            "auditor_fn_violation": 0.00392154197477164,
            "auditor_fp_violation": 0.00720148794884408,
            "ave_precision_score": 0.7698532182068653,
            "fpr": 0.32785087719298245,
            "logloss": 1.0366425110016417,
            "mae": 0.3841557779969496,
            "precision": 0.599195710455764,
            "recall": 0.9235537190082644
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7338714364347846,
            "auditor_fn_violation": 0.004402456968026719,
            "auditor_fp_violation": 0.009754798370134743,
            "ave_precision_score": 0.7351988980258757,
            "fpr": 0.34357848518111966,
            "logloss": 1.2009080568558188,
            "mae": 0.3987379456754552,
            "precision": 0.575880758807588,
            "recall": 0.9042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6950116789855867,
            "auditor_fn_violation": 0.012342322749021323,
            "auditor_fp_violation": 0.023231267420888674,
            "ave_precision_score": 0.6826309285882244,
            "fpr": 0.20723684210526316,
            "logloss": 2.246075599430015,
            "mae": 0.4022452729519642,
            "precision": 0.6142857142857143,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6892150319600258,
            "auditor_fn_violation": 0.022280869747997298,
            "auditor_fp_violation": 0.02947347984199169,
            "ave_precision_score": 0.6792105956333676,
            "fpr": 0.20965971459934138,
            "logloss": 2.0694028931723083,
            "mae": 0.3962175792865042,
            "precision": 0.6069958847736625,
            "recall": 0.6276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7511007745295656,
            "auditor_fn_violation": 0.03443979266347689,
            "auditor_fp_violation": 0.016631824889326123,
            "ave_precision_score": 0.7348007852346853,
            "fpr": 0.043859649122807015,
            "logloss": 0.6202098704289906,
            "mae": 0.4421469441435316,
            "precision": 0.8319327731092437,
            "recall": 0.4090909090909091
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7144012091128915,
            "auditor_fn_violation": 0.026533853375995533,
            "auditor_fp_violation": 0.013022991853162781,
            "ave_precision_score": 0.7039521024350978,
            "fpr": 0.05159165751920966,
            "logloss": 0.6388946767539113,
            "mae": 0.4494667894295882,
            "precision": 0.7920353982300885,
            "recall": 0.38085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7576792319545741,
            "auditor_fn_violation": 0.012473720458170226,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6396857750757828,
            "fpr": 0.09868421052631579,
            "logloss": 0.70528162702036,
            "mae": 0.42141175139368625,
            "precision": 0.7383720930232558,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7378567143307565,
            "auditor_fn_violation": 0.014092533339561392,
            "auditor_fp_violation": 0.008082120517434933,
            "ave_precision_score": 0.6171429499381087,
            "fpr": 0.09769484083424808,
            "logloss": 0.7185637048405092,
            "mae": 0.4314927934422582,
            "precision": 0.721875,
            "recall": 0.49148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 2917,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8361667030881408,
            "auditor_fn_violation": 0.005978595766275193,
            "auditor_fp_violation": 0.023807693884243315,
            "ave_precision_score": 0.8364528105411748,
            "fpr": 0.2642543859649123,
            "logloss": 0.9263253860472243,
            "mae": 0.322373472178649,
            "precision": 0.6547277936962751,
            "recall": 0.9442148760330579
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8258578067510652,
            "auditor_fn_violation": 0.004024102576079594,
            "auditor_fp_violation": 0.02436583854178334,
            "ave_precision_score": 0.8261100540508048,
            "fpr": 0.283205268935236,
            "logloss": 0.9417132442121632,
            "mae": 0.3410038658296107,
            "precision": 0.629842180774749,
            "recall": 0.9340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8079258945771017,
            "auditor_fn_violation": 0.04876214296070756,
            "auditor_fp_violation": 0.013560112313494015,
            "ave_precision_score": 0.7874575157020396,
            "fpr": 0.09100877192982457,
            "logloss": 0.552674693992262,
            "mae": 0.3830101681227812,
            "precision": 0.7810026385224275,
            "recall": 0.6115702479338843
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7677550855625135,
            "auditor_fn_violation": 0.04810472475885747,
            "auditor_fp_violation": 0.01601738390196913,
            "ave_precision_score": 0.7476184331606285,
            "fpr": 0.10647639956092206,
            "logloss": 0.5961047048442374,
            "mae": 0.39821585628452466,
            "precision": 0.7335164835164835,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7060950635514558,
            "auditor_fn_violation": 0.005407695374800646,
            "auditor_fp_violation": 0.010196343662895556,
            "ave_precision_score": 0.6776579733257045,
            "fpr": 0.3048245614035088,
            "logloss": 0.8688766456449282,
            "mae": 0.46669996526549784,
            "precision": 0.5435139573070608,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6806569073929539,
            "auditor_fn_violation": 0.009281360207394262,
            "auditor_fp_violation": 0.015235805262463565,
            "ave_precision_score": 0.6540257416605699,
            "fpr": 0.3084522502744237,
            "logloss": 0.8866487352396603,
            "mae": 0.4785298446988693,
            "precision": 0.5212947189097104,
            "recall": 0.6510638297872341
        }
    }
]