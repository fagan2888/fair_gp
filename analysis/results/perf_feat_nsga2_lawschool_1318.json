[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8453449844269421,
            "auditor_fn_violation": 0.00956067403435825,
            "auditor_fp_violation": 0.0038542557088777625,
            "ave_precision_score": 0.7955391931312786,
            "fpr": 0.03179824561403509,
            "logloss": 0.9295452679696561,
            "mae": 0.40161914646364094,
            "precision": 0.8925925925925926,
            "recall": 0.501039501039501
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.8303762507271024,
            "auditor_fn_violation": 0.002211634637029692,
            "auditor_fp_violation": 0.002699126355202023,
            "ave_precision_score": 0.7801232859005869,
            "fpr": 0.038419319429198684,
            "logloss": 0.8013726613137946,
            "mae": 0.4109989544366508,
            "precision": 0.8605577689243028,
            "recall": 0.45665961945031713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7167131109840605,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7205553932389667,
            "fpr": 0.4725877192982456,
            "logloss": 1.578154281892042,
            "mae": 0.4593550473974462,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7155815970393138,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7187359427313061,
            "fpr": 0.4807903402854007,
            "logloss": 1.5351913969749083,
            "mae": 0.46561282133820553,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4522027164571024,
            "auditor_fn_violation": 0.003164095269358442,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.520221715397154,
            "fpr": 0.023026315789473683,
            "logloss": 0.704002097192058,
            "mae": 0.5036010928778795,
            "precision": 0.36363636363636365,
            "recall": 0.02494802494802495
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5455589243082386,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.518176233034813,
            "fpr": 0.01756311745334797,
            "logloss": 0.6979355533248,
            "mae": 0.5004810072260814,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4531945624767499,
            "auditor_fn_violation": 0.003164095269358442,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5214778742495718,
            "fpr": 0.023026315789473683,
            "logloss": 0.7614364273901785,
            "mae": 0.504552405017437,
            "precision": 0.36363636363636365,
            "recall": 0.02494802494802495
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5464122206194089,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.519819550897775,
            "fpr": 0.01756311745334797,
            "logloss": 0.7154158436396628,
            "mae": 0.5007702746659394,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8003903174569182,
            "auditor_fn_violation": 0.021090928985665832,
            "auditor_fp_violation": 0.013745573330076932,
            "ave_precision_score": 0.7648304999566057,
            "fpr": 0.14912280701754385,
            "logloss": 0.5793211157761475,
            "mae": 0.38850320368318964,
            "precision": 0.7142857142857143,
            "recall": 0.7068607068607069
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7799727319368212,
            "auditor_fn_violation": 0.018964825030227225,
            "auditor_fp_violation": 0.025592830398628637,
            "ave_precision_score": 0.7500241704662529,
            "fpr": 0.15477497255762898,
            "logloss": 0.5808700272864555,
            "mae": 0.3865833055600115,
            "precision": 0.7122448979591837,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.45239289923110626,
            "auditor_fn_violation": 0.00425830688988584,
            "auditor_fp_violation": 0.006123560060243417,
            "ave_precision_score": 0.5171284492285221,
            "fpr": 0.0800438596491228,
            "logloss": 0.7086769041957102,
            "mae": 0.503684990532827,
            "precision": 0.4016393442622951,
            "recall": 0.10187110187110188
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5488263961740112,
            "auditor_fn_violation": 0.0060036713599116295,
            "auditor_fp_violation": 0.008210155932815058,
            "ave_precision_score": 0.5201964921636788,
            "fpr": 0.059275521405049394,
            "logloss": 0.7028145238009798,
            "mae": 0.500310461784168,
            "precision": 0.5462184873949579,
            "recall": 0.13742071881606766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7991183170631062,
            "auditor_fn_violation": 0.016306032753401187,
            "auditor_fp_violation": 0.0196783286522571,
            "ave_precision_score": 0.7469254450422986,
            "fpr": 0.12171052631578948,
            "logloss": 0.5828681714237919,
            "mae": 0.388203683374613,
            "precision": 0.74364896073903,
            "recall": 0.6694386694386695
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7987159006219673,
            "auditor_fn_violation": 0.01700150613943278,
            "auditor_fp_violation": 0.02114942183059411,
            "ave_precision_score": 0.7351436140001218,
            "fpr": 0.1350164654226125,
            "logloss": 0.5829207916033781,
            "mae": 0.3852966866005134,
            "precision": 0.7284768211920529,
            "recall": 0.6976744186046512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 1318,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5138405338234642,
            "auditor_fn_violation": 0.020067385198964154,
            "auditor_fp_violation": 0.01653641063214882,
            "ave_precision_score": 0.5248177443926632,
            "fpr": 0.05043859649122807,
            "logloss": 0.7451812339537568,
            "mae": 0.5007228982323965,
            "precision": 0.5053763440860215,
            "recall": 0.09771309771309772
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5734531247655815,
            "auditor_fn_violation": 0.020677507466877718,
            "auditor_fp_violation": 0.017315008345488173,
            "ave_precision_score": 0.5308801120336926,
            "fpr": 0.042810098792535674,
            "logloss": 0.6914644309292292,
            "mae": 0.49646704750183934,
            "precision": 0.6138613861386139,
            "recall": 0.13107822410147993
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8019017007289706,
            "auditor_fn_violation": 0.014201954991428681,
            "auditor_fp_violation": 0.019383217324052588,
            "ave_precision_score": 0.8022268185824877,
            "fpr": 0.17763157894736842,
            "logloss": 1.0735606977812606,
            "mae": 0.3017199561621757,
            "precision": 0.7,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7994914384853715,
            "auditor_fn_violation": 0.010761122572829619,
            "auditor_fp_violation": 0.018332506302973804,
            "ave_precision_score": 0.8015853413370413,
            "fpr": 0.18331503841931943,
            "logloss": 0.9914624188543861,
            "mae": 0.2848788853491136,
            "precision": 0.6963636363636364,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8267360226437639,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.7795334655771904,
            "fpr": 0.46600877192982454,
            "logloss": 4.355933297569032,
            "mae": 0.4657730158424193,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8304399321518033,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7878269263733116,
            "fpr": 0.47530186608122943,
            "logloss": 4.180981802120893,
            "mae": 0.47387527742368935,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7334411582927074,
            "auditor_fn_violation": 0.004385964912280711,
            "auditor_fp_violation": 0.005253490454674973,
            "ave_precision_score": 0.6546012809992903,
            "fpr": 0.039473684210526314,
            "logloss": 0.6913861067514941,
            "mae": 0.4285624707760552,
            "precision": 0.7647058823529411,
            "recall": 0.24324324324324326
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7428875739273685,
            "auditor_fn_violation": 0.0075353385796803375,
            "auditor_fp_violation": 0.004874466816033362,
            "ave_precision_score": 0.6513944383350428,
            "fpr": 0.031833150384193196,
            "logloss": 0.6630404781206362,
            "mae": 0.42654290702753134,
            "precision": 0.7986111111111112,
            "recall": 0.24312896405919662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.45411863272689573,
            "auditor_fn_violation": 0.00734717511033301,
            "auditor_fp_violation": 0.006123560060243417,
            "ave_precision_score": 0.516885566496563,
            "fpr": 0.0800438596491228,
            "logloss": 0.7085573179493285,
            "mae": 0.503635020534459,
            "precision": 0.4065040650406504,
            "recall": 0.10395010395010396
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.547677333180906,
            "auditor_fn_violation": 0.007964669542797353,
            "auditor_fp_violation": 0.00617516001784381,
            "ave_precision_score": 0.5199741967460032,
            "fpr": 0.06037321624588365,
            "logloss": 0.7033085361719655,
            "mae": 0.5005406384017936,
            "precision": 0.5454545454545454,
            "recall": 0.13953488372093023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4531945624767499,
            "auditor_fn_violation": 0.003164095269358442,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5214778742495718,
            "fpr": 0.023026315789473683,
            "logloss": 0.7614364048563633,
            "mae": 0.5045524050174375,
            "precision": 0.36363636363636365,
            "recall": 0.02494802494802495
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5464122206194089,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.519819550897775,
            "fpr": 0.01756311745334797,
            "logloss": 0.7154158436396666,
            "mae": 0.500770274665943,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6858790744309294,
            "auditor_fn_violation": 0.011386639676113374,
            "auditor_fp_violation": 0.017335246468840326,
            "ave_precision_score": 0.691003093927641,
            "fpr": 0.12171052631578948,
            "logloss": 0.7006001815303828,
            "mae": 0.4494938550909099,
            "precision": 0.6666666666666666,
            "recall": 0.46153846153846156
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6874960949502209,
            "auditor_fn_violation": 0.009561316584010793,
            "auditor_fp_violation": 0.01886631680776306,
            "ave_precision_score": 0.691271855890586,
            "fpr": 0.13391877058177826,
            "logloss": 0.6939158590827338,
            "mae": 0.4433288482456385,
            "precision": 0.659217877094972,
            "recall": 0.4989429175475687
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.589660160608828,
            "auditor_fn_violation": 0.0009893496735602157,
            "auditor_fp_violation": 0.00036125697073309743,
            "ave_precision_score": 0.5904179899059532,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6357798404398997,
            "mae": 0.4541975293439208,
            "precision": 0.96,
            "recall": 0.1995841995841996
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5913400025289063,
            "auditor_fn_violation": 0.005330666066376908,
            "auditor_fp_violation": 0.0016690976346931717,
            "ave_precision_score": 0.5920410938261227,
            "fpr": 0.003293084522502744,
            "logloss": 0.6389190433678723,
            "mae": 0.45759989941159407,
            "precision": 0.9666666666666667,
            "recall": 0.1839323467230444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7334361259913513,
            "auditor_fn_violation": 0.004385964912280711,
            "auditor_fp_violation": 0.005253490454674973,
            "ave_precision_score": 0.654596253696808,
            "fpr": 0.039473684210526314,
            "logloss": 0.683823827469498,
            "mae": 0.42848501263333477,
            "precision": 0.7647058823529411,
            "recall": 0.24324324324324326
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7429040046930905,
            "auditor_fn_violation": 0.0075353385796803375,
            "auditor_fp_violation": 0.004874466816033362,
            "ave_precision_score": 0.6514108688983192,
            "fpr": 0.031833150384193196,
            "logloss": 0.6527539208880373,
            "mae": 0.42645803567898455,
            "precision": 0.7986111111111112,
            "recall": 0.24312896405919662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8325965493416503,
            "auditor_fn_violation": 0.015127475653791444,
            "auditor_fp_violation": 0.012145357593519765,
            "ave_precision_score": 0.7853925102543168,
            "fpr": 0.07894736842105263,
            "logloss": 2.4635201819242636,
            "mae": 0.308544936957524,
            "precision": 0.8226600985221675,
            "recall": 0.6943866943866944
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8382343245287893,
            "auditor_fn_violation": 0.020886371178664348,
            "auditor_fp_violation": 0.009668736748718107,
            "ave_precision_score": 0.7956182631982317,
            "fpr": 0.07464324917672886,
            "logloss": 2.2023928099975763,
            "mae": 0.3046312079643248,
            "precision": 0.8233766233766234,
            "recall": 0.6701902748414377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8332449495384081,
            "auditor_fn_violation": 0.0013290111974322563,
            "auditor_fp_violation": 0.007927300850734726,
            "ave_precision_score": 0.7860396553656592,
            "fpr": 0.10087719298245613,
            "logloss": 2.4644197148418803,
            "mae": 0.3081709418748097,
            "precision": 0.7927927927927928,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8370501582555461,
            "auditor_fn_violation": 0.00978874595906736,
            "auditor_fp_violation": 0.0036238966663158082,
            "ave_precision_score": 0.7944349230756934,
            "fpr": 0.0867178924259056,
            "logloss": 2.2057135855400194,
            "mae": 0.305669839897742,
            "precision": 0.8105515587529976,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8004009664374618,
            "auditor_fn_violation": 0.015902542218331702,
            "auditor_fp_violation": 0.02077990800667563,
            "ave_precision_score": 0.8007435554786513,
            "fpr": 0.1699561403508772,
            "logloss": 1.000096520237585,
            "mae": 0.3011340268585192,
            "precision": 0.7064393939393939,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8006354786957088,
            "auditor_fn_violation": 0.011380751584463333,
            "auditor_fp_violation": 0.024229483381702086,
            "ave_precision_score": 0.801952490747466,
            "fpr": 0.17672886937431395,
            "logloss": 0.9235943004432584,
            "mae": 0.2840027950982053,
            "precision": 0.7034990791896869,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7334296531015774,
            "auditor_fn_violation": 0.004385964912280711,
            "auditor_fp_violation": 0.005253490454674973,
            "ave_precision_score": 0.6545897839903008,
            "fpr": 0.039473684210526314,
            "logloss": 0.6503062334862729,
            "mae": 0.42823206547914683,
            "precision": 0.7647058823529411,
            "recall": 0.24324324324324326
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7429251934225848,
            "auditor_fn_violation": 0.0075353385796803375,
            "auditor_fp_violation": 0.004874466816033362,
            "ave_precision_score": 0.65143205258705,
            "fpr": 0.031833150384193196,
            "logloss": 0.6425272985518814,
            "mae": 0.42621847398755275,
            "precision": 0.7986111111111112,
            "recall": 0.24312896405919662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8117473416242861,
            "auditor_fn_violation": 0.02942745376955904,
            "auditor_fp_violation": 0.00362274596002768,
            "ave_precision_score": 0.8130043069581081,
            "fpr": 0.03618421052631579,
            "logloss": 1.3147082933344625,
            "mae": 0.33566008962045424,
            "precision": 0.8764044943820225,
            "recall": 0.4864864864864865
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8217598827873348,
            "auditor_fn_violation": 0.03425364873300952,
            "auditor_fp_violation": 0.004150188713291133,
            "ave_precision_score": 0.8224951100729683,
            "fpr": 0.030735455543358946,
            "logloss": 1.2816367066464585,
            "mae": 0.32572005372962615,
            "precision": 0.8884462151394422,
            "recall": 0.4714587737843552
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8213564842706537,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.7741557489945023,
            "fpr": 0.46600877192982454,
            "logloss": 4.501518721325867,
            "mae": 0.46616196172602176,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8269939590698261,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7843830129415843,
            "fpr": 0.47530186608122943,
            "logloss": 4.333116078628043,
            "mae": 0.47428662453426157,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7996044194100697,
            "auditor_fn_violation": 0.011443629864682503,
            "auditor_fp_violation": 0.019177148206944283,
            "ave_precision_score": 0.7474149004863707,
            "fpr": 0.13486842105263158,
            "logloss": 0.5821636551389532,
            "mae": 0.38792333754367736,
            "precision": 0.7290748898678414,
            "recall": 0.6881496881496881
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7989936859553071,
            "auditor_fn_violation": 0.016729983314110138,
            "auditor_fp_violation": 0.021901267611987435,
            "ave_precision_score": 0.7354317731194798,
            "fpr": 0.141602634467618,
            "logloss": 0.5820357424584952,
            "mae": 0.38487997916900235,
            "precision": 0.7243589743589743,
            "recall": 0.7167019027484144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.719082944816839,
            "auditor_fn_violation": 0.004855564066090384,
            "auditor_fp_violation": 0.03323564130744494,
            "ave_precision_score": 0.6361890163678547,
            "fpr": 0.26864035087719296,
            "logloss": 0.6632863593412772,
            "mae": 0.43151229145424513,
            "precision": 0.5545454545454546,
            "recall": 0.6340956340956341
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7143914103333109,
            "auditor_fn_violation": 0.006579206921279266,
            "auditor_fp_violation": 0.02255036113659035,
            "ave_precision_score": 0.6258361576441749,
            "fpr": 0.2810098792535675,
            "logloss": 0.6576779786075599,
            "mae": 0.4331023052809452,
            "precision": 0.5294117647058824,
            "recall": 0.6088794926004228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.81075339326536,
            "auditor_fn_violation": 0.02895329540066383,
            "auditor_fp_violation": 0.011542414621239875,
            "ave_precision_score": 0.8111225039352982,
            "fpr": 0.06578947368421052,
            "logloss": 1.281234793184311,
            "mae": 0.3225666903582032,
            "precision": 0.8070739549839229,
            "recall": 0.5218295218295218
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.808591505399195,
            "auditor_fn_violation": 0.03143398862388983,
            "auditor_fp_violation": 0.0023958818900400515,
            "ave_precision_score": 0.8093728590765946,
            "fpr": 0.0570801317233809,
            "logloss": 1.2402890139395424,
            "mae": 0.31030286197535395,
            "precision": 0.832258064516129,
            "recall": 0.5454545454545454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8320602283395973,
            "auditor_fn_violation": 0.011040139329613015,
            "auditor_fp_violation": 0.006255851345300609,
            "ave_precision_score": 0.7848567669991484,
            "fpr": 0.0800438596491228,
            "logloss": 2.4721586971759866,
            "mae": 0.30269765073988536,
            "precision": 0.8215158924205379,
            "recall": 0.6985446985446986
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8368420977079281,
            "auditor_fn_violation": 0.015189033262706467,
            "auditor_fp_violation": 0.006135061576169498,
            "ave_precision_score": 0.7942268999148744,
            "fpr": 0.07244785949506037,
            "logloss": 2.2071580628949445,
            "mae": 0.29968479759018696,
            "precision": 0.8294573643410853,
            "recall": 0.678646934460888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8074320165824816,
            "auditor_fn_violation": 0.0427335229966809,
            "auditor_fp_violation": 0.008214779989416696,
            "ave_precision_score": 0.8078571653551918,
            "fpr": 0.11074561403508772,
            "logloss": 0.8434965990444714,
            "mae": 0.3490325890012981,
            "precision": 0.7725225225225225,
            "recall": 0.7130977130977131
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8187257891578421,
            "auditor_fn_violation": 0.04104636078189291,
            "auditor_fp_violation": 0.014164774521450157,
            "ave_precision_score": 0.8191542055705889,
            "fpr": 0.10867178924259056,
            "logloss": 0.8165759401975798,
            "mae": 0.34549162975557735,
            "precision": 0.7713625866050808,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7988514593895609,
            "auditor_fn_violation": 0.024122807017543865,
            "auditor_fp_violation": 0.01470977327308992,
            "ave_precision_score": 0.7991631127545407,
            "fpr": 0.1118421052631579,
            "logloss": 1.5206587348553837,
            "mae": 0.3033869388551354,
            "precision": 0.7536231884057971,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8123167972582612,
            "auditor_fn_violation": 0.021573300719651526,
            "auditor_fp_violation": 0.015969204396794136,
            "ave_precision_score": 0.8127615756610364,
            "fpr": 0.10537870472008781,
            "logloss": 1.2667537058259897,
            "mae": 0.2788209706454616,
            "precision": 0.7681159420289855,
            "recall": 0.6723044397463002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8181311042473491,
            "auditor_fn_violation": 0.018264215632636693,
            "auditor_fp_violation": 0.02328072210689136,
            "ave_precision_score": 0.8184250635523326,
            "fpr": 0.17214912280701755,
            "logloss": 1.025837604218133,
            "mae": 0.28715559263950774,
            "precision": 0.7054409005628518,
            "recall": 0.7817047817047817
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8230314159699168,
            "auditor_fn_violation": 0.014987131674646038,
            "auditor_fp_violation": 0.021472715516593237,
            "ave_precision_score": 0.8234799122096672,
            "fpr": 0.17014270032930845,
            "logloss": 0.9255329889974429,
            "mae": 0.27034720456474454,
            "precision": 0.710820895522388,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8102683859511062,
            "auditor_fn_violation": 0.013606977422766908,
            "auditor_fp_violation": 0.01948497985101966,
            "ave_precision_score": 0.7571871459920035,
            "fpr": 0.13157894736842105,
            "logloss": 0.6066571082387829,
            "mae": 0.3858478934881124,
            "precision": 0.7315436241610739,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8088147162405759,
            "auditor_fn_violation": 0.01567406121563322,
            "auditor_fp_violation": 0.021467703211383946,
            "ave_precision_score": 0.7444349311136575,
            "fpr": 0.14050493962678376,
            "logloss": 0.5875202272875385,
            "mae": 0.3826059091313641,
            "precision": 0.7241379310344828,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8253792938299731,
            "auditor_fn_violation": 0.028467738994054786,
            "auditor_fp_violation": 0.013058676273049215,
            "ave_precision_score": 0.7781800801928048,
            "fpr": 0.07894736842105263,
            "logloss": 2.522523481762903,
            "mae": 0.3324687332375399,
            "precision": 0.8134715025906736,
            "recall": 0.6528066528066528
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8270336661999153,
            "auditor_fn_violation": 0.03573426037878596,
            "auditor_fp_violation": 0.012796415199314324,
            "ave_precision_score": 0.7844252359672035,
            "fpr": 0.06805708013172337,
            "logloss": 2.247472254930302,
            "mae": 0.3309432816673551,
            "precision": 0.8277777777777777,
            "recall": 0.6300211416490487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8228525446803054,
            "auditor_fn_violation": 0.013189809242440833,
            "auditor_fp_violation": 0.01932470387104653,
            "ave_precision_score": 0.8206641371953216,
            "fpr": 0.12938596491228072,
            "logloss": 0.57178512755972,
            "mae": 0.3773452027847892,
            "precision": 0.7342342342342343,
            "recall": 0.6777546777546778
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8252111372384177,
            "auditor_fn_violation": 0.01626120031654456,
            "auditor_fp_violation": 0.021467703211383946,
            "ave_precision_score": 0.822994559029559,
            "fpr": 0.14050493962678376,
            "logloss": 0.5708635849361647,
            "mae": 0.3752286425095489,
            "precision": 0.7235421166306696,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8082378227671136,
            "auditor_fn_violation": 0.01679614837509575,
            "auditor_fp_violation": 0.016131904587454723,
            "ave_precision_score": 0.8085372341752575,
            "fpr": 0.16557017543859648,
            "logloss": 0.9774887705282199,
            "mae": 0.29524187085876147,
            "precision": 0.7112810707456979,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8124479465819427,
            "auditor_fn_violation": 0.010197190551005682,
            "auditor_fp_violation": 0.018713441498879747,
            "ave_precision_score": 0.8141473074952937,
            "fpr": 0.16575192096597147,
            "logloss": 0.8835885202285731,
            "mae": 0.27631179001951306,
            "precision": 0.7172284644194756,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8086277928561726,
            "auditor_fn_violation": 0.04605263157894738,
            "auditor_fp_violation": 0.01300779500956568,
            "ave_precision_score": 0.8089715048606045,
            "fpr": 0.10416666666666667,
            "logloss": 0.8872540329229439,
            "mae": 0.3532769954481989,
            "precision": 0.7780373831775701,
            "recall": 0.6923076923076923
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8185518098940171,
            "auditor_fn_violation": 0.0438033617774766,
            "auditor_fp_violation": 0.013064573528011266,
            "ave_precision_score": 0.8189796300681531,
            "fpr": 0.09769484083424808,
            "logloss": 0.8566086124433604,
            "mae": 0.3491778093662696,
            "precision": 0.7802469135802469,
            "recall": 0.6680761099365751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8259013638604465,
            "auditor_fn_violation": 0.011217948717948723,
            "auditor_fp_violation": 0.010685065331542312,
            "ave_precision_score": 0.7787017709899867,
            "fpr": 0.19956140350877194,
            "logloss": 2.527757973352168,
            "mae": 0.34443721435260355,
            "precision": 0.6910016977928692,
            "recall": 0.8461538461538461
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8276912525537219,
            "auditor_fn_violation": 0.006094178968352507,
            "auditor_fp_violation": 0.012826489030570055,
            "ave_precision_score": 0.7850823081671248,
            "fpr": 0.18221734357848518,
            "logloss": 2.251697369410728,
            "mae": 0.34357046827895754,
            "precision": 0.7025089605734767,
            "recall": 0.828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.754552260713625,
            "auditor_fn_violation": 0.008416311047890005,
            "auditor_fp_violation": 0.011689970285342136,
            "ave_precision_score": 0.662500120506784,
            "fpr": 0.23793859649122806,
            "logloss": 0.675355161362607,
            "mae": 0.42121653123671676,
            "precision": 0.5981481481481481,
            "recall": 0.6715176715176715
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7615339131698591,
            "auditor_fn_violation": 0.01579473802688773,
            "auditor_fp_violation": 0.011533314286573542,
            "ave_precision_score": 0.6569146725671866,
            "fpr": 0.24368825466520308,
            "logloss": 0.6711140495725114,
            "mae": 0.4168549350822067,
            "precision": 0.604982206405694,
            "recall": 0.718816067653277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8071232425620348,
            "auditor_fn_violation": 0.03542054199948937,
            "auditor_fp_violation": 0.002897687955387308,
            "ave_precision_score": 0.8084137405831577,
            "fpr": 0.02850877192982456,
            "logloss": 1.3125156144794508,
            "mae": 0.34359558775108073,
            "precision": 0.8930041152263375,
            "recall": 0.45114345114345117
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.820931198753932,
            "auditor_fn_violation": 0.029245561065947574,
            "auditor_fp_violation": 0.0024610418577608035,
            "ave_precision_score": 0.8215005915687599,
            "fpr": 0.024149286498353458,
            "logloss": 1.2727968321192527,
            "mae": 0.3341048894432284,
            "precision": 0.905982905982906,
            "recall": 0.44820295983086683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8109044211039346,
            "auditor_fn_violation": 0.013606977422766908,
            "auditor_fp_violation": 0.01948497985101966,
            "ave_precision_score": 0.7578344576063627,
            "fpr": 0.13157894736842105,
            "logloss": 0.5815125931636104,
            "mae": 0.3879298212235434,
            "precision": 0.7315436241610739,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8083565616684689,
            "auditor_fn_violation": 0.01567406121563322,
            "auditor_fp_violation": 0.021467703211383946,
            "ave_precision_score": 0.7439925316036307,
            "fpr": 0.14050493962678376,
            "logloss": 0.5815361651708418,
            "mae": 0.38576543328692703,
            "precision": 0.7241379310344828,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 1318,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5437063589359439,
            "auditor_fn_violation": 0.004044023780865894,
            "auditor_fp_violation": 0.001101579354418529,
            "ave_precision_score": 0.5445008059447658,
            "fpr": 0.005482456140350877,
            "logloss": 0.6571913703931703,
            "mae": 0.4689031202476798,
            "precision": 0.9333333333333333,
            "recall": 0.14553014553014554
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5679304164886659,
            "auditor_fn_violation": 0.008795482974126445,
            "auditor_fp_violation": 0.0016690976346931717,
            "ave_precision_score": 0.5684907183505992,
            "fpr": 0.003293084522502744,
            "logloss": 0.650095668349032,
            "mae": 0.4663186919937804,
            "precision": 0.96,
            "recall": 0.1522198731501057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6852774061779314,
            "auditor_fn_violation": 0.011379800853485071,
            "auditor_fp_violation": 0.017335246468840326,
            "ave_precision_score": 0.6940449236560589,
            "fpr": 0.12171052631578948,
            "logloss": 0.6959122922360939,
            "mae": 0.44800730669674904,
            "precision": 0.6656626506024096,
            "recall": 0.4594594594594595
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6833220881737807,
            "auditor_fn_violation": 0.009484733223022354,
            "auditor_fp_violation": 0.01886631680776306,
            "ave_precision_score": 0.6905718311758575,
            "fpr": 0.13391877058177826,
            "logloss": 0.6894906165091671,
            "mae": 0.4420016324382713,
            "precision": 0.6582633053221288,
            "recall": 0.49682875264270615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8327966301542074,
            "auditor_fn_violation": 0.0013290111974322563,
            "auditor_fp_violation": 0.007927300850734726,
            "ave_precision_score": 0.7855925225842912,
            "fpr": 0.10087719298245613,
            "logloss": 2.4651523936656647,
            "mae": 0.3084302023482068,
            "precision": 0.7927927927927928,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8370589314138057,
            "auditor_fn_violation": 0.010723991246289775,
            "auditor_fp_violation": 0.0036238966663158082,
            "ave_precision_score": 0.7944436893785246,
            "fpr": 0.0867178924259056,
            "logloss": 2.2056946053741187,
            "mae": 0.30567964925568725,
            "precision": 0.8100961538461539,
            "recall": 0.7124735729386892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4550438596491228,
            "auc_prc": 0.4223287167384247,
            "auditor_fn_violation": 0.0018236860342123649,
            "auditor_fp_violation": 0.008364879716693125,
            "ave_precision_score": 0.5178645795633248,
            "fpr": 0.03070175438596491,
            "logloss": 0.715614958970072,
            "mae": 0.5060470465799434,
            "precision": 0.3,
            "recall": 0.02494802494802495
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.516774169386011,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.005037366735335248,
            "ave_precision_score": 0.5227367081443062,
            "fpr": 0.02305159165751921,
            "logloss": 0.6988904745171208,
            "mae": 0.4985767259097911,
            "precision": 0.4878048780487805,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8325321720513822,
            "auditor_fn_violation": 0.014496024364445428,
            "auditor_fp_violation": 0.009435930313021536,
            "ave_precision_score": 0.7853281742345468,
            "fpr": 0.07785087719298246,
            "logloss": 2.463810852015321,
            "mae": 0.3085091281212507,
            "precision": 0.8251231527093597,
            "recall": 0.6964656964656964
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8378348082345595,
            "auditor_fn_violation": 0.02152688656147672,
            "auditor_fp_violation": 0.009668736748718107,
            "ave_precision_score": 0.7952189737530352,
            "fpr": 0.07464324917672886,
            "logloss": 2.2027983827053257,
            "mae": 0.3047560246009073,
            "precision": 0.8229166666666666,
            "recall": 0.6680761099365751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8005183565889346,
            "auditor_fn_violation": 0.025727650727650736,
            "auditor_fp_violation": 0.014892945821630647,
            "ave_precision_score": 0.800820200798011,
            "fpr": 0.11293859649122807,
            "logloss": 1.5059701399871452,
            "mae": 0.302189243605041,
            "precision": 0.7529976019184652,
            "recall": 0.6528066528066528
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8137069068328093,
            "auditor_fn_violation": 0.022030480177673395,
            "auditor_fp_violation": 0.015753675272794712,
            "ave_precision_score": 0.8141442635330123,
            "fpr": 0.10318331503841932,
            "logloss": 1.2531159406051533,
            "mae": 0.2775171479893011,
            "precision": 0.7723970944309927,
            "recall": 0.6744186046511628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.4775198285201313,
            "auditor_fn_violation": 0.00316409526935845,
            "auditor_fp_violation": 0.007942565229779786,
            "ave_precision_score": 0.5195418253787483,
            "fpr": 0.08552631578947369,
            "logloss": 0.7122136594497365,
            "mae": 0.5018618462051738,
            "precision": 0.4222222222222222,
            "recall": 0.11850311850311851
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5620760959680018,
            "auditor_fn_violation": 0.011793837592219133,
            "auditor_fp_violation": 0.008134971354675733,
            "ave_precision_score": 0.5334177971111028,
            "fpr": 0.06366630076838639,
            "logloss": 0.6978150756319126,
            "mae": 0.4959866354154049,
            "precision": 0.5703703703703704,
            "recall": 0.16279069767441862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.8145405638613199,
            "auditor_fn_violation": 0.0032940328992960574,
            "auditor_fp_violation": 0.01075121097407091,
            "ave_precision_score": 0.7673487274363304,
            "fpr": 0.39035087719298245,
            "logloss": 2.6574392170828602,
            "mae": 0.39865081291645765,
            "precision": 0.5572139303482587,
            "recall": 0.9313929313929314
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.8233596357863546,
            "auditor_fn_violation": 0.0011765989097314254,
            "auditor_fp_violation": 0.0027968663067831686,
            "ave_precision_score": 0.7807547601976417,
            "fpr": 0.3951701427003293,
            "logloss": 2.40422467071467,
            "mae": 0.3990289272615762,
            "precision": 0.5533498759305211,
            "recall": 0.9429175475687104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8312127797509083,
            "auditor_fn_violation": 0.00011853959222380592,
            "auditor_fp_violation": 0.02170085887572761,
            "ave_precision_score": 0.7840093959839818,
            "fpr": 0.19956140350877194,
            "logloss": 2.4764895911868336,
            "mae": 0.32710225004376026,
            "precision": 0.6936026936026936,
            "recall": 0.8565488565488566
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8386537994594959,
            "auditor_fn_violation": 0.009909422770321861,
            "auditor_fp_violation": 0.005062428261381695,
            "ave_precision_score": 0.7960373698977788,
            "fpr": 0.1734357848518112,
            "logloss": 2.2134380771686764,
            "mae": 0.3228960852501617,
            "precision": 0.7168458781362007,
            "recall": 0.8456659619450317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7969867430657797,
            "auditor_fn_violation": 0.014685231790494954,
            "auditor_fp_violation": 0.02028381568771116,
            "ave_precision_score": 0.7973256924252796,
            "fpr": 0.1524122807017544,
            "logloss": 0.9825289950453363,
            "mae": 0.30658285868682217,
            "precision": 0.7134020618556701,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.803671245338445,
            "auditor_fn_violation": 0.013810532764914615,
            "auditor_fp_violation": 0.021457678600965376,
            "ave_precision_score": 0.8045169958338315,
            "fpr": 0.15148188803512624,
            "logloss": 0.8972277199361546,
            "mae": 0.28773325252722454,
            "precision": 0.7206477732793523,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8074320165824816,
            "auditor_fn_violation": 0.0427335229966809,
            "auditor_fp_violation": 0.008214779989416696,
            "ave_precision_score": 0.8078571653551918,
            "fpr": 0.11074561403508772,
            "logloss": 0.8434962817580341,
            "mae": 0.3490325350199169,
            "precision": 0.7725225225225225,
            "recall": 0.7130977130977131
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8187257891578421,
            "auditor_fn_violation": 0.04104636078189291,
            "auditor_fp_violation": 0.014164774521450157,
            "ave_precision_score": 0.8191542055705889,
            "fpr": 0.10867178924259056,
            "logloss": 0.8165756362164434,
            "mae": 0.3454915546158267,
            "precision": 0.7713625866050808,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8008774857149492,
            "auditor_fn_violation": 0.02903764087974615,
            "auditor_fp_violation": 0.008939837994057074,
            "ave_precision_score": 0.7536928442363742,
            "fpr": 0.12280701754385964,
            "logloss": 2.5657045964656255,
            "mae": 0.3415867185535844,
            "precision": 0.7419354838709677,
            "recall": 0.6694386694386695
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8066870442674025,
            "auditor_fn_violation": 0.042011775271928946,
            "auditor_fp_violation": 0.003608859750687945,
            "ave_precision_score": 0.7640919555294028,
            "fpr": 0.10537870472008781,
            "logloss": 2.26851422777585,
            "mae": 0.336521476642467,
            "precision": 0.7581863979848866,
            "recall": 0.6363636363636364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.442867398241584,
            "auditor_fn_violation": 0.002309242440821389,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5183506403304016,
            "fpr": 0.023026315789473683,
            "logloss": 0.7285410781137797,
            "mae": 0.5069243448312607,
            "precision": 0.34375,
            "recall": 0.02286902286902287
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5477205979308226,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.5226025426687512,
            "fpr": 0.01756311745334797,
            "logloss": 0.7147836742287775,
            "mae": 0.49914956678412487,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.798348424478196,
            "auditor_fn_violation": 0.016764233869497026,
            "auditor_fp_violation": 0.018991431595229372,
            "ave_precision_score": 0.7446029866955641,
            "fpr": 0.12390350877192982,
            "logloss": 0.581929942590912,
            "mae": 0.39038985712747826,
            "precision": 0.7408256880733946,
            "recall": 0.6715176715176715
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7989479101355546,
            "auditor_fn_violation": 0.016414367038521435,
            "auditor_fp_violation": 0.02143261707491893,
            "ave_precision_score": 0.7340116539167556,
            "fpr": 0.13611416026344675,
            "logloss": 0.5830319905497672,
            "mae": 0.38816474609559504,
            "precision": 0.7274725274725274,
            "recall": 0.6997885835095138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7056871846841086,
            "auditor_fn_violation": 0.08017835649414598,
            "auditor_fp_violation": 0.08022957626083771,
            "ave_precision_score": 0.5573080931203644,
            "fpr": 0.26206140350877194,
            "logloss": 0.6879371605027602,
            "mae": 0.4959424913517739,
            "precision": 0.5716845878136201,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6894732531954131,
            "auditor_fn_violation": 0.07235038976289328,
            "auditor_fp_violation": 0.08913883584199209,
            "ave_precision_score": 0.5373729750789742,
            "fpr": 0.278814489571899,
            "logloss": 0.6924563939717756,
            "mae": 0.4980891301459198,
            "precision": 0.5488454706927176,
            "recall": 0.653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.442867398241584,
            "auditor_fn_violation": 0.002309242440821389,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5183506403304016,
            "fpr": 0.023026315789473683,
            "logloss": 0.7285410781137797,
            "mae": 0.5069243448312607,
            "precision": 0.34375,
            "recall": 0.02286902286902287
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5477205979308226,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.5226025426687512,
            "fpr": 0.01756311745334797,
            "logloss": 0.7147836742287775,
            "mae": 0.49914956678412487,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7883539833499078,
            "auditor_fn_violation": 0.002370791844476072,
            "auditor_fp_violation": 0.00036125697073309743,
            "ave_precision_score": 0.6117349395004262,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6386632379857289,
            "mae": 0.4540503056099017,
            "precision": 0.9578947368421052,
            "recall": 0.1891891891891892
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7883237892555619,
            "auditor_fn_violation": 0.005330666066376908,
            "auditor_fp_violation": 0.0016690976346931717,
            "ave_precision_score": 0.6038498336203557,
            "fpr": 0.003293084522502744,
            "logloss": 0.6374179150937505,
            "mae": 0.4549977923165823,
            "precision": 0.9666666666666667,
            "recall": 0.1839323467230444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.45201999012629046,
            "auditor_fn_violation": 0.00425830688988584,
            "auditor_fp_violation": 0.006123560060243417,
            "ave_precision_score": 0.5167649716412174,
            "fpr": 0.0800438596491228,
            "logloss": 0.7651246839896496,
            "mae": 0.5039866452611852,
            "precision": 0.4016393442622951,
            "recall": 0.10187110187110188
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5284509774301569,
            "auditor_fn_violation": 0.0060036713599116295,
            "auditor_fp_violation": 0.008210155932815058,
            "ave_precision_score": 0.5180432689913582,
            "fpr": 0.059275521405049394,
            "logloss": 0.7893707137084492,
            "mae": 0.5043052322140248,
            "precision": 0.5462184873949579,
            "recall": 0.13742071881606766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8196464463622231,
            "auditor_fn_violation": 0.020176806361016892,
            "auditor_fp_violation": 0.02100632962917735,
            "ave_precision_score": 0.8199325480573089,
            "fpr": 0.15789473684210525,
            "logloss": 1.035000830668303,
            "mae": 0.284630757657523,
            "precision": 0.7214700193423598,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8254841836607563,
            "auditor_fn_violation": 0.013109678976474982,
            "auditor_fp_violation": 0.020039196226736646,
            "ave_precision_score": 0.825885847779579,
            "fpr": 0.16245883644346873,
            "logloss": 0.9239963245232049,
            "mae": 0.2672265376562353,
            "precision": 0.7180952380952381,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8291225494552362,
            "auditor_fn_violation": 0.011375241638399543,
            "auditor_fp_violation": 0.00669851833760736,
            "ave_precision_score": 0.781919882488107,
            "fpr": 0.08662280701754387,
            "logloss": 2.4708515323572127,
            "mae": 0.30614030784968155,
            "precision": 0.8127962085308057,
            "recall": 0.7130977130977131
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8368776989140205,
            "auditor_fn_violation": 0.012190678644613753,
            "auditor_fp_violation": 0.006157616949611295,
            "ave_precision_score": 0.7942621876616606,
            "fpr": 0.07793633369923161,
            "logloss": 2.2030931097210273,
            "mae": 0.30048386164164964,
            "precision": 0.821608040201005,
            "recall": 0.6913319238900634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8031322226660974,
            "auditor_fn_violation": 0.015553762264288581,
            "auditor_fp_violation": 0.015551858183742422,
            "ave_precision_score": 0.8034533946456994,
            "fpr": 0.1787280701754386,
            "logloss": 1.01338441424512,
            "mae": 0.30354809072586475,
            "precision": 0.6964618249534451,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8017724140274254,
            "auditor_fn_violation": 0.005999029944094149,
            "auditor_fp_violation": 0.020337428386689328,
            "ave_precision_score": 0.8030725123317506,
            "fpr": 0.18111964873765093,
            "logloss": 0.9414401256436361,
            "mae": 0.2872781604408528,
            "precision": 0.7,
            "recall": 0.813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8209548827306905,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.7737587310567641,
            "fpr": 0.46600877192982454,
            "logloss": 3.599380440717206,
            "mae": 0.45895895797538716,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8268268159802306,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7842205578455099,
            "fpr": 0.47530186608122943,
            "logloss": 3.395133834736727,
            "mae": 0.46653754268550546,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7861519774282468,
            "auditor_fn_violation": 0.02301035853667433,
            "auditor_fp_violation": 0.014618186998819562,
            "ave_precision_score": 0.7857442380269627,
            "fpr": 0.11403508771929824,
            "logloss": 1.6743072648956432,
            "mae": 0.3050571725251343,
            "precision": 0.7535545023696683,
            "recall": 0.6611226611226612
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.805502579173508,
            "auditor_fn_violation": 0.02164524266482248,
            "auditor_fp_violation": 0.006972116546120728,
            "ave_precision_score": 0.8059502354437069,
            "fpr": 0.10318331503841932,
            "logloss": 1.3615481083241991,
            "mae": 0.28183638066715505,
            "precision": 0.7729468599033816,
            "recall": 0.6765327695560254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.809244806085131,
            "auditor_fn_violation": 0.036544388518072735,
            "auditor_fp_violation": 0.005197521064843082,
            "ave_precision_score": 0.8105127383854289,
            "fpr": 0.04057017543859649,
            "logloss": 1.2626774911525749,
            "mae": 0.333395077950418,
            "precision": 0.864963503649635,
            "recall": 0.49272349272349275
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8218926569727918,
            "auditor_fn_violation": 0.03182154684464951,
            "auditor_fp_violation": 0.003187826113107681,
            "ave_precision_score": 0.8224624286099405,
            "fpr": 0.038419319429198684,
            "logloss": 1.2193704660713012,
            "mae": 0.3218041625905514,
            "precision": 0.8703703703703703,
            "recall": 0.49682875264270615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7334204499431347,
            "auditor_fn_violation": 0.004385964912280711,
            "auditor_fp_violation": 0.005253490454674973,
            "ave_precision_score": 0.6545798895776098,
            "fpr": 0.039473684210526314,
            "logloss": 0.6557614599349576,
            "mae": 0.4264185081224231,
            "precision": 0.7647058823529411,
            "recall": 0.24324324324324326
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7428033393558168,
            "auditor_fn_violation": 0.0075353385796803375,
            "auditor_fp_violation": 0.004874466816033362,
            "ave_precision_score": 0.6513113604959133,
            "fpr": 0.031833150384193196,
            "logloss": 0.6577182716893334,
            "mae": 0.42466068060432016,
            "precision": 0.7986111111111112,
            "recall": 0.24312896405919662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7987901033708562,
            "auditor_fn_violation": 0.014242987927198462,
            "auditor_fp_violation": 0.0010481540277608174,
            "ave_precision_score": 0.6381039641471827,
            "fpr": 0.007675438596491228,
            "logloss": 0.6195708091027752,
            "mae": 0.4395569610295066,
            "precision": 0.9465648854961832,
            "recall": 0.2577962577962578
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7904122563226599,
            "auditor_fn_violation": 0.009723766137622616,
            "auditor_fp_violation": 0.00339333062668852,
            "ave_precision_score": 0.6274682758588503,
            "fpr": 0.008781558726673985,
            "logloss": 0.6227588326063469,
            "mae": 0.44144022899846475,
            "precision": 0.9375,
            "recall": 0.2536997885835095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7598526999788545,
            "auditor_fn_violation": 0.021111445453550717,
            "auditor_fp_violation": 0.004660723735091795,
            "ave_precision_score": 0.7619066233365901,
            "fpr": 0.12171052631578948,
            "logloss": 1.6365666047878504,
            "mae": 0.32011501634777284,
            "precision": 0.7363420427553444,
            "recall": 0.6444906444906445
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7803641346866323,
            "auditor_fn_violation": 0.023058553781245442,
            "auditor_fp_violation": 0.009157481617370651,
            "ave_precision_score": 0.781234538487181,
            "fpr": 0.10867178924259056,
            "logloss": 1.3749839301748965,
            "mae": 0.2945141933921757,
            "precision": 0.7620192307692307,
            "recall": 0.6701902748414377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7902017780763535,
            "auditor_fn_violation": 0.026502717292190985,
            "auditor_fp_violation": 0.018113729800138402,
            "ave_precision_score": 0.7880392401824965,
            "fpr": 0.18092105263157895,
            "logloss": 1.7119919170425144,
            "mae": 0.29465362567445563,
            "precision": 0.6994535519125683,
            "recall": 0.7983367983367984
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8080802375577244,
            "auditor_fn_violation": 0.016365632172437885,
            "auditor_fp_violation": 0.022284708960498032,
            "ave_precision_score": 0.8066688653713936,
            "fpr": 0.1778265642151482,
            "logloss": 1.4078500092430117,
            "mae": 0.2736657696418197,
            "precision": 0.7049180327868853,
            "recall": 0.8181818181818182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7903578221208101,
            "auditor_fn_violation": 0.021485301090564252,
            "auditor_fp_violation": 0.016650893474986772,
            "ave_precision_score": 0.7894906938873617,
            "fpr": 0.15789473684210525,
            "logloss": 1.614509274827241,
            "mae": 0.2925810174490985,
            "precision": 0.7165354330708661,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8066136349781288,
            "auditor_fn_violation": 0.014010113645066291,
            "auditor_fp_violation": 0.018891378333809505,
            "ave_precision_score": 0.8053316943728789,
            "fpr": 0.14928649835345773,
            "logloss": 1.3526654465373598,
            "mae": 0.27214808946579455,
            "precision": 0.7306930693069307,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8196493094199258,
            "auditor_fn_violation": 0.020176806361016892,
            "auditor_fp_violation": 0.02100632962917735,
            "ave_precision_score": 0.8199324560855726,
            "fpr": 0.15789473684210525,
            "logloss": 1.034938235704345,
            "mae": 0.2846255041626874,
            "precision": 0.7214700193423598,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8255054556175276,
            "auditor_fn_violation": 0.013109678976474982,
            "auditor_fp_violation": 0.020039196226736646,
            "ave_precision_score": 0.8259059616249091,
            "fpr": 0.16245883644346873,
            "logloss": 0.9239300327249526,
            "mae": 0.26721945470005715,
            "precision": 0.7180952380952381,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8283177565771971,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.7811164330909216,
            "fpr": 0.46600877192982454,
            "logloss": 3.5689478177692227,
            "mae": 0.4573759650395419,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8305774092610972,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7879670887590187,
            "fpr": 0.47530186608122943,
            "logloss": 3.3693609371625985,
            "mae": 0.4650556991684673,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8235826612755792,
            "auditor_fn_violation": 0.038662143925301824,
            "auditor_fp_violation": 0.019528228924980667,
            "ave_precision_score": 0.7763853542639655,
            "fpr": 0.10635964912280702,
            "logloss": 2.961026970964086,
            "mae": 0.2664623062247643,
            "precision": 0.7775229357798165,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8341168748004992,
            "auditor_fn_violation": 0.04082589353056257,
            "auditor_fp_violation": 0.013357793382754666,
            "ave_precision_score": 0.791506036154155,
            "fpr": 0.09769484083424808,
            "logloss": 2.615202850543539,
            "mae": 0.25564641156579615,
            "precision": 0.7915690866510539,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8103129989265878,
            "auditor_fn_violation": 0.013606977422766908,
            "auditor_fp_violation": 0.01948497985101966,
            "ave_precision_score": 0.7572250318893405,
            "fpr": 0.13157894736842105,
            "logloss": 0.58506344947884,
            "mae": 0.386006538151649,
            "precision": 0.7315436241610739,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8087590527798842,
            "auditor_fn_violation": 0.01567406121563322,
            "auditor_fp_violation": 0.021467703211383946,
            "ave_precision_score": 0.7443742199267882,
            "fpr": 0.14050493962678376,
            "logloss": 0.5832777213850052,
            "mae": 0.38272560580861553,
            "precision": 0.7241379310344828,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8311614518960141,
            "auditor_fn_violation": 0.0006177736440894398,
            "auditor_fp_violation": 0.023023771726299505,
            "ave_precision_score": 0.7839581001652873,
            "fpr": 0.20175438596491227,
            "logloss": 2.477948805805523,
            "mae": 0.32708311774114374,
            "precision": 0.6917922948073701,
            "recall": 0.8586278586278586
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8386445637287431,
            "auditor_fn_violation": 0.009909422770321861,
            "auditor_fp_violation": 0.007759048463979071,
            "ave_precision_score": 0.7960281357405565,
            "fpr": 0.1778265642151482,
            "logloss": 2.21481428508327,
            "mae": 0.3229313850214727,
            "precision": 0.7117437722419929,
            "recall": 0.8456659619450317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7334221403707759,
            "auditor_fn_violation": 0.004385964912280711,
            "auditor_fp_violation": 0.005253490454674973,
            "ave_precision_score": 0.6545822776058194,
            "fpr": 0.039473684210526314,
            "logloss": 0.6472821599689806,
            "mae": 0.42814915043879964,
            "precision": 0.7647058823529411,
            "recall": 0.24324324324324326
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7429252559624432,
            "auditor_fn_violation": 0.0075353385796803375,
            "auditor_fp_violation": 0.004874466816033362,
            "ave_precision_score": 0.6514321211488169,
            "fpr": 0.031833150384193196,
            "logloss": 0.6415450132110481,
            "mae": 0.4261480527210585,
            "precision": 0.7986111111111112,
            "recall": 0.24312896405919662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 1318,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8198813802398269,
            "auditor_fn_violation": 0.017728507860086812,
            "auditor_fp_violation": 0.017012150445719874,
            "ave_precision_score": 0.8201656807456541,
            "fpr": 0.13815789473684212,
            "logloss": 1.031061582050136,
            "mae": 0.2825172569863161,
            "precision": 0.7418032786885246,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8260396796313734,
            "auditor_fn_violation": 0.01270819650826288,
            "auditor_fp_violation": 0.020462736016921543,
            "ave_precision_score": 0.8264721813877214,
            "fpr": 0.1394072447859495,
            "logloss": 0.8952851908517281,
            "mae": 0.26505963945505084,
            "precision": 0.742914979757085,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8337402440234721,
            "auditor_fn_violation": 0.0014817449027975328,
            "auditor_fp_violation": 0.008001078682785852,
            "ave_precision_score": 0.7865335769370291,
            "fpr": 0.10087719298245613,
            "logloss": 2.4633865529833576,
            "mae": 0.3077741169734253,
            "precision": 0.7932584269662921,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8371196351818379,
            "auditor_fn_violation": 0.009006667393821813,
            "auditor_fp_violation": 0.0036238966663158082,
            "ave_precision_score": 0.7945043943402097,
            "fpr": 0.0867178924259056,
            "logloss": 2.2056598762014987,
            "mae": 0.3057366504909473,
            "precision": 0.8105515587529976,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.8247875544297288,
            "auditor_fn_violation": 0.0008252179304810897,
            "auditor_fp_violation": 0.01165689746407782,
            "ave_precision_score": 0.7775893907224473,
            "fpr": 0.39035087719298245,
            "logloss": 2.6494648959897638,
            "mae": 0.3940361112748322,
            "precision": 0.5604938271604938,
            "recall": 0.9438669438669439
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.8296512744682998,
            "auditor_fn_violation": 0.001081449885473065,
            "auditor_fp_violation": 0.006350590700168911,
            "ave_precision_score": 0.7870417595497908,
            "fpr": 0.3973655323819978,
            "logloss": 2.4016188829281138,
            "mae": 0.3971170056406838,
            "precision": 0.5530864197530864,
            "recall": 0.9471458773784355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.8111116549229793,
            "auditor_fn_violation": 0.035149268701900285,
            "auditor_fp_violation": 0.04473989498107217,
            "ave_precision_score": 0.758440990288029,
            "fpr": 0.23574561403508773,
            "logloss": 0.6020824352566765,
            "mae": 0.3817902986581127,
            "precision": 0.650974025974026,
            "recall": 0.8336798336798337
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.808916596878491,
            "auditor_fn_violation": 0.023694427748240324,
            "auditor_fp_violation": 0.03828398718854789,
            "ave_precision_score": 0.7447704544536755,
            "fpr": 0.2535675082327113,
            "logloss": 0.6083752350293997,
            "mae": 0.37959107489996763,
            "precision": 0.6356466876971609,
            "recall": 0.8520084566596194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8179355348838644,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.770742114547186,
            "fpr": 0.46600877192982454,
            "logloss": 3.955517976764997,
            "mae": 0.4634296396085885,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8257067376774353,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7831016676276432,
            "fpr": 0.47530186608122943,
            "logloss": 3.766189360941898,
            "mae": 0.47126851390295077,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.812896098045733,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.765704991131079,
            "fpr": 0.46600877192982454,
            "logloss": 3.454603270570427,
            "mae": 0.4563132244062185,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8149520827911286,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7723516021973896,
            "fpr": 0.47530186608122943,
            "logloss": 3.2567663134177205,
            "mae": 0.4640075979211483,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8127361246544471,
            "auditor_fn_violation": 0.03418043549622497,
            "auditor_fp_violation": 0.014999796474946068,
            "ave_precision_score": 0.8139859088349825,
            "fpr": 0.09758771929824561,
            "logloss": 0.9889950252477818,
            "mae": 0.30835536881775716,
            "precision": 0.7802469135802469,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8238077077857998,
            "auditor_fn_violation": 0.026599954049983415,
            "auditor_fp_violation": 0.016194758131212125,
            "ave_precision_score": 0.8245554737235642,
            "fpr": 0.09001097694840834,
            "logloss": 0.9346974529541006,
            "mae": 0.29081745020565586,
            "precision": 0.7955112219451371,
            "recall": 0.6744186046511628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7201866894469464,
            "auditor_fn_violation": 0.08822765072765074,
            "auditor_fp_violation": 0.10233748524443359,
            "ave_precision_score": 0.5532353626220182,
            "fpr": 0.3048245614035088,
            "logloss": 0.6885042608772151,
            "mae": 0.49704958194572674,
            "precision": 0.5622047244094488,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7178996323143675,
            "auditor_fn_violation": 0.08975105766262942,
            "auditor_fp_violation": 0.10599521826083035,
            "ave_precision_score": 0.5493370009549435,
            "fpr": 0.3029637760702525,
            "logloss": 0.6883495431644279,
            "mae": 0.4969764742448223,
            "precision": 0.5598086124401914,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8231953817452559,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0035108071803639034,
            "ave_precision_score": 0.7759928962255538,
            "fpr": 0.46600877192982454,
            "logloss": 4.4954299336207955,
            "mae": 0.46612604523115325,
            "precision": 0.5303867403314917,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.8285726860509459,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.7859579938961542,
            "fpr": 0.47530186608122943,
            "logloss": 4.326004311623727,
            "mae": 0.4742497542711005,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 1318,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.567798418993326,
            "auditor_fn_violation": 0.004044023780865894,
            "auditor_fp_violation": 0.001101579354418529,
            "ave_precision_score": 0.5689940953565523,
            "fpr": 0.005482456140350877,
            "logloss": 0.6574995629954052,
            "mae": 0.4690746902896647,
            "precision": 0.9333333333333333,
            "recall": 0.14553014553014554
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.578547939168529,
            "auditor_fn_violation": 0.008795482974126445,
            "auditor_fp_violation": 0.0016690976346931717,
            "ave_precision_score": 0.579696731313442,
            "fpr": 0.003293084522502744,
            "logloss": 0.65037032810554,
            "mae": 0.4664446735094198,
            "precision": 0.96,
            "recall": 0.1522198731501057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8105006997362775,
            "auditor_fn_violation": 0.0312762154867418,
            "auditor_fp_violation": 0.016727215370212076,
            "ave_precision_score": 0.8107682527867868,
            "fpr": 0.1118421052631579,
            "logloss": 1.4721789971653445,
            "mae": 0.2985975202442663,
            "precision": 0.7571428571428571,
            "recall": 0.6611226611226612
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8186146953837364,
            "auditor_fn_violation": 0.026702065197967986,
            "auditor_fp_violation": 0.02011187465227133,
            "ave_precision_score": 0.8192071278209723,
            "fpr": 0.09549945115257959,
            "logloss": 1.2323805798662917,
            "mae": 0.27266159018902075,
            "precision": 0.7851851851851852,
            "recall": 0.6723044397463002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.46402751570218925,
            "auditor_fn_violation": 0.003164095269358442,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5266823954705291,
            "fpr": 0.023026315789473683,
            "logloss": 0.7190435442219638,
            "mae": 0.5048089430814511,
            "precision": 0.36363636363636365,
            "recall": 0.02494802494802495
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5448021364968405,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.5234455939332808,
            "fpr": 0.01756311745334797,
            "logloss": 0.7168960297816408,
            "mae": 0.5014064656867023,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8241769316263801,
            "auditor_fn_violation": 0.018989130831236094,
            "auditor_fp_violation": 0.021861134855700744,
            "ave_precision_score": 0.8244390997786019,
            "fpr": 0.13267543859649122,
            "logloss": 1.0089073485905302,
            "mae": 0.2812603826072302,
            "precision": 0.7473903966597077,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8296514334726488,
            "auditor_fn_violation": 0.01331158056453541,
            "auditor_fp_violation": 0.01807938488990472,
            "ave_precision_score": 0.8300787430007451,
            "fpr": 0.12403951701427003,
            "logloss": 0.8676621405238959,
            "mae": 0.26295818763101514,
            "precision": 0.7621052631578947,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8008065841832329,
            "auditor_fn_violation": 0.016720921326184492,
            "auditor_fp_violation": 0.020940183986648757,
            "ave_precision_score": 0.8011263673629498,
            "fpr": 0.15899122807017543,
            "logloss": 0.9393866053887469,
            "mae": 0.3037361021773971,
            "precision": 0.7094188376753507,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8096202533442589,
            "auditor_fn_violation": 0.0128636839381485,
            "auditor_fp_violation": 0.02164313389370907,
            "ave_precision_score": 0.8104303575049394,
            "fpr": 0.14928649835345773,
            "logloss": 0.8584587099346114,
            "mae": 0.2877359334929261,
            "precision": 0.7269076305220884,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7986929720885075,
            "auditor_fn_violation": 0.015134314476419747,
            "auditor_fp_violation": 0.01854622053974845,
            "ave_precision_score": 0.7463747717981017,
            "fpr": 0.1206140350877193,
            "logloss": 0.5833335611824438,
            "mae": 0.387526052677187,
            "precision": 0.7447795823665894,
            "recall": 0.6673596673596673
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7989160904292817,
            "auditor_fn_violation": 0.015393255558675618,
            "auditor_fp_violation": 0.020089319278829534,
            "ave_precision_score": 0.7350318094639177,
            "fpr": 0.13391877058177826,
            "logloss": 0.5858496278556633,
            "mae": 0.3854000204857173,
            "precision": 0.729490022172949,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8316590433681477,
            "auditor_fn_violation": 0.0026375059269796103,
            "auditor_fp_violation": 0.02321457646436276,
            "ave_precision_score": 0.7844555166606204,
            "fpr": 0.20285087719298245,
            "logloss": 2.4756590656741393,
            "mae": 0.3258029035937956,
            "precision": 0.6906354515050167,
            "recall": 0.8586278586278586
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.839041772649065,
            "auditor_fn_violation": 0.01072631195419851,
            "auditor_fp_violation": 0.003919622673663847,
            "ave_precision_score": 0.796425185043961,
            "fpr": 0.1756311745334797,
            "logloss": 2.212612934711419,
            "mae": 0.321832600028206,
            "precision": 0.714795008912656,
            "recall": 0.8477801268498943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 1318,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.4957538425473952,
            "auditor_fn_violation": 0.003904967720757201,
            "auditor_fp_violation": 0.0028442626287295968,
            "ave_precision_score": 0.49792366198551335,
            "fpr": 0.05701754385964912,
            "logloss": 0.747276494636229,
            "mae": 0.5026947070372103,
            "precision": 0.3953488372093023,
            "recall": 0.07068607068607069
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5514363188954313,
            "auditor_fn_violation": 0.006718449395803706,
            "auditor_fp_violation": 0.00478173916966152,
            "ave_precision_score": 0.5525663310344004,
            "fpr": 0.03951701427003293,
            "logloss": 0.694135171696222,
            "mae": 0.4987573649458137,
            "precision": 0.5555555555555556,
            "recall": 0.09513742071881606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 1318,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7999804162346648,
            "auditor_fn_violation": 0.022878141299193935,
            "auditor_fp_violation": 0.027900740831196317,
            "ave_precision_score": 0.8002941869244576,
            "fpr": 0.1513157894736842,
            "logloss": 1.0272906335581125,
            "mae": 0.2999300785516026,
            "precision": 0.7177914110429447,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.803873641631548,
            "auditor_fn_violation": 0.019607661120948337,
            "auditor_fp_violation": 0.01599927822804987,
            "ave_precision_score": 0.8051609761943859,
            "fpr": 0.13830954994511527,
            "logloss": 0.9213522604101175,
            "mae": 0.280540082621451,
            "precision": 0.7433808553971487,
            "recall": 0.7716701902748414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7201866894469464,
            "auditor_fn_violation": 0.08822765072765074,
            "auditor_fp_violation": 0.10233748524443359,
            "ave_precision_score": 0.5532353626220182,
            "fpr": 0.3048245614035088,
            "logloss": 0.6885042608772151,
            "mae": 0.49704958194572674,
            "precision": 0.5622047244094488,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7178996323143675,
            "auditor_fn_violation": 0.08975105766262942,
            "auditor_fp_violation": 0.10599521826083035,
            "ave_precision_score": 0.5493370009549435,
            "fpr": 0.3029637760702525,
            "logloss": 0.6883495431644279,
            "mae": 0.4969764742448223,
            "precision": 0.5598086124401914,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7973364300834755,
            "auditor_fn_violation": 0.020812816865448447,
            "auditor_fp_violation": 0.022158790247079424,
            "ave_precision_score": 0.7976803450206743,
            "fpr": 0.17543859649122806,
            "logloss": 1.0618143023030209,
            "mae": 0.3039850145907459,
            "precision": 0.7014925373134329,
            "recall": 0.7817047817047817
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7998020599736941,
            "auditor_fn_violation": 0.012304393332142042,
            "auditor_fp_violation": 0.02286613636477553,
            "ave_precision_score": 0.7998014572212909,
            "fpr": 0.18221734357848518,
            "logloss": 0.9872196966268392,
            "mae": 0.28774374873243824,
            "precision": 0.696526508226691,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.44147320712063404,
            "auditor_fn_violation": 0.002309242440821389,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5204209482028044,
            "fpr": 0.023026315789473683,
            "logloss": 0.711326357802119,
            "mae": 0.5048579244563977,
            "precision": 0.34375,
            "recall": 0.02286902286902287
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5491669843860033,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.5241245384337272,
            "fpr": 0.01756311745334797,
            "logloss": 0.6936247571177866,
            "mae": 0.4974586277644014,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7645350153580541,
            "auditor_fn_violation": 0.02385609293504031,
            "auditor_fp_violation": 0.00416208735295315,
            "ave_precision_score": 0.7653640840420496,
            "fpr": 0.12171052631578948,
            "logloss": 1.5638189561448992,
            "mae": 0.3166671397170811,
            "precision": 0.7375886524822695,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7842863964962896,
            "auditor_fn_violation": 0.020946709584291588,
            "auditor_fp_violation": 0.010465693276995031,
            "ave_precision_score": 0.7846578755095716,
            "fpr": 0.1119648737650933,
            "logloss": 1.3285191341270193,
            "mae": 0.2909687526383455,
            "precision": 0.7571428571428571,
            "recall": 0.6723044397463002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.44147320712063404,
            "auditor_fn_violation": 0.002309242440821389,
            "auditor_fp_violation": 0.006968189034070095,
            "ave_precision_score": 0.5204209482028044,
            "fpr": 0.023026315789473683,
            "logloss": 0.7092725286224283,
            "mae": 0.5042051479645204,
            "precision": 0.34375,
            "recall": 0.02286902286902287
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5491669843860033,
            "auditor_fn_violation": 0.0003016920281362627,
            "auditor_fp_violation": 0.002571312572365158,
            "ave_precision_score": 0.5241245384337272,
            "fpr": 0.01756311745334797,
            "logloss": 0.69249671914273,
            "mae": 0.4971232006958104,
            "precision": 0.5555555555555556,
            "recall": 0.042283298097251586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8019966229679986,
            "auditor_fn_violation": 0.015134314476419747,
            "auditor_fp_violation": 0.01854622053974845,
            "ave_precision_score": 0.7496265134447058,
            "fpr": 0.1206140350877193,
            "logloss": 0.586015228533552,
            "mae": 0.387100501067675,
            "precision": 0.7447795823665894,
            "recall": 0.6673596673596673
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7994885472652129,
            "auditor_fn_violation": 0.015393255558675618,
            "auditor_fp_violation": 0.020089319278829534,
            "ave_precision_score": 0.7356484069236888,
            "fpr": 0.13391877058177826,
            "logloss": 0.5890091191845653,
            "mae": 0.3850091014192342,
            "precision": 0.729490022172949,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8333519882886136,
            "auditor_fn_violation": 0.008580442790969103,
            "auditor_fp_violation": 0.005108478853746897,
            "ave_precision_score": 0.7861473679040412,
            "fpr": 0.08662280701754387,
            "logloss": 2.460189808064905,
            "mae": 0.30474981112127897,
            "precision": 0.8127962085308057,
            "recall": 0.7130977130977131
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8381653509473559,
            "auditor_fn_violation": 0.013504199320960869,
            "auditor_fp_violation": 0.005909507841751503,
            "ave_precision_score": 0.7955491803352586,
            "fpr": 0.07903402854006586,
            "logloss": 2.2006300205294926,
            "mae": 0.30140874461239175,
            "precision": 0.82,
            "recall": 0.693446088794926
        }
    }
]