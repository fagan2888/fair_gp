[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 9296,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5243540884669436,
            "auditor_fn_violation": 0.005700363488001183,
            "auditor_fp_violation": 0.008682012548455423,
            "ave_precision_score": 0.5261197942346488,
            "fpr": 0.041666666666666664,
            "logloss": 0.6955452024709574,
            "mae": 0.5007262197241449,
            "precision": 0.5681818181818182,
            "recall": 0.10570824524312897
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5401047377500799,
            "auditor_fn_violation": 0.009860996688658617,
            "auditor_fp_violation": 0.010374492635233453,
            "ave_precision_score": 0.5414828240234809,
            "fpr": 0.048298572996706916,
            "logloss": 0.696120139445288,
            "mae": 0.5010221682317171,
            "precision": 0.580952380952381,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7341613755203105,
            "auditor_fn_violation": 0.009919420644634845,
            "auditor_fp_violation": 0.026700435599248694,
            "ave_precision_score": 0.7243743917887131,
            "fpr": 0.14692982456140352,
            "logloss": 1.7635985236611365,
            "mae": 0.2787899150957998,
            "precision": 0.7254098360655737,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7437287672384265,
            "auditor_fn_violation": 0.016006718531416667,
            "auditor_fp_violation": 0.042784571005539535,
            "ave_precision_score": 0.7313642433244136,
            "fpr": 0.13172338090010977,
            "logloss": 1.8432929094662183,
            "mae": 0.2522823101779384,
            "precision": 0.7614314115308151,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5243540884669436,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5261197942346488,
            "fpr": 0.05043859649122807,
            "logloss": 0.6958679846739322,
            "mae": 0.5007593950681519,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5401047377500799,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5414828240234809,
            "fpr": 0.06147091108671789,
            "logloss": 0.6963854072107236,
            "mae": 0.5010241354467055,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7482775436412535,
            "auditor_fn_violation": 0.01642418678832388,
            "auditor_fp_violation": 0.02605602845382248,
            "ave_precision_score": 0.717985371533767,
            "fpr": 0.20942982456140352,
            "logloss": 3.3512366113100494,
            "mae": 0.31492429915935977,
            "precision": 0.6666666666666666,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.750995117550334,
            "auditor_fn_violation": 0.01984750941940843,
            "auditor_fp_violation": 0.018390217752023083,
            "ave_precision_score": 0.715392936352192,
            "fpr": 0.2239297475301866,
            "logloss": 3.7246340654632157,
            "mae": 0.3320054577576282,
            "precision": 0.648881239242685,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5243540884669436,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5261197942346488,
            "fpr": 0.05043859649122807,
            "logloss": 0.6953693233683852,
            "mae": 0.5006392418750023,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5401047377500799,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5414828240234809,
            "fpr": 0.06147091108671789,
            "logloss": 0.6958047959540351,
            "mae": 0.50086063823768,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5823235918065225,
            "auditor_fn_violation": 0.08688707763065169,
            "auditor_fp_violation": 0.09535727131039444,
            "ave_precision_score": 0.5430481220746507,
            "fpr": 0.3059210526315789,
            "logloss": 0.6975642435023783,
            "mae": 0.49532900090541754,
            "precision": 0.5507246376811594,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7240756625660092,
            "auditor_fn_violation": 0.08266030110157445,
            "auditor_fp_violation": 0.09122099405202563,
            "ave_precision_score": 0.5724022729123781,
            "fpr": 0.278814489571899,
            "logloss": 0.6779841745407291,
            "mae": 0.48959003655499606,
            "precision": 0.573109243697479,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5243540884669436,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5261197942346488,
            "fpr": 0.05043859649122807,
            "logloss": 0.6957149161168313,
            "mae": 0.5007231308049277,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5401047377500799,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5414828240234809,
            "fpr": 0.06147091108671789,
            "logloss": 0.6962080317535634,
            "mae": 0.5009749831077689,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6525191380580393,
            "auditor_fn_violation": 0.08688707763065169,
            "auditor_fp_violation": 0.09607660951924228,
            "ave_precision_score": 0.5476148293452948,
            "fpr": 0.3048245614035088,
            "logloss": 0.6881781668662978,
            "mae": 0.49324263037558186,
            "precision": 0.5516129032258065,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7249140222769762,
            "auditor_fn_violation": 0.08192089750816427,
            "auditor_fp_violation": 0.09122099405202563,
            "ave_precision_score": 0.5729844999251729,
            "fpr": 0.278814489571899,
            "logloss": 0.6777273681641892,
            "mae": 0.4894057153085192,
            "precision": 0.5738255033557047,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.621642572879523,
            "auditor_fn_violation": 0.08615685619969586,
            "auditor_fp_violation": 0.09535727131039444,
            "ave_precision_score": 0.5487111213998281,
            "fpr": 0.3059210526315789,
            "logloss": 0.6901842445174233,
            "mae": 0.4925115290833147,
            "precision": 0.5514469453376206,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6897095206295215,
            "auditor_fn_violation": 0.08192089750816427,
            "auditor_fp_violation": 0.09122099405202563,
            "ave_precision_score": 0.5717171657719328,
            "fpr": 0.278814489571899,
            "logloss": 0.6801765018155431,
            "mae": 0.4894791147646082,
            "precision": 0.5738255033557047,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5341687544213675,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5304530209574835,
            "fpr": 0.05043859649122807,
            "logloss": 0.6951409275526423,
            "mae": 0.5006140068565544,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5464962986224138,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5443936334742019,
            "fpr": 0.06147091108671789,
            "logloss": 0.6956114872253857,
            "mae": 0.5008550590204748,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6517901696883577,
            "auditor_fn_violation": 0.027959367234153036,
            "auditor_fp_violation": 0.018657834791991373,
            "ave_precision_score": 0.6169265473023713,
            "fpr": 0.1118421052631579,
            "logloss": 0.7420894071936768,
            "mae": 0.4512969465240052,
            "precision": 0.6506849315068494,
            "recall": 0.40169133192389006
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6806812214348609,
            "auditor_fn_violation": 0.0300074624992298,
            "auditor_fp_violation": 0.019702346003624954,
            "ave_precision_score": 0.6428704738456011,
            "fpr": 0.09769484083424808,
            "logloss": 0.7047045606833162,
            "mae": 0.4370089435682077,
            "precision": 0.7072368421052632,
            "recall": 0.446985446985447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5614928987096872,
            "auditor_fn_violation": 0.02140591966173361,
            "auditor_fp_violation": 0.012608400271749991,
            "ave_precision_score": 0.5438830040822549,
            "fpr": 0.046052631578947366,
            "logloss": 0.6942322376161008,
            "mae": 0.4953402222967462,
            "precision": 0.6181818181818182,
            "recall": 0.14376321353065538
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.591220074145311,
            "auditor_fn_violation": 0.016495090040644388,
            "auditor_fp_violation": 0.012314604446940497,
            "ave_precision_score": 0.5669931666128621,
            "fpr": 0.04500548847420417,
            "logloss": 0.6868777206411638,
            "mae": 0.49326834023718513,
            "precision": 0.6554621848739496,
            "recall": 0.16216216216216217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6404034705490453,
            "auditor_fn_violation": 0.02859918029746672,
            "auditor_fp_violation": 0.019926667465931344,
            "ave_precision_score": 0.6181278497274508,
            "fpr": 0.11403508771929824,
            "logloss": 0.7425258217240956,
            "mae": 0.451437961865674,
            "precision": 0.6498316498316499,
            "recall": 0.4080338266384778
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6738272923985287,
            "auditor_fn_violation": 0.0300074624992298,
            "auditor_fp_violation": 0.020371174022923957,
            "ave_precision_score": 0.6456202064019951,
            "fpr": 0.09989023051591657,
            "logloss": 0.7050159713826605,
            "mae": 0.4369270975254762,
            "precision": 0.7026143790849673,
            "recall": 0.446985446985447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6056773011176917,
            "auditor_fn_violation": 0.08615685619969586,
            "auditor_fp_violation": 0.09535727131039444,
            "ave_precision_score": 0.5461225312828307,
            "fpr": 0.3059210526315789,
            "logloss": 0.6970083258968538,
            "mae": 0.4933839767125615,
            "precision": 0.5514469453376206,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7258000399415173,
            "auditor_fn_violation": 0.08192089750816427,
            "auditor_fp_violation": 0.09122099405202563,
            "ave_precision_score": 0.5747565352542552,
            "fpr": 0.278814489571899,
            "logloss": 0.6766178401459028,
            "mae": 0.48862813987271325,
            "precision": 0.5738255033557047,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.640285500543278,
            "auditor_fn_violation": 0.027959367234153036,
            "auditor_fp_violation": 0.019926667465931344,
            "ave_precision_score": 0.6180216415441159,
            "fpr": 0.11403508771929824,
            "logloss": 0.7424931961626401,
            "mae": 0.4514392351960404,
            "precision": 0.6462585034013606,
            "recall": 0.40169133192389006
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6742835335555215,
            "auditor_fn_violation": 0.0300074624992298,
            "auditor_fp_violation": 0.02026906287493938,
            "ave_precision_score": 0.6460131218639917,
            "fpr": 0.09879253567508232,
            "logloss": 0.7050011467032016,
            "mae": 0.4370121678458087,
            "precision": 0.7049180327868853,
            "recall": 0.446985446985447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6415545037844407,
            "auditor_fn_violation": 0.02859918029746672,
            "auditor_fp_violation": 0.020036566358949775,
            "ave_precision_score": 0.6192581862753551,
            "fpr": 0.11513157894736842,
            "logloss": 0.742574743719583,
            "mae": 0.45143447447110685,
            "precision": 0.6476510067114094,
            "recall": 0.4080338266384778
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6745243819477955,
            "auditor_fn_violation": 0.030301854670680143,
            "auditor_fp_violation": 0.020371174022923957,
            "ave_precision_score": 0.6462671411840744,
            "fpr": 0.09989023051591657,
            "logloss": 0.7050451217194521,
            "mae": 0.4368497684156332,
            "precision": 0.7045454545454546,
            "recall": 0.45114345114345117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.5798568914016657,
            "auditor_fn_violation": 0.09054513927524944,
            "auditor_fp_violation": 0.08353065180034369,
            "ave_precision_score": 0.581955966776222,
            "fpr": 0.24780701754385964,
            "logloss": 0.6986337767092364,
            "mae": 0.4893933641834066,
            "precision": 0.5830258302583026,
            "recall": 0.6680761099365751
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6207441081808719,
            "auditor_fn_violation": 0.08704423413534282,
            "auditor_fp_violation": 0.06926199167794145,
            "ave_precision_score": 0.6228401304691435,
            "fpr": 0.21185510428100987,
            "logloss": 0.6867849056334618,
            "mae": 0.48524639360595423,
            "precision": 0.6163021868787276,
            "recall": 0.6444906444906445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5758634456250097,
            "auditor_fn_violation": 0.05480137977078003,
            "auditor_fp_violation": 0.05527664548615275,
            "ave_precision_score": 0.5794490231013029,
            "fpr": 0.17653508771929824,
            "logloss": 0.7090650365599367,
            "mae": 0.4874492471272038,
            "precision": 0.5729442970822282,
            "recall": 0.45665961945031713
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6101388169053455,
            "auditor_fn_violation": 0.06598720649214612,
            "auditor_fp_violation": 0.0566589232379445,
            "ave_precision_score": 0.6111439297939651,
            "fpr": 0.15916575192096596,
            "logloss": 0.6856868285777576,
            "mae": 0.47954046348854595,
            "precision": 0.6070460704607046,
            "recall": 0.4656964656964657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7894735290749407,
            "auditor_fn_violation": 0.008057935536515721,
            "auditor_fp_violation": 0.0025076929225112897,
            "ave_precision_score": 0.7894467041678626,
            "fpr": 0.01206140350877193,
            "logloss": 0.6890560210838762,
            "mae": 0.44338053047019793,
            "precision": 0.9133858267716536,
            "recall": 0.2452431289640592
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.8168139203810723,
            "auditor_fn_violation": 0.003019231339758236,
            "auditor_fp_violation": 0.0029816455211497716,
            "ave_precision_score": 0.8172337607448936,
            "fpr": 0.013172338090010977,
            "logloss": 0.6751580619568324,
            "mae": 0.4324145707957095,
            "precision": 0.9194630872483222,
            "recall": 0.28482328482328484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.756749362168786,
            "auditor_fn_violation": 0.008899428804569568,
            "auditor_fp_violation": 0.025536506414099033,
            "ave_precision_score": 0.7464169403413958,
            "fpr": 0.15350877192982457,
            "logloss": 1.9096247244550104,
            "mae": 0.29910992340544296,
            "precision": 0.720558882235529,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7542083947095883,
            "auditor_fn_violation": 0.020415754773603294,
            "auditor_fp_violation": 0.022683991524774724,
            "ave_precision_score": 0.7408964768399307,
            "fpr": 0.15806805708013172,
            "logloss": 2.117139508415441,
            "mae": 0.30858696723574347,
            "precision": 0.7203883495145631,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6644676632073402,
            "auditor_fn_violation": 0.02371481028151775,
            "auditor_fp_violation": 0.018258202453742562,
            "ave_precision_score": 0.6364512813243937,
            "fpr": 0.09978070175438597,
            "logloss": 0.7093854970865214,
            "mae": 0.4408993462198659,
            "precision": 0.6840277777777778,
            "recall": 0.4164904862579281
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6849037395899256,
            "auditor_fn_violation": 0.0261506968422446,
            "auditor_fp_violation": 0.017563117453347977,
            "ave_precision_score": 0.6530324420294422,
            "fpr": 0.08342480790340286,
            "logloss": 0.6810448822290046,
            "mae": 0.42991215955674583,
            "precision": 0.735191637630662,
            "recall": 0.4386694386694387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6208653629943954,
            "auditor_fn_violation": 0.01155372575201217,
            "auditor_fp_violation": 0.028256504016305008,
            "ave_precision_score": 0.6194642304516296,
            "fpr": 0.19517543859649122,
            "logloss": 10.4579774724738,
            "mae": 0.4647202469195129,
            "precision": 0.5604938271604938,
            "recall": 0.4799154334038055
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6297971239377034,
            "auditor_fn_violation": 0.00905312979956231,
            "auditor_fp_violation": 0.011436448574273096,
            "ave_precision_score": 0.6265916650467862,
            "fpr": 0.19319429198682767,
            "logloss": 11.001887567634293,
            "mae": 0.4917405025384443,
            "precision": 0.5428571428571428,
            "recall": 0.43451143451143454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7460366829430598,
            "auditor_fn_violation": 0.025805793553651576,
            "auditor_fp_violation": 0.03181572952883347,
            "ave_precision_score": 0.7173127063602149,
            "fpr": 0.1162280701754386,
            "logloss": 3.2861613750351677,
            "mae": 0.32215538252068754,
            "precision": 0.744578313253012,
            "recall": 0.653276955602537
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7492871951939506,
            "auditor_fn_violation": 0.015354035112542252,
            "auditor_fp_violation": 0.040374747913103415,
            "ave_precision_score": 0.7158747004747619,
            "fpr": 0.11306256860592755,
            "logloss": 3.6485770689135544,
            "mae": 0.3249014227825304,
            "precision": 0.7576470588235295,
            "recall": 0.6694386694386695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7160666768158802,
            "auditor_fn_violation": 0.003943195727161458,
            "auditor_fp_violation": 0.0329821564160972,
            "ave_precision_score": 0.7080285555570296,
            "fpr": 0.14912280701754385,
            "logloss": 1.5480072784212078,
            "mae": 0.29580020182042405,
            "precision": 0.7263581488933601,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7220928401887734,
            "auditor_fn_violation": 0.016914998254185964,
            "auditor_fp_violation": 0.043468715697036225,
            "ave_precision_score": 0.7124840747223522,
            "fpr": 0.141602634467618,
            "logloss": 1.6977748641966233,
            "mae": 0.27362819387309156,
            "precision": 0.7504835589941973,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7198983039036831,
            "auditor_fn_violation": 0.007135306553911199,
            "auditor_fp_violation": 0.0020481157335251574,
            "ave_precision_score": 0.7025415259580898,
            "fpr": 0.015350877192982455,
            "logloss": 0.6698316327095966,
            "mae": 0.44329474582500233,
            "precision": 0.8931297709923665,
            "recall": 0.24735729386892177
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7147449259044599,
            "auditor_fn_violation": 0.006168542941320105,
            "auditor_fp_violation": 0.004875807316263753,
            "ave_precision_score": 0.7042782347852942,
            "fpr": 0.01646542261251372,
            "logloss": 0.6547482096448684,
            "mae": 0.4322148004565163,
            "precision": 0.9019607843137255,
            "recall": 0.2869022869022869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7445985065458969,
            "auditor_fn_violation": 0.008533159007455215,
            "auditor_fp_violation": 0.026887763257802823,
            "ave_precision_score": 0.7339349604566624,
            "fpr": 0.19407894736842105,
            "logloss": 1.7369603398874565,
            "mae": 0.29116045615293656,
            "precision": 0.6948275862068966,
            "recall": 0.8520084566596194
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7632314243929726,
            "auditor_fn_violation": 0.009048565579849885,
            "auditor_fp_violation": 0.03784239144308581,
            "ave_precision_score": 0.7488343264405846,
            "fpr": 0.18551042810098792,
            "logloss": 1.8102248046817195,
            "mae": 0.2707287317372231,
            "precision": 0.717391304347826,
            "recall": 0.8918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6657428659600433,
            "auditor_fn_violation": 0.025618022328548644,
            "auditor_fp_violation": 0.021430284138592496,
            "ave_precision_score": 0.639414163255642,
            "fpr": 0.10526315789473684,
            "logloss": 0.7096974283563101,
            "mae": 0.44079844232060406,
            "precision": 0.6767676767676768,
            "recall": 0.4249471458773784
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6876947611668875,
            "auditor_fn_violation": 0.028165799845272947,
            "auditor_fp_violation": 0.018201312128251608,
            "ave_precision_score": 0.657914358820904,
            "fpr": 0.09001097694840834,
            "logloss": 0.681383794847608,
            "mae": 0.42910488733345015,
            "precision": 0.722972972972973,
            "recall": 0.44490644490644493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7117740300788078,
            "auditor_fn_violation": 0.004640962872297021,
            "auditor_fp_violation": 0.03277234943851656,
            "ave_precision_score": 0.7031245913753722,
            "fpr": 0.14035087719298245,
            "logloss": 1.567643559321005,
            "mae": 0.2984021783489202,
            "precision": 0.732776617954071,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7176178569185917,
            "auditor_fn_violation": 0.019194826000534012,
            "auditor_fp_violation": 0.04480126617823501,
            "ave_precision_score": 0.7084051043221326,
            "fpr": 0.13172338090010977,
            "logloss": 1.695878729507489,
            "mae": 0.2743017538955593,
            "precision": 0.7585513078470825,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5621137962402049,
            "auditor_fn_violation": 0.02170496272393458,
            "auditor_fp_violation": 0.016936918035407426,
            "ave_precision_score": 0.5441761149061725,
            "fpr": 0.05592105263157895,
            "logloss": 0.6942214564446458,
            "mae": 0.4952046760733713,
            "precision": 0.6046511627906976,
            "recall": 0.1649048625792812
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.590292477857124,
            "auditor_fn_violation": 0.02272981416779443,
            "auditor_fp_violation": 0.017588645240344113,
            "ave_precision_score": 0.5668816816927057,
            "fpr": 0.052689352360043906,
            "logloss": 0.6865396840792807,
            "mae": 0.4929656269586963,
            "precision": 0.6496350364963503,
            "recall": 0.18503118503118504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5243540884669436,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5261197942346488,
            "fpr": 0.05043859649122807,
            "logloss": 0.6960613282745571,
            "mae": 0.5008039174503401,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5401047377500799,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5414828240234809,
            "fpr": 0.06147091108671789,
            "logloss": 0.6966087399016054,
            "mae": 0.5010845995171795,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.748934749909444,
            "auditor_fn_violation": 0.01642418678832388,
            "auditor_fp_violation": 0.0275396635095712,
            "ave_precision_score": 0.7187081236080797,
            "fpr": 0.21162280701754385,
            "logloss": 3.3015799372667587,
            "mae": 0.31443948452771087,
            "precision": 0.6643478260869565,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7497912352335667,
            "auditor_fn_violation": 0.01984750941940843,
            "auditor_fp_violation": 0.018390217752023083,
            "ave_precision_score": 0.7144248668948896,
            "fpr": 0.2239297475301866,
            "logloss": 3.670804306421078,
            "mae": 0.3316797298078959,
            "precision": 0.648881239242685,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6680028253982161,
            "auditor_fn_violation": 0.024781165387040546,
            "auditor_fp_violation": 0.019064960236582346,
            "ave_precision_score": 0.6415137193269616,
            "fpr": 0.10307017543859649,
            "logloss": 0.7067485117027063,
            "mae": 0.4402921554681502,
            "precision": 0.6802721088435374,
            "recall": 0.42283298097251587
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6876222320850263,
            "auditor_fn_violation": 0.028165799845272947,
            "auditor_fp_violation": 0.017588645240344113,
            "ave_precision_score": 0.6578619652503144,
            "fpr": 0.08781558726673985,
            "logloss": 0.6811009311709104,
            "mae": 0.42939542304278727,
            "precision": 0.7278911564625851,
            "recall": 0.44490644490644493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7178472606895716,
            "auditor_fn_violation": 0.0029579763361893114,
            "auditor_fp_violation": 0.029263077968269192,
            "ave_precision_score": 0.7120636428729068,
            "fpr": 0.13267543859649122,
            "logloss": 1.437943633882099,
            "mae": 0.29445081005948337,
            "precision": 0.7441860465116279,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7268145939794485,
            "auditor_fn_violation": 0.017010846868146544,
            "auditor_fp_violation": 0.041885992903275215,
            "ave_precision_score": 0.7194418065322982,
            "fpr": 0.12403951701427003,
            "logloss": 1.5271523349068694,
            "mae": 0.2699483711966528,
            "precision": 0.7689161554192229,
            "recall": 0.7817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6292823071025009,
            "auditor_fn_violation": 0.01161631616037982,
            "auditor_fp_violation": 0.02923810094712865,
            "ave_precision_score": 0.6222555109022089,
            "fpr": 0.1962719298245614,
            "logloss": 9.878900368223698,
            "mae": 0.46490194000105756,
            "precision": 0.5601965601965602,
            "recall": 0.4820295983086681
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.6513182688079752,
            "auditor_fn_violation": 0.007681581775983558,
            "auditor_fp_violation": 0.011436448574273096,
            "ave_precision_score": 0.644808064890093,
            "fpr": 0.19319429198682767,
            "logloss": 10.199708833757294,
            "mae": 0.4910998860798937,
            "precision": 0.5452196382428941,
            "recall": 0.4386694386694387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6674254465900388,
            "auditor_fn_violation": 0.027692778457772342,
            "auditor_fp_violation": 0.017334052671542182,
            "ave_precision_score": 0.6395399955213229,
            "fpr": 0.10197368421052631,
            "logloss": 0.7085043003940583,
            "mae": 0.4403381291123336,
            "precision": 0.6804123711340206,
            "recall": 0.4186046511627907
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6857768758926615,
            "auditor_fn_violation": 0.025053002001410352,
            "auditor_fp_violation": 0.014573813596099354,
            "ave_precision_score": 0.6535013119199613,
            "fpr": 0.0845225027442371,
            "logloss": 0.6836696700509064,
            "mae": 0.43035253888950914,
            "precision": 0.7326388888888888,
            "recall": 0.4386694386694387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 9296,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6881160120820295,
            "auditor_fn_violation": 0.006365676347316496,
            "auditor_fp_violation": 0.020818347120649016,
            "ave_precision_score": 0.6865223042036257,
            "fpr": 0.4133771929824561,
            "logloss": 3.287470673057359,
            "mae": 0.4454533816324771,
            "precision": 0.5413625304136253,
            "recall": 0.9408033826638478
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7178841112718425,
            "auditor_fn_violation": 0.003534988167260398,
            "auditor_fp_violation": 0.010047736961682797,
            "ave_precision_score": 0.7192610925381371,
            "fpr": 0.3973655323819978,
            "logloss": 3.1413978590103753,
            "mae": 0.43447553673101486,
            "precision": 0.5536374845869297,
            "recall": 0.9334719334719335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7996367677864188,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7520713429221899,
            "fpr": 0.47478070175438597,
            "logloss": 4.611808255480068,
            "mae": 0.4758412356188579,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8431077266876945,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.8007200895739759,
            "fpr": 0.4654226125137212,
            "logloss": 4.452820655469959,
            "mae": 0.4653803217267007,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6366744378147329,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005444990608640045,
            "ave_precision_score": 0.5044709631121003,
            "fpr": 0.48026315789473684,
            "logloss": 11.61661197915698,
            "mae": 0.48026401021101855,
            "precision": 0.5192096597145993,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6679313819549709,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0008679447578689377,
            "ave_precision_score": 0.5336587165939584,
            "fpr": 0.4698133918770582,
            "logloss": 11.215712172560442,
            "mae": 0.4697834253676348,
            "precision": 0.5291529152915292,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5407154983263429,
            "auditor_fn_violation": 0.08103603352991359,
            "auditor_fp_violation": 0.09887153818486993,
            "ave_precision_score": 0.5428301127472108,
            "fpr": 0.30372807017543857,
            "logloss": 0.6961621048744147,
            "mae": 0.4884920477846192,
            "precision": 0.5495934959349593,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5753475919424541,
            "auditor_fn_violation": 0.09261714640419362,
            "auditor_fp_violation": 0.09271181681260053,
            "ave_precision_score": 0.5771980035640745,
            "fpr": 0.2711306256860593,
            "logloss": 0.6762396580463157,
            "mae": 0.4806046563560505,
            "precision": 0.5834738617200674,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7065581696067521,
            "mae": 0.49036852055519775,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6931027262750824,
            "mae": 0.4861902065570203,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6368745474773043,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005444990608640045,
            "ave_precision_score": 0.5047339362779859,
            "fpr": 0.48026315789473684,
            "logloss": 11.621016899115073,
            "mae": 0.4802644541516337,
            "precision": 0.5192096597145993,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6674826250325103,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0008679447578689377,
            "ave_precision_score": 0.5333854255371102,
            "fpr": 0.4698133918770582,
            "logloss": 11.22177837365403,
            "mae": 0.4697878138761204,
            "precision": 0.5291529152915292,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8458101598699757,
            "auditor_fn_violation": 0.004979414710136867,
            "auditor_fp_violation": 0.012496003676617516,
            "ave_precision_score": 0.846429013420179,
            "fpr": 0.1162280701754386,
            "logloss": 0.8835355006209102,
            "mae": 0.25180879194655276,
            "precision": 0.774468085106383,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8837183493076959,
            "auditor_fn_violation": 0.009632785703038176,
            "auditor_fp_violation": 0.010997370637939399,
            "ave_precision_score": 0.8838923857063707,
            "fpr": 0.09769484083424808,
            "logloss": 0.730380976783402,
            "mae": 0.22268875192619103,
            "precision": 0.8098290598290598,
            "recall": 0.7879417879417879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6468759568058736,
            "auditor_fn_violation": 0.019398390267423335,
            "auditor_fp_violation": 0.011796647084682095,
            "ave_precision_score": 0.6150857874283621,
            "fpr": 0.08552631578947369,
            "logloss": 0.7300794826195801,
            "mae": 0.4485990798852423,
            "precision": 0.6829268292682927,
            "recall": 0.35517970401691334
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6576880280244105,
            "auditor_fn_violation": 0.012763840425750416,
            "auditor_fp_violation": 0.01094120950654788,
            "ave_precision_score": 0.6375807535772827,
            "fpr": 0.08122941822173436,
            "logloss": 0.7074638485675331,
            "mae": 0.4369992984767541,
            "precision": 0.7131782945736435,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6564059406579194,
            "auditor_fn_violation": 0.018230035977894004,
            "auditor_fp_violation": 0.010415417815609639,
            "ave_precision_score": 0.6209695305410938,
            "fpr": 0.07675438596491228,
            "logloss": 0.712345531353346,
            "mae": 0.4491636495579753,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6454409880133274,
            "auditor_fn_violation": 0.010575297073650554,
            "auditor_fp_violation": 0.007699180558037425,
            "ave_precision_score": 0.628692457254925,
            "fpr": 0.07793633369923161,
            "logloss": 0.7107172934826318,
            "mae": 0.4428205619986311,
            "precision": 0.7066115702479339,
            "recall": 0.35550935550935553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6468759568058736,
            "auditor_fn_violation": 0.019398390267423335,
            "auditor_fp_violation": 0.011796647084682095,
            "ave_precision_score": 0.6150857874283621,
            "fpr": 0.08552631578947369,
            "logloss": 0.7304150126852197,
            "mae": 0.44867839592329245,
            "precision": 0.6829268292682927,
            "recall": 0.35517970401691334
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6576880280244105,
            "auditor_fn_violation": 0.012763840425750416,
            "auditor_fp_violation": 0.01094120950654788,
            "ave_precision_score": 0.6375807535772827,
            "fpr": 0.08122941822173436,
            "logloss": 0.7077528210296509,
            "mae": 0.43706068282069804,
            "precision": 0.7131782945736435,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5621137962402049,
            "auditor_fn_violation": 0.02170496272393458,
            "auditor_fp_violation": 0.016936918035407426,
            "ave_precision_score": 0.5441761149061725,
            "fpr": 0.05592105263157895,
            "logloss": 0.6942220872956159,
            "mae": 0.4952058035618903,
            "precision": 0.6046511627906976,
            "recall": 0.1649048625792812
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.590292477857124,
            "auditor_fn_violation": 0.02272981416779443,
            "auditor_fp_violation": 0.017588645240344113,
            "ave_precision_score": 0.5668816816927057,
            "fpr": 0.052689352360043906,
            "logloss": 0.6865441857057816,
            "mae": 0.49296862214116705,
            "precision": 0.6496350364963503,
            "recall": 0.18503118503118504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7451425065104222,
            "auditor_fn_violation": 0.012123993917139574,
            "auditor_fp_violation": 0.02023138712384607,
            "ave_precision_score": 0.7373578841163273,
            "fpr": 0.15570175438596492,
            "logloss": 1.6876817813759764,
            "mae": 0.272188153918596,
            "precision": 0.7263969171483622,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7582735654070933,
            "auditor_fn_violation": 0.012467166144443865,
            "auditor_fp_violation": 0.03543256835064969,
            "ave_precision_score": 0.7480076150816702,
            "fpr": 0.14818880351262348,
            "logloss": 1.7224545076377626,
            "mae": 0.24884115540263702,
            "precision": 0.7471910112359551,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7563457358713699,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7483773816965482,
            "fpr": 0.47478070175438597,
            "logloss": 4.604059891700198,
            "mae": 0.4758417245094097,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8022390618990113,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.796436921937074,
            "fpr": 0.4654226125137212,
            "logloss": 4.444815317994469,
            "mae": 0.465380154554652,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7374934282059388,
            "auditor_fn_violation": 0.011171228811987685,
            "auditor_fp_violation": 0.01619010510330496,
            "ave_precision_score": 0.7385765204213589,
            "fpr": 0.23574561403508773,
            "logloss": 0.7431807455815211,
            "mae": 0.3753898480603546,
            "precision": 0.6386554621848739,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7817249926123714,
            "auditor_fn_violation": 0.006709402977240522,
            "auditor_fp_violation": 0.027217726495290133,
            "ave_precision_score": 0.7825783412330767,
            "fpr": 0.1942919868276619,
            "logloss": 0.6348390908169637,
            "mae": 0.33800210223504534,
            "precision": 0.6921739130434783,
            "recall": 0.8274428274428275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7729002434414817,
            "auditor_fn_violation": 0.01021382738029005,
            "auditor_fp_violation": 0.0063042001358749955,
            "ave_precision_score": 0.6559739935019467,
            "fpr": 0.019736842105263157,
            "logloss": 0.6655773171638091,
            "mae": 0.4340789746819881,
            "precision": 0.8909090909090909,
            "recall": 0.3107822410147992
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7983886678968964,
            "auditor_fn_violation": 0.01049314111882718,
            "auditor_fp_violation": 0.004689454471191892,
            "ave_precision_score": 0.6773433633480532,
            "fpr": 0.012074643249176729,
            "logloss": 0.6506285362404437,
            "mae": 0.42332918275838755,
            "precision": 0.9371428571428572,
            "recall": 0.340956340956341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7895747728536447,
            "auditor_fn_violation": 0.008057935536515721,
            "auditor_fp_violation": 0.0025076929225112897,
            "ave_precision_score": 0.7895472840283371,
            "fpr": 0.01206140350877193,
            "logloss": 0.6919358771463223,
            "mae": 0.44286226495598,
            "precision": 0.9133858267716536,
            "recall": 0.2452431289640592
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.8169385623562683,
            "auditor_fn_violation": 0.003019231339758236,
            "auditor_fp_violation": 0.0029816455211497716,
            "ave_precision_score": 0.8173573466278177,
            "fpr": 0.013172338090010977,
            "logloss": 0.6782896618421229,
            "mae": 0.43200195038693207,
            "precision": 0.9194630872483222,
            "recall": 0.28482328482328484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7294257556414736,
            "auditor_fn_violation": 0.015394922295167097,
            "auditor_fp_violation": 0.026578048195660002,
            "ave_precision_score": 0.719778628824991,
            "fpr": 0.14364035087719298,
            "logloss": 1.8265621709516902,
            "mae": 0.28174928609190997,
            "precision": 0.7298969072164948,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7396696493782735,
            "auditor_fn_violation": 0.01604779650882834,
            "auditor_fp_violation": 0.04224338192122125,
            "ave_precision_score": 0.7259246770730998,
            "fpr": 0.12952799121844127,
            "logloss": 1.9904468721692619,
            "mae": 0.25324574327146954,
            "precision": 0.7635270541082164,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6068417840665952,
            "auditor_fn_violation": 0.009284243907866925,
            "auditor_fp_violation": 0.008147504296047645,
            "ave_precision_score": 0.6088112723970236,
            "fpr": 0.13925438596491227,
            "logloss": 0.9168127303042645,
            "mae": 0.4584391346325467,
            "precision": 0.6068111455108359,
            "recall": 0.4143763213530655
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6618368220130281,
            "auditor_fn_violation": 0.007514987756480628,
            "auditor_fp_violation": 0.0129476935644449,
            "ave_precision_score": 0.6629957064993242,
            "fpr": 0.1119648737650933,
            "logloss": 0.8083940232670801,
            "mae": 0.4334118804222204,
            "precision": 0.6851851851851852,
            "recall": 0.46153846153846156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5243540884669436,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5261197942346488,
            "fpr": 0.05043859649122807,
            "logloss": 0.6953697430621829,
            "mae": 0.5006393985005847,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5401047377500799,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5414828240234809,
            "fpr": 0.06147091108671789,
            "logloss": 0.6958052535135945,
            "mae": 0.5008608143690781,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5183357235655096,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5220061362324284,
            "fpr": 0.05043859649122807,
            "logloss": 0.6951821675650631,
            "mae": 0.5005374139730345,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5032028717244674,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5242427287884787,
            "fpr": 0.06147091108671789,
            "logloss": 0.6960627776025928,
            "mae": 0.5009889677248723,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 9296,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6648509514219121,
            "auditor_fn_violation": 0.02600515559511888,
            "auditor_fp_violation": 0.024320125484554214,
            "ave_precision_score": 0.6436218651094557,
            "fpr": 0.09320175438596491,
            "logloss": 0.7107204021974719,
            "mae": 0.44036573687927766,
            "precision": 0.7007042253521126,
            "recall": 0.42071881606765327
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6773687734955995,
            "auditor_fn_violation": 0.029414113936616693,
            "auditor_fp_violation": 0.0223470247364256,
            "ave_precision_score": 0.6527711940270862,
            "fpr": 0.07903402854006586,
            "logloss": 0.6859117395183844,
            "mae": 0.42926433401102554,
            "precision": 0.7446808510638298,
            "recall": 0.4365904365904366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7726714478544366,
            "auditor_fn_violation": 0.009778012684989429,
            "auditor_fp_violation": 0.005105303121128566,
            "ave_precision_score": 0.7735767504857255,
            "fpr": 0.09758771929824561,
            "logloss": 0.5943614259306049,
            "mae": 0.3847059693918087,
            "precision": 0.7620320855614974,
            "recall": 0.6025369978858351
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8286984491599436,
            "auditor_fn_violation": 0.006483474101476298,
            "auditor_fp_violation": 0.006425343986929772,
            "ave_precision_score": 0.8299463365959563,
            "fpr": 0.06476399560922064,
            "logloss": 0.5362261973687974,
            "mae": 0.3555848268681597,
            "precision": 0.8387978142076503,
            "recall": 0.6382536382536382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7451403875339365,
            "auditor_fn_violation": 0.012123993917139574,
            "auditor_fp_violation": 0.02023138712384607,
            "ave_precision_score": 0.7373563460532008,
            "fpr": 0.15570175438596492,
            "logloss": 1.6876735744823264,
            "mae": 0.2721895502710463,
            "precision": 0.7263969171483622,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7582717986280906,
            "auditor_fn_violation": 0.012467166144443865,
            "auditor_fp_violation": 0.03543256835064969,
            "ave_precision_score": 0.748004078272879,
            "fpr": 0.14818880351262348,
            "logloss": 1.7224472428268183,
            "mae": 0.24884212759055738,
            "precision": 0.7471910112359551,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7746222264101013,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.752143147781952,
            "fpr": 0.47478070175438597,
            "logloss": 4.516820610829061,
            "mae": 0.47583974006090207,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8169255562016692,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.7979485038378276,
            "fpr": 0.4654226125137212,
            "logloss": 4.359085712060845,
            "mae": 0.4653777825862161,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7955623726285803,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7408396838852993,
            "fpr": 0.47478070175438597,
            "logloss": 4.520583791416371,
            "mae": 0.4758399787502259,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8393182464935223,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.789496736413235,
            "fpr": 0.4654226125137212,
            "logloss": 4.362720865828508,
            "mae": 0.46537804764107765,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6592929542676486,
            "auditor_fn_violation": 0.006875672267349137,
            "auditor_fp_violation": 0.025379151180913575,
            "ave_precision_score": 0.6584740675927496,
            "fpr": 0.36951754385964913,
            "logloss": 3.933318712539432,
            "mae": 0.4462226961789609,
            "precision": 0.5464333781965006,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6871172920472199,
            "auditor_fn_violation": 0.006928485523436131,
            "auditor_fp_violation": 0.01708319505782046,
            "ave_precision_score": 0.6866707796424169,
            "fpr": 0.3556531284302964,
            "logloss": 3.788293176862534,
            "mae": 0.4361608330555529,
            "precision": 0.5591836734693878,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8965282390809779,
            "mae": 0.5041922357922886,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.9010197314027305,
            "mae": 0.5070295500609683,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.577765589710057,
            "auditor_fn_violation": 0.05480137977078003,
            "auditor_fp_violation": 0.05527664548615275,
            "ave_precision_score": 0.5814325067324873,
            "fpr": 0.17653508771929824,
            "logloss": 0.7091063592819272,
            "mae": 0.48748515040693874,
            "precision": 0.5729442970822282,
            "recall": 0.45665961945031713
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.614750239315512,
            "auditor_fn_violation": 0.06598720649214612,
            "auditor_fp_violation": 0.0566589232379445,
            "ave_precision_score": 0.6154906639539179,
            "fpr": 0.15916575192096596,
            "logloss": 0.6855257710607372,
            "mae": 0.47948995624943896,
            "precision": 0.6070460704607046,
            "recall": 0.4656964656964657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5475721506226674,
            "auditor_fn_violation": 0.05301175772412003,
            "auditor_fp_violation": 0.054000319705870596,
            "ave_precision_score": 0.5628158651189366,
            "fpr": 0.16885964912280702,
            "logloss": 0.7094614626500185,
            "mae": 0.488470147323377,
            "precision": 0.574585635359116,
            "recall": 0.4397463002114165
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.584200205837968,
            "auditor_fn_violation": 0.056813124870205,
            "auditor_fp_violation": 0.05093304061470911,
            "ave_precision_score": 0.599486603875154,
            "fpr": 0.14928649835345773,
            "logloss": 0.6863026776804251,
            "mae": 0.48087666906443505,
            "precision": 0.6114285714285714,
            "recall": 0.44490644490644493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6560518140068847,
            "auditor_fn_violation": 0.0073717592077445285,
            "auditor_fp_violation": 0.0016684650121887863,
            "ave_precision_score": 0.6222011043230947,
            "fpr": 0.013157894736842105,
            "logloss": 0.68763615225673,
            "mae": 0.4523076388184308,
            "precision": 0.9032258064516129,
            "recall": 0.23678646934460887
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6976215807560793,
            "auditor_fn_violation": 0.006499448870469728,
            "auditor_fp_violation": 0.0015342199984683326,
            "ave_precision_score": 0.6551267702586372,
            "fpr": 0.012074643249176729,
            "logloss": 0.667941878363573,
            "mae": 0.4380140583819079,
            "precision": 0.9246575342465754,
            "recall": 0.2806652806652807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7458822881221865,
            "auditor_fn_violation": 0.027254645599198844,
            "auditor_fp_violation": 0.03181572952883347,
            "ave_precision_score": 0.7157044101145074,
            "fpr": 0.1162280701754386,
            "logloss": 3.3979148998122732,
            "mae": 0.3229978500251421,
            "precision": 0.7427184466019418,
            "recall": 0.6469344608879493
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7491549236852818,
            "auditor_fn_violation": 0.015913152027312295,
            "auditor_fp_violation": 0.040374747913103415,
            "ave_precision_score": 0.7136601904066863,
            "fpr": 0.11306256860592755,
            "logloss": 3.782871189666723,
            "mae": 0.3252320645492792,
            "precision": 0.7570754716981132,
            "recall": 0.6673596673596673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6252929997776513,
            "auditor_fn_violation": 0.011447090241459899,
            "auditor_fp_violation": 0.029592774647324474,
            "ave_precision_score": 0.6221489875338894,
            "fpr": 0.19298245614035087,
            "logloss": 10.56237174772488,
            "mae": 0.4646922327826581,
            "precision": 0.5621890547263682,
            "recall": 0.47780126849894294
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.635946357621176,
            "auditor_fn_violation": 0.012667991811789845,
            "auditor_fp_violation": 0.012074643249176734,
            "ave_precision_score": 0.6321639037386858,
            "fpr": 0.18880351262349068,
            "logloss": 11.130193830661574,
            "mae": 0.4913988517731213,
            "precision": 0.5473684210526316,
            "recall": 0.43243243243243246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8129962226125215,
            "auditor_fn_violation": 0.010800322688327589,
            "auditor_fp_violation": 0.011067318067378016,
            "ave_precision_score": 0.81288084086233,
            "fpr": 0.12390350877192982,
            "logloss": 1.0750227326665327,
            "mae": 0.2714464839266807,
            "precision": 0.7554112554112554,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8570172718653353,
            "auditor_fn_violation": 0.009936306313913344,
            "auditor_fp_violation": 0.0057565159676307666,
            "ave_precision_score": 0.8570038024840889,
            "fpr": 0.10647639956092206,
            "logloss": 0.9012880418635727,
            "mae": 0.2396989789597737,
            "precision": 0.7927350427350427,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.621642572879523,
            "auditor_fn_violation": 0.08615685619969586,
            "auditor_fp_violation": 0.09535727131039444,
            "ave_precision_score": 0.5487111213998281,
            "fpr": 0.3059210526315789,
            "logloss": 0.6880915372374152,
            "mae": 0.4930332945496367,
            "precision": 0.5514469453376206,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6897095206295215,
            "auditor_fn_violation": 0.08192089750816427,
            "auditor_fp_violation": 0.09122099405202563,
            "ave_precision_score": 0.5717171657719328,
            "fpr": 0.278814489571899,
            "logloss": 0.6801374920089067,
            "mae": 0.4902550183915411,
            "precision": 0.5738255033557047,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.663384943118163,
            "auditor_fn_violation": 0.014379566781647575,
            "auditor_fp_violation": 0.006061923030811657,
            "ave_precision_score": 0.6313922341134544,
            "fpr": 0.08662280701754387,
            "logloss": 0.7168527912330335,
            "mae": 0.44004759695707707,
            "precision": 0.6973180076628352,
            "recall": 0.38477801268498946
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6703049937012435,
            "auditor_fn_violation": 0.014206133854871511,
            "auditor_fp_violation": 0.005886707681311111,
            "ave_precision_score": 0.6518711912577703,
            "fpr": 0.07793633369923161,
            "logloss": 0.6870673291208486,
            "mae": 0.42937890777996157,
            "precision": 0.7320754716981132,
            "recall": 0.40332640332640335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7996359350399456,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7520723308849824,
            "fpr": 0.47478070175438597,
            "logloss": 4.578552726077591,
            "mae": 0.47584205258189155,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8430868201339258,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.800701182503182,
            "fpr": 0.4654226125137212,
            "logloss": 4.419424295117192,
            "mae": 0.46537856822804186,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7403869365453579,
            "auditor_fn_violation": 0.013667890656874748,
            "auditor_fp_violation": 0.01520850817248132,
            "ave_precision_score": 0.7338632490727144,
            "fpr": 0.16557017543859648,
            "logloss": 1.6271821853311756,
            "mae": 0.2780032057227041,
            "precision": 0.7177570093457943,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7496606707950191,
            "auditor_fn_violation": 0.012044975821046078,
            "auditor_fp_violation": 0.037727516401603156,
            "ave_precision_score": 0.7421708408159441,
            "fpr": 0.16355653128430298,
            "logloss": 1.653144204871746,
            "mae": 0.26174342295362707,
            "precision": 0.730072463768116,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7425954845071736,
            "auditor_fn_violation": 0.011857405140758878,
            "auditor_fp_violation": 0.018045897774047883,
            "ave_precision_score": 0.70973106811605,
            "fpr": 0.18201754385964913,
            "logloss": 3.421807703717726,
            "mae": 0.32903003315817714,
            "precision": 0.6862003780718336,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7533726152408301,
            "auditor_fn_violation": 0.013847842607447437,
            "auditor_fp_violation": 0.022206621907946807,
            "ave_precision_score": 0.718233292620927,
            "fpr": 0.16794731064763996,
            "logloss": 3.7044474887088135,
            "mae": 0.3291334364995769,
            "precision": 0.7074569789674953,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6795905786666506,
            "auditor_fn_violation": 0.002702978376173001,
            "auditor_fp_violation": 0.005994485073732168,
            "ave_precision_score": 0.6808660891306363,
            "fpr": 0.1162280701754386,
            "logloss": 0.7639199131149674,
            "mae": 0.4053095340341237,
            "precision": 0.7111716621253406,
            "recall": 0.5517970401691332
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7589114912757043,
            "auditor_fn_violation": 0.009050847689706097,
            "auditor_fp_violation": 0.008516069741914073,
            "ave_precision_score": 0.7597999099706662,
            "fpr": 0.08342480790340286,
            "logloss": 0.6431546170614834,
            "mae": 0.36839489501143435,
            "precision": 0.7923497267759563,
            "recall": 0.6029106029106029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6586237960468483,
            "auditor_fn_violation": 0.006875672267349137,
            "auditor_fp_violation": 0.025379151180913575,
            "ave_precision_score": 0.6572717059009912,
            "fpr": 0.36951754385964913,
            "logloss": 3.9537472994395544,
            "mae": 0.44612686333590834,
            "precision": 0.5464333781965006,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6877296408739432,
            "auditor_fn_violation": 0.006928485523436131,
            "auditor_fp_violation": 0.01708319505782046,
            "ave_precision_score": 0.6860840558706996,
            "fpr": 0.3556531284302964,
            "logloss": 3.808106036795605,
            "mae": 0.43610981458701026,
            "precision": 0.5591836734693878,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7289976316809579,
            "auditor_fn_violation": 0.0073717592077445285,
            "auditor_fp_violation": 0.0024527434760020783,
            "ave_precision_score": 0.6771765081160299,
            "fpr": 0.01206140350877193,
            "logloss": 0.683087673024568,
            "mae": 0.44419501521297844,
            "precision": 0.9105691056910569,
            "recall": 0.23678646934460887
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7569245552188055,
            "auditor_fn_violation": 0.009803943942253491,
            "auditor_fp_violation": 0.0017614173027340266,
            "ave_precision_score": 0.7163514906466122,
            "fpr": 0.010976948408342482,
            "logloss": 0.6615970058458372,
            "mae": 0.4295231447617486,
            "precision": 0.9305555555555556,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.638367703475999,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005444990608640045,
            "ave_precision_score": 0.5069319951667519,
            "fpr": 0.48026315789473684,
            "logloss": 11.461191431614468,
            "mae": 0.48027886997198965,
            "precision": 0.5192096597145993,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6677561954281569,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0008679447578689377,
            "ave_precision_score": 0.5342935466200677,
            "fpr": 0.4698133918770582,
            "logloss": 11.08369878436822,
            "mae": 0.4697378338751452,
            "precision": 0.5291529152915292,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6222590918759645,
            "auditor_fn_violation": 0.011447090241459899,
            "auditor_fp_violation": 0.029592774647324474,
            "ave_precision_score": 0.620018490419626,
            "fpr": 0.19298245614035087,
            "logloss": 10.604570680381812,
            "mae": 0.46464950979262704,
            "precision": 0.5621890547263682,
            "recall": 0.47780126849894294
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6324808682239241,
            "auditor_fn_violation": 0.012667991811789845,
            "auditor_fp_violation": 0.012074643249176734,
            "ave_precision_score": 0.6291383781419482,
            "fpr": 0.18880351262349068,
            "logloss": 11.190621757671357,
            "mae": 0.4915791376904338,
            "precision": 0.5473684210526316,
            "recall": 0.43243243243243246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7465789340411972,
            "auditor_fn_violation": 0.02486693742813694,
            "auditor_fp_violation": 0.02948787115853415,
            "ave_precision_score": 0.7151294888163541,
            "fpr": 0.11951754385964912,
            "logloss": 3.4058367186162797,
            "mae": 0.3224880289137602,
            "precision": 0.7404761904761905,
            "recall": 0.6575052854122622
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7525214582935399,
            "auditor_fn_violation": 0.009203749050071772,
            "auditor_fp_violation": 0.04007096724784928,
            "ave_precision_score": 0.716941302985592,
            "fpr": 0.11745334796926454,
            "logloss": 3.7544817794564382,
            "mae": 0.32401736057823444,
            "precision": 0.7568181818181818,
            "recall": 0.6923076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7555197768441674,
            "auditor_fn_violation": 0.008370887578353926,
            "auditor_fp_violation": 0.01919733844862726,
            "ave_precision_score": 0.753277590160659,
            "fpr": 0.13048245614035087,
            "logloss": 1.0511195305145495,
            "mae": 0.288621174918674,
            "precision": 0.7457264957264957,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7732358077649021,
            "auditor_fn_violation": 0.017798174768537012,
            "auditor_fp_violation": 0.03315548975059352,
            "ave_precision_score": 0.7726312675602871,
            "fpr": 0.1141602634467618,
            "logloss": 1.0819789260613526,
            "mae": 0.26536246451142614,
            "precision": 0.7815126050420168,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6644072015854772,
            "auditor_fn_violation": 0.015406513111531489,
            "auditor_fp_violation": 0.004066259041681657,
            "ave_precision_score": 0.6323371132110017,
            "fpr": 0.08662280701754387,
            "logloss": 0.7158437629640984,
            "mae": 0.4394632701418902,
            "precision": 0.6984732824427481,
            "recall": 0.386892177589852
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6689901820377099,
            "auditor_fn_violation": 0.013551168326140893,
            "auditor_fp_violation": 0.008214841855359561,
            "ave_precision_score": 0.6504611339003885,
            "fpr": 0.07903402854006586,
            "logloss": 0.6897795284103042,
            "mae": 0.42988270740346773,
            "precision": 0.7293233082706767,
            "recall": 0.40332640332640335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6260023960614398,
            "auditor_fn_violation": 0.013259893920848637,
            "auditor_fp_violation": 0.00699106821724014,
            "ave_precision_score": 0.6199767142445158,
            "fpr": 0.051535087719298246,
            "logloss": 9.092279963494677,
            "mae": 0.4627488931306157,
            "precision": 0.7006369426751592,
            "recall": 0.23255813953488372
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6479590195749318,
            "auditor_fn_violation": 0.0050845407596230964,
            "auditor_fp_violation": 0.005028974038240627,
            "ave_precision_score": 0.6424642369145711,
            "fpr": 0.036223929747530186,
            "logloss": 9.656844747348478,
            "mae": 0.4635374644382231,
            "precision": 0.7785234899328859,
            "recall": 0.24116424116424118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5265204250009596,
            "auditor_fn_violation": 0.061711824487222296,
            "auditor_fp_violation": 0.08149002917316069,
            "ave_precision_score": 0.5286114629695025,
            "fpr": 0.24013157894736842,
            "logloss": 0.7021159697621094,
            "mae": 0.4927762435808402,
            "precision": 0.5330490405117271,
            "recall": 0.5285412262156448
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5596469145605272,
            "auditor_fn_violation": 0.07320551996732019,
            "auditor_fp_violation": 0.08048911239884614,
            "ave_precision_score": 0.5610826600790497,
            "fpr": 0.22502744237102085,
            "logloss": 0.6884082955310149,
            "mae": 0.4879135358833292,
            "precision": 0.5665961945031712,
            "recall": 0.5571725571725572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7729123907499649,
            "auditor_fn_violation": 0.01021382738029005,
            "auditor_fp_violation": 0.0063042001358749955,
            "ave_precision_score": 0.7004572054575683,
            "fpr": 0.019736842105263157,
            "logloss": 0.6656655974782355,
            "mae": 0.43387535781387176,
            "precision": 0.8909090909090909,
            "recall": 0.3107822410147992
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.788239179250775,
            "auditor_fn_violation": 0.01049314111882718,
            "auditor_fp_violation": 0.004689454471191892,
            "ave_precision_score": 0.7141275144943144,
            "fpr": 0.012074643249176729,
            "logloss": 0.6485330047123061,
            "mae": 0.4227885003441906,
            "precision": 0.9371428571428572,
            "recall": 0.340956340956341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7389592100782357,
            "auditor_fn_violation": 0.011857405140758878,
            "auditor_fp_violation": 0.018045897774047883,
            "ave_precision_score": 0.7065389992396449,
            "fpr": 0.18201754385964913,
            "logloss": 3.485861901861195,
            "mae": 0.3338338929130897,
            "precision": 0.6862003780718336,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7522922602026229,
            "auditor_fn_violation": 0.013847842607447437,
            "auditor_fp_violation": 0.022206621907946807,
            "ave_precision_score": 0.7185418174396057,
            "fpr": 0.16794731064763996,
            "logloss": 3.7518579951542317,
            "mae": 0.3320385533145529,
            "precision": 0.7074569789674953,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 9296,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8468330999210558,
            "auditor_fn_violation": 0.0004242238789362429,
            "auditor_fp_violation": 0.014146984774007915,
            "ave_precision_score": 0.8471534403827388,
            "fpr": 0.11513157894736842,
            "logloss": 0.8867439464758614,
            "mae": 0.2513669827254526,
            "precision": 0.7722342733188721,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8841384599078828,
            "auditor_fn_violation": 0.009883817787220646,
            "auditor_fp_violation": 0.010563398259004927,
            "ave_precision_score": 0.8843149458456763,
            "fpr": 0.09110867178924259,
            "logloss": 0.7424716288878647,
            "mae": 0.2206915992685451,
            "precision": 0.8191721132897604,
            "recall": 0.7817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5987755225387584,
            "auditor_fn_violation": 0.009363061459144707,
            "auditor_fp_violation": 0.00835231586940016,
            "ave_precision_score": 0.6007621245190077,
            "fpr": 0.14364035087719298,
            "logloss": 0.9354436159949784,
            "mae": 0.4624665515818337,
            "precision": 0.600609756097561,
            "recall": 0.4164904862579281
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6591811432948947,
            "auditor_fn_violation": 0.008028462474126589,
            "auditor_fp_violation": 0.013836060551910761,
            "ave_precision_score": 0.6603440924633373,
            "fpr": 0.11525795828759605,
            "logloss": 0.8189717832810013,
            "mae": 0.4355632978961539,
            "precision": 0.6798780487804879,
            "recall": 0.46361746361746364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5341687544213675,
            "auditor_fn_violation": 0.006801491042617115,
            "auditor_fp_violation": 0.008954262078887424,
            "ave_precision_score": 0.5304530209574835,
            "fpr": 0.05043859649122807,
            "logloss": 0.6951552501981023,
            "mae": 0.5006176204208219,
            "precision": 0.5353535353535354,
            "recall": 0.11205073995771671
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5464962986224138,
            "auditor_fn_violation": 0.009858714578802425,
            "auditor_fp_violation": 0.000566716871314428,
            "ave_precision_score": 0.5443936334742019,
            "fpr": 0.06147091108671789,
            "logloss": 0.6956284704893121,
            "mae": 0.5008600709794251,
            "precision": 0.5294117647058824,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7594290983106231,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7488793619587115,
            "fpr": 0.47478070175438597,
            "logloss": 4.599118506700617,
            "mae": 0.4758408658613296,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8021457025957675,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.7931543361042648,
            "fpr": 0.4654226125137212,
            "logloss": 4.442065816302832,
            "mae": 0.46537962972471225,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6056773011176917,
            "auditor_fn_violation": 0.08615685619969586,
            "auditor_fp_violation": 0.09535727131039444,
            "ave_precision_score": 0.5461225312828307,
            "fpr": 0.3059210526315789,
            "logloss": 0.6970083258968538,
            "mae": 0.4933839767125615,
            "precision": 0.5514469453376206,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7258000399415173,
            "auditor_fn_violation": 0.08192089750816427,
            "auditor_fp_violation": 0.09122099405202563,
            "ave_precision_score": 0.5747565352542552,
            "fpr": 0.278814489571899,
            "logloss": 0.6766178401459028,
            "mae": 0.48862813987271325,
            "precision": 0.5738255033557047,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.736916804165379,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7149752306269814,
            "fpr": 0.47478070175438597,
            "logloss": 4.028651791480377,
            "mae": 0.47576783830927644,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8020561697793199,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.7721556419047694,
            "fpr": 0.4654226125137212,
            "logloss": 3.8713193343057664,
            "mae": 0.46529125729918663,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 9296,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7906853043736292,
            "auditor_fn_violation": 0.004328010830458812,
            "auditor_fp_violation": 0.020148962954082247,
            "ave_precision_score": 0.790560321337932,
            "fpr": 0.13048245614035087,
            "logloss": 0.8920182385615472,
            "mae": 0.2748882055711495,
            "precision": 0.7566462167689162,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.7993211682178283,
            "auditor_fn_violation": 0.014977486986268548,
            "auditor_fp_violation": 0.028195440737242488,
            "ave_precision_score": 0.7996746080515554,
            "fpr": 0.12623490669593854,
            "logloss": 0.85957925602198,
            "mae": 0.2541043676035842,
            "precision": 0.7749510763209393,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7560660378664761,
            "auditor_fn_violation": 0.0073717592077445285,
            "auditor_fp_violation": 0.0016684650121887863,
            "ave_precision_score": 0.614046476937129,
            "fpr": 0.013157894736842105,
            "logloss": 0.6840100377057445,
            "mae": 0.4508377441548203,
            "precision": 0.9032258064516129,
            "recall": 0.23678646934460887
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7834992000756853,
            "auditor_fn_violation": 0.006499448870469728,
            "auditor_fp_violation": 0.0015342199984683326,
            "ave_precision_score": 0.645280860100983,
            "fpr": 0.012074643249176729,
            "logloss": 0.665048112344852,
            "mae": 0.4369806886520789,
            "precision": 0.9246575342465754,
            "recall": 0.2806652806652807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7160643250246594,
            "auditor_fn_violation": 0.003943195727161458,
            "auditor_fp_violation": 0.0329821564160972,
            "ave_precision_score": 0.7080352307509259,
            "fpr": 0.14912280701754385,
            "logloss": 1.548248799681045,
            "mae": 0.29580246910880964,
            "precision": 0.7263581488933601,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7220897271601414,
            "auditor_fn_violation": 0.016914998254185964,
            "auditor_fp_violation": 0.043468715697036225,
            "ave_precision_score": 0.7124866909605508,
            "fpr": 0.141602634467618,
            "logloss": 1.698022599031619,
            "mae": 0.2736335226162421,
            "precision": 0.7504835589941973,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7261740383973991,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7041098533634358,
            "fpr": 0.47478070175438597,
            "logloss": 4.497601402575094,
            "mae": 0.4758568048520725,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7919270082720185,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.7606764297005836,
            "fpr": 0.4654226125137212,
            "logloss": 4.330067969366286,
            "mae": 0.4653963211590637,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8450725793957029,
            "auditor_fn_violation": 0.004258465932272546,
            "auditor_fp_violation": 0.012496003676617516,
            "ave_precision_score": 0.8455255978163647,
            "fpr": 0.1162280701754386,
            "logloss": 0.881834664962454,
            "mae": 0.25220924074491935,
            "precision": 0.7739872068230277,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.883569715112704,
            "auditor_fn_violation": 0.009183210061365936,
            "auditor_fp_violation": 0.010655298292191048,
            "ave_precision_score": 0.8837485153039097,
            "fpr": 0.09769484083424808,
            "logloss": 0.7280855341424772,
            "mae": 0.22346514169858456,
            "precision": 0.8102345415778252,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6354307237154411,
            "auditor_fn_violation": 0.006201086754942328,
            "auditor_fp_violation": 0.02663549534428327,
            "ave_precision_score": 0.5130630396952791,
            "fpr": 0.32456140350877194,
            "logloss": 9.494084310540847,
            "mae": 0.48431947332625114,
            "precision": 0.5410852713178295,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6635502328069279,
            "auditor_fn_violation": 0.01485197094417732,
            "auditor_fp_violation": 0.005743752074132696,
            "ave_precision_score": 0.5390276916261115,
            "fpr": 0.29637760702524696,
            "logloss": 9.210967329930146,
            "mae": 0.45238561048167303,
            "precision": 0.5794392523364486,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7300417085301588,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7337979887832051,
            "fpr": 0.47478070175438597,
            "logloss": 4.576943103388446,
            "mae": 0.4758379383928246,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8250269817988676,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.8254405318052831,
            "fpr": 0.4654226125137212,
            "logloss": 4.415709364760486,
            "mae": 0.46537801252740807,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    }
]