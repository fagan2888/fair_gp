[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8139565437839731,
            "auditor_fn_violation": 0.019111649738381045,
            "auditor_fp_violation": 0.02417089873807325,
            "ave_precision_score": 0.8143208462689113,
            "fpr": 0.16228070175438597,
            "logloss": 0.8033190003991484,
            "mae": 0.27173022214046016,
            "precision": 0.7098039215686275,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.834334538408451,
            "auditor_fn_violation": 0.01719281076005449,
            "auditor_fp_violation": 0.02850551372384337,
            "ave_precision_score": 0.8348158446296879,
            "fpr": 0.1350164654226125,
            "logloss": 0.7865539788548699,
            "mae": 0.27074411591130687,
            "precision": 0.7588235294117647,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8133011154322083,
            "auditor_fn_violation": 0.01624538319482918,
            "auditor_fp_violation": 0.02337257617728532,
            "ave_precision_score": 0.8136741785672541,
            "fpr": 0.1611842105263158,
            "logloss": 0.8040513013720152,
            "mae": 0.2716784741132747,
            "precision": 0.711764705882353,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8339960883914598,
            "auditor_fn_violation": 0.01719281076005449,
            "auditor_fp_violation": 0.03045903844058229,
            "ave_precision_score": 0.8344795221727853,
            "fpr": 0.13611416026344675,
            "logloss": 0.7875276240849859,
            "mae": 0.2710521717804867,
            "precision": 0.7573385518590998,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7502786509448764,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5016525868568461,
            "fpr": 0.4956140350877193,
            "logloss": 17.121845485542295,
            "mae": 0.4968480631104556,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7757475083056478,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5514950166112956,
            "fpr": 0.4445664105378705,
            "logloss": 15.355630254029974,
            "mae": 0.445045459021852,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6140125770856415,
            "auditor_fn_violation": 0.08739227454601417,
            "auditor_fp_violation": 0.11205370883348724,
            "ave_precision_score": 0.6346477236818215,
            "fpr": 0.2982456140350877,
            "logloss": 0.6774542374003643,
            "mae": 0.42357427986306057,
            "precision": 0.5562805872756933,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6563094937499031,
            "auditor_fn_violation": 0.0995066985835769,
            "auditor_fp_violation": 0.0964775424393278,
            "ave_precision_score": 0.663372384487645,
            "fpr": 0.300768386388584,
            "logloss": 0.6631820848466766,
            "mae": 0.4196527408912336,
            "precision": 0.571875,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.789624737499478,
            "auditor_fn_violation": 0.002183364112034472,
            "auditor_fp_violation": 0.010726858264081252,
            "ave_precision_score": 0.7545273845976014,
            "fpr": 0.4682017543859649,
            "logloss": 5.433786086335929,
            "mae": 0.4664377737769636,
            "precision": 0.5142207053469852,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.8342099260899979,
            "auditor_fn_violation": 0.0004893338447092432,
            "auditor_fp_violation": 0.009501837907947785,
            "ave_precision_score": 0.8089689017199666,
            "fpr": 0.42371020856201974,
            "logloss": 4.67980473449455,
            "mae": 0.42276019343632865,
            "precision": 0.5618615209988649,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8135094976366349,
            "auditor_fn_violation": 0.018395083102493076,
            "auditor_fp_violation": 0.023257156048014777,
            "ave_precision_score": 0.8138716863985425,
            "fpr": 0.15679824561403508,
            "logloss": 0.8042753201489362,
            "mae": 0.2721583199756049,
            "precision": 0.717391304347826,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.834405275636573,
            "auditor_fn_violation": 0.014210519355137343,
            "auditor_fp_violation": 0.028263648758913795,
            "ave_precision_score": 0.8348857888055196,
            "fpr": 0.13611416026344675,
            "logloss": 0.787268614306835,
            "mae": 0.2708506636212617,
            "precision": 0.7582846003898636,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.8327964966433689,
            "auditor_fn_violation": 0.01313625346260388,
            "auditor_fp_violation": 0.02799659510618653,
            "ave_precision_score": 0.8330267961211643,
            "fpr": 0.33223684210526316,
            "logloss": 1.3760726648658912,
            "mae": 0.36038747724530185,
            "precision": 0.5871934604904632,
            "recall": 0.9451754385964912
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8386783309471606,
            "auditor_fn_violation": 0.007904284536609667,
            "auditor_fp_violation": 0.02717126963159449,
            "ave_precision_score": 0.8393572245407357,
            "fpr": 0.29527991218441274,
            "logloss": 1.2047919294590659,
            "mae": 0.3280638816761481,
            "precision": 0.6369770580296896,
            "recall": 0.9477911646586346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6175994915093063,
            "auditor_fn_violation": 0.08200600184672206,
            "auditor_fp_violation": 0.1115246999076639,
            "ave_precision_score": 0.6384517499553233,
            "fpr": 0.3026315789473684,
            "logloss": 0.6769855575633751,
            "mae": 0.42263604406463473,
            "precision": 0.5576923076923077,
            "recall": 0.7631578947368421
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6654500810031008,
            "auditor_fn_violation": 0.08869286145680416,
            "auditor_fp_violation": 0.0921027102165356,
            "ave_precision_score": 0.6724942304434289,
            "fpr": 0.3029637760702525,
            "logloss": 0.6629410227145307,
            "mae": 0.41889309981259243,
            "precision": 0.5792682926829268,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6130470180152576,
            "auditor_fn_violation": 0.00196695136965222,
            "auditor_fp_violation": 0.002522410741766697,
            "ave_precision_score": 0.5143692564745197,
            "fpr": 0.007675438596491228,
            "logloss": 16.627696728350113,
            "mae": 0.4829419737338628,
            "precision": 0.7586206896551724,
            "recall": 0.04824561403508772
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.6321516398561681,
            "auditor_fn_violation": 0.002940411481270866,
            "auditor_fp_violation": 0.0009222762948413659,
            "ave_precision_score": 0.5629980588288022,
            "fpr": 0.0043907793633369925,
            "logloss": 18.127576017645627,
            "mae": 0.5279260458165022,
            "precision": 0.8461538461538461,
            "recall": 0.04417670682730924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5939554203491183,
            "auditor_fn_violation": 0.003905047706986779,
            "auditor_fp_violation": 0.0008969105878731918,
            "ave_precision_score": 0.5100965132128567,
            "fpr": 0.005482456140350877,
            "logloss": 16.817091760596227,
            "mae": 0.48845036618672966,
            "precision": 0.7619047619047619,
            "recall": 0.03508771929824561
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5791049925391903,
            "auditor_fn_violation": 0.003202712055687076,
            "auditor_fp_violation": 0.0012438769624949833,
            "ave_precision_score": 0.5566218142131015,
            "fpr": 0.003293084522502744,
            "logloss": 18.431044039954692,
            "mae": 0.5367873471749601,
            "precision": 0.8125,
            "recall": 0.02610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.23636974496921,
            "mae": 0.5000413302911049,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880944340743227,
            "mae": 0.5468861439588967,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.8228297314076389,
            "auditor_fn_violation": 0.01071483533394891,
            "auditor_fp_violation": 0.011871441212680836,
            "ave_precision_score": 0.8236265077122716,
            "fpr": 0.43969298245614036,
            "logloss": 1.566438924487914,
            "mae": 0.44031306079756305,
            "precision": 0.5209080047789725,
            "recall": 0.956140350877193
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.8188296640757362,
            "auditor_fn_violation": 0.00558545929051001,
            "auditor_fp_violation": 0.021246906919198512,
            "ave_precision_score": 0.8193664944300385,
            "fpr": 0.3929747530186608,
            "logloss": 1.4099532176714762,
            "mae": 0.40055629862375297,
            "precision": 0.5717703349282297,
            "recall": 0.9598393574297188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6152892716846343,
            "auditor_fn_violation": 0.08739227454601417,
            "auditor_fp_violation": 0.11001461988304094,
            "ave_precision_score": 0.6360728609310566,
            "fpr": 0.2916666666666667,
            "logloss": 0.676996160082127,
            "mae": 0.4226611169675986,
            "precision": 0.5617792421746294,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.658070897203675,
            "auditor_fn_violation": 0.0995066985835769,
            "auditor_fp_violation": 0.09263428156802919,
            "ave_precision_score": 0.6652756166615644,
            "fpr": 0.29198682766191,
            "logloss": 0.6641750838320314,
            "mae": 0.41948797114594183,
            "precision": 0.5791139240506329,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.605733489423387,
            "auditor_fn_violation": 0.08637753924284394,
            "auditor_fp_violation": 0.10091566635887966,
            "ave_precision_score": 0.6077919577111941,
            "fpr": 0.2675438596491228,
            "logloss": 0.676652674750456,
            "mae": 0.48932360178023054,
            "precision": 0.5771230502599654,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6016551874563469,
            "auditor_fn_violation": 0.09618716358298177,
            "auditor_fp_violation": 0.08424342778470298,
            "ave_precision_score": 0.6023169873178842,
            "fpr": 0.27661909989023054,
            "logloss": 0.6854069315887804,
            "mae": 0.493468142301662,
            "precision": 0.5827814569536424,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.23648282590583,
            "mae": 0.5000374641819546,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880920745344994,
            "mae": 0.5468656677644848,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.715680811218457,
            "auditor_fn_violation": 0.013561865189289013,
            "auditor_fp_violation": 0.006319252077562329,
            "ave_precision_score": 0.6857745891885648,
            "fpr": 0.039473684210526314,
            "logloss": 14.192718872319562,
            "mae": 0.41260419818655947,
            "precision": 0.7631578947368421,
            "recall": 0.2543859649122807
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7752495179576543,
            "auditor_fn_violation": 0.011470690666067134,
            "auditor_fp_violation": 0.0071071089694692,
            "ave_precision_score": 0.7529560047144178,
            "fpr": 0.030735455543358946,
            "logloss": 14.36046723756049,
            "mae": 0.42030921224278434,
            "precision": 0.8362573099415205,
            "recall": 0.28714859437751006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.718603081520631,
            "auditor_fn_violation": 0.08324195906432749,
            "auditor_fp_violation": 0.10031692443828873,
            "ave_precision_score": 0.5627529597474228,
            "fpr": 0.2642543859649123,
            "logloss": 0.6728455689839838,
            "mae": 0.48057829787987366,
            "precision": 0.5726950354609929,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7059101620529612,
            "auditor_fn_violation": 0.09780505115963305,
            "auditor_fp_violation": 0.086561078877215,
            "ave_precision_score": 0.5903940058233101,
            "fpr": 0.25905598243688255,
            "logloss": 0.675738484130735,
            "mae": 0.48100370593966035,
            "precision": 0.5972696245733788,
            "recall": 0.7028112449799196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.36586245608970414,
            "auditor_fn_violation": 0.09143197907048324,
            "auditor_fp_violation": 0.10200013465681748,
            "ave_precision_score": 0.5574973375839309,
            "fpr": 0.26864035087719296,
            "logloss": 0.6846251934278471,
            "mae": 0.4844709207679619,
            "precision": 0.5663716814159292,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.38131145569254976,
            "auditor_fn_violation": 0.10440664965019243,
            "auditor_fp_violation": 0.09471804126588403,
            "ave_precision_score": 0.5839347869225695,
            "fpr": 0.2711306256860593,
            "logloss": 0.6814628988301723,
            "mae": 0.48251009651518023,
            "precision": 0.5869565217391305,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.80109101668809,
            "auditor_fn_violation": 0.001091682056017236,
            "auditor_fp_violation": 0.005992228377962443,
            "ave_precision_score": 0.7812695281846082,
            "fpr": 0.4780701754385965,
            "logloss": 4.96711783202904,
            "mae": 0.4743545790719636,
            "precision": 0.5101123595505618,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.8354575906152502,
            "auditor_fn_violation": 0.0010271602325878709,
            "auditor_fp_violation": 0.007306448226279295,
            "ave_precision_score": 0.8184759284884888,
            "fpr": 0.43468715697036225,
            "logloss": 4.410380446822739,
            "mae": 0.4312035673988928,
            "precision": 0.5560538116591929,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7141875267436885,
            "auditor_fn_violation": 0.08739227454601417,
            "auditor_fp_violation": 0.11222683902739307,
            "ave_precision_score": 0.5407342033946655,
            "fpr": 0.30043859649122806,
            "logloss": 0.6849177746815984,
            "mae": 0.49399977569517334,
            "precision": 0.5544715447154471,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.726644358515007,
            "auditor_fn_violation": 0.09875285995794374,
            "auditor_fp_violation": 0.0964775424393278,
            "ave_precision_score": 0.5657322509159476,
            "fpr": 0.300768386388584,
            "logloss": 0.68672380885614,
            "mae": 0.4948723470602025,
            "precision": 0.5725429017160687,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 19863,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7333045622905581,
            "auditor_fn_violation": 0.01306652046783627,
            "auditor_fp_violation": 0.004737034472145277,
            "ave_precision_score": 0.6932042191959594,
            "fpr": 0.07675438596491228,
            "logloss": 6.88634590409714,
            "mae": 0.36857690613547067,
            "precision": 0.7307692307692307,
            "recall": 0.4166666666666667
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.789013217438991,
            "auditor_fn_violation": 0.013912951476597959,
            "auditor_fp_violation": 0.006910427569416577,
            "ave_precision_score": 0.7590589241709713,
            "fpr": 0.059275521405049394,
            "logloss": 6.78508092694561,
            "mae": 0.3704383501323455,
            "precision": 0.8,
            "recall": 0.43373493975903615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6140125770856415,
            "auditor_fn_violation": 0.08739227454601417,
            "auditor_fp_violation": 0.11205370883348724,
            "ave_precision_score": 0.6346477236818215,
            "fpr": 0.2982456140350877,
            "logloss": 0.6783292341081759,
            "mae": 0.4239126555621624,
            "precision": 0.5562805872756933,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6566692584370787,
            "auditor_fn_violation": 0.0995066985835769,
            "auditor_fp_violation": 0.09611341606355468,
            "ave_precision_score": 0.6637799494745072,
            "fpr": 0.2996706915477497,
            "logloss": 0.6632526435987004,
            "mae": 0.4195448150684491,
            "precision": 0.5727699530516432,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.8015212170374821,
            "auditor_fn_violation": 0.001091682056017236,
            "auditor_fp_violation": 0.005992228377962443,
            "ave_precision_score": 0.7808846642035334,
            "fpr": 0.4780701754385965,
            "logloss": 5.025834082005409,
            "mae": 0.4748763422224198,
            "precision": 0.5101123595505618,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.8345376738255043,
            "auditor_fn_violation": 0.0010271602325878709,
            "auditor_fp_violation": 0.007306448226279295,
            "ave_precision_score": 0.8158219870181793,
            "fpr": 0.43468715697036225,
            "logloss": 4.507279589153157,
            "mae": 0.4318793617384769,
            "precision": 0.5560538116591929,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.8019189672223855,
            "auditor_fn_violation": 0.002183364112034472,
            "auditor_fp_violation": 0.012696214219759933,
            "ave_precision_score": 0.7940963964485546,
            "fpr": 0.4594298245614035,
            "logloss": 3.9378855995434967,
            "mae": 0.45784019485451727,
            "precision": 0.5189437428243399,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.8370657795209213,
            "auditor_fn_violation": 0.0010271602325878709,
            "auditor_fp_violation": 0.013916537982102004,
            "ave_precision_score": 0.8314074902072902,
            "fpr": 0.4149286498353458,
            "logloss": 3.455315278242148,
            "mae": 0.4154903977979619,
            "precision": 0.5675057208237986,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7298032768548959,
            "auditor_fn_violation": 0.011962815481686687,
            "auditor_fp_violation": 0.008656509695290863,
            "ave_precision_score": 0.6907410024138894,
            "fpr": 0.06140350877192982,
            "logloss": 8.448400696954101,
            "mae": 0.38176403805911885,
            "precision": 0.7419354838709677,
            "recall": 0.3530701754385965
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7882912051466726,
            "auditor_fn_violation": 0.012262000802331172,
            "auditor_fp_violation": 0.0066765361747594,
            "ave_precision_score": 0.7590399278222816,
            "fpr": 0.043907793633369926,
            "logloss": 8.476465748989904,
            "mae": 0.38045486407536583,
            "precision": 0.8268398268398268,
            "recall": 0.38353413654618473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6796428989630368,
            "auditor_fn_violation": 0.011994075100030787,
            "auditor_fp_violation": 0.007021391197291475,
            "ave_precision_score": 0.5706295337303929,
            "fpr": 0.027412280701754384,
            "logloss": 14.22133175242077,
            "mae": 0.4301299640138746,
            "precision": 0.7807017543859649,
            "recall": 0.19517543859649122
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7445232802031545,
            "auditor_fn_violation": 0.011248065808789504,
            "auditor_fp_violation": 0.0038671815821158134,
            "ave_precision_score": 0.6362531746139618,
            "fpr": 0.020856201975850714,
            "logloss": 14.667962783969497,
            "mae": 0.44804278639811357,
            "precision": 0.8515625,
            "recall": 0.21887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8097366658203766,
            "auditor_fn_violation": 0.022038030932594644,
            "auditor_fp_violation": 0.02625807940904894,
            "ave_precision_score": 0.8100483825573621,
            "fpr": 0.17105263157894737,
            "logloss": 0.8630330250977658,
            "mae": 0.2798864317283471,
            "precision": 0.7005758157389635,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8301788335053268,
            "auditor_fn_violation": 0.011913736174114687,
            "auditor_fp_violation": 0.030514853432489112,
            "ave_precision_score": 0.8306730631212187,
            "fpr": 0.14489571899012074,
            "logloss": 0.8449896204708816,
            "mae": 0.27983396959433593,
            "precision": 0.7446808510638298,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7064189488284911,
            "auditor_fn_violation": 0.030480532471529705,
            "auditor_fp_violation": 0.017601569713758078,
            "ave_precision_score": 0.6983851961045847,
            "fpr": 0.13267543859649122,
            "logloss": 1.5638164124338536,
            "mae": 0.3679252772718635,
            "precision": 0.6936708860759494,
            "recall": 0.6008771929824561
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7643381610370652,
            "auditor_fn_violation": 0.017951057798703048,
            "auditor_fp_violation": 0.026958641090997045,
            "ave_precision_score": 0.7581481170096125,
            "fpr": 0.11525795828759605,
            "logloss": 1.3084173938026915,
            "mae": 0.3524254135435813,
            "precision": 0.7457627118644068,
            "recall": 0.6184738955823293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7302636906134393,
            "auditor_fn_violation": 0.011895487072945535,
            "auditor_fp_violation": 0.00858677670052324,
            "ave_precision_score": 0.6904492667774762,
            "fpr": 0.07346491228070176,
            "logloss": 7.739972654892196,
            "mae": 0.37074681093124723,
            "precision": 0.7341269841269841,
            "recall": 0.4057017543859649
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7887597420842843,
            "auditor_fn_violation": 0.012881382830994687,
            "auditor_fp_violation": 0.006214069098959982,
            "ave_precision_score": 0.7595076713026316,
            "fpr": 0.05378704720087816,
            "logloss": 7.692138354966886,
            "mae": 0.3732681071651878,
            "precision": 0.8093385214007782,
            "recall": 0.41767068273092367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 19863,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.33296783625730997,
            "auditor_fn_violation": 0.0006011465066174313,
            "auditor_fp_violation": 0.0022603108648815025,
            "ave_precision_score": 0.49963450292397665,
            "fpr": 0.0043859649122807015,
            "logloss": 17.274661098069807,
            "mae": 0.5028037822952396,
            "precision": 0.2,
            "recall": 0.0021929824561403508
        },
        "train": {
            "accuracy": 0.446761800219539,
            "auc_prc": 0.37584277835821883,
            "auditor_fn_violation": 0.0012872566004964033,
            "auditor_fp_violation": 0.0038778130091456854,
            "ave_precision_score": 0.5484727053108152,
            "fpr": 0.008781558726673985,
            "logloss": 18.821153125236595,
            "mae": 0.5510437471544704,
            "precision": 0.2,
            "recall": 0.004016064257028112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7502786509448764,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5016525868568461,
            "fpr": 0.4956140350877193,
            "logloss": 17.12100016380581,
            "mae": 0.49749529247351904,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7757475083056478,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5514950166112956,
            "fpr": 0.4445664105378705,
            "logloss": 15.358177755070443,
            "mae": 0.44709792082186717,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.8031153748167429,
            "auditor_fn_violation": 0.001091682056017236,
            "auditor_fp_violation": 0.005992228377962443,
            "ave_precision_score": 0.7808258201697507,
            "fpr": 0.4780701754385965,
            "logloss": 5.10953178573407,
            "mae": 0.47568789051647714,
            "precision": 0.5101123595505618,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.8375175562559183,
            "auditor_fn_violation": 0.0010271602325878709,
            "auditor_fp_violation": 0.007306448226279295,
            "ave_precision_score": 0.8184150878012599,
            "fpr": 0.43468715697036225,
            "logloss": 4.562427613961416,
            "mae": 0.4325440431906779,
            "precision": 0.5560538116591929,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8092239612007013,
            "auditor_fn_violation": 0.021929824561403514,
            "auditor_fp_violation": 0.027474799938442603,
            "ave_precision_score": 0.8095373539246082,
            "fpr": 0.1699561403508772,
            "logloss": 0.8621166270085069,
            "mae": 0.2798741425095413,
            "precision": 0.7001934235976789,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8298707771416319,
            "auditor_fn_violation": 0.010432509400940763,
            "auditor_fp_violation": 0.03298666021693427,
            "ave_precision_score": 0.8304035684922314,
            "fpr": 0.1437980241492865,
            "logloss": 0.8454509494073914,
            "mae": 0.2801551496735498,
            "precision": 0.745136186770428,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6997135476485773,
            "auditor_fn_violation": 0.029220529393659593,
            "auditor_fp_violation": 0.0275781971375808,
            "ave_precision_score": 0.698496910774398,
            "fpr": 0.1611842105263158,
            "logloss": 1.2897248952910825,
            "mae": 0.40012842939611065,
            "precision": 0.676923076923077,
            "recall": 0.6754385964912281
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7619700756997089,
            "auditor_fn_violation": 0.01766891936571753,
            "auditor_fp_violation": 0.03289363523042289,
            "ave_precision_score": 0.7592884986423545,
            "fpr": 0.141602634467618,
            "logloss": 1.1055119833504097,
            "mae": 0.37822618445894723,
            "precision": 0.7207792207792207,
            "recall": 0.6686746987951807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7998239546053842,
            "auditor_fn_violation": 0.023564943059402897,
            "auditor_fp_violation": 0.021573945829485998,
            "ave_precision_score": 0.8001226175519056,
            "fpr": 0.16885964912280702,
            "logloss": 0.9344396965213363,
            "mae": 0.30084713747016517,
            "precision": 0.6907630522088354,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8146511556071747,
            "auditor_fn_violation": 0.010284827564924907,
            "auditor_fp_violation": 0.026339360466507016,
            "ave_precision_score": 0.8152353564652552,
            "fpr": 0.14928649835345773,
            "logloss": 1.077020442799947,
            "mae": 0.31048828373559834,
            "precision": 0.7246963562753036,
            "recall": 0.7188755020080321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7169072930568869,
            "auditor_fn_violation": 0.003751154201292705,
            "auditor_fp_violation": 0.017168744228993553,
            "ave_precision_score": 0.7152010268810409,
            "fpr": 0.41118421052631576,
            "logloss": 0.8252068577808118,
            "mae": 0.44267163725096015,
            "precision": 0.5398773006134969,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7453544968870687,
            "auditor_fn_violation": 0.0030682554587174167,
            "auditor_fp_violation": 0.02801381022371182,
            "ave_precision_score": 0.7441500454465503,
            "fpr": 0.3589462129527991,
            "logloss": 0.7169600402751729,
            "mae": 0.4296046442032253,
            "precision": 0.5937888198757764,
            "recall": 0.9598393574297188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.718323057148105,
            "auditor_fn_violation": 0.08552631578947367,
            "auditor_fp_violation": 0.1087738534933826,
            "ave_precision_score": 0.720198544726208,
            "fpr": 0.2883771929824561,
            "logloss": 0.6798084488692522,
            "mae": 0.49075177958921384,
            "precision": 0.5652892561983471,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7044963661232531,
            "auditor_fn_violation": 0.09875285995794374,
            "auditor_fp_violation": 0.09185552953809109,
            "ave_precision_score": 0.7058681198308947,
            "fpr": 0.29308452250274425,
            "logloss": 0.6840932804648983,
            "mae": 0.49276496124843344,
            "precision": 0.5788643533123028,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8357597598359249,
            "auditor_fn_violation": 0.013095375500153893,
            "auditor_fp_violation": 0.028277931671283493,
            "ave_precision_score": 0.836003489330978,
            "fpr": 0.3157894736842105,
            "logloss": 1.3062321959288015,
            "mae": 0.35195464978255386,
            "precision": 0.5988857938718662,
            "recall": 0.9429824561403509
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.8406855608576946,
            "auditor_fn_violation": 0.0070755028897147325,
            "auditor_fp_violation": 0.02787294381556601,
            "ave_precision_score": 0.8413835703490824,
            "fpr": 0.27771679473106475,
            "logloss": 1.1451474313738887,
            "mae": 0.32104760398572557,
            "precision": 0.6490984743411928,
            "recall": 0.9397590361445783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 19863,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8133057279442706,
            "auditor_fn_violation": 0.014146179593721147,
            "auditor_fp_violation": 0.027037165281625124,
            "ave_precision_score": 0.8135658322606081,
            "fpr": 0.2949561403508772,
            "logloss": 1.2832542943386565,
            "mae": 0.33266556704957223,
            "precision": 0.611271676300578,
            "recall": 0.9276315789473685
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8338831836378611,
            "auditor_fn_violation": 0.006542084914851504,
            "auditor_fp_violation": 0.02387552725233426,
            "ave_precision_score": 0.8342848024148941,
            "fpr": 0.24478594950603733,
            "logloss": 1.1155010816989137,
            "mae": 0.3018120059099395,
            "precision": 0.6749271137026239,
            "recall": 0.929718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.43649843271949385,
            "auditor_fn_violation": 0.09143197907048324,
            "auditor_fp_violation": 0.1015793321021853,
            "ave_precision_score": 0.5286328324367132,
            "fpr": 0.2675438596491228,
            "logloss": 0.6810404348847272,
            "mae": 0.4867186678671523,
            "precision": 0.5673758865248227,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.47140230678472606,
            "auditor_fn_violation": 0.10440664965019243,
            "auditor_fp_violation": 0.09646691101229792,
            "ave_precision_score": 0.551710209392684,
            "fpr": 0.2689352360043908,
            "logloss": 0.6802353075757621,
            "mae": 0.48606694016184426,
            "precision": 0.5889261744966443,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7639798739176543,
            "auditor_fn_violation": 0.015913550323176363,
            "auditor_fp_violation": 0.015985687903970456,
            "ave_precision_score": 0.7644640169262329,
            "fpr": 0.18859649122807018,
            "logloss": 1.0720340779843587,
            "mae": 0.3038096409784765,
            "precision": 0.6820702402957486,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7995183079176371,
            "auditor_fn_violation": 0.007617737690608764,
            "auditor_fp_violation": 0.024372546465980766,
            "ave_precision_score": 0.7999563163886455,
            "fpr": 0.17233809001097694,
            "logloss": 1.0275978828625107,
            "mae": 0.3030814403220874,
            "precision": 0.7097966728280961,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 19863,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.8153418181269504,
            "auditor_fn_violation": 0.013004001231148045,
            "auditor_fp_violation": 0.015043090181594328,
            "ave_precision_score": 0.8159623387753776,
            "fpr": 0.43201754385964913,
            "logloss": 1.4219226486982572,
            "mae": 0.4279499232443254,
            "precision": 0.5241545893719807,
            "recall": 0.9517543859649122
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.8180449381956111,
            "auditor_fn_violation": 0.007035827172576145,
            "auditor_fp_violation": 0.021855556116658664,
            "ave_precision_score": 0.8185957086079613,
            "fpr": 0.38309549945115257,
            "logloss": 1.2575904989390079,
            "mae": 0.38432603881035315,
            "precision": 0.5774818401937046,
            "recall": 0.9578313253012049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 19863,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.33296783625730997,
            "auditor_fn_violation": 0.0006011465066174313,
            "auditor_fp_violation": 0.001861149584487535,
            "ave_precision_score": 0.49963450292397665,
            "fpr": 0.005482456140350877,
            "logloss": 17.277713320677602,
            "mae": 0.5035562202857252,
            "precision": 0.16666666666666666,
            "recall": 0.0021929824561403508
        },
        "train": {
            "accuracy": 0.446761800219539,
            "auc_prc": 0.37584277835821883,
            "auditor_fn_violation": 0.0012872566004964033,
            "auditor_fp_violation": 0.0038778130091456854,
            "ave_precision_score": 0.5484727053108152,
            "fpr": 0.008781558726673985,
            "logloss": 18.82577969470325,
            "mae": 0.5520053074074629,
            "precision": 0.2,
            "recall": 0.004016064257028112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6670520544682204,
            "auditor_fn_violation": 0.08640158510310866,
            "auditor_fp_violation": 0.07552804709141275,
            "ave_precision_score": 0.6827119924409236,
            "fpr": 0.20942982456140352,
            "logloss": 0.6363044124032986,
            "mae": 0.39688991606562285,
            "precision": 0.6217821782178218,
            "recall": 0.6885964912280702
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7240628174934148,
            "auditor_fn_violation": 0.09640978844025941,
            "auditor_fp_violation": 0.07081327758921761,
            "ave_precision_score": 0.7299186870207937,
            "fpr": 0.20197585071350166,
            "logloss": 0.6198687150889978,
            "mae": 0.39523235451671346,
            "precision": 0.6495238095238095,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.236482755204705,
            "mae": 0.5000374666583651,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880920759959924,
            "mae": 0.5468656805492608,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8059385908243839,
            "auditor_fn_violation": 0.023033529547553094,
            "auditor_fp_violation": 0.028277931671283476,
            "ave_precision_score": 0.8062657479133977,
            "fpr": 0.16776315789473684,
            "logloss": 0.8827490310707407,
            "mae": 0.2806599634708733,
            "precision": 0.7034883720930233,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8297937685210373,
            "auditor_fn_violation": 0.009925541904169924,
            "auditor_fp_violation": 0.0341933271848247,
            "ave_precision_score": 0.8302017171754877,
            "fpr": 0.14489571899012074,
            "logloss": 0.8615187894673442,
            "mae": 0.2806254119603488,
            "precision": 0.7436893203883496,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5939554203491183,
            "auditor_fn_violation": 0.003905047706986779,
            "auditor_fp_violation": 0.0008969105878731918,
            "ave_precision_score": 0.5100965132128567,
            "fpr": 0.005482456140350877,
            "logloss": 16.817103009032618,
            "mae": 0.4884576555668262,
            "precision": 0.7619047619047619,
            "recall": 0.03508771929824561
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5791049925391903,
            "auditor_fn_violation": 0.003202712055687076,
            "auditor_fp_violation": 0.0012438769624949833,
            "ave_precision_score": 0.5566218142131015,
            "fpr": 0.003293084522502744,
            "logloss": 18.43108800630095,
            "mae": 0.5368094128259058,
            "precision": 0.8125,
            "recall": 0.02610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.717994682870039,
            "auditor_fn_violation": 0.08552631578947367,
            "auditor_fp_violation": 0.1087738534933826,
            "ave_precision_score": 0.7198601180427023,
            "fpr": 0.2883771929824561,
            "logloss": 0.6798783519337336,
            "mae": 0.49067597947361175,
            "precision": 0.5652892561983471,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.704351704634602,
            "auditor_fn_violation": 0.09875285995794374,
            "auditor_fp_violation": 0.09185552953809109,
            "ave_precision_score": 0.7057236494822563,
            "fpr": 0.29308452250274425,
            "logloss": 0.6840794204741026,
            "mae": 0.4926412474899732,
            "precision": 0.5788643533123028,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7638408954659164,
            "auditor_fn_violation": 0.015913550323176363,
            "auditor_fp_violation": 0.015985687903970456,
            "ave_precision_score": 0.7643335252358016,
            "fpr": 0.18859649122807018,
            "logloss": 1.0719875754610435,
            "mae": 0.30380377457470137,
            "precision": 0.6820702402957486,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7995251429563149,
            "auditor_fn_violation": 0.008569954901934854,
            "auditor_fp_violation": 0.024372546465980766,
            "ave_precision_score": 0.7999690463318797,
            "fpr": 0.17233809001097694,
            "logloss": 1.0277253704284697,
            "mae": 0.3031343777919591,
            "precision": 0.7092592592592593,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6130470180152576,
            "auditor_fn_violation": 0.00196695136965222,
            "auditor_fp_violation": 0.002522410741766697,
            "ave_precision_score": 0.5143692564745197,
            "fpr": 0.007675438596491228,
            "logloss": 16.627696733241432,
            "mae": 0.4829419793953237,
            "precision": 0.7586206896551724,
            "recall": 0.04824561403508772
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.6321516398561681,
            "auditor_fn_violation": 0.002940411481270866,
            "auditor_fp_violation": 0.0009222762948413659,
            "ave_precision_score": 0.5629980588288022,
            "fpr": 0.0043907793633369925,
            "logloss": 18.127576059803342,
            "mae": 0.5279260729690022,
            "precision": 0.8461538461538461,
            "recall": 0.04417670682730924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.47941444520391896,
            "auditor_fn_violation": 0.002171341181902138,
            "auditor_fp_violation": 0.001077254539858418,
            "ave_precision_score": 0.5007148553201185,
            "fpr": 0.0021929824561403508,
            "logloss": 17.195918014424976,
            "mae": 0.4990587171668538,
            "precision": 0.6,
            "recall": 0.006578947368421052
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.5016770693508485,
            "auditor_fn_violation": 0.005076287587231479,
            "auditor_fp_violation": 0.0014910576409394992,
            "ave_precision_score": 0.5511146250917015,
            "fpr": 0.003293084522502744,
            "logloss": 18.655602948490767,
            "mae": 0.5416297036495048,
            "precision": 0.7,
            "recall": 0.014056224899598393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7933457819146561,
            "auditor_fn_violation": 0.01517053324099723,
            "auditor_fp_violation": 0.02349761465066176,
            "ave_precision_score": 0.7937111267333881,
            "fpr": 0.27850877192982454,
            "logloss": 1.3445569366493897,
            "mae": 0.3241452094589161,
            "precision": 0.6214605067064084,
            "recall": 0.9144736842105263
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8256503382046938,
            "auditor_fn_violation": 0.007476668474116003,
            "auditor_fp_violation": 0.022488126024936033,
            "ave_precision_score": 0.8260030045212533,
            "fpr": 0.2349066959385291,
            "logloss": 1.1671303543134717,
            "mae": 0.29531582038278487,
            "precision": 0.6815476190476191,
            "recall": 0.9196787148594378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7079146768617876,
            "auditor_fn_violation": 0.09025613650353956,
            "auditor_fp_violation": 0.10031692443828873,
            "ave_precision_score": 0.5483386983097689,
            "fpr": 0.2642543859649123,
            "logloss": 0.6809656034108249,
            "mae": 0.4859876008540915,
            "precision": 0.568100358422939,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7278730511186736,
            "auditor_fn_violation": 0.10521338923201037,
            "auditor_fp_violation": 0.086561078877215,
            "ave_precision_score": 0.5812111748636327,
            "fpr": 0.25905598243688255,
            "logloss": 0.6801911827477869,
            "mae": 0.4855378228275496,
            "precision": 0.5938037865748709,
            "recall": 0.6927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7837546681761101,
            "auditor_fn_violation": 0.008733456448137888,
            "auditor_fp_violation": 0.021251731301939053,
            "ave_precision_score": 0.782376521020371,
            "fpr": 0.3925438596491228,
            "logloss": 2.895113150878357,
            "mae": 0.4088450221529074,
            "precision": 0.5525,
            "recall": 0.9692982456140351
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.80757390908741,
            "auditor_fn_violation": 0.011415585503374641,
            "auditor_fp_violation": 0.019080753661862158,
            "ave_precision_score": 0.8068881102526511,
            "fpr": 0.3677277716794731,
            "logloss": 2.7244929947773335,
            "mae": 0.382919985960185,
            "precision": 0.5884520884520884,
            "recall": 0.9618473895582329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7795588433106597,
            "auditor_fn_violation": 0.010395025392428441,
            "auditor_fp_violation": 0.02154509079716836,
            "ave_precision_score": 0.7791391933152051,
            "fpr": 0.37280701754385964,
            "logloss": 2.474289548949535,
            "mae": 0.3920389551644554,
            "precision": 0.5612903225806452,
            "recall": 0.9539473684210527
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8026754885711916,
            "auditor_fn_violation": 0.012466992007547206,
            "auditor_fp_violation": 0.01548201561225061,
            "ave_precision_score": 0.8024425578403334,
            "fpr": 0.3336992316136114,
            "logloss": 2.348930839213618,
            "mae": 0.3601083713369348,
            "precision": 0.6102564102564103,
            "recall": 0.9558232931726908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8069110604024649,
            "auditor_fn_violation": 0.022391505078485696,
            "auditor_fp_violation": 0.026248461064943062,
            "ave_precision_score": 0.8072349052370984,
            "fpr": 0.1699561403508772,
            "logloss": 0.8704129425418682,
            "mae": 0.2801529556937899,
            "precision": 0.6990291262135923,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8301614637972419,
            "auditor_fn_violation": 0.012392048986285433,
            "auditor_fp_violation": 0.03050156414870177,
            "ave_precision_score": 0.8303669902931703,
            "fpr": 0.14270032930845225,
            "logloss": 0.8526297670549063,
            "mae": 0.28050665213249715,
            "precision": 0.74609375,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.36586245608970414,
            "auditor_fn_violation": 0.09143197907048324,
            "auditor_fp_violation": 0.10200013465681748,
            "ave_precision_score": 0.5574973375839309,
            "fpr": 0.26864035087719296,
            "logloss": 0.6846869660182786,
            "mae": 0.4844552068072453,
            "precision": 0.5663716814159292,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.38131145569254976,
            "auditor_fn_violation": 0.10440664965019243,
            "auditor_fp_violation": 0.09471804126588403,
            "ave_precision_score": 0.5839347869225695,
            "fpr": 0.2711306256860593,
            "logloss": 0.6814853966979166,
            "mae": 0.4824731191282869,
            "precision": 0.5869565217391305,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8139565437839731,
            "auditor_fn_violation": 0.019111649738381045,
            "auditor_fp_violation": 0.02417089873807325,
            "ave_precision_score": 0.8143208462689113,
            "fpr": 0.16228070175438597,
            "logloss": 0.8033186358235629,
            "mae": 0.2717301590455507,
            "precision": 0.7098039215686275,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.834334538408451,
            "auditor_fn_violation": 0.01719281076005449,
            "auditor_fp_violation": 0.02850551372384337,
            "ave_precision_score": 0.8348158446296879,
            "fpr": 0.1350164654226125,
            "logloss": 0.786553500857486,
            "mae": 0.2707440881270056,
            "precision": 0.7588235294117647,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7636516963814823,
            "auditor_fn_violation": 0.015915954909202834,
            "auditor_fp_violation": 0.016259810710987997,
            "ave_precision_score": 0.7641403683434156,
            "fpr": 0.19078947368421054,
            "logloss": 1.0653191606829948,
            "mae": 0.3043007953234168,
            "precision": 0.6807339449541284,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8000877297737765,
            "auditor_fn_violation": 0.0005157843228016385,
            "auditor_fp_violation": 0.02516192992294874,
            "ave_precision_score": 0.8006077660307451,
            "fpr": 0.17014270032930845,
            "logloss": 1.0190188054974354,
            "mae": 0.30262398597251966,
            "precision": 0.712430426716141,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.7214498444823771,
            "auditor_fn_violation": 0.08627654662973222,
            "auditor_fp_violation": 0.10381078793474918,
            "ave_precision_score": 0.5589078074533238,
            "fpr": 0.27521929824561403,
            "logloss": 0.6748014733258456,
            "mae": 0.48199093425867484,
            "precision": 0.5724020442930153,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7273267264165713,
            "auditor_fn_violation": 0.09778741750757144,
            "auditor_fp_violation": 0.08502483767139854,
            "ave_precision_score": 0.5759163926872685,
            "fpr": 0.2810098792535675,
            "logloss": 0.679328987506186,
            "mae": 0.48724993478235756,
            "precision": 0.5850891410048622,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.718603081520631,
            "auditor_fn_violation": 0.08324195906432749,
            "auditor_fp_violation": 0.10031692443828873,
            "ave_precision_score": 0.5627529597474228,
            "fpr": 0.2642543859649123,
            "logloss": 0.6728455689839838,
            "mae": 0.48057829787987366,
            "precision": 0.5726950354609929,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7059101620529612,
            "auditor_fn_violation": 0.09780505115963305,
            "auditor_fp_violation": 0.086561078877215,
            "ave_precision_score": 0.5903940058233101,
            "fpr": 0.25905598243688255,
            "logloss": 0.675738484130735,
            "mae": 0.48100370593966035,
            "precision": 0.5972696245733788,
            "recall": 0.7028112449799196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8091448517324388,
            "auditor_fn_violation": 0.021929824561403514,
            "auditor_fp_violation": 0.0255078485687904,
            "ave_precision_score": 0.8094555360773092,
            "fpr": 0.17105263157894737,
            "logloss": 0.8675134126249636,
            "mae": 0.2801280098827406,
            "precision": 0.6988416988416989,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.829903279475595,
            "auditor_fn_violation": 0.010432509400940763,
            "auditor_fp_violation": 0.03289363523042289,
            "ave_precision_score": 0.8304445575554764,
            "fpr": 0.141602634467618,
            "logloss": 0.8497077014622824,
            "mae": 0.280647225183858,
            "precision": 0.748046875,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8181072549633825,
            "auditor_fn_violation": 0.0167118728839643,
            "auditor_fp_violation": 0.024408952754693763,
            "ave_precision_score": 0.8184518850781763,
            "fpr": 0.16557017543859648,
            "logloss": 0.7998296425809596,
            "mae": 0.27098931502462986,
            "precision": 0.7118320610687023,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8361002863687543,
            "auditor_fn_violation": 0.014726303677938979,
            "auditor_fp_violation": 0.03125373761106519,
            "ave_precision_score": 0.8366053787351386,
            "fpr": 0.14270032930845225,
            "logloss": 0.7830148848661582,
            "mae": 0.2691999866243113,
            "precision": 0.751434034416826,
            "recall": 0.7891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7079146768617876,
            "auditor_fn_violation": 0.09025613650353956,
            "auditor_fp_violation": 0.10031692443828873,
            "ave_precision_score": 0.5483386983097689,
            "fpr": 0.2642543859649123,
            "logloss": 0.6809656034108249,
            "mae": 0.4859876008540915,
            "precision": 0.568100358422939,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7278730511186736,
            "auditor_fn_violation": 0.10521338923201037,
            "auditor_fp_violation": 0.086561078877215,
            "ave_precision_score": 0.5812111748636327,
            "fpr": 0.25905598243688255,
            "logloss": 0.6801911827477869,
            "mae": 0.4855378228275496,
            "precision": 0.5938037865748709,
            "recall": 0.6927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7007405717761351,
            "auditor_fn_violation": 0.029220529393659593,
            "auditor_fp_violation": 0.0275781971375808,
            "ave_precision_score": 0.6992762498841039,
            "fpr": 0.1611842105263158,
            "logloss": 1.2449750504027044,
            "mae": 0.40104221719268124,
            "precision": 0.676923076923077,
            "recall": 0.6754385964912281
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7615603966616289,
            "auditor_fn_violation": 0.01766891936571753,
            "auditor_fp_violation": 0.03289363523042289,
            "ave_precision_score": 0.7590286258062419,
            "fpr": 0.141602634467618,
            "logloss": 1.0710030119384897,
            "mae": 0.37884856202730627,
            "precision": 0.7207792207792207,
            "recall": 0.6686746987951807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7613506716205711,
            "auditor_fn_violation": 0.014624692212988614,
            "auditor_fp_violation": 0.019419436749769165,
            "ave_precision_score": 0.7617861809145717,
            "fpr": 0.19407894736842105,
            "logloss": 1.0779861427975344,
            "mae": 0.3060941173288831,
            "precision": 0.676416819012797,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7989859358214346,
            "auditor_fn_violation": 0.006204841319173511,
            "auditor_fp_violation": 0.024372546465980766,
            "ave_precision_score": 0.7998936695030483,
            "fpr": 0.17233809001097694,
            "logloss": 1.0295684455429308,
            "mae": 0.3043509013802396,
            "precision": 0.7092592592592593,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7842719637925762,
            "auditor_fn_violation": 0.01146506617420745,
            "auditor_fp_violation": 0.023197041397353037,
            "ave_precision_score": 0.7838285591122648,
            "fpr": 0.37609649122807015,
            "logloss": 2.5928109299565683,
            "mae": 0.39577666248632964,
            "precision": 0.5596919127086007,
            "recall": 0.956140350877193
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8061245890874073,
            "auditor_fn_violation": 0.013926176715644136,
            "auditor_fp_violation": 0.01657705259632738,
            "ave_precision_score": 0.8054911146212196,
            "fpr": 0.33699231613611413,
            "logloss": 2.4571511104261416,
            "mae": 0.3647237639563844,
            "precision": 0.6074168797953964,
            "recall": 0.9538152610441767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6056583891130417,
            "auditor_fn_violation": 0.08637753924284394,
            "auditor_fp_violation": 0.10091566635887966,
            "ave_precision_score": 0.6078209084678518,
            "fpr": 0.2675438596491228,
            "logloss": 0.6761881104001444,
            "mae": 0.4889562059716697,
            "precision": 0.5771230502599654,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6015729807819836,
            "auditor_fn_violation": 0.09618716358298177,
            "auditor_fp_violation": 0.08424342778470298,
            "ave_precision_score": 0.6022782698939861,
            "fpr": 0.27661909989023054,
            "logloss": 0.6855145151777327,
            "mae": 0.49337583966757675,
            "precision": 0.5827814569536424,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6056430411248109,
            "auditor_fn_violation": 0.08637753924284394,
            "auditor_fp_violation": 0.10091566635887966,
            "ave_precision_score": 0.607824042512797,
            "fpr": 0.2675438596491228,
            "logloss": 0.6766527538733321,
            "mae": 0.4893235191376063,
            "precision": 0.5771230502599654,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6014853648497207,
            "auditor_fn_violation": 0.09618716358298177,
            "auditor_fp_violation": 0.08424342778470298,
            "ave_precision_score": 0.6022049965119599,
            "fpr": 0.27661909989023054,
            "logloss": 0.6854068600090661,
            "mae": 0.4934679763769868,
            "precision": 0.5827814569536424,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.764204194902854,
            "auditor_fn_violation": 0.015913550323176363,
            "auditor_fp_violation": 0.015985687903970456,
            "ave_precision_score": 0.7646936642985022,
            "fpr": 0.18859649122807018,
            "logloss": 1.0710590495081411,
            "mae": 0.30373879287275163,
            "precision": 0.6820702402957486,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.799745555386271,
            "auditor_fn_violation": 0.0005157843228016385,
            "auditor_fp_violation": 0.024372546465980766,
            "ave_precision_score": 0.8002086208927931,
            "fpr": 0.17233809001097694,
            "logloss": 1.026979902364449,
            "mae": 0.3032081392480487,
            "precision": 0.7097966728280961,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7502786509448764,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5016525868568461,
            "fpr": 0.4956140350877193,
            "logloss": 17.12147208978801,
            "mae": 0.49798202544058623,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7757475083056478,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0032558745278981954,
            "ave_precision_score": 0.5514950166112956,
            "fpr": 0.4456641053787047,
            "logloss": 15.360441180125704,
            "mae": 0.4484805881519087,
            "precision": 0.5508849557522124,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7127767187929465,
            "auditor_fn_violation": 0.08375894506001848,
            "auditor_fp_violation": 0.069360283933518,
            "ave_precision_score": 0.6974740501646083,
            "fpr": 0.19846491228070176,
            "logloss": 0.615321646337239,
            "mae": 0.42601354635042843,
            "precision": 0.6306122448979592,
            "recall": 0.6776315789473685
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7464506815846488,
            "auditor_fn_violation": 0.09409757581368285,
            "auditor_fp_violation": 0.059831013467360195,
            "ave_precision_score": 0.7341309981167973,
            "fpr": 0.18660812294182216,
            "logloss": 0.6180816441526056,
            "mae": 0.4257497620307784,
            "precision": 0.6640316205533597,
            "recall": 0.6746987951807228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7033539007848151,
            "auditor_fn_violation": 0.030480532471529705,
            "auditor_fp_violation": 0.017601569713758078,
            "ave_precision_score": 0.6998084811293777,
            "fpr": 0.13267543859649122,
            "logloss": 1.3462799394169596,
            "mae": 0.36760725115891546,
            "precision": 0.6936708860759494,
            "recall": 0.6008771929824561
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7615109772716067,
            "auditor_fn_violation": 0.017951057798703048,
            "auditor_fp_violation": 0.026958641090997045,
            "ave_precision_score": 0.7585174721041191,
            "fpr": 0.11525795828759605,
            "logloss": 1.1686395425440959,
            "mae": 0.352223880574696,
            "precision": 0.7457627118644068,
            "recall": 0.6184738955823293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7665082564191282,
            "auditor_fn_violation": 0.015466297322253,
            "auditor_fp_violation": 0.02037165281625116,
            "ave_precision_score": 0.7620791190418644,
            "fpr": 0.2598684210526316,
            "logloss": 1.6955010098553265,
            "mae": 0.3148833955017488,
            "precision": 0.6325581395348837,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.814876716466002,
            "auditor_fn_violation": 0.00615855298251183,
            "auditor_fp_violation": 0.022209051065401886,
            "ave_precision_score": 0.8123321523812876,
            "fpr": 0.22722283205268934,
            "logloss": 1.4443820352743277,
            "mae": 0.2922696836421342,
            "precision": 0.6830015313935681,
            "recall": 0.8955823293172691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8029460098183655,
            "auditor_fn_violation": 0.002183364112034472,
            "auditor_fp_violation": 0.01131117266851339,
            "ave_precision_score": 0.7952728683045315,
            "fpr": 0.46271929824561403,
            "logloss": 3.985675866461553,
            "mae": 0.4607342087395086,
            "precision": 0.517162471395881,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8373660148339959,
            "auditor_fn_violation": 0.0010271602325878709,
            "auditor_fp_violation": 0.01177696329234033,
            "ave_precision_score": 0.8318207062997723,
            "fpr": 0.42041712403951703,
            "logloss": 3.500384839070748,
            "mae": 0.41823859558387466,
            "precision": 0.5642775881683731,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6944676176989865,
            "auditor_fn_violation": 0.028047091412742392,
            "auditor_fp_violation": 0.020448599569098183,
            "ave_precision_score": 0.6935531423646185,
            "fpr": 0.17982456140350878,
            "logloss": 1.3098924406632058,
            "mae": 0.4043208350868602,
            "precision": 0.6554621848739496,
            "recall": 0.6842105263157895
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7523680098458528,
            "auditor_fn_violation": 0.017042924717530935,
            "auditor_fp_violation": 0.025199139917553282,
            "ave_precision_score": 0.753459518971227,
            "fpr": 0.15587266739846323,
            "logloss": 1.12065796971564,
            "mae": 0.3814400106046909,
            "precision": 0.7016806722689075,
            "recall": 0.6706827309236948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.818101377329018,
            "auditor_fn_violation": 0.01954447522314558,
            "auditor_fp_violation": 0.026200369344413672,
            "ave_precision_score": 0.8183911095460321,
            "fpr": 0.17214912280701755,
            "logloss": 0.7982185836350766,
            "mae": 0.27914134793624085,
            "precision": 0.7054409005628518,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8381582692287781,
            "auditor_fn_violation": 0.016657188578683563,
            "auditor_fp_violation": 0.032391300303261455,
            "ave_precision_score": 0.8386497026784199,
            "fpr": 0.15367727771679474,
            "logloss": 0.7577146215449646,
            "mae": 0.2753641634694549,
            "precision": 0.7412199630314233,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.824450989578707,
            "auditor_fn_violation": 0.02173986226531241,
            "auditor_fp_violation": 0.021929824561403514,
            "ave_precision_score": 0.8247243595388108,
            "fpr": 0.16666666666666666,
            "logloss": 0.767476881476901,
            "mae": 0.31727495614549733,
            "precision": 0.699009900990099,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8255397163684836,
            "auditor_fn_violation": 0.016394888004267347,
            "auditor_fp_violation": 0.0261426790664544,
            "ave_precision_score": 0.8259174527042324,
            "fpr": 0.14818880351262348,
            "logloss": 0.9241190846573161,
            "mae": 0.32700825595428157,
            "precision": 0.7283702213279678,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7814235479363032,
            "auditor_fn_violation": 0.010395025392428441,
            "auditor_fp_violation": 0.02264158202523855,
            "ave_precision_score": 0.7810198982637196,
            "fpr": 0.37280701754385964,
            "logloss": 2.461624258461101,
            "mae": 0.39160473827142855,
            "precision": 0.5612903225806452,
            "recall": 0.9539473684210527
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8040031853749524,
            "auditor_fn_violation": 0.01220028302011559,
            "auditor_fp_violation": 0.014929181406697278,
            "ave_precision_score": 0.8038262386991704,
            "fpr": 0.33260153677277715,
            "logloss": 2.335105670461698,
            "mae": 0.3593050614931614,
            "precision": 0.6115384615384616,
            "recall": 0.9578313253012049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8145760724946474,
            "auditor_fn_violation": 0.010897583871960603,
            "auditor_fp_violation": 0.028696329639889214,
            "ave_precision_score": 0.814835467961679,
            "fpr": 0.29605263157894735,
            "logloss": 1.285821635245802,
            "mae": 0.33412570722732915,
            "precision": 0.6131805157593123,
            "recall": 0.9385964912280702
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8362210674156226,
            "auditor_fn_violation": 0.007994657003425339,
            "auditor_fp_violation": 0.02300640809264226,
            "ave_precision_score": 0.836621996056569,
            "fpr": 0.2557628979143798,
            "logloss": 1.121898459814644,
            "mae": 0.3057095226176139,
            "precision": 0.666189111747851,
            "recall": 0.9337349397590361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8070020243741962,
            "auditor_fn_violation": 0.01896977916281933,
            "auditor_fp_violation": 0.025846895198522617,
            "ave_precision_score": 0.8073266694787247,
            "fpr": 0.1787280701754386,
            "logloss": 0.8760610069192035,
            "mae": 0.2809421126748259,
            "precision": 0.6912878787878788,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8305052126829209,
            "auditor_fn_violation": 0.009711733872923086,
            "auditor_fp_violation": 0.03253482456816473,
            "ave_precision_score": 0.8309814264917833,
            "fpr": 0.1525795828759605,
            "logloss": 0.8509316652306473,
            "mae": 0.2802790225696062,
            "precision": 0.7352380952380952,
            "recall": 0.7751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7915332862232916,
            "auditor_fn_violation": 0.002183364112034472,
            "auditor_fp_violation": 0.013706140350877194,
            "ave_precision_score": 0.766575852884309,
            "fpr": 0.46381578947368424,
            "logloss": 4.926837698670927,
            "mae": 0.4624452156161349,
            "precision": 0.5165714285714286,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8326299450054921,
            "auditor_fn_violation": 0.0004893338447092432,
            "auditor_fp_violation": 0.00903937083214838,
            "ave_precision_score": 0.812737985999412,
            "fpr": 0.41931942919868276,
            "logloss": 4.340347622887404,
            "mae": 0.4186977601446879,
            "precision": 0.56442417331813,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7074087147036167,
            "auditor_fn_violation": 0.030480532471529705,
            "auditor_fp_violation": 0.017601569713758078,
            "ave_precision_score": 0.6965090637369309,
            "fpr": 0.13267543859649122,
            "logloss": 1.6661849121125893,
            "mae": 0.36728282067352874,
            "precision": 0.6936708860759494,
            "recall": 0.6008771929824561
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7651842978850361,
            "auditor_fn_violation": 0.017951057798703048,
            "auditor_fp_violation": 0.026958641090997045,
            "ave_precision_score": 0.7564037648574166,
            "fpr": 0.11525795828759605,
            "logloss": 1.4058930079339553,
            "mae": 0.35190783145210813,
            "precision": 0.7457627118644068,
            "recall": 0.6184738955823293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 19863,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7548282726012927,
            "auditor_fn_violation": 0.01252308402585411,
            "auditor_fp_violation": 0.03127885503231764,
            "ave_precision_score": 0.7554154521248295,
            "fpr": 0.2850877192982456,
            "logloss": 1.648971998726474,
            "mae": 0.34107854908782576,
            "precision": 0.6142433234421365,
            "recall": 0.9078947368421053
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7953452640614114,
            "auditor_fn_violation": 0.01472630367793898,
            "auditor_fp_violation": 0.025956629093431657,
            "ave_precision_score": 0.7952930489813088,
            "fpr": 0.25686059275521406,
            "logloss": 1.6038786193292085,
            "mae": 0.3235653580432227,
            "precision": 0.6553755522827688,
            "recall": 0.893574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7611498557103995,
            "auditor_fn_violation": 0.015913550323176363,
            "auditor_fp_violation": 0.020414935364727615,
            "ave_precision_score": 0.7615764763067607,
            "fpr": 0.19078947368421054,
            "logloss": 1.0770240384411924,
            "mae": 0.3060274514135561,
            "precision": 0.6795580110497238,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7982696644420919,
            "auditor_fn_violation": 0.006204841319173511,
            "auditor_fp_violation": 0.02159774401118426,
            "ave_precision_score": 0.7985270999003359,
            "fpr": 0.17014270032930845,
            "logloss": 1.0292877581274678,
            "mae": 0.30440796105384704,
            "precision": 0.7118959107806692,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7916609540711887,
            "auditor_fn_violation": 0.002183364112034472,
            "auditor_fp_violation": 0.013730186211141884,
            "ave_precision_score": 0.7666863882868068,
            "fpr": 0.46271929824561403,
            "logloss": 4.912136076679352,
            "mae": 0.46184591137736003,
            "precision": 0.517162471395881,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.8324196391458601,
            "auditor_fn_violation": 0.0004893338447092432,
            "auditor_fp_violation": 0.009472601483615653,
            "ave_precision_score": 0.8124418089269768,
            "fpr": 0.41822173435784854,
            "logloss": 4.329650757362564,
            "mae": 0.41844818349532237,
            "precision": 0.565068493150685,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8246416191372652,
            "auditor_fn_violation": 0.023810210834102806,
            "auditor_fp_violation": 0.02382463835026162,
            "ave_precision_score": 0.8249185581699818,
            "fpr": 0.16228070175438597,
            "logloss": 0.7813629450829193,
            "mae": 0.3168640689373795,
            "precision": 0.7028112449799196,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8230006145374036,
            "auditor_fn_violation": 0.01661090024202188,
            "auditor_fp_violation": 0.02611344264212225,
            "ave_precision_score": 0.8234188551441621,
            "fpr": 0.14709110867178923,
            "logloss": 0.9445009853441387,
            "mae": 0.3291025133383719,
            "precision": 0.7292929292929293,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7939606229051956,
            "auditor_fn_violation": 0.011960410895660203,
            "auditor_fp_violation": 0.02475761772853187,
            "ave_precision_score": 0.7942586210228921,
            "fpr": 0.28289473684210525,
            "logloss": 1.346629766970783,
            "mae": 0.32554270995483825,
            "precision": 0.6205882352941177,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8276010909632853,
            "auditor_fn_violation": 0.009601523547538123,
            "auditor_fp_violation": 0.021863529686931078,
            "ave_precision_score": 0.8280511639696522,
            "fpr": 0.24368825466520308,
            "logloss": 1.173385440520613,
            "mae": 0.2991700238569103,
            "precision": 0.6744868035190615,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7572782248641137,
            "auditor_fn_violation": 0.01865958756540474,
            "auditor_fp_violation": 0.028554459064327506,
            "ave_precision_score": 0.7578321731359806,
            "fpr": 0.25109649122807015,
            "logloss": 1.4599949048096674,
            "mae": 0.3258338169915908,
            "precision": 0.6359300476947536,
            "recall": 0.8771929824561403
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7964898931950105,
            "auditor_fn_violation": 0.015202412283602031,
            "auditor_fp_violation": 0.02889621866719117,
            "ave_precision_score": 0.7965407493911433,
            "fpr": 0.23380900109769484,
            "logloss": 1.44420447326946,
            "mae": 0.31491099015686946,
            "precision": 0.6702786377708978,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5939554203491183,
            "auditor_fn_violation": 0.003905047706986779,
            "auditor_fp_violation": 0.0008969105878731918,
            "ave_precision_score": 0.5100965132128567,
            "fpr": 0.005482456140350877,
            "logloss": 16.817178781339265,
            "mae": 0.48850840122618694,
            "precision": 0.7619047619047619,
            "recall": 0.03508771929824561
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5791049925391903,
            "auditor_fn_violation": 0.003202712055687076,
            "auditor_fp_violation": 0.0012438769624949833,
            "ave_precision_score": 0.5566218142131015,
            "fpr": 0.003293084522502744,
            "logloss": 18.431585487522057,
            "mae": 0.5370293135308015,
            "precision": 0.8125,
            "recall": 0.02610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8068617546972416,
            "auditor_fn_violation": 0.022391505078485696,
            "auditor_fp_violation": 0.027441135734072024,
            "ave_precision_score": 0.8071857298680254,
            "fpr": 0.17105263157894737,
            "logloss": 0.8700034843599885,
            "mae": 0.280309341458214,
            "precision": 0.6976744186046512,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8302392497341682,
            "auditor_fn_violation": 0.012392048986285433,
            "auditor_fp_violation": 0.03052016914600405,
            "ave_precision_score": 0.830444691371377,
            "fpr": 0.1437980241492865,
            "logloss": 0.8511955609142021,
            "mae": 0.280479170364827,
            "precision": 0.7446393762183235,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6803370375787907,
            "auditor_fn_violation": 0.011994075100030787,
            "auditor_fp_violation": 0.006636657433056327,
            "ave_precision_score": 0.5567542847113937,
            "fpr": 0.02631578947368421,
            "logloss": 14.771870855209201,
            "mae": 0.4291065954276475,
            "precision": 0.7876106194690266,
            "recall": 0.19517543859649122
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7349502771098689,
            "auditor_fn_violation": 0.013053310938595212,
            "auditor_fp_violation": 0.0038671815821158134,
            "ave_precision_score": 0.6160101863291427,
            "fpr": 0.020856201975850714,
            "logloss": 15.4343978864809,
            "mae": 0.44945600884838766,
            "precision": 0.8503937007874016,
            "recall": 0.21686746987951808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.818466073737594,
            "auditor_fn_violation": 0.014591028008618038,
            "auditor_fp_violation": 0.024065096952908593,
            "ave_precision_score": 0.8187488654846159,
            "fpr": 0.2631578947368421,
            "logloss": 1.3396460754564992,
            "mae": 0.31482482727089345,
            "precision": 0.6319018404907976,
            "recall": 0.9035087719298246
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8249592242202491,
            "auditor_fn_violation": 0.013308998893488333,
            "auditor_fp_violation": 0.029029111505064546,
            "ave_precision_score": 0.8256427333586493,
            "fpr": 0.23600439077936333,
            "logloss": 1.362580472746724,
            "mae": 0.3048202752021713,
            "precision": 0.6717557251908397,
            "recall": 0.8835341365461847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7504269049610512,
            "auditor_fn_violation": 0.026056094182825486,
            "auditor_fp_violation": 0.01965989535241614,
            "ave_precision_score": 0.751006961443751,
            "fpr": 0.13925438596491227,
            "logloss": 0.7649768223523431,
            "mae": 0.32718191596894275,
            "precision": 0.7080459770114943,
            "recall": 0.6754385964912281
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7955044829098386,
            "auditor_fn_violation": 0.013189971742072575,
            "auditor_fp_violation": 0.018450841610342265,
            "ave_precision_score": 0.795984079760384,
            "fpr": 0.12184412733260154,
            "logloss": 0.7554506574924781,
            "mae": 0.3278734493981556,
            "precision": 0.7459954233409611,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8181074564584718,
            "auditor_fn_violation": 0.01954447522314558,
            "auditor_fp_violation": 0.026200369344413672,
            "ave_precision_score": 0.8183970643682839,
            "fpr": 0.17214912280701755,
            "logloss": 0.7982197313928233,
            "mae": 0.27914198969169557,
            "precision": 0.7054409005628518,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8381582692287781,
            "auditor_fn_violation": 0.016657188578683563,
            "auditor_fp_violation": 0.032391300303261455,
            "ave_precision_score": 0.8386497026784199,
            "fpr": 0.15367727771679474,
            "logloss": 0.7577132351993832,
            "mae": 0.27536420812637247,
            "precision": 0.7412199630314233,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.7214498444823771,
            "auditor_fn_violation": 0.08627654662973222,
            "auditor_fp_violation": 0.10381078793474918,
            "ave_precision_score": 0.5589078074533238,
            "fpr": 0.27521929824561403,
            "logloss": 0.6770246875373,
            "mae": 0.4816341199008692,
            "precision": 0.5724020442930153,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7273267264165713,
            "auditor_fn_violation": 0.09778741750757144,
            "auditor_fp_violation": 0.08502483767139854,
            "ave_precision_score": 0.5759163926872685,
            "fpr": 0.2810098792535675,
            "logloss": 0.679864158615247,
            "mae": 0.48703318714637484,
            "precision": 0.5850891410048622,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7543583885612462,
            "auditor_fn_violation": 0.013850415512465374,
            "auditor_fp_violation": 0.03142793936595877,
            "ave_precision_score": 0.754861921487374,
            "fpr": 0.2817982456140351,
            "logloss": 1.6411726573015764,
            "mae": 0.33915608654913865,
            "precision": 0.6158445440956651,
            "recall": 0.9035087719298246
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7948554127111788,
            "auditor_fn_violation": 0.014296483408937617,
            "auditor_fp_violation": 0.026251651193510576,
            "ave_precision_score": 0.7949330200962382,
            "fpr": 0.2535675082327113,
            "logloss": 1.6126754608659584,
            "mae": 0.3221768634164398,
            "precision": 0.6567607726597325,
            "recall": 0.8875502008032129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7612321252158045,
            "auditor_fn_violation": 0.014624692212988614,
            "auditor_fp_violation": 0.019419436749769165,
            "ave_precision_score": 0.7617239644288332,
            "fpr": 0.19407894736842105,
            "logloss": 1.0790895165444838,
            "mae": 0.30627269490240905,
            "precision": 0.676416819012797,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7989040042809776,
            "auditor_fn_violation": 0.006204841319173511,
            "auditor_fp_violation": 0.024372546465980766,
            "ave_precision_score": 0.7998192636705777,
            "fpr": 0.17233809001097694,
            "logloss": 1.0292993806556103,
            "mae": 0.30441177275126186,
            "precision": 0.7092592592592593,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8193429259893314,
            "auditor_fn_violation": 0.014283240997229921,
            "auditor_fp_violation": 0.02146573945829487,
            "ave_precision_score": 0.8195716996334532,
            "fpr": 0.32127192982456143,
            "logloss": 1.4783376166651239,
            "mae": 0.35868236545937543,
            "precision": 0.5924895688456189,
            "recall": 0.9342105263157895
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.8306096036887418,
            "auditor_fn_violation": 0.008261365990856952,
            "auditor_fp_violation": 0.025005116374258122,
            "ave_precision_score": 0.8310469984262372,
            "fpr": 0.29088913282107576,
            "logloss": 1.2951220582190148,
            "mae": 0.3283023072310453,
            "precision": 0.6364883401920439,
            "recall": 0.9317269076305221
        }
    }
]