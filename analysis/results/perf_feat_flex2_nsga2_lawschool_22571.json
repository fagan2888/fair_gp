[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.4723085610963944,
            "auditor_fn_violation": 0.0031560264759261355,
            "auditor_fp_violation": 0.004516811120880963,
            "ave_precision_score": 0.5202674426582223,
            "fpr": 0.019736842105263157,
            "logloss": 0.9117447663730831,
            "mae": 0.4928463572276789,
            "precision": 0.3076923076923077,
            "recall": 0.016227180527383367
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5641381713036926,
            "auditor_fn_violation": 0.004026468494253176,
            "auditor_fp_violation": 0.0019026710574460298,
            "ave_precision_score": 0.5016482852328895,
            "fpr": 0.005488474204171241,
            "logloss": 0.8347414156325721,
            "mae": 0.49028584904126354,
            "precision": 0.782608695652174,
            "recall": 0.039045553145336226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5772743852531939,
            "auditor_fn_violation": 0.0023909291484288785,
            "auditor_fp_violation": 0.0031743290206422987,
            "ave_precision_score": 0.5423783851108501,
            "fpr": 0.010964912280701754,
            "logloss": 0.7223725689226346,
            "mae": 0.4973712814481635,
            "precision": 0.6,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5361539513707164,
            "auditor_fn_violation": 0.0001333425403182855,
            "auditor_fp_violation": 0.0037614343212586904,
            "ave_precision_score": 0.507111469866041,
            "fpr": 0.008781558726673985,
            "logloss": 0.7179891391924503,
            "mae": 0.49893569141528216,
            "precision": 0.5555555555555556,
            "recall": 0.021691973969631236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5103301436387371,
            "auditor_fn_violation": 0.0008740792142628378,
            "auditor_fp_violation": 0.003875664698739698,
            "ave_precision_score": 0.5510942477779236,
            "fpr": 0.4309210526315789,
            "logloss": 0.690507852670105,
            "mae": 0.49857459119276,
            "precision": 0.5523917995444191,
            "recall": 0.9837728194726166
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5329555033558404,
            "auditor_fn_violation": 0.002271585418993216,
            "auditor_fp_violation": 0.008025368947432613,
            "ave_precision_score": 0.5150068614474491,
            "fpr": 0.4698133918770582,
            "logloss": 0.69147650352455,
            "mae": 0.49907094236917215,
            "precision": 0.5147392290249433,
            "recall": 0.9848156182212582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 0.6926614607275038,
            "mae": 0.4997474559043583,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 0.6930913913792198,
            "mae": 0.4999624184536227,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 22571,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.539042788410534,
            "auditor_fn_violation": 0.000676132521974307,
            "auditor_fp_violation": 0.007748712473307393,
            "ave_precision_score": 0.541358721587979,
            "fpr": 0.43859649122807015,
            "logloss": 0.7004640324971058,
            "mae": 0.49325513514882086,
            "precision": 0.5495495495495496,
            "recall": 0.9898580121703854
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5034078752485203,
            "auditor_fn_violation": 0.0026954242078619716,
            "auditor_fp_violation": 0.0024393218685205545,
            "ave_precision_score": 0.5039938337788336,
            "fpr": 0.4829857299670692,
            "logloss": 0.7120558805171228,
            "mae": 0.49776718893860755,
            "precision": 0.5067264573991032,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6228709158737105,
            "auditor_fn_violation": 0.005698195793744009,
            "auditor_fp_violation": 0.0135582841351589,
            "ave_precision_score": 0.6238489702723405,
            "fpr": 0.09649122807017543,
            "logloss": 0.6898211243402522,
            "mae": 0.4898361210433537,
            "precision": 0.6053811659192825,
            "recall": 0.2738336713995943
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6169115543745387,
            "auditor_fn_violation": 0.0041717166185284435,
            "auditor_fp_violation": 0.02388583973655324,
            "ave_precision_score": 0.6175195710817178,
            "fpr": 0.12184412733260154,
            "logloss": 0.6782362650577289,
            "mae": 0.48407081260246715,
            "precision": 0.5763358778625954,
            "recall": 0.3275488069414317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6228835701932288,
            "auditor_fn_violation": 0.005698195793744009,
            "auditor_fp_violation": 0.0135582841351589,
            "ave_precision_score": 0.6238616429605666,
            "fpr": 0.09649122807017543,
            "logloss": 0.6898210545996983,
            "mae": 0.4898361514338799,
            "precision": 0.6053811659192825,
            "recall": 0.2738336713995943
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.616915068232595,
            "auditor_fn_violation": 0.0041717166185284435,
            "auditor_fp_violation": 0.02388583973655324,
            "ave_precision_score": 0.6175230849397739,
            "fpr": 0.12184412733260154,
            "logloss": 0.6782362854643995,
            "mae": 0.4840708831662535,
            "precision": 0.5763358778625954,
            "recall": 0.3275488069414317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6142157047178776,
            "auditor_fn_violation": 0.03502099569410342,
            "auditor_fp_violation": 0.04009127831511955,
            "ave_precision_score": 0.6151747298283017,
            "fpr": 0.32127192982456143,
            "logloss": 0.7143710714679221,
            "mae": 0.47387195340145316,
            "precision": 0.5753623188405798,
            "recall": 0.8052738336713996
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6028847803761388,
            "auditor_fn_violation": 0.0340190155986961,
            "auditor_fp_violation": 0.04414196853274789,
            "ave_precision_score": 0.6035615467596135,
            "fpr": 0.3468715697036224,
            "logloss": 0.713244222786414,
            "mae": 0.4734068702656927,
            "precision": 0.5297619047619048,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5772743852531939,
            "auditor_fn_violation": 0.0023909291484288785,
            "auditor_fp_violation": 0.0031743290206422987,
            "ave_precision_score": 0.5423783851108501,
            "fpr": 0.010964912280701754,
            "logloss": 0.7223725689226346,
            "mae": 0.4973712814481635,
            "precision": 0.6,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5361539513707164,
            "auditor_fn_violation": 0.0001333425403182855,
            "auditor_fp_violation": 0.0037614343212586904,
            "ave_precision_score": 0.507111469866041,
            "fpr": 0.008781558726673985,
            "logloss": 0.7179891391924503,
            "mae": 0.49893569141528216,
            "precision": 0.5555555555555556,
            "recall": 0.021691973969631236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.4739544878527022,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4841400393997068,
            "fpr": 0.4594298245614035,
            "logloss": 0.6929076382664362,
            "mae": 0.49987712848866195,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.49339943599324015,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4822576565209112,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931066380801084,
            "mae": 0.49997658342221174,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.4748245361289835,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4798486580893108,
            "fpr": 0.4594298245614035,
            "logloss": 0.6929041473698255,
            "mae": 0.4998752807446739,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.49449477238656214,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4763040082333357,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931065147487149,
            "mae": 0.4999764181518136,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5643849214021661,
            "auditor_fn_violation": 0.013271324863883853,
            "auditor_fp_violation": 0.01493478624963364,
            "ave_precision_score": 0.5673520241524713,
            "fpr": 0.12828947368421054,
            "logloss": 1.8846799594096093,
            "mae": 0.5110423630359863,
            "precision": 0.5894736842105263,
            "recall": 0.3407707910750507
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.525365041673505,
            "auditor_fn_violation": 0.0018691766812470594,
            "auditor_fp_violation": 0.013289425539699962,
            "ave_precision_score": 0.5265851469475649,
            "fpr": 0.15587266739846323,
            "logloss": 1.7988233622353764,
            "mae": 0.497092274224851,
            "precision": 0.5218855218855218,
            "recall": 0.3362255965292842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.44513603410333485,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5351409829200551,
            "fpr": 0.4594298245614035,
            "logloss": 0.6927856892153664,
            "mae": 0.49980957564293294,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5120667234634002,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5213918430320967,
            "fpr": 0.49396267837541163,
            "logloss": 0.6930520167917408,
            "mae": 0.49994310700670946,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7845858017114192,
            "auditor_fn_violation": 0.011772267890822394,
            "auditor_fp_violation": 0.024614788761880838,
            "ave_precision_score": 0.7529475167562061,
            "fpr": 0.17434210526315788,
            "logloss": 3.8570415316408857,
            "mae": 0.3008731793729771,
            "precision": 0.7093235831809872,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7671285352270439,
            "auditor_fn_violation": 0.006159949139345337,
            "auditor_fp_violation": 0.023476033662641786,
            "ave_precision_score": 0.7283636904799325,
            "fpr": 0.18441273326015367,
            "logloss": 3.9534873053747845,
            "mae": 0.29149202598510326,
            "precision": 0.6883116883116883,
            "recall": 0.8047722342733189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7868678168008236,
            "auditor_fn_violation": 0.014189886480908161,
            "auditor_fp_violation": 0.021788510656115232,
            "ave_precision_score": 0.7798555769945807,
            "fpr": 0.1600877192982456,
            "logloss": 2.2931228885657684,
            "mae": 0.3045115564173784,
            "precision": 0.7208413001912046,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7549414083072734,
            "auditor_fn_violation": 0.009486369296927644,
            "auditor_fp_violation": 0.024851811196487373,
            "ave_precision_score": 0.7378915810410981,
            "fpr": 0.18441273326015367,
            "logloss": 2.6002341136754525,
            "mae": 0.29960837698098564,
            "precision": 0.6848030018761726,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.5335327544510897,
            "auditor_fn_violation": 0.037903455393046515,
            "auditor_fp_violation": 0.04099411715446136,
            "ave_precision_score": 0.5350303225826588,
            "fpr": 0.3256578947368421,
            "logloss": 0.7221868511523002,
            "mae": 0.4824426869551341,
            "precision": 0.5757142857142857,
            "recall": 0.8174442190669371
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.529630424702738,
            "auditor_fn_violation": 0.037188282048046174,
            "auditor_fp_violation": 0.041536772777167955,
            "ave_precision_score": 0.531819800916892,
            "fpr": 0.3556531284302964,
            "logloss": 0.7223423379305223,
            "mae": 0.48284788254717964,
            "precision": 0.5358166189111748,
            "recall": 0.8112798264642083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6141785408573721,
            "auditor_fn_violation": 0.035156667022525886,
            "auditor_fp_violation": 0.039091613281413556,
            "ave_precision_score": 0.6151373204852681,
            "fpr": 0.3190789473684211,
            "logloss": 0.7146392921753643,
            "mae": 0.4737675500412782,
            "precision": 0.575801749271137,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6033206645755493,
            "auditor_fn_violation": 0.03353803000683381,
            "auditor_fp_violation": 0.0446761800219539,
            "ave_precision_score": 0.6039973140365076,
            "fpr": 0.34577387486278816,
            "logloss": 0.7134017739739392,
            "mae": 0.47326592979165516,
            "precision": 0.5298507462686567,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.8019561657122186,
            "auditor_fn_violation": 0.001276644959254119,
            "auditor_fp_violation": 0.009140916132814139,
            "ave_precision_score": 0.8023450131261083,
            "fpr": 0.43530701754385964,
            "logloss": 1.5250899720328934,
            "mae": 0.4256168867608434,
            "precision": 0.5509049773755657,
            "recall": 0.9878296146044625
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7991824017767369,
            "auditor_fn_violation": 0.0025644627843351086,
            "auditor_fp_violation": 0.0031735577509452613,
            "ave_precision_score": 0.799467948248949,
            "fpr": 0.4818880351262349,
            "logloss": 1.7837513316587756,
            "mae": 0.46734807421949115,
            "precision": 0.5067415730337078,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7825058707011469,
            "auditor_fn_violation": 0.011836767374826519,
            "auditor_fp_violation": 0.021267742745886206,
            "ave_precision_score": 0.7831535367710247,
            "fpr": 0.17653508771929824,
            "logloss": 0.6060802216825583,
            "mae": 0.3766046255120289,
            "precision": 0.6979362101313321,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7988245869425139,
            "auditor_fn_violation": 0.00663141026404204,
            "auditor_fp_violation": 0.0289254787169167,
            "ave_precision_score": 0.7992023924889826,
            "fpr": 0.1734357848518112,
            "logloss": 0.6000380146523077,
            "mae": 0.3762324632357082,
            "precision": 0.6926070038910506,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6727960757478273,
            "auditor_fn_violation": 0.01262633002384258,
            "auditor_fp_violation": 0.010004501109575854,
            "ave_precision_score": 0.6740496002058654,
            "fpr": 0.09429824561403509,
            "logloss": 1.3678346914663277,
            "mae": 0.45986563611328374,
            "precision": 0.6244541484716157,
            "recall": 0.29006085192697767
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6308862269250061,
            "auditor_fn_violation": 0.004007419559922016,
            "auditor_fp_violation": 0.012908891328210758,
            "ave_precision_score": 0.6328039149334723,
            "fpr": 0.10867178924259056,
            "logloss": 1.2942219781776108,
            "mae": 0.44620439844904597,
            "precision": 0.5840336134453782,
            "recall": 0.30151843817787416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.780251213428872,
            "auditor_fn_violation": 0.0007183908045977016,
            "auditor_fp_violation": 0.00894202989574176,
            "ave_precision_score": 0.7806251770955444,
            "fpr": 0.43201754385964913,
            "logloss": 1.5253768719880527,
            "mae": 0.44247780716978014,
            "precision": 0.55125284738041,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.7619158923319456,
            "auditor_fn_violation": 0.0019477535353631566,
            "auditor_fp_violation": 0.003805342114892053,
            "ave_precision_score": 0.7622095844918086,
            "fpr": 0.4774972557628979,
            "logloss": 1.6859195164563374,
            "mae": 0.4860232822539778,
            "precision": 0.5056818181818182,
            "recall": 0.96529284164859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 22571,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.5145654072458784,
            "auditor_fn_violation": 0.0015946941389986195,
            "auditor_fp_violation": 0.0018187622995436087,
            "ave_precision_score": 0.5232344869058574,
            "fpr": 0.008771929824561403,
            "logloss": 0.6976343296738612,
            "mae": 0.5018391195161823,
            "precision": 0.38461538461538464,
            "recall": 0.010141987829614604
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5157466010664427,
            "auditor_fn_violation": 0.003966940574468254,
            "auditor_fp_violation": 0.001975850713501647,
            "ave_precision_score": 0.5192388216321593,
            "fpr": 0.010976948408342482,
            "logloss": 0.6927108417650836,
            "mae": 0.4990934345188308,
            "precision": 0.6,
            "recall": 0.03253796095444685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.788653432933777,
            "auditor_fn_violation": 0.009287925696594434,
            "auditor_fp_violation": 0.027009274379265587,
            "ave_precision_score": 0.7872605277730603,
            "fpr": 0.12171052631578948,
            "logloss": 1.5600669986699272,
            "mae": 0.31343948481750983,
            "precision": 0.754424778761062,
            "recall": 0.691683569979716
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7505662566859344,
            "auditor_fn_violation": 0.010876941503103792,
            "auditor_fp_violation": 0.022788144895718992,
            "ave_precision_score": 0.7458819246584024,
            "fpr": 0.14489571899012074,
            "logloss": 1.584692631330597,
            "mae": 0.3059085769043643,
            "precision": 0.714902807775378,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7390430802756534,
            "auditor_fn_violation": 0.011209565495889827,
            "auditor_fp_violation": 0.029199639911233935,
            "ave_precision_score": 0.7397884842131138,
            "fpr": 0.11951754385964912,
            "logloss": 1.1147197715602588,
            "mae": 0.34140802029668144,
            "precision": 0.7398568019093079,
            "recall": 0.6288032454361054
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7018207532277206,
            "auditor_fn_violation": 0.009848299049220067,
            "auditor_fp_violation": 0.019709720697646062,
            "ave_precision_score": 0.7032694639156605,
            "fpr": 0.1437980241492865,
            "logloss": 1.037691753321985,
            "mae": 0.3326615460810377,
            "precision": 0.7036199095022625,
            "recall": 0.6746203904555315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8014058348142348,
            "auditor_fn_violation": 0.009514785950677918,
            "auditor_fp_violation": 0.01811696604279195,
            "ave_precision_score": 0.802276951451207,
            "fpr": 0.1699561403508772,
            "logloss": 1.183919751809065,
            "mae": 0.286033752531927,
            "precision": 0.7155963302752294,
            "recall": 0.7910750507099391
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8121560330522135,
            "auditor_fn_violation": 0.007598143681349426,
            "auditor_fp_violation": 0.025364068788876697,
            "ave_precision_score": 0.8125088426646476,
            "fpr": 0.18221734357848518,
            "logloss": 1.1479126036417595,
            "mae": 0.28720673549721193,
            "precision": 0.6920222634508348,
            "recall": 0.8091106290672451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5921041510978257,
            "auditor_fn_violation": 0.004643962848297231,
            "auditor_fp_violation": 0.0035904199639911235,
            "ave_precision_score": 0.5439953204512294,
            "fpr": 0.013157894736842105,
            "logloss": 0.7263205949914878,
            "mae": 0.4958546160998052,
            "precision": 0.625,
            "recall": 0.04056795131845842
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.49385251203852965,
            "auditor_fn_violation": 0.0011143626583740322,
            "auditor_fp_violation": 0.0032882058787657036,
            "ave_precision_score": 0.5048416835130679,
            "fpr": 0.01756311745334797,
            "logloss": 0.746593930050672,
            "mae": 0.501093347921853,
            "precision": 0.4666666666666667,
            "recall": 0.03036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5913754812490332,
            "auditor_fn_violation": 0.04098608590441623,
            "auditor_fp_violation": 0.03461143909894067,
            "ave_precision_score": 0.5926580604688623,
            "fpr": 0.08114035087719298,
            "logloss": 0.9078853683225507,
            "mae": 0.504750014446153,
            "precision": 0.5460122699386503,
            "recall": 0.18052738336713997
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5381956363850923,
            "auditor_fn_violation": 0.04639606068038032,
            "auditor_fp_violation": 0.04873765093304062,
            "ave_precision_score": 0.539519312013427,
            "fpr": 0.09879253567508232,
            "logloss": 0.9155668696498065,
            "mae": 0.5006528781534252,
            "precision": 0.46745562130177515,
            "recall": 0.17136659436008678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5711117965668469,
            "auditor_fn_violation": 0.07826233941852603,
            "auditor_fp_violation": 0.023557551396390743,
            "ave_precision_score": 0.5722904907315695,
            "fpr": 0.06469298245614036,
            "logloss": 0.7811044355206441,
            "mae": 0.502176396783621,
            "precision": 0.6927083333333334,
            "recall": 0.2697768762677485
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5408214301283033,
            "auditor_fn_violation": 0.07336697057653983,
            "auditor_fp_violation": 0.01779729235272594,
            "ave_precision_score": 0.5419330374217222,
            "fpr": 0.05817782656421515,
            "logloss": 0.780868921500246,
            "mae": 0.5002549035652539,
            "precision": 0.6845238095238095,
            "recall": 0.24945770065075923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.788653432933777,
            "auditor_fn_violation": 0.009287925696594434,
            "auditor_fp_violation": 0.027009274379265587,
            "ave_precision_score": 0.7872605277730603,
            "fpr": 0.12171052631578948,
            "logloss": 1.5600723187399717,
            "mae": 0.31343979436607755,
            "precision": 0.754424778761062,
            "recall": 0.691683569979716
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7505662566859344,
            "auditor_fn_violation": 0.010876941503103792,
            "auditor_fp_violation": 0.022788144895718992,
            "ave_precision_score": 0.7458819246584024,
            "fpr": 0.14489571899012074,
            "logloss": 1.5846989930667412,
            "mae": 0.3059088818777098,
            "precision": 0.714902807775378,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7274556222720427,
            "auditor_fn_violation": 0.004890840183623361,
            "auditor_fp_violation": 0.014356446007620488,
            "ave_precision_score": 0.7279106827439141,
            "fpr": 0.08114035087719298,
            "logloss": 1.4697291153177172,
            "mae": 0.4545596991133929,
            "precision": 0.6768558951965066,
            "recall": 0.3144016227180527
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6887160110261286,
            "auditor_fn_violation": 0.0026168473537458528,
            "auditor_fp_violation": 0.0065642151481888015,
            "ave_precision_score": 0.6893608969208208,
            "fpr": 0.09549945115257959,
            "logloss": 1.3559262963256098,
            "mae": 0.43586019225687245,
            "precision": 0.640495867768595,
            "recall": 0.3362255965292842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.45897968910570697,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4616783467446624,
            "fpr": 0.4594298245614035,
            "logloss": 0.6929041336921117,
            "mae": 0.49987524081217616,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.4499375205787012,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.45092313167743714,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931066753384574,
            "mae": 0.4999764684657234,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.47487225237597147,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4786064197086044,
            "fpr": 0.4594298245614035,
            "logloss": 0.6929024694569983,
            "mae": 0.49987444261971276,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.49587108947323,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4757055759531097,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931058794314673,
            "mae": 0.4999760991262945,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7884772017882548,
            "auditor_fn_violation": 0.026255738229956235,
            "auditor_fp_violation": 0.030748859021061007,
            "ave_precision_score": 0.7889666652764875,
            "fpr": 0.15679824561403508,
            "logloss": 1.1428146781032253,
            "mae": 0.2916974107740165,
            "precision": 0.72552783109405,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7763124176459084,
            "auditor_fn_violation": 0.024927911689140443,
            "auditor_fp_violation": 0.03194535919014514,
            "ave_precision_score": 0.7772989570402791,
            "fpr": 0.17233809001097694,
            "logloss": 1.0882387346376152,
            "mae": 0.29185411173292636,
            "precision": 0.6951456310679611,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 22571,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6079252972060581,
            "auditor_fn_violation": 0.03531680367246717,
            "auditor_fp_violation": 0.03868860695892476,
            "ave_precision_score": 0.6088889881953148,
            "fpr": 0.3157894736842105,
            "logloss": 0.7208942696523397,
            "mae": 0.47218502746698887,
            "precision": 0.5739644970414202,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6044737467558807,
            "auditor_fn_violation": 0.033130859035504834,
            "auditor_fp_violation": 0.04412001463593121,
            "ave_precision_score": 0.6051482417389837,
            "fpr": 0.33260153677277715,
            "logloss": 0.7180661905806266,
            "mae": 0.47123752466508245,
            "precision": 0.5436746987951807,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0.5271283083287601,
            "auditor_fn_violation": 0.0037387459521013664,
            "auditor_fp_violation": 0.005189360633086297,
            "ave_precision_score": 0.5291904360582753,
            "fpr": 0.03508771929824561,
            "logloss": 0.6951491887993446,
            "mae": 0.5007710299340257,
            "precision": 0.43859649122807015,
            "recall": 0.05070993914807302
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5134644310536535,
            "auditor_fn_violation": 0.006540927825968957,
            "auditor_fp_violation": 0.0065129893889498735,
            "ave_precision_score": 0.5137611565456134,
            "fpr": 0.03293084522502744,
            "logloss": 0.6921613223713554,
            "mae": 0.4989633716225755,
            "precision": 0.5238095238095238,
            "recall": 0.07158351409978309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7414563178868048,
            "auditor_fn_violation": 0.009754990925589839,
            "auditor_fp_violation": 0.008565192814972998,
            "ave_precision_score": 0.7425247414588104,
            "fpr": 0.12171052631578948,
            "logloss": 0.5837190698860143,
            "mae": 0.3707643431731859,
            "precision": 0.7592190889370932,
            "recall": 0.7099391480730223
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7541305818066686,
            "auditor_fn_violation": 0.0033811858437844504,
            "auditor_fp_violation": 0.008276619099890229,
            "ave_precision_score": 0.7550593774410612,
            "fpr": 0.11086717892425905,
            "logloss": 0.5597849795799831,
            "mae": 0.36086729464747835,
            "precision": 0.769406392694064,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.5407919670587811,
            "auditor_fn_violation": 0.008509483648268753,
            "auditor_fp_violation": 0.01239375287861659,
            "ave_precision_score": 0.5420161974514162,
            "fpr": 0.051535087719298246,
            "logloss": 0.7827383130630401,
            "mae": 0.5039855984015096,
            "precision": 0.44047619047619047,
            "recall": 0.07505070993914807
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5525875931899897,
            "auditor_fn_violation": 0.011362689328548886,
            "auditor_fp_violation": 0.0028149774362727182,
            "ave_precision_score": 0.5547515401887805,
            "fpr": 0.04171240395170143,
            "logloss": 0.7379438937387024,
            "mae": 0.48334944111210193,
            "precision": 0.5730337078651685,
            "recall": 0.11062906724511931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7264646519022931,
            "auditor_fn_violation": 0.003253887762001372,
            "auditor_fp_violation": 0.012098040447180004,
            "ave_precision_score": 0.7269282539330542,
            "fpr": 0.08114035087719298,
            "logloss": 1.4461983059997119,
            "mae": 0.4531482538106001,
            "precision": 0.6782608695652174,
            "recall": 0.31643002028397565
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6884185276285708,
            "auditor_fn_violation": 0.001507246928954634,
            "auditor_fp_violation": 0.005390901329430422,
            "ave_precision_score": 0.689054266237136,
            "fpr": 0.09659714599341383,
            "logloss": 1.3387138896956923,
            "mae": 0.43607780148209196,
            "precision": 0.6348547717842323,
            "recall": 0.3318872017353579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7853699735443258,
            "auditor_fn_violation": 0.012733087790470093,
            "auditor_fp_violation": 0.025418184482686425,
            "ave_precision_score": 0.7784934255138544,
            "fpr": 0.16666666666666666,
            "logloss": 2.1367057320091978,
            "mae": 0.30247064278827646,
            "precision": 0.7148217636022514,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7524837898095815,
            "auditor_fn_violation": 0.010836462517650029,
            "auditor_fp_violation": 0.025790950115867798,
            "ave_precision_score": 0.7374623382294088,
            "fpr": 0.18551042810098792,
            "logloss": 2.4105321074184762,
            "mae": 0.29882085806305037,
            "precision": 0.6852886405959032,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.793584741869385,
            "auditor_fn_violation": 0.012148144194156794,
            "auditor_fp_violation": 0.016915797847841564,
            "ave_precision_score": 0.7939865276378186,
            "fpr": 0.31140350877192985,
            "logloss": 0.6959883454550064,
            "mae": 0.393792315032905,
            "precision": 0.5854014598540146,
            "recall": 0.8133874239350912
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7963214252416626,
            "auditor_fn_violation": 0.008333908769891254,
            "auditor_fp_violation": 0.024412733260153693,
            "ave_precision_score": 0.7965965186789588,
            "fpr": 0.3358946212952799,
            "logloss": 0.697617386291041,
            "mae": 0.39774630264441446,
            "precision": 0.5513196480938416,
            "recall": 0.8156182212581344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6547851540139831,
            "auditor_fn_violation": 0.010655759581509565,
            "auditor_fp_violation": 0.016080999036971903,
            "ave_precision_score": 0.6560790457888968,
            "fpr": 0.09429824561403509,
            "logloss": 1.5016560076203613,
            "mae": 0.45737425711970164,
            "precision": 0.6600790513833992,
            "recall": 0.33874239350912777
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6107754023315409,
            "auditor_fn_violation": 0.0020882394260556135,
            "auditor_fp_violation": 0.017285034760336628,
            "ave_precision_score": 0.6126041211813197,
            "fpr": 0.12184412733260154,
            "logloss": 1.4526096393258146,
            "mae": 0.4511078488158171,
            "precision": 0.5795454545454546,
            "recall": 0.3318872017353579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.6116556871196954,
            "auditor_fn_violation": 0.00397450268673713,
            "auditor_fp_violation": 0.00433886027718461,
            "ave_precision_score": 0.6125141777823113,
            "fpr": 0.041666666666666664,
            "logloss": 0.7676576418752402,
            "mae": 0.49360270463256983,
            "precision": 0.6984126984126984,
            "recall": 0.17849898580121704
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5899232067608706,
            "auditor_fn_violation": 0.013281869462415273,
            "auditor_fp_violation": 0.0002000243932186854,
            "ave_precision_score": 0.5906030307864256,
            "fpr": 0.050493962678375415,
            "logloss": 0.7520628766424785,
            "mae": 0.4854086742344855,
            "precision": 0.676056338028169,
            "recall": 0.20824295010845986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6648209406051913,
            "auditor_fn_violation": 0.007426337141027014,
            "auditor_fp_violation": 0.0249942427668216,
            "ave_precision_score": 0.6659851367546323,
            "fpr": 0.18421052631578946,
            "logloss": 1.034325067406344,
            "mae": 0.39909052389959887,
            "precision": 0.6440677966101694,
            "recall": 0.6166328600405679
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6179452672634043,
            "auditor_fn_violation": 0.012405618483180985,
            "auditor_fp_violation": 0.023417489937797298,
            "ave_precision_score": 0.6189326058936708,
            "fpr": 0.21953896816684962,
            "logloss": 1.11010650541316,
            "mae": 0.41300084695371936,
            "precision": 0.5815899581589958,
            "recall": 0.6030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8038833384206772,
            "auditor_fn_violation": 0.013055585210490737,
            "auditor_fp_violation": 0.016779717790897295,
            "ave_precision_score": 0.8042540894315036,
            "fpr": 0.16447368421052633,
            "logloss": 1.2427693283222254,
            "mae": 0.3001512240820756,
            "precision": 0.7169811320754716,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8039770387145524,
            "auditor_fn_violation": 0.008841086646458928,
            "auditor_fp_violation": 0.020048786437370413,
            "ave_precision_score": 0.8042347980422044,
            "fpr": 0.17892425905598244,
            "logloss": 1.1751054929458367,
            "mae": 0.2929010006280308,
            "precision": 0.6924528301886792,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8001349218540723,
            "auditor_fn_violation": 0.013171239457670545,
            "auditor_fp_violation": 0.01619352677636813,
            "ave_precision_score": 0.800805377536212,
            "fpr": 0.16337719298245615,
            "logloss": 1.1854104923147737,
            "mae": 0.28063165127830797,
            "precision": 0.7250922509225092,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8144469993999877,
            "auditor_fn_violation": 0.007633860433220387,
            "auditor_fp_violation": 0.024698133918770578,
            "ave_precision_score": 0.8148094395088831,
            "fpr": 0.17892425905598244,
            "logloss": 1.1469483408916743,
            "mae": 0.2835026409316489,
            "precision": 0.6964618249534451,
            "recall": 0.8112798264642083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7875767177783645,
            "auditor_fn_violation": 0.014189886480908161,
            "auditor_fp_violation": 0.021788510656115232,
            "ave_precision_score": 0.7803801831192361,
            "fpr": 0.1600877192982456,
            "logloss": 2.2943865925316125,
            "mae": 0.3043202731829545,
            "precision": 0.7208413001912046,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7549172805031532,
            "auditor_fn_violation": 0.009486369296927644,
            "auditor_fp_violation": 0.024851811196487373,
            "ave_precision_score": 0.7372838122570613,
            "fpr": 0.18441273326015367,
            "logloss": 2.62663436177412,
            "mae": 0.29940155087396014,
            "precision": 0.6848030018761726,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7962372834987729,
            "auditor_fn_violation": 0.005849435963132985,
            "auditor_fp_violation": 0.012762739186869319,
            "ave_precision_score": 0.7967552702378407,
            "fpr": 0.3651315789473684,
            "logloss": 0.7461896401136666,
            "mae": 0.38954419047947514,
            "precision": 0.5827067669172933,
            "recall": 0.9432048681541582
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7954527594497675,
            "auditor_fn_violation": 0.00992211366975339,
            "auditor_fp_violation": 0.022378338821807547,
            "ave_precision_score": 0.7958723186297214,
            "fpr": 0.4083424807903403,
            "logloss": 0.7832589363409161,
            "mae": 0.40934452585851455,
            "precision": 0.535,
            "recall": 0.928416485900217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7296937887730797,
            "auditor_fn_violation": 0.002190758336002281,
            "auditor_fp_violation": 0.005686576225767284,
            "ave_precision_score": 0.7310950243718445,
            "fpr": 0.1162280701754386,
            "logloss": 0.5793919952835156,
            "mae": 0.37159968582400643,
            "precision": 0.7670329670329671,
            "recall": 0.7079107505070994
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7373722101686203,
            "auditor_fn_violation": 0.0028835324343823715,
            "auditor_fp_violation": 0.009308452250274428,
            "ave_precision_score": 0.7385830370600668,
            "fpr": 0.11086717892425905,
            "logloss": 0.5513635795736505,
            "mae": 0.3609938241695243,
            "precision": 0.7662037037037037,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6142418838224037,
            "auditor_fn_violation": 0.009336856339632046,
            "auditor_fp_violation": 0.007392810785914685,
            "ave_precision_score": 0.6152447393615326,
            "fpr": 0.2807017543859649,
            "logloss": 1.210770755927797,
            "mae": 0.4076072912990767,
            "precision": 0.6067588325652842,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.5919215271797231,
            "auditor_fn_violation": 0.014808165325701067,
            "auditor_fp_violation": 0.026639834126112944,
            "ave_precision_score": 0.593410199258103,
            "fpr": 0.29747530186608123,
            "logloss": 1.5219991029567828,
            "mae": 0.4077546941742616,
            "precision": 0.5752351097178683,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7871772037223482,
            "auditor_fn_violation": 0.01235053912672147,
            "auditor_fp_violation": 0.026368127957124322,
            "ave_precision_score": 0.7554110477721009,
            "fpr": 0.16776315789473684,
            "logloss": 3.908554389292241,
            "mae": 0.29868466079991246,
            "precision": 0.7150837988826816,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7693723452818486,
            "auditor_fn_violation": 0.008010076886261194,
            "auditor_fp_violation": 0.02188071716062935,
            "ave_precision_score": 0.7303896661535286,
            "fpr": 0.18111964873765093,
            "logloss": 3.9919265420662957,
            "mae": 0.2891871228919811,
            "precision": 0.6921641791044776,
            "recall": 0.8047722342733189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.47506290661558453,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.48032821557615446,
            "fpr": 0.4594298245614035,
            "logloss": 0.6929038367881816,
            "mae": 0.49987513571977615,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.4963588173348039,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4788800088223592,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931058755228487,
            "mae": 0.4999761040988005,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5772743852531939,
            "auditor_fn_violation": 0.0023909291484288785,
            "auditor_fp_violation": 0.0031743290206422987,
            "ave_precision_score": 0.5423783851108501,
            "fpr": 0.010964912280701754,
            "logloss": 0.7223725689226346,
            "mae": 0.4973712814481635,
            "precision": 0.6,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5361539513707164,
            "auditor_fn_violation": 0.0001333425403182855,
            "auditor_fp_violation": 0.0037614343212586904,
            "ave_precision_score": 0.507111469866041,
            "fpr": 0.008781558726673985,
            "logloss": 0.7179891391924503,
            "mae": 0.49893569141528216,
            "precision": 0.5555555555555556,
            "recall": 0.021691973969631236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6547815164608284,
            "auditor_fn_violation": 0.010655759581509565,
            "auditor_fp_violation": 0.016080999036971903,
            "ave_precision_score": 0.6560712326920021,
            "fpr": 0.09429824561403509,
            "logloss": 1.4975962386586346,
            "mae": 0.45703769068876304,
            "precision": 0.6600790513833992,
            "recall": 0.33874239350912777
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.610973846936594,
            "auditor_fn_violation": 0.003407378128489832,
            "auditor_fp_violation": 0.017285034760336628,
            "ave_precision_score": 0.6128013286670768,
            "fpr": 0.12184412733260154,
            "logloss": 1.4492487458243903,
            "mae": 0.45090189597060176,
            "precision": 0.5811320754716981,
            "recall": 0.33405639913232105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.4643548450891383,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6036378428396181,
            "fpr": 0.4594298245614035,
            "logloss": 0.6928186734739942,
            "mae": 0.4998315534832185,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5408838832558766,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5867962921787198,
            "fpr": 0.49396267837541163,
            "logloss": 0.6930939592678039,
            "mae": 0.49996913604757265,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8054629966585014,
            "auditor_fn_violation": 0.011011618803601301,
            "auditor_fp_violation": 0.02088043796842943,
            "ave_precision_score": 0.8058273906713419,
            "fpr": 0.16447368421052633,
            "logloss": 1.2371002635981534,
            "mae": 0.2987328253552254,
            "precision": 0.7191011235955056,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8060560526665761,
            "auditor_fn_violation": 0.008652978419938522,
            "auditor_fp_violation": 0.020392730820831817,
            "ave_precision_score": 0.8063250395935324,
            "fpr": 0.1800219538968167,
            "logloss": 1.1705779084469397,
            "mae": 0.2919978184675975,
            "precision": 0.6923076923076923,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7960257456545556,
            "auditor_fn_violation": 0.004014536849222448,
            "auditor_fp_violation": 0.0029047858309257566,
            "ave_precision_score": 0.7964965741329094,
            "fpr": 0.38048245614035087,
            "logloss": 0.7576803862790934,
            "mae": 0.3915516932437752,
            "precision": 0.5737100737100738,
            "recall": 0.947261663286004
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7966134810463363,
            "auditor_fn_violation": 0.009893540268256618,
            "auditor_fp_violation": 0.019656055616538617,
            "ave_precision_score": 0.7970163188156572,
            "fpr": 0.42151481888035125,
            "logloss": 0.7946910155637542,
            "mae": 0.4115141121472276,
            "precision": 0.5282555282555282,
            "recall": 0.9327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 22571,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7289230112572357,
            "auditor_fn_violation": 0.00862958613572471,
            "auditor_fp_violation": 0.012801993049449402,
            "ave_precision_score": 0.7293799415601949,
            "fpr": 0.08223684210526316,
            "logloss": 1.4226606270820457,
            "mae": 0.45214010238830127,
            "precision": 0.6696035242290749,
            "recall": 0.30831643002028397
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6900627390558651,
            "auditor_fn_violation": 0.004438401699164936,
            "auditor_fp_violation": 0.005195755579948775,
            "ave_precision_score": 0.6907106022241216,
            "fpr": 0.09220636663007684,
            "logloss": 1.315464687637335,
            "mae": 0.4344901557390213,
            "precision": 0.6410256410256411,
            "recall": 0.32537960954446854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7803265400841284,
            "auditor_fn_violation": 0.012982189245934313,
            "auditor_fp_violation": 0.02597558933132354,
            "ave_precision_score": 0.7734991362266225,
            "fpr": 0.17434210526315788,
            "logloss": 2.1214888390582582,
            "mae": 0.30553619708542396,
            "precision": 0.7055555555555556,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.746554072183109,
            "auditor_fn_violation": 0.010393574794450093,
            "auditor_fp_violation": 0.025966581290401268,
            "ave_precision_score": 0.7315323781542455,
            "fpr": 0.18990120746432493,
            "logloss": 2.4047005511996216,
            "mae": 0.3029981451156084,
            "precision": 0.6802218114602587,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8062935383595639,
            "auditor_fn_violation": 0.010733603786342126,
            "auditor_fp_violation": 0.02077314407737722,
            "ave_precision_score": 0.8066594827719775,
            "fpr": 0.16337719298245615,
            "logloss": 1.2318652474659533,
            "mae": 0.29839079833235455,
            "precision": 0.7199248120300752,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.807001375527389,
            "auditor_fn_violation": 0.007743391805624678,
            "auditor_fp_violation": 0.020812294182217347,
            "ave_precision_score": 0.8072282114985755,
            "fpr": 0.1778265642151482,
            "logloss": 1.1657303712179554,
            "mae": 0.2915993981611115,
            "precision": 0.6937618147448015,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7264646519022931,
            "auditor_fn_violation": 0.003253887762001372,
            "auditor_fp_violation": 0.012098040447180004,
            "ave_precision_score": 0.7269282539330542,
            "fpr": 0.08114035087719298,
            "logloss": 1.4462028895582328,
            "mae": 0.45314847133829955,
            "precision": 0.6782608695652174,
            "recall": 0.31643002028397565
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6884185276285708,
            "auditor_fn_violation": 0.001507246928954634,
            "auditor_fp_violation": 0.005390901329430422,
            "ave_precision_score": 0.689054266237136,
            "fpr": 0.09659714599341383,
            "logloss": 1.3387181499455827,
            "mae": 0.4360780242328483,
            "precision": 0.6348547717842323,
            "recall": 0.3318872017353579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.557112910133603,
            "auditor_fn_violation": 0.013831803138678366,
            "auditor_fp_violation": 0.014432336808608639,
            "ave_precision_score": 0.5586472812335018,
            "fpr": 0.13157894736842105,
            "logloss": 1.8651444281335494,
            "mae": 0.5124526164257539,
            "precision": 0.5847750865051903,
            "recall": 0.34279918864097364
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5329280351893009,
            "auditor_fn_violation": 0.002662088572782405,
            "auditor_fp_violation": 0.01337236248322967,
            "ave_precision_score": 0.5344597403464136,
            "fpr": 0.15697036223929747,
            "logloss": 1.7676925882747887,
            "mae": 0.49636559004043806,
            "precision": 0.5249169435215947,
            "recall": 0.34273318872017355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7919131346280599,
            "auditor_fn_violation": 0.011818974413721938,
            "auditor_fp_violation": 0.01624586525980824,
            "ave_precision_score": 0.7923975838906934,
            "fpr": 0.16885964912280702,
            "logloss": 1.2556878707834982,
            "mae": 0.3007688594664339,
            "precision": 0.7148148148148148,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7788621504218782,
            "auditor_fn_violation": 0.0073219341335473195,
            "auditor_fp_violation": 0.02561287961946579,
            "ave_precision_score": 0.7795040116357358,
            "fpr": 0.18660812294182216,
            "logloss": 1.2156972349359758,
            "mae": 0.29561807943338464,
            "precision": 0.6840148698884758,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7868425719029486,
            "auditor_fn_violation": 0.014023077470552654,
            "auditor_fp_violation": 0.021819913746179292,
            "ave_precision_score": 0.7552440358079975,
            "fpr": 0.16337719298245615,
            "logloss": 3.819287732066581,
            "mae": 0.2992182537593512,
            "precision": 0.7199248120300752,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7691831998783009,
            "auditor_fn_violation": 0.010134033064187763,
            "auditor_fp_violation": 0.023544334674960365,
            "ave_precision_score": 0.7324266714295862,
            "fpr": 0.1800219538968167,
            "logloss": 3.8651915646612527,
            "mae": 0.2923343292244159,
            "precision": 0.6893939393939394,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7865413950419038,
            "auditor_fn_violation": 0.014023077470552654,
            "auditor_fp_violation": 0.026509441862412598,
            "ave_precision_score": 0.7549457951307114,
            "fpr": 0.16228070175438597,
            "logloss": 3.7964874114597005,
            "mae": 0.29948595061394573,
            "precision": 0.7212806026365348,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7699732482413171,
            "auditor_fn_violation": 0.01083408140085863,
            "auditor_fp_violation": 0.024139529210879387,
            "ave_precision_score": 0.7331597851916629,
            "fpr": 0.1800219538968167,
            "logloss": 3.846439097533713,
            "mae": 0.29151390223015494,
            "precision": 0.690566037735849,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8062051836722547,
            "auditor_fn_violation": 0.010733603786342126,
            "auditor_fp_violation": 0.02088043796842943,
            "ave_precision_score": 0.8065684989960681,
            "fpr": 0.16447368421052633,
            "logloss": 1.2356020348966723,
            "mae": 0.29844211083633454,
            "precision": 0.7185741088180112,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8070445751434064,
            "auditor_fn_violation": 0.007743391805624678,
            "auditor_fp_violation": 0.023771191608732783,
            "ave_precision_score": 0.8073111646104153,
            "fpr": 0.17672886937431395,
            "logloss": 1.167537426523389,
            "mae": 0.29132283783010887,
            "precision": 0.6950757575757576,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8062797982764556,
            "auditor_fn_violation": 0.010733603786342126,
            "auditor_fp_violation": 0.02077314407737722,
            "ave_precision_score": 0.8066457486219146,
            "fpr": 0.16337719298245615,
            "logloss": 1.2325790044116032,
            "mae": 0.2983959335627217,
            "precision": 0.7199248120300752,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8070059861327018,
            "auditor_fn_violation": 0.007743391805624678,
            "auditor_fp_violation": 0.020812294182217347,
            "ave_precision_score": 0.8072342485348325,
            "fpr": 0.1778265642151482,
            "logloss": 1.1657305879029727,
            "mae": 0.29159888305571086,
            "precision": 0.6937618147448015,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7840205326255079,
            "auditor_fn_violation": 0.013869613181025586,
            "auditor_fp_violation": 0.02096156261776159,
            "ave_precision_score": 0.7710284504505197,
            "fpr": 0.16228070175438597,
            "logloss": 2.5959084318057153,
            "mae": 0.30334089005593573,
            "precision": 0.7186311787072244,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7568717855677085,
            "auditor_fn_violation": 0.009486369296927644,
            "auditor_fp_violation": 0.02291011098914502,
            "ave_precision_score": 0.7348295702764285,
            "fpr": 0.18551042810098792,
            "logloss": 2.8735809584153733,
            "mae": 0.298354606785421,
            "precision": 0.6835205992509363,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8001597289079422,
            "auditor_fn_violation": 0.013255756022917333,
            "auditor_fp_violation": 0.017674705857723072,
            "ave_precision_score": 0.8005341405810669,
            "fpr": 0.16337719298245615,
            "logloss": 1.277823427587011,
            "mae": 0.29947374644056807,
            "precision": 0.71939736346516,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8014352221552659,
            "auditor_fn_violation": 0.009450652545056688,
            "auditor_fp_violation": 0.027769240151237964,
            "ave_precision_score": 0.801755593827739,
            "fpr": 0.17672886937431395,
            "logloss": 1.2036251329630172,
            "mae": 0.2904239513683941,
            "precision": 0.6944971537001897,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5993666807891009,
            "auditor_fn_violation": 0.04163997722500979,
            "auditor_fp_violation": 0.03401478038772349,
            "ave_precision_score": 0.6003497147664894,
            "fpr": 0.07894736842105263,
            "logloss": 0.9044795568423071,
            "mae": 0.5046225478360786,
            "precision": 0.55,
            "recall": 0.17849898580121704
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5404686254677555,
            "auditor_fn_violation": 0.043307752201937756,
            "auditor_fp_violation": 0.04663739480424443,
            "ave_precision_score": 0.5412025228420192,
            "fpr": 0.09549945115257959,
            "logloss": 0.9092663446242712,
            "mae": 0.4988977548987814,
            "precision": 0.48823529411764705,
            "recall": 0.18004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.6972025516724901,
            "auditor_fn_violation": 0.01417209351980358,
            "auditor_fp_violation": 0.009609345559603067,
            "ave_precision_score": 0.6977950832163137,
            "fpr": 0.08552631578947369,
            "logloss": 1.3002463265898363,
            "mae": 0.4523472412271004,
            "precision": 0.6438356164383562,
            "recall": 0.28600405679513186
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6516538212521057,
            "auditor_fn_violation": 0.006017082131861486,
            "auditor_fp_violation": 0.010537870472008782,
            "ave_precision_score": 0.6534575388561588,
            "fpr": 0.09440175631174534,
            "logloss": 1.2245530984109048,
            "mae": 0.436362324683104,
            "precision": 0.6160714285714286,
            "recall": 0.2993492407809111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7274556222720427,
            "auditor_fn_violation": 0.004890840183623361,
            "auditor_fp_violation": 0.014356446007620488,
            "ave_precision_score": 0.7279106827439141,
            "fpr": 0.08114035087719298,
            "logloss": 1.4697262331465915,
            "mae": 0.4545595665001891,
            "precision": 0.6768558951965066,
            "recall": 0.3144016227180527
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6887160110261286,
            "auditor_fn_violation": 0.0026168473537458528,
            "auditor_fp_violation": 0.0065642151481888015,
            "ave_precision_score": 0.6893608969208208,
            "fpr": 0.09549945115257959,
            "logloss": 1.3559236373631687,
            "mae": 0.43586006045297565,
            "precision": 0.640495867768595,
            "recall": 0.3362255965292842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7983678243104104,
            "auditor_fn_violation": 0.009863972812355438,
            "auditor_fp_violation": 0.018881107901017463,
            "ave_precision_score": 0.7987402258818261,
            "fpr": 0.17324561403508773,
            "logloss": 1.2985026915119635,
            "mae": 0.30251550573440583,
            "precision": 0.7095588235294118,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7942599466165368,
            "auditor_fn_violation": 0.006779039505108692,
            "auditor_fp_violation": 0.026869130381753883,
            "ave_precision_score": 0.7945575018835109,
            "fpr": 0.18551042810098792,
            "logloss": 1.2455123973615343,
            "mae": 0.29561674216195505,
            "precision": 0.6876155268022182,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8077565914631699,
            "auditor_fn_violation": 0.010789206789793955,
            "auditor_fp_violation": 0.02198739689318762,
            "ave_precision_score": 0.8080918035393241,
            "fpr": 0.1600877192982456,
            "logloss": 1.1894581484933988,
            "mae": 0.296510862895231,
            "precision": 0.7229601518026565,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8097409301563525,
            "auditor_fn_violation": 0.009212540865916932,
            "auditor_fp_violation": 0.022173435784851814,
            "ave_precision_score": 0.8100040618523191,
            "fpr": 0.17233809001097694,
            "logloss": 1.1191810515134424,
            "mae": 0.28926547275396325,
            "precision": 0.6992337164750958,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.802743240857327,
            "auditor_fn_violation": 0.008295968115013696,
            "auditor_fp_violation": 0.01902503873047775,
            "ave_precision_score": 0.7890429379000531,
            "fpr": 0.16447368421052633,
            "logloss": 2.5338979960284997,
            "mae": 0.28816268103147374,
            "precision": 0.7185741088180112,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.787025189594968,
            "auditor_fn_violation": 0.0081981851127816,
            "auditor_fp_violation": 0.028069276741065987,
            "ave_precision_score": 0.7685352763261551,
            "fpr": 0.17892425905598244,
            "logloss": 2.596318073800691,
            "mae": 0.28326081441874573,
            "precision": 0.6941838649155723,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.789502324159435,
            "auditor_fn_violation": 0.01173668196861322,
            "auditor_fp_violation": 0.023942239249675507,
            "ave_precision_score": 0.7621774014125864,
            "fpr": 0.15350877192982457,
            "logloss": 3.601682339755927,
            "mae": 0.29830566301980777,
            "precision": 0.7286821705426356,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.771738218333971,
            "auditor_fn_violation": 0.012617537877615362,
            "auditor_fp_violation": 0.022119770703744365,
            "ave_precision_score": 0.7386433588557922,
            "fpr": 0.16575192096597147,
            "logloss": 3.6637551205777097,
            "mae": 0.2893221313054032,
            "precision": 0.705078125,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6956897481728912,
            "auditor_fn_violation": 0.011923508060211375,
            "auditor_fp_violation": 0.011598207930327011,
            "ave_precision_score": 0.6962834762048487,
            "fpr": 0.08552631578947369,
            "logloss": 1.317025568903763,
            "mae": 0.4544322870595056,
            "precision": 0.6405529953917051,
            "recall": 0.281947261663286
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6508170333387628,
            "auditor_fn_violation": 0.006017082131861486,
            "auditor_fp_violation": 0.010098792535675081,
            "ave_precision_score": 0.6526221939780155,
            "fpr": 0.09549945115257959,
            "logloss": 1.2412775168612749,
            "mae": 0.43801886274234103,
            "precision": 0.6133333333333333,
            "recall": 0.2993492407809111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7814087203245916,
            "auditor_fn_violation": 0.014543521582861827,
            "auditor_fp_violation": 0.022078989239207807,
            "ave_precision_score": 0.7684393978109127,
            "fpr": 0.17543859649122806,
            "logloss": 2.5143413045471097,
            "mae": 0.30359737000538173,
            "precision": 0.7058823529411765,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7531046290907301,
            "auditor_fn_violation": 0.011291255824806955,
            "auditor_fp_violation": 0.025869008415660446,
            "ave_precision_score": 0.7311458370273196,
            "fpr": 0.1942919868276619,
            "logloss": 2.8135163186688854,
            "mae": 0.30251695857920224,
            "precision": 0.6758241758241759,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7390430802756534,
            "auditor_fn_violation": 0.011209565495889827,
            "auditor_fp_violation": 0.029199639911233935,
            "ave_precision_score": 0.7397884842131138,
            "fpr": 0.11951754385964912,
            "logloss": 1.1147163519933343,
            "mae": 0.34140738578233604,
            "precision": 0.7398568019093079,
            "recall": 0.6288032454361054
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7018207532277206,
            "auditor_fn_violation": 0.009848299049220067,
            "auditor_fp_violation": 0.019709720697646062,
            "ave_precision_score": 0.7032694639156605,
            "fpr": 0.1437980241492865,
            "logloss": 1.037688981429167,
            "mae": 0.33266097810734924,
            "precision": 0.7036199095022625,
            "recall": 0.6746203904555315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.809430463959812,
            "auditor_fn_violation": 0.011496476993701295,
            "auditor_fp_violation": 0.016779717790897295,
            "ave_precision_score": 0.8098143190580523,
            "fpr": 0.16447368421052633,
            "logloss": 1.2556635077754168,
            "mae": 0.2941317906969281,
            "precision": 0.7191011235955056,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.815217061093781,
            "auditor_fn_violation": 0.009091103909555658,
            "auditor_fp_violation": 0.02613489449932919,
            "ave_precision_score": 0.8154751419964182,
            "fpr": 0.1734357848518112,
            "logloss": 1.1736521404964961,
            "mae": 0.28319795703513495,
            "precision": 0.7001897533206831,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8015729052918865,
            "auditor_fn_violation": 0.011011618803601301,
            "auditor_fp_violation": 0.017894527488171504,
            "ave_precision_score": 0.80193208076919,
            "fpr": 0.16557017543859648,
            "logloss": 1.2637322070816972,
            "mae": 0.29914264099682986,
            "precision": 0.7177570093457943,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.802701754557088,
            "auditor_fn_violation": 0.009950687071250157,
            "auditor_fp_violation": 0.02173435784851812,
            "ave_precision_score": 0.8029800268299294,
            "fpr": 0.17892425905598244,
            "logloss": 1.1919869231223517,
            "mae": 0.29111274789482994,
            "precision": 0.6930320150659134,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7946321046002678,
            "auditor_fn_violation": 0.026393633678516777,
            "auditor_fp_violation": 0.032763890633505,
            "ave_precision_score": 0.7950620724134126,
            "fpr": 0.15460526315789475,
            "logloss": 1.079724318517503,
            "mae": 0.2900922578119923,
            "precision": 0.7267441860465116,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7830074344696673,
            "auditor_fn_violation": 0.02616371130387575,
            "auditor_fp_violation": 0.030625686059275525,
            "ave_precision_score": 0.7838500014073722,
            "fpr": 0.16794731064763996,
            "logloss": 1.0246793632553859,
            "mae": 0.29043402289975295,
            "precision": 0.6994106090373281,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7886536575490756,
            "auditor_fn_violation": 0.009287925696594434,
            "auditor_fp_violation": 0.027009274379265587,
            "ave_precision_score": 0.7872607528391574,
            "fpr": 0.12171052631578948,
            "logloss": 1.5598742521842968,
            "mae": 0.3134496521653447,
            "precision": 0.754424778761062,
            "recall": 0.691683569979716
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7505649247875712,
            "auditor_fn_violation": 0.010876941503103792,
            "auditor_fp_violation": 0.022788144895718992,
            "ave_precision_score": 0.7458805956647754,
            "fpr": 0.14489571899012074,
            "logloss": 1.5844579830358032,
            "mae": 0.30591820776605994,
            "precision": 0.714902807775378,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.780726356748817,
            "auditor_fn_violation": 0.0007183908045977016,
            "auditor_fp_violation": 0.008510237407360899,
            "ave_precision_score": 0.7810884957926536,
            "fpr": 0.4309210526315789,
            "logloss": 1.5178966757500412,
            "mae": 0.4422602080862577,
            "precision": 0.5518814139110604,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.7613716085590054,
            "auditor_fn_violation": 0.0031240252303135216,
            "auditor_fp_violation": 0.003805342114892053,
            "ave_precision_score": 0.7616667529416856,
            "fpr": 0.4774972557628979,
            "logloss": 1.6786407539979578,
            "mae": 0.48584695516152127,
            "precision": 0.5051194539249146,
            "recall": 0.9631236442516269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6227435865338677,
            "auditor_fn_violation": 0.005698195793744009,
            "auditor_fp_violation": 0.0135582841351589,
            "ave_precision_score": 0.6237367593100034,
            "fpr": 0.09649122807017543,
            "logloss": 0.6902255449243113,
            "mae": 0.48987450702279284,
            "precision": 0.6053811659192825,
            "recall": 0.2738336713995943
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6166763417312482,
            "auditor_fn_violation": 0.0041717166185284435,
            "auditor_fp_violation": 0.02334431028174168,
            "ave_precision_score": 0.6172832229240173,
            "fpr": 0.1207464324917673,
            "logloss": 0.6784825754127127,
            "mae": 0.48403774697484875,
            "precision": 0.578544061302682,
            "recall": 0.3275488069414317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6671360253291864,
            "auditor_fn_violation": 0.007546439628482985,
            "auditor_fp_violation": 0.024753485742997117,
            "ave_precision_score": 0.6683028852076291,
            "fpr": 0.1699561403508772,
            "logloss": 1.0335408562875168,
            "mae": 0.40131046371959855,
            "precision": 0.651685393258427,
            "recall": 0.5882352941176471
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6275231545117719,
            "auditor_fn_violation": 0.01532248655264293,
            "auditor_fp_violation": 0.018192462495426283,
            "ave_precision_score": 0.6284672221506787,
            "fpr": 0.20636663007683864,
            "logloss": 1.0874285829102606,
            "mae": 0.41325593411595923,
            "precision": 0.5886214442013129,
            "recall": 0.5835140997830802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6649455838634184,
            "auditor_fn_violation": 0.007426337141027014,
            "auditor_fp_violation": 0.0249942427668216,
            "ave_precision_score": 0.666109761035458,
            "fpr": 0.18421052631578946,
            "logloss": 1.0309766770748996,
            "mae": 0.3990711831638292,
            "precision": 0.6440677966101694,
            "recall": 0.6166328600405679
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6179452672634043,
            "auditor_fn_violation": 0.012405618483180985,
            "auditor_fp_violation": 0.023417489937797298,
            "ave_precision_score": 0.6189326058936708,
            "fpr": 0.21953896816684962,
            "logloss": 1.1101145943704502,
            "mae": 0.4130018372509255,
            "precision": 0.5815899581589958,
            "recall": 0.6030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8086439473961041,
            "auditor_fn_violation": 0.011062773566776986,
            "auditor_fp_violation": 0.016468303814428674,
            "ave_precision_score": 0.8089893959965677,
            "fpr": 0.15570175438596492,
            "logloss": 1.2080612325570028,
            "mae": 0.2939095166302989,
            "precision": 0.7290076335877863,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8138383577728152,
            "auditor_fn_violation": 0.0107674101306995,
            "auditor_fp_violation": 0.028757165507988777,
            "ave_precision_score": 0.8141073803638965,
            "fpr": 0.16575192096597147,
            "logloss": 1.1224616882954317,
            "mae": 0.2846576033208273,
            "precision": 0.7073643410852714,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8021623256222044,
            "auditor_fn_violation": 0.00995738585815452,
            "auditor_fp_violation": 0.0171827241133861,
            "ave_precision_score": 0.8025276839104439,
            "fpr": 0.16666666666666666,
            "logloss": 1.2786265421069534,
            "mae": 0.29875330863540095,
            "precision": 0.7169459962756052,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8036456380736202,
            "auditor_fn_violation": 0.009312547771155626,
            "auditor_fp_violation": 0.029023051591657526,
            "ave_precision_score": 0.8039497867182702,
            "fpr": 0.1778265642151482,
            "logloss": 1.20684779764284,
            "mae": 0.2902997595213479,
            "precision": 0.6949152542372882,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7890199484584143,
            "auditor_fn_violation": 0.026393633678516777,
            "auditor_fp_violation": 0.030748859021061007,
            "ave_precision_score": 0.7895074961382063,
            "fpr": 0.15679824561403508,
            "logloss": 1.1331235838532272,
            "mae": 0.29095379788152176,
            "precision": 0.7239382239382239,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7777397043449393,
            "auditor_fn_violation": 0.02580654378516612,
            "auditor_fp_violation": 0.030359799975606793,
            "ave_precision_score": 0.7787143932278019,
            "fpr": 0.1734357848518112,
            "logloss": 1.0760826326796298,
            "mae": 0.2914090929418097,
            "precision": 0.6920077972709552,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7948506923756391,
            "auditor_fn_violation": 0.02283726557773745,
            "auditor_fp_violation": 0.02947441694929448,
            "ave_precision_score": 0.7952473453555727,
            "fpr": 0.15460526315789475,
            "logloss": 1.1216626409154673,
            "mae": 0.28979838785050344,
            "precision": 0.7262135922330097,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7862029797530435,
            "auditor_fn_violation": 0.023320657854947136,
            "auditor_fp_violation": 0.029603610196365406,
            "ave_precision_score": 0.7869644953756518,
            "fpr": 0.1690450054884742,
            "logloss": 1.0503110582083781,
            "mae": 0.28828903884694257,
            "precision": 0.6998050682261209,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8033739290763503,
            "auditor_fn_violation": 0.02573306999750899,
            "auditor_fp_violation": 0.031130929950173764,
            "ave_precision_score": 0.8037682595822315,
            "fpr": 0.1524122807017544,
            "logloss": 1.0299956496303713,
            "mae": 0.2872944924624536,
            "precision": 0.7300970873786408,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7958811423916505,
            "auditor_fn_violation": 0.025951791909441368,
            "auditor_fp_violation": 0.03153555311623368,
            "ave_precision_score": 0.7966276990533072,
            "fpr": 0.16575192096597147,
            "logloss": 0.9697061079547612,
            "mae": 0.2866842009249231,
            "precision": 0.702755905511811,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7968071735547648,
            "auditor_fn_violation": 0.0254150208177645,
            "auditor_fp_violation": 0.031206820751161917,
            "ave_precision_score": 0.7972170769371522,
            "fpr": 0.15350877192982457,
            "logloss": 1.074492146700131,
            "mae": 0.2882883022662299,
            "precision": 0.7297297297297297,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7868176549864863,
            "auditor_fn_violation": 0.02613751901917038,
            "auditor_fp_violation": 0.03118673008903525,
            "ave_precision_score": 0.7876502144170918,
            "fpr": 0.17014270032930845,
            "logloss": 1.0103151747841117,
            "mae": 0.2886013392342189,
            "precision": 0.6984435797665369,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7861083034461345,
            "auditor_fn_violation": 0.014023077470552654,
            "auditor_fp_violation": 0.021477096679646618,
            "ave_precision_score": 0.7544490489944585,
            "fpr": 0.16776315789473684,
            "logloss": 3.8620753586231227,
            "mae": 0.29975836790043947,
            "precision": 0.7145522388059702,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7700966176854709,
            "auditor_fn_violation": 0.011915108424153099,
            "auditor_fp_violation": 0.02298816928893768,
            "ave_precision_score": 0.7316856213465165,
            "fpr": 0.18221734357848518,
            "logloss": 3.9422799786887492,
            "mae": 0.291503714203275,
            "precision": 0.6891385767790262,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6789073712910147,
            "auditor_fn_violation": 0.01009972954699123,
            "auditor_fp_violation": 0.014134007453000043,
            "ave_precision_score": 0.6798597176217905,
            "fpr": 0.0800438596491228,
            "logloss": 1.59655819365812,
            "mae": 0.45061164882500704,
            "precision": 0.683982683982684,
            "recall": 0.3204868154158215
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6421284367409791,
            "auditor_fn_violation": 0.0013167575856428424,
            "auditor_fp_violation": 0.012967435053055256,
            "ave_precision_score": 0.6432090184788267,
            "fpr": 0.09549945115257959,
            "logloss": 1.5057027304159578,
            "mae": 0.4394652185708697,
            "precision": 0.634453781512605,
            "recall": 0.3275488069414317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6998765879036741,
            "auditor_fn_violation": 0.01417209351980358,
            "auditor_fp_violation": 0.011768308001507353,
            "ave_precision_score": 0.7004679516950174,
            "fpr": 0.08442982456140351,
            "logloss": 1.2488970393764278,
            "mae": 0.44741544973229347,
            "precision": 0.6467889908256881,
            "recall": 0.28600405679513186
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6560622251554042,
            "auditor_fn_violation": 0.005705155832188424,
            "auditor_fp_violation": 0.010537870472008782,
            "ave_precision_score": 0.6573123124297977,
            "fpr": 0.09440175631174534,
            "logloss": 1.1752892152014698,
            "mae": 0.4320373295661117,
            "precision": 0.6194690265486725,
            "recall": 0.3036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6655639577057573,
            "auditor_fn_violation": 0.011343012704174244,
            "auditor_fp_violation": 0.01660176694720094,
            "ave_precision_score": 0.6667390027982535,
            "fpr": 0.08991228070175439,
            "logloss": 1.5311443677710113,
            "mae": 0.45327043323947774,
            "precision": 0.6680161943319838,
            "recall": 0.33468559837728196
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6202745215049559,
            "auditor_fn_violation": 0.0006857616359224833,
            "auditor_fp_violation": 0.018075375045737283,
            "ave_precision_score": 0.6218110806904789,
            "fpr": 0.1207464324917673,
            "logloss": 1.4768308117422204,
            "mae": 0.44698092471574224,
            "precision": 0.5864661654135338,
            "recall": 0.3383947939262473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.805527654566249,
            "auditor_fn_violation": 0.011011618803601301,
            "auditor_fp_violation": 0.02088043796842943,
            "ave_precision_score": 0.8058946929094045,
            "fpr": 0.16447368421052633,
            "logloss": 1.2392942696417235,
            "mae": 0.2987127568570534,
            "precision": 0.7191011235955056,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8063160259256665,
            "auditor_fn_violation": 0.008652978419938522,
            "auditor_fp_violation": 0.020812294182217347,
            "ave_precision_score": 0.8065861546845428,
            "fpr": 0.1778265642151482,
            "logloss": 1.1714049820169552,
            "mae": 0.2916393301775984,
            "precision": 0.6949152542372882,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7891904346473357,
            "auditor_fn_violation": 0.009287925696594434,
            "auditor_fp_violation": 0.027009274379265587,
            "ave_precision_score": 0.7877970199060439,
            "fpr": 0.12171052631578948,
            "logloss": 1.5513996743623997,
            "mae": 0.31279566269654846,
            "precision": 0.754424778761062,
            "recall": 0.691683569979716
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7507076968922892,
            "auditor_fn_violation": 0.011367451562131675,
            "auditor_fp_violation": 0.022788144895718992,
            "ave_precision_score": 0.7460232705070677,
            "fpr": 0.14489571899012074,
            "logloss": 1.579930863168046,
            "mae": 0.3055348146980394,
            "precision": 0.7155172413793104,
            "recall": 0.720173535791757
        }
    }
]