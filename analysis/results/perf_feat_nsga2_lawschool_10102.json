[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.64810285090831,
            "mae": 0.5109649122807017,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.50156188882153,
            "mae": 0.535675082327113,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5506559087369002,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.011141924317520256,
            "ave_precision_score": 0.5022913745858295,
            "fpr": 0.046052631578947366,
            "logloss": 0.69620656599847,
            "mae": 0.4985857583713113,
            "precision": 0.5714285714285714,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5097903449571217,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5166915860463701,
            "fpr": 0.05378704720087816,
            "logloss": 0.7079883826790565,
            "mae": 0.5045889116799138,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7600707778028764,
            "auditor_fn_violation": 0.008781341766433253,
            "auditor_fp_violation": 0.0049465030288726305,
            "ave_precision_score": 0.6028497656101923,
            "fpr": 0.013157894736842105,
            "logloss": 0.6438498593931464,
            "mae": 0.46043835214355533,
            "precision": 0.896551724137931,
            "recall": 0.22317596566523606
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7673560512677475,
            "auditor_fn_violation": 0.009377643015241766,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6238186599125443,
            "fpr": 0.015367727771679473,
            "logloss": 0.6464292794071537,
            "mae": 0.46120347653471677,
            "precision": 0.888,
            "recall": 0.22745901639344263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8263774345269619,
            "auditor_fn_violation": 0.004320081319177772,
            "auditor_fp_violation": 0.003953268822279917,
            "ave_precision_score": 0.8265884309644466,
            "fpr": 0.04824561403508772,
            "logloss": 0.5818346023329468,
            "mae": 0.36905008391780264,
            "precision": 0.8445229681978799,
            "recall": 0.5128755364806867
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.8464308213110958,
            "auditor_fn_violation": 0.004453761854204538,
            "auditor_fp_violation": 0.00412608699036987,
            "ave_precision_score": 0.8465096403406884,
            "fpr": 0.04610318331503842,
            "logloss": 0.5501200142257796,
            "mae": 0.36968042424881,
            "precision": 0.8541666666666666,
            "recall": 0.5040983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.573773073095325,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.519432345916326,
            "fpr": 0.044956140350877194,
            "logloss": 0.694449976758788,
            "mae": 0.4976079833219972,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5043065700149152,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5279743610586601,
            "fpr": 0.05378704720087816,
            "logloss": 0.707587723520783,
            "mae": 0.5043434490225841,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6380486987816067,
            "auditor_fn_violation": 0.009435471726526635,
            "auditor_fp_violation": 0.046588584690425615,
            "ave_precision_score": 0.5347936832623603,
            "fpr": 0.1524122807017544,
            "logloss": 0.6947725460268391,
            "mae": 0.49104627339463486,
            "precision": 0.5709876543209876,
            "recall": 0.3969957081545064
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.6032745665997457,
            "auditor_fn_violation": 0.015111299058861648,
            "auditor_fp_violation": 0.04967653035009459,
            "ave_precision_score": 0.5297397926270387,
            "fpr": 0.16465422612513722,
            "logloss": 0.713128159956519,
            "mae": 0.5003471677442021,
            "precision": 0.5176848874598071,
            "recall": 0.32991803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8267567242322449,
            "auditor_fn_violation": 0.00391066184775243,
            "auditor_fp_violation": 0.0052906931004641665,
            "ave_precision_score": 0.8269685478699396,
            "fpr": 0.05043859649122807,
            "logloss": 0.5795341244402632,
            "mae": 0.3688935471375113,
            "precision": 0.8424657534246576,
            "recall": 0.5278969957081545
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8472014816734128,
            "auditor_fn_violation": 0.0034190495042378376,
            "auditor_fp_violation": 0.0016348646565616453,
            "ave_precision_score": 0.8472767100603502,
            "fpr": 0.052689352360043906,
            "logloss": 0.5452076521293242,
            "mae": 0.3689155817782417,
            "precision": 0.8441558441558441,
            "recall": 0.5327868852459017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5735263324786902,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.5189388646830563,
            "fpr": 0.044956140350877194,
            "logloss": 0.694685232503135,
            "mae": 0.49781807851895954,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5043065700149152,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5279743610586601,
            "fpr": 0.05378704720087816,
            "logloss": 0.7071693133301962,
            "mae": 0.5041623752805456,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8267275639033773,
            "auditor_fn_violation": 0.004950681424591529,
            "auditor_fp_violation": 0.000821139170796948,
            "ave_precision_score": 0.8270032327134111,
            "fpr": 0.06469298245614036,
            "logloss": 0.5695541352866351,
            "mae": 0.36881458691220065,
            "precision": 0.8279883381924198,
            "recall": 0.6094420600858369
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8444140380593235,
            "auditor_fn_violation": 0.003877921937701331,
            "auditor_fp_violation": 0.006145015090060284,
            "ave_precision_score": 0.8445595356980126,
            "fpr": 0.07464324917672886,
            "logloss": 0.5356203937343544,
            "mae": 0.36737303836420354,
            "precision": 0.8152173913043478,
            "recall": 0.6147540983606558
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7524923111094892,
            "auditor_fn_violation": 0.01229199608463219,
            "auditor_fp_violation": 0.0041892848713712535,
            "ave_precision_score": 0.6643331403452231,
            "fpr": 0.01206140350877193,
            "logloss": 0.6489922441701398,
            "mae": 0.4644573423031129,
            "precision": 0.897196261682243,
            "recall": 0.20600858369098712
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7879873756511062,
            "auditor_fn_violation": 0.004300804376383369,
            "auditor_fp_violation": 0.001590749261067126,
            "ave_precision_score": 0.7077316625396908,
            "fpr": 0.012074643249176729,
            "logloss": 0.6475170009495375,
            "mae": 0.46292023087568523,
            "precision": 0.9051724137931034,
            "recall": 0.2151639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6380486987816067,
            "auditor_fn_violation": 0.009435471726526635,
            "auditor_fp_violation": 0.046588584690425615,
            "ave_precision_score": 0.5347936832623603,
            "fpr": 0.1524122807017544,
            "logloss": 0.6947725460268391,
            "mae": 0.49104627339463486,
            "precision": 0.5709876543209876,
            "recall": 0.3969957081545064
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.6032745665997457,
            "auditor_fn_violation": 0.015111299058861648,
            "auditor_fp_violation": 0.04967653035009459,
            "ave_precision_score": 0.5297397926270387,
            "fpr": 0.16465422612513722,
            "logloss": 0.713128159956519,
            "mae": 0.5003471677442021,
            "precision": 0.5176848874598071,
            "recall": 0.32991803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.570580824378543,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.011141924317520256,
            "ave_precision_score": 0.5182309314057676,
            "fpr": 0.046052631578947366,
            "logloss": 0.6950870693624465,
            "mae": 0.49817948474695806,
            "precision": 0.5714285714285714,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5043065700149152,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5279743610586601,
            "fpr": 0.05378704720087816,
            "logloss": 0.7069692127847489,
            "mae": 0.5042336673427753,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7638986846510853,
            "auditor_fn_violation": 0.011207269783901826,
            "auditor_fp_violation": 0.0031714656596648575,
            "ave_precision_score": 0.5883626144852588,
            "fpr": 0.007675438596491228,
            "logloss": 0.6487075315869462,
            "mae": 0.46456613273997055,
            "precision": 0.925531914893617,
            "recall": 0.18669527896995708
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7728607973299212,
            "auditor_fn_violation": 0.0036349894729265186,
            "auditor_fp_violation": 0.0018191113083328796,
            "ave_precision_score": 0.6061184885338717,
            "fpr": 0.007683863885839737,
            "logloss": 0.6528553595710247,
            "mae": 0.4665224350637191,
            "precision": 0.9263157894736842,
            "recall": 0.18032786885245902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7612568526821437,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.6043252138545449,
            "fpr": 0.46271929824561403,
            "logloss": 0.8335397499703529,
            "mae": 0.46305301981536967,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7630690075244987,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.618975158889458,
            "fpr": 0.44017563117453345,
            "logloss": 0.8157356337873012,
            "mae": 0.45308946352758733,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5570811185513209,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.011141924317520256,
            "ave_precision_score": 0.5209251603821345,
            "fpr": 0.046052631578947366,
            "logloss": 0.6951089911547237,
            "mae": 0.4981260668290289,
            "precision": 0.5714285714285714,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5095869091926927,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5264737288809573,
            "fpr": 0.05378704720087816,
            "logloss": 0.7070781347065167,
            "mae": 0.5042240360565688,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 10102,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8288389461129093,
            "auditor_fn_violation": 0.00438361192681275,
            "auditor_fp_violation": 0.0028666115962552173,
            "ave_precision_score": 0.8291343457055742,
            "fpr": 0.07785087719298246,
            "logloss": 0.5689002405705643,
            "mae": 0.3688142028783005,
            "precision": 0.8101604278074866,
            "recall": 0.6502145922746781
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8459804877504029,
            "auditor_fn_violation": 0.001709524752118909,
            "auditor_fp_violation": 0.01130392133965481,
            "ave_precision_score": 0.8461319600908306,
            "fpr": 0.0889132821075741,
            "logloss": 0.531249858154784,
            "mae": 0.36533113853903304,
            "precision": 0.7985074626865671,
            "recall": 0.6577868852459017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 10102,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5755951899953422,
            "auditor_fn_violation": 0.013092011143739193,
            "auditor_fp_violation": 0.010694477224451264,
            "ave_precision_score": 0.5205822190315271,
            "fpr": 0.05043859649122807,
            "logloss": 0.6941611900681491,
            "mae": 0.4987134627932519,
            "precision": 0.5740740740740741,
            "recall": 0.13304721030042918
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.5841432257183271,
            "auditor_fn_violation": 0.006545680300876371,
            "auditor_fp_violation": 0.012440541529454811,
            "ave_precision_score": 0.5446964379007841,
            "fpr": 0.05159165751920966,
            "logloss": 0.6977299521143409,
            "mae": 0.5004865864760004,
            "precision": 0.5688073394495413,
            "recall": 0.12704918032786885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8269486294728885,
            "auditor_fn_violation": 0.00391066184775243,
            "auditor_fp_violation": 0.0052906931004641665,
            "ave_precision_score": 0.8271611869717903,
            "fpr": 0.05043859649122807,
            "logloss": 0.5789853082845695,
            "mae": 0.3684590284721195,
            "precision": 0.8424657534246576,
            "recall": 0.5278969957081545
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8475335401079913,
            "auditor_fn_violation": 0.0034190495042378376,
            "auditor_fp_violation": 0.0016348646565616453,
            "ave_precision_score": 0.8476108620392659,
            "fpr": 0.052689352360043906,
            "logloss": 0.5439636112584065,
            "mae": 0.3678948925357854,
            "precision": 0.8441558441558441,
            "recall": 0.5327868852459017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8451384310125174,
            "auditor_fn_violation": 0.010851968978239594,
            "auditor_fp_violation": 0.012823538667296044,
            "ave_precision_score": 0.8455074371342353,
            "fpr": 0.14692982456140352,
            "logloss": 0.5004185264654858,
            "mae": 0.3327832531054778,
            "precision": 0.7357001972386588,
            "recall": 0.8004291845493562
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8669552835288787,
            "auditor_fn_violation": 0.007980781342786713,
            "auditor_fp_violation": 0.01779666954714249,
            "ave_precision_score": 0.8671069896657578,
            "fpr": 0.141602634467618,
            "logloss": 0.49304966195136724,
            "mae": 0.3252256541196247,
            "precision": 0.7552182163187856,
            "recall": 0.8155737704918032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8340376612236492,
            "auditor_fn_violation": 0.0032800617423386818,
            "auditor_fp_violation": 0.005396408622452994,
            "ave_precision_score": 0.8342684144304136,
            "fpr": 0.047149122807017545,
            "logloss": 0.5681497364986182,
            "mae": 0.3632475759555058,
            "precision": 0.8547297297297297,
            "recall": 0.5429184549356223
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8514044939610956,
            "auditor_fn_violation": 0.0017095247521189151,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.8515018661526765,
            "fpr": 0.05159165751920966,
            "logloss": 0.5414036011861327,
            "mae": 0.3636360337877803,
            "precision": 0.8478964401294499,
            "recall": 0.5368852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8001861560115264,
            "auditor_fn_violation": 0.012108463218131166,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.8006979916762291,
            "fpr": 0.19736842105263158,
            "logloss": 0.9161286307517897,
            "mae": 0.29392890944596434,
            "precision": 0.6858638743455497,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8376333794080768,
            "auditor_fn_violation": 0.011314354609418582,
            "auditor_fp_violation": 0.029495034422983603,
            "ave_precision_score": 0.8378687852728892,
            "fpr": 0.17233809001097694,
            "logloss": 0.8679398540520895,
            "mae": 0.2704364675353428,
            "precision": 0.7250437828371279,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7638986846510853,
            "auditor_fn_violation": 0.011207269783901826,
            "auditor_fp_violation": 0.0031714656596648575,
            "ave_precision_score": 0.5883626144852588,
            "fpr": 0.007675438596491228,
            "logloss": 0.6487075315869462,
            "mae": 0.46456613273997055,
            "precision": 0.925531914893617,
            "recall": 0.18669527896995708
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7728607973299212,
            "auditor_fn_violation": 0.0036349894729265186,
            "auditor_fp_violation": 0.0018191113083328796,
            "ave_precision_score": 0.6061184885338717,
            "fpr": 0.007683863885839737,
            "logloss": 0.6528553595710247,
            "mae": 0.4665224350637191,
            "precision": 0.9263157894736842,
            "recall": 0.18032786885245902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5735263324786902,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.5189388646830563,
            "fpr": 0.044956140350877194,
            "logloss": 0.694685232503135,
            "mae": 0.49781807851895954,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5043065700149152,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5279743610586601,
            "fpr": 0.05378704720087816,
            "logloss": 0.7071693133301962,
            "mae": 0.5041623752805456,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.863425693059469,
            "auditor_fn_violation": 0.014197914313681203,
            "auditor_fp_violation": 0.015758988277869562,
            "ave_precision_score": 0.8638711746552649,
            "fpr": 0.15899122807017543,
            "logloss": 0.508765861444082,
            "mae": 0.2992061859790658,
            "precision": 0.7248576850094877,
            "recall": 0.8197424892703863
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8711017828471461,
            "auditor_fn_violation": 0.005848374151985749,
            "auditor_fp_violation": 0.01979743248398222,
            "ave_precision_score": 0.8711893701151658,
            "fpr": 0.14489571899012074,
            "logloss": 0.5159408518075986,
            "mae": 0.29628795187742196,
            "precision": 0.7555555555555555,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5570811185513209,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.011141924317520256,
            "ave_precision_score": 0.5209251603821345,
            "fpr": 0.046052631578947366,
            "logloss": 0.6951089911547237,
            "mae": 0.4981260668290289,
            "precision": 0.5714285714285714,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5095869091926927,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5264737288809573,
            "fpr": 0.05378704720087816,
            "logloss": 0.7070781347065167,
            "mae": 0.5042240360565688,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8275415242968631,
            "auditor_fn_violation": 0.0036306565770649795,
            "auditor_fp_violation": 0.003638580756824797,
            "ave_precision_score": 0.8277684329506795,
            "fpr": 0.05482456140350877,
            "logloss": 0.5742744890284793,
            "mae": 0.3690019596433021,
            "precision": 0.8371335504885994,
            "recall": 0.5515021459227468
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.847315586414895,
            "auditor_fn_violation": 0.0025597883788306894,
            "auditor_fp_violation": 0.0050343451329041165,
            "ave_precision_score": 0.8474069059558142,
            "fpr": 0.0570801317233809,
            "logloss": 0.5396881609494889,
            "mae": 0.36770431245552215,
            "precision": 0.8404907975460123,
            "recall": 0.5614754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 10102,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.506726869049515,
            "auditor_fn_violation": 0.012127287101874865,
            "auditor_fp_violation": 0.002315907481708757,
            "ave_precision_score": 0.5087757695560946,
            "fpr": 0.010964912280701754,
            "logloss": 0.6494024162913746,
            "mae": 0.46525353755344423,
            "precision": 0.9038461538461539,
            "recall": 0.2017167381974249
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5393379330131194,
            "auditor_fn_violation": 0.003715966961184813,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.541217006589813,
            "fpr": 0.009879253567508232,
            "logloss": 0.649490625283051,
            "mae": 0.4651715536934092,
            "precision": 0.9158878504672897,
            "recall": 0.20081967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8001819304669043,
            "auditor_fn_violation": 0.012108463218131166,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.8006937699120213,
            "fpr": 0.19736842105263158,
            "logloss": 0.9161329034799661,
            "mae": 0.29392913061693127,
            "precision": 0.6858638743455497,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8376333794080768,
            "auditor_fn_violation": 0.011314354609418582,
            "auditor_fp_violation": 0.029495034422983603,
            "ave_precision_score": 0.8378687852728892,
            "fpr": 0.17233809001097694,
            "logloss": 0.8679441085988532,
            "mae": 0.27043683876638674,
            "precision": 0.7250437828371279,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8447090834206508,
            "auditor_fn_violation": 0.018616821022513372,
            "auditor_fp_violation": 0.016206435370938556,
            "ave_precision_score": 0.8450671818049242,
            "fpr": 0.08442982456140351,
            "logloss": 0.5125578120660492,
            "mae": 0.3355225854319175,
            "precision": 0.8040712468193384,
            "recall": 0.6781115879828327
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8646814072032445,
            "auditor_fn_violation": 0.022687192960357035,
            "auditor_fp_violation": 0.020485113649043867,
            "ave_precision_score": 0.8648246824900174,
            "fpr": 0.08781558726673985,
            "logloss": 0.5071449698774948,
            "mae": 0.3319107789845149,
            "precision": 0.8067632850241546,
            "recall": 0.6844262295081968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7954800149067287,
            "auditor_fn_violation": 0.007713086363978617,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7959921281695487,
            "fpr": 0.19736842105263158,
            "logloss": 0.9596819299140775,
            "mae": 0.29414139083745344,
            "precision": 0.6842105263157895,
            "recall": 0.8369098712446352
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8326914667385641,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.832943727094114,
            "fpr": 0.1712403951701427,
            "logloss": 0.9128184234544772,
            "mae": 0.2709684371482867,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7028636156804173,
            "auditor_fn_violation": 0.008781341766433253,
            "auditor_fp_violation": 0.0049465030288726305,
            "ave_precision_score": 0.59660335982021,
            "fpr": 0.013157894736842105,
            "logloss": 0.6458351062477372,
            "mae": 0.46184323025507884,
            "precision": 0.896551724137931,
            "recall": 0.22317596566523606
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7653335102841409,
            "auditor_fn_violation": 0.009377643015241766,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6171916107322163,
            "fpr": 0.015367727771679473,
            "logloss": 0.6485916885686005,
            "mae": 0.4621582965557714,
            "precision": 0.888,
            "recall": 0.22745901639344263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7966560147536901,
            "auditor_fn_violation": 0.010193133047210303,
            "auditor_fp_violation": 0.034733695224608625,
            "ave_precision_score": 0.7928047198716727,
            "fpr": 0.3092105263157895,
            "logloss": 0.6082791447137869,
            "mae": 0.39797077282412496,
            "precision": 0.606694560669456,
            "recall": 0.9334763948497854
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8151654672762945,
            "auditor_fn_violation": 0.006138543484911195,
            "auditor_fp_violation": 0.033680806948434304,
            "ave_precision_score": 0.8117930732039738,
            "fpr": 0.29418221734357847,
            "logloss": 0.574496608158844,
            "mae": 0.3892232626419413,
            "precision": 0.6251748251748251,
            "recall": 0.9159836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.832704800753747,
            "auditor_fn_violation": 0.0027529929975152524,
            "auditor_fp_violation": 0.0045310164424514215,
            "ave_precision_score": 0.8329377300277452,
            "fpr": 0.044956140350877194,
            "logloss": 0.5705492422993579,
            "mae": 0.3657422815591857,
            "precision": 0.8581314878892734,
            "recall": 0.5321888412017167
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8513702188871239,
            "auditor_fn_violation": 0.001300138561479913,
            "auditor_fp_violation": 0.008293694352969875,
            "ave_precision_score": 0.851469005473225,
            "fpr": 0.05159165751920966,
            "logloss": 0.5429486949472708,
            "mae": 0.36612028361641213,
            "precision": 0.8459016393442623,
            "recall": 0.5286885245901639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8447074556042035,
            "auditor_fn_violation": 0.011066090655824113,
            "auditor_fp_violation": 0.01175654944536229,
            "ave_precision_score": 0.8450765779423725,
            "fpr": 0.1524122807017544,
            "logloss": 0.5020449664664848,
            "mae": 0.33392294488511287,
            "precision": 0.728515625,
            "recall": 0.8004291845493562
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8662340456736503,
            "auditor_fn_violation": 0.008034766334958886,
            "auditor_fp_violation": 0.015090060282390433,
            "ave_precision_score": 0.866387228517159,
            "fpr": 0.1394072447859495,
            "logloss": 0.4947516668770434,
            "mae": 0.3266808698336547,
            "precision": 0.7562380038387716,
            "recall": 0.8073770491803278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.8336218030441503,
            "auditor_fn_violation": 0.009261350801897448,
            "auditor_fp_violation": 0.016226103375029503,
            "ave_precision_score": 0.8338491314665408,
            "fpr": 0.34649122807017546,
            "logloss": 0.6453732514572187,
            "mae": 0.3817743072993874,
            "precision": 0.5847568988173456,
            "recall": 0.9549356223175965
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.851586291906713,
            "auditor_fn_violation": 0.0066356552878299845,
            "auditor_fp_violation": 0.024517779801895928,
            "ave_precision_score": 0.8516867052423189,
            "fpr": 0.3238199780461032,
            "logloss": 0.5881580002841034,
            "mae": 0.36493063100617784,
            "precision": 0.6123521681997371,
            "recall": 0.9549180327868853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7954674620009423,
            "auditor_fn_violation": 0.007713086363978617,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7959795612825391,
            "fpr": 0.19736842105263158,
            "logloss": 0.9597920631584058,
            "mae": 0.2941424630791895,
            "precision": 0.6842105263157895,
            "recall": 0.8369098712446352
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8326468412901771,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.8328922716975335,
            "fpr": 0.1712403951701427,
            "logloss": 0.9128795695009291,
            "mae": 0.27096997286572594,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8340376612236492,
            "auditor_fn_violation": 0.0032800617423386818,
            "auditor_fp_violation": 0.005396408622452994,
            "ave_precision_score": 0.8342684144304136,
            "fpr": 0.047149122807017545,
            "logloss": 0.5681497394722208,
            "mae": 0.36324762372925196,
            "precision": 0.8547297297297297,
            "recall": 0.5429184549356223
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8514044939610956,
            "auditor_fn_violation": 0.0017095247521189151,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.8515018661526765,
            "fpr": 0.05159165751920966,
            "logloss": 0.5414035273725278,
            "mae": 0.3636360713801814,
            "precision": 0.8478964401294499,
            "recall": 0.5368852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 10102,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.756728814442842,
            "auditor_fn_violation": 0.012127287101874865,
            "auditor_fp_violation": 0.002315907481708757,
            "ave_precision_score": 0.5902156348282392,
            "fpr": 0.010964912280701754,
            "logloss": 0.6495082217642029,
            "mae": 0.46529748774411384,
            "precision": 0.9038461538461539,
            "recall": 0.2017167381974249
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7767244809716485,
            "auditor_fn_violation": 0.003715966961184813,
            "auditor_fp_violation": 0.0016063194006534268,
            "ave_precision_score": 0.6137644583862291,
            "fpr": 0.008781558726673985,
            "logloss": 0.6487932933849941,
            "mae": 0.4650779358314761,
            "precision": 0.9245283018867925,
            "recall": 0.20081967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7554928651099634,
            "auditor_fn_violation": 0.010044894962728704,
            "auditor_fp_violation": 0.004317126897962395,
            "ave_precision_score": 0.5963316238694503,
            "fpr": 0.01425438596491228,
            "logloss": 0.6537061873672707,
            "mae": 0.4723959724631226,
            "precision": 0.8898305084745762,
            "recall": 0.22532188841201717
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7664783609447912,
            "auditor_fn_violation": 0.0044897518489859815,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6176669322936097,
            "fpr": 0.015367727771679473,
            "logloss": 0.6544268449998812,
            "mae": 0.47227919330712076,
            "precision": 0.889763779527559,
            "recall": 0.23155737704918034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7963902667823473,
            "auditor_fn_violation": 0.009863715081695656,
            "auditor_fp_violation": 0.0359531114782472,
            "ave_precision_score": 0.7887856787585987,
            "fpr": 0.31030701754385964,
            "logloss": 0.6074047425966976,
            "mae": 0.39775918855677145,
            "precision": 0.6063977746870653,
            "recall": 0.9356223175965666
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8142759156527307,
            "auditor_fn_violation": 0.006138543484911195,
            "auditor_fp_violation": 0.033680806948434304,
            "ave_precision_score": 0.8076772348846648,
            "fpr": 0.29418221734357847,
            "logloss": 0.5737903130930645,
            "mae": 0.3890754442558397,
            "precision": 0.6251748251748251,
            "recall": 0.9159836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8446963313857201,
            "auditor_fn_violation": 0.011407273548678563,
            "auditor_fp_violation": 0.01175654944536229,
            "ave_precision_score": 0.8450654653066918,
            "fpr": 0.1524122807017544,
            "logloss": 0.5020336766594818,
            "mae": 0.3339349162635157,
            "precision": 0.7279843444227005,
            "recall": 0.7982832618025751
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.866230814739775,
            "auditor_fn_violation": 0.007926796350614532,
            "auditor_fp_violation": 0.015090060282390433,
            "ave_precision_score": 0.8663839823915764,
            "fpr": 0.1394072447859495,
            "logloss": 0.49474477980713233,
            "mae": 0.32668140318674577,
            "precision": 0.7571701720841301,
            "recall": 0.8114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7954753444509426,
            "auditor_fn_violation": 0.007713086363978617,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7959874623981787,
            "fpr": 0.19736842105263158,
            "logloss": 0.9596878960764514,
            "mae": 0.29414175734744274,
            "precision": 0.6842105263157895,
            "recall": 0.8369098712446352
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8326914667385641,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.832943727094114,
            "fpr": 0.1712403951701427,
            "logloss": 0.9128228100461846,
            "mae": 0.2709690188565563,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5497908113065162,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.519377436727682,
            "fpr": 0.044956140350877194,
            "logloss": 0.6958566469272716,
            "mae": 0.49814345922909287,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5237604678657954,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5244594132141609,
            "fpr": 0.05378704720087816,
            "logloss": 0.7080143043625237,
            "mae": 0.5043299300872142,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7507193597505487,
            "auditor_fn_violation": 0.010654318198930805,
            "auditor_fp_violation": 0.003461568720006294,
            "ave_precision_score": 0.6189332762687317,
            "fpr": 0.015350877192982455,
            "logloss": 0.6429740501813196,
            "mae": 0.45020435227636707,
            "precision": 0.8923076923076924,
            "recall": 0.24892703862660945
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7754277334489337,
            "auditor_fn_violation": 0.005002609274621671,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6517054071487427,
            "fpr": 0.015367727771679473,
            "logloss": 0.6386651738775628,
            "mae": 0.44966608318617785,
            "precision": 0.9014084507042254,
            "recall": 0.26229508196721313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7612568526821437,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.6043252138545449,
            "fpr": 0.46271929824561403,
            "logloss": 0.8381276422739268,
            "mae": 0.46262419602850025,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7630690075244987,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.618975158889458,
            "fpr": 0.44017563117453345,
            "logloss": 0.8204962862859827,
            "mae": 0.4526245589771857,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6978678402864231,
            "mae": 0.5008503837805045,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7017083471224641,
            "mae": 0.5027667810377776,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7963902667823473,
            "auditor_fn_violation": 0.009863715081695656,
            "auditor_fp_violation": 0.0359531114782472,
            "ave_precision_score": 0.7887856787585987,
            "fpr": 0.31030701754385964,
            "logloss": 0.6074010860510577,
            "mae": 0.39775798581085464,
            "precision": 0.6063977746870653,
            "recall": 0.9356223175965666
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8142195038052382,
            "auditor_fn_violation": 0.006138543484911195,
            "auditor_fp_violation": 0.033680806948434304,
            "ave_precision_score": 0.8075644111896798,
            "fpr": 0.29418221734357847,
            "logloss": 0.5737881700172848,
            "mae": 0.38907451085616085,
            "precision": 0.6251748251748251,
            "recall": 0.9159836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.841977428468133,
            "auditor_fn_violation": 0.009600180709283942,
            "auditor_fp_violation": 0.020127743686570682,
            "ave_precision_score": 0.8423001826905441,
            "fpr": 0.15021929824561403,
            "logloss": 0.5091072049203813,
            "mae": 0.33874070956836366,
            "precision": 0.7265469061876247,
            "recall": 0.7811158798283262
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8625799778535324,
            "auditor_fn_violation": 0.012618991920246174,
            "auditor_fp_violation": 0.019514574948164415,
            "ave_precision_score": 0.8627016594556005,
            "fpr": 0.13391877058177826,
            "logloss": 0.5009107193834149,
            "mae": 0.3315538082965195,
            "precision": 0.756,
            "recall": 0.7745901639344263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5497908113065162,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.519377436727682,
            "fpr": 0.044956140350877194,
            "logloss": 0.6958566469272716,
            "mae": 0.49814345922909287,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5237604678657954,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5244594132141609,
            "fpr": 0.05378704720087816,
            "logloss": 0.7080143043625237,
            "mae": 0.5043299300872142,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 10102,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.506726869049515,
            "auditor_fn_violation": 0.012127287101874865,
            "auditor_fp_violation": 0.002315907481708757,
            "ave_precision_score": 0.5087757695560946,
            "fpr": 0.010964912280701754,
            "logloss": 0.6494024165277744,
            "mae": 0.46525353755344423,
            "precision": 0.9038461538461539,
            "recall": 0.2017167381974249
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5393379330131194,
            "auditor_fn_violation": 0.003715966961184813,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.541217006589813,
            "fpr": 0.009879253567508232,
            "logloss": 0.6494906249395932,
            "mae": 0.4651715532354152,
            "precision": 0.9158878504672897,
            "recall": 0.20081967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.573773073095325,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.519432345916326,
            "fpr": 0.044956140350877194,
            "logloss": 0.6944499767180051,
            "mae": 0.49760798328931916,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5043065700149152,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5279743610586601,
            "fpr": 0.05378704720087816,
            "logloss": 0.707587723520783,
            "mae": 0.5043434490225841,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8420301601801723,
            "auditor_fn_violation": 0.009600180709283942,
            "auditor_fp_violation": 0.01905829596412556,
            "ave_precision_score": 0.8423289425631867,
            "fpr": 0.14802631578947367,
            "logloss": 0.508917544086613,
            "mae": 0.33850721762696356,
            "precision": 0.7294589178356713,
            "recall": 0.7811158798283262
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8624652210856218,
            "auditor_fn_violation": 0.012618991920246174,
            "auditor_fp_violation": 0.019514574948164415,
            "ave_precision_score": 0.8625736578991733,
            "fpr": 0.13391877058177826,
            "logloss": 0.5009185869746244,
            "mae": 0.331443219763328,
            "precision": 0.756,
            "recall": 0.7745901639344263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7028636156804173,
            "auditor_fn_violation": 0.008781341766433253,
            "auditor_fp_violation": 0.0049465030288726305,
            "ave_precision_score": 0.59660335982021,
            "fpr": 0.013157894736842105,
            "logloss": 0.6458351062477372,
            "mae": 0.46184323025507884,
            "precision": 0.896551724137931,
            "recall": 0.22317596566523606
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7653335102841409,
            "auditor_fn_violation": 0.009377643015241766,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6171916107322163,
            "fpr": 0.015367727771679473,
            "logloss": 0.6485916885686005,
            "mae": 0.4621582965557714,
            "precision": 0.888,
            "recall": 0.22745901639344263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5287668734243038,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.011141924317520256,
            "ave_precision_score": 0.49380281731197084,
            "fpr": 0.046052631578947366,
            "logloss": 0.695281295004058,
            "mae": 0.49827997562916654,
            "precision": 0.5714285714285714,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.4805812177788242,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.4898081350625905,
            "fpr": 0.05378704720087816,
            "logloss": 0.7072435332842001,
            "mae": 0.5043695467625439,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7988785353894187,
            "auditor_fn_violation": 0.009823714328740308,
            "auditor_fp_violation": 0.013492250806388174,
            "ave_precision_score": 0.7994182576454962,
            "fpr": 0.15350877192982457,
            "logloss": 0.906624167157593,
            "mae": 0.2872319913915938,
            "precision": 0.716024340770791,
            "recall": 0.7575107296137339
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8341726846622282,
            "auditor_fn_violation": 0.01168775080527614,
            "auditor_fp_violation": 0.0270479274846699,
            "ave_precision_score": 0.8344119339220462,
            "fpr": 0.132821075740944,
            "logloss": 0.8930886489907727,
            "mae": 0.27283675631539245,
            "precision": 0.7560483870967742,
            "recall": 0.7684426229508197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7612568526821437,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.6043252138545449,
            "fpr": 0.46271929824561403,
            "logloss": 0.8335271566687191,
            "mae": 0.46305306321173384,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7630690075244987,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.618975158889458,
            "fpr": 0.44017563117453345,
            "logloss": 0.8157236959525794,
            "mae": 0.45308979557322093,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 10102,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5406440184361359,
            "auditor_fn_violation": 0.012127287101874865,
            "auditor_fp_violation": 0.002315907481708757,
            "ave_precision_score": 0.541616774662806,
            "fpr": 0.010964912280701754,
            "logloss": 0.6495799206966615,
            "mae": 0.4653719401542555,
            "precision": 0.9038461538461539,
            "recall": 0.2017167381974249
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5625229372965234,
            "auditor_fn_violation": 0.003715966961184813,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.5632564302942917,
            "fpr": 0.009879253567508232,
            "logloss": 0.6502338835098039,
            "mae": 0.46558283163085334,
            "precision": 0.9158878504672897,
            "recall": 0.20081967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8072631704050466,
            "auditor_fn_violation": 0.012748475265416765,
            "auditor_fp_violation": 0.01551313822673275,
            "ave_precision_score": 0.8081343874378026,
            "fpr": 0.1162280701754386,
            "logloss": 0.5554387958615482,
            "mae": 0.3451404520693407,
            "precision": 0.7639198218262806,
            "recall": 0.7360515021459227
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.813910704064732,
            "auditor_fn_violation": 0.009820769825988373,
            "auditor_fp_violation": 0.011664629573404126,
            "ave_precision_score": 0.8143033443495944,
            "fpr": 0.10976948408342481,
            "logloss": 0.5783848525566474,
            "mae": 0.3485062560704245,
            "precision": 0.7792494481236203,
            "recall": 0.7233606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8047993517077843,
            "auditor_fn_violation": 0.0037553648068669597,
            "auditor_fp_violation": 0.005590630162851077,
            "ave_precision_score": 0.7896421338116247,
            "fpr": 0.04824561403508772,
            "logloss": 0.5835037965693926,
            "mae": 0.38759351509407713,
            "precision": 0.8439716312056738,
            "recall": 0.5107296137339056
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8241882766625287,
            "auditor_fn_violation": 0.0043750337406201064,
            "auditor_fp_violation": 0.0011807355852945234,
            "ave_precision_score": 0.8113822371307251,
            "fpr": 0.050493962678375415,
            "logloss": 0.5712890566150743,
            "mae": 0.38832014689759253,
            "precision": 0.8491803278688524,
            "recall": 0.5307377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7930113794117034,
            "auditor_fn_violation": 0.020285087719298243,
            "auditor_fp_violation": 0.014293721973094173,
            "ave_precision_score": 0.7939130040705185,
            "fpr": 0.09868421052631579,
            "logloss": 0.58671503148733,
            "mae": 0.35404885286404525,
            "precision": 0.7709923664122137,
            "recall": 0.6502145922746781
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8026957003900573,
            "auditor_fn_violation": 0.018116463623112783,
            "auditor_fp_violation": 0.013047776973320567,
            "ave_precision_score": 0.8031070849845542,
            "fpr": 0.09989023051591657,
            "logloss": 0.6133969719564845,
            "mae": 0.35971878171514676,
            "precision": 0.7775061124694377,
            "recall": 0.6516393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7529769662444062,
            "auditor_fn_violation": 0.00800015059106996,
            "auditor_fp_violation": 0.003965561324836756,
            "ave_precision_score": 0.7009878476130259,
            "fpr": 0.01425438596491228,
            "logloss": 0.6322638739731155,
            "mae": 0.4016309773055183,
            "precision": 0.8976377952755905,
            "recall": 0.2446351931330472
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.787780224406227,
            "auditor_fn_violation": 0.006233017221212516,
            "auditor_fp_violation": 0.002024118146219181,
            "ave_precision_score": 0.7364297951596694,
            "fpr": 0.013172338090010977,
            "logloss": 0.6322481509913714,
            "mae": 0.39823905862949616,
            "precision": 0.9111111111111111,
            "recall": 0.2520491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8635056190561179,
            "auditor_fn_violation": 0.013534372411715985,
            "auditor_fp_violation": 0.015645897254346633,
            "ave_precision_score": 0.8639457557913524,
            "fpr": 0.15570175438596492,
            "logloss": 0.5087463586409026,
            "mae": 0.2996438513720549,
            "precision": 0.7284894837476099,
            "recall": 0.8175965665236051
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8706891784700129,
            "auditor_fn_violation": 0.006201525975778734,
            "auditor_fp_violation": 0.02060188969594113,
            "ave_precision_score": 0.8707754047641427,
            "fpr": 0.14270032930845225,
            "logloss": 0.514985068901766,
            "mae": 0.29652385471046094,
            "precision": 0.7579143389199255,
            "recall": 0.8340163934426229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8046877891662761,
            "auditor_fn_violation": 0.0021412167758451915,
            "auditor_fp_violation": 0.007488592557627251,
            "ave_precision_score": 0.7895314885565026,
            "fpr": 0.0537280701754386,
            "logloss": 0.5765933739174753,
            "mae": 0.388216773222279,
            "precision": 0.835016835016835,
            "recall": 0.5321888412017167
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8237606025393504,
            "auditor_fn_violation": 0.0023213546634035832,
            "auditor_fp_violation": 0.0020734235882424686,
            "ave_precision_score": 0.8110250086524378,
            "fpr": 0.05159165751920966,
            "logloss": 0.5624549517586209,
            "mae": 0.38770720624604366,
            "precision": 0.8512658227848101,
            "recall": 0.5512295081967213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7868921398840529,
            "auditor_fn_violation": 0.009567238912732484,
            "auditor_fp_violation": 0.004191743371882621,
            "ave_precision_score": 0.7151292711504081,
            "fpr": 0.009868421052631578,
            "logloss": 0.7064144513691031,
            "mae": 0.4296777143486236,
            "precision": 0.9108910891089109,
            "recall": 0.19742489270386265
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7809808291400653,
            "auditor_fn_violation": 0.003778949452052341,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.7174124925374749,
            "fpr": 0.009879253567508232,
            "logloss": 0.7384097093927768,
            "mae": 0.44460357629114394,
            "precision": 0.9142857142857143,
            "recall": 0.19672131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 10102,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.506726869049515,
            "auditor_fn_violation": 0.012127287101874865,
            "auditor_fp_violation": 0.002315907481708757,
            "ave_precision_score": 0.5087757695560946,
            "fpr": 0.010964912280701754,
            "logloss": 0.6494024157212096,
            "mae": 0.46525353729202035,
            "precision": 0.9038461538461539,
            "recall": 0.2017167381974249
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5393379330131194,
            "auditor_fn_violation": 0.003715966961184813,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.541217006589813,
            "fpr": 0.009879253567508232,
            "logloss": 0.6494906246937658,
            "mae": 0.4651715533662706,
            "precision": 0.9158878504672897,
            "recall": 0.20081967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 10102,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5755951899953422,
            "auditor_fn_violation": 0.013092011143739193,
            "auditor_fp_violation": 0.010694477224451264,
            "ave_precision_score": 0.5205822190315271,
            "fpr": 0.05043859649122807,
            "logloss": 0.6941612086567839,
            "mae": 0.4987134654728467,
            "precision": 0.5740740740740741,
            "recall": 0.13304721030042918
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.5841432257183271,
            "auditor_fn_violation": 0.006545680300876371,
            "auditor_fp_violation": 0.012440541529454811,
            "ave_precision_score": 0.5446964379007841,
            "fpr": 0.05159165751920966,
            "logloss": 0.697729985491544,
            "mae": 0.5004865965518679,
            "precision": 0.5688073394495413,
            "recall": 0.12704918032786885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7529769662444062,
            "auditor_fn_violation": 0.00800015059106996,
            "auditor_fp_violation": 0.003965561324836756,
            "ave_precision_score": 0.7009878476130259,
            "fpr": 0.01425438596491228,
            "logloss": 0.6322638727468933,
            "mae": 0.4016309774055946,
            "precision": 0.8976377952755905,
            "recall": 0.2446351931330472
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.787780224406227,
            "auditor_fn_violation": 0.006233017221212516,
            "auditor_fp_violation": 0.002024118146219181,
            "ave_precision_score": 0.7364297951596694,
            "fpr": 0.013172338090010977,
            "logloss": 0.6322481493365407,
            "mae": 0.39823905871332543,
            "precision": 0.9111111111111111,
            "recall": 0.2520491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 10102,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8645802672864079,
            "auditor_fn_violation": 0.012884948422558547,
            "auditor_fp_violation": 0.018251907796396825,
            "ave_precision_score": 0.865025345541447,
            "fpr": 0.14912280701754385,
            "logloss": 0.5070453354666343,
            "mae": 0.29776675417142223,
            "precision": 0.7364341085271318,
            "recall": 0.8154506437768241
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8717468974734908,
            "auditor_fn_violation": 0.006201525975778734,
            "auditor_fp_violation": 0.018899554434505507,
            "ave_precision_score": 0.8718368158734718,
            "fpr": 0.14050493962678376,
            "logloss": 0.5150428630234738,
            "mae": 0.29548848903140934,
            "precision": 0.7607476635514019,
            "recall": 0.8340163934426229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8001745859079115,
            "auditor_fn_violation": 0.012108463218131166,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.800686437522794,
            "fpr": 0.19736842105263158,
            "logloss": 0.9161558435830226,
            "mae": 0.29393059627748075,
            "precision": 0.6858638743455497,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.837629078921138,
            "auditor_fn_violation": 0.011314354609418582,
            "auditor_fp_violation": 0.029495034422983603,
            "ave_precision_score": 0.8378653358259794,
            "fpr": 0.17233809001097694,
            "logloss": 0.867962984880439,
            "mae": 0.270439993476204,
            "precision": 0.7250437828371279,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7612568526821437,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.6043252138545449,
            "fpr": 0.46271929824561403,
            "logloss": 0.8381237710624998,
            "mae": 0.46262420478620025,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7630690075244987,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.618975158889458,
            "fpr": 0.44017563117453345,
            "logloss": 0.8204926077787011,
            "mae": 0.45262465420721915,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7529769662444062,
            "auditor_fn_violation": 0.00800015059106996,
            "auditor_fp_violation": 0.003965561324836756,
            "ave_precision_score": 0.7009878476130259,
            "fpr": 0.01425438596491228,
            "logloss": 0.6331491824476534,
            "mae": 0.4017649600078074,
            "precision": 0.8976377952755905,
            "recall": 0.2446351931330472
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.787780224406227,
            "auditor_fn_violation": 0.006233017221212516,
            "auditor_fp_violation": 0.002024118146219181,
            "ave_precision_score": 0.7364297951596694,
            "fpr": 0.013172338090010977,
            "logloss": 0.6333833535371655,
            "mae": 0.39849119847711956,
            "precision": 0.9111111111111111,
            "recall": 0.2520491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8287110765722945,
            "auditor_fn_violation": 0.0058824636699043795,
            "auditor_fp_violation": 0.00402702383762096,
            "ave_precision_score": 0.8289305558016667,
            "fpr": 0.044956140350877194,
            "logloss": 0.5801762811747833,
            "mae": 0.36983928436970165,
            "precision": 0.8530465949820788,
            "recall": 0.5107296137339056
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8456859295150787,
            "auditor_fn_violation": 0.006586169045005493,
            "auditor_fp_violation": 0.00412608699036987,
            "ave_precision_score": 0.8457779872714519,
            "fpr": 0.04610318331503842,
            "logloss": 0.5514630431472853,
            "mae": 0.371167250616794,
            "precision": 0.8531468531468531,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7529769662444062,
            "auditor_fn_violation": 0.00806838716964084,
            "auditor_fp_violation": 0.018242073794351353,
            "ave_precision_score": 0.7009878476130259,
            "fpr": 0.10087719298245613,
            "logloss": 0.6288000977658318,
            "mae": 0.4011390781205703,
            "precision": 0.707936507936508,
            "recall": 0.47854077253218885
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.787780224406227,
            "auditor_fn_violation": 0.020802216983678536,
            "auditor_fp_violation": 0.0076112032344370015,
            "ave_precision_score": 0.7364297951596694,
            "fpr": 0.08342480790340286,
            "logloss": 0.6277280359746974,
            "mae": 0.39725968558811525,
            "precision": 0.7639751552795031,
            "recall": 0.5040983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.741614917497618,
            "auditor_fn_violation": 0.005200097884195474,
            "auditor_fp_violation": 0.0041892848713712535,
            "ave_precision_score": 0.6094996858072842,
            "fpr": 0.01206140350877193,
            "logloss": 0.6422580490944708,
            "mae": 0.4539041226206903,
            "precision": 0.9035087719298246,
            "recall": 0.22103004291845493
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7648666593692223,
            "auditor_fn_violation": 0.0044897518489859815,
            "auditor_fp_violation": 0.0031996636849849366,
            "ave_precision_score": 0.6289354912244286,
            "fpr": 0.014270032930845226,
            "logloss": 0.6550234123192491,
            "mae": 0.4551989142583636,
            "precision": 0.8968253968253969,
            "recall": 0.23155737704918034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.757354266310486,
            "auditor_fn_violation": 0.003225943076575574,
            "auditor_fp_violation": 0.003495987727165448,
            "ave_precision_score": 0.5959923542294812,
            "fpr": 0.013157894736842105,
            "logloss": 0.6535608750289107,
            "mae": 0.47249359464305535,
            "precision": 0.8956521739130435,
            "recall": 0.22103004291845493
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7589669998211086,
            "auditor_fn_violation": 0.003967896924654954,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6102676544156018,
            "fpr": 0.015367727771679473,
            "logloss": 0.6580182373790059,
            "mae": 0.4744174962640463,
            "precision": 0.8823529411764706,
            "recall": 0.2151639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 10102,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.756728814442842,
            "auditor_fn_violation": 0.012127287101874865,
            "auditor_fp_violation": 0.002315907481708757,
            "ave_precision_score": 0.5902156348282392,
            "fpr": 0.010964912280701754,
            "logloss": 0.6495082217642029,
            "mae": 0.46529748774411384,
            "precision": 0.9038461538461539,
            "recall": 0.2017167381974249
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7767244809716485,
            "auditor_fn_violation": 0.003715966961184813,
            "auditor_fp_violation": 0.0016063194006534268,
            "ave_precision_score": 0.6137644583862291,
            "fpr": 0.008781558726673985,
            "logloss": 0.6487932933849941,
            "mae": 0.4650779358314761,
            "precision": 0.9245283018867925,
            "recall": 0.20081967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7551330847628757,
            "auditor_fn_violation": 0.008258978992545749,
            "auditor_fp_violation": 0.018242073794351353,
            "ave_precision_score": 0.7031342095319314,
            "fpr": 0.10087719298245613,
            "logloss": 0.6126850698202673,
            "mae": 0.3998267068200859,
            "precision": 0.7097791798107256,
            "recall": 0.48283261802575106
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7904578957554435,
            "auditor_fn_violation": 0.02132407190800958,
            "auditor_fp_violation": 0.007606013187908229,
            "ave_precision_score": 0.739771495469477,
            "fpr": 0.08232711306256861,
            "logloss": 0.6063476821207467,
            "mae": 0.3947580731898121,
            "precision": 0.7670807453416149,
            "recall": 0.5061475409836066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8620479567502373,
            "auditor_fn_violation": 0.012230818462465178,
            "auditor_fp_violation": 0.014254385964912282,
            "ave_precision_score": 0.8623922374365067,
            "fpr": 0.14912280701754385,
            "logloss": 0.5083954748814011,
            "mae": 0.29910424586488626,
            "precision": 0.7359223300970874,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8717412281792631,
            "auditor_fn_violation": 0.008135988195281715,
            "auditor_fp_violation": 0.021229885325921953,
            "ave_precision_score": 0.8718671842968175,
            "fpr": 0.13830954994511527,
            "logloss": 0.5131475176060835,
            "mae": 0.29410394452660243,
            "precision": 0.7627118644067796,
            "recall": 0.8299180327868853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6380486987816067,
            "auditor_fn_violation": 0.009435471726526635,
            "auditor_fp_violation": 0.046588584690425615,
            "ave_precision_score": 0.5347936832623603,
            "fpr": 0.1524122807017544,
            "logloss": 0.6947725460268391,
            "mae": 0.49104627339463486,
            "precision": 0.5709876543209876,
            "recall": 0.3969957081545064
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.6032745665997457,
            "auditor_fn_violation": 0.015111299058861648,
            "auditor_fp_violation": 0.04967653035009459,
            "ave_precision_score": 0.5297397926270387,
            "fpr": 0.16465422612513722,
            "logloss": 0.713128159956519,
            "mae": 0.5003471677442021,
            "precision": 0.5176848874598071,
            "recall": 0.32991803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7507193597505487,
            "auditor_fn_violation": 0.010654318198930805,
            "auditor_fp_violation": 0.003461568720006294,
            "ave_precision_score": 0.6189332762687317,
            "fpr": 0.015350877192982455,
            "logloss": 0.6429740531268338,
            "mae": 0.45020435015229804,
            "precision": 0.8923076923076924,
            "recall": 0.24892703862660945
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7754277334489337,
            "auditor_fn_violation": 0.005002609274621671,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6517054071487427,
            "fpr": 0.015367727771679473,
            "logloss": 0.63866518008541,
            "mae": 0.4496660825646146,
            "precision": 0.9014084507042254,
            "recall": 0.26229508196721313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7952078710400498,
            "auditor_fn_violation": 0.0057648143965062905,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7957360887643475,
            "fpr": 0.19736842105263158,
            "logloss": 0.9444057674040516,
            "mae": 0.29443807025186575,
            "precision": 0.6836555360281195,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8332769268095213,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.8335267433167641,
            "fpr": 0.1712403951701427,
            "logloss": 0.8963671836741973,
            "mae": 0.27105595913173625,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7495961934989988,
            "auditor_fn_violation": 0.010654318198930805,
            "auditor_fp_violation": 0.003461568720006294,
            "ave_precision_score": 0.6166797913616565,
            "fpr": 0.015350877192982455,
            "logloss": 0.6431704849983971,
            "mae": 0.45037868357541266,
            "precision": 0.8923076923076924,
            "recall": 0.24892703862660945
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7758129493225776,
            "auditor_fn_violation": 0.005002609274621671,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6504657461035944,
            "fpr": 0.015367727771679473,
            "logloss": 0.6381785542740841,
            "mae": 0.44947901868663165,
            "precision": 0.9014084507042254,
            "recall": 0.26229508196721313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5287668734243038,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.011141924317520256,
            "ave_precision_score": 0.49380281731197084,
            "fpr": 0.046052631578947366,
            "logloss": 0.695281295004058,
            "mae": 0.49827997562916654,
            "precision": 0.5714285714285714,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.4805812177788242,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.4898081350625905,
            "fpr": 0.05378704720087816,
            "logloss": 0.7072435332842001,
            "mae": 0.5043695467625439,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7915710832917757,
            "auditor_fn_violation": 0.010131955425043297,
            "auditor_fp_violation": 0.023547517897883733,
            "ave_precision_score": 0.7921494947655563,
            "fpr": 0.19298245614035087,
            "logloss": 0.9713697480500372,
            "mae": 0.2938497474293641,
            "precision": 0.6868327402135231,
            "recall": 0.8283261802575107
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8313185427963614,
            "auditor_fn_violation": 0.00946536862752155,
            "auditor_fp_violation": 0.029113566003119224,
            "ave_precision_score": 0.8315653194029995,
            "fpr": 0.1690450054884742,
            "logloss": 0.9193015524284419,
            "mae": 0.2741375266615855,
            "precision": 0.7245080500894454,
            "recall": 0.8299180327868853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7620802514419097,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.5997991022962826,
            "fpr": 0.46271929824561403,
            "logloss": 0.8543832117284499,
            "mae": 0.46366174316458536,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7725936272138276,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.619260748967817,
            "fpr": 0.44017563117453345,
            "logloss": 0.8315521635045018,
            "mae": 0.4527003162353413,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8001745859079115,
            "auditor_fn_violation": 0.012108463218131166,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.800686437522794,
            "fpr": 0.19736842105263158,
            "logloss": 0.9161531113448047,
            "mae": 0.2939303612585405,
            "precision": 0.6858638743455497,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8376290866196718,
            "auditor_fn_violation": 0.011314354609418582,
            "auditor_fp_violation": 0.029495034422983603,
            "ave_precision_score": 0.837864496685796,
            "fpr": 0.17233809001097694,
            "logloss": 0.8679605904009305,
            "mae": 0.2704398909223296,
            "precision": 0.7250437828371279,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7868921398840529,
            "auditor_fn_violation": 0.009567238912732484,
            "auditor_fp_violation": 0.004191743371882621,
            "ave_precision_score": 0.7151292711504081,
            "fpr": 0.009868421052631578,
            "logloss": 0.7064144513691031,
            "mae": 0.4296777143486236,
            "precision": 0.9108910891089109,
            "recall": 0.19742489270386265
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7809808291400653,
            "auditor_fn_violation": 0.003778949452052341,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.7174124925374749,
            "fpr": 0.009879253567508232,
            "logloss": 0.7384097093927768,
            "mae": 0.44460357629114394,
            "precision": 0.9142857142857143,
            "recall": 0.19672131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7868921398840529,
            "auditor_fn_violation": 0.009567238912732484,
            "auditor_fp_violation": 0.004191743371882621,
            "ave_precision_score": 0.7151292711504081,
            "fpr": 0.009868421052631578,
            "logloss": 0.7064144336755996,
            "mae": 0.4296777119631307,
            "precision": 0.9108910891089109,
            "recall": 0.19742489270386265
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7804015620660341,
            "auditor_fn_violation": 0.003778949452052341,
            "auditor_fp_violation": 0.0007006562813835626,
            "ave_precision_score": 0.7168342173803981,
            "fpr": 0.009879253567508232,
            "logloss": 0.739245520770533,
            "mae": 0.44487642936007776,
            "precision": 0.9142857142857143,
            "recall": 0.19672131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8401485358643812,
            "auditor_fn_violation": 0.005967171146750997,
            "auditor_fp_violation": 0.015601644245142007,
            "ave_precision_score": 0.8404105825810844,
            "fpr": 0.13267543859649122,
            "logloss": 0.5090681978922936,
            "mae": 0.3364429082295126,
            "precision": 0.7463312368972747,
            "recall": 0.7639484978540773
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8607156536888322,
            "auditor_fn_violation": 0.010167173525759843,
            "auditor_fp_violation": 0.022304224957376738,
            "ave_precision_score": 0.8607989116670273,
            "fpr": 0.12184412733260154,
            "logloss": 0.5008497389819565,
            "mae": 0.3294536141663612,
            "precision": 0.7720739219712526,
            "recall": 0.7704918032786885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6978678402864231,
            "mae": 0.5008503837805045,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7017083471224641,
            "mae": 0.5027667810377776,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.702334613594699,
            "auditor_fn_violation": 0.010830792109027949,
            "auditor_fp_violation": 0.003461568720006294,
            "ave_precision_score": 0.6517446891391193,
            "fpr": 0.015350877192982455,
            "logloss": 0.6498014866301798,
            "mae": 0.4496325047915442,
            "precision": 0.8914728682170543,
            "recall": 0.24678111587982832
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7335336081177017,
            "auditor_fn_violation": 0.004820409926040581,
            "auditor_fp_violation": 0.00309326773114521,
            "ave_precision_score": 0.6836417605477474,
            "fpr": 0.015367727771679473,
            "logloss": 0.6514530820179514,
            "mae": 0.4515289712357861,
            "precision": 0.900709219858156,
            "recall": 0.26024590163934425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6978678402864231,
            "mae": 0.5008503837805045,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7017083471224641,
            "mae": 0.5027667810377776,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.573773073095325,
            "auditor_fn_violation": 0.0022776899329869896,
            "auditor_fp_violation": 0.004066359845802847,
            "ave_precision_score": 0.519432345916326,
            "fpr": 0.044956140350877194,
            "logloss": 0.6944499767995707,
            "mae": 0.49760798335467515,
            "precision": 0.5773195876288659,
            "recall": 0.12017167381974249
        },
        "train": {
            "accuracy": 0.4522502744237102,
            "auc_prc": 0.5043065700149152,
            "auditor_fn_violation": 0.007517410159975531,
            "auditor_fp_violation": 0.011877421481083578,
            "ave_precision_score": 0.5279743610586601,
            "fpr": 0.05378704720087816,
            "logloss": 0.707587723520783,
            "mae": 0.5043434490225841,
            "precision": 0.4367816091954023,
            "recall": 0.0778688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7954257520003555,
            "auditor_fn_violation": 0.0057648143965062905,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7959409509792199,
            "fpr": 0.19736842105263158,
            "logloss": 0.9591114591120363,
            "mae": 0.294178586509422,
            "precision": 0.6836555360281195,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8326132080906858,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.8328663694488494,
            "fpr": 0.1712403951701427,
            "logloss": 0.9123060225749419,
            "mae": 0.27103333842721195,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7612568526821437,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.6043252138545449,
            "fpr": 0.46271929824561403,
            "logloss": 0.8381190358570264,
            "mae": 0.46262420981860997,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7630690075244987,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.618975158889458,
            "fpr": 0.44017563117453345,
            "logloss": 0.8204881140297613,
            "mae": 0.45262476577782346,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7952732595763174,
            "auditor_fn_violation": 0.0057648143965062905,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7958014975285921,
            "fpr": 0.19736842105263158,
            "logloss": 0.9443353084305174,
            "mae": 0.29444381151834764,
            "precision": 0.6836555360281195,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8332198700515061,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.8334687415117911,
            "fpr": 0.1712403951701427,
            "logloss": 0.8965857081920751,
            "mae": 0.27107588630649837,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7954826989879509,
            "auditor_fn_violation": 0.007713086363978617,
            "auditor_fp_violation": 0.0227558807332232,
            "ave_precision_score": 0.7959948109056975,
            "fpr": 0.19736842105263158,
            "logloss": 0.9596756654154606,
            "mae": 0.29414099662614407,
            "precision": 0.6842105263157895,
            "recall": 0.8369098712446352
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.832693323586249,
            "auditor_fn_violation": 0.005650429180687775,
            "auditor_fp_violation": 0.02854785093148361,
            "ave_precision_score": 0.832945583361083,
            "fpr": 0.1712403951701427,
            "logloss": 0.9128125475474741,
            "mae": 0.270967859571396,
            "precision": 0.723404255319149,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7612568526821437,
            "auditor_fn_violation": 0.0020141555605752578,
            "auditor_fp_violation": 0.004336794902053348,
            "ave_precision_score": 0.6043252138545449,
            "fpr": 0.46271929824561403,
            "logloss": 0.8335301918715965,
            "mae": 0.4630530488334204,
            "precision": 0.5226244343891403,
            "recall": 0.9914163090128756
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7630690075244987,
            "auditor_fn_violation": 0.0012259091972431665,
            "auditor_fp_violation": 0.0067418704408685175,
            "ave_precision_score": 0.618975158889458,
            "fpr": 0.44017563117453345,
            "logloss": 0.8157265762584208,
            "mae": 0.4530897119402493,
            "precision": 0.5443181818181818,
            "recall": 0.9815573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8627171020170257,
            "auditor_fn_violation": 0.012230818462465178,
            "auditor_fp_violation": 0.014190464951616716,
            "ave_precision_score": 0.863034643068458,
            "fpr": 0.1524122807017544,
            "logloss": 0.5044298235128553,
            "mae": 0.29935371025101376,
            "precision": 0.7316602316602316,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8719497233080676,
            "auditor_fn_violation": 0.008633099998200501,
            "auditor_fp_violation": 0.021229885325921953,
            "ave_precision_score": 0.8720758048101991,
            "fpr": 0.13830954994511527,
            "logloss": 0.5086241850670887,
            "mae": 0.2942095399195848,
            "precision": 0.7631578947368421,
            "recall": 0.8319672131147541
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7962866179776835,
            "auditor_fn_violation": 0.009863715081695656,
            "auditor_fp_violation": 0.034733695224608625,
            "ave_precision_score": 0.7886784359180574,
            "fpr": 0.3092105263157895,
            "logloss": 0.6054788636592943,
            "mae": 0.3970368749303448,
            "precision": 0.6072423398328691,
            "recall": 0.9356223175965666
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8143913501848932,
            "auditor_fn_violation": 0.007171006460204066,
            "auditor_fp_violation": 0.033680806948434304,
            "ave_precision_score": 0.8077876845661194,
            "fpr": 0.29418221734357847,
            "logloss": 0.5722148504625404,
            "mae": 0.3884924614606332,
            "precision": 0.6235955056179775,
            "recall": 0.9098360655737705
        }
    }
]