[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7403710597256681,
            "auditor_fn_violation": 0.01156153250773995,
            "auditor_fp_violation": 0.023690246257846454,
            "ave_precision_score": 0.7395495488886656,
            "fpr": 0.1074561403508772,
            "logloss": 2.0424875884236675,
            "mae": 0.3687276444990202,
            "precision": 0.7142857142857143,
            "recall": 0.5147058823529411
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.771972174023136,
            "auditor_fn_violation": 0.0165894299794699,
            "auditor_fp_violation": 0.014627480904419425,
            "ave_precision_score": 0.7717546625510846,
            "fpr": 0.09440175631174534,
            "logloss": 1.7677195897513394,
            "mae": 0.35444491901959607,
            "precision": 0.7417417417417418,
            "recall": 0.5167364016736402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.7129233188139077,
            "auditor_fn_violation": 0.013807496682883686,
            "auditor_fp_violation": 0.02511870272010302,
            "ave_precision_score": 0.7121097314825724,
            "fpr": 0.13815789473684212,
            "logloss": 2.828521358282776,
            "mae": 0.39238853876065494,
            "precision": 0.6621983914209115,
            "recall": 0.5189075630252101
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7460622989143827,
            "auditor_fn_violation": 0.009631238833595896,
            "auditor_fp_violation": 0.009983192339965984,
            "ave_precision_score": 0.7458559141789964,
            "fpr": 0.11964873765093303,
            "logloss": 2.438050672336698,
            "mae": 0.37095688348842276,
            "precision": 0.7093333333333334,
            "recall": 0.5564853556485355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8328732461993282,
            "auditor_fn_violation": 0.012153545628777827,
            "auditor_fp_violation": 0.025098583615000808,
            "ave_precision_score": 0.8319087425300026,
            "fpr": 0.16228070175438597,
            "logloss": 1.0479627916795555,
            "mae": 0.26972794558992813,
            "precision": 0.7218045112781954,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8570204483482016,
            "auditor_fn_violation": 0.00757363511521203,
            "auditor_fp_violation": 0.021766300007858785,
            "ave_precision_score": 0.8566750287620251,
            "fpr": 0.15148188803512624,
            "logloss": 0.8905469631102433,
            "mae": 0.2660961934759391,
            "precision": 0.7325581395348837,
            "recall": 0.7907949790794979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8097423014677194,
            "auditor_fn_violation": 0.012780112044817932,
            "auditor_fp_violation": 0.02508349428617416,
            "ave_precision_score": 0.8090154835368274,
            "fpr": 0.16885964912280702,
            "logloss": 1.079692575527784,
            "mae": 0.27298044745157224,
            "precision": 0.7158671586715867,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8094009585855433,
            "auditor_fn_violation": 0.007116645003651335,
            "auditor_fp_violation": 0.022113607613388334,
            "ave_precision_score": 0.8092791011234425,
            "fpr": 0.16575192096597147,
            "logloss": 0.9768290409371865,
            "mae": 0.27397483223312835,
            "precision": 0.7150943396226415,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8221071509742813,
            "auditor_fn_violation": 0.019773698953265518,
            "auditor_fp_violation": 0.025594016578142614,
            "ave_precision_score": 0.8224238700395592,
            "fpr": 0.1524122807017544,
            "logloss": 1.0552962344809524,
            "mae": 0.27165588598093776,
            "precision": 0.734225621414914,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8236399494761986,
            "auditor_fn_violation": 0.01643327255441398,
            "auditor_fp_violation": 0.02985831370749601,
            "ave_precision_score": 0.8240261188647124,
            "fpr": 0.14489571899012074,
            "logloss": 1.0010438021040637,
            "mae": 0.26442118251706864,
            "precision": 0.7421875,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7730440241955769,
            "auditor_fn_violation": 0.017313504349108066,
            "auditor_fp_violation": 0.018743461290841784,
            "ave_precision_score": 0.7476867784328279,
            "fpr": 0.13706140350877194,
            "logloss": 4.133017305795271,
            "mae": 0.31600356731262497,
            "precision": 0.7139588100686499,
            "recall": 0.6554621848739496
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7834650796237874,
            "auditor_fn_violation": 0.004188693283852861,
            "auditor_fp_violation": 0.019294585296973355,
            "ave_precision_score": 0.7608125669751744,
            "fpr": 0.12294182217343579,
            "logloss": 3.859305160181408,
            "mae": 0.3025568391397224,
            "precision": 0.7389277389277389,
            "recall": 0.6631799163179917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8197691460291155,
            "auditor_fn_violation": 0.015012254901960786,
            "auditor_fp_violation": 0.02330798326090456,
            "ave_precision_score": 0.8201555816375155,
            "fpr": 0.15350877192982457,
            "logloss": 1.0286878604888539,
            "mae": 0.2748129556453113,
            "precision": 0.7333333333333333,
            "recall": 0.8088235294117647
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8226263300214879,
            "auditor_fn_violation": 0.012313472252203425,
            "auditor_fp_violation": 0.02217952000567862,
            "ave_precision_score": 0.8230461472697304,
            "fpr": 0.150384193194292,
            "logloss": 0.9604854212596222,
            "mae": 0.2685229396192701,
            "precision": 0.732943469785575,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8509155447838742,
            "auditor_fn_violation": 0.02832448768981277,
            "auditor_fp_violation": 0.015393630291324643,
            "ave_precision_score": 0.8499314532937787,
            "fpr": 0.044956140350877194,
            "logloss": 0.6938258441398597,
            "mae": 0.2962519277093534,
            "precision": 0.8797653958944281,
            "recall": 0.6302521008403361
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8814416396774736,
            "auditor_fn_violation": 0.029477010412025967,
            "auditor_fp_violation": 0.006203370151319643,
            "ave_precision_score": 0.8810637185513983,
            "fpr": 0.038419319429198684,
            "logloss": 0.595189839371121,
            "mae": 0.2840432111789066,
            "precision": 0.8955223880597015,
            "recall": 0.6276150627615062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7965580277108035,
            "auditor_fn_violation": 0.014862523956951203,
            "auditor_fp_violation": 0.018982375663930476,
            "ave_precision_score": 0.7434910704480274,
            "fpr": 0.1600877192982456,
            "logloss": 3.074507502136383,
            "mae": 0.2717152866595203,
            "precision": 0.73502722323049,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8143709986539006,
            "auditor_fn_violation": 0.010508476133174727,
            "auditor_fp_violation": 0.016080088626816712,
            "ave_precision_score": 0.7666574631070965,
            "fpr": 0.141602634467618,
            "logloss": 2.6666981887032084,
            "mae": 0.25477873712507426,
            "precision": 0.7588785046728972,
            "recall": 0.8493723849372385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7069458115473528,
            "auditor_fn_violation": 0.01223647353678315,
            "auditor_fp_violation": 0.01903267342668598,
            "ave_precision_score": 0.7061198774833018,
            "fpr": 0.07894736842105263,
            "logloss": 2.2473221038448146,
            "mae": 0.39871904859225693,
            "precision": 0.7455830388692579,
            "recall": 0.4432773109243697
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7341392765638881,
            "auditor_fn_violation": 0.016258743667586797,
            "auditor_fp_violation": 0.011382563130128809,
            "ave_precision_score": 0.733988572546846,
            "fpr": 0.08342480790340286,
            "logloss": 1.8895377904777317,
            "mae": 0.38271418120767364,
            "precision": 0.7483443708609272,
            "recall": 0.47280334728033474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.814133471729563,
            "auditor_fn_violation": 0.01655102830605927,
            "auditor_fp_violation": 0.01927410268791244,
            "ave_precision_score": 0.8106587757222956,
            "fpr": 0.11842105263157894,
            "logloss": 1.2328994237771227,
            "mae": 0.26969941794944735,
            "precision": 0.7726315789473684,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8114156039732943,
            "auditor_fn_violation": 0.012837058912685037,
            "auditor_fp_violation": 0.021241535961547726,
            "ave_precision_score": 0.8066802653769127,
            "fpr": 0.12623490669593854,
            "logloss": 1.159989520036164,
            "mae": 0.26338848410095267,
            "precision": 0.7573839662447257,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7007661273646228,
            "auditor_fn_violation": 0.009490638360607399,
            "auditor_fp_violation": 0.01654544905842588,
            "ave_precision_score": 0.6999373911251727,
            "fpr": 0.0756578947368421,
            "logloss": 3.9731383914032956,
            "mae": 0.41485473033327525,
            "precision": 0.7272727272727273,
            "recall": 0.3865546218487395
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.7074901732408082,
            "auditor_fn_violation": 0.011015987764606477,
            "auditor_fp_violation": 0.01369710213632204,
            "ave_precision_score": 0.7073913078112379,
            "fpr": 0.08122941822173436,
            "logloss": 3.5988286965805725,
            "mae": 0.4088875614920644,
            "precision": 0.7186311787072244,
            "recall": 0.39539748953974896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.814720862117048,
            "auditor_fn_violation": 0.015899122807017545,
            "auditor_fp_violation": 0.018637835989055208,
            "ave_precision_score": 0.8112333986045914,
            "fpr": 0.11513157894736842,
            "logloss": 1.2092319803095317,
            "mae": 0.2723803552283752,
            "precision": 0.7727272727272727,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8118562924547197,
            "auditor_fn_violation": 0.013379017034937928,
            "auditor_fp_violation": 0.023728461224500143,
            "ave_precision_score": 0.8079100084143536,
            "fpr": 0.11855104281009879,
            "logloss": 1.1272461296241452,
            "mae": 0.265810683463546,
            "precision": 0.7672413793103449,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.807947942096987,
            "auditor_fn_violation": 0.015995872033023738,
            "auditor_fp_violation": 0.020335385482053766,
            "ave_precision_score": 0.8070240914328433,
            "fpr": 0.1425438596491228,
            "logloss": 1.1481755990322418,
            "mae": 0.27222872381700414,
            "precision": 0.7415506958250497,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8233122565359996,
            "auditor_fn_violation": 0.015078377248781746,
            "auditor_fp_violation": 0.020658464798979884,
            "ave_precision_score": 0.8232364595213756,
            "fpr": 0.141602634467618,
            "logloss": 0.9708991352137774,
            "mae": 0.2661918995152949,
            "precision": 0.742,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8144308480599656,
            "auditor_fn_violation": 0.01373608653987911,
            "auditor_fp_violation": 0.01864035087719298,
            "ave_precision_score": 0.8108678978219279,
            "fpr": 0.11951754385964912,
            "logloss": 1.2245864882125834,
            "mae": 0.27016062966652593,
            "precision": 0.770042194092827,
            "recall": 0.7668067226890757
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8120877297807325,
            "auditor_fn_violation": 0.013225156042603419,
            "auditor_fp_violation": 0.01907910247602437,
            "ave_precision_score": 0.8072965138508069,
            "fpr": 0.11964873765093303,
            "logloss": 1.149814706689435,
            "mae": 0.262583190224732,
            "precision": 0.7690677966101694,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6983483783551416,
            "auditor_fn_violation": 0.016408208020050136,
            "auditor_fp_violation": 0.013238371157250928,
            "ave_precision_score": 0.6975834460354655,
            "fpr": 0.043859649122807015,
            "logloss": 3.795273298807213,
            "mae": 0.42291803846306053,
            "precision": 0.7927461139896373,
            "recall": 0.32142857142857145
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7243498654719016,
            "auditor_fn_violation": 0.01665143366294798,
            "auditor_fp_violation": 0.011296370001749214,
            "ave_precision_score": 0.7242483713768174,
            "fpr": 0.043907793633369926,
            "logloss": 3.4949450862815374,
            "mae": 0.40838163138201244,
            "precision": 0.8048780487804879,
            "recall": 0.34518828451882844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7529471340676063,
            "auditor_fn_violation": 0.01844685242518061,
            "auditor_fp_violation": 0.01270018509576694,
            "ave_precision_score": 0.7521008126142583,
            "fpr": 0.06798245614035088,
            "logloss": 1.8779953647946732,
            "mae": 0.3715325334474694,
            "precision": 0.7777777777777778,
            "recall": 0.45588235294117646
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7848617614267415,
            "auditor_fn_violation": 0.022165168627054737,
            "auditor_fp_violation": 0.015377868139724131,
            "ave_precision_score": 0.7846194947221528,
            "fpr": 0.06586169045005488,
            "logloss": 1.6212849711383586,
            "mae": 0.3557544166934739,
            "precision": 0.7952218430034129,
            "recall": 0.4874476987447699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.7134057627263836,
            "auditor_fn_violation": 0.010771413828689378,
            "auditor_fp_violation": 0.006055850635763722,
            "ave_precision_score": 0.7138682432658816,
            "fpr": 0.02850877192982456,
            "logloss": 3.6921005625057264,
            "mae": 0.4223594651397541,
            "precision": 0.8497109826589595,
            "recall": 0.3088235294117647
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7279021028824846,
            "auditor_fn_violation": 0.013250416802538946,
            "auditor_fp_violation": 0.010006008168066464,
            "ave_precision_score": 0.7283902090409433,
            "fpr": 0.04610318331503842,
            "logloss": 3.4205677561889223,
            "mae": 0.4119738159116186,
            "precision": 0.7857142857142857,
            "recall": 0.32217573221757323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.8533269658898369,
            "auditor_fn_violation": 0.004901960784313725,
            "auditor_fp_violation": 0.01443545791083212,
            "ave_precision_score": 0.8531483324293281,
            "fpr": 0.4232456140350877,
            "logloss": 2.045144983663033,
            "mae": 0.42094561463205027,
            "precision": 0.5448113207547169,
            "recall": 0.9705882352941176
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.8615233073122979,
            "auditor_fn_violation": 0.0021035323728120737,
            "auditor_fp_violation": 0.012153231101522829,
            "ave_precision_score": 0.8628235477836921,
            "fpr": 0.407244785949506,
            "logloss": 1.8850598279786068,
            "mae": 0.4014175251125282,
            "precision": 0.558858501783591,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8295057494026199,
            "auditor_fn_violation": 0.011939315199764119,
            "auditor_fp_violation": 0.018657955094157415,
            "ave_precision_score": 0.8297767455201093,
            "fpr": 0.12609649122807018,
            "logloss": 0.9128740825145711,
            "mae": 0.2718425857497476,
            "precision": 0.7553191489361702,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8493061643565811,
            "auditor_fn_violation": 0.016419493958085507,
            "auditor_fp_violation": 0.018975163703566625,
            "ave_precision_score": 0.849613339116861,
            "fpr": 0.1251372118551043,
            "logloss": 0.7639113655021849,
            "mae": 0.25821695791650434,
            "precision": 0.7605042016806722,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8100166834102202,
            "auditor_fn_violation": 0.017295075925106887,
            "auditor_fp_violation": 0.023126911314984712,
            "ave_precision_score": 0.8030445661842642,
            "fpr": 0.15460526315789475,
            "logloss": 1.4005095310353413,
            "mae": 0.267124424322591,
            "precision": 0.7403314917127072,
            "recall": 0.8445378151260504
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8136362487682619,
            "auditor_fn_violation": 0.012249172136003931,
            "auditor_fp_violation": 0.022562318899364452,
            "ave_precision_score": 0.8052940228415846,
            "fpr": 0.14928649835345773,
            "logloss": 1.3020073981947664,
            "mae": 0.25961894672885805,
            "precision": 0.739961759082218,
            "recall": 0.8096234309623431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8152352436007475,
            "auditor_fn_violation": 0.010425880878667259,
            "auditor_fp_violation": 0.02054663608562691,
            "ave_precision_score": 0.8143777902340513,
            "fpr": 0.17214912280701755,
            "logloss": 0.966606772704638,
            "mae": 0.2836587708708912,
            "precision": 0.7226148409893993,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8264130105841638,
            "auditor_fn_violation": 0.012990919905019545,
            "auditor_fp_violation": 0.015461526176092564,
            "ave_precision_score": 0.8261584262271751,
            "fpr": 0.14818880351262348,
            "logloss": 0.873492492290009,
            "mae": 0.26470480501165145,
            "precision": 0.7527472527472527,
            "recall": 0.8598326359832636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.811814028728792,
            "auditor_fn_violation": 0.01543150154798762,
            "auditor_fp_violation": 0.023994547722517304,
            "ave_precision_score": 0.8110077813484775,
            "fpr": 0.13267543859649122,
            "logloss": 1.1005528280953485,
            "mae": 0.27063369779186186,
            "precision": 0.7550607287449392,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8117032005376326,
            "auditor_fn_violation": 0.013783189193906193,
            "auditor_fp_violation": 0.01577334249346581,
            "ave_precision_score": 0.8117119631832741,
            "fpr": 0.12403951701427003,
            "logloss": 1.0211944037443166,
            "mae": 0.2658560498417956,
            "precision": 0.7631027253668763,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 12092,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7427428310739517,
            "auditor_fn_violation": 0.012128206545776211,
            "auditor_fp_violation": 0.024163045227748273,
            "ave_precision_score": 0.7419202524241767,
            "fpr": 0.10964912280701754,
            "logloss": 1.9816286810863362,
            "mae": 0.3652318467288631,
            "precision": 0.7150997150997151,
            "recall": 0.5273109243697479
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7753429316841662,
            "auditor_fn_violation": 0.019064984453150476,
            "auditor_fp_violation": 0.014105251950119536,
            "ave_precision_score": 0.7751256666134216,
            "fpr": 0.09659714599341383,
            "logloss": 1.713701025451538,
            "mae": 0.35123426228936167,
            "precision": 0.7404129793510325,
            "recall": 0.5251046025104602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 12092,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7429837314275918,
            "auditor_fn_violation": 0.013756818516880445,
            "auditor_fp_violation": 0.02319732818284243,
            "ave_precision_score": 0.7421320812442764,
            "fpr": 0.10526315789473684,
            "logloss": 2.0867563950218293,
            "mae": 0.3733568670801494,
            "precision": 0.7108433734939759,
            "recall": 0.4957983193277311
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7711459747832413,
            "auditor_fn_violation": 0.012359400906631643,
            "auditor_fp_violation": 0.016026851694582255,
            "ave_precision_score": 0.7709271744289701,
            "fpr": 0.0889132821075741,
            "logloss": 1.8171999842094553,
            "mae": 0.3575574220170439,
            "precision": 0.7515337423312883,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7509919770110745,
            "auditor_fn_violation": 0.01677908005307387,
            "auditor_fp_violation": 0.024308908739739257,
            "ave_precision_score": 0.7501423275989001,
            "fpr": 0.12609649122807018,
            "logloss": 1.7670397877634993,
            "mae": 0.3582407124137336,
            "precision": 0.6973684210526315,
            "recall": 0.5567226890756303
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.785157057562124,
            "auditor_fn_violation": 0.015330984848136919,
            "auditor_fp_violation": 0.011362282394039497,
            "ave_precision_score": 0.7849055122024661,
            "fpr": 0.11086717892425905,
            "logloss": 1.5058513887022278,
            "mae": 0.34196832475745026,
            "precision": 0.7349081364829396,
            "recall": 0.5857740585774058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8013173253857434,
            "auditor_fn_violation": 0.02036340852130327,
            "auditor_fp_violation": 0.010577619507484308,
            "ave_precision_score": 0.8017164761584525,
            "fpr": 0.11513157894736842,
            "logloss": 1.102989285599328,
            "mae": 0.2979232158540851,
            "precision": 0.7546728971962616,
            "recall": 0.6785714285714286
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8036474535505844,
            "auditor_fn_violation": 0.012795723123699651,
            "auditor_fp_violation": 0.012325617358282023,
            "ave_precision_score": 0.8040715934285748,
            "fpr": 0.10537870472008781,
            "logloss": 1.0562204437330183,
            "mae": 0.2915946765431101,
            "precision": 0.7741176470588236,
            "recall": 0.6882845188284519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8004897842857175,
            "auditor_fn_violation": 0.019220846233230136,
            "auditor_fp_violation": 0.006533679381941097,
            "ave_precision_score": 0.8009410709559894,
            "fpr": 0.1118421052631579,
            "logloss": 1.1001659303643323,
            "mae": 0.3006556733703226,
            "precision": 0.7594339622641509,
            "recall": 0.6764705882352942
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8008178818702623,
            "auditor_fn_violation": 0.01565707829457721,
            "auditor_fp_violation": 0.013205294286156117,
            "ave_precision_score": 0.8011746678647133,
            "fpr": 0.10208562019758508,
            "logloss": 1.0562357436092746,
            "mae": 0.2918605805159841,
            "precision": 0.7780429594272077,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7070416136254882,
            "auditor_fn_violation": 0.01223647353678315,
            "auditor_fp_violation": 0.01903267342668598,
            "ave_precision_score": 0.7062156040948063,
            "fpr": 0.07894736842105263,
            "logloss": 2.249189284063097,
            "mae": 0.3987414629487008,
            "precision": 0.7455830388692579,
            "recall": 0.4432773109243697
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.734249540571585,
            "auditor_fn_violation": 0.016258743667586797,
            "auditor_fp_violation": 0.011382563130128809,
            "ave_precision_score": 0.7340985716155966,
            "fpr": 0.08342480790340286,
            "logloss": 1.8913110558632455,
            "mae": 0.38282078277176945,
            "precision": 0.7483443708609272,
            "recall": 0.47280334728033474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7643442174270343,
            "auditor_fn_violation": 0.010803663570691438,
            "auditor_fp_violation": 0.017906003540962504,
            "ave_precision_score": 0.7636359955755087,
            "fpr": 0.15350877192982457,
            "logloss": 1.043218869517738,
            "mae": 0.3339684839933378,
            "precision": 0.7095435684647303,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7794628370804737,
            "auditor_fn_violation": 0.015601963909263356,
            "auditor_fp_violation": 0.016650484329328738,
            "ave_precision_score": 0.7795891782891958,
            "fpr": 0.132821075740944,
            "logloss": 0.9565057264881802,
            "mae": 0.3179745658756586,
            "precision": 0.7420042643923241,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8231784572658797,
            "auditor_fn_violation": 0.016604010025062656,
            "auditor_fp_violation": 0.020508912763560278,
            "ave_precision_score": 0.8234359403085848,
            "fpr": 0.13925438596491227,
            "logloss": 1.0120135797266299,
            "mae": 0.26887530255636544,
            "precision": 0.7475149105367793,
            "recall": 0.7899159663865546
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8231963413123026,
            "auditor_fn_violation": 0.013737260539477976,
            "auditor_fp_violation": 0.015730245929276004,
            "ave_precision_score": 0.8235297113060828,
            "fpr": 0.12733260153677278,
            "logloss": 0.9598401228723107,
            "mae": 0.26336591143178106,
            "precision": 0.7622950819672131,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8117954110374518,
            "auditor_fn_violation": 0.01538312693498452,
            "auditor_fp_violation": 0.023048949782713674,
            "ave_precision_score": 0.8067029359288769,
            "fpr": 0.1524122807017544,
            "logloss": 1.197363266451916,
            "mae": 0.2801807656252023,
            "precision": 0.744954128440367,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.81077762371071,
            "auditor_fn_violation": 0.011321413316554067,
            "auditor_fp_violation": 0.016531335004804006,
            "ave_precision_score": 0.8057396538784263,
            "fpr": 0.14709110867178923,
            "logloss": 1.0985009227304856,
            "mae": 0.2731858429148019,
            "precision": 0.7462121212121212,
            "recall": 0.8242677824267782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7069787697879661,
            "auditor_fn_violation": 0.01223647353678315,
            "auditor_fp_violation": 0.01930428134556575,
            "ave_precision_score": 0.7061537318246712,
            "fpr": 0.08114035087719298,
            "logloss": 2.2393095535335727,
            "mae": 0.3983935528116989,
            "precision": 0.7403508771929824,
            "recall": 0.4432773109243697
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7342011541219595,
            "auditor_fn_violation": 0.016258743667586797,
            "auditor_fp_violation": 0.011382563130128809,
            "ave_precision_score": 0.7340503995000159,
            "fpr": 0.08342480790340286,
            "logloss": 1.881760275395106,
            "mae": 0.38216020248031457,
            "precision": 0.7483443708609272,
            "recall": 0.47280334728033474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8188743669484124,
            "auditor_fn_violation": 0.01759223426212591,
            "auditor_fp_violation": 0.025136306937067445,
            "ave_precision_score": 0.8179327747650644,
            "fpr": 0.15679824561403508,
            "logloss": 0.9736460313085491,
            "mae": 0.2700406098366269,
            "precision": 0.730188679245283,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8314259042726495,
            "auditor_fn_violation": 0.01695685921489558,
            "auditor_fp_violation": 0.02107675498082203,
            "ave_precision_score": 0.8311669737578163,
            "fpr": 0.14489571899012074,
            "logloss": 0.8353785542613706,
            "mae": 0.25970741450522966,
            "precision": 0.7416829745596869,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7006703983781474,
            "auditor_fn_violation": 0.014385688485920691,
            "auditor_fp_violation": 0.019218775148881383,
            "ave_precision_score": 0.6998541903785622,
            "fpr": 0.08552631578947369,
            "logloss": 3.9288033645255886,
            "mae": 0.4085816402915549,
            "precision": 0.7121771217712177,
            "recall": 0.4054621848739496
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7262954629023077,
            "auditor_fn_violation": 0.014733912340570157,
            "auditor_fp_violation": 0.016734142365697164,
            "ave_precision_score": 0.7261240857754006,
            "fpr": 0.08781558726673985,
            "logloss": 3.478673736154034,
            "mae": 0.39542556468936346,
            "precision": 0.7132616487455197,
            "recall": 0.41631799163179917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7056133036011186,
            "auditor_fn_violation": 0.0030591183841957837,
            "auditor_fp_violation": 0.010637976822790945,
            "ave_precision_score": 0.6844933847993172,
            "fpr": 0.4243421052631579,
            "logloss": 4.63425149818023,
            "mae": 0.4327738769526038,
            "precision": 0.5473684210526316,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7602661728061116,
            "auditor_fn_violation": 0.0012768165931042724,
            "auditor_fp_violation": 0.00842664584511096,
            "ave_precision_score": 0.7429389389654316,
            "fpr": 0.41931942919868276,
            "logloss": 4.201895438634843,
            "mae": 0.42791636323946824,
            "precision": 0.5505882352941176,
            "recall": 0.9790794979079498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.5549757667867813,
            "auditor_fn_violation": 0.004950335397316827,
            "auditor_fp_violation": 0.009667230001609527,
            "ave_precision_score": 0.551777252962717,
            "fpr": 0.18969298245614036,
            "logloss": 2.8243183312748537,
            "mae": 0.45317680405588534,
            "precision": 0.6121076233183856,
            "recall": 0.5735294117647058
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5505498737271892,
            "auditor_fn_violation": 0.009419967023226119,
            "auditor_fp_violation": 0.0073619072004218414,
            "ave_precision_score": 0.5491387407844278,
            "fpr": 0.18331503841931943,
            "logloss": 2.5941417678748424,
            "mae": 0.44828482172495515,
            "precision": 0.6152073732718893,
            "recall": 0.5585774058577406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8134869287682885,
            "auditor_fn_violation": 0.018826938670204928,
            "auditor_fp_violation": 0.019668940125543218,
            "ave_precision_score": 0.8125542173194771,
            "fpr": 0.12828947368421054,
            "logloss": 0.9788902028718823,
            "mae": 0.2714042930699056,
            "precision": 0.7552301255230126,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8384794193921468,
            "auditor_fn_violation": 0.018387536800334364,
            "auditor_fp_violation": 0.016191632675307953,
            "ave_precision_score": 0.8382013149322483,
            "fpr": 0.12294182217343579,
            "logloss": 0.7849857280330909,
            "mae": 0.25476550321570895,
            "precision": 0.7681159420289855,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6563917762547502,
            "auditor_fn_violation": 0.0017553073861123407,
            "auditor_fp_violation": 0.014676887172058593,
            "ave_precision_score": 0.6539949299372765,
            "fpr": 0.28289473684210525,
            "logloss": 1.5843297616272598,
            "mae": 0.387247247759022,
            "precision": 0.6120300751879699,
            "recall": 0.8550420168067226
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.6565295448365891,
            "auditor_fn_violation": 0.009047944922357613,
            "auditor_fp_violation": 0.013177408274033318,
            "ave_precision_score": 0.6550104732176092,
            "fpr": 0.2667398463227223,
            "logloss": 1.4017522663977644,
            "mae": 0.36363671391102986,
            "precision": 0.6345864661654136,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8182771992501783,
            "auditor_fn_violation": 0.0192530959752322,
            "auditor_fp_violation": 0.028820618058908745,
            "ave_precision_score": 0.8173207492932133,
            "fpr": 0.17763157894736842,
            "logloss": 1.0414894529101206,
            "mae": 0.2696686588477318,
            "precision": 0.7147887323943662,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8299229767289675,
            "auditor_fn_violation": 0.015409063560664868,
            "auditor_fp_violation": 0.023634662820087058,
            "ave_precision_score": 0.8297441225625678,
            "fpr": 0.16355653128430298,
            "logloss": 0.8830955897855268,
            "mae": 0.2612629032213872,
            "precision": 0.7276051188299817,
            "recall": 0.8326359832635983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7707954640428165,
            "auditor_fn_violation": 0.010819788441692471,
            "auditor_fp_violation": 0.019641276356027686,
            "ave_precision_score": 0.7691094934199653,
            "fpr": 0.15460526315789475,
            "logloss": 1.224500037735638,
            "mae": 0.2874149496144349,
            "precision": 0.724609375,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7551009033930393,
            "auditor_fn_violation": 0.0016029100395445746,
            "auditor_fp_violation": 0.027617292369626564,
            "ave_precision_score": 0.7546883391337219,
            "fpr": 0.15806805708013172,
            "logloss": 1.1237240535282993,
            "mae": 0.28415155521689117,
            "precision": 0.71875,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.835629769590187,
            "auditor_fn_violation": 0.02582282913165266,
            "auditor_fp_violation": 0.014646708514405282,
            "ave_precision_score": 0.8346685763433918,
            "fpr": 0.049342105263157895,
            "logloss": 0.9067107655567134,
            "mae": 0.30457163727123115,
            "precision": 0.8557692307692307,
            "recall": 0.5609243697478992
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8626523401042254,
            "auditor_fn_violation": 0.028767412701110107,
            "auditor_fp_violation": 0.004646823656464613,
            "ave_precision_score": 0.862439508448766,
            "fpr": 0.03293084522502744,
            "logloss": 0.7831574773585477,
            "mae": 0.292721095874943,
            "precision": 0.9022801302931596,
            "recall": 0.5794979079497908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8297369937569674,
            "auditor_fn_violation": 0.012701791242812923,
            "auditor_fp_violation": 0.020423406566875905,
            "ave_precision_score": 0.8301597273314445,
            "fpr": 0.13706140350877194,
            "logloss": 0.9940076189720614,
            "mae": 0.2708990910858161,
            "precision": 0.7474747474747475,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8334896552405836,
            "auditor_fn_violation": 0.012308879386760608,
            "auditor_fp_violation": 0.01327627686246873,
            "ave_precision_score": 0.8337843520568451,
            "fpr": 0.1207464324917673,
            "logloss": 0.9497683342759572,
            "mae": 0.2652162100514175,
            "precision": 0.7689075630252101,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8261751363797555,
            "auditor_fn_violation": 0.013643944419873214,
            "auditor_fp_violation": 0.018906929019797205,
            "ave_precision_score": 0.8264109194753659,
            "fpr": 0.13815789473684212,
            "logloss": 1.010716269342419,
            "mae": 0.2688768690073051,
            "precision": 0.7485029940119761,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8287227482889671,
            "auditor_fn_violation": 0.01108717717897019,
            "auditor_fp_violation": 0.014848033909390749,
            "ave_precision_score": 0.8291290750489735,
            "fpr": 0.12733260153677278,
            "logloss": 0.9521849380836098,
            "mae": 0.2629111198463065,
            "precision": 0.7603305785123967,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7777826076873635,
            "auditor_fn_violation": 0.01259352425180599,
            "auditor_fp_violation": 0.02674332045710607,
            "ave_precision_score": 0.7770031268439431,
            "fpr": 0.12171052631578948,
            "logloss": 1.3501496731749818,
            "mae": 0.32098730097817313,
            "precision": 0.7369668246445498,
            "recall": 0.6533613445378151
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8119259875650009,
            "auditor_fn_violation": 0.013741853404920809,
            "auditor_fp_violation": 0.022341765894393142,
            "ave_precision_score": 0.8116753232031431,
            "fpr": 0.11086717892425905,
            "logloss": 1.1679149465371625,
            "mae": 0.3074635304751085,
            "precision": 0.7554479418886199,
            "recall": 0.6527196652719666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.810928847528601,
            "auditor_fn_violation": 0.014659811292938233,
            "auditor_fp_violation": 0.012946644133268955,
            "ave_precision_score": 0.8100648399286379,
            "fpr": 0.1074561403508772,
            "logloss": 1.0814919188654333,
            "mae": 0.27478712477760264,
            "precision": 0.7802690582959642,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8151748809572076,
            "auditor_fn_violation": 0.00914898796209968,
            "auditor_fp_violation": 0.01180338840398213,
            "ave_precision_score": 0.8149347042867605,
            "fpr": 0.09769484083424808,
            "logloss": 1.0074698962191786,
            "mae": 0.26793581778802655,
            "precision": 0.7963386727688787,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8028498522289307,
            "auditor_fn_violation": 0.01689425770308123,
            "auditor_fp_violation": 0.020169402864960575,
            "ave_precision_score": 0.8032853547288497,
            "fpr": 0.15570175438596492,
            "logloss": 1.0716923209158906,
            "mae": 0.2661212078179913,
            "precision": 0.7350746268656716,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7928323332505627,
            "auditor_fn_violation": 0.01284624464357068,
            "auditor_fp_violation": 0.01963428762646941,
            "ave_precision_score": 0.794499039833288,
            "fpr": 0.1394072447859495,
            "logloss": 0.9658319629114103,
            "mae": 0.25737697533045506,
            "precision": 0.751953125,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7867544194388909,
            "auditor_fn_violation": 0.01686661506707947,
            "auditor_fp_violation": 0.02139666827619508,
            "ave_precision_score": 0.7868898915075389,
            "fpr": 0.16228070175438597,
            "logloss": 1.0378465772520344,
            "mae": 0.3121182520403859,
            "precision": 0.7148362235067437,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7953529712146166,
            "auditor_fn_violation": 0.007465702777305746,
            "auditor_fp_violation": 0.02736124807649894,
            "ave_precision_score": 0.7956943476584292,
            "fpr": 0.14818880351262348,
            "logloss": 0.9405319946135011,
            "mae": 0.3080670610546289,
            "precision": 0.725609756097561,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7402194338620186,
            "auditor_fn_violation": 0.013498820580863928,
            "auditor_fp_violation": 0.02284524384355384,
            "ave_precision_score": 0.73939803564225,
            "fpr": 0.10416666666666667,
            "logloss": 2.051560723430765,
            "mae": 0.36939290024688676,
            "precision": 0.7172619047619048,
            "recall": 0.5063025210084033
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7721074098416423,
            "auditor_fn_violation": 0.016805294655282497,
            "auditor_fp_violation": 0.015763202125421146,
            "ave_precision_score": 0.7718927277355622,
            "fpr": 0.09001097694840834,
            "logloss": 1.7770267196806295,
            "mae": 0.35488177079967514,
            "precision": 0.7492354740061162,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8273648136365068,
            "auditor_fn_violation": 0.009753243402624217,
            "auditor_fp_violation": 0.012250020119105106,
            "ave_precision_score": 0.8277914034109326,
            "fpr": 0.09100877192982457,
            "logloss": 0.8499547373594802,
            "mae": 0.28371118152896063,
            "precision": 0.8004807692307693,
            "recall": 0.6995798319327731
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8301144002870742,
            "auditor_fn_violation": 0.010186975552177248,
            "auditor_fp_violation": 0.01101497478850995,
            "ave_precision_score": 0.8304718272482237,
            "fpr": 0.08122941822173436,
            "logloss": 0.8007391862339859,
            "mae": 0.27889223999323737,
            "precision": 0.821256038647343,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 12092,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8066285116550028,
            "auditor_fn_violation": 0.017958499189149348,
            "auditor_fp_violation": 0.01894716723000162,
            "ave_precision_score": 0.8041448775830975,
            "fpr": 0.1206140350877193,
            "logloss": 1.2931078796572182,
            "mae": 0.27511507992128026,
            "precision": 0.7619047619047619,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8000103258989375,
            "auditor_fn_violation": 0.009454413514047282,
            "auditor_fp_violation": 0.01720566947977377,
            "ave_precision_score": 0.7969166780039931,
            "fpr": 0.1163556531284303,
            "logloss": 1.232762686589282,
            "mae": 0.26949209700848814,
            "precision": 0.7710583153347732,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.740624379388193,
            "auditor_fn_violation": 0.00604452307238685,
            "auditor_fp_violation": 0.01899243521648157,
            "ave_precision_score": 0.7410280174874526,
            "fpr": 0.19517543859649122,
            "logloss": 1.0842879566845407,
            "mae": 0.35418693399096657,
            "precision": 0.6622390891840607,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7390231036318673,
            "auditor_fn_violation": 0.008055885986708247,
            "auditor_fp_violation": 0.020947465288252635,
            "ave_precision_score": 0.7394862158563538,
            "fpr": 0.2074643249176729,
            "logloss": 1.0563403255112114,
            "mae": 0.3523534821109811,
            "precision": 0.653211009174312,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7465120934445674,
            "auditor_fn_violation": 0.015530554326993956,
            "auditor_fp_violation": 0.016925197167230004,
            "ave_precision_score": 0.7457216522843991,
            "fpr": 0.08114035087719298,
            "logloss": 1.862484682577923,
            "mae": 0.3676064236358764,
            "precision": 0.7597402597402597,
            "recall": 0.49159663865546216
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7798913369718747,
            "auditor_fn_violation": 0.016065843318988287,
            "auditor_fp_violation": 0.011217782149403114,
            "ave_precision_score": 0.7797498306181849,
            "fpr": 0.06805708013172337,
            "logloss": 1.6230911842856128,
            "mae": 0.3519988771882297,
            "precision": 0.7987012987012987,
            "recall": 0.5146443514644351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7252185118922682,
            "auditor_fn_violation": 0.015956711632021222,
            "auditor_fp_violation": 0.021628037984870434,
            "ave_precision_score": 0.724401473422662,
            "fpr": 0.12390350877192982,
            "logloss": 1.575053074339658,
            "mae": 0.37684092140710296,
            "precision": 0.7026315789473684,
            "recall": 0.5609243697478992
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.760880836864868,
            "auditor_fn_violation": 0.01287380183622761,
            "auditor_fp_violation": 0.013555136983696823,
            "ave_precision_score": 0.760689413279314,
            "fpr": 0.1119648737650933,
            "logloss": 1.3014460346548968,
            "mae": 0.35464223435511827,
            "precision": 0.7350649350649351,
            "recall": 0.5920502092050209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8212605863229876,
            "auditor_fn_violation": 0.016963364293085658,
            "auditor_fp_violation": 0.03453444390793498,
            "ave_precision_score": 0.8203938943324847,
            "fpr": 0.2236842105263158,
            "logloss": 0.9825016983151172,
            "mae": 0.2918828272205161,
            "precision": 0.6792452830188679,
            "recall": 0.907563025210084
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8541716326628468,
            "auditor_fn_violation": 0.010719747943544498,
            "auditor_fp_violation": 0.02584526305382254,
            "ave_precision_score": 0.8539813485341082,
            "fpr": 0.20965971459934138,
            "logloss": 0.8248345841071465,
            "mae": 0.2750804301643869,
            "precision": 0.6953748006379585,
            "recall": 0.9121338912133892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8322735824728857,
            "auditor_fn_violation": 0.01174812030075188,
            "auditor_fp_violation": 0.023956824400450674,
            "ave_precision_score": 0.8325976273652028,
            "fpr": 0.15460526315789475,
            "logloss": 1.0383310470912228,
            "mae": 0.2740691389055373,
            "precision": 0.7267441860465116,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8343180375672735,
            "auditor_fn_violation": 0.011413270625410489,
            "auditor_fp_violation": 0.026679308325495674,
            "ave_precision_score": 0.8349173062961518,
            "fpr": 0.13830954994511527,
            "logloss": 0.895690011642143,
            "mae": 0.2699396192628728,
            "precision": 0.7459677419354839,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8368320056800067,
            "auditor_fn_violation": 0.026034756007666228,
            "auditor_fp_violation": 0.014194028649605669,
            "ave_precision_score": 0.8358833930224076,
            "fpr": 0.049342105263157895,
            "logloss": 0.8882016135547893,
            "mae": 0.29876409094257533,
            "precision": 0.8611111111111112,
            "recall": 0.5861344537815126
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8719439250521537,
            "auditor_fn_violation": 0.028271383233285423,
            "auditor_fp_violation": 0.0041651561743433485,
            "ave_precision_score": 0.8716144562715621,
            "fpr": 0.036223929747530186,
            "logloss": 0.7673667518365019,
            "mae": 0.2857868693302873,
            "precision": 0.8949044585987261,
            "recall": 0.5878661087866108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7474359661621912,
            "auditor_fn_violation": 0.012045278637770905,
            "auditor_fp_violation": 0.02027502816674714,
            "ave_precision_score": 0.7465958454736958,
            "fpr": 0.09978070175438597,
            "logloss": 1.8965486150320636,
            "mae": 0.36411047458352885,
            "precision": 0.7291666666666666,
            "recall": 0.5147058823529411
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7763453762679531,
            "auditor_fn_violation": 0.017930546688773665,
            "auditor_fp_violation": 0.0142649627468229,
            "ave_precision_score": 0.7761306278488905,
            "fpr": 0.08781558726673985,
            "logloss": 1.6308895193884103,
            "mae": 0.35092182668277117,
            "precision": 0.7538461538461538,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7433909945173427,
            "auditor_fn_violation": 0.007495761462479729,
            "auditor_fp_violation": 0.02657733784001288,
            "ave_precision_score": 0.7438332787601428,
            "fpr": 0.18859649122807018,
            "logloss": 1.2686148956997987,
            "mae": 0.3019432009950681,
            "precision": 0.6917562724014337,
            "recall": 0.8109243697478992
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7110774106881343,
            "auditor_fn_violation": 0.005474695607842782,
            "auditor_fp_violation": 0.024501664287905334,
            "ave_precision_score": 0.7116690133997207,
            "fpr": 0.1964873765093304,
            "logloss": 1.2131473308625604,
            "mae": 0.3013471945245668,
            "precision": 0.6843033509700176,
            "recall": 0.8117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6627790834037075,
            "auditor_fn_violation": 0.0030591183841957837,
            "auditor_fp_violation": 0.010637976822790945,
            "ave_precision_score": 0.6503027016881917,
            "fpr": 0.4243421052631579,
            "logloss": 4.396273346324906,
            "mae": 0.4333062451853613,
            "precision": 0.5473684210526316,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7164397333448405,
            "auditor_fn_violation": 0.000964501742992436,
            "auditor_fp_violation": 0.008710576150361376,
            "ave_precision_score": 0.7044643402850759,
            "fpr": 0.4138309549945115,
            "logloss": 4.000807448779959,
            "mae": 0.4256691759601481,
            "precision": 0.5533175355450237,
            "recall": 0.9769874476987448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7430427491100078,
            "auditor_fn_violation": 0.013885817484888702,
            "auditor_fp_violation": 0.01365081281184613,
            "ave_precision_score": 0.742232674306166,
            "fpr": 0.0712719298245614,
            "logloss": 1.9735284542784883,
            "mae": 0.37973005802061705,
            "precision": 0.7653429602888087,
            "recall": 0.44537815126050423
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7640971974774883,
            "auditor_fn_violation": 0.016203629282272917,
            "auditor_fp_violation": 0.01902840063580108,
            "ave_precision_score": 0.7639192282007266,
            "fpr": 0.07025246981339188,
            "logloss": 1.7360159415512648,
            "mae": 0.3695016901128843,
            "precision": 0.7777777777777778,
            "recall": 0.4686192468619247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.764365852819331,
            "auditor_fn_violation": 0.015555893409995579,
            "auditor_fp_violation": 0.022156164493803313,
            "ave_precision_score": 0.7644104705521033,
            "fpr": 0.19078947368421054,
            "logloss": 1.275264854582905,
            "mae": 0.2885268854312844,
            "precision": 0.6984402079722704,
            "recall": 0.8466386554621849
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7408154878972463,
            "auditor_fn_violation": 0.007794092656467449,
            "auditor_fp_violation": 0.021931080988584484,
            "ave_precision_score": 0.740534867096993,
            "fpr": 0.18880351262349068,
            "logloss": 1.279054664781499,
            "mae": 0.28228024392378614,
            "precision": 0.6993006993006993,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8265896553155574,
            "auditor_fn_violation": 0.015572018280996617,
            "auditor_fp_violation": 0.015159745694511508,
            "ave_precision_score": 0.8256422794627174,
            "fpr": 0.10964912280701754,
            "logloss": 0.8892572121045063,
            "mae": 0.27163844827749634,
            "precision": 0.7787610619469026,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8387895393670223,
            "auditor_fn_violation": 0.015002594968975201,
            "auditor_fp_violation": 0.01885347928703072,
            "ave_precision_score": 0.8385435790707152,
            "fpr": 0.09769484083424808,
            "logloss": 0.7767316247086232,
            "mae": 0.263684493148236,
            "precision": 0.7986425339366516,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7774971592461537,
            "auditor_fn_violation": 0.0073897980244729475,
            "auditor_fp_violation": 0.024444712699179146,
            "ave_precision_score": 0.7775403047629335,
            "fpr": 0.13486842105263158,
            "logloss": 1.442601240230973,
            "mae": 0.32883815364912045,
            "precision": 0.7159353348729792,
            "recall": 0.6512605042016807
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8200980990093334,
            "auditor_fn_violation": 0.015326391982694091,
            "auditor_fp_violation": 0.01903347081982341,
            "ave_precision_score": 0.8203387312890827,
            "fpr": 0.1251372118551043,
            "logloss": 1.2251105870239303,
            "mae": 0.3126151250698368,
            "precision": 0.7397260273972602,
            "recall": 0.6778242677824268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7919997467092883,
            "auditor_fn_violation": 0.01813356921716055,
            "auditor_fp_violation": 0.019226319813294705,
            "ave_precision_score": 0.7911071933681424,
            "fpr": 0.14583333333333334,
            "logloss": 1.144927618478716,
            "mae": 0.28986440871266594,
            "precision": 0.7313131313131314,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7964132973842487,
            "auditor_fn_violation": 0.016692769451933372,
            "auditor_fp_violation": 0.021702922707579675,
            "ave_precision_score": 0.796347912266371,
            "fpr": 0.13391877058177826,
            "logloss": 1.048212719832812,
            "mae": 0.28457249098715487,
            "precision": 0.7453027139874739,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8121191403146687,
            "auditor_fn_violation": 0.011351909184726523,
            "auditor_fp_violation": 0.01982737807822308,
            "ave_precision_score": 0.8112208066820566,
            "fpr": 0.13157894736842105,
            "logloss": 1.0711306997145003,
            "mae": 0.2725391037818231,
            "precision": 0.7520661157024794,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8162226607167318,
            "auditor_fn_violation": 0.010421211689761125,
            "auditor_fp_violation": 0.016059807890727397,
            "ave_precision_score": 0.8160713965196227,
            "fpr": 0.11855104281009879,
            "logloss": 0.9932141248912745,
            "mae": 0.2688482343200876,
            "precision": 0.7711864406779662,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7993024234109698,
            "auditor_fn_violation": 0.016963364293085655,
            "auditor_fp_violation": 0.02349408498309996,
            "ave_precision_score": 0.7997178989576381,
            "fpr": 0.1524122807017544,
            "logloss": 1.1026956636599299,
            "mae": 0.28974275257087506,
            "precision": 0.7236580516898609,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8001902130805694,
            "auditor_fn_violation": 0.01393475375351929,
            "auditor_fp_violation": 0.01849856640546769,
            "ave_precision_score": 0.800804063213634,
            "fpr": 0.13611416026344675,
            "logloss": 1.041961509581788,
            "mae": 0.2860451939295985,
            "precision": 0.7432712215320911,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7560489922566267,
            "auditor_fn_violation": 0.017253611971104227,
            "auditor_fp_violation": 0.02600394334460003,
            "ave_precision_score": 0.7544373832124202,
            "fpr": 0.18201754385964913,
            "logloss": 1.5352727632081846,
            "mae": 0.3056115101685258,
            "precision": 0.6948529411764706,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7477820228385554,
            "auditor_fn_violation": 0.011360452672818046,
            "auditor_fp_violation": 0.02485150698544604,
            "ave_precision_score": 0.746254245938794,
            "fpr": 0.18111964873765093,
            "logloss": 1.434311833264191,
            "mae": 0.3061769827806048,
            "precision": 0.6921641791044776,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7033782830313255,
            "auditor_fn_violation": 0.003671863482235004,
            "auditor_fp_violation": 0.01205637373249638,
            "ave_precision_score": 0.7025842485218554,
            "fpr": 0.0537280701754386,
            "logloss": 3.4201857080683284,
            "mae": 0.4176737557789782,
            "precision": 0.7632850241545893,
            "recall": 0.3319327731092437
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7195485669717545,
            "auditor_fn_violation": 0.01029720432280496,
            "auditor_fp_violation": 0.01003389418018927,
            "ave_precision_score": 0.7194833685594978,
            "fpr": 0.05378704720087816,
            "logloss": 3.1395292922747786,
            "mae": 0.4044008856298168,
            "precision": 0.7860262008733624,
            "recall": 0.37656903765690375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8100253456933592,
            "auditor_fn_violation": 0.012349347633790359,
            "auditor_fp_violation": 0.02508349428617416,
            "ave_precision_score": 0.8093125650785314,
            "fpr": 0.16885964912280702,
            "logloss": 1.0792270197806921,
            "mae": 0.27310822750352,
            "precision": 0.716390423572744,
            "recall": 0.8172268907563025
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8091386260388437,
            "auditor_fn_violation": 0.006802033720818088,
            "auditor_fp_violation": 0.022113607613388334,
            "ave_precision_score": 0.8090591031613086,
            "fpr": 0.16575192096597147,
            "logloss": 0.9776459466273297,
            "mae": 0.2743630820741617,
            "precision": 0.7156308851224106,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8325045933018383,
            "auditor_fn_violation": 0.02638028895768834,
            "auditor_fp_violation": 0.04176474730403991,
            "ave_precision_score": 0.8332019069274863,
            "fpr": 0.1962719298245614,
            "logloss": 0.5891528336830684,
            "mae": 0.3145332893899442,
            "precision": 0.6966101694915254,
            "recall": 0.8634453781512605
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8817794941818115,
            "auditor_fn_violation": 0.0219171538931424,
            "auditor_fp_violation": 0.0314250005703957,
            "ave_precision_score": 0.8819524842144799,
            "fpr": 0.17233809001097694,
            "logloss": 0.5087163358840314,
            "mae": 0.2916914435398983,
            "precision": 0.7255244755244755,
            "recall": 0.8682008368200836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7551645028268263,
            "auditor_fn_violation": 0.014217529116909931,
            "auditor_fp_violation": 0.019334460003219058,
            "ave_precision_score": 0.7556000923409405,
            "fpr": 0.18201754385964913,
            "logloss": 0.9829306024450525,
            "mae": 0.3449775988174262,
            "precision": 0.675146771037182,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7607667456964436,
            "auditor_fn_violation": 0.010003260934464407,
            "auditor_fp_violation": 0.023563680243774452,
            "ave_precision_score": 0.7611575417671166,
            "fpr": 0.1964873765093304,
            "logloss": 0.9347220290461319,
            "mae": 0.34481174970301876,
            "precision": 0.6641651031894934,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7263545277770833,
            "auditor_fn_violation": 0.011126160990712078,
            "auditor_fp_violation": 0.02760089731208756,
            "ave_precision_score": 0.6902542645305251,
            "fpr": 0.24451754385964913,
            "logloss": 3.4615541499476645,
            "mae": 0.31878331920311803,
            "precision": 0.6454689984101749,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.726895602546004,
            "auditor_fn_violation": 0.006498904601591891,
            "auditor_fp_violation": 0.04094427107231857,
            "ave_precision_score": 0.6852150526226113,
            "fpr": 0.21514818880351264,
            "logloss": 3.5372500067766905,
            "mae": 0.3039713819308447,
            "precision": 0.6754966887417219,
            "recall": 0.8535564853556485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7651152658790319,
            "auditor_fn_violation": 0.00940310334660181,
            "auditor_fp_violation": 0.015531949138902303,
            "ave_precision_score": 0.7642829748467675,
            "fpr": 0.08333333333333333,
            "logloss": 1.6783602500052146,
            "mae": 0.35349122068635347,
            "precision": 0.7647058823529411,
            "recall": 0.5189075630252101
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7989657757814714,
            "auditor_fn_violation": 0.020433658355111177,
            "auditor_fp_violation": 0.015712500285197856,
            "ave_precision_score": 0.7987008126889776,
            "fpr": 0.07244785949506037,
            "logloss": 1.4430334075084257,
            "mae": 0.33629811905836904,
            "precision": 0.7917981072555205,
            "recall": 0.5251046025104602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8400107940309345,
            "auditor_fn_violation": 0.011139982308712966,
            "auditor_fp_violation": 0.011915539996780945,
            "ave_precision_score": 0.8404648259719131,
            "fpr": 0.11074561403508772,
            "logloss": 0.9868961431591112,
            "mae": 0.275930461304556,
            "precision": 0.7770419426048565,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8416438773643844,
            "auditor_fn_violation": 0.011737067639129373,
            "auditor_fp_violation": 0.015603491328717781,
            "ave_precision_score": 0.8419557850772597,
            "fpr": 0.10537870472008781,
            "logloss": 0.8853005506829266,
            "mae": 0.275322635667534,
            "precision": 0.785234899328859,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.721686313014475,
            "auditor_fn_violation": 0.00404734262125903,
            "auditor_fp_violation": 0.021074762594559798,
            "ave_precision_score": 0.7024167267634778,
            "fpr": 0.39473684210526316,
            "logloss": 3.856163080352692,
            "mae": 0.4059140027226229,
            "precision": 0.5625759416767923,
            "recall": 0.9726890756302521
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7066121256617335,
            "auditor_fn_violation": 0.0004822508714962178,
            "auditor_fp_violation": 0.014680717836653883,
            "ave_precision_score": 0.687150100373122,
            "fpr": 0.3929747530186608,
            "logloss": 3.8824242038913233,
            "mae": 0.39374672511232406,
            "precision": 0.5686746987951807,
            "recall": 0.9874476987447699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8117489188248679,
            "auditor_fn_violation": 0.017530038331121923,
            "auditor_fp_violation": 0.022867877836793827,
            "ave_precision_score": 0.8110679311476849,
            "fpr": 0.14583333333333334,
            "logloss": 1.0798944330708087,
            "mae": 0.26825870793534323,
            "precision": 0.7392156862745098,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8157799818195225,
            "auditor_fn_violation": 0.012529336928016024,
            "auditor_fp_violation": 0.01862785609803708,
            "ave_precision_score": 0.8156858872690023,
            "fpr": 0.13172338090010977,
            "logloss": 0.9968350749043235,
            "mae": 0.263616948480265,
            "precision": 0.7565922920892495,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8107832144358469,
            "auditor_fn_violation": 0.017092363261093913,
            "auditor_fp_violation": 0.012856108160309031,
            "ave_precision_score": 0.8099037090230689,
            "fpr": 0.09649122807017543,
            "logloss": 0.9580665212480047,
            "mae": 0.2838285036063083,
            "precision": 0.7843137254901961,
            "recall": 0.6722689075630253
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8208922000168095,
            "auditor_fn_violation": 0.01207923611461955,
            "auditor_fp_violation": 0.012875732324704726,
            "ave_precision_score": 0.8206943912051696,
            "fpr": 0.08562019758507135,
            "logloss": 0.8540457536937444,
            "mae": 0.27401536655172365,
            "precision": 0.8078817733990148,
            "recall": 0.6861924686192469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8078466180076004,
            "auditor_fn_violation": 0.013236215538847117,
            "auditor_fp_violation": 0.026403810558506362,
            "ave_precision_score": 0.8070845575865035,
            "fpr": 0.1524122807017544,
            "logloss": 1.0521519991869284,
            "mae": 0.27352910619417364,
            "precision": 0.7332053742802304,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.811001236629512,
            "auditor_fn_violation": 0.012047086056519806,
            "auditor_fp_violation": 0.02468419091270918,
            "ave_precision_score": 0.8108507234645057,
            "fpr": 0.14709110867178923,
            "logloss": 0.9384521581355553,
            "mae": 0.2712164771590576,
            "precision": 0.7341269841269841,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8160501960128802,
            "auditor_fn_violation": 0.015908337019018136,
            "auditor_fp_violation": 0.027236238532110095,
            "ave_precision_score": 0.8151362724326141,
            "fpr": 0.17324561403508773,
            "logloss": 1.0457768879542613,
            "mae": 0.2707762748965608,
            "precision": 0.7178571428571429,
            "recall": 0.8445378151260504
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8224216439454064,
            "auditor_fn_violation": 0.011362749105539456,
            "auditor_fp_violation": 0.022392467734616433,
            "ave_precision_score": 0.8223154589454306,
            "fpr": 0.1668496158068057,
            "logloss": 0.9015870262598433,
            "mae": 0.26381085355874645,
            "precision": 0.7226277372262774,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8303128232452899,
            "auditor_fn_violation": 0.01390885301489017,
            "auditor_fp_violation": 0.02188204168678577,
            "ave_precision_score": 0.8293557378753589,
            "fpr": 0.15021929824561403,
            "logloss": 0.7992173497011409,
            "mae": 0.2803810824664069,
            "precision": 0.7419962335216572,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.841618594883561,
            "auditor_fn_violation": 0.016401122496314226,
            "auditor_fp_violation": 0.017933240886978,
            "ave_precision_score": 0.8413961062243567,
            "fpr": 0.12843029637760703,
            "logloss": 0.7084224809882937,
            "mae": 0.2637996479904976,
            "precision": 0.7692307692307693,
            "recall": 0.8158995815899581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7391584358139511,
            "auditor_fn_violation": 0.011278195488721809,
            "auditor_fp_violation": 0.014694491389023016,
            "ave_precision_score": 0.7383450670273808,
            "fpr": 0.0668859649122807,
            "logloss": 2.0628165817039745,
            "mae": 0.3842350076021296,
            "precision": 0.769811320754717,
            "recall": 0.42857142857142855
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7585922079603586,
            "auditor_fn_violation": 0.01631845091834344,
            "auditor_fp_violation": 0.018331250332730826,
            "ave_precision_score": 0.7584269171595133,
            "fpr": 0.06915477497255763,
            "logloss": 1.8153450102265971,
            "mae": 0.37468750120138306,
            "precision": 0.7758007117437722,
            "recall": 0.4560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8244873185417525,
            "auditor_fn_violation": 0.0172858617131063,
            "auditor_fp_violation": 0.013137775631739904,
            "ave_precision_score": 0.8248312120082775,
            "fpr": 0.09868421052631579,
            "logloss": 0.9532941012310865,
            "mae": 0.2825061039011693,
            "precision": 0.782608695652174,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8230254197900005,
            "auditor_fn_violation": 0.012033307460191343,
            "auditor_fp_violation": 0.017251301135974735,
            "ave_precision_score": 0.8243489476389875,
            "fpr": 0.0889132821075741,
            "logloss": 0.8761536786011125,
            "mae": 0.27478186480198813,
            "precision": 0.8057553956834532,
            "recall": 0.702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7863740962959428,
            "auditor_fn_violation": 0.015016862007961082,
            "auditor_fp_violation": 0.01132705617254145,
            "ave_precision_score": 0.7647679308375794,
            "fpr": 0.10964912280701754,
            "logloss": 2.6830802902504867,
            "mae": 0.2803243352575041,
            "precision": 0.7762863534675615,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7986061687368915,
            "auditor_fn_violation": 0.018295679491477937,
            "auditor_fp_violation": 0.009100980320080719,
            "ave_precision_score": 0.778334067754207,
            "fpr": 0.1119648737650933,
            "logloss": 2.3364749638182345,
            "mae": 0.2720268361419907,
            "precision": 0.7758241758241758,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7798279578413362,
            "auditor_fn_violation": 0.010815181335692172,
            "auditor_fp_violation": 0.018585023338161925,
            "ave_precision_score": 0.7784643464116627,
            "fpr": 0.1524122807017544,
            "logloss": 1.1469493715169155,
            "mae": 0.2849672164586963,
            "precision": 0.7295719844357976,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7661507060413731,
            "auditor_fn_violation": 0.005157787892288117,
            "auditor_fp_violation": 0.02689986133046699,
            "ave_precision_score": 0.7656821727625759,
            "fpr": 0.150384193194292,
            "logloss": 1.0490051928028854,
            "mae": 0.28187085700922426,
            "precision": 0.7281746031746031,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 12092,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7636842360597563,
            "auditor_fn_violation": 0.022478070175438597,
            "auditor_fp_violation": 0.023838624657975215,
            "ave_precision_score": 0.7436991548100442,
            "fpr": 0.16337719298245615,
            "logloss": 2.3288149254173547,
            "mae": 0.3199907929138888,
            "precision": 0.7055335968379447,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7653430410589499,
            "auditor_fn_violation": 0.009426856321390361,
            "auditor_fp_violation": 0.024892068457624667,
            "ave_precision_score": 0.744387990492769,
            "fpr": 0.16465422612513722,
            "logloss": 2.168610642395721,
            "mae": 0.3136180735302604,
            "precision": 0.7029702970297029,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8233291129440112,
            "auditor_fn_violation": 0.014284332153914201,
            "auditor_fp_violation": 0.01880130371801063,
            "ave_precision_score": 0.8223752552234613,
            "fpr": 0.13157894736842105,
            "logloss": 0.8184117103530456,
            "mae": 0.2672945683175396,
            "precision": 0.7585513078470825,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.838980928217863,
            "auditor_fn_violation": 0.012194057750690082,
            "auditor_fp_violation": 0.010911036016052205,
            "ave_precision_score": 0.8387788727095244,
            "fpr": 0.11745334796926454,
            "logloss": 0.695548339450513,
            "mae": 0.2582189119093186,
            "precision": 0.7793814432989691,
            "recall": 0.7907949790794979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8216023354372417,
            "auditor_fn_violation": 0.01356332006486805,
            "auditor_fp_violation": 0.01477748269756961,
            "ave_precision_score": 0.8219523549118666,
            "fpr": 0.11074561403508772,
            "logloss": 0.9679128520568174,
            "mae": 0.27768767259839044,
            "precision": 0.7750556792873051,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8180335113685991,
            "auditor_fn_violation": 0.014515751232036156,
            "auditor_fp_violation": 0.012847846312581918,
            "ave_precision_score": 0.8193815664713129,
            "fpr": 0.1119648737650933,
            "logloss": 0.8850103002946629,
            "mae": 0.27125746849125265,
            "precision": 0.7748344370860927,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.8220673223590971,
            "auditor_fn_violation": 0.004597891788294266,
            "auditor_fp_violation": 0.01651778528891035,
            "ave_precision_score": 0.820740980623145,
            "fpr": 0.42105263157894735,
            "logloss": 3.2020986956737945,
            "mae": 0.4257268715059023,
            "precision": 0.5477031802120141,
            "recall": 0.976890756302521
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.8375126644461894,
            "auditor_fn_violation": 0.0016924709156795833,
            "auditor_fp_violation": 0.010786816507505147,
            "ave_precision_score": 0.8373208757301969,
            "fpr": 0.40285400658616904,
            "logloss": 2.994636971202175,
            "mae": 0.4065991422859785,
            "precision": 0.5630952380952381,
            "recall": 0.9895397489539749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7352971307794686,
            "auditor_fn_violation": 0.011766548724753068,
            "auditor_fp_violation": 0.01926404313536134,
            "ave_precision_score": 0.7344631506423458,
            "fpr": 0.10087719298245613,
            "logloss": 2.337114339245649,
            "mae": 0.38061937067007434,
            "precision": 0.7125,
            "recall": 0.4789915966386555
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7625157751755967,
            "auditor_fn_violation": 0.012262950732332396,
            "auditor_fp_violation": 0.017286792424131038,
            "ave_precision_score": 0.7623066360080881,
            "fpr": 0.08562019758507135,
            "logloss": 2.054792020705757,
            "mae": 0.3654413385112173,
            "precision": 0.7531645569620253,
            "recall": 0.497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8297869561913577,
            "auditor_fn_violation": 0.011697442134748643,
            "auditor_fp_violation": 0.018454249154997594,
            "ave_precision_score": 0.8287968314132044,
            "fpr": 0.12390350877192982,
            "logloss": 0.8646986707492317,
            "mae": 0.2780003068138029,
            "precision": 0.7575107296137339,
            "recall": 0.7415966386554622
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8457313906439605,
            "auditor_fn_violation": 0.008841265977430663,
            "auditor_fp_violation": 0.018310969596641514,
            "ave_precision_score": 0.8454370533749624,
            "fpr": 0.11525795828759605,
            "logloss": 0.8243700100030241,
            "mae": 0.2717931295211765,
            "precision": 0.7732181425485961,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8057414411068577,
            "auditor_fn_violation": 0.014632168656936461,
            "auditor_fp_violation": 0.016952860936745535,
            "ave_precision_score": 0.8025047210180535,
            "fpr": 0.11293859649122807,
            "logloss": 0.7652087305204504,
            "mae": 0.3105579303507846,
            "precision": 0.7822410147991543,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.820068290078694,
            "auditor_fn_violation": 0.012182575587083033,
            "auditor_fp_violation": 0.003201821210100822,
            "ave_precision_score": 0.82127382283695,
            "fpr": 0.09989023051591657,
            "logloss": 0.7157837332968814,
            "mae": 0.29281949512629835,
            "precision": 0.8063829787234043,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8029461050876889,
            "auditor_fn_violation": 0.00938928202860092,
            "auditor_fp_violation": 0.019291706904876877,
            "ave_precision_score": 0.7984349853617377,
            "fpr": 0.13048245614035087,
            "logloss": 1.4535682115526385,
            "mae": 0.2737803230716598,
            "precision": 0.7525987525987526,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7971230822097108,
            "auditor_fn_violation": 0.005963835777503227,
            "auditor_fp_violation": 0.01694709009463499,
            "ave_precision_score": 0.7919156770714233,
            "fpr": 0.13062568605927552,
            "logloss": 1.3910423643619183,
            "mae": 0.26880169335037446,
            "precision": 0.7551440329218106,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7430414704797214,
            "auditor_fn_violation": 0.016410511573050283,
            "auditor_fp_violation": 0.023690246257846454,
            "ave_precision_score": 0.7421902019979884,
            "fpr": 0.1074561403508772,
            "logloss": 2.0705786413302603,
            "mae": 0.3725065908110075,
            "precision": 0.7100591715976331,
            "recall": 0.5042016806722689
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7712489163472878,
            "auditor_fn_violation": 0.01292432335609864,
            "auditor_fp_violation": 0.010733579575270685,
            "ave_precision_score": 0.7710314061168266,
            "fpr": 0.09549945115257959,
            "logloss": 1.8007276339402627,
            "mae": 0.35671414264768525,
            "precision": 0.7418397626112759,
            "recall": 0.5230125523012552
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7542388674194237,
            "auditor_fn_violation": 0.00899307091257556,
            "auditor_fp_violation": 0.020214670851440523,
            "ave_precision_score": 0.7546820608063597,
            "fpr": 0.18640350877192982,
            "logloss": 0.9982210599502556,
            "mae": 0.3436806979728513,
            "precision": 0.6718146718146718,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.761900863030627,
            "auditor_fn_violation": 0.009410781292340478,
            "auditor_fp_violation": 0.022159239269589293,
            "ave_precision_score": 0.7622872726287186,
            "fpr": 0.1964873765093304,
            "logloss": 0.9427735733975974,
            "mae": 0.3447527231047228,
            "precision": 0.6654205607476635,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.762655193255547,
            "auditor_fn_violation": 0.00979470735662686,
            "auditor_fp_violation": 0.012664976661838082,
            "ave_precision_score": 0.7631650345082082,
            "fpr": 0.0756578947368421,
            "logloss": 1.5111328118625051,
            "mae": 0.3674092869666857,
            "precision": 0.770764119601329,
            "recall": 0.48739495798319327
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.790284800824113,
            "auditor_fn_violation": 0.01624496507125831,
            "auditor_fp_violation": 0.01446016483168257,
            "ave_precision_score": 0.7905745429930702,
            "fpr": 0.06915477497255763,
            "logloss": 1.3028130316741238,
            "mae": 0.3534214565297302,
            "precision": 0.7920792079207921,
            "recall": 0.502092050209205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8127355163074286,
            "auditor_fn_violation": 0.011674406604747164,
            "auditor_fp_violation": 0.02460566553999679,
            "ave_precision_score": 0.8118899712833951,
            "fpr": 0.19298245614035087,
            "logloss": 1.0391457240492439,
            "mae": 0.27833064276990116,
            "precision": 0.697594501718213,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.815041192800853,
            "auditor_fn_violation": 0.005605592272963187,
            "auditor_fp_violation": 0.020128630568646493,
            "ave_precision_score": 0.8149070564925851,
            "fpr": 0.1756311745334797,
            "logloss": 0.9182197349605874,
            "mae": 0.26816114628104293,
            "precision": 0.7168141592920354,
            "recall": 0.8472803347280334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7645168657335326,
            "auditor_fn_violation": 0.004095717234262127,
            "auditor_fp_violation": 0.026149806856591025,
            "ave_precision_score": 0.7637006767881616,
            "fpr": 0.1524122807017544,
            "logloss": 1.5100977601230345,
            "mae": 0.32940639153871726,
            "precision": 0.6984815618221258,
            "recall": 0.6764705882352942
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8029567438271331,
            "auditor_fn_violation": 0.01943011725585476,
            "auditor_fp_violation": 0.01577080740145465,
            "ave_precision_score": 0.8026936785156722,
            "fpr": 0.1394072447859495,
            "logloss": 1.2794679319504827,
            "mae": 0.3161828847087933,
            "precision": 0.7239130434782609,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7569660048610011,
            "auditor_fn_violation": 0.015240306648975382,
            "auditor_fp_violation": 0.012498994044744891,
            "ave_precision_score": 0.7561041552140458,
            "fpr": 0.05921052631578947,
            "logloss": 1.9093311755344806,
            "mae": 0.3683599957934616,
            "precision": 0.8021978021978022,
            "recall": 0.46008403361344535
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7817357570077489,
            "auditor_fn_violation": 0.01701656646565227,
            "auditor_fp_violation": 0.014804937345200947,
            "ave_precision_score": 0.7814939563329965,
            "fpr": 0.06256860592755215,
            "logloss": 1.6430018750344668,
            "mae": 0.35814074830863724,
            "precision": 0.7985865724381626,
            "recall": 0.47280334728033474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8299684746654485,
            "auditor_fn_violation": 0.01932680967123692,
            "auditor_fp_violation": 0.014304683727667796,
            "ave_precision_score": 0.8303510904464091,
            "fpr": 0.11842105263157894,
            "logloss": 1.0022281934093475,
            "mae": 0.27334840458862697,
            "precision": 0.7682403433476395,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8398466510820081,
            "auditor_fn_violation": 0.015914278759375188,
            "auditor_fp_violation": 0.020780149215515777,
            "ave_precision_score": 0.8405936034568838,
            "fpr": 0.1119648737650933,
            "logloss": 0.8877198270347765,
            "mae": 0.2655269229744037,
            "precision": 0.7777777777777778,
            "recall": 0.7468619246861925
        }
    }
]