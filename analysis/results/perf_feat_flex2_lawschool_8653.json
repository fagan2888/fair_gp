[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8593282489818682,
            "auditor_fn_violation": 0.00020373219060177195,
            "auditor_fp_violation": 0.010212815526113205,
            "ave_precision_score": 0.811219327390781,
            "fpr": 0.08662280701754387,
            "logloss": 6.139341934603403,
            "mae": 0.22823371259995484,
            "precision": 0.8162790697674419,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.857526264419033,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.009194453116345588,
            "ave_precision_score": 0.8068522545387187,
            "fpr": 0.08122941822173436,
            "logloss": 5.940244213211563,
            "mae": 0.22494354008846032,
            "precision": 0.8242280285035629,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7955113525880104,
            "auditor_fn_violation": 0.010822986485001648,
            "auditor_fp_violation": 0.01680948908066934,
            "ave_precision_score": 0.7960601796043665,
            "fpr": 0.14035087719298245,
            "logloss": 0.9488736778931695,
            "mae": 0.28546890621215876,
            "precision": 0.7349896480331263,
            "recall": 0.7411273486430062
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8396934191626393,
            "auditor_fn_violation": 0.01321855682015137,
            "auditor_fp_violation": 0.01728869374313941,
            "ave_precision_score": 0.8399245354049176,
            "fpr": 0.11964873765093303,
            "logloss": 0.9059601167150018,
            "mae": 0.264924627331613,
            "precision": 0.7660944206008584,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8526397882018418,
            "auditor_fn_violation": 0.005853294509760843,
            "auditor_fp_violation": 0.005644524127871643,
            "ave_precision_score": 0.794511066187255,
            "fpr": 0.08881578947368421,
            "logloss": 6.659142871929104,
            "mae": 0.232539010286353,
            "precision": 0.8111888111888111,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8537257704916613,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.013071632141310586,
            "ave_precision_score": 0.7954579995176023,
            "fpr": 0.08232711306256861,
            "logloss": 6.480590934233397,
            "mae": 0.22521535248359859,
            "precision": 0.8222748815165877,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8512626782329252,
            "auditor_fn_violation": 0.005120774273889318,
            "auditor_fp_violation": 0.006839775535837287,
            "ave_precision_score": 0.7906968304448035,
            "fpr": 0.09100877192982457,
            "logloss": 6.7826918526226585,
            "mae": 0.23260498861730003,
            "precision": 0.8083140877598153,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.853710855270578,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.013071632141310586,
            "ave_precision_score": 0.7940332823615985,
            "fpr": 0.08232711306256861,
            "logloss": 6.56961179939989,
            "mae": 0.22614118887363946,
            "precision": 0.8222748815165877,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.782277281844904,
            "auditor_fn_violation": 0.010122514009449508,
            "auditor_fp_violation": 0.017153883554150963,
            "ave_precision_score": 0.7833296449209799,
            "fpr": 0.14035087719298245,
            "logloss": 1.010706575031851,
            "mae": 0.2889306749944621,
            "precision": 0.7338877338877339,
            "recall": 0.7369519832985386
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.830260554418542,
            "auditor_fn_violation": 0.015349240279623316,
            "auditor_fp_violation": 0.01229619633631759,
            "ave_precision_score": 0.8305302623734426,
            "fpr": 0.12294182217343579,
            "logloss": 0.9727525014583874,
            "mae": 0.26666557719003703,
            "precision": 0.7617021276595745,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8188787313971558,
            "auditor_fn_violation": 0.011747793282789442,
            "auditor_fp_violation": 0.015039402779465983,
            "ave_precision_score": 0.8173328115128531,
            "fpr": 0.11293859649122807,
            "logloss": 1.0914225042229302,
            "mae": 0.2828203800234791,
            "precision": 0.7669683257918553,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8683743563542845,
            "auditor_fn_violation": 0.016021722803165984,
            "auditor_fp_violation": 0.0024874369328996273,
            "ave_precision_score": 0.8685224420385714,
            "fpr": 0.09110867178924259,
            "logloss": 0.9244889894752164,
            "mae": 0.250759371659482,
            "precision": 0.8074245939675174,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8555740198199582,
            "auditor_fn_violation": 0.0028865875544812018,
            "auditor_fp_violation": 0.004236558486284997,
            "ave_precision_score": 0.8011006648417783,
            "fpr": 0.08771929824561403,
            "logloss": 6.5302539116948575,
            "mae": 0.23262287310458932,
            "precision": 0.813953488372093,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8525246424510704,
            "auditor_fn_violation": 0.00017100930151945569,
            "auditor_fp_violation": 0.011407466339036648,
            "ave_precision_score": 0.794102181039337,
            "fpr": 0.08232711306256861,
            "logloss": 6.439070081422381,
            "mae": 0.22601228674203447,
            "precision": 0.8218527315914489,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8174906485825861,
            "auditor_fn_violation": 0.01410330366626379,
            "auditor_fp_violation": 0.015761111786394395,
            "ave_precision_score": 0.8171539842401414,
            "fpr": 0.09868421052631579,
            "logloss": 0.8944211779691625,
            "mae": 0.28433956303447383,
            "precision": 0.7862232779097387,
            "recall": 0.6910229645093946
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8650137478455928,
            "auditor_fn_violation": 0.012851117915535277,
            "auditor_fp_violation": 0.01176245480820552,
            "ave_precision_score": 0.8651733185388724,
            "fpr": 0.08781558726673985,
            "logloss": 0.7791504652692179,
            "mae": 0.25463275627241366,
            "precision": 0.8099762470308789,
            "recall": 0.7178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6873859358367564,
            "auditor_fn_violation": 0.007547247555213714,
            "auditor_fp_violation": 0.036052530286455164,
            "ave_precision_score": 0.6633426449804161,
            "fpr": 0.16447368421052633,
            "logloss": 2.7998491823908185,
            "mae": 0.31153540698965726,
            "precision": 0.7041420118343196,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7124206646835927,
            "auditor_fn_violation": 0.007364954647871052,
            "auditor_fp_violation": 0.03567256467839556,
            "ave_precision_score": 0.6880811582236916,
            "fpr": 0.1525795828759605,
            "logloss": 2.6799393994541294,
            "mae": 0.28973155151751295,
            "precision": 0.7236580516898609,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8161191164133915,
            "auditor_fn_violation": 0.011727191151155553,
            "auditor_fp_violation": 0.011747396782950455,
            "ave_precision_score": 0.8154751193397369,
            "fpr": 0.11403508771929824,
            "logloss": 1.0450071679827029,
            "mae": 0.28805997223643237,
            "precision": 0.7625570776255708,
            "recall": 0.697286012526096
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8638324034348721,
            "auditor_fn_violation": 0.013230111502686465,
            "auditor_fp_violation": 0.01569753975367325,
            "ave_precision_score": 0.8639908161857583,
            "fpr": 0.09549945115257959,
            "logloss": 0.8930245012984757,
            "mae": 0.2582749177500624,
            "precision": 0.8009153318077803,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8140919041691814,
            "auditor_fn_violation": 0.006430154195509649,
            "auditor_fp_violation": 0.01405433329281634,
            "ave_precision_score": 0.813362996828706,
            "fpr": 0.11293859649122807,
            "logloss": 1.0782833592376588,
            "mae": 0.29317513917734705,
            "precision": 0.7674943566591422,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8613508147890482,
            "auditor_fn_violation": 0.014138309549945128,
            "auditor_fp_violation": 0.010830924782726917,
            "ave_precision_score": 0.8615085593598009,
            "fpr": 0.09769484083424808,
            "logloss": 0.906760129433961,
            "mae": 0.26542179246207254,
            "precision": 0.7935034802784223,
            "recall": 0.72
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8228439992831696,
            "auditor_fn_violation": 0.013425722448082633,
            "auditor_fp_violation": 0.014155625785016817,
            "ave_precision_score": 0.8214026797712785,
            "fpr": 0.11293859649122807,
            "logloss": 1.0482878400694793,
            "mae": 0.27970129361634544,
            "precision": 0.7680180180180181,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8684825711497748,
            "auditor_fn_violation": 0.017336645675660067,
            "auditor_fp_violation": 0.0026888488303004098,
            "ave_precision_score": 0.8686305665519192,
            "fpr": 0.09220636663007684,
            "logloss": 0.9034058072284775,
            "mae": 0.2517792836291526,
            "precision": 0.8055555555555556,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8038093912970189,
            "auditor_fn_violation": 0.009683001867926602,
            "auditor_fp_violation": 0.015885195089339974,
            "ave_precision_score": 0.8043318540052192,
            "fpr": 0.14035087719298245,
            "logloss": 0.9903420499080379,
            "mae": 0.28098987406174974,
            "precision": 0.7382413087934561,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8480708064507947,
            "auditor_fn_violation": 0.012553007106129756,
            "auditor_fp_violation": 0.01444123304363589,
            "ave_precision_score": 0.8482975251505261,
            "fpr": 0.1251372118551043,
            "logloss": 0.9375565965086131,
            "mae": 0.2600799886818465,
            "precision": 0.762993762993763,
            "recall": 0.7726315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6826141574030519,
            "auditor_fn_violation": 0.01036058308610776,
            "auditor_fp_violation": 0.034193813054576395,
            "ave_precision_score": 0.6587434937292131,
            "fpr": 0.16666666666666666,
            "logloss": 2.811073813985688,
            "mae": 0.3171484614016215,
            "precision": 0.7013752455795678,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7100256323835781,
            "auditor_fn_violation": 0.0059622161881102385,
            "auditor_fp_violation": 0.03563228229891541,
            "ave_precision_score": 0.6856253698774087,
            "fpr": 0.15477497255762898,
            "logloss": 2.6884741085325734,
            "mae": 0.2923513856493064,
            "precision": 0.7229862475442044,
            "recall": 0.7747368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8523532166853987,
            "auditor_fn_violation": 0.005120774273889318,
            "auditor_fp_violation": 0.009083404238077877,
            "ave_precision_score": 0.7925754801817628,
            "fpr": 0.08881578947368421,
            "logloss": 6.753435108640758,
            "mae": 0.23167236702917834,
            "precision": 0.8120649651972158,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8531884419312805,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.011407466339036648,
            "ave_precision_score": 0.7935684284895025,
            "fpr": 0.08232711306256861,
            "logloss": 6.564319664208133,
            "mae": 0.22556260285520835,
            "precision": 0.8222748815165877,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8170496031696474,
            "auditor_fn_violation": 0.011207559608834195,
            "auditor_fp_violation": 0.015300230946882218,
            "ave_precision_score": 0.814854105671989,
            "fpr": 0.11293859649122807,
            "logloss": 1.1235441338905068,
            "mae": 0.2833880086805818,
            "precision": 0.7669683257918553,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8671709926550566,
            "auditor_fn_violation": 0.016666474088624417,
            "auditor_fp_violation": 0.00787016989093546,
            "ave_precision_score": 0.8673179730046212,
            "fpr": 0.09440175631174534,
            "logloss": 0.9404961889809518,
            "mae": 0.2523714454781553,
            "precision": 0.8013856812933026,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8176690031853731,
            "auditor_fn_violation": 0.011582976229718355,
            "auditor_fp_violation": 0.015512945180503222,
            "ave_precision_score": 0.8171809439429134,
            "fpr": 0.11293859649122807,
            "logloss": 1.0179514740195625,
            "mae": 0.2858947891385411,
            "precision": 0.7659090909090909,
            "recall": 0.7035490605427975
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8654042977032331,
            "auditor_fn_violation": 0.015376971517707557,
            "auditor_fp_violation": 0.008328381957522233,
            "ave_precision_score": 0.8655578245583517,
            "fpr": 0.09220636663007684,
            "logloss": 0.8748381262459017,
            "mae": 0.25807414177502813,
            "precision": 0.8060046189376443,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8033564857286628,
            "auditor_fn_violation": 0.009648664981870125,
            "auditor_fp_violation": 0.017105769620355746,
            "ave_precision_score": 0.8038372130870989,
            "fpr": 0.14035087719298245,
            "logloss": 0.9855271655868415,
            "mae": 0.2807645965253919,
            "precision": 0.7393075356415478,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8484701593028277,
            "auditor_fn_violation": 0.012814142931422957,
            "auditor_fp_violation": 0.01801629422249973,
            "ave_precision_score": 0.8486926812334356,
            "fpr": 0.12733260153677278,
            "logloss": 0.9316609081130802,
            "mae": 0.2604877615310413,
            "precision": 0.7613168724279835,
            "recall": 0.7789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7649197371857765,
            "auditor_fn_violation": 0.016081108303116872,
            "auditor_fp_violation": 0.021608220898666996,
            "ave_precision_score": 0.7658359460982693,
            "fpr": 0.1962719298245614,
            "logloss": 0.7221253537081533,
            "mae": 0.35344703500021774,
            "precision": 0.6763110307414105,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.813076406745898,
            "auditor_fn_violation": 0.01696227396152291,
            "auditor_fp_violation": 0.022812415029355784,
            "ave_precision_score": 0.8138671667671863,
            "fpr": 0.17453347969264543,
            "logloss": 0.5999150122787034,
            "mae": 0.32393026243341333,
            "precision": 0.7093235831809872,
            "recall": 0.8168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8036378279893149,
            "auditor_fn_violation": 0.011505145954657004,
            "auditor_fp_violation": 0.018121226854665533,
            "ave_precision_score": 0.804221259468888,
            "fpr": 0.13815789473684212,
            "logloss": 0.9678737847071721,
            "mae": 0.2801738907348481,
            "precision": 0.7433808553971487,
            "recall": 0.7620041753653445
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8461147437754701,
            "auditor_fn_violation": 0.01326708648679878,
            "auditor_fp_violation": 0.019398483368412572,
            "ave_precision_score": 0.8463453608557658,
            "fpr": 0.132821075740944,
            "logloss": 0.9359678331253973,
            "mae": 0.26213202563320137,
            "precision": 0.7540650406504065,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8512209162717745,
            "auditor_fn_violation": 0.005120774273889318,
            "auditor_fp_violation": 0.006839775535837287,
            "ave_precision_score": 0.789740273708141,
            "fpr": 0.09100877192982457,
            "logloss": 6.805328957237371,
            "mae": 0.2334442798603692,
            "precision": 0.8083140877598153,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8525902763113996,
            "auditor_fn_violation": 0.0005661794442197735,
            "auditor_fp_violation": 0.012175349197877123,
            "ave_precision_score": 0.7920437241321555,
            "fpr": 0.08342480790340286,
            "logloss": 6.598030149019659,
            "mae": 0.2270875600249125,
            "precision": 0.8207547169811321,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8148650133429765,
            "auditor_fn_violation": 0.01675182214408673,
            "auditor_fp_violation": 0.015406588063692717,
            "ave_precision_score": 0.813427020993561,
            "fpr": 0.11293859649122807,
            "logloss": 1.0307425021408647,
            "mae": 0.2884797810623565,
            "precision": 0.7626728110599078,
            "recall": 0.6910229645093946
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8623010498347202,
            "auditor_fn_violation": 0.016010168120630892,
            "auditor_fp_violation": 0.01166426650822264,
            "ave_precision_score": 0.8624583910971019,
            "fpr": 0.09330406147091108,
            "logloss": 0.8312910173127889,
            "mae": 0.2585064420692827,
            "precision": 0.802784222737819,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8196601401376119,
            "auditor_fn_violation": 0.01289464527707579,
            "auditor_fp_violation": 0.014434180138568125,
            "ave_precision_score": 0.8180264751839665,
            "fpr": 0.1162280701754386,
            "logloss": 1.1168132669013118,
            "mae": 0.28269510070884946,
            "precision": 0.7644444444444445,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8653748542921708,
            "auditor_fn_violation": 0.014078225200762616,
            "auditor_fp_violation": 0.014073656330879472,
            "ave_precision_score": 0.8655276907374451,
            "fpr": 0.10318331503841932,
            "logloss": 0.9688828991626051,
            "mae": 0.2557523605810968,
            "precision": 0.7878103837471784,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8156579385171885,
            "auditor_fn_violation": 0.008128685492436739,
            "auditor_fp_violation": 0.015829484218629716,
            "ave_precision_score": 0.8150666423758646,
            "fpr": 0.11513157894736842,
            "logloss": 1.02567332999129,
            "mae": 0.28860680045080594,
            "precision": 0.7640449438202247,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8671958045650612,
            "auditor_fn_violation": 0.011092495233693461,
            "auditor_fp_violation": 0.012940714408000084,
            "ave_precision_score": 0.8673543493229274,
            "fpr": 0.09440175631174534,
            "logloss": 0.8522297871897575,
            "mae": 0.25458474734212844,
            "precision": 0.8058690744920993,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8214996884288759,
            "auditor_fn_violation": 0.009804325531992826,
            "auditor_fp_violation": 0.01511537214861635,
            "ave_precision_score": 0.821001224970263,
            "fpr": 0.10855263157894737,
            "logloss": 1.003575979916057,
            "mae": 0.28077595586603044,
            "precision": 0.7755102040816326,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.868558255690074,
            "auditor_fn_violation": 0.015185163787624936,
            "auditor_fp_violation": 0.008368664337002386,
            "ave_precision_score": 0.8687111844872613,
            "fpr": 0.09001097694840834,
            "logloss": 0.8561710312484001,
            "mae": 0.2542008794744456,
            "precision": 0.8106235565819861,
            "recall": 0.7389473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8168819151616167,
            "auditor_fn_violation": 0.009644086730395934,
            "auditor_fp_violation": 0.010339431141363811,
            "ave_precision_score": 0.8163749270474685,
            "fpr": 0.1206140350877193,
            "logloss": 1.0219875872537105,
            "mae": 0.2866228092742775,
            "precision": 0.7566371681415929,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.867179337437791,
            "auditor_fn_violation": 0.014667514010052576,
            "auditor_fp_violation": 0.00941600620348644,
            "ave_precision_score": 0.8673380198845768,
            "fpr": 0.09220636663007684,
            "logloss": 0.8544603834772281,
            "mae": 0.25467815276589206,
            "precision": 0.8073394495412844,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8211121571053419,
            "auditor_fn_violation": 0.013352470424495479,
            "auditor_fp_violation": 0.012848952635630649,
            "ave_precision_score": 0.8195473892615708,
            "fpr": 0.11403508771929824,
            "logloss": 1.078427949476499,
            "mae": 0.2793372827737056,
            "precision": 0.767337807606264,
            "recall": 0.7160751565762005
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8670695071413843,
            "auditor_fn_violation": 0.018434340516494313,
            "auditor_fp_violation": 0.009974924218773603,
            "ave_precision_score": 0.8672189477156229,
            "fpr": 0.09549945115257959,
            "logloss": 0.9340826344765745,
            "mae": 0.25310906325799004,
            "precision": 0.8,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8053560923104098,
            "auditor_fn_violation": 0.0072725524667619015,
            "auditor_fp_violation": 0.019237976581175806,
            "ave_precision_score": 0.8071083336033539,
            "fpr": 0.1425438596491228,
            "logloss": 0.9707638064371348,
            "mae": 0.2763222242310018,
            "precision": 0.74,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8576240291944028,
            "auditor_fn_violation": 0.01418683921659253,
            "auditor_fp_violation": 0.01332339701306157,
            "ave_precision_score": 0.8578072408265995,
            "fpr": 0.1251372118551043,
            "logloss": 0.9228513911307396,
            "mae": 0.257234579784382,
            "precision": 0.7659137577002053,
            "recall": 0.7852631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8096178627981039,
            "auditor_fn_violation": 0.013041149324250089,
            "auditor_fp_violation": 0.012585592155909405,
            "ave_precision_score": 0.8090970187066913,
            "fpr": 0.11403508771929824,
            "logloss": 1.4678110322492643,
            "mae": 0.295702285633227,
            "precision": 0.7647058823529411,
            "recall": 0.7056367432150313
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8590881770231634,
            "auditor_fn_violation": 0.0174591253105321,
            "auditor_fp_violation": 0.011767490105640543,
            "ave_precision_score": 0.8591549925857555,
            "fpr": 0.09549945115257959,
            "logloss": 1.3105250077002208,
            "mae": 0.26576501244643397,
            "precision": 0.7986111111111112,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.836105331837989,
            "auditor_fn_violation": 0.007242793832179619,
            "auditor_fp_violation": 0.013421255216563349,
            "ave_precision_score": 0.8353371291474614,
            "fpr": 0.09649122807017543,
            "logloss": 0.9920577574417923,
            "mae": 0.2627336106822166,
            "precision": 0.794392523364486,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8797991811117247,
            "auditor_fn_violation": 0.014117511121381944,
            "auditor_fp_violation": 0.004310214604376682,
            "ave_precision_score": 0.8799232782435372,
            "fpr": 0.07683863885839737,
            "logloss": 0.8416220087689932,
            "mae": 0.23480492040548354,
            "precision": 0.83451536643026,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8401412762016507,
            "auditor_fn_violation": 0.0072496612093909145,
            "auditor_fp_violation": 0.005391292897370453,
            "ave_precision_score": 0.7533806905131712,
            "fpr": 0.09320175438596491,
            "logloss": 7.708085559751453,
            "mae": 0.24013260134641684,
            "precision": 0.8036951501154734,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8422061282036475,
            "auditor_fn_violation": 0.0010283667456236667,
            "auditor_fp_violation": 0.014985045166617994,
            "ave_precision_score": 0.7581024201368184,
            "fpr": 0.08781558726673985,
            "logloss": 7.514795820412262,
            "mae": 0.23037092320521105,
            "precision": 0.8126463700234192,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8175490051151961,
            "auditor_fn_violation": 0.010431545983957808,
            "auditor_fp_violation": 0.015201470766986755,
            "ave_precision_score": 0.8168530484471157,
            "fpr": 0.11951754385964912,
            "logloss": 1.0501914010900433,
            "mae": 0.2865162867089288,
            "precision": 0.7566964285714286,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8649251934874533,
            "auditor_fn_violation": 0.015617308914437578,
            "auditor_fp_violation": 0.010020241895688781,
            "ave_precision_score": 0.865079991407508,
            "fpr": 0.09330406147091108,
            "logloss": 0.8947833197039277,
            "mae": 0.2579983980813465,
            "precision": 0.8059360730593608,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8154544842622995,
            "auditor_fn_violation": 0.015142566750906496,
            "auditor_fp_violation": 0.01031917264292371,
            "ave_precision_score": 0.815137442846819,
            "fpr": 0.1118421052631579,
            "logloss": 0.9222552763377577,
            "mae": 0.28497051442363297,
            "precision": 0.7655172413793103,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.862448863776486,
            "auditor_fn_violation": 0.012659310185452655,
            "auditor_fp_violation": 0.01001017130081874,
            "ave_precision_score": 0.8626133694049842,
            "fpr": 0.09659714599341383,
            "logloss": 0.8136509072522756,
            "mae": 0.2565370655731337,
            "precision": 0.7958236658932715,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7978716992727102,
            "auditor_fn_violation": 0.005539684283778337,
            "auditor_fp_violation": 0.01658917791013331,
            "ave_precision_score": 0.797794420354449,
            "fpr": 0.2883771929824561,
            "logloss": 0.896094296932266,
            "mae": 0.363766713337317,
            "precision": 0.6143695014662757,
            "recall": 0.8747390396659708
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.8329529075097557,
            "auditor_fn_violation": 0.004779016696516264,
            "auditor_fp_violation": 0.023459450749755813,
            "ave_precision_score": 0.8332878037530465,
            "fpr": 0.26125137211855104,
            "logloss": 0.7643143540570235,
            "mae": 0.3351062016608741,
            "precision": 0.641566265060241,
            "recall": 0.8968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8175147868817998,
            "auditor_fn_violation": 0.01194694722191701,
            "auditor_fp_violation": 0.010382480450549006,
            "ave_precision_score": 0.8168035403214471,
            "fpr": 0.10855263157894737,
            "logloss": 0.9408059944307039,
            "mae": 0.2849145070820818,
            "precision": 0.7708333333333334,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8645066536083056,
            "auditor_fn_violation": 0.014593564041827952,
            "auditor_fp_violation": 0.01141501928518918,
            "ave_precision_score": 0.8646639223859037,
            "fpr": 0.0867178924259056,
            "logloss": 0.7983682437933474,
            "mae": 0.25526293336434724,
            "precision": 0.8114558472553699,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8191668834180843,
            "auditor_fn_violation": 0.011212137860308396,
            "auditor_fp_violation": 0.014963433410315632,
            "ave_precision_score": 0.818629246343424,
            "fpr": 0.09649122807017543,
            "logloss": 0.9992280781745476,
            "mae": 0.28786677424914264,
            "precision": 0.7904761904761904,
            "recall": 0.6931106471816284
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8678871729215422,
            "auditor_fn_violation": 0.016934542723438677,
            "auditor_fp_violation": 0.01000513600338372,
            "ave_precision_score": 0.8680381158349554,
            "fpr": 0.0801317233809001,
            "logloss": 0.8340425599253379,
            "mae": 0.2560760291877006,
            "precision": 0.8249400479616307,
            "recall": 0.7242105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 8653,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6960379697256351,
            "auditor_fn_violation": 0.02236704757718932,
            "auditor_fp_violation": 0.051324905797982254,
            "ave_precision_score": 0.6209119259669055,
            "fpr": 0.31030701754385964,
            "logloss": 5.46166068060598,
            "mae": 0.37764748056454917,
            "precision": 0.6008462623413258,
            "recall": 0.8893528183716075
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7099912215395007,
            "auditor_fn_violation": 0.016377607025246984,
            "auditor_fp_violation": 0.04600499501505554,
            "ave_precision_score": 0.6404838045868307,
            "fpr": 0.28869374313940727,
            "logloss": 4.865753060580865,
            "mae": 0.34884772520641866,
            "precision": 0.6210374639769453,
            "recall": 0.9073684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7988944485528117,
            "auditor_fn_violation": 0.009236622349192402,
            "auditor_fp_violation": 0.013983428548276004,
            "ave_precision_score": 0.7991862957311829,
            "fpr": 0.13925438596491227,
            "logloss": 0.9794121831928229,
            "mae": 0.28430824505899777,
            "precision": 0.7365145228215768,
            "recall": 0.7411273486430062
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8414623097341352,
            "auditor_fn_violation": 0.012109307296782019,
            "auditor_fp_violation": 0.018348623853211017,
            "ave_precision_score": 0.841700954404099,
            "fpr": 0.12184412733260154,
            "logloss": 0.9218396089578086,
            "mae": 0.26208614441071804,
            "precision": 0.7643312101910829,
            "recall": 0.7578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8183005173098321,
            "auditor_fn_violation": 0.00987986668131708,
            "auditor_fp_violation": 0.01663475953162352,
            "ave_precision_score": 0.8175279285334327,
            "fpr": 0.1074561403508772,
            "logloss": 1.0369745422895469,
            "mae": 0.2832479138372482,
            "precision": 0.7752293577981652,
            "recall": 0.7056367432150313
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8636875244949145,
            "auditor_fn_violation": 0.01676353342191924,
            "auditor_fp_violation": 0.010085700762344031,
            "ave_precision_score": 0.8638456732462179,
            "fpr": 0.0889132821075741,
            "logloss": 0.919284778845441,
            "mae": 0.25567952493036966,
            "precision": 0.8080568720379147,
            "recall": 0.7178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8478102870587657,
            "auditor_fn_violation": 0.005853294509760843,
            "auditor_fp_violation": 0.004327721729265432,
            "ave_precision_score": 0.7815029442322026,
            "fpr": 0.09210526315789473,
            "logloss": 7.091174186460065,
            "mae": 0.23661463734362292,
            "precision": 0.8055555555555556,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8499489726953684,
            "auditor_fn_violation": 0.00017100930151945569,
            "auditor_fp_violation": 0.011984007895346382,
            "ave_precision_score": 0.7847194861637674,
            "fpr": 0.08342480790340286,
            "logloss": 6.86385332371832,
            "mae": 0.22817151834993646,
            "precision": 0.8199052132701422,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8152634171606956,
            "auditor_fn_violation": 0.012077427388931616,
            "auditor_fp_violation": 0.01666767959158868,
            "ave_precision_score": 0.8157702241530838,
            "fpr": 0.13706140350877194,
            "logloss": 0.9236318684527509,
            "mae": 0.2715485866204335,
            "precision": 0.7484909456740443,
            "recall": 0.7766179540709812
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8564112140070863,
            "auditor_fn_violation": 0.015853024438153566,
            "auditor_fp_violation": 0.013408997069456892,
            "ave_precision_score": 0.856622327520691,
            "fpr": 0.1251372118551043,
            "logloss": 0.8861618931449301,
            "mae": 0.2528695176418795,
            "precision": 0.7673469387755102,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7804431352795893,
            "auditor_fn_violation": 0.003543566641028459,
            "auditor_fp_violation": 0.016290365058141895,
            "ave_precision_score": 0.780165610572461,
            "fpr": 0.1875,
            "logloss": 0.986194561825897,
            "mae": 0.29210075142051956,
            "precision": 0.7126050420168067,
            "recall": 0.8851774530271399
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.827437112556705,
            "auditor_fn_violation": 0.00749898896527818,
            "auditor_fp_violation": 0.009174311926605514,
            "ave_precision_score": 0.8276002858156897,
            "fpr": 0.1712403951701427,
            "logloss": 0.8490866923156102,
            "mae": 0.27106370185708184,
            "precision": 0.7291666666666666,
            "recall": 0.8842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8506753332968502,
            "auditor_fn_violation": 0.019851298392118088,
            "auditor_fp_violation": 0.014700072930594386,
            "ave_precision_score": 0.8511686912967577,
            "fpr": 0.1118421052631579,
            "logloss": 0.4985084334578359,
            "mae": 0.30589170756202455,
            "precision": 0.7806451612903226,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8760789475259221,
            "auditor_fn_violation": 0.018690854468773475,
            "auditor_fp_violation": 0.012613420074723816,
            "ave_precision_score": 0.8762434530477772,
            "fpr": 0.09440175631174534,
            "logloss": 0.4617627601832715,
            "mae": 0.2956773899171019,
            "precision": 0.8138528138528138,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8196057378947674,
            "auditor_fn_violation": 0.008657473537706477,
            "auditor_fp_violation": 0.013854280620720394,
            "ave_precision_score": 0.8190770821024748,
            "fpr": 0.10416666666666667,
            "logloss": 1.0127779205198433,
            "mae": 0.284475287282205,
            "precision": 0.7800925925925926,
            "recall": 0.7035490605427975
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.867153522728234,
            "auditor_fn_violation": 0.01585302443815357,
            "auditor_fp_violation": 0.008806735213849084,
            "ave_precision_score": 0.8673056734143023,
            "fpr": 0.0867178924259056,
            "logloss": 0.8615278005176066,
            "mae": 0.25584244999485134,
            "precision": 0.8136792452830188,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.81810016750759,
            "auditor_fn_violation": 0.012482602644398058,
            "auditor_fp_violation": 0.015391394189862649,
            "ave_precision_score": 0.8173191468320319,
            "fpr": 0.10964912280701754,
            "logloss": 1.0177729586572974,
            "mae": 0.28520108579167003,
            "precision": 0.7701149425287356,
            "recall": 0.6993736951983298
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8664292151316025,
            "auditor_fn_violation": 0.016416892945866318,
            "auditor_fp_violation": 0.01054391282893081,
            "ave_precision_score": 0.8665823517697814,
            "fpr": 0.08781558726673985,
            "logloss": 0.8614590930353843,
            "mae": 0.2558151976487278,
            "precision": 0.812206572769953,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.855004491489582,
            "auditor_fn_violation": 0.0017740724462513263,
            "auditor_fp_violation": 0.010711681050200563,
            "ave_precision_score": 0.800025769459758,
            "fpr": 0.08991228070175439,
            "logloss": 6.499018130952755,
            "mae": 0.23022710773161162,
            "precision": 0.8110599078341014,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8537273838686882,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.012175349197877123,
            "ave_precision_score": 0.7966091863535045,
            "fpr": 0.08342480790340286,
            "logloss": 6.3653739083808,
            "mae": 0.22589041438749058,
            "precision": 0.8203309692671394,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7658409706595503,
            "auditor_fn_violation": 0.01027817455957222,
            "auditor_fp_violation": 0.015110307524006331,
            "ave_precision_score": 0.7461787354338489,
            "fpr": 0.13925438596491227,
            "logloss": 2.5838719271896937,
            "mae": 0.28752162333586345,
            "precision": 0.735966735966736,
            "recall": 0.7390396659707724
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8036448958994172,
            "auditor_fn_violation": 0.014175284534057427,
            "auditor_fp_violation": 0.016246387174090375,
            "ave_precision_score": 0.7859202053586334,
            "fpr": 0.12403951701427003,
            "logloss": 2.565254375245678,
            "mae": 0.26725223294947026,
            "precision": 0.760593220338983,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8177407020793142,
            "auditor_fn_violation": 0.011582976229718355,
            "auditor_fp_violation": 0.015512945180503222,
            "ave_precision_score": 0.8172182841044365,
            "fpr": 0.11293859649122807,
            "logloss": 1.0193462334395287,
            "mae": 0.28563851114217764,
            "precision": 0.7659090909090909,
            "recall": 0.7035490605427975
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8652819627452107,
            "auditor_fn_violation": 0.015376971517707557,
            "auditor_fp_violation": 0.008328381957522233,
            "ave_precision_score": 0.8654357923735934,
            "fpr": 0.09220636663007684,
            "logloss": 0.8764640121169928,
            "mae": 0.2579428676693987,
            "precision": 0.8060046189376443,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8190673391211201,
            "auditor_fn_violation": 0.011411291799435966,
            "auditor_fp_violation": 0.012210809934767638,
            "ave_precision_score": 0.8184112822297724,
            "fpr": 0.11842105263157894,
            "logloss": 1.0081746132663254,
            "mae": 0.28581906217231234,
            "precision": 0.7615894039735099,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.86820698206252,
            "auditor_fn_violation": 0.016735802183835,
            "auditor_fp_violation": 0.009713088752152588,
            "ave_precision_score": 0.8683567620607742,
            "fpr": 0.09769484083424808,
            "logloss": 0.8534147977269868,
            "mae": 0.2581874656376964,
            "precision": 0.7981859410430839,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7118274942266618,
            "auditor_fn_violation": 0.0099897447166978,
            "auditor_fp_violation": 0.019010068473724738,
            "ave_precision_score": 0.7067430185595788,
            "fpr": 0.20942982456140352,
            "logloss": 1.6817109808233985,
            "mae": 0.2952049086378072,
            "precision": 0.684297520661157,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7365922642137703,
            "auditor_fn_violation": 0.01269397423305795,
            "auditor_fp_violation": 0.02956978418715194,
            "ave_precision_score": 0.7329011942383978,
            "fpr": 0.20965971459934138,
            "logloss": 1.6280382582060688,
            "mae": 0.29199446314523897,
            "precision": 0.6789915966386555,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8205071542642668,
            "auditor_fn_violation": 0.011482254697286016,
            "auditor_fp_violation": 0.014337952270977679,
            "ave_precision_score": 0.8198079439561254,
            "fpr": 0.10307017543859649,
            "logloss": 0.9712795051671194,
            "mae": 0.28440470638440785,
            "precision": 0.7813953488372093,
            "recall": 0.7014613778705637
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8684930654202271,
            "auditor_fn_violation": 0.016322144549078522,
            "auditor_fp_violation": 0.00972315934702263,
            "ave_precision_score": 0.868641999028041,
            "fpr": 0.0845225027442371,
            "logloss": 0.8226645426134455,
            "mae": 0.25480495047227075,
            "precision": 0.817966903073286,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7929303960664501,
            "auditor_fn_violation": 0.006665934146430803,
            "auditor_fp_violation": 0.018346602649811593,
            "ave_precision_score": 0.7933707062396814,
            "fpr": 0.14035087719298245,
            "logloss": 1.0865718102189543,
            "mae": 0.2854055532903257,
            "precision": 0.7360824742268042,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8385190430309661,
            "auditor_fn_violation": 0.016807441215552606,
            "auditor_fp_violation": 0.013338502905366619,
            "ave_precision_score": 0.8387522592114623,
            "fpr": 0.1251372118551043,
            "logloss": 1.0394256178613173,
            "mae": 0.26673058890782164,
            "precision": 0.7548387096774194,
            "recall": 0.7389473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7181095114385121,
            "auditor_fn_violation": 0.0069223162289858255,
            "auditor_fp_violation": 0.026893156679226943,
            "ave_precision_score": 0.7079934549886545,
            "fpr": 0.15460526315789475,
            "logloss": 1.755025281152953,
            "mae": 0.31529605821898643,
            "precision": 0.7191235059760956,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7506629919366399,
            "auditor_fn_violation": 0.012074643249176727,
            "auditor_fp_violation": 0.025171451877662416,
            "ave_precision_score": 0.7408018632364788,
            "fpr": 0.1437980241492865,
            "logloss": 1.5446895661129096,
            "mae": 0.2914251395690586,
            "precision": 0.733739837398374,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8219454768376877,
            "auditor_fn_violation": 0.01079551697615647,
            "auditor_fp_violation": 0.013545338519508938,
            "ave_precision_score": 0.8211379113757693,
            "fpr": 0.11951754385964912,
            "logloss": 1.0546449569437721,
            "mae": 0.2787875423953938,
            "precision": 0.7609649122807017,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8664053386433023,
            "auditor_fn_violation": 0.016805130279045587,
            "auditor_fp_violation": 0.012751890754186855,
            "ave_precision_score": 0.8665590498933557,
            "fpr": 0.10428100987925357,
            "logloss": 0.9363624425779072,
            "mae": 0.2546580606170018,
            "precision": 0.7898230088495575,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.81065131747537,
            "auditor_fn_violation": 0.011022140424129225,
            "auditor_fp_violation": 0.01608524776143593,
            "ave_precision_score": 0.8099815615329576,
            "fpr": 0.12390350877192982,
            "logloss": 1.008067698937979,
            "mae": 0.29045933812214497,
            "precision": 0.75,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8571208886269084,
            "auditor_fn_violation": 0.01197065110636086,
            "auditor_fp_violation": 0.00786765224221795,
            "ave_precision_score": 0.8572717598044102,
            "fpr": 0.10208562019758508,
            "logloss": 0.8707163493648045,
            "mae": 0.26497740358825456,
            "precision": 0.7876712328767124,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8146394687715285,
            "auditor_fn_violation": 0.01251465040471744,
            "auditor_fp_violation": 0.01709057574652568,
            "ave_precision_score": 0.8138095648999342,
            "fpr": 0.1206140350877193,
            "logloss": 1.0676159723412058,
            "mae": 0.28788194612320384,
            "precision": 0.7560975609756098,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8638033956685818,
            "auditor_fn_violation": 0.014732220232249118,
            "auditor_fp_violation": 0.011208572090353383,
            "ave_precision_score": 0.8639617988184269,
            "fpr": 0.10098792535675083,
            "logloss": 0.9094834431166491,
            "mae": 0.2594610561390038,
            "precision": 0.7918552036199095,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8479472426816091,
            "auditor_fn_violation": 0.005853294509760843,
            "auditor_fp_violation": 0.005457133017300762,
            "ave_precision_score": 0.7816407278064215,
            "fpr": 0.09210526315789473,
            "logloss": 7.087178388635807,
            "mae": 0.23659782759936537,
            "precision": 0.8055555555555556,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8503134624618011,
            "auditor_fn_violation": 0.001409671269281884,
            "auditor_fp_violation": 0.01256054945165611,
            "ave_precision_score": 0.7850524287277961,
            "fpr": 0.0845225027442371,
            "logloss": 6.863047338292739,
            "mae": 0.22805650324792395,
            "precision": 0.8175355450236966,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8157040159727498,
            "auditor_fn_violation": 0.007162674431381178,
            "auditor_fp_violation": 0.010937056845346627,
            "ave_precision_score": 0.8151113213737224,
            "fpr": 0.12280701754385964,
            "logloss": 1.0448484512063019,
            "mae": 0.28653651380104955,
            "precision": 0.7527593818984547,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8661308552626251,
            "auditor_fn_violation": 0.014501126581547173,
            "auditor_fp_violation": 0.010090736059779056,
            "ave_precision_score": 0.8662908683333387,
            "fpr": 0.09220636663007684,
            "logloss": 0.8774043654797375,
            "mae": 0.2541583855653855,
            "precision": 0.8064516129032258,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8183005489194297,
            "auditor_fn_violation": 0.011997307988133173,
            "auditor_fp_violation": 0.014725396053644507,
            "ave_precision_score": 0.8177017940441949,
            "fpr": 0.11293859649122807,
            "logloss": 1.0349628139059401,
            "mae": 0.2847485191118571,
            "precision": 0.7685393258426966,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8643648577187274,
            "auditor_fn_violation": 0.01692760991391762,
            "auditor_fp_violation": 0.0086556762907985,
            "ave_precision_score": 0.8645212514171466,
            "fpr": 0.09549945115257959,
            "logloss": 0.8935153692133202,
            "mae": 0.25865664047599235,
            "precision": 0.8009153318077803,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7751087856344088,
            "auditor_fn_violation": 0.008458319598578914,
            "auditor_fp_violation": 0.01646509460718772,
            "ave_precision_score": 0.7757636933257164,
            "fpr": 0.14912280701754385,
            "logloss": 1.152336792584606,
            "mae": 0.2941701586889157,
            "precision": 0.7274549098196392,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.816118475715716,
            "auditor_fn_violation": 0.013634525391414874,
            "auditor_fp_violation": 0.016729775727852246,
            "ave_precision_score": 0.8164833185116042,
            "fpr": 0.1350164654226125,
            "logloss": 1.1064829417245756,
            "mae": 0.2729324754115078,
            "precision": 0.7463917525773196,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 8653,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6986209286712173,
            "auditor_fn_violation": 0.0025477969453906197,
            "auditor_fp_violation": 0.005153255540699326,
            "ave_precision_score": 0.6853450458595731,
            "fpr": 0.2598684210526316,
            "logloss": 2.19981762665605,
            "mae": 0.3554085626991466,
            "precision": 0.6359447004608295,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7415739232385395,
            "auditor_fn_violation": 0.008122941822173437,
            "auditor_fp_violation": 0.0008207534819081796,
            "ave_precision_score": 0.7301447182583661,
            "fpr": 0.2579582875960483,
            "logloss": 1.9755779192246692,
            "mae": 0.341027239447434,
            "precision": 0.6401225114854517,
            "recall": 0.88
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8158952076163979,
            "auditor_fn_violation": 0.006828462073764791,
            "auditor_fp_violation": 0.010845893602366196,
            "ave_precision_score": 0.8154636596844571,
            "fpr": 0.11951754385964912,
            "logloss": 1.0243765624146899,
            "mae": 0.28733317001613706,
            "precision": 0.7583148558758315,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8668851643556132,
            "auditor_fn_violation": 0.014270032930845224,
            "auditor_fp_violation": 0.00941600620348644,
            "ave_precision_score": 0.8670457530122666,
            "fpr": 0.09220636663007684,
            "logloss": 0.8565506701165373,
            "mae": 0.2545813935991676,
            "precision": 0.8064516129032258,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7657245657816307,
            "auditor_fn_violation": 0.010580339156869211,
            "auditor_fp_violation": 0.015328086382237349,
            "ave_precision_score": 0.7460023024705844,
            "fpr": 0.13596491228070176,
            "logloss": 2.5543693631605753,
            "mae": 0.2863995645509794,
            "precision": 0.7432712215320911,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8016759101866713,
            "auditor_fn_violation": 0.015515627708128726,
            "auditor_fp_violation": 0.018401494476278726,
            "ave_precision_score": 0.7840396924083333,
            "fpr": 0.12623490669593854,
            "logloss": 2.5524128778415105,
            "mae": 0.268000545472072,
            "precision": 0.7573839662447257,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.817554718059285,
            "auditor_fn_violation": 0.01065130205471926,
            "auditor_fp_violation": 0.014370872330942832,
            "ave_precision_score": 0.8169658162792142,
            "fpr": 0.11513157894736842,
            "logloss": 1.0588509919955107,
            "mae": 0.2854454409518716,
            "precision": 0.7635135135135135,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8644672799792745,
            "auditor_fn_violation": 0.013634525391414869,
            "auditor_fp_violation": 0.009949747731598504,
            "ave_precision_score": 0.8646232000743443,
            "fpr": 0.09659714599341383,
            "logloss": 0.9055005334783122,
            "mae": 0.25705079561128447,
            "precision": 0.7990867579908676,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8549256739553242,
            "auditor_fn_violation": 0.0017740724462513263,
            "auditor_fp_violation": 0.0102963818321786,
            "ave_precision_score": 0.8003440876345321,
            "fpr": 0.08991228070175439,
            "logloss": 6.455875806120283,
            "mae": 0.23023512981047695,
            "precision": 0.8110599078341014,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8545597581207557,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.012175349197877123,
            "ave_precision_score": 0.7985111338663567,
            "fpr": 0.08342480790340286,
            "logloss": 6.293394564642746,
            "mae": 0.22659787514216534,
            "precision": 0.8203309692671394,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8025725881096968,
            "auditor_fn_violation": 0.007634234333223459,
            "auditor_fp_violation": 0.017835075564199183,
            "ave_precision_score": 0.8042931567829275,
            "fpr": 0.14144736842105263,
            "logloss": 1.009497591741886,
            "mae": 0.27762508723717283,
            "precision": 0.7393939393939394,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8561494802644523,
            "auditor_fn_violation": 0.010214339361026057,
            "auditor_fp_violation": 0.013758950241190752,
            "ave_precision_score": 0.8563373515692843,
            "fpr": 0.12403951701427003,
            "logloss": 0.95751384087309,
            "mae": 0.25724641912145196,
            "precision": 0.7665289256198347,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8547728750965107,
            "auditor_fn_violation": 0.0017740724462513263,
            "auditor_fp_violation": 0.009648109882095541,
            "ave_precision_score": 0.8005882560526283,
            "fpr": 0.08771929824561403,
            "logloss": 6.439843100937678,
            "mae": 0.22983597506629513,
            "precision": 0.8148148148148148,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8553445284435642,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.012175349197877123,
            "ave_precision_score": 0.800123126212099,
            "fpr": 0.08342480790340286,
            "logloss": 6.254142993661264,
            "mae": 0.22648087318365806,
            "precision": 0.8203309692671394,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8362756014957096,
            "auditor_fn_violation": 0.003575614401347838,
            "auditor_fp_violation": 0.0028767067784935796,
            "ave_precision_score": 0.737644431133619,
            "fpr": 0.09539473684210527,
            "logloss": 7.962306196330373,
            "mae": 0.23990001409106773,
            "precision": 0.8,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8370143406299528,
            "auditor_fn_violation": 0.005453810156565952,
            "auditor_fp_violation": 0.010639583480196179,
            "ave_precision_score": 0.7399038435851816,
            "fpr": 0.09001097694840834,
            "logloss": 7.749424211598682,
            "mae": 0.23745812565493274,
            "precision": 0.8056872037914692,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8483006492956124,
            "auditor_fn_violation": 0.0043951214152290995,
            "auditor_fp_violation": 0.004327721729265432,
            "ave_precision_score": 0.7832141781570998,
            "fpr": 0.09210526315789473,
            "logloss": 7.035831846953108,
            "mae": 0.23656541821259916,
            "precision": 0.8060046189376443,
            "recall": 0.7286012526096033
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8501803651298585,
            "auditor_fn_violation": 0.00017100930151945569,
            "auditor_fp_violation": 0.011984007895346382,
            "ave_precision_score": 0.7853426983302485,
            "fpr": 0.08342480790340286,
            "logloss": 6.817251770314893,
            "mae": 0.22825652449483727,
            "precision": 0.8199052132701422,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8002596705079754,
            "auditor_fn_violation": 0.009273248360985977,
            "auditor_fp_violation": 0.01893156679226936,
            "ave_precision_score": 0.8008236311240837,
            "fpr": 0.13596491228070176,
            "logloss": 0.9687507581359753,
            "mae": 0.28342918113111504,
            "precision": 0.7405857740585774,
            "recall": 0.7390396659707724
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8434468167671771,
            "auditor_fn_violation": 0.015732855739788554,
            "auditor_fp_violation": 0.018935236004390777,
            "ave_precision_score": 0.8436772583807643,
            "fpr": 0.11964873765093303,
            "logloss": 0.9153659119290964,
            "mae": 0.2616429980647038,
            "precision": 0.7670940170940171,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8027816021421272,
            "auditor_fn_violation": 0.009330476504413435,
            "auditor_fp_violation": 0.017888254122604433,
            "ave_precision_score": 0.8034221760982023,
            "fpr": 0.13706140350877194,
            "logloss": 0.995868652433864,
            "mae": 0.2822679874127825,
            "precision": 0.7412008281573499,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8497711703551638,
            "auditor_fn_violation": 0.014475706279969964,
            "auditor_fp_violation": 0.011800219538968171,
            "ave_precision_score": 0.8499881804848215,
            "fpr": 0.11964873765093303,
            "logloss": 0.9342688578375612,
            "mae": 0.2597804017188839,
            "precision": 0.7705263157894737,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7727948835609493,
            "auditor_fn_violation": 0.009856975423946089,
            "auditor_fp_violation": 0.014608909687613957,
            "ave_precision_score": 0.7426545271523733,
            "fpr": 0.1513157894736842,
            "logloss": 2.3817780556732933,
            "mae": 0.29059048325311204,
            "precision": 0.727810650887574,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8122326592532978,
            "auditor_fn_violation": 0.010147322202322492,
            "auditor_fp_violation": 0.01338633823099931,
            "ave_precision_score": 0.7840537722688491,
            "fpr": 0.1437980241492865,
            "logloss": 2.1501459393785187,
            "mae": 0.26555719490778734,
            "precision": 0.744140625,
            "recall": 0.8021052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8169170295014143,
            "auditor_fn_violation": 0.012068270885983227,
            "auditor_fp_violation": 0.014917851788825418,
            "ave_precision_score": 0.8145680708913545,
            "fpr": 0.11951754385964912,
            "logloss": 1.210039525317598,
            "mae": 0.281918906637017,
            "precision": 0.7566964285714286,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8620027033702576,
            "auditor_fn_violation": 0.016021722803165984,
            "auditor_fp_violation": 0.010470901016123026,
            "ave_precision_score": 0.8621618505620097,
            "fpr": 0.10208562019758508,
            "logloss": 1.0501958149778077,
            "mae": 0.254872953008479,
            "precision": 0.7891156462585034,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7894433855146213,
            "auditor_fn_violation": 0.008373621946306267,
            "auditor_fp_violation": 0.018916372918439287,
            "ave_precision_score": 0.7900013305783533,
            "fpr": 0.13815789473684212,
            "logloss": 1.1506458253156455,
            "mae": 0.2878138292390695,
            "precision": 0.7418032786885246,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8330394997109878,
            "auditor_fn_violation": 0.01361141602634468,
            "auditor_fp_violation": 0.01543822193576975,
            "ave_precision_score": 0.8333065445938732,
            "fpr": 0.13172338090010977,
            "logloss": 1.0846243473518293,
            "mae": 0.268500855633585,
            "precision": 0.7505197505197505,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 8653,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8527698016288772,
            "auditor_fn_violation": 0.005120774273889318,
            "auditor_fp_violation": 0.006832178598922249,
            "ave_precision_score": 0.7952929440636867,
            "fpr": 0.08991228070175439,
            "logloss": 6.601151957975563,
            "mae": 0.2318189478488007,
            "precision": 0.8101851851851852,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8538435142069677,
            "auditor_fn_violation": 0.0005661794442197735,
            "auditor_fp_violation": 0.012175349197877123,
            "ave_precision_score": 0.796208643637462,
            "fpr": 0.08342480790340286,
            "logloss": 6.415669604651293,
            "mae": 0.224983661359285,
            "precision": 0.8207547169811321,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8016821153066835,
            "auditor_fn_violation": 0.006830751199501889,
            "auditor_fp_violation": 0.014702605242899403,
            "ave_precision_score": 0.8021649409266363,
            "fpr": 0.14802631578947367,
            "logloss": 0.8797710433031392,
            "mae": 0.2835967440934605,
            "precision": 0.7289156626506024,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8435480036630667,
            "auditor_fn_violation": 0.009904673869085445,
            "auditor_fp_violation": 0.020151260334947987,
            "ave_precision_score": 0.8437756889355241,
            "fpr": 0.13391877058177826,
            "logloss": 0.8383276649778861,
            "mae": 0.263793011232875,
            "precision": 0.75,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8191703756896312,
            "auditor_fn_violation": 0.011621891367249022,
            "auditor_fp_violation": 0.01507738746404117,
            "ave_precision_score": 0.8175881611718565,
            "fpr": 0.11074561403508772,
            "logloss": 1.0964777971135895,
            "mae": 0.28189885835371903,
            "precision": 0.7699316628701595,
            "recall": 0.7056367432150313
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8687259601286785,
            "auditor_fn_violation": 0.017782656421514827,
            "auditor_fp_violation": 0.002719060614910523,
            "ave_precision_score": 0.8688740861575924,
            "fpr": 0.09001097694840834,
            "logloss": 0.9276311839829395,
            "mae": 0.24964800304429777,
            "precision": 0.8093023255813954,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 8653,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8142392228440722,
            "auditor_fn_violation": 0.012077427388931616,
            "auditor_fp_violation": 0.0172880961063166,
            "ave_precision_score": 0.8147564898852533,
            "fpr": 0.13925438596491227,
            "logloss": 0.9339771048184837,
            "mae": 0.2720641285804908,
            "precision": 0.7454909819639278,
            "recall": 0.7766179540709812
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8550482862383163,
            "auditor_fn_violation": 0.012536830550580629,
            "auditor_fp_violation": 0.0141340799000997,
            "ave_precision_score": 0.8552627624373507,
            "fpr": 0.1251372118551043,
            "logloss": 0.896459857880197,
            "mae": 0.25334306327473594,
            "precision": 0.7668711656441718,
            "recall": 0.7894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8052326891521766,
            "auditor_fn_violation": 0.009678423616452405,
            "auditor_fp_violation": 0.019536789433167216,
            "ave_precision_score": 0.8058621542973693,
            "fpr": 0.13815789473684212,
            "logloss": 0.9743987244143957,
            "mae": 0.27938998191919956,
            "precision": 0.7428571428571429,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8477200217842389,
            "auditor_fn_violation": 0.013911837772257208,
            "auditor_fp_violation": 0.016807822838095045,
            "ave_precision_score": 0.847943284934558,
            "fpr": 0.13062568605927552,
            "logloss": 0.9356464839562312,
            "mae": 0.2609396470425291,
            "precision": 0.7566462167689162,
            "recall": 0.7789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.83781437167313,
            "auditor_fn_violation": 0.007467128154415268,
            "auditor_fp_violation": 0.00512540010534419,
            "ave_precision_score": 0.7442630196928439,
            "fpr": 0.09429824561403509,
            "logloss": 7.783003080487644,
            "mae": 0.24090679159666276,
            "precision": 0.8009259259259259,
            "recall": 0.7223382045929019
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8402934187396867,
            "auditor_fn_violation": 0.002299381824484374,
            "auditor_fp_violation": 0.011923584326126146,
            "ave_precision_score": 0.7519278152166629,
            "fpr": 0.08562019758507135,
            "logloss": 7.559104142024347,
            "mae": 0.23010388578025462,
            "precision": 0.8156028368794326,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8406743659597536,
            "auditor_fn_violation": 0.008103505109328649,
            "auditor_fp_violation": 0.00512540010534419,
            "ave_precision_score": 0.7557253947294174,
            "fpr": 0.09429824561403509,
            "logloss": 7.675335029379837,
            "mae": 0.23921226894578593,
            "precision": 0.8013856812933026,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8440821039015731,
            "auditor_fn_violation": 0.0010283667456236667,
            "auditor_fp_violation": 0.011923584326126146,
            "ave_precision_score": 0.7624265828260909,
            "fpr": 0.08562019758507135,
            "logloss": 7.465170549067153,
            "mae": 0.22739664751376856,
            "precision": 0.8164705882352942,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.83781437167313,
            "auditor_fn_violation": 0.007467128154415268,
            "auditor_fp_violation": 0.00512540010534419,
            "ave_precision_score": 0.7442630196928439,
            "fpr": 0.09429824561403509,
            "logloss": 7.783094233666018,
            "mae": 0.24090398997741677,
            "precision": 0.8009259259259259,
            "recall": 0.7223382045929019
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8402934187396867,
            "auditor_fn_violation": 0.002299381824484374,
            "auditor_fp_violation": 0.011923584326126146,
            "ave_precision_score": 0.7519278152166629,
            "fpr": 0.08562019758507135,
            "logloss": 7.5591622880068545,
            "mae": 0.23009752746516665,
            "precision": 0.8156028368794326,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8212072379936396,
            "auditor_fn_violation": 0.012532963410614226,
            "auditor_fp_violation": 0.013413658279648315,
            "ave_precision_score": 0.8204474021338556,
            "fpr": 0.1118421052631579,
            "logloss": 1.0526146686290148,
            "mae": 0.28112130250904355,
            "precision": 0.7697516930022573,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8697915784921333,
            "auditor_fn_violation": 0.016021722803165984,
            "auditor_fp_violation": 0.0031672020866272575,
            "ave_precision_score": 0.8699388787321654,
            "fpr": 0.09110867178924259,
            "logloss": 0.905475808161462,
            "mae": 0.25003361772631677,
            "precision": 0.8074245939675174,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8113999191775267,
            "auditor_fn_violation": 0.011608156612826426,
            "auditor_fp_violation": 0.01027612333373851,
            "ave_precision_score": 0.8111599004714093,
            "fpr": 0.10307017543859649,
            "logloss": 1.4477579667442362,
            "mae": 0.29251693550008373,
            "precision": 0.7783018867924528,
            "recall": 0.6889352818371608
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8608138279403619,
            "auditor_fn_violation": 0.014672135883066617,
            "auditor_fp_violation": 0.009806241754700453,
            "ave_precision_score": 0.8608770720160464,
            "fpr": 0.09110867178924259,
            "logloss": 1.3030355236271367,
            "mae": 0.26224955399058275,
            "precision": 0.8051643192488263,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8225094752681873,
            "auditor_fn_violation": 0.008758195070138815,
            "auditor_fp_violation": 0.012451379603743772,
            "ave_precision_score": 0.8217201044321857,
            "fpr": 0.10855263157894737,
            "logloss": 1.0252590776961599,
            "mae": 0.281286963345187,
            "precision": 0.7780269058295964,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8709470809466278,
            "auditor_fn_violation": 0.016814374025073665,
            "auditor_fp_violation": 0.008882264675374375,
            "ave_precision_score": 0.8710932771449924,
            "fpr": 0.0845225027442371,
            "logloss": 0.8698485384337818,
            "mae": 0.24925181710442382,
            "precision": 0.8205128205128205,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.800600632161097,
            "auditor_fn_violation": 0.008217961396183573,
            "auditor_fp_violation": 0.016893055386734742,
            "ave_precision_score": 0.8011932143584923,
            "fpr": 0.1337719298245614,
            "logloss": 0.9904142249224636,
            "mae": 0.2852729526497131,
            "precision": 0.7431578947368421,
            "recall": 0.7369519832985386
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8484235995903898,
            "auditor_fn_violation": 0.011055520249581147,
            "auditor_fp_violation": 0.009697982859847534,
            "ave_precision_score": 0.8486424090338258,
            "fpr": 0.1141602634467618,
            "logloss": 0.9239839421724507,
            "mae": 0.2608654328655864,
            "precision": 0.7748917748917749,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8170543410125577,
            "auditor_fn_violation": 0.007558693183899209,
            "auditor_fp_violation": 0.01832887646367651,
            "ave_precision_score": 0.8154586390717571,
            "fpr": 0.1162280701754386,
            "logloss": 1.0291904635529074,
            "mae": 0.2825671285747479,
            "precision": 0.7639198218262806,
            "recall": 0.7160751565762005
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8634133697178215,
            "auditor_fn_violation": 0.014223814200704843,
            "auditor_fp_violation": 0.01212499622352693,
            "ave_precision_score": 0.8635671805800036,
            "fpr": 0.10537870472008781,
            "logloss": 0.8662569379817706,
            "mae": 0.25762602389716643,
            "precision": 0.7866666666666666,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8525266594654904,
            "auditor_fn_violation": 0.011285389883895549,
            "auditor_fp_violation": 0.01437340464324785,
            "ave_precision_score": 0.8528083769647123,
            "fpr": 0.12390350877192982,
            "logloss": 0.5395964913495492,
            "mae": 0.31523126865700546,
            "precision": 0.769857433808554,
            "recall": 0.7891440501043842
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8700798892656898,
            "auditor_fn_violation": 0.007760124790571384,
            "auditor_fp_violation": 0.009405935608616404,
            "ave_precision_score": 0.8703200640464792,
            "fpr": 0.09659714599341383,
            "logloss": 0.47391095683895296,
            "mae": 0.30119316384305045,
            "precision": 0.8131634819532909,
            "recall": 0.8063157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8169195965296989,
            "auditor_fn_violation": 0.01188285170127826,
            "auditor_fp_violation": 0.015518009805113251,
            "ave_precision_score": 0.8162554103184742,
            "fpr": 0.11732456140350878,
            "logloss": 1.0579396675914226,
            "mae": 0.28625850405026443,
            "precision": 0.7611607142857143,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8638654382462612,
            "auditor_fn_violation": 0.015617308914437578,
            "auditor_fp_violation": 0.01259327888498374,
            "ave_precision_score": 0.8640219365903352,
            "fpr": 0.10318331503841932,
            "logloss": 0.9058459416566207,
            "mae": 0.25915614915701946,
            "precision": 0.7897091722595079,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8187355062361679,
            "auditor_fn_violation": 0.009355656887521518,
            "auditor_fp_violation": 0.015092581337871235,
            "ave_precision_score": 0.817958141873258,
            "fpr": 0.11293859649122807,
            "logloss": 0.9841882782419245,
            "mae": 0.2833539009253076,
            "precision": 0.7680180180180181,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8661067108433262,
            "auditor_fn_violation": 0.01566352764457797,
            "auditor_fp_violation": 0.008252852495996938,
            "ave_precision_score": 0.8662595765621286,
            "fpr": 0.09330406147091108,
            "logloss": 0.8162595719276462,
            "mae": 0.2534720970162892,
            "precision": 0.8036951501154734,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.660999749818719,
            "auditor_fn_violation": 0.012214774933157533,
            "auditor_fp_violation": 0.007748875653336586,
            "ave_precision_score": 0.5229947556354654,
            "fpr": 0.28728070175438597,
            "logloss": 16.01531895575971,
            "mae": 0.4900370228375435,
            "precision": 0.5304659498207885,
            "recall": 0.6179540709812108
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6905200103874066,
            "auditor_fn_violation": 0.007249407822520081,
            "auditor_fp_violation": 0.01517638646914875,
            "ave_precision_score": 0.5529786384505408,
            "fpr": 0.25905598243688255,
            "logloss": 14.489576515667755,
            "mae": 0.4390707536768113,
            "precision": 0.5701275045537341,
            "recall": 0.6589473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8492224623764574,
            "auditor_fn_violation": 0.003770190089001215,
            "auditor_fp_violation": 0.00594586929216807,
            "ave_precision_score": 0.8473451668895049,
            "fpr": 0.08662280701754387,
            "logloss": 1.0881118193568056,
            "mae": 0.24891934149044773,
            "precision": 0.8110047846889952,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8868918350988193,
            "auditor_fn_violation": 0.01150846380495696,
            "auditor_fp_violation": 0.004826332591466183,
            "ave_precision_score": 0.8870106181832573,
            "fpr": 0.06915477497255763,
            "logloss": 0.85275627488297,
            "mae": 0.2168552971086322,
            "precision": 0.8492822966507177,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8172754004462327,
            "auditor_fn_violation": 0.013611141632787614,
            "auditor_fp_violation": 0.017460293343057418,
            "ave_precision_score": 0.8168181887933863,
            "fpr": 0.11513157894736842,
            "logloss": 1.0307292174459954,
            "mae": 0.28451402552717653,
            "precision": 0.7645739910313901,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8641088894898112,
            "auditor_fn_violation": 0.01513663412097753,
            "auditor_fp_violation": 0.009335441444526131,
            "ave_precision_score": 0.8642671265295593,
            "fpr": 0.09879253567508232,
            "logloss": 0.9066632233679732,
            "mae": 0.2568194311739309,
            "precision": 0.7959183673469388,
            "recall": 0.7389473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8212679210677098,
            "auditor_fn_violation": 0.010628410797348282,
            "auditor_fp_violation": 0.011977837202706539,
            "ave_precision_score": 0.8206182613131859,
            "fpr": 0.09978070175438597,
            "logloss": 1.0576227090753905,
            "mae": 0.2841401736482062,
            "precision": 0.7833333333333333,
            "recall": 0.6868475991649269
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8695206256002244,
            "auditor_fn_violation": 0.010815182852851124,
            "auditor_fp_violation": 0.00893261764972457,
            "ave_precision_score": 0.8696665793445683,
            "fpr": 0.07903402854006586,
            "logloss": 0.9063968089416828,
            "mae": 0.2523218202044343,
            "precision": 0.8213399503722084,
            "recall": 0.6968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7768311698762096,
            "auditor_fn_violation": 0.011461652565652127,
            "auditor_fp_violation": 0.01799714355171995,
            "ave_precision_score": 0.7775643786834079,
            "fpr": 0.1524122807017544,
            "logloss": 1.131870651228927,
            "mae": 0.2935218721338439,
            "precision": 0.7225548902195609,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8165192111922648,
            "auditor_fn_violation": 0.013197758391588193,
            "auditor_fp_violation": 0.01626904601254796,
            "ave_precision_score": 0.8169156261599748,
            "fpr": 0.13830954994511527,
            "logloss": 1.0897975126410826,
            "mae": 0.27170664681582063,
            "precision": 0.7439024390243902,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 8653,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8510477144903645,
            "auditor_fn_violation": 0.005120774273889318,
            "auditor_fp_violation": 0.004970929054738464,
            "ave_precision_score": 0.7886527066574954,
            "fpr": 0.08991228070175439,
            "logloss": 6.883279801672934,
            "mae": 0.2338986413714435,
            "precision": 0.8101851851851852,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8530090133273613,
            "auditor_fn_violation": 0.0008712230631463395,
            "auditor_fp_violation": 0.012175349197877123,
            "ave_precision_score": 0.7914742280628562,
            "fpr": 0.08342480790340286,
            "logloss": 6.666252852214504,
            "mae": 0.22729475682034062,
            "precision": 0.8203309692671394,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7896007421763103,
            "auditor_fn_violation": 0.013318133538439003,
            "auditor_fp_violation": 0.018860662047729022,
            "ave_precision_score": 0.7901888311702968,
            "fpr": 0.14144736842105263,
            "logloss": 1.0242498977737324,
            "mae": 0.28779786133261714,
            "precision": 0.7345679012345679,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8346916111605099,
            "auditor_fn_violation": 0.01864925761164712,
            "auditor_fp_violation": 0.018489612181391557,
            "ave_precision_score": 0.8349488179328525,
            "fpr": 0.132821075740944,
            "logloss": 0.9953303851175046,
            "mae": 0.2679555131672045,
            "precision": 0.7510288065843621,
            "recall": 0.7684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8409860127440916,
            "auditor_fn_violation": 0.0036740468080430798,
            "auditor_fp_violation": 0.003719966776062559,
            "ave_precision_score": 0.7634939102434283,
            "fpr": 0.10197368421052631,
            "logloss": 7.741378589301244,
            "mae": 0.24565029929582016,
            "precision": 0.7886363636363637,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8380140053584206,
            "auditor_fn_violation": 0.003477959443064308,
            "auditor_fp_violation": 0.007809746321715223,
            "ave_precision_score": 0.7555668784598979,
            "fpr": 0.10428100987925357,
            "logloss": 7.791298419382259,
            "mae": 0.24508061660324926,
            "precision": 0.7855530474040632,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.818514116676683,
            "auditor_fn_violation": 0.010003479471120394,
            "auditor_fp_violation": 0.016695535026943802,
            "ave_precision_score": 0.8177093085090839,
            "fpr": 0.11513157894736842,
            "logloss": 0.9731180266722633,
            "mae": 0.2845798863830943,
            "precision": 0.7640449438202247,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8663013261044964,
            "auditor_fn_violation": 0.016250505517360916,
            "auditor_fp_violation": 0.009350547336831189,
            "ave_precision_score": 0.86645448653839,
            "fpr": 0.09330406147091108,
            "logloss": 0.8023339060830594,
            "mae": 0.25382004900176874,
            "precision": 0.804147465437788,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8178930197658123,
            "auditor_fn_violation": 0.009428908911108678,
            "auditor_fp_violation": 0.013955573112920878,
            "ave_precision_score": 0.8173276399601479,
            "fpr": 0.10964912280701754,
            "logloss": 1.0177797332930612,
            "mae": 0.2857164279003818,
            "precision": 0.771689497716895,
            "recall": 0.7056367432150313
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.866150657752855,
            "auditor_fn_violation": 0.01447108440695592,
            "auditor_fp_violation": 0.007401887229478645,
            "ave_precision_score": 0.8663039565067762,
            "fpr": 0.09220636663007684,
            "logloss": 0.8683074599300795,
            "mae": 0.2572514644524665,
            "precision": 0.8051044083526682,
            "recall": 0.7305263157894737
        }
    }
]