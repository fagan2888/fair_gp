[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8432692118260354,
            "auditor_fn_violation": 0.036795843564285974,
            "auditor_fp_violation": 0.02058472553699284,
            "ave_precision_score": 0.843729278265023,
            "fpr": 0.11293859649122807,
            "logloss": 0.8600639721625313,
            "mae": 0.2698192751076727,
            "precision": 0.783157894736842,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8275714176189869,
            "auditor_fn_violation": 0.03262606227572856,
            "auditor_fp_violation": 0.027813147944871323,
            "ave_precision_score": 0.8289704165105192,
            "fpr": 0.1163556531284303,
            "logloss": 0.7374555488185383,
            "mae": 0.27015204775424434,
            "precision": 0.7644444444444445,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8209760252051074,
            "auditor_fn_violation": 0.04232723034767446,
            "auditor_fp_violation": 0.02673973118954905,
            "ave_precision_score": 0.8215146919945004,
            "fpr": 0.12390350877192982,
            "logloss": 0.731981103671911,
            "mae": 0.32250128095591196,
            "precision": 0.7635983263598326,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8199950779054433,
            "auditor_fn_violation": 0.035895335630317333,
            "auditor_fp_violation": 0.023197950969630444,
            "ave_precision_score": 0.8208396254492467,
            "fpr": 0.09330406147091108,
            "logloss": 0.628477306689633,
            "mae": 0.3087886425092746,
            "precision": 0.7956730769230769,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8469796393197071,
            "auditor_fn_violation": 0.018818280488238855,
            "auditor_fp_violation": 0.024046916216555716,
            "ave_precision_score": 0.8472684752091513,
            "fpr": 0.14035087719298245,
            "logloss": 0.6786101031197337,
            "mae": 0.2717930438226623,
            "precision": 0.751937984496124,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.842267895606912,
            "auditor_fn_violation": 0.0034978605665629326,
            "auditor_fp_violation": 0.024598121722161245,
            "ave_precision_score": 0.8426281320662398,
            "fpr": 0.14709110867178923,
            "logloss": 0.6766009784587609,
            "mae": 0.27260139534601574,
            "precision": 0.7276422764227642,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8184943624600365,
            "auditor_fn_violation": 0.027628020355147512,
            "auditor_fp_violation": 0.023507829837122646,
            "ave_precision_score": 0.8197672420718947,
            "fpr": 0.13706140350877194,
            "logloss": 0.7918860235051564,
            "mae": 0.2829066057322882,
            "precision": 0.7504990019960079,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8132340304058678,
            "auditor_fn_violation": 0.014396232120789299,
            "auditor_fp_violation": 0.030332967435053055,
            "ave_precision_score": 0.8135559531687534,
            "fpr": 0.145993413830955,
            "logloss": 0.761909548207558,
            "mae": 0.2791639636973058,
            "precision": 0.7257731958762886,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8211295154181494,
            "auditor_fn_violation": 0.03615084872424469,
            "auditor_fp_violation": 0.029403759996650337,
            "ave_precision_score": 0.8216355094001085,
            "fpr": 0.14473684210526316,
            "logloss": 1.428711246894918,
            "mae": 0.2809872947791473,
            "precision": 0.7426900584795322,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7923091058708083,
            "auditor_fn_violation": 0.0331665757873758,
            "auditor_fp_violation": 0.03724356628857178,
            "ave_precision_score": 0.7933103123534679,
            "fpr": 0.150384193194292,
            "logloss": 1.3053853196936718,
            "mae": 0.2884997480568997,
            "precision": 0.7151767151767152,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8580280220193919,
            "auditor_fn_violation": 0.02531493541155119,
            "auditor_fp_violation": 0.016026043629359804,
            "ave_precision_score": 0.8582411931453425,
            "fpr": 0.09320175438596491,
            "logloss": 0.6078908756640432,
            "mae": 0.27541474835596635,
            "precision": 0.8098434004474273,
            "recall": 0.7342799188640974
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8523010867226798,
            "auditor_fn_violation": 0.0023525433899007353,
            "auditor_fp_violation": 0.017685083546773995,
            "ave_precision_score": 0.853023594521126,
            "fpr": 0.10976948408342481,
            "logloss": 0.5810520612375698,
            "mae": 0.2672010646525614,
            "precision": 0.7727272727272727,
            "recall": 0.737527114967462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8583657003730313,
            "auditor_fn_violation": 0.030332550443044733,
            "auditor_fp_violation": 0.023497362140434623,
            "ave_precision_score": 0.8585665351565127,
            "fpr": 0.125,
            "logloss": 0.6978435610368819,
            "mae": 0.26629910863787226,
            "precision": 0.7724550898203593,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8414570410573412,
            "auditor_fn_violation": 0.019941853127954077,
            "auditor_fp_violation": 0.023419929259665823,
            "ave_precision_score": 0.8422526176036665,
            "fpr": 0.13062568605927552,
            "logloss": 0.6460770222437867,
            "mae": 0.2625638450640457,
            "precision": 0.750524109014675,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8593787870405445,
            "auditor_fn_violation": 0.03323725134336856,
            "auditor_fp_violation": 0.025525478373738652,
            "ave_precision_score": 0.8595843600356958,
            "fpr": 0.12719298245614036,
            "logloss": 0.7516083900894918,
            "mae": 0.2617241605257571,
            "precision": 0.7738791423001949,
            "recall": 0.8052738336713996
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8375539879732123,
            "auditor_fn_violation": 0.026968528779368103,
            "auditor_fp_violation": 0.028613245517746067,
            "ave_precision_score": 0.8389239624857605,
            "fpr": 0.1251372118551043,
            "logloss": 0.6859608179935053,
            "mae": 0.2590490006146138,
            "precision": 0.7574468085106383,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8638673503621007,
            "auditor_fn_violation": 0.0381636774492011,
            "auditor_fp_violation": 0.03106550684587363,
            "ave_precision_score": 0.8640418115238437,
            "fpr": 0.1513157894736842,
            "logloss": 0.6019132817912333,
            "mae": 0.29247518322781263,
            "precision": 0.7444444444444445,
            "recall": 0.8154158215010142
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.851464918425117,
            "auditor_fn_violation": 0.03279988380150058,
            "auditor_fp_violation": 0.03767776558116844,
            "ave_precision_score": 0.8527606226335949,
            "fpr": 0.132821075740944,
            "logloss": 0.5250698884330702,
            "mae": 0.2765237720798097,
            "precision": 0.7555555555555555,
            "recall": 0.8112798264642083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8519713423176132,
            "auditor_fn_violation": 0.035339044873847904,
            "auditor_fp_violation": 0.020637064020432947,
            "ave_precision_score": 0.8521827041254553,
            "fpr": 0.10855263157894737,
            "logloss": 0.8664948637546684,
            "mae": 0.26939586109700475,
            "precision": 0.7884615384615384,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8303808701094829,
            "auditor_fn_violation": 0.0318307692674018,
            "auditor_fp_violation": 0.02676180021953897,
            "ave_precision_score": 0.8317726289774376,
            "fpr": 0.11086717892425905,
            "logloss": 0.7525407784053387,
            "mae": 0.26967894400738973,
            "precision": 0.769406392694064,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8278378062292798,
            "auditor_fn_violation": 0.025165919362300275,
            "auditor_fp_violation": 0.012773206883557342,
            "ave_precision_score": 0.8281095605629449,
            "fpr": 0.07894736842105263,
            "logloss": 0.7392896993255343,
            "mae": 0.31867664628688336,
            "precision": 0.8105263157894737,
            "recall": 0.6247464503042597
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.82019255957525,
            "auditor_fn_violation": 0.005243219174657306,
            "auditor_fp_violation": 0.018360775704354192,
            "ave_precision_score": 0.820948713575177,
            "fpr": 0.09549945115257959,
            "logloss": 0.6858191751024066,
            "mae": 0.30655827493885784,
            "precision": 0.7648648648648648,
            "recall": 0.613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8587349885642827,
            "auditor_fn_violation": 0.03234315504786307,
            "auditor_fp_violation": 0.028485219612276513,
            "ave_precision_score": 0.8589377772104153,
            "fpr": 0.13157894736842105,
            "logloss": 0.7234027426789941,
            "mae": 0.26561492430345107,
            "precision": 0.7637795275590551,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8398683091769443,
            "auditor_fn_violation": 0.019934709777579884,
            "auditor_fp_violation": 0.028627881448957188,
            "ave_precision_score": 0.8411719000726989,
            "fpr": 0.12733260153677278,
            "logloss": 0.6630914450873379,
            "mae": 0.26118456788541783,
            "precision": 0.7547568710359408,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8542154281850673,
            "auditor_fn_violation": 0.030708426746379133,
            "auditor_fp_violation": 0.026098584767407777,
            "ave_precision_score": 0.8544341421229384,
            "fpr": 0.14144736842105263,
            "logloss": 0.7337718112718812,
            "mae": 0.2679322572521327,
            "precision": 0.7504835589941973,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8363122893088302,
            "auditor_fn_violation": 0.015748706458303074,
            "auditor_fp_violation": 0.029476765459202345,
            "ave_precision_score": 0.8376410078471215,
            "fpr": 0.14489571899012074,
            "logloss": 0.6841918650106159,
            "mae": 0.26435683730519194,
            "precision": 0.7344064386317908,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8252855596243072,
            "auditor_fn_violation": 0.02714538628518558,
            "auditor_fp_violation": 0.017564795042498853,
            "ave_precision_score": 0.8256021758773386,
            "fpr": 0.11293859649122807,
            "logloss": 0.875806788973774,
            "mae": 0.2803965532332541,
            "precision": 0.7817796610169492,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7872529866435497,
            "auditor_fn_violation": 0.030068742841767648,
            "auditor_fp_violation": 0.025251859982924754,
            "ave_precision_score": 0.7880414589001403,
            "fpr": 0.12952799121844127,
            "logloss": 0.8080728179831096,
            "mae": 0.28707861500121634,
            "precision": 0.7429193899782135,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8509526151527004,
            "auditor_fn_violation": 0.019303138678338855,
            "auditor_fp_violation": 0.02150064899719467,
            "ave_precision_score": 0.8512472626415973,
            "fpr": 0.15789473684210525,
            "logloss": 0.6162657180216493,
            "mae": 0.2705363109210004,
            "precision": 0.740072202166065,
            "recall": 0.8316430020283976
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8496223400020312,
            "auditor_fn_violation": 0.003495479449771537,
            "auditor_fp_violation": 0.024588364434687156,
            "ave_precision_score": 0.8500166768787227,
            "fpr": 0.16575192096597147,
            "logloss": 0.6199627495985198,
            "mae": 0.2718271330562773,
            "precision": 0.7166979362101313,
            "recall": 0.8286334056399133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8521775516926896,
            "auditor_fn_violation": 0.03491201380733783,
            "auditor_fp_violation": 0.023991960808943606,
            "ave_precision_score": 0.8523950908479685,
            "fpr": 0.11842105263157894,
            "logloss": 0.8479787269081415,
            "mae": 0.27408745924455974,
            "precision": 0.7740585774058577,
            "recall": 0.7505070993914807
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8314699274726901,
            "auditor_fn_violation": 0.03279988380150058,
            "auditor_fp_violation": 0.027530186608122943,
            "ave_precision_score": 0.8322654426989962,
            "fpr": 0.11855104281009879,
            "logloss": 0.7404536840548158,
            "mae": 0.2758985301326624,
            "precision": 0.7573033707865169,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.827815146108752,
            "auditor_fn_violation": 0.03662236219351625,
            "auditor_fp_violation": 0.02319641586065403,
            "ave_precision_score": 0.8283166021726059,
            "fpr": 0.12171052631578948,
            "logloss": 0.8593820428360451,
            "mae": 0.277380971579665,
            "precision": 0.7748478701825557,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8062602682049995,
            "auditor_fn_violation": 0.030454483761974047,
            "auditor_fp_violation": 0.029749969508476647,
            "ave_precision_score": 0.8070125124825226,
            "fpr": 0.12952799121844127,
            "logloss": 0.7670306199003224,
            "mae": 0.2792200609572989,
            "precision": 0.7473233404710921,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 7376,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8178281520654473,
            "auditor_fn_violation": 0.029476264189886484,
            "auditor_fp_violation": 0.04005725830088348,
            "ave_precision_score": 0.8126306082046988,
            "fpr": 0.2050438596491228,
            "logloss": 1.3437316417919127,
            "mae": 0.2866483857680478,
            "precision": 0.6993569131832797,
            "recall": 0.8823529411764706
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7935199820257357,
            "auditor_fn_violation": 0.02904248150467532,
            "auditor_fp_violation": 0.04830833028418101,
            "ave_precision_score": 0.7881885687156944,
            "fpr": 0.1964873765093304,
            "logloss": 1.2848535395457816,
            "mae": 0.2913273234984419,
            "precision": 0.6897746967071057,
            "recall": 0.8633405639913232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8392388028419642,
            "auditor_fn_violation": 0.017256948151311347,
            "auditor_fp_violation": 0.020835950257505342,
            "ave_precision_score": 0.8396418309908132,
            "fpr": 0.13157894736842105,
            "logloss": 0.676230461948434,
            "mae": 0.2712275288865002,
            "precision": 0.7623762376237624,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8395938640310117,
            "auditor_fn_violation": 0.004333632560343454,
            "auditor_fp_violation": 0.02318331503841932,
            "ave_precision_score": 0.8400381364406059,
            "fpr": 0.13611416026344675,
            "logloss": 0.6580718376870096,
            "mae": 0.2680876934470592,
            "precision": 0.7422037422037422,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8397061498597563,
            "auditor_fn_violation": 0.018317853457172347,
            "auditor_fp_violation": 0.023547083699702723,
            "ave_precision_score": 0.84015037184701,
            "fpr": 0.1337719298245614,
            "logloss": 0.6665499277381891,
            "mae": 0.2702066014288117,
            "precision": 0.758893280632411,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8407446713546577,
            "auditor_fn_violation": 0.005238456941074504,
            "auditor_fp_violation": 0.022436882546652038,
            "ave_precision_score": 0.8412778970259547,
            "fpr": 0.13830954994511527,
            "logloss": 0.6457626612845362,
            "mae": 0.2664203449157298,
            "precision": 0.7407407407407407,
            "recall": 0.7809110629067245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8138478855741429,
            "auditor_fn_violation": 0.01891391765417601,
            "auditor_fp_violation": 0.01986768831386342,
            "ave_precision_score": 0.8151109476155805,
            "fpr": 0.14692982456140352,
            "logloss": 0.7497717013694716,
            "mae": 0.291745076885702,
            "precision": 0.7351778656126482,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8116100475894341,
            "auditor_fn_violation": 0.008810132128170755,
            "auditor_fp_violation": 0.025808025368947433,
            "ave_precision_score": 0.8118960479312805,
            "fpr": 0.15916575192096596,
            "logloss": 0.7578031310734039,
            "mae": 0.290259221347362,
            "precision": 0.7094188376753507,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8376588752814952,
            "auditor_fn_violation": 0.029264972776769514,
            "auditor_fp_violation": 0.028006322488799574,
            "ave_precision_score": 0.837959539743272,
            "fpr": 0.13815789473684212,
            "logloss": 0.6757640607717548,
            "mae": 0.2831308649656381,
            "precision": 0.7567567567567568,
            "recall": 0.795131845841785
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8226296973964198,
            "auditor_fn_violation": 0.012093692183507913,
            "auditor_fp_violation": 0.033735821441639224,
            "ave_precision_score": 0.8234316334912343,
            "fpr": 0.14489571899012074,
            "logloss": 0.6469799501361887,
            "mae": 0.2764653986292239,
            "precision": 0.7396449704142012,
            "recall": 0.8134490238611713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.821040341528845,
            "auditor_fn_violation": 0.01583795950322053,
            "auditor_fp_violation": 0.024586002595988782,
            "ave_precision_score": 0.8127308314883285,
            "fpr": 0.18092105263157895,
            "logloss": 1.1474715348303957,
            "mae": 0.2703543077122161,
            "precision": 0.729064039408867,
            "recall": 0.9006085192697769
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.790714342112178,
            "auditor_fn_violation": 0.0008738698624428824,
            "auditor_fp_violation": 0.022685693377241127,
            "ave_precision_score": 0.7826229158445822,
            "fpr": 0.19209659714599342,
            "logloss": 1.269799161591273,
            "mae": 0.29181429452230107,
            "precision": 0.7038917089678511,
            "recall": 0.9023861171366594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 7376,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8129414046673586,
            "auditor_fn_violation": 0.03935580584320843,
            "auditor_fp_violation": 0.015882112799899508,
            "ave_precision_score": 0.8094689064606252,
            "fpr": 0.10307017543859649,
            "logloss": 1.1842271239749569,
            "mae": 0.2754803367035454,
            "precision": 0.8,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7871892591729353,
            "auditor_fn_violation": 0.03616916406132805,
            "auditor_fp_violation": 0.025449445054274916,
            "ave_precision_score": 0.7843686765832285,
            "fpr": 0.11745334796926454,
            "logloss": 1.1238814342848535,
            "mae": 0.28234351730656976,
            "precision": 0.7600896860986547,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8449880959853053,
            "auditor_fn_violation": 0.04379514963880289,
            "auditor_fp_violation": 0.021605325964074863,
            "ave_precision_score": 0.8452047918823207,
            "fpr": 0.09320175438596491,
            "logloss": 0.7230713124196163,
            "mae": 0.3148916856762193,
            "precision": 0.8036951501154734,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8332347060288263,
            "auditor_fn_violation": 0.04185288984239389,
            "auditor_fp_violation": 0.021741675814123673,
            "ave_precision_score": 0.8337236954850917,
            "fpr": 0.06695938529088913,
            "logloss": 0.6196479790591033,
            "mae": 0.29957066112881775,
            "precision": 0.8377659574468085,
            "recall": 0.6832971800433839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8497391804285889,
            "auditor_fn_violation": 0.016818796484110894,
            "auditor_fp_violation": 0.0197577774986392,
            "ave_precision_score": 0.8500472312639276,
            "fpr": 0.1337719298245614,
            "logloss": 0.6270755716223859,
            "mae": 0.26695588842443485,
            "precision": 0.7626459143968871,
            "recall": 0.795131845841785
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8471476357004702,
            "auditor_fn_violation": 6.905238695053021e-05,
            "auditor_fp_violation": 0.022919868276619106,
            "ave_precision_score": 0.8475858865793531,
            "fpr": 0.13830954994511527,
            "logloss": 0.6149624292302514,
            "mae": 0.26521568627318876,
            "precision": 0.744421906693712,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8554289361400506,
            "auditor_fn_violation": 0.03221860432013096,
            "auditor_fp_violation": 0.021435225892894535,
            "ave_precision_score": 0.8556423382188258,
            "fpr": 0.1118421052631579,
            "logloss": 0.8124308152015396,
            "mae": 0.2675464807745295,
            "precision": 0.7879417879417879,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8356252655433312,
            "auditor_fn_violation": 0.02985682344733327,
            "auditor_fp_violation": 0.02597877789974387,
            "ave_precision_score": 0.8369939442020289,
            "fpr": 0.11525795828759605,
            "logloss": 0.700455094817155,
            "mae": 0.266563724664843,
            "precision": 0.7661469933184856,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8517590740562827,
            "auditor_fn_violation": 0.030641703142236937,
            "auditor_fp_violation": 0.021770192186911203,
            "ave_precision_score": 0.8520340159498745,
            "fpr": 0.12609649122807018,
            "logloss": 0.7386066200733306,
            "mae": 0.2687100348420749,
            "precision": 0.7722772277227723,
            "recall": 0.7910750507099391
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8358925185336121,
            "auditor_fn_violation": 0.024511216250645885,
            "auditor_fp_violation": 0.027608244907915604,
            "ave_precision_score": 0.8362997054760454,
            "fpr": 0.12952799121844127,
            "logloss": 0.6948522741150639,
            "mae": 0.2669570005099707,
            "precision": 0.7510548523206751,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8503828241147938,
            "auditor_fn_violation": 0.0202684068182627,
            "auditor_fp_violation": 0.021903655319683454,
            "ave_precision_score": 0.8507719628180594,
            "fpr": 0.13267543859649122,
            "logloss": 0.6055249015173625,
            "mae": 0.26720015447916556,
            "precision": 0.7655038759689923,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8529957207855662,
            "auditor_fn_violation": 0.0029478225877501104,
            "auditor_fp_violation": 0.022990608610806193,
            "ave_precision_score": 0.8534117178906737,
            "fpr": 0.1437980241492865,
            "logloss": 0.5950285698275752,
            "mae": 0.26382875938020756,
            "precision": 0.7395626242544732,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8543210764602049,
            "auditor_fn_violation": 0.0198169104302338,
            "auditor_fp_violation": 0.014644307666541054,
            "ave_precision_score": 0.8545780981414597,
            "fpr": 0.10307017543859649,
            "logloss": 0.6086636172103893,
            "mae": 0.2729454389970526,
            "precision": 0.7952069716775599,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.852655966526953,
            "auditor_fn_violation": 0.0025763683682921003,
            "auditor_fp_violation": 0.020778143676058063,
            "ave_precision_score": 0.8531186477242305,
            "fpr": 0.1141602634467618,
            "logloss": 0.5858259538492175,
            "mae": 0.2659913951836595,
            "precision": 0.7719298245614035,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8456486078591605,
            "auditor_fn_violation": 0.03347968043841856,
            "auditor_fp_violation": 0.026030544738935648,
            "ave_precision_score": 0.8459310078693103,
            "fpr": 0.15021929824561403,
            "logloss": 0.8329863409990598,
            "mae": 0.2670563423439647,
            "precision": 0.7434456928838952,
            "recall": 0.8052738336713996
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8369179879572617,
            "auditor_fn_violation": 0.021749120772624773,
            "auditor_fp_violation": 0.02985729967069155,
            "ave_precision_score": 0.8374093365642229,
            "fpr": 0.145993413830955,
            "logloss": 0.7611075015646691,
            "mae": 0.26213423310780243,
            "precision": 0.7318548387096774,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8519188938377664,
            "auditor_fn_violation": 0.020324009821714534,
            "auditor_fp_violation": 0.02072603944228112,
            "ave_precision_score": 0.8522838994510071,
            "fpr": 0.13048245614035087,
            "logloss": 0.6246194444057263,
            "mae": 0.263276710445357,
            "precision": 0.767578125,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8555356380912265,
            "auditor_fn_violation": 0.00279543111310067,
            "auditor_fp_violation": 0.021295279912184422,
            "ave_precision_score": 0.8558973969866661,
            "fpr": 0.14270032930845225,
            "logloss": 0.6109088013847902,
            "mae": 0.2595045117997089,
            "precision": 0.74,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8514115700668115,
            "auditor_fn_violation": 0.020152752571082885,
            "auditor_fp_violation": 0.021338399698530346,
            "ave_precision_score": 0.8517161633063304,
            "fpr": 0.12719298245614036,
            "logloss": 0.60147720414553,
            "mae": 0.26987955706978317,
            "precision": 0.7712031558185405,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.851834012160061,
            "auditor_fn_violation": 0.0013477121039309867,
            "auditor_fp_violation": 0.02065617758263203,
            "ave_precision_score": 0.8521779932160143,
            "fpr": 0.1437980241492865,
            "logloss": 0.5957798436613596,
            "mae": 0.26828857618739316,
            "precision": 0.7358870967741935,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8504348441861176,
            "auditor_fn_violation": 0.019392103483861785,
            "auditor_fp_violation": 0.020995582631997654,
            "ave_precision_score": 0.8506980814455237,
            "fpr": 0.13157894736842105,
            "logloss": 0.6348978189174249,
            "mae": 0.27145917097933353,
            "precision": 0.7628458498023716,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.846486141450449,
            "auditor_fn_violation": 0.0020525226741846454,
            "auditor_fp_violation": 0.022612513721185515,
            "ave_precision_score": 0.846859628050211,
            "fpr": 0.14818880351262348,
            "logloss": 0.6282516158763869,
            "mae": 0.2694943503924706,
            "precision": 0.7305389221556886,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.834282883206551,
            "auditor_fn_violation": 0.04964013736165973,
            "auditor_fp_violation": 0.03170665326801491,
            "ave_precision_score": 0.834370767411853,
            "fpr": 0.12171052631578948,
            "logloss": 1.5546675200677955,
            "mae": 0.3171460658620039,
            "precision": 0.7612903225806451,
            "recall": 0.718052738336714
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8108801091443187,
            "auditor_fn_violation": 0.049103390472199276,
            "auditor_fp_violation": 0.03695572630808635,
            "ave_precision_score": 0.8121092843487416,
            "fpr": 0.10976948408342481,
            "logloss": 1.3429592436210627,
            "mae": 0.3074032594556283,
            "precision": 0.7619047619047619,
            "recall": 0.6941431670281996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8620750243663509,
            "auditor_fn_violation": 0.0317137290487883,
            "auditor_fp_violation": 0.02612737093329984,
            "ave_precision_score": 0.8622739719483478,
            "fpr": 0.1337719298245614,
            "logloss": 0.6815819020722514,
            "mae": 0.26559679252087576,
            "precision": 0.7649325626204239,
            "recall": 0.8052738336713996
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8475420237440091,
            "auditor_fn_violation": 0.018401270563919894,
            "auditor_fp_violation": 0.028235150628125382,
            "ave_precision_score": 0.8482804181087531,
            "fpr": 0.13721185510428102,
            "logloss": 0.622996265307052,
            "mae": 0.25938746162606857,
            "precision": 0.7448979591836735,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8375889841026878,
            "auditor_fn_violation": 0.052102238354506954,
            "auditor_fp_violation": 0.03539389942637023,
            "ave_precision_score": 0.8377956677837294,
            "fpr": 0.13596491228070176,
            "logloss": 0.9627396388242818,
            "mae": 0.3167241947775127,
            "precision": 0.751004016064257,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.817649907903012,
            "auditor_fn_violation": 0.05020346642982491,
            "auditor_fp_violation": 0.04482985729967069,
            "ave_precision_score": 0.8190113523809417,
            "fpr": 0.12952799121844127,
            "logloss": 0.8386929995341156,
            "mae": 0.30827368812405054,
            "precision": 0.7429193899782135,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8540485603434103,
            "auditor_fn_violation": 0.03142904167111491,
            "auditor_fp_violation": 0.027195075995477956,
            "ave_precision_score": 0.8542696773179763,
            "fpr": 0.14144736842105263,
            "logloss": 0.747530511414929,
            "mae": 0.26720340449413504,
            "precision": 0.75,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8358338710397649,
            "auditor_fn_violation": 0.017220236635386733,
            "auditor_fp_violation": 0.027125259177948544,
            "ave_precision_score": 0.8371649003940513,
            "fpr": 0.14270032930845225,
            "logloss": 0.6914844382263627,
            "mae": 0.26388850293518706,
            "precision": 0.7363083164300203,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.837635330779801,
            "auditor_fn_violation": 0.030857442795630054,
            "auditor_fp_violation": 0.024531047188376672,
            "ave_precision_score": 0.8378939326575803,
            "fpr": 0.13486842105263158,
            "logloss": 0.9151834511931978,
            "mae": 0.2749315028664167,
            "precision": 0.7583497053045186,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8117617043361193,
            "auditor_fn_violation": 0.030968804988915903,
            "auditor_fp_violation": 0.02978168069276742,
            "ave_precision_score": 0.8122096910117779,
            "fpr": 0.1394072447859495,
            "logloss": 0.8353996181554015,
            "mae": 0.2799817539928873,
            "precision": 0.7326315789473684,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8502203864824501,
            "auditor_fn_violation": 0.020421871107789757,
            "auditor_fp_violation": 0.021903655319683454,
            "ave_precision_score": 0.8506100928844589,
            "fpr": 0.13267543859649122,
            "logloss": 0.603369694471863,
            "mae": 0.26735913440539627,
            "precision": 0.7650485436893204,
            "recall": 0.7991886409736308
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8539017885926848,
            "auditor_fn_violation": 0.0036764443259177464,
            "auditor_fp_violation": 0.023754116355653127,
            "ave_precision_score": 0.8543100722644386,
            "fpr": 0.14050493962678376,
            "logloss": 0.590990953501375,
            "mae": 0.26341501826023134,
            "precision": 0.7429718875502008,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8554682808923295,
            "auditor_fn_violation": 0.02373358599338102,
            "auditor_fp_violation": 0.02110811037139389,
            "ave_precision_score": 0.8556866320425949,
            "fpr": 0.12828947368421054,
            "logloss": 0.6552473743774183,
            "mae": 0.26763478614668457,
            "precision": 0.7655310621242485,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8471931065017448,
            "auditor_fn_violation": 0.010250707786966247,
            "auditor_fp_violation": 0.02529088913282107,
            "ave_precision_score": 0.8475857893051009,
            "fpr": 0.13611416026344675,
            "logloss": 0.6406386065634789,
            "mae": 0.2646129307146205,
            "precision": 0.7448559670781894,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8267561441807656,
            "auditor_fn_violation": 0.027114248603252556,
            "auditor_fp_violation": 0.025064899719465728,
            "ave_precision_score": 0.8279851234921668,
            "fpr": 0.1513157894736842,
            "logloss": 0.8357561619525145,
            "mae": 0.279151917643185,
            "precision": 0.7371428571428571,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8121733813076562,
            "auditor_fn_violation": 0.016474947079679315,
            "auditor_fp_violation": 0.028920600073179658,
            "ave_precision_score": 0.8125506093384942,
            "fpr": 0.15148188803512624,
            "logloss": 0.8367347959356383,
            "mae": 0.27574261757746504,
            "precision": 0.724,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8344262184814818,
            "auditor_fn_violation": 0.033372922671791046,
            "auditor_fp_violation": 0.0273651760666583,
            "ave_precision_score": 0.8346800164411479,
            "fpr": 0.12719298245614036,
            "logloss": 0.9367216033786296,
            "mae": 0.28097614901901774,
            "precision": 0.7578288100208769,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8036746547077775,
            "auditor_fn_violation": 0.02648516207071441,
            "auditor_fp_violation": 0.03099158433955361,
            "ave_precision_score": 0.8043816433504867,
            "fpr": 0.12623490669593854,
            "logloss": 0.8651921822690434,
            "mae": 0.286357624834551,
            "precision": 0.7433035714285714,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8384751906842753,
            "auditor_fn_violation": 0.03690704957118964,
            "auditor_fp_violation": 0.02223077084118411,
            "ave_precision_score": 0.8387590144805603,
            "fpr": 0.09649122807017543,
            "logloss": 0.8101679270285552,
            "mae": 0.2828005531253069,
            "precision": 0.7990867579908676,
            "recall": 0.7099391480730223
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8189015101506631,
            "auditor_fn_violation": 0.03313562126908764,
            "auditor_fp_violation": 0.02674960361019637,
            "ave_precision_score": 0.8195689526379241,
            "fpr": 0.10647639956092206,
            "logloss": 0.7236957004229078,
            "mae": 0.28186951541298794,
            "precision": 0.7717647058823529,
            "recall": 0.7114967462039046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8498221874946417,
            "auditor_fn_violation": 0.03716504750720615,
            "auditor_fp_violation": 0.02379830842021522,
            "ave_precision_score": 0.8500543858042373,
            "fpr": 0.12828947368421054,
            "logloss": 0.7476624600187378,
            "mae": 0.27074883447980236,
            "precision": 0.7705882352941177,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8343796073379453,
            "auditor_fn_violation": 0.02690423862600037,
            "auditor_fp_violation": 0.028057080131723384,
            "ave_precision_score": 0.8352383401657699,
            "fpr": 0.1251372118551043,
            "logloss": 0.6598203287968505,
            "mae": 0.26958731516997797,
            "precision": 0.7569296375266524,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8286624058859317,
            "auditor_fn_violation": 0.03283246147823921,
            "auditor_fp_violation": 0.022973977306033587,
            "ave_precision_score": 0.8292789847050082,
            "fpr": 0.12609649122807018,
            "logloss": 0.8046312020638322,
            "mae": 0.2764806310402764,
            "precision": 0.7709163346613546,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8081961885330249,
            "auditor_fn_violation": 0.027049486750275617,
            "auditor_fp_violation": 0.029135260397609473,
            "ave_precision_score": 0.8091590816157914,
            "fpr": 0.13062568605927552,
            "logloss": 0.7172168926807653,
            "mae": 0.2781938774519372,
            "precision": 0.75,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.836092084605597,
            "auditor_fn_violation": 0.037104996263478164,
            "auditor_fp_violation": 0.028247079512624045,
            "ave_precision_score": 0.8365324929761424,
            "fpr": 0.13267543859649122,
            "logloss": 0.6034282698554274,
            "mae": 0.3115629387679972,
            "precision": 0.758,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8429940447917926,
            "auditor_fn_violation": 0.039043172028544834,
            "auditor_fp_violation": 0.029657275277472864,
            "ave_precision_score": 0.8436366404807543,
            "fpr": 0.09769484083424808,
            "logloss": 0.5250612329475326,
            "mae": 0.2901426525387949,
            "precision": 0.7920560747663551,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.852544633237355,
            "auditor_fn_violation": 0.03142904167111491,
            "auditor_fp_violation": 0.025331825985010263,
            "ave_precision_score": 0.8527831485933409,
            "fpr": 0.13706140350877194,
            "logloss": 0.7299280156770833,
            "mae": 0.2684258998054393,
            "precision": 0.755859375,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8362139047967583,
            "auditor_fn_violation": 0.01525819639927519,
            "auditor_fp_violation": 0.027349676789852423,
            "ave_precision_score": 0.8369983533057981,
            "fpr": 0.14050493962678376,
            "logloss": 0.6813816418128167,
            "mae": 0.26552651439551866,
            "precision": 0.7393075356415478,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8478598941120019,
            "auditor_fn_violation": 0.018393473541866844,
            "auditor_fp_violation": 0.015481723401582716,
            "ave_precision_score": 0.848111065129481,
            "fpr": 0.10964912280701754,
            "logloss": 0.5452084287987692,
            "mae": 0.3018194209154197,
            "precision": 0.7876857749469215,
            "recall": 0.7525354969574036
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8619948515067595,
            "auditor_fn_violation": 0.007326696367130122,
            "auditor_fp_violation": 0.010793999268203446,
            "ave_precision_score": 0.8623703666911009,
            "fpr": 0.08232711306256861,
            "logloss": 0.48727202517615903,
            "mae": 0.2788963865777058,
            "precision": 0.8214285714285714,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8600083837905819,
            "auditor_fn_violation": 0.03279020319561582,
            "auditor_fp_violation": 0.02998995101117951,
            "ave_precision_score": 0.8602029117026115,
            "fpr": 0.14802631578947367,
            "logloss": 0.7210224699785948,
            "mae": 0.26796283794674103,
            "precision": 0.75,
            "recall": 0.821501014198783
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8377029220976309,
            "auditor_fn_violation": 0.02474932792978563,
            "auditor_fp_violation": 0.032457616782534456,
            "ave_precision_score": 0.839033279526477,
            "fpr": 0.13611416026344675,
            "logloss": 0.6578398244807674,
            "mae": 0.26451625396727707,
            "precision": 0.7443298969072165,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8604920773945728,
            "auditor_fn_violation": 0.034471638019999286,
            "auditor_fp_violation": 0.02478750575723318,
            "ave_precision_score": 0.860689234082344,
            "fpr": 0.11951754385964912,
            "logloss": 0.6647786508758752,
            "mae": 0.2702799505797672,
            "precision": 0.781563126252505,
            "recall": 0.7910750507099391
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8413540588432493,
            "auditor_fn_violation": 0.026785182786430498,
            "auditor_fp_violation": 0.02749115745822662,
            "ave_precision_score": 0.8421249608668671,
            "fpr": 0.1207464324917673,
            "logloss": 0.611059656620207,
            "mae": 0.26694424037781994,
            "precision": 0.7608695652173914,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8605967479138292,
            "auditor_fn_violation": 0.0336687306501548,
            "auditor_fp_violation": 0.022856215718293348,
            "ave_precision_score": 0.8607871594097414,
            "fpr": 0.1118421052631579,
            "logloss": 0.687708619200805,
            "mae": 0.2710420946587351,
            "precision": 0.7870563674321504,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8406116050793975,
            "auditor_fn_violation": 0.032249845822687764,
            "auditor_fp_violation": 0.027198438834004152,
            "ave_precision_score": 0.8413826323224487,
            "fpr": 0.10976948408342481,
            "logloss": 0.6270381550377924,
            "mae": 0.26718919246689504,
            "precision": 0.771689497716895,
            "recall": 0.7331887201735358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.838704266373612,
            "auditor_fn_violation": 0.030014501263300245,
            "auditor_fp_violation": 0.026485889544864555,
            "ave_precision_score": 0.8390133045554667,
            "fpr": 0.14035087719298245,
            "logloss": 1.0345296474750711,
            "mae": 0.26807586909385284,
            "precision": 0.7514563106796116,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8234527592768708,
            "auditor_fn_violation": 0.027192353757759462,
            "auditor_fp_violation": 0.030813513843151605,
            "ave_precision_score": 0.8237657130603833,
            "fpr": 0.14050493962678376,
            "logloss": 0.9325253829887007,
            "mae": 0.270446204960143,
            "precision": 0.7322175732217573,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8506197370722863,
            "auditor_fn_violation": 0.018493558948080142,
            "auditor_fp_violation": 0.022186283130260023,
            "ave_precision_score": 0.8509193504435206,
            "fpr": 0.16337719298245615,
            "logloss": 0.6155329215307614,
            "mae": 0.2720208132604807,
            "precision": 0.7348754448398577,
            "recall": 0.8377281947261663
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.849813968524832,
            "auditor_fn_violation": 0.0015143902793288153,
            "auditor_fp_violation": 0.02483717526527626,
            "ave_precision_score": 0.8502053674629371,
            "fpr": 0.1712403951701427,
            "logloss": 0.6199491921709382,
            "mae": 0.27370997843011585,
            "precision": 0.711645101663586,
            "recall": 0.8351409978308026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8548719143196666,
            "auditor_fn_violation": 0.019634532578911786,
            "auditor_fp_violation": 0.022871917263325388,
            "ave_precision_score": 0.8551526340981926,
            "fpr": 0.16885964912280702,
            "logloss": 0.6415402592880188,
            "mae": 0.2679201902915418,
            "precision": 0.7317073170731707,
            "recall": 0.8519269776876268
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8537253790401254,
            "auditor_fn_violation": 0.003481192749023147,
            "auditor_fp_violation": 0.025451884376143437,
            "ave_precision_score": 0.8541120383178185,
            "fpr": 0.1800219538968167,
            "logloss": 0.6453187935435102,
            "mae": 0.2703968862748082,
            "precision": 0.7055655296229802,
            "recall": 0.8524945770065075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8224794644922169,
            "auditor_fn_violation": 0.07603821928045265,
            "auditor_fp_violation": 0.0442024661893397,
            "ave_precision_score": 0.8227293247011346,
            "fpr": 0.12938596491228072,
            "logloss": 0.938897359782485,
            "mae": 0.35977299442660926,
            "precision": 0.7456896551724138,
            "recall": 0.7018255578093306
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7946522177900492,
            "auditor_fn_violation": 0.07268597117420013,
            "auditor_fp_violation": 0.049288937675326265,
            "ave_precision_score": 0.7952913573899215,
            "fpr": 0.13391877058177826,
            "logloss": 0.8496750674971711,
            "mae": 0.3523269012619597,
            "precision": 0.7182448036951501,
            "recall": 0.6746203904555315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.819749760206707,
            "auditor_fn_violation": 0.023244279563004875,
            "auditor_fp_violation": 0.044317610852907925,
            "ave_precision_score": 0.8133406929885201,
            "fpr": 0.3651315789473684,
            "logloss": 1.8939617272061289,
            "mae": 0.3778373915268755,
            "precision": 0.5806045340050378,
            "recall": 0.9350912778904665
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7947126293131529,
            "auditor_fn_violation": 0.016641625255077137,
            "auditor_fp_violation": 0.05249176728869374,
            "ave_precision_score": 0.7867618407519871,
            "fpr": 0.3721185510428101,
            "logloss": 1.8823802186362226,
            "mae": 0.3822525895459932,
            "precision": 0.562015503875969,
            "recall": 0.9436008676789588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8653688799583044,
            "auditor_fn_violation": 0.02063983488132095,
            "auditor_fp_violation": 0.018949147929489592,
            "ave_precision_score": 0.8655834925716803,
            "fpr": 0.10416666666666667,
            "logloss": 0.5553441428026076,
            "mae": 0.2710218995272411,
            "precision": 0.7983014861995754,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8609945878197856,
            "auditor_fn_violation": 0.0056313412116550925,
            "auditor_fp_violation": 0.02024637150872058,
            "ave_precision_score": 0.8617067056706642,
            "fpr": 0.10976948408342481,
            "logloss": 0.5336409065951567,
            "mae": 0.26276486872211835,
            "precision": 0.7782705099778271,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8120397750768849,
            "auditor_fn_violation": 0.019260880395715455,
            "auditor_fp_violation": 0.01531162333040238,
            "ave_precision_score": 0.8027721135784768,
            "fpr": 0.10855263157894737,
            "logloss": 1.1916508007490128,
            "mae": 0.2690075561376784,
            "precision": 0.7946058091286307,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7829826669422459,
            "auditor_fn_violation": 0.003743115596076883,
            "auditor_fp_violation": 0.014694474935967806,
            "ave_precision_score": 0.7732487358187166,
            "fpr": 0.1251372118551043,
            "logloss": 1.3114601875241283,
            "mae": 0.2847862870037059,
            "precision": 0.7516339869281046,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8534098464927089,
            "auditor_fn_violation": 0.045663410554784525,
            "auditor_fp_violation": 0.026802537369677186,
            "ave_precision_score": 0.8536499240394246,
            "fpr": 0.11403508771929824,
            "logloss": 0.7406577572368136,
            "mae": 0.2876601855238015,
            "precision": 0.7868852459016393,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8350720321753125,
            "auditor_fn_violation": 0.035381014403375474,
            "auditor_fp_violation": 0.028522990608610806,
            "ave_precision_score": 0.8360168533979137,
            "fpr": 0.09769484083424808,
            "logloss": 0.627411516242322,
            "mae": 0.279842427340295,
            "precision": 0.7963386727688787,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8325239372596168,
            "auditor_fn_violation": 0.033537507562008476,
            "auditor_fp_violation": 0.018810450948373324,
            "ave_precision_score": 0.8330844169847381,
            "fpr": 0.1118421052631579,
            "logloss": 0.6203346854933975,
            "mae": 0.2921092350159661,
            "precision": 0.777292576419214,
            "recall": 0.7221095334685599
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8211750113993888,
            "auditor_fn_violation": 0.010434053779903857,
            "auditor_fp_violation": 0.022141724600561047,
            "ave_precision_score": 0.8226068675715765,
            "fpr": 0.11745334796926454,
            "logloss": 0.5984112425443098,
            "mae": 0.28263804201954307,
            "precision": 0.7595505617977528,
            "recall": 0.7331887201735358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8215275668040724,
            "auditor_fn_violation": 0.01896284829721363,
            "auditor_fp_violation": 0.018624649332160955,
            "ave_precision_score": 0.8219089498515881,
            "fpr": 0.12938596491228072,
            "logloss": 0.664402362183865,
            "mae": 0.2961099625199016,
            "precision": 0.7556935817805382,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8202044907143712,
            "auditor_fn_violation": 0.0017382152577201772,
            "auditor_fp_violation": 0.02303207708257105,
            "ave_precision_score": 0.8205559828254523,
            "fpr": 0.14928649835345773,
            "logloss": 0.6530383627146736,
            "mae": 0.2908032156652786,
            "precision": 0.7213114754098361,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8317721187269507,
            "auditor_fn_violation": 0.039440322408455214,
            "auditor_fp_violation": 0.036966670853745345,
            "ave_precision_score": 0.8320260477370264,
            "fpr": 0.17982456140350878,
            "logloss": 0.6206430458871434,
            "mae": 0.32641207603304184,
            "precision": 0.7097345132743362,
            "recall": 0.8133874239350912
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8329456813500239,
            "auditor_fn_violation": 0.033707089299023024,
            "auditor_fp_violation": 0.03832174655445786,
            "ave_precision_score": 0.8337038874652187,
            "fpr": 0.16245883644346873,
            "logloss": 0.5574135411279324,
            "mae": 0.31816148409029443,
            "precision": 0.7120622568093385,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8381729797304914,
            "auditor_fn_violation": 0.029307231059392903,
            "auditor_fp_violation": 0.0265643972700247,
            "ave_precision_score": 0.8385297348412517,
            "fpr": 0.1425438596491228,
            "logloss": 0.8718820413271654,
            "mae": 0.2718954167524547,
            "precision": 0.7485493230174082,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8178099991875009,
            "auditor_fn_violation": 0.023175409730671885,
            "auditor_fp_violation": 0.03018904744481034,
            "ave_precision_score": 0.8182333098899572,
            "fpr": 0.14050493962678376,
            "logloss": 0.8430670438887602,
            "mae": 0.27337649642860284,
            "precision": 0.7355371900826446,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7662815814746868,
            "auditor_fn_violation": 0.04013869613181026,
            "auditor_fp_violation": 0.03829868525729598,
            "ave_precision_score": 0.76554616966068,
            "fpr": 0.16228070175438597,
            "logloss": 2.031567233698195,
            "mae": 0.2928039079936876,
            "precision": 0.720226843100189,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7259109180887651,
            "auditor_fn_violation": 0.037540687333173,
            "auditor_fp_violation": 0.04479082814977437,
            "ave_precision_score": 0.724536172008904,
            "fpr": 0.1602634467618002,
            "logloss": 2.1171398007948414,
            "mae": 0.2976197192324705,
            "precision": 0.7020408163265306,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8272134687383117,
            "auditor_fn_violation": 0.04843466424682396,
            "auditor_fp_violation": 0.03018098647573588,
            "ave_precision_score": 0.8274387405611245,
            "fpr": 0.125,
            "logloss": 0.8607670245352737,
            "mae": 0.3184433340725539,
            "precision": 0.7579617834394905,
            "recall": 0.7241379310344828
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8123781672008119,
            "auditor_fn_violation": 0.04112188698743485,
            "auditor_fp_violation": 0.03000365898280279,
            "ave_precision_score": 0.8132274338518917,
            "fpr": 0.10976948408342481,
            "logloss": 0.7651747749708506,
            "mae": 0.31109912550628555,
            "precision": 0.76905311778291,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8322635944019812,
            "auditor_fn_violation": 0.03509439165865984,
            "auditor_fp_violation": 0.02199786458987565,
            "ave_precision_score": 0.832675363182662,
            "fpr": 0.125,
            "logloss": 0.8004237040127193,
            "mae": 0.27577386247492675,
            "precision": 0.7729083665338645,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8176059865048355,
            "auditor_fn_violation": 0.025396991697045755,
            "auditor_fp_violation": 0.029001097694840834,
            "ave_precision_score": 0.8182857444349741,
            "fpr": 0.12843029637760703,
            "logloss": 0.7053292982011136,
            "mae": 0.27491910575293504,
            "precision": 0.7547169811320755,
            "recall": 0.7809110629067245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8495827803100815,
            "auditor_fn_violation": 0.036522276787302944,
            "auditor_fp_violation": 0.023526148306326683,
            "ave_precision_score": 0.8498951498717819,
            "fpr": 0.11732456140350878,
            "logloss": 0.8381237051092214,
            "mae": 0.26558319974005273,
            "precision": 0.7816326530612245,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8357471560604701,
            "auditor_fn_violation": 0.028709125153879675,
            "auditor_fp_violation": 0.026564215148188807,
            "ave_precision_score": 0.8370672737524145,
            "fpr": 0.11525795828759605,
            "logloss": 0.7145374080244875,
            "mae": 0.2649350076589484,
            "precision": 0.7676991150442478,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.851247848693121,
            "auditor_fn_violation": 0.030279171559730974,
            "auditor_fp_violation": 0.019655717455930997,
            "ave_precision_score": 0.8515321961507545,
            "fpr": 0.12390350877192982,
            "logloss": 0.7423266480105202,
            "mae": 0.2687587863087537,
            "precision": 0.7749003984063745,
            "recall": 0.7890466531440162
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.834999075282596,
            "auditor_fn_violation": 0.02629229161061121,
            "auditor_fp_violation": 0.027564337114282238,
            "ave_precision_score": 0.8354080898951541,
            "fpr": 0.12733260153677278,
            "logloss": 0.6980663597397845,
            "mae": 0.26728645381245986,
            "precision": 0.7531914893617021,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8588059598915947,
            "auditor_fn_violation": 0.03234315504786307,
            "auditor_fp_violation": 0.028485219612276513,
            "ave_precision_score": 0.8590078692891803,
            "fpr": 0.13157894736842105,
            "logloss": 0.723322952909245,
            "mae": 0.2655588417221972,
            "precision": 0.7637795275590551,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8399970579135145,
            "auditor_fn_violation": 0.023351612373235294,
            "auditor_fp_violation": 0.028627881448957188,
            "ave_precision_score": 0.8412980101353882,
            "fpr": 0.12733260153677278,
            "logloss": 0.6630094122386775,
            "mae": 0.26106315368001426,
            "precision": 0.7552742616033755,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.858197673301307,
            "auditor_fn_violation": 0.032681221308850227,
            "auditor_fp_violation": 0.02545482142109451,
            "ave_precision_score": 0.8583948389052667,
            "fpr": 0.14364035087719298,
            "logloss": 0.7600926972981822,
            "mae": 0.2674720954401664,
            "precision": 0.7542213883677298,
            "recall": 0.8154158215010142
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8377572513337078,
            "auditor_fn_violation": 0.023942129337501884,
            "auditor_fp_violation": 0.0324624954262715,
            "ave_precision_score": 0.8383949786745142,
            "fpr": 0.14489571899012074,
            "logloss": 0.6767866757078426,
            "mae": 0.26789648674508815,
            "precision": 0.7311608961303462,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.856872715643653,
            "auditor_fn_violation": 0.023775844276004418,
            "auditor_fp_violation": 0.017481053468994687,
            "ave_precision_score": 0.8571121692395864,
            "fpr": 0.10197368421052631,
            "logloss": 0.6034539981617103,
            "mae": 0.27271732425843337,
            "precision": 0.7982646420824295,
            "recall": 0.7464503042596349
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8524354541049163,
            "auditor_fn_violation": 0.003771688997573643,
            "auditor_fp_violation": 0.020234174899377975,
            "ave_precision_score": 0.8531704516615306,
            "fpr": 0.11525795828759605,
            "logloss": 0.5793145472569733,
            "mae": 0.2649439135119094,
            "precision": 0.7692307692307693,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8535310811939062,
            "auditor_fn_violation": 0.030332550443044733,
            "auditor_fp_violation": 0.02420916551522003,
            "ave_precision_score": 0.8537500414192799,
            "fpr": 0.13486842105263158,
            "logloss": 0.7531224690536935,
            "mae": 0.26810794825643497,
            "precision": 0.7588235294117647,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.833280360198941,
            "auditor_fn_violation": 0.01956801779170467,
            "auditor_fp_violation": 0.028683985851933165,
            "ave_precision_score": 0.8346061365310335,
            "fpr": 0.1394072447859495,
            "logloss": 0.7042941866701024,
            "mae": 0.2660000524939492,
            "precision": 0.7381443298969073,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8297451934852439,
            "auditor_fn_violation": 0.024545389843777805,
            "auditor_fp_violation": 0.01452131223045681,
            "ave_precision_score": 0.8300356310842486,
            "fpr": 0.07675438596491228,
            "logloss": 1.3886394712604626,
            "mae": 0.2956782886738646,
            "precision": 0.8191214470284238,
            "recall": 0.6430020283975659
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8239270439332018,
            "auditor_fn_violation": 0.012098454417090714,
            "auditor_fp_violation": 0.01445298207098427,
            "ave_precision_score": 0.8244769376696223,
            "fpr": 0.08232711306256861,
            "logloss": 1.1988209217245471,
            "mae": 0.2855913832626657,
            "precision": 0.7945205479452054,
            "recall": 0.6290672451193059
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.85302081161759,
            "auditor_fn_violation": 0.0395426319348066,
            "auditor_fp_violation": 0.02777603316166311,
            "ave_precision_score": 0.8532735039899614,
            "fpr": 0.1118421052631579,
            "logloss": 0.9488959402729027,
            "mae": 0.27270744255682067,
            "precision": 0.7825159914712153,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8384777932469967,
            "auditor_fn_violation": 0.036204880813199,
            "auditor_fp_violation": 0.028662031955116483,
            "ave_precision_score": 0.8387973907263566,
            "fpr": 0.10976948408342481,
            "logloss": 0.8241620698727676,
            "mae": 0.27011577556801974,
            "precision": 0.7695852534562212,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7644562260011891,
            "auditor_fn_violation": 0.04143313405216897,
            "auditor_fp_violation": 0.03843738223841227,
            "ave_precision_score": 0.7635261384499712,
            "fpr": 0.16885964912280702,
            "logloss": 2.0048655702560323,
            "mae": 0.2928973568296389,
            "precision": 0.717948717948718,
            "recall": 0.795131845841785
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7275000285840675,
            "auditor_fn_violation": 0.03673586985768065,
            "auditor_fp_violation": 0.0474057811928284,
            "ave_precision_score": 0.726702801998768,
            "fpr": 0.16136114160263446,
            "logloss": 2.0564660239105126,
            "mae": 0.29431078107739184,
            "precision": 0.7094861660079052,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8509168798858036,
            "auditor_fn_violation": 0.021022383545069575,
            "auditor_fp_violation": 0.015853326634007462,
            "ave_precision_score": 0.8511264824426099,
            "fpr": 0.13048245614035087,
            "logloss": 0.6843826988588542,
            "mae": 0.2748716267264762,
            "precision": 0.7591093117408907,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8375062867273431,
            "auditor_fn_violation": 0.009467320362596466,
            "auditor_fp_violation": 0.027137455787291133,
            "ave_precision_score": 0.838104171463754,
            "fpr": 0.13721185510428102,
            "logloss": 0.6762203781680342,
            "mae": 0.2747383386479127,
            "precision": 0.7384937238493724,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8441611089206695,
            "auditor_fn_violation": 0.020003736521831968,
            "auditor_fp_violation": 0.01930766654105431,
            "ave_precision_score": 0.8444950242226814,
            "fpr": 0.12280701754385964,
            "logloss": 0.5183410448529013,
            "mae": 0.32658472925980103,
            "precision": 0.7746478873239436,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8598637839611669,
            "auditor_fn_violation": 0.009407792442811527,
            "auditor_fp_violation": 0.01870472008781559,
            "ave_precision_score": 0.860248316332067,
            "fpr": 0.09220636663007684,
            "logloss": 0.47305987120279624,
            "mae": 0.3065362867503606,
            "precision": 0.8120805369127517,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8259065739913057,
            "auditor_fn_violation": 0.02529047009003239,
            "auditor_fp_violation": 0.023361282083490347,
            "ave_precision_score": 0.8271452814522249,
            "fpr": 0.1206140350877193,
            "logloss": 0.766473402949458,
            "mae": 0.2899353897181538,
            "precision": 0.7654584221748401,
            "recall": 0.7281947261663286
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8149628936160392,
            "auditor_fn_violation": 0.013234247126587313,
            "auditor_fp_violation": 0.025429930479326752,
            "ave_precision_score": 0.8155824669662436,
            "fpr": 0.12184412733260154,
            "logloss": 0.6900057546950232,
            "mae": 0.2862946618052082,
            "precision": 0.7516778523489933,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7969673965097841,
            "auditor_fn_violation": 0.013329151987473753,
            "auditor_fp_violation": 0.025530712222082662,
            "ave_precision_score": 0.7974015761339948,
            "fpr": 0.12609649122807018,
            "logloss": 0.5588125705466166,
            "mae": 0.3778826393893707,
            "precision": 0.762396694214876,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.815652952706792,
            "auditor_fn_violation": 0.008169611711284832,
            "auditor_fp_violation": 0.021331869740212228,
            "ave_precision_score": 0.8160905072662286,
            "fpr": 0.11525795828759605,
            "logloss": 0.5154264908073667,
            "mae": 0.35660937149486577,
            "precision": 0.7666666666666667,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8168601609550624,
            "auditor_fn_violation": 0.026845130066545677,
            "auditor_fp_violation": 0.04039484151907215,
            "ave_precision_score": 0.8108127716763971,
            "fpr": 0.21820175438596492,
            "logloss": 1.4134945294548116,
            "mae": 0.29987122854199294,
            "precision": 0.6900311526479751,
            "recall": 0.8985801217038539
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7923794986491338,
            "auditor_fn_violation": 0.027732867269406696,
            "auditor_fp_violation": 0.050308574216367856,
            "ave_precision_score": 0.7868307996832441,
            "fpr": 0.21844127332601537,
            "logloss": 1.3476037098871785,
            "mae": 0.3042095879535656,
            "precision": 0.6705298013245033,
            "recall": 0.8785249457700651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8197154904588886,
            "auditor_fn_violation": 0.02384924024056084,
            "auditor_fp_violation": 0.019888623707239473,
            "ave_precision_score": 0.8209743868907082,
            "fpr": 0.11732456140350878,
            "logloss": 0.8007073775847333,
            "mae": 0.2908123778187043,
            "precision": 0.7713675213675214,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8094621609786348,
            "auditor_fn_violation": 0.01867033676134781,
            "auditor_fp_violation": 0.024978655933650444,
            "ave_precision_score": 0.8102555214984348,
            "fpr": 0.1207464324917673,
            "logloss": 0.7235218214593364,
            "mae": 0.2880120686166852,
            "precision": 0.7505668934240363,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8483495245252888,
            "auditor_fn_violation": 0.01646071314188107,
            "auditor_fp_violation": 0.018396976929196503,
            "ave_precision_score": 0.8487653998025301,
            "fpr": 0.13048245614035087,
            "logloss": 0.6469602938599865,
            "mae": 0.2679395691962869,
            "precision": 0.765748031496063,
            "recall": 0.7890466531440162
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8484576033790703,
            "auditor_fn_violation": 0.0012667541330234709,
            "auditor_fp_violation": 0.017650933040614717,
            "ave_precision_score": 0.8488522937984428,
            "fpr": 0.13830954994511527,
            "logloss": 0.6394945045392773,
            "mae": 0.26484175536488563,
            "precision": 0.7423312883435583,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8491248154882606,
            "auditor_fn_violation": 0.03135564570655849,
            "auditor_fp_violation": 0.02856372733743667,
            "ave_precision_score": 0.8493783888708726,
            "fpr": 0.1524122807017544,
            "logloss": 0.849458567525751,
            "mae": 0.2652597861122576,
            "precision": 0.7406716417910447,
            "recall": 0.8052738336713996
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8316105733425063,
            "auditor_fn_violation": 0.02345161927847399,
            "auditor_fp_violation": 0.03232345407976582,
            "ave_precision_score": 0.8324055083377914,
            "fpr": 0.141602634467618,
            "logloss": 0.7750611208025376,
            "mae": 0.2624872429318633,
            "precision": 0.7372708757637475,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8586309358751162,
            "auditor_fn_violation": 0.034393793815166725,
            "auditor_fp_violation": 0.020956328769417578,
            "ave_precision_score": 0.8588359465995371,
            "fpr": 0.11074561403508772,
            "logloss": 0.6789048882716353,
            "mae": 0.2675299090566603,
            "precision": 0.7900207900207901,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8402950454206894,
            "auditor_fn_violation": 0.024589793104761996,
            "auditor_fp_violation": 0.024763995609220647,
            "ave_precision_score": 0.8415958118789519,
            "fpr": 0.11855104281009879,
            "logloss": 0.6283548128620344,
            "mae": 0.26372207144571036,
            "precision": 0.7647058823529411,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8517010407019542,
            "auditor_fn_violation": 0.020152752571082885,
            "auditor_fp_violation": 0.02082286563664532,
            "ave_precision_score": 0.8520156182243491,
            "fpr": 0.12828947368421054,
            "logloss": 0.597742386244144,
            "mae": 0.26934373515618254,
            "precision": 0.7696850393700787,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8525829360663189,
            "auditor_fn_violation": 0.0004000276209547823,
            "auditor_fp_violation": 0.021892913769971954,
            "ave_precision_score": 0.852921116626121,
            "fpr": 0.1437980241492865,
            "logloss": 0.5914816419203799,
            "mae": 0.2677223119203872,
            "precision": 0.7369477911646586,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8176051218041833,
            "auditor_fn_violation": 0.03053494537560941,
            "auditor_fp_violation": 0.0331145584725537,
            "ave_precision_score": 0.8117321062796719,
            "fpr": 0.17214912280701755,
            "logloss": 1.3293878296544646,
            "mae": 0.27553933296056426,
            "precision": 0.7311643835616438,
            "recall": 0.8661257606490872
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.794758766200304,
            "auditor_fn_violation": 0.03037590690785793,
            "auditor_fp_violation": 0.04231247713135749,
            "ave_precision_score": 0.7893570124916006,
            "fpr": 0.1712403951701427,
            "logloss": 1.2521679791930567,
            "mae": 0.28216487011333335,
            "precision": 0.7132352941176471,
            "recall": 0.841648590021692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 7376,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.85971083035149,
            "auditor_fn_violation": 0.03323725134336856,
            "auditor_fp_violation": 0.025855210819411296,
            "ave_precision_score": 0.8599119970397375,
            "fpr": 0.12609649122807018,
            "logloss": 0.7486489944913218,
            "mae": 0.2614079773474539,
            "precision": 0.775390625,
            "recall": 0.8052738336713996
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.83828103086743,
            "auditor_fn_violation": 0.025456519616830688,
            "auditor_fp_violation": 0.028613245517746067,
            "ave_precision_score": 0.8396491667793546,
            "fpr": 0.1251372118551043,
            "logloss": 0.6841452429546468,
            "mae": 0.25867838041471014,
            "precision": 0.7579617834394905,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8077957752739446,
            "auditor_fn_violation": 0.021053521227002606,
            "auditor_fp_violation": 0.012210568186576228,
            "ave_precision_score": 0.7933897126113587,
            "fpr": 0.08552631578947369,
            "logloss": 1.5751926895845016,
            "mae": 0.2881746424171449,
            "precision": 0.805,
            "recall": 0.6531440162271805
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7857331555464109,
            "auditor_fn_violation": 0.008602974967319182,
            "auditor_fp_violation": 0.01567996097085011,
            "ave_precision_score": 0.7695465474215322,
            "fpr": 0.10318331503841932,
            "logloss": 1.6338778672376184,
            "mae": 0.29054205145005196,
            "precision": 0.7589743589743589,
            "recall": 0.6420824295010846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8077951971611775,
            "auditor_fn_violation": 0.0214138286893705,
            "auditor_fp_violation": 0.010580224427416993,
            "ave_precision_score": 0.7948803513391502,
            "fpr": 0.08333333333333333,
            "logloss": 1.5567608554016563,
            "mae": 0.29212237467256924,
            "precision": 0.8075949367088607,
            "recall": 0.6470588235294118
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7841679266034952,
            "auditor_fn_violation": 0.008048174754923561,
            "auditor_fp_violation": 0.014584705451884379,
            "ave_precision_score": 0.768008457076456,
            "fpr": 0.09989023051591657,
            "logloss": 1.6498040940940144,
            "mae": 0.29314596983226,
            "precision": 0.7611548556430446,
            "recall": 0.6290672451193059
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.835529222675359,
            "auditor_fn_violation": 0.030857442795630054,
            "auditor_fp_violation": 0.02627130176276013,
            "ave_precision_score": 0.8358186614645597,
            "fpr": 0.13486842105263158,
            "logloss": 0.9169948709804374,
            "mae": 0.2749287178736047,
            "precision": 0.7583497053045186,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8089827431711749,
            "auditor_fn_violation": 0.030078267308933242,
            "auditor_fp_violation": 0.03018904744481034,
            "ave_precision_score": 0.8094784592047333,
            "fpr": 0.14050493962678376,
            "logloss": 0.8390654246341487,
            "mae": 0.28011921059373296,
            "precision": 0.7305263157894737,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8482885153665469,
            "auditor_fn_violation": 0.01938543112344757,
            "auditor_fp_violation": 0.02326968973747017,
            "ave_precision_score": 0.8487004843076353,
            "fpr": 0.1337719298245614,
            "logloss": 0.6422723001581889,
            "mae": 0.2661910652629614,
            "precision": 0.7653846153846153,
            "recall": 0.8073022312373225
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8492327773833028,
            "auditor_fn_violation": 0.003457381581109174,
            "auditor_fp_violation": 0.023644346871569705,
            "ave_precision_score": 0.8495129843279254,
            "fpr": 0.145993413830955,
            "logloss": 0.6404736058654421,
            "mae": 0.2654745304982686,
            "precision": 0.7371541501976284,
            "recall": 0.8091106290672451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8179572859190929,
            "auditor_fn_violation": 0.0768455748905733,
            "auditor_fp_violation": 0.04113281413557761,
            "ave_precision_score": 0.8182135853771353,
            "fpr": 0.1162280701754386,
            "logloss": 1.0030577382627586,
            "mae": 0.3565824362754536,
            "precision": 0.7557603686635944,
            "recall": 0.665314401622718
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7928787868727849,
            "auditor_fn_violation": 0.0700453126525403,
            "auditor_fp_violation": 0.04488352238077815,
            "ave_precision_score": 0.7933414440321653,
            "fpr": 0.10976948408342481,
            "logloss": 0.9047780026302266,
            "mae": 0.3468082453563874,
            "precision": 0.7448979591836735,
            "recall": 0.6334056399132321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7641053819204384,
            "auditor_fn_violation": 0.04180456211522721,
            "auditor_fp_violation": 0.03831962065067202,
            "ave_precision_score": 0.7630532894595532,
            "fpr": 0.17214912280701755,
            "logloss": 2.008675917043347,
            "mae": 0.293207273246161,
            "precision": 0.7145454545454546,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.727233647328596,
            "auditor_fn_violation": 0.033640418028863896,
            "auditor_fp_violation": 0.046308086351994154,
            "ave_precision_score": 0.7262830111349148,
            "fpr": 0.16136114160263446,
            "logloss": 2.061277972417713,
            "mae": 0.29466676106958634,
            "precision": 0.7111984282907662,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8472108992424049,
            "auditor_fn_violation": 0.024574303405572755,
            "auditor_fp_violation": 0.020681551731357033,
            "ave_precision_score": 0.8476846057685006,
            "fpr": 0.1162280701754386,
            "logloss": 0.613396030910673,
            "mae": 0.26662220467730086,
            "precision": 0.7805383022774327,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8546143509160851,
            "auditor_fn_violation": 0.005274173692945469,
            "auditor_fp_violation": 0.022875960482985735,
            "ave_precision_score": 0.8549468186703062,
            "fpr": 0.12952799121844127,
            "logloss": 0.5984943923834222,
            "mae": 0.2635074287248391,
            "precision": 0.7478632478632479,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8554759737226717,
            "auditor_fn_violation": 0.024171737660581477,
            "auditor_fp_violation": 0.02110811037139389,
            "ave_precision_score": 0.8556848668532857,
            "fpr": 0.12828947368421054,
            "logloss": 0.6552252810181661,
            "mae": 0.26761852965836896,
            "precision": 0.766,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8471808382163137,
            "auditor_fn_violation": 0.010250707786966247,
            "auditor_fp_violation": 0.02529088913282107,
            "ave_precision_score": 0.8475736386748061,
            "fpr": 0.13611416026344675,
            "logloss": 0.6406496568308672,
            "mae": 0.26461128491631364,
            "precision": 0.7448559670781894,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8077661791720512,
            "auditor_fn_violation": 0.034498327461656174,
            "auditor_fp_violation": 0.026012226269731608,
            "ave_precision_score": 0.8001331274478436,
            "fpr": 0.1524122807017544,
            "logloss": 1.3100376913004659,
            "mae": 0.27998208390169116,
            "precision": 0.7425925925925926,
            "recall": 0.8133874239350912
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7802110529192431,
            "auditor_fn_violation": 0.024687418893209297,
            "auditor_fp_violation": 0.031716062934504206,
            "ave_precision_score": 0.772224718349585,
            "fpr": 0.1525795828759605,
            "logloss": 1.3209303459725297,
            "mae": 0.286476432260761,
            "precision": 0.7236580516898609,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8568710581145013,
            "auditor_fn_violation": 0.04267641720935198,
            "auditor_fp_violation": 0.029725641669806978,
            "ave_precision_score": 0.8570469426592346,
            "fpr": 0.12609649122807018,
            "logloss": 0.6527243625251916,
            "mae": 0.29470983499314857,
            "precision": 0.7672064777327935,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8374573128296502,
            "auditor_fn_violation": 0.03977179376671247,
            "auditor_fp_violation": 0.03243322356384925,
            "ave_precision_score": 0.8388074938243226,
            "fpr": 0.10208562019758508,
            "logloss": 0.5773701445547612,
            "mae": 0.27860004525021026,
            "precision": 0.7891156462585034,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8208268654009192,
            "auditor_fn_violation": 0.03022134443614106,
            "auditor_fp_violation": 0.020739124063141153,
            "ave_precision_score": 0.8220700434749713,
            "fpr": 0.10964912280701754,
            "logloss": 1.550970942208291,
            "mae": 0.2933168155538897,
            "precision": 0.7752808988764045,
            "recall": 0.6997971602434077
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8005416554143994,
            "auditor_fn_violation": 0.023842122432263187,
            "auditor_fp_violation": 0.024134650567142344,
            "ave_precision_score": 0.801207230368534,
            "fpr": 0.1163556531284303,
            "logloss": 1.509066811534811,
            "mae": 0.2934377435071298,
            "precision": 0.7476190476190476,
            "recall": 0.6811279826464208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.850822904819569,
            "auditor_fn_violation": 0.04387744208391161,
            "auditor_fp_violation": 0.03349139555332245,
            "ave_precision_score": 0.8509995132221571,
            "fpr": 0.14035087719298245,
            "logloss": 0.7195798893692571,
            "mae": 0.32831283404867717,
            "precision": 0.7485265225933202,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8250792643084839,
            "auditor_fn_violation": 0.040709953782523074,
            "auditor_fp_violation": 0.0381119648737651,
            "ave_precision_score": 0.825587724959943,
            "fpr": 0.11855104281009879,
            "logloss": 0.6341213209535762,
            "mae": 0.32117414100417907,
            "precision": 0.7641921397379913,
            "recall": 0.7592190889370932
        }
    }
]