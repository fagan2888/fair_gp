[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8063044563356857,
            "auditor_fn_violation": 0.02038360965839546,
            "auditor_fp_violation": 0.030524417535867,
            "ave_precision_score": 0.8069765165769971,
            "fpr": 0.13486842105263158,
            "logloss": 0.970222179633315,
            "mae": 0.2766661900788346,
            "precision": 0.7426778242677824,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8367775846958287,
            "auditor_fn_violation": 0.01832306003546399,
            "auditor_fp_violation": 0.01735123682127997,
            "ave_precision_score": 0.8370094896399689,
            "fpr": 0.132821075740944,
            "logloss": 0.8859746588846275,
            "mae": 0.26860643918072186,
            "precision": 0.7535641547861507,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8265672425853594,
            "auditor_fn_violation": 0.014718018619487412,
            "auditor_fp_violation": 0.01816079207129441,
            "ave_precision_score": 0.8191400794795982,
            "fpr": 0.11951754385964912,
            "logloss": 0.5229440171264247,
            "mae": 0.33460650436188044,
            "precision": 0.7640692640692641,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8512218231412029,
            "auditor_fn_violation": 0.014167337987316037,
            "auditor_fp_violation": 0.007104383121027237,
            "ave_precision_score": 0.845041754923875,
            "fpr": 0.10208562019758508,
            "logloss": 0.4988493327847498,
            "mae": 0.3276027512586339,
            "precision": 0.7937915742793792,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8498349307903926,
            "auditor_fn_violation": 0.014590519639479257,
            "auditor_fp_violation": 0.020903268992526883,
            "ave_precision_score": 0.8427994603382747,
            "fpr": 0.10964912280701754,
            "logloss": 0.4950632867691821,
            "mae": 0.31477861553267167,
            "precision": 0.77728285077951,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8669927989442345,
            "auditor_fn_violation": 0.015360881442110863,
            "auditor_fp_violation": 0.008756030939677837,
            "ave_precision_score": 0.8629235404406137,
            "fpr": 0.08781558726673985,
            "logloss": 0.47930118835062185,
            "mae": 0.30959992061658437,
            "precision": 0.813953488372093,
            "recall": 0.7276507276507277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.631021422253655,
            "auditor_fn_violation": 0.001618077964467203,
            "auditor_fp_violation": 0.002255425008991728,
            "ave_precision_score": 0.6255268708491512,
            "fpr": 0.010964912280701754,
            "logloss": 0.7820630139364102,
            "mae": 0.47080225590616465,
            "precision": 0.8837209302325582,
            "recall": 0.160676532769556
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6277695294286298,
            "auditor_fn_violation": 0.00977884073383526,
            "auditor_fp_violation": 0.0032113956041150797,
            "ave_precision_score": 0.6214465559809199,
            "fpr": 0.014270032930845226,
            "logloss": 0.8049318258264875,
            "mae": 0.47937355444047897,
            "precision": 0.8433734939759037,
            "recall": 0.14553014553014554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7304499300200807,
            "auditor_fn_violation": 0.005929861652015899,
            "auditor_fp_violation": 0.0004395955720736923,
            "ave_precision_score": 0.7312745379843137,
            "fpr": 0.020833333333333332,
            "logloss": 0.8453381615958347,
            "mae": 0.43105132077267116,
            "precision": 0.8455284552845529,
            "recall": 0.21987315010570824
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7513996706444753,
            "auditor_fn_violation": 0.007314162089134667,
            "auditor_fp_violation": 0.004988129579046792,
            "ave_precision_score": 0.7519190864559598,
            "fpr": 0.020856201975850714,
            "logloss": 0.8449588277699212,
            "mae": 0.4369076262948918,
            "precision": 0.8240740740740741,
            "recall": 0.18503118503118504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7203235221679145,
            "auditor_fn_violation": 0.010512870442491004,
            "auditor_fp_violation": 0.0012013947168604984,
            "ave_precision_score": 0.6183479491489112,
            "fpr": 0.27521929824561403,
            "logloss": 0.6906970764310361,
            "mae": 0.4517636905636704,
            "precision": 0.5774410774410774,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7602112671628115,
            "auditor_fn_violation": 0.009171799512084914,
            "auditor_fp_violation": 0.006254307814055598,
            "ave_precision_score": 0.6631640738365363,
            "fpr": 0.2305159165751921,
            "logloss": 0.6442420948924036,
            "mae": 0.4290582916968217,
            "precision": 0.6347826086956522,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.82449728730045,
            "auditor_fn_violation": 0.009645877378435521,
            "auditor_fp_violation": 0.010712644367182193,
            "ave_precision_score": 0.8228834404486461,
            "fpr": 0.0800438596491228,
            "logloss": 0.5193364117784741,
            "mae": 0.32337310937694846,
            "precision": 0.8215158924205379,
            "recall": 0.7103594080338267
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8585515101354186,
            "auditor_fn_violation": 0.010356214527454928,
            "auditor_fp_violation": 0.006619355168100478,
            "ave_precision_score": 0.8558767413646454,
            "fpr": 0.07574094401756312,
            "logloss": 0.49831030137458004,
            "mae": 0.30720936238835234,
            "precision": 0.8329297820823245,
            "recall": 0.7151767151767152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7608094601191409,
            "auditor_fn_violation": 0.007754256147768999,
            "auditor_fp_violation": 0.036813631459057666,
            "ave_precision_score": 0.7613332702153266,
            "fpr": 0.3190789473684211,
            "logloss": 1.4586999984588152,
            "mae": 0.37784589231504423,
            "precision": 0.6056910569105691,
            "recall": 0.945031712473573
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7976092662764317,
            "auditor_fn_violation": 0.0075058593170558045,
            "auditor_fp_violation": 0.027467898807852362,
            "ave_precision_score": 0.7979489102381654,
            "fpr": 0.31833150384193193,
            "logloss": 1.4199362867959493,
            "mae": 0.38197576949775675,
            "precision": 0.6070460704607046,
            "recall": 0.9313929313929314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7958790279147758,
            "auditor_fn_violation": 0.009942602277363606,
            "auditor_fp_violation": 0.00916406905646805,
            "ave_precision_score": 0.7778047788609164,
            "fpr": 0.09868421052631579,
            "logloss": 0.5516014574873435,
            "mae": 0.35326694791907803,
            "precision": 0.7940503432494279,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8181920427763184,
            "auditor_fn_violation": 0.005846765451595316,
            "auditor_fp_violation": 0.0043014321088504885,
            "ave_precision_score": 0.8015523059693106,
            "fpr": 0.09330406147091108,
            "logloss": 0.5430248961993791,
            "mae": 0.35144537687301636,
            "precision": 0.7980997624703088,
            "recall": 0.6985446985446986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.796844899208047,
            "auditor_fn_violation": 0.007948981862690555,
            "auditor_fp_violation": 0.008502177996243468,
            "ave_precision_score": 0.7512068835276006,
            "fpr": 0.18311403508771928,
            "logloss": 0.5785131156094717,
            "mae": 0.40512922994400324,
            "precision": 0.7059859154929577,
            "recall": 0.8477801268498943
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7589649977616136,
            "auditor_fn_violation": 0.003242878105666254,
            "auditor_fp_violation": 0.0006611696832001722,
            "ave_precision_score": 0.7211538581606429,
            "fpr": 0.1986827661909989,
            "logloss": 0.5941875665747174,
            "mae": 0.4101914429115019,
            "precision": 0.6916524701873935,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7934764668830688,
            "auditor_fn_violation": 0.02106051333407515,
            "auditor_fp_violation": 0.02548655237181793,
            "ave_precision_score": 0.7819416697177826,
            "fpr": 0.1337719298245614,
            "logloss": 0.5597534457939316,
            "mae": 0.3650324280177684,
            "precision": 0.7347826086956522,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8272647486185161,
            "auditor_fn_violation": 0.0340331042855741,
            "auditor_fp_violation": 0.025246981339187704,
            "ave_precision_score": 0.8164100850866419,
            "fpr": 0.10976948408342481,
            "logloss": 0.5368727177125858,
            "mae": 0.35664783266468053,
            "precision": 0.7742663656884876,
            "recall": 0.7130977130977131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8224811268137981,
            "auditor_fn_violation": 0.009713104113348916,
            "auditor_fp_violation": 0.014619050473564323,
            "ave_precision_score": 0.7278381826653725,
            "fpr": 0.13596491228070176,
            "logloss": 0.5693938000541957,
            "mae": 0.38091396416227025,
            "precision": 0.7405857740585774,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8222688295203932,
            "auditor_fn_violation": 0.01080807227898337,
            "auditor_fp_violation": 0.015132872131314938,
            "ave_precision_score": 0.7345162013273109,
            "fpr": 0.132821075740944,
            "logloss": 0.5683658678025167,
            "mae": 0.38273327060771695,
            "precision": 0.7457983193277311,
            "recall": 0.738045738045738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8396991866380923,
            "auditor_fn_violation": 0.011699770038203335,
            "auditor_fp_violation": 0.011601826319785796,
            "ave_precision_score": 0.807563162036149,
            "fpr": 0.09539473684210527,
            "logloss": 0.5226711011107446,
            "mae": 0.3356587020598613,
            "precision": 0.7995391705069125,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8214155463628467,
            "auditor_fn_violation": 0.004621272458813622,
            "auditor_fp_violation": 0.008056569575983458,
            "ave_precision_score": 0.8107642747097621,
            "fpr": 0.0889132821075741,
            "logloss": 0.5058361312335732,
            "mae": 0.3282104201459466,
            "precision": 0.8111888111888111,
            "recall": 0.7234927234927235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6190089762572125,
            "auditor_fn_violation": 0.024922573346685954,
            "auditor_fp_violation": 0.026670463173880037,
            "ave_precision_score": 0.6163935513844713,
            "fpr": 0.10307017543859649,
            "logloss": 0.743480464016622,
            "mae": 0.45924454152976213,
            "precision": 0.6713286713286714,
            "recall": 0.4059196617336152
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6393703865357092,
            "auditor_fn_violation": 0.02128295651896093,
            "auditor_fp_violation": 0.022413396982615578,
            "ave_precision_score": 0.6356018469002767,
            "fpr": 0.09001097694840834,
            "logloss": 0.7277172582698277,
            "mae": 0.4530992725727063,
            "precision": 0.712280701754386,
            "recall": 0.42203742203742206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8370938813945711,
            "auditor_fn_violation": 0.011855086977486001,
            "auditor_fp_violation": 0.01957449146784958,
            "ave_precision_score": 0.8364606528243352,
            "fpr": 0.15789473684210525,
            "logloss": 0.5704124378539762,
            "mae": 0.30788354097207876,
            "precision": 0.7203883495145631,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8592481997228462,
            "auditor_fn_violation": 0.011823611164994263,
            "auditor_fp_violation": 0.020381385137722415,
            "ave_precision_score": 0.8580500402433984,
            "fpr": 0.13830954994511527,
            "logloss": 0.5328845513374652,
            "mae": 0.29420793875471746,
            "precision": 0.7485029940119761,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 6654,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7832424524985504,
            "auditor_fn_violation": 0.013857980045250547,
            "auditor_fp_violation": 0.01488630459976821,
            "ave_precision_score": 0.7724423396896536,
            "fpr": 0.11842105263157894,
            "logloss": 0.5811388092822133,
            "mae": 0.3580155578164155,
            "precision": 0.7567567567567568,
            "recall": 0.7103594080338267
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.798761639066995,
            "auditor_fn_violation": 0.013204287627997836,
            "auditor_fp_violation": 0.0019605340413039597,
            "ave_precision_score": 0.7881187404917769,
            "fpr": 0.10098792535675083,
            "logloss": 0.5719634103453674,
            "mae": 0.35275693427112964,
            "precision": 0.7825059101654847,
            "recall": 0.6881496881496881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7599554461350684,
            "auditor_fn_violation": 0.011613997997106934,
            "auditor_fp_violation": 0.014384266474843156,
            "ave_precision_score": 0.7614993360632754,
            "fpr": 0.2741228070175439,
            "logloss": 0.930553963912352,
            "mae": 0.3764675780758057,
            "precision": 0.6069182389937107,
            "recall": 0.8160676532769556
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8066900698262401,
            "auditor_fn_violation": 0.011002051616760732,
            "auditor_fp_violation": 0.011824470936614503,
            "ave_precision_score": 0.8069770152918143,
            "fpr": 0.2502744237102086,
            "logloss": 0.8450259903841973,
            "mae": 0.34345418950246337,
            "precision": 0.6415094339622641,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.589246014457852,
            "auditor_fn_violation": 0.007909573087051675,
            "auditor_fp_violation": 0.013769831754785598,
            "ave_precision_score": 0.5783432049224274,
            "fpr": 0.0800438596491228,
            "logloss": 2.79663855230021,
            "mae": 0.48025427554287653,
            "precision": 0.5575757575757576,
            "recall": 0.1945031712473573
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5883647388421609,
            "auditor_fn_violation": 0.01990228005595734,
            "auditor_fp_violation": 0.006759757996579281,
            "ave_precision_score": 0.575654591280778,
            "fpr": 0.09001097694840834,
            "logloss": 3.263621765694032,
            "mae": 0.49149243843302437,
            "precision": 0.5089820359281437,
            "recall": 0.17671517671517672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6044309196414712,
            "auditor_fn_violation": 0.012784670449909127,
            "auditor_fp_violation": 0.017526375734324424,
            "ave_precision_score": 0.5933913904616926,
            "fpr": 0.12280701754385964,
            "logloss": 1.6977187888061085,
            "mae": 0.44904027539158914,
            "precision": 0.5757575757575758,
            "recall": 0.321353065539112
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.649773394428971,
            "auditor_fn_violation": 0.008322854645576938,
            "auditor_fp_violation": 0.005258724121205937,
            "ave_precision_score": 0.6425487227488841,
            "fpr": 0.09330406147091108,
            "logloss": 1.3371766851681477,
            "mae": 0.4377071934807136,
            "precision": 0.6413502109704642,
            "recall": 0.316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6476049729835374,
            "auditor_fn_violation": 0.01560123882645303,
            "auditor_fp_violation": 0.011009870918754746,
            "ave_precision_score": 0.6390938384555054,
            "fpr": 0.03618421052631579,
            "logloss": 9.471971625977545,
            "mae": 0.44669506340950055,
            "precision": 0.7950310559006211,
            "recall": 0.27061310782241016
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.655079621789739,
            "auditor_fn_violation": 0.01431795723782551,
            "auditor_fp_violation": 0.004694560028591122,
            "ave_precision_score": 0.6436497241833905,
            "fpr": 0.036223929747530186,
            "logloss": 9.42923701325299,
            "mae": 0.44923953008839856,
            "precision": 0.8,
            "recall": 0.27442827442827444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6744760119749703,
            "auditor_fn_violation": 0.01821380883498388,
            "auditor_fp_violation": 0.009116612716301003,
            "ave_precision_score": 0.6753136638236303,
            "fpr": 0.0537280701754386,
            "logloss": 1.546269966489801,
            "mae": 0.43677192278192467,
            "precision": 0.73224043715847,
            "recall": 0.2832980972515856
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6818369244499197,
            "auditor_fn_violation": 0.0268467403483869,
            "auditor_fp_violation": 0.010251959257651959,
            "ave_precision_score": 0.6826607628063754,
            "fpr": 0.0570801317233809,
            "logloss": 1.4536251716146351,
            "mae": 0.44532584888117294,
            "precision": 0.7158469945355191,
            "recall": 0.27234927234927236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7967731201920336,
            "auditor_fn_violation": 0.017344497607655503,
            "auditor_fp_violation": 0.04715411821124565,
            "ave_precision_score": 0.761575888560524,
            "fpr": 0.1962719298245614,
            "logloss": 0.5979107324205746,
            "mae": 0.3899921254201776,
            "precision": 0.6721611721611722,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8357098165051434,
            "auditor_fn_violation": 0.028238827360671497,
            "auditor_fp_violation": 0.04418859929032752,
            "ave_precision_score": 0.8075792792355654,
            "fpr": 0.16575192096597147,
            "logloss": 0.5706223643438398,
            "mae": 0.3720852660687904,
            "precision": 0.7084942084942085,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6802822327915816,
            "auditor_fn_violation": 0.0006050406142205527,
            "auditor_fp_violation": 0.0077079087239739445,
            "ave_precision_score": 0.613731739895508,
            "fpr": 0.046052631578947366,
            "logloss": 0.6829122542241308,
            "mae": 0.4705981764239831,
            "precision": 0.7103448275862069,
            "recall": 0.21775898520084566
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6492387036495084,
            "auditor_fn_violation": 0.007866432674336071,
            "auditor_fp_violation": 0.0039108569678094635,
            "ave_precision_score": 0.6006286503798434,
            "fpr": 0.05378704720087816,
            "logloss": 0.6992175448823013,
            "mae": 0.4761484972028518,
            "precision": 0.6573426573426573,
            "recall": 0.19542619542619544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7581466680617197,
            "auditor_fn_violation": 0.014544156374021738,
            "auditor_fp_violation": 0.029023298565319912,
            "ave_precision_score": 0.7029049659920474,
            "fpr": 0.17434210526315788,
            "logloss": 5.234402463442553,
            "mae": 0.333081206548528,
            "precision": 0.6761710794297352,
            "recall": 0.7019027484143763
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7782404547345914,
            "auditor_fn_violation": 0.018434883418418,
            "auditor_fp_violation": 0.015212008271002995,
            "ave_precision_score": 0.7224118456476494,
            "fpr": 0.16136114160263446,
            "logloss": 4.912018494606128,
            "mae": 0.309361109928644,
            "precision": 0.706,
            "recall": 0.7338877338877339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8458978389367391,
            "auditor_fn_violation": 0.010454916360669116,
            "auditor_fp_violation": 0.01038044998601287,
            "ave_precision_score": 0.7941494231993702,
            "fpr": 0.08991228070175439,
            "logloss": 0.5163795206890339,
            "mae": 0.3329874715816818,
            "precision": 0.8088578088578089,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.859179051217136,
            "auditor_fn_violation": 0.0059061003078566265,
            "auditor_fp_violation": 0.008426722487427566,
            "ave_precision_score": 0.8119160418420281,
            "fpr": 0.09110867178924259,
            "logloss": 0.5072650008264564,
            "mae": 0.328292696547626,
            "precision": 0.8074245939675174,
            "recall": 0.7234927234927235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.36637299183062216,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.001158933780921563,
            "ave_precision_score": 0.3677864474490726,
            "fpr": 0.4791666666666667,
            "logloss": 0.6924089186578795,
            "mae": 0.49943976058510314,
            "precision": 0.5197802197802198,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.37222129370947693,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011947004314196061,
            "ave_precision_score": 0.3736190837422111,
            "fpr": 0.46871569703622395,
            "logloss": 0.6918909338215817,
            "mae": 0.4991813605297541,
            "precision": 0.5297356828193832,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8165873042309855,
            "auditor_fn_violation": 0.00752475798375432,
            "auditor_fp_violation": 0.01195650001998162,
            "ave_precision_score": 0.7924075607961365,
            "fpr": 0.0712719298245614,
            "logloss": 0.5714108539133897,
            "mae": 0.3865856599520173,
            "precision": 0.8042168674698795,
            "recall": 0.5644820295983086
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8315195625593774,
            "auditor_fn_violation": 0.016981179440015887,
            "auditor_fp_violation": 0.0074796415898705755,
            "ave_precision_score": 0.8104499450275466,
            "fpr": 0.05817782656421515,
            "logloss": 0.5698435399348034,
            "mae": 0.3851763837113077,
            "precision": 0.8403614457831325,
            "recall": 0.58004158004158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7875949600445675,
            "auditor_fn_violation": 0.013570527799413982,
            "auditor_fp_violation": 0.009056667865563682,
            "ave_precision_score": 0.7169042946054107,
            "fpr": 0.11293859649122807,
            "logloss": 0.5846407853924394,
            "mae": 0.38862434722352446,
            "precision": 0.7610208816705336,
            "recall": 0.693446088794926
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7925254977109693,
            "auditor_fn_violation": 0.011180056185544669,
            "auditor_fp_violation": 0.006920583054655,
            "ave_precision_score": 0.7287264112370517,
            "fpr": 0.10647639956092206,
            "logloss": 0.5840662117466471,
            "mae": 0.38948130574891127,
            "precision": 0.7706855791962175,
            "recall": 0.6777546777546778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7551431179304323,
            "auditor_fn_violation": 0.007346259411742884,
            "auditor_fp_violation": 0.010125684370379253,
            "ave_precision_score": 0.7561231907908541,
            "fpr": 0.039473684210526314,
            "logloss": 0.6203540795070568,
            "mae": 0.39763149163959416,
            "precision": 0.8554216867469879,
            "recall": 0.4503171247357294
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7708885191570023,
            "auditor_fn_violation": 0.02207256652920759,
            "auditor_fp_violation": 0.005756515967630767,
            "ave_precision_score": 0.7712964116141684,
            "fpr": 0.038419319429198684,
            "logloss": 0.6193495337388409,
            "mae": 0.399472753183035,
            "precision": 0.8559670781893004,
            "recall": 0.43243243243243246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7956385261694319,
            "auditor_fn_violation": 0.014370294128556083,
            "auditor_fp_violation": 0.010772589217919517,
            "ave_precision_score": 0.6763293350655653,
            "fpr": 0.05701754385964912,
            "logloss": 0.5968589784595323,
            "mae": 0.4132477019570376,
            "precision": 0.8243243243243243,
            "recall": 0.5158562367864693
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7986810786716698,
            "auditor_fn_violation": 0.002889151077954591,
            "auditor_fp_violation": 0.015495366706660197,
            "ave_precision_score": 0.6811586697112807,
            "fpr": 0.054884742041712405,
            "logloss": 0.5984301798804328,
            "mae": 0.4143502835580991,
            "precision": 0.8299319727891157,
            "recall": 0.5072765072765073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 6654,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8456503875217805,
            "auditor_fn_violation": 0.007721801861948746,
            "auditor_fp_violation": 0.008811893058386292,
            "ave_precision_score": 0.8459664511157505,
            "fpr": 0.12609649122807018,
            "logloss": 0.5274643678893284,
            "mae": 0.29293844324454993,
            "precision": 0.760914760914761,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.863972588651259,
            "auditor_fn_violation": 0.007841329465917833,
            "auditor_fp_violation": 0.009368697827585325,
            "ave_precision_score": 0.8642330684045549,
            "fpr": 0.10976948408342481,
            "logloss": 0.4879037834286682,
            "mae": 0.2781508847600102,
            "precision": 0.7920997920997921,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8493883638834956,
            "auditor_fn_violation": 0.009560105337339128,
            "auditor_fp_violation": 0.018010929944451106,
            "ave_precision_score": 0.8398985538586776,
            "fpr": 0.08881578947368421,
            "logloss": 0.5165208704139292,
            "mae": 0.3031321915873457,
            "precision": 0.80622009569378,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8480357841682794,
            "auditor_fn_violation": 0.011225698382668754,
            "auditor_fp_violation": 0.007903402854006586,
            "ave_precision_score": 0.8392137332459887,
            "fpr": 0.07354555433589462,
            "logloss": 0.5256270037950066,
            "mae": 0.3068429187919564,
            "precision": 0.8308080808080808,
            "recall": 0.683991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7546405642740871,
            "auditor_fn_violation": 0.0023853900077890284,
            "auditor_fp_violation": 0.0035092714702473693,
            "ave_precision_score": 0.521420835626322,
            "fpr": 0.46381578947368424,
            "logloss": 0.6931003083403544,
            "mae": 0.49796051244463835,
            "precision": 0.5214932126696833,
            "recall": 0.9746300211416491
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7571123864061363,
            "auditor_fn_violation": 0.004025641786344312,
            "auditor_fp_violation": 0.00044673627243256125,
            "ave_precision_score": 0.5289146569686721,
            "fpr": 0.45554335894621295,
            "logloss": 0.6921223667278431,
            "mae": 0.49747460295418616,
            "precision": 0.52894438138479,
            "recall": 0.9688149688149689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7142928115195768,
            "auditor_fn_violation": 0.0891982864137087,
            "auditor_fp_violation": 0.09932611996962794,
            "ave_precision_score": 0.5432608435684239,
            "fpr": 0.31359649122807015,
            "logloss": 0.6914536232802515,
            "mae": 0.49028257581225615,
            "precision": 0.5517241379310345,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7267955301742883,
            "auditor_fn_violation": 0.0937924329801388,
            "auditor_fp_violation": 0.10486814898016493,
            "ave_precision_score": 0.5643359515812729,
            "fpr": 0.2854006586169045,
            "logloss": 0.6840634400518888,
            "mae": 0.4863023384996617,
            "precision": 0.5772357723577236,
            "recall": 0.738045738045738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 6654,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6313144432939326,
            "auditor_fn_violation": 0.005315548384703836,
            "auditor_fp_violation": 0.013812292690724535,
            "ave_precision_score": 0.5190086025155668,
            "fpr": 0.22478070175438597,
            "logloss": 0.9014302379006369,
            "mae": 0.5064227946690822,
            "precision": 0.5187793427230047,
            "recall": 0.46723044397463004
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.6278335456187805,
            "auditor_fn_violation": 0.020043770867041996,
            "auditor_fp_violation": 0.014905674827049244,
            "ave_precision_score": 0.5177748365667829,
            "fpr": 0.24259055982436883,
            "logloss": 0.9215100579855308,
            "mae": 0.5178450698975543,
            "precision": 0.5055928411633109,
            "recall": 0.4698544698544699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6314161083158392,
            "auditor_fn_violation": 0.0027029783761729907,
            "auditor_fp_violation": 0.0034393358110538304,
            "ave_precision_score": 0.5390460241888664,
            "fpr": 0.4692982456140351,
            "logloss": 0.6896291178655475,
            "mae": 0.49239889019283284,
            "precision": 0.5207166853303471,
            "recall": 0.9830866807610994
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6339692283738896,
            "auditor_fn_violation": 0.001227775102637891,
            "auditor_fp_violation": 0.00393127919740639,
            "ave_precision_score": 0.549006444004978,
            "fpr": 0.4522502744237102,
            "logloss": 0.6848741037993485,
            "mae": 0.4905242080484342,
            "precision": 0.5355129650507328,
            "recall": 0.9875259875259875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8479607233697399,
            "auditor_fn_violation": 0.0065696747153295544,
            "auditor_fp_violation": 0.005909563201854297,
            "ave_precision_score": 0.794978608802464,
            "fpr": 0.08991228070175439,
            "logloss": 0.5223123438398749,
            "mae": 0.3347893664164044,
            "precision": 0.8066037735849056,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8525646364392898,
            "auditor_fn_violation": 0.009468473793391476,
            "auditor_fp_violation": 0.005488474204171243,
            "ave_precision_score": 0.7996556747222164,
            "fpr": 0.09001097694840834,
            "logloss": 0.517273074531618,
            "mae": 0.33293426658806896,
            "precision": 0.8088578088578089,
            "recall": 0.7214137214137214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5212694295277276,
            "auditor_fn_violation": 0.009926375134453476,
            "auditor_fp_violation": 0.007830296127562647,
            "ave_precision_score": 0.5269272232309709,
            "fpr": 0.09758771929824561,
            "logloss": 7.755826228069515,
            "mae": 0.4710894351562424,
            "precision": 0.644,
            "recall": 0.3403805496828753
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5170054871856182,
            "auditor_fn_violation": 0.011271340579792845,
            "auditor_fp_violation": 0.004600107216705389,
            "ave_precision_score": 0.52561862863665,
            "fpr": 0.10757409440175632,
            "logloss": 8.166395132682174,
            "mae": 0.47844037104430676,
            "precision": 0.6186770428015564,
            "recall": 0.3305613305613306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6225887827965538,
            "auditor_fn_violation": 0.0020678016394050725,
            "auditor_fp_violation": 0.00883437237741278,
            "ave_precision_score": 0.5764983977640523,
            "fpr": 0.0712719298245614,
            "logloss": 0.6750131204334894,
            "mae": 0.47100147835322115,
            "precision": 0.5886075949367089,
            "recall": 0.19661733615221988
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6232564589599607,
            "auditor_fn_violation": 0.010039001257442547,
            "auditor_fp_violation": 0.010394914864830369,
            "ave_precision_score": 0.575833631687734,
            "fpr": 0.07903402854006586,
            "logloss": 0.6837848236103851,
            "mae": 0.47688042495959937,
            "precision": 0.5838150289017341,
            "recall": 0.20997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7011435678499875,
            "auditor_fn_violation": 0.004889006342494724,
            "auditor_fp_violation": 0.004535827039124007,
            "ave_precision_score": 0.643845399921552,
            "fpr": 0.03179824561403509,
            "logloss": 0.6571081724083369,
            "mae": 0.44603599027093305,
            "precision": 0.7387387387387387,
            "recall": 0.1733615221987315
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6929515895249199,
            "auditor_fn_violation": 0.006476627771907699,
            "auditor_fp_violation": 0.006851658029765401,
            "ave_precision_score": 0.6420138280513448,
            "fpr": 0.031833150384193196,
            "logloss": 0.6745004781786551,
            "mae": 0.45371959049307814,
            "precision": 0.7264150943396226,
            "recall": 0.1600831600831601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 6654,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7350019096306808,
            "auditor_fn_violation": 0.013308575349579025,
            "auditor_fp_violation": 0.009813471606122368,
            "ave_precision_score": 0.7354651858132634,
            "fpr": 0.0756578947368421,
            "logloss": 0.6893854658102976,
            "mae": 0.42921515242855285,
            "precision": 0.7434944237918215,
            "recall": 0.42283298097251587
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7477815426895866,
            "auditor_fn_violation": 0.007371214835539771,
            "auditor_fp_violation": 0.002828478799172902,
            "ave_precision_score": 0.7481282332933367,
            "fpr": 0.07464324917672886,
            "logloss": 0.6979964660443928,
            "mae": 0.4321209971916823,
            "precision": 0.7527272727272727,
            "recall": 0.4303534303534304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.5653084975376075,
            "auditor_fn_violation": 0.021640054152294055,
            "auditor_fp_violation": 0.07144427127043122,
            "ave_precision_score": 0.567147865680448,
            "fpr": 0.24342105263157895,
            "logloss": 0.7576859397372516,
            "mae": 0.46121125341507424,
            "precision": 0.628140703517588,
            "recall": 0.7928118393234672
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.5513351499975212,
            "auditor_fn_violation": 0.011264494250224223,
            "auditor_fp_violation": 0.07302989303857248,
            "ave_precision_score": 0.5528613745495327,
            "fpr": 0.24039517014270034,
            "logloss": 0.7882555314510276,
            "mae": 0.4688719069395055,
            "precision": 0.6313131313131313,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8411932754303355,
            "auditor_fn_violation": 0.014189477393271768,
            "auditor_fp_violation": 0.010263057986652285,
            "ave_precision_score": 0.8414137282475525,
            "fpr": 0.08881578947368421,
            "logloss": 0.5540287812123255,
            "mae": 0.31232392007248627,
            "precision": 0.7964824120603015,
            "recall": 0.6701902748414377
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8504707832366034,
            "auditor_fn_violation": 0.00945706324411045,
            "auditor_fp_violation": 0.007471983253771727,
            "ave_precision_score": 0.8507106312126828,
            "fpr": 0.0867178924259056,
            "logloss": 0.524661383478932,
            "mae": 0.3094324332770036,
            "precision": 0.808252427184466,
            "recall": 0.6923076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 6654,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.831674399384051,
            "auditor_fn_violation": 0.010686732687956684,
            "auditor_fp_violation": 0.013047995843823679,
            "ave_precision_score": 0.7483618861175876,
            "fpr": 0.11842105263157894,
            "logloss": 0.5434516326817669,
            "mae": 0.3450692113194811,
            "precision": 0.7687366167023555,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8459808684889106,
            "auditor_fn_violation": 0.003208646457823189,
            "auditor_fp_violation": 0.025369514716769206,
            "ave_precision_score": 0.7744959578317141,
            "fpr": 0.12952799121844127,
            "logloss": 0.5310835340238094,
            "mae": 0.3425195243467222,
            "precision": 0.7581967213114754,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6123695635616816,
            "auditor_fn_violation": 0.04445541708393606,
            "auditor_fp_violation": 0.06746792950485554,
            "ave_precision_score": 0.6081445596688945,
            "fpr": 0.2730263157894737,
            "logloss": 0.667293482009966,
            "mae": 0.47711811119919284,
            "precision": 0.5897858319604613,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6321824818847914,
            "auditor_fn_violation": 0.043177518479384565,
            "auditor_fp_violation": 0.06394710642534399,
            "ave_precision_score": 0.6176669815286174,
            "fpr": 0.24698133918770582,
            "logloss": 0.6616951845354839,
            "mae": 0.47407209496990127,
            "precision": 0.6160409556313993,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6488750088044584,
            "auditor_fn_violation": 0.03485822113423094,
            "auditor_fp_violation": 0.020793370099508456,
            "ave_precision_score": 0.6288182029750673,
            "fpr": 0.1425438596491228,
            "logloss": 0.6952293507285981,
            "mae": 0.4559265062980877,
            "precision": 0.616519174041298,
            "recall": 0.4418604651162791
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7034001731340185,
            "auditor_fn_violation": 0.0278120728175613,
            "auditor_fp_violation": 0.006611696832001635,
            "ave_precision_score": 0.6817784329364056,
            "fpr": 0.11964873765093303,
            "logloss": 0.6526288621210975,
            "mae": 0.4380313301894458,
            "precision": 0.6812865497076024,
            "recall": 0.48440748440748443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6357376391683304,
            "auditor_fn_violation": 0.010434052891213236,
            "auditor_fp_violation": 0.011929025296727009,
            "ave_precision_score": 0.6097391355316348,
            "fpr": 0.3618421052631579,
            "logloss": 0.6795573974321523,
            "mae": 0.48586421639642174,
            "precision": 0.5528455284552846,
            "recall": 0.8625792811839323
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6231737628023186,
            "auditor_fn_violation": 0.0029918460214837846,
            "auditor_fp_violation": 0.008715186480484017,
            "ave_precision_score": 0.6099543004657836,
            "fpr": 0.36882546652030734,
            "logloss": 0.6769459472689695,
            "mae": 0.48365715658036595,
            "precision": 0.5642023346303502,
            "recall": 0.9043659043659044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.40134051654859487,
            "auditor_fn_violation": 0.0020770742924965673,
            "auditor_fp_violation": 0.0017384006713823284,
            "ave_precision_score": 0.5184433069989985,
            "fpr": 0.005482456140350877,
            "logloss": 17.89812609868865,
            "mae": 0.5196578616884963,
            "precision": 0.4444444444444444,
            "recall": 0.008456659619450317
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.4748418706423807,
            "auditor_fn_violation": 0.000842098536939384,
            "auditor_fp_violation": 0.0009955836928496667,
            "ave_precision_score": 0.5313260655741445,
            "fpr": 0.0021953896816684962,
            "logloss": 18.07075415223404,
            "mae": 0.5246966156316448,
            "precision": 0.7142857142857143,
            "recall": 0.010395010395010396
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8109389007879649,
            "auditor_fn_violation": 0.01061486962649754,
            "auditor_fp_violation": 0.011601826319785796,
            "ave_precision_score": 0.7861353722554663,
            "fpr": 0.09539473684210527,
            "logloss": 0.5591921000526946,
            "mae": 0.36196436523868325,
            "precision": 0.7990762124711316,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8142559313363084,
            "auditor_fn_violation": 0.004477499537872759,
            "auditor_fp_violation": 0.008056569575983458,
            "ave_precision_score": 0.7975172637403065,
            "fpr": 0.0889132821075741,
            "logloss": 0.5599703572093673,
            "mae": 0.36391211033653864,
            "precision": 0.8098591549295775,
            "recall": 0.7172557172557172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7636029782898275,
            "auditor_fn_violation": 0.014061978413263605,
            "auditor_fp_violation": 0.022039723454421938,
            "ave_precision_score": 0.6498457907278866,
            "fpr": 0.16337719298245615,
            "logloss": 0.631946677878155,
            "mae": 0.42216760018971144,
            "precision": 0.6788793103448276,
            "recall": 0.6659619450317125
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7896973967789963,
            "auditor_fn_violation": 0.013825021508885402,
            "auditor_fp_violation": 0.015760855691420113,
            "ave_precision_score": 0.6847396819068916,
            "fpr": 0.14050493962678376,
            "logloss": 0.6045068192041927,
            "mae": 0.40845796808551355,
            "precision": 0.7253218884120172,
            "recall": 0.7027027027027027
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5826085697986423,
            "auditor_fn_violation": 0.006627628797151455,
            "auditor_fp_violation": 0.0197568237221756,
            "ave_precision_score": 0.5814314097763746,
            "fpr": 0.14473684210526316,
            "logloss": 8.596974556556349,
            "mae": 0.46545935596755483,
            "precision": 0.580952380952381,
            "recall": 0.386892177589852
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6398578333391975,
            "auditor_fn_violation": 0.008781558726673981,
            "auditor_fp_violation": 0.012294182217343587,
            "ave_precision_score": 0.6359355147280219,
            "fpr": 0.12843029637760703,
            "logloss": 8.41078369807197,
            "mae": 0.45451817840612335,
            "precision": 0.6125827814569537,
            "recall": 0.38461538461538464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.655225243700561,
            "auditor_fn_violation": 0.008718612069285267,
            "auditor_fp_violation": 0.008622067697718103,
            "ave_precision_score": 0.6545767539827685,
            "fpr": 0.047149122807017545,
            "logloss": 6.377442251952202,
            "mae": 0.4452861166256474,
            "precision": 0.7556818181818182,
            "recall": 0.28118393234672306
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6531259433217483,
            "auditor_fn_violation": 0.0050320522329304,
            "auditor_fp_violation": 2.5527786996146858e-05,
            "ave_precision_score": 0.6520528143514531,
            "fpr": 0.043907793633369926,
            "logloss": 6.242117862003421,
            "mae": 0.45900467071386536,
            "precision": 0.7633136094674556,
            "recall": 0.2681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 6654,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7960867953656218,
            "auditor_fn_violation": 0.00888320166165944,
            "auditor_fp_violation": 0.0069411141749590385,
            "ave_precision_score": 0.7801051034608352,
            "fpr": 0.07236842105263158,
            "logloss": 0.5658989433268689,
            "mae": 0.3653282427408716,
            "precision": 0.8221024258760108,
            "recall": 0.6448202959830867
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8031221818948253,
            "auditor_fn_violation": 0.011622785497648298,
            "auditor_fp_violation": 0.0007352002654889845,
            "ave_precision_score": 0.7864503090842327,
            "fpr": 0.06695938529088913,
            "logloss": 0.5752483256417498,
            "mae": 0.36784496802006544,
            "precision": 0.8342391304347826,
            "recall": 0.6382536382536382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.744099282799853,
            "auditor_fn_violation": 0.014416657394013578,
            "auditor_fp_violation": 0.04586280621827919,
            "ave_precision_score": 0.6877158543721678,
            "fpr": 0.25548245614035087,
            "logloss": 0.6112688227408856,
            "mae": 0.39877011376563787,
            "precision": 0.6381987577639752,
            "recall": 0.86892177589852
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7577579535264152,
            "auditor_fn_violation": 0.016086592376383817,
            "auditor_fp_violation": 0.032381997804610325,
            "ave_precision_score": 0.6985152478778254,
            "fpr": 0.23600439077936333,
            "logloss": 0.6033951226954926,
            "mae": 0.3992494313224218,
            "precision": 0.6565495207667732,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6895044973326507,
            "auditor_fn_violation": 0.0026334334779867237,
            "auditor_fp_violation": 0.02353834472285498,
            "ave_precision_score": 0.6913056710615488,
            "fpr": 0.17105263157894737,
            "logloss": 0.6483350655441313,
            "mae": 0.40562599726335813,
            "precision": 0.6630669546436285,
            "recall": 0.6490486257928119
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7061851168261359,
            "auditor_fn_violation": 0.012884792248129252,
            "auditor_fp_violation": 0.02047839072830777,
            "ave_precision_score": 0.7067452041145935,
            "fpr": 0.1690450054884742,
            "logloss": 0.6507418983849573,
            "mae": 0.41798395026499724,
            "precision": 0.6515837104072398,
            "recall": 0.5987525987525988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8490214221245205,
            "auditor_fn_violation": 0.027059919884277295,
            "auditor_fp_violation": 0.020398733165487754,
            "ave_precision_score": 0.846469181121318,
            "fpr": 0.11732456140350878,
            "logloss": 0.5094622764270439,
            "mae": 0.3087562529284409,
            "precision": 0.7703862660944206,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8626732744107645,
            "auditor_fn_violation": 0.02592248585662417,
            "auditor_fp_violation": 0.016715594925075947,
            "ave_precision_score": 0.8595212903828917,
            "fpr": 0.10098792535675083,
            "logloss": 0.4897233526645238,
            "mae": 0.3019613865640272,
            "precision": 0.7991266375545851,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8351119885733032,
            "auditor_fn_violation": 0.012726716368087244,
            "auditor_fp_violation": 0.011666766574751226,
            "ave_precision_score": 0.8364662642407732,
            "fpr": 0.09978070175438597,
            "logloss": 0.5010774964429755,
            "mae": 0.3250794703949635,
            "precision": 0.7931818181818182,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8530595852730678,
            "auditor_fn_violation": 0.004689735754499749,
            "auditor_fp_violation": 0.011518137492660762,
            "ave_precision_score": 0.8533909866484778,
            "fpr": 0.09220636663007684,
            "logloss": 0.4965337434426317,
            "mae": 0.32906741379227583,
            "precision": 0.8060046189376443,
            "recall": 0.7255717255717256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7733619266878615,
            "auditor_fn_violation": 0.01004228329809725,
            "auditor_fp_violation": 0.012905626823322549,
            "ave_precision_score": 0.76343138325616,
            "fpr": 0.08662280701754387,
            "logloss": 0.5352984303923511,
            "mae": 0.35513514431454896,
            "precision": 0.8110047846889952,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.7702475102141058,
            "auditor_fn_violation": 0.003977717479364024,
            "auditor_fp_violation": 0.009690347943736759,
            "ave_precision_score": 0.7655359917625053,
            "fpr": 0.0867178924259056,
            "logloss": 0.5371684297431967,
            "mae": 0.35870992810221064,
            "precision": 0.8119047619047619,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.529440494125331,
            "auditor_fn_violation": 0.030022532547012353,
            "auditor_fp_violation": 0.03080416017264117,
            "ave_precision_score": 0.5308557424108045,
            "fpr": 0.3157894736842105,
            "logloss": 1.5191325912338378,
            "mae": 0.4830520115785771,
            "precision": 0.55895865237366,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5420862175066943,
            "auditor_fn_violation": 0.03664612007092799,
            "auditor_fp_violation": 0.024299900441630724,
            "ave_precision_score": 0.5434092394849068,
            "fpr": 0.2996706915477497,
            "logloss": 1.7761367348580686,
            "mae": 0.4832532441198372,
            "precision": 0.5700787401574803,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.754742984110949,
            "auditor_fn_violation": 0.007425076963020661,
            "auditor_fp_violation": 0.026041042241138172,
            "ave_precision_score": 0.7553710590695655,
            "fpr": 0.2412280701754386,
            "logloss": 1.0551100556113433,
            "mae": 0.33784098231873305,
            "precision": 0.6405228758169934,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7762528563470634,
            "auditor_fn_violation": 0.01427003293084523,
            "auditor_fp_violation": 0.014928649835345783,
            "ave_precision_score": 0.7766987413081929,
            "fpr": 0.2261251372118551,
            "logloss": 0.9480758506794589,
            "mae": 0.3131969065807675,
            "precision": 0.6639477977161501,
            "recall": 0.8461538461538461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.726119124931298,
            "auditor_fn_violation": 0.08551240680983643,
            "auditor_fp_violation": 0.09980318107341248,
            "ave_precision_score": 0.5578453388901814,
            "fpr": 0.29605263157894735,
            "logloss": 0.7036240939461565,
            "mae": 0.4721802596264241,
            "precision": 0.569377990430622,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7409408960435468,
            "auditor_fn_violation": 0.08852075921230697,
            "auditor_fp_violation": 0.09739106016899395,
            "ave_precision_score": 0.5810886207268655,
            "fpr": 0.2667398463227223,
            "logloss": 0.6854270338556312,
            "mae": 0.46301210793522396,
            "precision": 0.5983471074380166,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5106321262034902,
            "auditor_fn_violation": 0.0966952264381885,
            "auditor_fp_violation": 0.06746043639851339,
            "ave_precision_score": 0.5226442340657788,
            "fpr": 0.2894736842105263,
            "logloss": 0.6946423900411612,
            "mae": 0.5001745653060967,
            "precision": 0.5440414507772021,
            "recall": 0.6659619450317125
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5481261695229567,
            "auditor_fn_violation": 0.09107672225125574,
            "auditor_fp_violation": 0.06997166415643429,
            "ave_precision_score": 0.547603796848984,
            "fpr": 0.2689352360043908,
            "logloss": 0.6913573746723485,
            "mae": 0.49853577401844784,
            "precision": 0.5679012345679012,
            "recall": 0.6694386694386695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8086363510371652,
            "auditor_fn_violation": 0.03172870071584882,
            "auditor_fp_violation": 0.03254006314190945,
            "ave_precision_score": 0.8023585446602063,
            "fpr": 0.15021929824561403,
            "logloss": 0.545302697049173,
            "mae": 0.36209697152177495,
            "precision": 0.7365384615384616,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8201694862591807,
            "auditor_fn_violation": 0.03705005351547613,
            "auditor_fp_violation": 0.03648431317489088,
            "ave_precision_score": 0.8164552172668701,
            "fpr": 0.15148188803512624,
            "logloss": 0.5274265716496892,
            "mae": 0.3548212259778861,
            "precision": 0.7351247600767754,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8030867723897359,
            "auditor_fn_violation": 0.002160528170320096,
            "auditor_fp_violation": 0.01340516724613356,
            "ave_precision_score": 0.8199187831900951,
            "fpr": 0.09978070175438597,
            "logloss": 0.5122623706645429,
            "mae": 0.31443837234799404,
            "precision": 0.796875,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8429507381457496,
            "auditor_fn_violation": 0.018302521046758155,
            "auditor_fp_violation": 0.008847930972863962,
            "ave_precision_score": 0.8415348726569758,
            "fpr": 0.09549945115257959,
            "logloss": 0.49953599662160475,
            "mae": 0.30967991402051714,
            "precision": 0.8044943820224719,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 6654,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8412865067778305,
            "auditor_fn_violation": 0.007114443084455331,
            "auditor_fp_violation": 0.006653878431842705,
            "ave_precision_score": 0.8345861866794941,
            "fpr": 0.08662280701754387,
            "logloss": 0.508079540682094,
            "mae": 0.3090670079425827,
            "precision": 0.8119047619047619,
            "recall": 0.7209302325581395
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8533340194992615,
            "auditor_fn_violation": 0.010310572330330843,
            "auditor_fp_violation": 0.005856074336915737,
            "ave_precision_score": 0.8451454565430059,
            "fpr": 0.07793633369923161,
            "logloss": 0.49808598993650816,
            "mae": 0.306219623457849,
            "precision": 0.829736211031175,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7569471222243627,
            "auditor_fn_violation": 0.016813638218166983,
            "auditor_fp_violation": 0.011966490828437839,
            "ave_precision_score": 0.7531951916363363,
            "fpr": 0.0800438596491228,
            "logloss": 0.6256142305434691,
            "mae": 0.3765171970559382,
            "precision": 0.7914285714285715,
            "recall": 0.5856236786469344
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7856996816642733,
            "auditor_fn_violation": 0.008473473896086419,
            "auditor_fp_violation": 0.004161029280371686,
            "ave_precision_score": 0.7725886779619748,
            "fpr": 0.07683863885839737,
            "logloss": 0.6111343004423115,
            "mae": 0.37424793167798304,
            "precision": 0.7988505747126436,
            "recall": 0.577962577962578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6923593186295159,
            "auditor_fn_violation": 0.020501835985312127,
            "auditor_fp_violation": 0.0019906685849018927,
            "ave_precision_score": 0.6830026418441487,
            "fpr": 0.05592105263157895,
            "logloss": 0.6907257978120009,
            "mae": 0.42670902933337185,
            "precision": 0.7213114754098361,
            "recall": 0.27906976744186046
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.696616564839337,
            "auditor_fn_violation": 0.018069745841425313,
            "auditor_fp_violation": 0.008082097362979605,
            "ave_precision_score": 0.6856730701304474,
            "fpr": 0.05598243688254665,
            "logloss": 0.6858023261422045,
            "mae": 0.4309581926442135,
            "precision": 0.7166666666666667,
            "recall": 0.2681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8064107359113846,
            "auditor_fn_violation": 0.01112022921998443,
            "auditor_fp_violation": 0.009825960116692645,
            "ave_precision_score": 0.761339604021389,
            "fpr": 0.08881578947368421,
            "logloss": 0.5355830196563878,
            "mae": 0.3374810694663769,
            "precision": 0.8071428571428572,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7869644365899648,
            "auditor_fn_violation": 0.005481627874602628,
            "auditor_fp_violation": 0.0042733515431547285,
            "ave_precision_score": 0.758377879158828,
            "fpr": 0.08122941822173436,
            "logloss": 0.5552505618930677,
            "mae": 0.3459050571801536,
            "precision": 0.821256038647343,
            "recall": 0.7068607068607069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5810909509784811,
            "auditor_fn_violation": 0.0010849004117057975,
            "auditor_fp_violation": 0.0035767094273268874,
            "ave_precision_score": 0.5821279944536293,
            "fpr": 0.4550438596491228,
            "logloss": 0.6912642110271504,
            "mae": 0.49828447378649,
            "precision": 0.5273348519362187,
            "recall": 0.9788583509513742
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.590605194142363,
            "auditor_fn_violation": 0.0016613759753166999,
            "auditor_fp_violation": 0.005539529778163548,
            "ave_precision_score": 0.5927591993869806,
            "fpr": 0.44127332601536773,
            "logloss": 0.6904668556794734,
            "mae": 0.497899420502157,
            "precision": 0.5379310344827586,
            "recall": 0.972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.843098426381601,
            "auditor_fn_violation": 0.0063216312451318665,
            "auditor_fp_violation": 0.006066918435039762,
            "ave_precision_score": 0.8410164006659655,
            "fpr": 0.07017543859649122,
            "logloss": 0.5219859402112463,
            "mae": 0.3199322175570527,
            "precision": 0.8337662337662337,
            "recall": 0.678646934460888
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8526785038616931,
            "auditor_fn_violation": 0.007656478567565288,
            "auditor_fp_violation": 0.00557782145865775,
            "ave_precision_score": 0.8513916437779956,
            "fpr": 0.07135016465422613,
            "logloss": 0.53490078295062,
            "mae": 0.31666277767758116,
            "precision": 0.836272040302267,
            "recall": 0.6902286902286903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6502633839708674,
            "auditor_fn_violation": 0.015172378620971042,
            "auditor_fp_violation": 0.030369560004795598,
            "ave_precision_score": 0.6386975737029427,
            "fpr": 0.17543859649122806,
            "logloss": 0.64491014082626,
            "mae": 0.4403824153960797,
            "precision": 0.673469387755102,
            "recall": 0.6976744186046512
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6071554453230854,
            "auditor_fn_violation": 0.016287418043729792,
            "auditor_fp_violation": 0.014928649835345783,
            "ave_precision_score": 0.6665987731573096,
            "fpr": 0.1602634467618002,
            "logloss": 0.6204498375079734,
            "mae": 0.4281700287345474,
            "precision": 0.7062374245472837,
            "recall": 0.7297297297297297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6862828821602527,
            "auditor_fn_violation": 0.008871610845295058,
            "auditor_fp_violation": 0.012695819845741918,
            "ave_precision_score": 0.6830078916234481,
            "fpr": 0.30701754385964913,
            "logloss": 0.6912226294623157,
            "mae": 0.439106893483078,
            "precision": 0.6056338028169014,
            "recall": 0.9090909090909091
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6870901483335382,
            "auditor_fn_violation": 0.015041386062242269,
            "auditor_fp_violation": 0.021075740944017565,
            "ave_precision_score": 0.6720972487314884,
            "fpr": 0.3040614709110867,
            "logloss": 0.6625975168774486,
            "mae": 0.44019573440975046,
            "precision": 0.6076487252124646,
            "recall": 0.8918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7506198251302325,
            "auditor_fn_violation": 0.010097919216646269,
            "auditor_fp_violation": 0.021477740478759545,
            "ave_precision_score": 0.7265518069124055,
            "fpr": 0.19298245614035087,
            "logloss": 0.5551285717595877,
            "mae": 0.37927887910617547,
            "precision": 0.6991452991452991,
            "recall": 0.864693446088795
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7869939818764252,
            "auditor_fn_violation": 0.011417395610589905,
            "auditor_fp_violation": 0.013672682715135429,
            "ave_precision_score": 0.7493843941804471,
            "fpr": 0.19099890230515917,
            "logloss": 0.5717347421740611,
            "mae": 0.3835349229095927,
            "precision": 0.7,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.858418626552627,
            "auditor_fn_violation": 0.018517488223730574,
            "auditor_fp_violation": 0.013709886904048276,
            "ave_precision_score": 0.855000436610802,
            "fpr": 0.09210526315789473,
            "logloss": 0.4887414939904967,
            "mae": 0.29406278872486663,
            "precision": 0.8086560364464692,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8715522596349429,
            "auditor_fn_violation": 0.018110823818836996,
            "auditor_fp_violation": 0.008122941822173442,
            "ave_precision_score": 0.8683931411898136,
            "fpr": 0.09440175631174534,
            "logloss": 0.47556705264612065,
            "mae": 0.2892761214050484,
            "precision": 0.8080357142857143,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7488428501662895,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5492478332900609,
            "fpr": 0.48135964912280704,
            "logloss": 0.6747632354616095,
            "mae": 0.4835267240802447,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7444005772216531,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5515870172291687,
            "fpr": 0.47200878155872666,
            "logloss": 0.6785350213578653,
            "mae": 0.4863133301588366,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7926033154517726,
            "auditor_fn_violation": 0.007119079411001079,
            "auditor_fp_violation": 0.014359289453702597,
            "ave_precision_score": 0.7545280979102564,
            "fpr": 0.09210526315789473,
            "logloss": 0.5656496305103159,
            "mae": 0.38748256465126024,
            "precision": 0.7851662404092071,
            "recall": 0.6490486257928119
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8147042837141327,
            "auditor_fn_violation": 0.003884150975259654,
            "auditor_fp_violation": 0.003956806984402527,
            "ave_precision_score": 0.7736766460711078,
            "fpr": 0.0845225027442371,
            "logloss": 0.5711266807043123,
            "mae": 0.3920492868457484,
            "precision": 0.7935656836461126,
            "recall": 0.6153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5727165319041083,
            "auditor_fn_violation": 0.00017386224546567608,
            "auditor_fp_violation": 0.012366123166686652,
            "ave_precision_score": 0.5241034889902698,
            "fpr": 0.06140350877192982,
            "logloss": 0.7565349147010344,
            "mae": 0.5012601547335324,
            "precision": 0.5555555555555556,
            "recall": 0.14799154334038056
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6082498305619226,
            "auditor_fn_violation": 0.0011844150153700198,
            "auditor_fp_violation": 0.004620529446302298,
            "ave_precision_score": 0.5416368283662755,
            "fpr": 0.0570801317233809,
            "logloss": 0.7517576414500708,
            "mae": 0.4989806553011537,
            "precision": 0.6090225563909775,
            "recall": 0.1683991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8231061034194679,
            "auditor_fn_violation": 0.006748173287340972,
            "auditor_fp_violation": 0.02976511609319426,
            "ave_precision_score": 0.8238594578103531,
            "fpr": 0.18969298245614036,
            "logloss": 0.8517194510644149,
            "mae": 0.2880221718896153,
            "precision": 0.6938053097345133,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8539707908561349,
            "auditor_fn_violation": 0.013980204979107286,
            "auditor_fp_violation": 0.015679166773032452,
            "ave_precision_score": 0.8541599717796553,
            "fpr": 0.18221734357848518,
            "logloss": 0.7874318154747655,
            "mae": 0.2758920580049437,
            "precision": 0.7072310405643739,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7589658255992985,
            "auditor_fn_violation": 0.010155873298468164,
            "auditor_fp_violation": 0.02819406146345363,
            "ave_precision_score": 0.5898215919473512,
            "fpr": 0.2894736842105263,
            "logloss": 0.6594290705563736,
            "mae": 0.44813754967528213,
            "precision": 0.5950920245398773,
            "recall": 0.8202959830866807
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7847233038990813,
            "auditor_fn_violation": 0.013770250872336492,
            "auditor_fp_violation": 0.025272509126183854,
            "ave_precision_score": 0.6220910819407539,
            "fpr": 0.2689352360043908,
            "logloss": 0.6305563672243785,
            "mae": 0.43360828593553224,
            "precision": 0.6282245827010622,
            "recall": 0.8607068607068608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.603740663093226,
            "auditor_fn_violation": 0.006173268795667821,
            "auditor_fp_violation": 0.01213383687007953,
            "ave_precision_score": 0.591227242687655,
            "fpr": 0.08333333333333333,
            "logloss": 0.7002252379424438,
            "mae": 0.4503073559485768,
            "precision": 0.5824175824175825,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5961325816838984,
            "auditor_fn_violation": 0.009619093043900951,
            "auditor_fp_violation": 0.011283281852296226,
            "ave_precision_score": 0.5861479954543813,
            "fpr": 0.09879253567508232,
            "logloss": 0.7125404832130464,
            "mae": 0.4580608727461551,
            "precision": 0.5673076923076923,
            "recall": 0.24532224532224534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6642908702884223,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5117659981797069,
            "fpr": 0.48135964912280704,
            "logloss": 0.693023494098063,
            "mae": 0.4996894373182665,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6806033505905754,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5286479675985263,
            "fpr": 0.47200878155872666,
            "logloss": 0.6920339630308289,
            "mae": 0.4991942930692637,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7059749284697014,
            "auditor_fn_violation": 0.021011831905344766,
            "auditor_fp_violation": 0.021787455540902376,
            "ave_precision_score": 0.7065385045690443,
            "fpr": 0.18640350877192982,
            "logloss": 1.5081326318155448,
            "mae": 0.33564519135682974,
            "precision": 0.66796875,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7247569643782279,
            "auditor_fn_violation": 0.019610169994363193,
            "auditor_fp_violation": 0.014336405177035202,
            "ave_precision_score": 0.7251730492570073,
            "fpr": 0.1734357848518112,
            "logloss": 1.3626078639327839,
            "mae": 0.3137682508012115,
            "precision": 0.6973180076628352,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7239456258715952,
            "auditor_fn_violation": 0.015450558213716117,
            "auditor_fp_violation": 0.029045777884346407,
            "ave_precision_score": 0.6601686238130093,
            "fpr": 0.15350877192982457,
            "logloss": 0.6123991718711357,
            "mae": 0.414092754847125,
            "precision": 0.6825396825396826,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7650524740087542,
            "auditor_fn_violation": 0.013834149948310222,
            "auditor_fp_violation": 0.016386286472825674,
            "ave_precision_score": 0.7081318374931312,
            "fpr": 0.13062568605927552,
            "logloss": 0.5909185120055543,
            "mae": 0.40335462421473245,
            "precision": 0.7331838565022422,
            "recall": 0.6798336798336798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 6654,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6894566031582777,
            "auditor_fn_violation": 0.007874800637958538,
            "auditor_fp_violation": 0.004011309595172442,
            "ave_precision_score": 0.6900235465908411,
            "fpr": 0.013157894736842105,
            "logloss": 2.6470418367939086,
            "mae": 0.4493231110130472,
            "precision": 0.8956521739130435,
            "recall": 0.21775898520084566
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6949725751469431,
            "auditor_fn_violation": 0.008929895867327267,
            "auditor_fp_violation": 0.004224848747862048,
            "ave_precision_score": 0.695486302810844,
            "fpr": 0.020856201975850714,
            "logloss": 2.6766029124025756,
            "mae": 0.45628902547279215,
            "precision": 0.8515625,
            "recall": 0.22661122661122662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6854926959541756,
            "auditor_fn_violation": 0.0003616334705686006,
            "auditor_fp_violation": 0.013599988011029868,
            "ave_precision_score": 0.6226042263422747,
            "fpr": 0.36403508771929827,
            "logloss": 0.7366385068484212,
            "mae": 0.4353359544224906,
            "precision": 0.5682704811443433,
            "recall": 0.9238900634249472
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.704908273702084,
            "auditor_fn_violation": 0.0033866510266071202,
            "auditor_fp_violation": 0.010466392668419576,
            "ave_precision_score": 0.6427963779452973,
            "fpr": 0.3512623490669594,
            "logloss": 0.7380821217145768,
            "mae": 0.43708284542733306,
            "precision": 0.5698924731182796,
            "recall": 0.8814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.549854999962966,
            "auditor_fn_violation": 0.013417529023404182,
            "auditor_fp_violation": 0.02314121008672022,
            "ave_precision_score": 0.5462747859274903,
            "fpr": 0.23135964912280702,
            "logloss": 0.7155269974126204,
            "mae": 0.470769919283492,
            "precision": 0.5720081135902637,
            "recall": 0.5961945031712473
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5841269206528892,
            "auditor_fn_violation": 0.005404036139491694,
            "auditor_fp_violation": 0.017175095091006554,
            "ave_precision_score": 0.5726936387778544,
            "fpr": 0.22722283205268934,
            "logloss": 0.6931462112339296,
            "mae": 0.46146200886803845,
            "precision": 0.588469184890656,
            "recall": 0.6153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8445571944853569,
            "auditor_fn_violation": 0.010556915544675638,
            "auditor_fp_violation": 0.014554110218598891,
            "ave_precision_score": 0.844857967972868,
            "fpr": 0.10635964912280702,
            "logloss": 0.4999261140870809,
            "mae": 0.32122207517845947,
            "precision": 0.7853982300884956,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.850872129770106,
            "auditor_fn_violation": 0.002663222202190377,
            "auditor_fp_violation": 0.012743471268475737,
            "ave_precision_score": 0.851182398907488,
            "fpr": 0.10757409440175632,
            "logloss": 0.4962061570972982,
            "mae": 0.32770104797375027,
            "precision": 0.7841409691629956,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.454277163492429,
            "auditor_fn_violation": 0.05622473202032566,
            "auditor_fp_violation": 0.07227101067018343,
            "ave_precision_score": 0.4876106472335574,
            "fpr": 0.1206140350877193,
            "logloss": 0.8583082057424751,
            "mae": 0.5204048393000114,
            "precision": 0.41798941798941797,
            "recall": 0.16701902748414377
        },
        "train": {
            "accuracy": 0.4105378704720088,
            "auc_prc": 0.42795506739258893,
            "auditor_fn_violation": 0.05261404273478917,
            "auditor_fp_violation": 0.07892425905598245,
            "ave_precision_score": 0.4813124088484483,
            "fpr": 0.141602634467618,
            "logloss": 0.8866965732964389,
            "mae": 0.5329433046567584,
            "precision": 0.3613861386138614,
            "recall": 0.15176715176715178
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7832257529576743,
            "auditor_fn_violation": 0.02558093171618264,
            "auditor_fp_violation": 0.018235723134716067,
            "ave_precision_score": 0.7494087843905332,
            "fpr": 0.08223684210526316,
            "logloss": 3.244191664985743,
            "mae": 0.3271535785336903,
            "precision": 0.8143564356435643,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7830013794311873,
            "auditor_fn_violation": 0.028190903053691208,
            "auditor_fp_violation": 0.01686365608965359,
            "ave_precision_score": 0.7509525552167464,
            "fpr": 0.07793633369923161,
            "logloss": 2.920607487765738,
            "mae": 0.3301709667473225,
            "precision": 0.8179487179487179,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8394704610851897,
            "auditor_fn_violation": 0.010489688809762254,
            "auditor_fp_violation": 0.018600387643368105,
            "ave_precision_score": 0.8346059831547247,
            "fpr": 0.10964912280701754,
            "logloss": 0.506401380839914,
            "mae": 0.2889041991796132,
            "precision": 0.7854077253218884,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8729639010654369,
            "auditor_fn_violation": 0.015203415862032768,
            "auditor_fp_violation": 0.008408853036530268,
            "ave_precision_score": 0.8709085904990139,
            "fpr": 0.09001097694840834,
            "logloss": 0.4885430050915187,
            "mae": 0.27817297348462283,
            "precision": 0.8148984198645598,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6439695318028128,
            "auditor_fn_violation": 0.006692537368791971,
            "auditor_fp_violation": 0.008824381568956562,
            "ave_precision_score": 0.6446255514826271,
            "fpr": 0.04824561403508772,
            "logloss": 0.897740171066365,
            "mae": 0.46799299718705906,
            "precision": 0.6788321167883211,
            "recall": 0.19661733615221988
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.65589355064156,
            "auditor_fn_violation": 0.005725813629216489,
            "auditor_fp_violation": 0.01092589283435019,
            "ave_precision_score": 0.6563317998426135,
            "fpr": 0.043907793633369926,
            "logloss": 0.9223352163816277,
            "mae": 0.4730919544696481,
            "precision": 0.6923076923076923,
            "recall": 0.18711018711018712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6004548664409062,
            "auditor_fn_violation": 0.03645079930269649,
            "auditor_fp_violation": 0.010627722495304328,
            "ave_precision_score": 0.6025500290081587,
            "fpr": 0.23464912280701755,
            "logloss": 0.6959737503760742,
            "mae": 0.4471348217410738,
            "precision": 0.6232394366197183,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6150537918708453,
            "auditor_fn_violation": 0.03579032887485138,
            "auditor_fp_violation": 0.014571260817399742,
            "ave_precision_score": 0.6167794016409465,
            "fpr": 0.22063666300768386,
            "logloss": 0.6842893285286579,
            "mae": 0.44560774919933727,
            "precision": 0.6332116788321168,
            "recall": 0.7214137214137214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5566055174019182,
            "auditor_fn_violation": 0.003059975520195841,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5576308913344781,
            "fpr": 0.0,
            "logloss": 0.7636872305050157,
            "mae": 0.4998927836943614,
            "precision": 1.0,
            "recall": 0.010570824524312896
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.5540189897331764,
            "auditor_fn_violation": 0.0005773737936196945,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5553184264576038,
            "fpr": 0.0,
            "logloss": 0.7725101739989041,
            "mae": 0.504147182884253,
            "precision": 1.0,
            "recall": 0.002079002079002079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 6654,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5501786543901112,
            "auditor_fn_violation": 0.006330903898223363,
            "auditor_fp_violation": 0.007445650001998163,
            "ave_precision_score": 0.5389731176061825,
            "fpr": 0.05592105263157895,
            "logloss": 0.7405183663511672,
            "mae": 0.4994063832911483,
            "precision": 0.5526315789473685,
            "recall": 0.1331923890063425
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5593345613543154,
            "auditor_fn_violation": 0.008030744583982794,
            "auditor_fp_violation": 0.0017767339749317163,
            "ave_precision_score": 0.5508290022463851,
            "fpr": 0.059275521405049394,
            "logloss": 0.7429715069854762,
            "mae": 0.5000497026023436,
            "precision": 0.5384615384615384,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8294402958652584,
            "auditor_fn_violation": 0.006500129817143286,
            "auditor_fp_violation": 0.009094133397274507,
            "ave_precision_score": 0.8246892920413297,
            "fpr": 0.07894736842105263,
            "logloss": 0.5167128704138269,
            "mae": 0.3031823123057716,
            "precision": 0.8163265306122449,
            "recall": 0.6765327695560254
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8542363297030693,
            "auditor_fn_violation": 0.013010308290220483,
            "auditor_fp_violation": 0.005452735302376637,
            "ave_precision_score": 0.8515903812801945,
            "fpr": 0.07793633369923161,
            "logloss": 0.5095388559158461,
            "mae": 0.30020008179840646,
            "precision": 0.821608040201005,
            "recall": 0.6798336798336798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 6654,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8296563198054571,
            "auditor_fn_violation": 0.011166592485441943,
            "auditor_fp_violation": 0.007056008472205574,
            "ave_precision_score": 0.7216207726638562,
            "fpr": 0.09210526315789473,
            "logloss": 0.5514992256947506,
            "mae": 0.3646898542187716,
            "precision": 0.7995226730310262,
            "recall": 0.7082452431289641
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.837000787097607,
            "auditor_fn_violation": 0.011577143300524203,
            "auditor_fp_violation": 0.0067138079799862185,
            "ave_precision_score": 0.7336681971595256,
            "fpr": 0.08781558726673985,
            "logloss": 0.5449621885706553,
            "mae": 0.3636057671286272,
            "precision": 0.8076923076923077,
            "recall": 0.6985446985446986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7455328861762878,
            "auditor_fn_violation": 0.029964578465190468,
            "auditor_fp_violation": 0.055943531950605446,
            "ave_precision_score": 0.7339452104696937,
            "fpr": 0.12828947368421054,
            "logloss": 0.617509352341144,
            "mae": 0.39485273510217667,
            "precision": 0.7030456852791879,
            "recall": 0.5856236786469344
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7445154928840161,
            "auditor_fn_violation": 0.030361189526941453,
            "auditor_fp_violation": 0.06379393970336712,
            "ave_precision_score": 0.735395322720456,
            "fpr": 0.1207464324917673,
            "logloss": 0.6082606126788446,
            "mae": 0.3937241933937261,
            "precision": 0.7105263157894737,
            "recall": 0.5613305613305614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6174361729254854,
            "auditor_fn_violation": 0.015177014947516772,
            "auditor_fp_violation": 0.007393198257603007,
            "ave_precision_score": 0.6177135640611039,
            "fpr": 0.07785087719298246,
            "logloss": 3.765475601067743,
            "mae": 0.46504343161494516,
            "precision": 0.7279693486590039,
            "recall": 0.40169133192389006
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6000539827316166,
            "auditor_fn_violation": 0.010463473690696532,
            "auditor_fp_violation": 0.005432313072779723,
            "ave_precision_score": 0.6231264944115463,
            "fpr": 0.07464324917672886,
            "logloss": 3.8782755879603346,
            "mae": 0.4686090200684059,
            "precision": 0.7364341085271318,
            "recall": 0.39501039501039503
        }
    }
]