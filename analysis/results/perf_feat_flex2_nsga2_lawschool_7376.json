[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.4721489003950038,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5394296466317925,
            "fpr": 0.4594298245614035,
            "logloss": 0.6904432879373277,
            "mae": 0.4978328957630877,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5430189567510953,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.50717209385546,
            "fpr": 0.49396267837541163,
            "logloss": 0.69396428423389,
            "mae": 0.499575972753351,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 7376,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.585816618473905,
            "auditor_fn_violation": 0.012277143162165048,
            "auditor_fp_violation": 0.012011681949503833,
            "ave_precision_score": 0.5739156621424086,
            "fpr": 0.019736842105263157,
            "logloss": 1.4732583301247575,
            "mae": 0.4844326639108578,
            "precision": 0.5714285714285714,
            "recall": 0.0486815415821501
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6296541964275812,
            "auditor_fn_violation": 0.014643868267094646,
            "auditor_fp_violation": 0.0068154653006464215,
            "ave_precision_score": 0.560931716467409,
            "fpr": 0.012074643249176729,
            "logloss": 1.389264636483182,
            "mae": 0.46194611439896943,
            "precision": 0.7317073170731707,
            "recall": 0.0650759219088937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5481246319120074,
            "auditor_fn_violation": 0.014668072310593935,
            "auditor_fp_violation": 0.010185068877444204,
            "ave_precision_score": 0.5831208407313981,
            "fpr": 0.16447368421052633,
            "logloss": 1.4718195578417466,
            "mae": 0.48450717323660347,
            "precision": 0.5562130177514792,
            "recall": 0.3813387423935091
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5394281819013328,
            "auditor_fn_violation": 0.010431672663112455,
            "auditor_fp_violation": 0.012318575436028784,
            "ave_precision_score": 0.5762606417199712,
            "fpr": 0.16355653128430298,
            "logloss": 1.389442595503999,
            "mae": 0.4639644126021114,
            "precision": 0.56047197640118,
            "recall": 0.4121475054229935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7669582355935585,
            "auditor_fn_violation": 0.015284153588840273,
            "auditor_fp_violation": 0.000648997194657288,
            "ave_precision_score": 0.7675272733478599,
            "fpr": 0.01206140350877193,
            "logloss": 0.816073185370822,
            "mae": 0.46126606907662854,
            "precision": 0.8764044943820225,
            "recall": 0.15821501014198783
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7752412562185301,
            "auditor_fn_violation": 0.004276485757349921,
            "auditor_fp_violation": 0.004281009879253567,
            "ave_precision_score": 0.775912690115885,
            "fpr": 0.009879253567508232,
            "logloss": 0.7750092663767392,
            "mae": 0.4385808374892213,
            "precision": 0.891566265060241,
            "recall": 0.16052060737527116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.724851371378128,
            "auditor_fn_violation": 0.0004915305505142166,
            "auditor_fp_violation": 0.0012456559058744714,
            "ave_precision_score": 0.5626586239588526,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6848390622421513,
            "mae": 0.49304925323578347,
            "precision": 0.8947368421052632,
            "recall": 0.034482758620689655
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7223384041447373,
            "auditor_fn_violation": 0.0006262337161375601,
            "auditor_fp_violation": 0.0005854372484449324,
            "ave_precision_score": 0.5292385547791798,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6870253595799369,
            "mae": 0.4947030207328294,
            "precision": 0.9230769230769231,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.8056802907511013,
            "auditor_fn_violation": 0.004334810149105029,
            "auditor_fp_violation": 0.005205062178118327,
            "ave_precision_score": 0.8060658378865522,
            "fpr": 0.02631578947368421,
            "logloss": 0.6292594197505976,
            "mae": 0.4353447340820965,
            "precision": 0.8867924528301887,
            "recall": 0.3813387423935091
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.765612765253323,
            "auditor_fn_violation": 0.006831424074519447,
            "auditor_fp_violation": 0.006159287718014392,
            "ave_precision_score": 0.7660855127287363,
            "fpr": 0.027442371020856202,
            "logloss": 0.6302714948979533,
            "mae": 0.43451018279784337,
            "precision": 0.8691099476439791,
            "recall": 0.3600867678958785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 7376,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.5854707107936491,
            "auditor_fn_violation": 0.012277143162165048,
            "auditor_fp_violation": 0.012011681949503833,
            "ave_precision_score": 0.5731650959441997,
            "fpr": 0.019736842105263157,
            "logloss": 1.467821442812408,
            "mae": 0.48413704582599804,
            "precision": 0.5714285714285714,
            "recall": 0.0486815415821501
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6293101894625863,
            "auditor_fn_violation": 0.014643868267094646,
            "auditor_fp_violation": 0.0068154653006464215,
            "ave_precision_score": 0.5610829172903804,
            "fpr": 0.012074643249176729,
            "logloss": 1.3844868488282582,
            "mae": 0.46153341600905007,
            "precision": 0.7317073170731707,
            "recall": 0.0650759219088937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5481246319120074,
            "auditor_fn_violation": 0.014668072310593935,
            "auditor_fp_violation": 0.010185068877444204,
            "ave_precision_score": 0.5831208407313981,
            "fpr": 0.16447368421052633,
            "logloss": 1.4718307907242663,
            "mae": 0.4845079132224272,
            "precision": 0.5562130177514792,
            "recall": 0.3813387423935091
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5394281819013328,
            "auditor_fn_violation": 0.010431672663112455,
            "auditor_fp_violation": 0.012318575436028784,
            "ave_precision_score": 0.5762606417199712,
            "fpr": 0.16355653128430298,
            "logloss": 1.3894485999357695,
            "mae": 0.4639646409360056,
            "precision": 0.56047197640118,
            "recall": 0.4121475054229935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8052937274177971,
            "auditor_fn_violation": 0.009385786982669658,
            "auditor_fp_violation": 0.013215467068626224,
            "ave_precision_score": 0.8056546042793362,
            "fpr": 0.11951754385964912,
            "logloss": 0.5720770267991763,
            "mae": 0.4085411821867813,
            "precision": 0.7288557213930348,
            "recall": 0.5943204868154158
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7692318643271217,
            "auditor_fn_violation": 0.0033359446247478997,
            "auditor_fp_violation": 0.015472618612025858,
            "ave_precision_score": 0.7697089615027428,
            "fpr": 0.1394072447859495,
            "logloss": 0.5898650736349651,
            "mae": 0.4181425300243788,
            "precision": 0.6735218508997429,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6886591188522511,
            "mae": 0.49566470870846197,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6847436272827647,
            "mae": 0.49408780641927413,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5758957529788591,
            "auditor_fn_violation": 0.00650777552400271,
            "auditor_fp_violation": 0.015188627894318135,
            "ave_precision_score": 0.5990838778877977,
            "fpr": 0.21929824561403508,
            "logloss": 0.6826919641282307,
            "mae": 0.4941530057082051,
            "precision": 0.5859213250517599,
            "recall": 0.5740365111561866
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5807957251858427,
            "auditor_fn_violation": 0.00767433941867415,
            "auditor_fp_violation": 0.007291133065007941,
            "ave_precision_score": 0.5953595477474293,
            "fpr": 0.24259055982436883,
            "logloss": 0.6829142223040124,
            "mae": 0.4943437574331114,
            "precision": 0.5632411067193676,
            "recall": 0.6182212581344902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5759044276619774,
            "auditor_fn_violation": 0.00650777552400271,
            "auditor_fp_violation": 0.014926935477117615,
            "ave_precision_score": 0.5990924964844648,
            "fpr": 0.21820175438596492,
            "logloss": 0.682221050389294,
            "mae": 0.49386131622942914,
            "precision": 0.5871369294605809,
            "recall": 0.5740365111561866
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5808036818910519,
            "auditor_fn_violation": 0.00767433941867415,
            "auditor_fp_violation": 0.007291133065007941,
            "ave_precision_score": 0.5953675034771968,
            "fpr": 0.24259055982436883,
            "logloss": 0.6824933321633089,
            "mae": 0.4940850647691838,
            "precision": 0.5632411067193676,
            "recall": 0.6182212581344902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7716585424427653,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005103002135410231,
            "ave_precision_score": 0.5442415315638054,
            "fpr": 0.4583333333333333,
            "logloss": 0.6903924721506015,
            "mae": 0.49824077745270506,
            "precision": 0.5411635565312843,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7552602436323367,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010293938285156792,
            "ave_precision_score": 0.5105204872646734,
            "fpr": 0.49176728869374314,
            "logloss": 0.6916740830774326,
            "mae": 0.4987211062825407,
            "precision": 0.5071507150715071,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7328267464092528,
            "auditor_fn_violation": 0.007148322123767841,
            "auditor_fp_violation": 0.0005914248628731736,
            "ave_precision_score": 0.6202442544833322,
            "fpr": 0.007675438596491228,
            "logloss": 0.6488298031573527,
            "mae": 0.45987129251268033,
            "precision": 0.9278350515463918,
            "recall": 0.18255578093306288
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7572640156538926,
            "auditor_fn_violation": 0.0022072952656255,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.6022513835484177,
            "fpr": 0.006586169045005488,
            "logloss": 0.6399838504275603,
            "mae": 0.45618819727151655,
            "precision": 0.9354838709677419,
            "recall": 0.18872017353579176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 7376,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.585816618473905,
            "auditor_fn_violation": 0.012277143162165048,
            "auditor_fp_violation": 0.012011681949503833,
            "ave_precision_score": 0.5739156621424086,
            "fpr": 0.019736842105263157,
            "logloss": 1.4732585831125284,
            "mae": 0.4844326638429489,
            "precision": 0.5714285714285714,
            "recall": 0.0486815415821501
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6296541964275812,
            "auditor_fn_violation": 0.014643868267094646,
            "auditor_fp_violation": 0.0068154653006464215,
            "ave_precision_score": 0.560931716467409,
            "fpr": 0.012074643249176729,
            "logloss": 1.3892648726924566,
            "mae": 0.4619461141996194,
            "precision": 0.7317073170731707,
            "recall": 0.0650759219088937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7755735870950169,
            "auditor_fn_violation": 0.02333102024838974,
            "auditor_fp_violation": 0.010083008834736012,
            "ave_precision_score": 0.732246638153772,
            "fpr": 0.13925438596491227,
            "logloss": 2.652268109754332,
            "mae": 0.36433302568695997,
            "precision": 0.7303609341825902,
            "recall": 0.6977687626774848
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7400338643904468,
            "auditor_fn_violation": 0.006776658388317293,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6806075960421194,
            "fpr": 0.14928649835345773,
            "logloss": 3.454183926991311,
            "mae": 0.3829739148734279,
            "precision": 0.7024070021881839,
            "recall": 0.6963123644251626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7793353736701192,
            "auditor_fn_violation": 0.02429184014803744,
            "auditor_fp_violation": 0.010240024285056323,
            "ave_precision_score": 0.7265812824837593,
            "fpr": 0.13815789473684212,
            "logloss": 2.6942303251291495,
            "mae": 0.37126615881711555,
            "precision": 0.7290322580645161,
            "recall": 0.6876267748478702
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7469485145561907,
            "auditor_fn_violation": 0.008945855785280416,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6776987866261012,
            "fpr": 0.14928649835345773,
            "logloss": 3.5128061786456173,
            "mae": 0.3906484062902985,
            "precision": 0.6991150442477876,
            "recall": 0.6854663774403471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.8058064117227951,
            "auditor_fn_violation": 0.007577577310415991,
            "auditor_fp_violation": 0.003333961395134616,
            "ave_precision_score": 0.8062182384063723,
            "fpr": 0.03070175438596491,
            "logloss": 0.6303856826424542,
            "mae": 0.43825444201693725,
            "precision": 0.8727272727272727,
            "recall": 0.3894523326572008
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7676669383191579,
            "auditor_fn_violation": 0.006455207621478651,
            "auditor_fp_violation": 0.007274057811928284,
            "ave_precision_score": 0.768128157559463,
            "fpr": 0.031833150384193196,
            "logloss": 0.6311160632376808,
            "mae": 0.43747365790389636,
            "precision": 0.8535353535353535,
            "recall": 0.3665943600867679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6054430076080513,
            "auditor_fn_violation": 0.008972100636988,
            "auditor_fp_violation": 0.00555834694133903,
            "ave_precision_score": 0.6069948051877687,
            "fpr": 0.06578947368421052,
            "logloss": 0.6771321895847897,
            "mae": 0.47790118143485305,
            "precision": 0.696969696969697,
            "recall": 0.2799188640973631
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6083568226590268,
            "auditor_fn_violation": 0.0047479468820466235,
            "auditor_fp_violation": 0.009703622392974755,
            "ave_precision_score": 0.6089781548843964,
            "fpr": 0.06915477497255763,
            "logloss": 0.6732364874820788,
            "mae": 0.47787952128671,
            "precision": 0.6818181818181818,
            "recall": 0.2928416485900217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7793353736701192,
            "auditor_fn_violation": 0.02429184014803744,
            "auditor_fp_violation": 0.010240024285056323,
            "ave_precision_score": 0.7265812824837593,
            "fpr": 0.13815789473684212,
            "logloss": 2.694230234648203,
            "mae": 0.37126618384876275,
            "precision": 0.7290322580645161,
            "recall": 0.6876267748478702
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7469485145561907,
            "auditor_fn_violation": 0.008945855785280416,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6776987866261012,
            "fpr": 0.14928649835345773,
            "logloss": 3.5128062908318434,
            "mae": 0.3906484353077794,
            "precision": 0.6991150442477876,
            "recall": 0.6854663774403471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7862816347109776,
            "auditor_fn_violation": 0.02333102024838974,
            "auditor_fp_violation": 0.010083008834736012,
            "ave_precision_score": 0.7203625641512763,
            "fpr": 0.13925438596491227,
            "logloss": 2.6520244366662213,
            "mae": 0.3642916062455237,
            "precision": 0.7303609341825902,
            "recall": 0.6977687626774848
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7501426380257764,
            "auditor_fn_violation": 0.006776658388317293,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6688536183042096,
            "fpr": 0.14928649835345773,
            "logloss": 3.453932179105069,
            "mae": 0.38292637432065246,
            "precision": 0.7024070021881839,
            "recall": 0.6963123644251626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7877594513832256,
            "auditor_fn_violation": 0.02372246539269066,
            "auditor_fp_violation": 0.010083008834736012,
            "ave_precision_score": 0.7453787766650587,
            "fpr": 0.13925438596491227,
            "logloss": 2.6403715439314617,
            "mae": 0.3659047730136336,
            "precision": 0.7292110874200426,
            "recall": 0.6937119675456389
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7443902026488228,
            "auditor_fn_violation": 0.008057699222089142,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6857111270363487,
            "fpr": 0.14928649835345773,
            "logloss": 3.4492282206250926,
            "mae": 0.38623216993591525,
            "precision": 0.7004405286343612,
            "recall": 0.6898047722342733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6090229157176247,
            "auditor_fn_violation": 0.13453702715205865,
            "auditor_fp_violation": 0.10943976887325714,
            "ave_precision_score": 0.5795121766193243,
            "fpr": 0.17982456140350878,
            "logloss": 0.6900360440926462,
            "mae": 0.4972540934426146,
            "precision": 0.6159250585480094,
            "recall": 0.5334685598377282
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5949074010541233,
            "auditor_fn_violation": 0.12540865916932362,
            "auditor_fp_violation": 0.12067081351384316,
            "ave_precision_score": 0.5476809216800552,
            "fpr": 0.20965971459934138,
            "logloss": 0.6880766968387804,
            "mae": 0.49612240757359727,
            "precision": 0.5688487584650113,
            "recall": 0.5466377440347071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7237714082226879,
            "auditor_fn_violation": 0.005933952528379778,
            "auditor_fp_violation": 0.020822865636645312,
            "ave_precision_score": 0.573102015089406,
            "fpr": 0.2642543859649123,
            "logloss": 1.4658887062975543,
            "mae": 0.484181369877453,
            "precision": 0.5873287671232876,
            "recall": 0.6957403651115619
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7085637256646183,
            "auditor_fn_violation": 0.0035811996542618454,
            "auditor_fp_violation": 0.02169776802049032,
            "ave_precision_score": 0.5485823465868959,
            "fpr": 0.2689352360043908,
            "logloss": 1.3858775660786975,
            "mae": 0.4640725990844242,
            "precision": 0.5671378091872792,
            "recall": 0.6963123644251626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7289720704763658,
            "auditor_fn_violation": 0.013814010177573782,
            "auditor_fp_violation": 0.0029675920110538885,
            "ave_precision_score": 0.7295015235312956,
            "fpr": 0.020833333333333332,
            "logloss": 0.937143279048447,
            "mae": 0.48549637296482134,
            "precision": 0.8061224489795918,
            "recall": 0.16024340770791076
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7135396915329815,
            "auditor_fn_violation": 0.002862102383259804,
            "auditor_fp_violation": 0.004302963776070253,
            "ave_precision_score": 0.7142244019572158,
            "fpr": 0.009879253567508232,
            "logloss": 0.8883534790858771,
            "mae": 0.4616773752526316,
            "precision": 0.896551724137931,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.732857829035926,
            "auditor_fn_violation": 0.007148322123767841,
            "auditor_fp_violation": 0.0005914248628731736,
            "ave_precision_score": 0.6203064197366787,
            "fpr": 0.007675438596491228,
            "logloss": 0.6488295356532329,
            "mae": 0.4598712397742498,
            "precision": 0.9278350515463918,
            "recall": 0.18255578093306288
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7573429823358102,
            "auditor_fn_violation": 0.0022072952656255,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.602409316912253,
            "fpr": 0.006586169045005488,
            "logloss": 0.6399840562308352,
            "mae": 0.4561883837481764,
            "precision": 0.9354838709677419,
            "recall": 0.18872017353579176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7875474344992377,
            "auditor_fn_violation": 0.02372246539269066,
            "auditor_fp_violation": 0.010083008834736012,
            "ave_precision_score": 0.7451610891310303,
            "fpr": 0.13925438596491227,
            "logloss": 2.6407315194009113,
            "mae": 0.365676162829786,
            "precision": 0.7292110874200426,
            "recall": 0.6937119675456389
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7441340995292263,
            "auditor_fn_violation": 0.008057699222089142,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6854881233682654,
            "fpr": 0.14928649835345773,
            "logloss": 3.449759252120367,
            "mae": 0.3859302599788628,
            "precision": 0.7004405286343612,
            "recall": 0.6898047722342733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5877032954539827,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005103002135410231,
            "ave_precision_score": 0.5456951077557752,
            "fpr": 0.4583333333333333,
            "logloss": 0.690899690147829,
            "mae": 0.4971585544719761,
            "precision": 0.5411635565312843,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5974562587219967,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010293938285156792,
            "ave_precision_score": 0.5197093575385316,
            "fpr": 0.49176728869374314,
            "logloss": 0.6887116308317237,
            "mae": 0.49592551659244705,
            "precision": 0.5071507150715071,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7874089539604952,
            "auditor_fn_violation": 0.022167805416177366,
            "auditor_fp_violation": 0.010240024285056323,
            "ave_precision_score": 0.7449331660052225,
            "fpr": 0.13815789473684212,
            "logloss": 2.6443722027885057,
            "mae": 0.3684342764644769,
            "precision": 0.7290322580645161,
            "recall": 0.6876267748478702
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7431365124513636,
            "auditor_fn_violation": 0.005528953189624999,
            "auditor_fp_violation": 0.023002805220148796,
            "ave_precision_score": 0.6844675824096984,
            "fpr": 0.14928649835345773,
            "logloss": 3.454392781882102,
            "mae": 0.3885571597109249,
            "precision": 0.6991150442477876,
            "recall": 0.6854663774403471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6588978393305894,
            "auditor_fn_violation": 0.01552213444361411,
            "auditor_fp_violation": 0.010048988820499946,
            "ave_precision_score": 0.6603286996253674,
            "fpr": 0.1699561403508772,
            "logloss": 0.8960695630050017,
            "mae": 0.3744520865727457,
            "precision": 0.69,
            "recall": 0.6997971602434077
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.658662517339565,
            "auditor_fn_violation": 0.011324591459886518,
            "auditor_fp_violation": 0.007015489693865107,
            "ave_precision_score": 0.660088936846302,
            "fpr": 0.1668496158068057,
            "logloss": 0.8479252293286431,
            "mae": 0.36981862034238794,
            "precision": 0.6695652173913044,
            "recall": 0.6681127982646421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7739492968000793,
            "auditor_fn_violation": 0.0088475499092559,
            "auditor_fp_violation": 0.025007327387681626,
            "ave_precision_score": 0.7753842803700097,
            "fpr": 0.3684210526315789,
            "logloss": 0.6852132894898846,
            "mae": 0.4949848199295893,
            "precision": 0.5862068965517241,
            "recall": 0.9655172413793104
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7743036464184097,
            "auditor_fn_violation": 0.005162261203749784,
            "auditor_fp_violation": 0.016977680204903044,
            "ave_precision_score": 0.7755732099840135,
            "fpr": 0.40175631174533477,
            "logloss": 0.6876019235727142,
            "mae": 0.49627427490168424,
            "precision": 0.5459057071960298,
            "recall": 0.9544468546637744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6221632038307244,
            "auditor_fn_violation": 0.006694601615600874,
            "auditor_fp_violation": 0.009986182640371818,
            "ave_precision_score": 0.6235326207219125,
            "fpr": 0.12609649122807018,
            "logloss": 1.1045162600112979,
            "mae": 0.4086151302827565,
            "precision": 0.6989528795811518,
            "recall": 0.5415821501014199
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6233838253864952,
            "auditor_fn_violation": 0.005609911160532514,
            "auditor_fp_violation": 0.001405049396267841,
            "ave_precision_score": 0.6247572351445143,
            "fpr": 0.1251372118551043,
            "logloss": 1.0346881488262056,
            "mae": 0.39446624508502015,
            "precision": 0.6797752808988764,
            "recall": 0.5249457700650759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8193977210762466,
            "auditor_fn_violation": 0.008322657556670582,
            "auditor_fp_violation": 0.023505212912950654,
            "ave_precision_score": 0.8199463102895977,
            "fpr": 0.29385964912280704,
            "logloss": 0.923698510747338,
            "mae": 0.33832460525139285,
            "precision": 0.6358695652173914,
            "recall": 0.949290060851927
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7982762612317869,
            "auditor_fn_violation": 0.0031621230989758824,
            "auditor_fp_violation": 0.020351262349066965,
            "ave_precision_score": 0.7989065512046927,
            "fpr": 0.3150384193194292,
            "logloss": 1.042950415722832,
            "mae": 0.36139451202136,
            "precision": 0.6063100137174211,
            "recall": 0.9587852494577006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 7376,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.5766605687285077,
            "auditor_fn_violation": 0.013300238425678809,
            "auditor_fp_violation": 0.01334631327722648,
            "ave_precision_score": 0.5622434511480401,
            "fpr": 0.021929824561403508,
            "logloss": 1.5259528692790052,
            "mae": 0.494142881084643,
            "precision": 0.5652173913043478,
            "recall": 0.05273833671399594
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.608423512819419,
            "auditor_fn_violation": 0.015620126151567612,
            "auditor_fp_violation": 0.008605927552140505,
            "ave_precision_score": 0.5470788569127332,
            "fpr": 0.015367727771679473,
            "logloss": 1.4485399397144687,
            "mae": 0.4723646656473849,
            "precision": 0.6956521739130435,
            "recall": 0.06941431670281996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.607602096632992,
            "auditor_fn_violation": 0.010855930393936175,
            "auditor_fp_violation": 0.008418645061340704,
            "ave_precision_score": 0.6091448790851519,
            "fpr": 0.0581140350877193,
            "logloss": 0.6782744334971875,
            "mae": 0.47912214634319145,
            "precision": 0.7055555555555556,
            "recall": 0.25760649087221094
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6063484637710093,
            "auditor_fn_violation": 0.00027620954780212086,
            "auditor_fp_violation": 0.009462129527991218,
            "ave_precision_score": 0.6069765277603348,
            "fpr": 0.05817782656421515,
            "logloss": 0.6730728543617995,
            "mae": 0.47858134304652755,
            "precision": 0.6971428571428572,
            "recall": 0.2646420824295011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7790207324904841,
            "auditor_fn_violation": 0.00621419166577701,
            "auditor_fp_violation": 0.0020333500816480344,
            "ave_precision_score": 0.6254331114596099,
            "fpr": 0.009868421052631578,
            "logloss": 0.6437731499109477,
            "mae": 0.4537671980509047,
            "precision": 0.9203539823008849,
            "recall": 0.21095334685598377
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7761331441099159,
            "auditor_fn_violation": 0.0024501691783480294,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.6025516127042533,
            "fpr": 0.006586169045005488,
            "logloss": 0.6351620367632845,
            "mae": 0.4520402656256177,
            "precision": 0.9411764705882353,
            "recall": 0.20824295010845986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.8160253760459245,
            "auditor_fn_violation": 0.0013922992064339349,
            "auditor_fp_violation": 0.006620818155173158,
            "ave_precision_score": 0.8166532687646053,
            "fpr": 0.42653508771929827,
            "logloss": 1.2625690998746315,
            "mae": 0.3958117778376235,
            "precision": 0.5579545454545455,
            "recall": 0.9959432048681541
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7917189314041219,
            "auditor_fn_violation": 0.0006119470153891578,
            "auditor_fp_violation": 0.002927186242224677,
            "ave_precision_score": 0.7928284375045871,
            "fpr": 0.4665203073545554,
            "logloss": 1.4066933501861363,
            "mae": 0.4250947645692611,
            "precision": 0.519774011299435,
            "recall": 0.9978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.6079429267820181,
            "auditor_fn_violation": 0.017828547026796197,
            "auditor_fp_violation": 0.008109848009044098,
            "ave_precision_score": 0.6092444417609617,
            "fpr": 0.18969298245614036,
            "logloss": 1.0672165063317491,
            "mae": 0.3942290746257034,
            "precision": 0.6666666666666666,
            "recall": 0.7018255578093306
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.60728482673798,
            "auditor_fn_violation": 0.007376699819749462,
            "auditor_fp_violation": 0.004883522380778143,
            "ave_precision_score": 0.6086147525441007,
            "fpr": 0.19978046103183314,
            "logloss": 0.9993573266179672,
            "mae": 0.3912699613517354,
            "precision": 0.636,
            "recall": 0.6898047722342733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6430104557335796,
            "auditor_fn_violation": 0.010435571687840296,
            "auditor_fp_violation": 0.008936796047397734,
            "ave_precision_score": 0.6444913051837284,
            "fpr": 0.10307017543859649,
            "logloss": 1.1264176144255347,
            "mae": 0.41472410859631825,
            "precision": 0.7015873015873015,
            "recall": 0.4482758620689655
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6435365053525955,
            "auditor_fn_violation": 0.014258127346888243,
            "auditor_fp_violation": 0.0012513721185510446,
            "ave_precision_score": 0.6449569441666361,
            "fpr": 0.0889132821075741,
            "logloss": 1.0534789475938406,
            "mae": 0.39740191109235945,
            "precision": 0.7096774193548387,
            "recall": 0.42950108459869846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8159769300063661,
            "auditor_fn_violation": 0.005159958720330238,
            "auditor_fp_violation": 0.022113009253443883,
            "ave_precision_score": 0.8174495004197617,
            "fpr": 0.2598684210526316,
            "logloss": 0.8354730021495643,
            "mae": 0.3220667431882599,
            "precision": 0.6619115549215406,
            "recall": 0.9411764705882353
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8113926858831106,
            "auditor_fn_violation": 0.004681275611887488,
            "auditor_fp_violation": 0.027076472740578117,
            "ave_precision_score": 0.8117540228862314,
            "fpr": 0.27991218441273324,
            "logloss": 0.8486618239300739,
            "mae": 0.33971048463197295,
            "precision": 0.6315028901734104,
            "recall": 0.9479392624728851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7805352761166198,
            "auditor_fn_violation": 0.00621419166577701,
            "auditor_fp_violation": 0.0013974375078507728,
            "ave_precision_score": 0.6452625347746015,
            "fpr": 0.010964912280701754,
            "logloss": 0.6449087218733482,
            "mae": 0.4536129928035958,
            "precision": 0.9122807017543859,
            "recall": 0.21095334685598377
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7718131406602385,
            "auditor_fn_violation": 0.0024501691783480294,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.6139303840544127,
            "fpr": 0.006586169045005488,
            "logloss": 0.6345044995777743,
            "mae": 0.4513332009652597,
            "precision": 0.9411764705882353,
            "recall": 0.20824295010845986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7328267464092528,
            "auditor_fn_violation": 0.007148322123767841,
            "auditor_fp_violation": 0.0005914248628731736,
            "ave_precision_score": 0.6202442544833322,
            "fpr": 0.007675438596491228,
            "logloss": 0.6488295269125884,
            "mae": 0.45987118691845463,
            "precision": 0.9278350515463918,
            "recall": 0.18255578093306288
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7572640156538926,
            "auditor_fn_violation": 0.0022072952656255,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.6022513835484177,
            "fpr": 0.006586169045005488,
            "logloss": 0.6399838521488418,
            "mae": 0.45618823369141426,
            "precision": 0.9354838709677419,
            "recall": 0.18872017353579176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 7376,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6242333900049246,
            "auditor_fn_violation": 0.010698017864132952,
            "auditor_fp_violation": 0.012084955826319979,
            "ave_precision_score": 0.6256568425057483,
            "fpr": 0.13157894736842105,
            "logloss": 1.0984067929328065,
            "mae": 0.40849183008668005,
            "precision": 0.6883116883116883,
            "recall": 0.537525354969574
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.627852726187944,
            "auditor_fn_violation": 0.015651080669855776,
            "auditor_fp_violation": 0.0034882302719843896,
            "ave_precision_score": 0.6292539688226041,
            "fpr": 0.1207464324917673,
            "logloss": 1.0287288194586743,
            "mae": 0.3933549242879462,
            "precision": 0.6839080459770115,
            "recall": 0.5162689804772235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6075998882596778,
            "auditor_fn_violation": 0.010855930393936175,
            "auditor_fp_violation": 0.008418645061340704,
            "ave_precision_score": 0.6091426708192921,
            "fpr": 0.0581140350877193,
            "logloss": 0.6782747370503416,
            "mae": 0.479121886781956,
            "precision": 0.7055555555555556,
            "recall": 0.25760649087221094
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6063501376558456,
            "auditor_fn_violation": 0.00027620954780212086,
            "auditor_fp_violation": 0.009462129527991218,
            "ave_precision_score": 0.6069799661394264,
            "fpr": 0.05817782656421515,
            "logloss": 0.6730729588728254,
            "mae": 0.47858106442262,
            "precision": 0.6971428571428572,
            "recall": 0.2646420824295011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7289258570542281,
            "auditor_fn_violation": 0.013814010177573782,
            "auditor_fp_violation": 0.0029675920110538885,
            "ave_precision_score": 0.7294477827136381,
            "fpr": 0.020833333333333332,
            "logloss": 0.9368981334886856,
            "mae": 0.48547893572239237,
            "precision": 0.8061224489795918,
            "recall": 0.16024340770791076
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7135394460828461,
            "auditor_fn_violation": 0.002862102383259804,
            "auditor_fp_violation": 0.004302963776070253,
            "ave_precision_score": 0.7142257862526298,
            "fpr": 0.009879253567508232,
            "logloss": 0.8881453313557122,
            "mae": 0.46166869355150947,
            "precision": 0.896551724137931,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8015093059804068,
            "auditor_fn_violation": 0.006979288993274263,
            "auditor_fp_violation": 0.016060063643595864,
            "ave_precision_score": 0.8018723972912014,
            "fpr": 0.1524122807017544,
            "logloss": 0.9023866710502824,
            "mae": 0.3035871670551897,
            "precision": 0.728515625,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7736847274444703,
            "auditor_fn_violation": 0.0013286631695998063,
            "auditor_fp_violation": 0.022319795096963045,
            "ave_precision_score": 0.7740036040687418,
            "fpr": 0.16465422612513722,
            "logloss": 1.0094628326184205,
            "mae": 0.32617943231076635,
            "precision": 0.6981891348088531,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.8151648511873878,
            "auditor_fn_violation": 0.005644816910430234,
            "auditor_fp_violation": 0.013304442490474399,
            "ave_precision_score": 0.817147660517094,
            "fpr": 0.35964912280701755,
            "logloss": 1.0403458161312196,
            "mae": 0.3638252789734683,
            "precision": 0.5960591133004927,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7958720141647528,
            "auditor_fn_violation": 0.0001476292410666454,
            "auditor_fp_violation": 0.018455909257226486,
            "ave_precision_score": 0.7966986428587957,
            "fpr": 0.40175631174533477,
            "logloss": 1.1701128409489714,
            "mae": 0.3901903827303589,
            "precision": 0.5525672371638142,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7754943344215726,
            "auditor_fn_violation": 0.007568680829863715,
            "auditor_fp_violation": 0.005388246870158693,
            "ave_precision_score": 0.7534877643082718,
            "fpr": 0.08114035087719298,
            "logloss": 0.5731522922020112,
            "mae": 0.40336249432150734,
            "precision": 0.7989130434782609,
            "recall": 0.5963488843813387
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7445173757763853,
            "auditor_fn_violation": 0.009029194872979327,
            "auditor_fp_violation": 0.009232833272350291,
            "ave_precision_score": 0.7230486402938378,
            "fpr": 0.07135016465422613,
            "logloss": 0.5669697615786287,
            "mae": 0.4012048350142072,
            "precision": 0.8076923076923077,
            "recall": 0.5921908893709328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8008773002408653,
            "auditor_fn_violation": 0.017955321874666388,
            "auditor_fp_violation": 0.02086735334756941,
            "ave_precision_score": 0.7996940598233149,
            "fpr": 0.22039473684210525,
            "logloss": 1.080709389299411,
            "mae": 0.3244733631307323,
            "precision": 0.6814580031695721,
            "recall": 0.8722109533468559
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7687006650477612,
            "auditor_fn_violation": 0.013567603477382964,
            "auditor_fp_violation": 0.013874862788144902,
            "ave_precision_score": 0.7675956284674101,
            "fpr": 0.2261251372118551,
            "logloss": 1.3025773881485123,
            "mae": 0.34224959845454295,
            "precision": 0.6595041322314049,
            "recall": 0.8655097613882863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8183924531630645,
            "auditor_fn_violation": 0.02878901106722181,
            "auditor_fp_violation": 0.02111072729556589,
            "ave_precision_score": 0.8187391082125187,
            "fpr": 0.13486842105263158,
            "logloss": 0.7588836294126713,
            "mae": 0.2859226342430032,
            "precision": 0.7625482625482626,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7918763861361656,
            "auditor_fn_violation": 0.014296225215550601,
            "auditor_fp_violation": 0.02008781558726674,
            "ave_precision_score": 0.7923884442919187,
            "fpr": 0.14818880351262348,
            "logloss": 0.8566036160673395,
            "mae": 0.3030140116634706,
            "precision": 0.7283702213279678,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7836540076520624,
            "auditor_fn_violation": 0.007568680829863715,
            "auditor_fp_violation": 0.005388246870158693,
            "ave_precision_score": 0.7638514827478575,
            "fpr": 0.08114035087719298,
            "logloss": 0.5762808050266767,
            "mae": 0.408231836335178,
            "precision": 0.7989130434782609,
            "recall": 0.5963488843813387
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7477593204135169,
            "auditor_fn_violation": 0.009029194872979327,
            "auditor_fp_violation": 0.009232833272350291,
            "ave_precision_score": 0.7294134563222409,
            "fpr": 0.07135016465422613,
            "logloss": 0.5730660764126981,
            "mae": 0.4073804113461864,
            "precision": 0.8076923076923077,
            "recall": 0.5921908893709328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.8058817129112887,
            "auditor_fn_violation": 0.008847549909255889,
            "auditor_fp_violation": 0.00346742452790688,
            "ave_precision_score": 0.8062686225643851,
            "fpr": 0.025219298245614034,
            "logloss": 0.6390413907962077,
            "mae": 0.4384405099574411,
            "precision": 0.8904761904761904,
            "recall": 0.3793103448275862
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7682544187597603,
            "auditor_fn_violation": 0.006040893299775463,
            "auditor_fp_violation": 0.008598609586534944,
            "ave_precision_score": 0.7687067361423385,
            "fpr": 0.027442371020856202,
            "logloss": 0.6396896038876565,
            "mae": 0.4369643831750302,
            "precision": 0.8691099476439791,
            "recall": 0.3600867678958785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 7376,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6342208789206247,
            "auditor_fn_violation": 0.00877192982456141,
            "auditor_fp_violation": 0.009130448436126119,
            "ave_precision_score": 0.6356822587219094,
            "fpr": 0.1074561403508772,
            "logloss": 1.0950188171640822,
            "mae": 0.4125363169787269,
            "precision": 0.703030303030303,
            "recall": 0.47058823529411764
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6335883050070588,
            "auditor_fn_violation": 0.011829388219662788,
            "auditor_fp_violation": 0.0010001219660934297,
            "ave_precision_score": 0.6350061753452279,
            "fpr": 0.10318331503841932,
            "logloss": 1.0223093511275727,
            "mae": 0.39772683903187184,
            "precision": 0.6887417218543046,
            "recall": 0.4511930585683297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8183718324125026,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8186082050109271,
            "fpr": 0.4594298245614035,
            "logloss": 1.4723673399052961,
            "mae": 0.411900400004366,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.81694380570887,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8172178201150918,
            "fpr": 0.49396267837541163,
            "logloss": 1.630891647161422,
            "mae": 0.44896619825017703,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7356361414782868,
            "auditor_fn_violation": 0.014398953773887075,
            "auditor_fp_violation": 0.003841644684503622,
            "ave_precision_score": 0.7361482788804747,
            "fpr": 0.02412280701754386,
            "logloss": 0.6538119668084151,
            "mae": 0.4512526148668768,
            "precision": 0.8018018018018018,
            "recall": 0.18052738336713997
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7111566547339117,
            "auditor_fn_violation": 0.004121713165909092,
            "auditor_fp_violation": 0.0033955360409806076,
            "ave_precision_score": 0.7118403927862875,
            "fpr": 0.015367727771679473,
            "logloss": 0.6430027759958883,
            "mae": 0.4448311587163829,
            "precision": 0.8585858585858586,
            "recall": 0.1843817787418655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7056889914344256,
            "auditor_fn_violation": 0.010786982669655883,
            "auditor_fp_violation": 0.0028759996650337062,
            "ave_precision_score": 0.7063325617113329,
            "fpr": 0.023026315789473683,
            "logloss": 0.882310757835984,
            "mae": 0.48119662710253086,
            "precision": 0.7878787878787878,
            "recall": 0.15821501014198783
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6952354653086266,
            "auditor_fn_violation": 0.0037145421945801002,
            "auditor_fp_violation": 0.004188315648249788,
            "ave_precision_score": 0.6960406023886058,
            "fpr": 0.012074643249176729,
            "logloss": 0.8413512315619932,
            "mae": 0.45964339781965563,
            "precision": 0.8777777777777778,
            "recall": 0.17136659436008678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6429319026982618,
            "auditor_fn_violation": 0.010435571687840296,
            "auditor_fp_violation": 0.009313633128166481,
            "ave_precision_score": 0.6444130935543917,
            "fpr": 0.10197368421052631,
            "logloss": 1.1278653495137083,
            "mae": 0.41492250797149527,
            "precision": 0.7038216560509554,
            "recall": 0.4482758620689655
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.643490256916404,
            "auditor_fn_violation": 0.016894023634965276,
            "auditor_fp_violation": 0.0002439321868520573,
            "ave_precision_score": 0.64491074247536,
            "fpr": 0.08781558726673985,
            "logloss": 1.054868389225031,
            "mae": 0.39755041815078956,
            "precision": 0.7111913357400722,
            "recall": 0.42733188720173537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.722948758395199,
            "auditor_fn_violation": 0.010927102238354509,
            "auditor_fp_violation": 0.009410459322530682,
            "ave_precision_score": 0.7184824039700138,
            "fpr": 0.24671052631578946,
            "logloss": 1.3642804531406558,
            "mae": 0.33582472181501144,
            "precision": 0.6626686656671664,
            "recall": 0.896551724137931
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7212377095729967,
            "auditor_fn_violation": 0.008731555274054639,
            "auditor_fp_violation": 0.011259909745090868,
            "ave_precision_score": 0.718392529956592,
            "fpr": 0.2513721185510428,
            "logloss": 1.2770845534347712,
            "mae": 0.3442971374467424,
            "precision": 0.6444099378881988,
            "recall": 0.9002169197396963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7894540897751111,
            "auditor_fn_violation": 0.02065317960214939,
            "auditor_fp_violation": 0.014919084704601605,
            "ave_precision_score": 0.7332743682449794,
            "fpr": 0.11732456140350878,
            "logloss": 3.0259263704519967,
            "mae": 0.3670917039670946,
            "precision": 0.7505827505827506,
            "recall": 0.6531440162271805
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7603835411150298,
            "auditor_fn_violation": 0.0011500794102449969,
            "auditor_fp_violation": 0.01742163678497378,
            "ave_precision_score": 0.6886361458917472,
            "fpr": 0.12952799121844127,
            "logloss": 3.815973070812247,
            "mae": 0.38807312668858596,
            "precision": 0.7121951219512195,
            "recall": 0.6334056399132321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7237714082226879,
            "auditor_fn_violation": 0.005933952528379778,
            "auditor_fp_violation": 0.020822865636645312,
            "ave_precision_score": 0.573102015089406,
            "fpr": 0.2642543859649123,
            "logloss": 1.4658886296427185,
            "mae": 0.48418136990604627,
            "precision": 0.5873287671232876,
            "recall": 0.6957403651115619
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7085637256646183,
            "auditor_fn_violation": 0.0035811996542618454,
            "auditor_fp_violation": 0.02169776802049032,
            "ave_precision_score": 0.5485823465868959,
            "fpr": 0.2689352360043908,
            "logloss": 1.385877494495463,
            "mae": 0.46407259915087423,
            "precision": 0.5671378091872792,
            "recall": 0.6963123644251626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.793920934635955,
            "auditor_fn_violation": 0.01120066901533754,
            "auditor_fp_violation": 0.016732613155801206,
            "ave_precision_score": 0.7928239140069185,
            "fpr": 0.16885964912280702,
            "logloss": 1.0709390537717463,
            "mae": 0.30851120120151093,
            "precision": 0.7105263157894737,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7592101845079446,
            "auditor_fn_violation": 0.004566982005900411,
            "auditor_fp_violation": 0.021768508354677404,
            "ave_precision_score": 0.7573239729496196,
            "fpr": 0.17892425905598244,
            "logloss": 1.2452183993721344,
            "mae": 0.3329924175077664,
            "precision": 0.681640625,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.717386947327814,
            "auditor_fn_violation": 0.007148322123767841,
            "auditor_fp_violation": 0.0005914248628731736,
            "ave_precision_score": 0.6348740583936129,
            "fpr": 0.007675438596491228,
            "logloss": 0.7022659616132847,
            "mae": 0.47529720266051956,
            "precision": 0.9278350515463918,
            "recall": 0.18255578093306288
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7103139353798928,
            "auditor_fn_violation": 0.001273897483397679,
            "auditor_fp_violation": 0.001083058909623125,
            "ave_precision_score": 0.624835142525447,
            "fpr": 0.007683863885839737,
            "logloss": 0.7085122360503138,
            "mae": 0.4710596102233627,
            "precision": 0.9270833333333334,
            "recall": 0.19305856832971802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8199002896478111,
            "auditor_fn_violation": 0.00661008505035408,
            "auditor_fp_violation": 0.01825304609973624,
            "ave_precision_score": 0.8204380683447625,
            "fpr": 0.28618421052631576,
            "logloss": 0.9085687705306478,
            "mae": 0.33557092413161227,
            "precision": 0.640495867768595,
            "recall": 0.9432048681541582
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7981276484973782,
            "auditor_fn_violation": 0.0031621230989758824,
            "auditor_fp_violation": 0.02104159043785828,
            "ave_precision_score": 0.7987736666455438,
            "fpr": 0.3106476399560922,
            "logloss": 1.029254132309468,
            "mae": 0.3591825986101111,
            "precision": 0.6096551724137931,
            "recall": 0.9587852494577006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6353579469785218,
            "auditor_fn_violation": 0.012045834667805419,
            "auditor_fp_violation": 0.01427793828246033,
            "ave_precision_score": 0.6367383823186138,
            "fpr": 0.17982456140350878,
            "logloss": 0.968824628962023,
            "mae": 0.3828126534214007,
            "precision": 0.6758893280632411,
            "recall": 0.6937119675456389
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.6357744010126887,
            "auditor_fn_violation": 0.007467182257822569,
            "auditor_fp_violation": 0.003841931942919879,
            "ave_precision_score": 0.6371829654867724,
            "fpr": 0.18111964873765093,
            "logloss": 0.9115524754932574,
            "mae": 0.37847222892653887,
            "precision": 0.6518987341772152,
            "recall": 0.6702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8207324788139776,
            "auditor_fn_violation": 0.018644799117469132,
            "auditor_fp_violation": 0.021149981158145956,
            "ave_precision_score": 0.8211292732421545,
            "fpr": 0.1611842105263158,
            "logloss": 0.7195822164588729,
            "mae": 0.28884188581617454,
            "precision": 0.7370304114490162,
            "recall": 0.8356997971602435
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8024975125950085,
            "auditor_fn_violation": 0.014343847551378549,
            "auditor_fp_violation": 0.02424198072935724,
            "ave_precision_score": 0.802836272067763,
            "fpr": 0.1734357848518112,
            "logloss": 0.7733485865787881,
            "mae": 0.3085734469267365,
            "precision": 0.7074074074074074,
            "recall": 0.8286334056399133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7790207324904841,
            "auditor_fn_violation": 0.00621419166577701,
            "auditor_fp_violation": 0.0020333500816480344,
            "ave_precision_score": 0.6254331114596099,
            "fpr": 0.009868421052631578,
            "logloss": 0.6438016916809022,
            "mae": 0.45378022550739605,
            "precision": 0.9203539823008849,
            "recall": 0.21095334685598377
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7761337634912752,
            "auditor_fn_violation": 0.0024501691783480294,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.6025516127042533,
            "fpr": 0.006586169045005488,
            "logloss": 0.6351966177016398,
            "mae": 0.4520559508436806,
            "precision": 0.9411764705882353,
            "recall": 0.20824295010845986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8089073581428007,
            "auditor_fn_violation": 0.019340948720686094,
            "auditor_fp_violation": 0.024816291923125237,
            "ave_precision_score": 0.8088746625534678,
            "fpr": 0.20833333333333334,
            "logloss": 1.0051390939942733,
            "mae": 0.31301648187939446,
            "precision": 0.6964856230031949,
            "recall": 0.8843813387423936
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7710434873872134,
            "auditor_fn_violation": 0.010338809108247953,
            "auditor_fp_violation": 0.01889498719356019,
            "ave_precision_score": 0.7708208763180966,
            "fpr": 0.21844127332601537,
            "logloss": 1.206285523459512,
            "mae": 0.33453462545621454,
            "precision": 0.6672240802675585,
            "recall": 0.8655097613882863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8236715361657989,
            "auditor_fn_violation": 0.019263104515853526,
            "auditor_fp_violation": 0.016130720596240006,
            "ave_precision_score": 0.824049706017367,
            "fpr": 0.13157894736842105,
            "logloss": 0.6984469851405642,
            "mae": 0.28277702030855406,
            "precision": 0.765625,
            "recall": 0.795131845841785
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8052492279704918,
            "auditor_fn_violation": 0.01678449226256099,
            "auditor_fp_violation": 0.016280034150506165,
            "ave_precision_score": 0.8055975511626956,
            "fpr": 0.14709110867178923,
            "logloss": 0.7465057061206474,
            "mae": 0.3006439888229122,
            "precision": 0.7219917012448133,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8198189836451857,
            "auditor_fn_violation": 0.008322657556670582,
            "auditor_fp_violation": 0.018860172507641437,
            "ave_precision_score": 0.8203700373236165,
            "fpr": 0.2905701754385965,
            "logloss": 0.9240683724584634,
            "mae": 0.3383384554906291,
            "precision": 0.6384720327421555,
            "recall": 0.949290060851927
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7981452978694888,
            "auditor_fn_violation": 0.002404927959311477,
            "auditor_fp_violation": 0.020351262349066965,
            "ave_precision_score": 0.7988012675469724,
            "fpr": 0.3150384193194292,
            "logloss": 1.0438667870840024,
            "mae": 0.3615686642149163,
            "precision": 0.6068493150684932,
            "recall": 0.9609544468546638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7997974336797544,
            "auditor_fn_violation": 0.0137850966157788,
            "auditor_fp_violation": 0.02668477578193694,
            "ave_precision_score": 0.7956823359430518,
            "fpr": 0.2236842105263158,
            "logloss": 1.20152786985833,
            "mae": 0.3178178037994433,
            "precision": 0.6837209302325581,
            "recall": 0.8945233265720081
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7629871187631054,
            "auditor_fn_violation": 0.010803126882570463,
            "auditor_fp_violation": 0.01606537382607635,
            "ave_precision_score": 0.7579806931341908,
            "fpr": 0.2349066959385291,
            "logloss": 1.4676374728985062,
            "mae": 0.34167208776831764,
            "precision": 0.6553945249597424,
            "recall": 0.8828633405639913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.8154662201046772,
            "auditor_fn_violation": 0.000622753638660546,
            "auditor_fp_violation": 0.0053489930075786285,
            "ave_precision_score": 0.8159854518515022,
            "fpr": 0.4375,
            "logloss": 1.3291859416640714,
            "mae": 0.40321236542475064,
            "precision": 0.5521885521885522,
            "recall": 0.9979716024340771
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7903643205809093,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.005410415904378582,
            "ave_precision_score": 0.7912909026692869,
            "fpr": 0.47639956092206365,
            "logloss": 1.4848463048298381,
            "mae": 0.43440732693158574,
            "precision": 0.5150837988826815,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7289891060383002,
            "auditor_fn_violation": 0.013814010177573782,
            "auditor_fp_violation": 0.0029675920110538885,
            "ave_precision_score": 0.7295244747220708,
            "fpr": 0.020833333333333332,
            "logloss": 0.9370114677351498,
            "mae": 0.48548329988363803,
            "precision": 0.8061224489795918,
            "recall": 0.16024340770791076
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7138994239210943,
            "auditor_fn_violation": 0.002862102383259804,
            "auditor_fp_violation": 0.004302963776070253,
            "ave_precision_score": 0.7145870870630352,
            "fpr": 0.009879253567508232,
            "logloss": 0.8882226697006611,
            "mae": 0.4616684666073152,
            "precision": 0.896551724137931,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8013635596636002,
            "auditor_fn_violation": 0.006465517241379314,
            "auditor_fp_violation": 0.016060063643595864,
            "ave_precision_score": 0.8017762850756489,
            "fpr": 0.1524122807017544,
            "logloss": 0.9059122289443686,
            "mae": 0.3036683644381015,
            "precision": 0.7290448343079922,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7733831047465913,
            "auditor_fn_violation": 0.0013286631695998063,
            "auditor_fp_violation": 0.02287839980485426,
            "ave_precision_score": 0.7736586307099291,
            "fpr": 0.16575192096597147,
            "logloss": 1.0144410473717778,
            "mae": 0.32634855462454965,
            "precision": 0.6967871485943775,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.8026436240568118,
            "auditor_fn_violation": 0.014995017970890714,
            "auditor_fp_violation": 0.03818092366955576,
            "ave_precision_score": 0.8030839637404058,
            "fpr": 0.2774122807017544,
            "logloss": 0.6536341276706708,
            "mae": 0.38965127839331043,
            "precision": 0.6421499292786421,
            "recall": 0.920892494929006
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7700367838783262,
            "auditor_fn_violation": 0.0026858997406963843,
            "auditor_fp_violation": 0.03615075009147457,
            "ave_precision_score": 0.7702900381876328,
            "fpr": 0.3150384193194292,
            "logloss": 0.7085732862761502,
            "mae": 0.4164300985249939,
            "precision": 0.5911680911680912,
            "recall": 0.9002169197396963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 7376,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7724580606479061,
            "auditor_fn_violation": 0.012768673712679271,
            "auditor_fp_violation": 0.00993646108110372,
            "ave_precision_score": 0.7732197700539931,
            "fpr": 0.17214912280701755,
            "logloss": 1.2095137088242645,
            "mae": 0.32653334543458995,
            "precision": 0.7087198515769945,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7586667834312951,
            "auditor_fn_violation": 0.0029835393396210738,
            "auditor_fp_violation": 0.006142212464934751,
            "ave_precision_score": 0.7584202864253176,
            "fpr": 0.18551042810098792,
            "logloss": 1.297346451594186,
            "mae": 0.346665095703275,
            "precision": 0.6640159045725647,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8191468428073294,
            "auditor_fn_violation": 0.0066901533753247235,
            "auditor_fp_violation": 0.020173868441988034,
            "ave_precision_score": 0.8199406700377653,
            "fpr": 0.24013157894736842,
            "logloss": 0.791535377394288,
            "mae": 0.32303922096208115,
            "precision": 0.672645739910314,
            "recall": 0.9127789046653144
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7978350515070831,
            "auditor_fn_violation": 0.003971702808051034,
            "auditor_fp_violation": 0.017848518111964883,
            "ave_precision_score": 0.798661458399328,
            "fpr": 0.2491767288693743,
            "logloss": 0.8908719791618126,
            "mae": 0.34127106433724075,
            "precision": 0.6529051987767585,
            "recall": 0.9262472885032538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 7376,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.605212255896241,
            "auditor_fn_violation": 0.003516333938294032,
            "auditor_fp_violation": 0.0005652556211531214,
            "ave_precision_score": 0.6094141216301995,
            "fpr": 0.0010964912280701754,
            "logloss": 1.1621025221443093,
            "mae": 0.5058712101022697,
            "precision": 0.9375,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.6030247176518493,
            "auditor_fn_violation": 0.0041074264651607025,
            "auditor_fp_violation": 0.00014635931211123327,
            "ave_precision_score": 0.6056143276720652,
            "fpr": 0.0043907793633369925,
            "logloss": 1.088184547769889,
            "mae": 0.4777097419848917,
            "precision": 0.75,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8182866118731038,
            "auditor_fn_violation": 0.02878901106722181,
            "auditor_fp_violation": 0.02083071640916133,
            "ave_precision_score": 0.818629243668954,
            "fpr": 0.13706140350877194,
            "logloss": 0.7638510321011919,
            "mae": 0.2857112391168158,
            "precision": 0.7596153846153846,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7915136978974623,
            "auditor_fn_violation": 0.013436642053856102,
            "auditor_fp_violation": 0.02093426027564337,
            "ave_precision_score": 0.7920094442458752,
            "fpr": 0.14928649835345773,
            "logloss": 0.8630584681139455,
            "mae": 0.30288306264534925,
            "precision": 0.728,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7975216107107456,
            "auditor_fn_violation": 0.011712216647094412,
            "auditor_fp_violation": 0.01473851693673325,
            "ave_precision_score": 0.7974734720329886,
            "fpr": 0.15570175438596492,
            "logloss": 0.9952936166831563,
            "mae": 0.3046410726302937,
            "precision": 0.7269230769230769,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7674317101281706,
            "auditor_fn_violation": 0.006464732088644216,
            "auditor_fp_violation": 0.022919868276619102,
            "ave_precision_score": 0.7673225432504052,
            "fpr": 0.1712403951701427,
            "logloss": 1.1425990069220209,
            "mae": 0.32865061289241904,
            "precision": 0.691089108910891,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7976132799722553,
            "auditor_fn_violation": 0.007842247606846731,
            "auditor_fp_violation": 0.014531779927144835,
            "ave_precision_score": 0.7977413849125227,
            "fpr": 0.15899122807017543,
            "logloss": 0.9739156391583772,
            "mae": 0.3076932491606211,
            "precision": 0.722753346080306,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7644880626561903,
            "auditor_fn_violation": 0.007791014141452628,
            "auditor_fp_violation": 0.014840834248079037,
            "ave_precision_score": 0.7645986251248431,
            "fpr": 0.1778265642151482,
            "logloss": 1.1163992862482914,
            "mae": 0.3326507760596164,
            "precision": 0.686046511627907,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7991472392701487,
            "auditor_fn_violation": 0.015911355467776948,
            "auditor_fp_violation": 0.02139597203031445,
            "ave_precision_score": 0.7967957712770365,
            "fpr": 0.22587719298245615,
            "logloss": 1.1566119598303444,
            "mae": 0.3247435818618549,
            "precision": 0.6791277258566978,
            "recall": 0.8843813387423936
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7646600146795063,
            "auditor_fn_violation": 0.013627131397167902,
            "auditor_fp_violation": 0.015401878277838761,
            "ave_precision_score": 0.7612297623126528,
            "fpr": 0.22941822173435786,
            "logloss": 1.4004201179578217,
            "mae": 0.3431428555675458,
            "precision": 0.6584967320261438,
            "recall": 0.8741865509761388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7788760217817747,
            "auditor_fn_violation": 0.013676114729013209,
            "auditor_fp_violation": 0.011799711091571413,
            "ave_precision_score": 0.7812269795774317,
            "fpr": 0.16557017543859648,
            "logloss": 1.14740622722281,
            "mae": 0.31882053447897474,
            "precision": 0.7166979362101313,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7655664006013796,
            "auditor_fn_violation": 0.0046860378454702855,
            "auditor_fp_violation": 0.004115135992194187,
            "ave_precision_score": 0.7650580199445527,
            "fpr": 0.17672886937431395,
            "logloss": 1.2412271222552427,
            "mae": 0.33797062004161965,
            "precision": 0.6754032258064516,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7952875831993367,
            "auditor_fn_violation": 0.007677662716629305,
            "auditor_fp_violation": 0.011825880333291468,
            "ave_precision_score": 0.7957098088451044,
            "fpr": 0.09978070175438597,
            "logloss": 0.571019000068277,
            "mae": 0.4104025604513784,
            "precision": 0.7775061124694377,
            "recall": 0.6450304259634888
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7941871933990261,
            "auditor_fn_violation": 0.008612499434484765,
            "auditor_fp_violation": 0.011240395170142702,
            "ave_precision_score": 0.7947795769519213,
            "fpr": 0.07903402854006586,
            "logloss": 0.5670067184727385,
            "mae": 0.4088695681481147,
            "precision": 0.8090185676392573,
            "recall": 0.6616052060737527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6059817214557794,
            "auditor_fn_violation": 0.010208711433756812,
            "auditor_fp_violation": 0.006351274965456602,
            "ave_precision_score": 0.6075403328612695,
            "fpr": 0.06359649122807018,
            "logloss": 0.6781190373277686,
            "mae": 0.4784128053538632,
            "precision": 0.7010309278350515,
            "recall": 0.27586206896551724
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6079067887412186,
            "auditor_fn_violation": 0.005669439080317451,
            "auditor_fp_violation": 0.006452006342236862,
            "ave_precision_score": 0.6085307347981188,
            "fpr": 0.06476399560922064,
            "logloss": 0.673369183385437,
            "mae": 0.478222062670177,
            "precision": 0.6878306878306878,
            "recall": 0.28199566160520606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7215693505179177,
            "auditor_fn_violation": 0.013814010177573782,
            "auditor_fp_violation": 0.0029675920110538885,
            "ave_precision_score": 0.7189797177543706,
            "fpr": 0.020833333333333332,
            "logloss": 0.9591682730150459,
            "mae": 0.4858010884756105,
            "precision": 0.8061224489795918,
            "recall": 0.16024340770791076
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7029992936046374,
            "auditor_fn_violation": 0.002862102383259804,
            "auditor_fp_violation": 0.004302963776070253,
            "ave_precision_score": 0.698442417800671,
            "fpr": 0.009879253567508232,
            "logloss": 0.8965796146790239,
            "mae": 0.46167195280603635,
            "precision": 0.896551724137931,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7999568917676045,
            "auditor_fn_violation": 0.013422565033272838,
            "auditor_fp_violation": 0.026637671146840854,
            "ave_precision_score": 0.7958505392759135,
            "fpr": 0.22149122807017543,
            "logloss": 1.2005706122183482,
            "mae": 0.3173634827114272,
            "precision": 0.6863354037267081,
            "recall": 0.896551724137931
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7633976471597557,
            "auditor_fn_violation": 0.010679308809417793,
            "auditor_fp_violation": 0.015579948774240756,
            "ave_precision_score": 0.758426412563838,
            "fpr": 0.23380900109769484,
            "logloss": 1.4667895480380697,
            "mae": 0.34118964291498693,
            "precision": 0.6570048309178744,
            "recall": 0.8850325379609545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6703645257893175,
            "auditor_fn_violation": 0.008771929824561405,
            "auditor_fp_violation": 0.006351274965456596,
            "ave_precision_score": 0.671878403957091,
            "fpr": 0.12390350877192982,
            "logloss": 0.9385984689288142,
            "mae": 0.3780448577615201,
            "precision": 0.7196029776674938,
            "recall": 0.5882352941176471
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6740572939991749,
            "auditor_fn_violation": 0.009893540268256614,
            "auditor_fp_violation": 0.0008537626539821985,
            "ave_precision_score": 0.6754679198062703,
            "fpr": 0.1207464324917673,
            "logloss": 0.885130971410473,
            "mae": 0.3665374484421313,
            "precision": 0.708994708994709,
            "recall": 0.5813449023861171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.787670689197739,
            "auditor_fn_violation": 0.014748140635564577,
            "auditor_fp_violation": 0.018485952351044676,
            "ave_precision_score": 0.7857581880074406,
            "fpr": 0.17324561403508773,
            "logloss": 1.1013201312226022,
            "mae": 0.313636413575314,
            "precision": 0.7024482109227872,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7514216665164839,
            "auditor_fn_violation": 0.0053646561310185725,
            "auditor_fp_violation": 0.0139821929503598,
            "ave_precision_score": 0.7506893043921916,
            "fpr": 0.18331503841931943,
            "logloss": 1.2980487208449063,
            "mae": 0.337708465539947,
            "precision": 0.6744639376218323,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8222694670469363,
            "auditor_fn_violation": 0.01926755275612968,
            "auditor_fp_violation": 0.02039892392078047,
            "ave_precision_score": 0.8226231540730514,
            "fpr": 0.1611842105263158,
            "logloss": 0.7104682796998736,
            "mae": 0.289471201427755,
            "precision": 0.7365591397849462,
            "recall": 0.8336713995943205
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8013932395263595,
            "auditor_fn_violation": 0.011715094613675705,
            "auditor_fp_violation": 0.026417855836077576,
            "ave_precision_score": 0.8018067241695779,
            "fpr": 0.17892425905598244,
            "logloss": 0.7664253547079595,
            "mae": 0.3097670740549786,
            "precision": 0.6964618249534451,
            "recall": 0.8112798264642083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8181902599788122,
            "auditor_fn_violation": 0.007486388384754992,
            "auditor_fp_violation": 0.023371749780178388,
            "ave_precision_score": 0.8189818686194383,
            "fpr": 0.2741228070175439,
            "logloss": 0.8599983157639475,
            "mae": 0.3321658757687832,
            "precision": 0.6473906911142454,
            "recall": 0.9310344827586207
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8001882474757772,
            "auditor_fn_violation": 0.004874146071990686,
            "auditor_fp_violation": 0.02654226125137212,
            "ave_precision_score": 0.8008666077163364,
            "fpr": 0.2864983534577388,
            "logloss": 0.9578483639117737,
            "mae": 0.3500169500459137,
            "precision": 0.6297872340425532,
            "recall": 0.9631236442516269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7705335176123209,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005103002135410231,
            "ave_precision_score": 0.5465835807321661,
            "fpr": 0.4583333333333333,
            "logloss": 0.6894958029739109,
            "mae": 0.49756677537439636,
            "precision": 0.5411635565312843,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7546334760331933,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010293938285156792,
            "ave_precision_score": 0.5134874930643428,
            "fpr": 0.49176728869374314,
            "logloss": 0.6915329684393474,
            "mae": 0.4984197526378915,
            "precision": 0.5071507150715071,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 7376,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.585816618473905,
            "auditor_fn_violation": 0.012277143162165048,
            "auditor_fp_violation": 0.012011681949503833,
            "ave_precision_score": 0.5739156621424086,
            "fpr": 0.019736842105263157,
            "logloss": 1.4732584779076916,
            "mae": 0.48443266387154216,
            "precision": 0.5714285714285714,
            "recall": 0.0486815415821501
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6296541964275812,
            "auditor_fn_violation": 0.014643868267094646,
            "auditor_fp_violation": 0.0068154653006464215,
            "ave_precision_score": 0.560931716467409,
            "fpr": 0.012074643249176729,
            "logloss": 1.389264774439833,
            "mae": 0.46194611428268195,
            "precision": 0.7317073170731707,
            "recall": 0.0650759219088937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7790207324904841,
            "auditor_fn_violation": 0.00621419166577701,
            "auditor_fp_violation": 0.0020333500816480344,
            "ave_precision_score": 0.6254331114596099,
            "fpr": 0.009868421052631578,
            "logloss": 0.6437330053909411,
            "mae": 0.45372016040691204,
            "precision": 0.9203539823008849,
            "recall": 0.21095334685598377
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7761337634912752,
            "auditor_fn_violation": 0.0024501691783480294,
            "auditor_fp_violation": 0.0019758507135016466,
            "ave_precision_score": 0.6025516127042533,
            "fpr": 0.006586169045005488,
            "logloss": 0.6350702231390322,
            "mae": 0.45196845399269375,
            "precision": 0.9411764705882353,
            "recall": 0.20824295010845986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 7376,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.605212255896241,
            "auditor_fn_violation": 0.003516333938294032,
            "auditor_fp_violation": 0.0005652556211531214,
            "ave_precision_score": 0.6094141216301995,
            "fpr": 0.0010964912280701754,
            "logloss": 1.1615514883919866,
            "mae": 0.5058282702806888,
            "precision": 0.9375,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.6030247176518493,
            "auditor_fn_violation": 0.0041074264651607025,
            "auditor_fp_violation": 0.00014635931211123327,
            "ave_precision_score": 0.6056143276720652,
            "fpr": 0.0043907793633369925,
            "logloss": 1.0876578978453333,
            "mae": 0.4776694905999373,
            "precision": 0.75,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7288067359095023,
            "auditor_fn_violation": 0.013814010177573782,
            "auditor_fp_violation": 0.0029675920110538885,
            "ave_precision_score": 0.7293384629511885,
            "fpr": 0.020833333333333332,
            "logloss": 0.9370366444142478,
            "mae": 0.4854866740489869,
            "precision": 0.8061224489795918,
            "recall": 0.16024340770791076
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7133177029128692,
            "auditor_fn_violation": 0.002862102383259804,
            "auditor_fp_violation": 0.004302963776070253,
            "ave_precision_score": 0.7140073433997836,
            "fpr": 0.009879253567508232,
            "logloss": 0.8882810462135768,
            "mae": 0.4616719066736858,
            "precision": 0.896551724137931,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 7376,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.6070713259777154,
            "auditor_fn_violation": 0.003516333938294032,
            "auditor_fp_violation": 0.0005652556211531214,
            "ave_precision_score": 0.6094783345892678,
            "fpr": 0.0010964912280701754,
            "logloss": 1.143768151541051,
            "mae": 0.5044618170966778,
            "precision": 0.9375,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.603956768823158,
            "auditor_fn_violation": 0.0041074264651607025,
            "auditor_fp_violation": 0.00014635931211123327,
            "ave_precision_score": 0.605616473627164,
            "fpr": 0.0043907793633369925,
            "logloss": 1.0716387010486923,
            "mae": 0.47670273234787613,
            "precision": 0.75,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7875040229910854,
            "auditor_fn_violation": 0.012555158179424224,
            "auditor_fp_violation": 0.01487983084202153,
            "ave_precision_score": 0.7788098590641329,
            "fpr": 0.16776315789473684,
            "logloss": 1.3331891186558629,
            "mae": 0.3101565456948745,
            "precision": 0.7107750472589792,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7565820053712882,
            "auditor_fn_violation": 0.010534060685142548,
            "auditor_fp_violation": 0.015245761678253452,
            "ave_precision_score": 0.7491812853916893,
            "fpr": 0.1800219538968167,
            "logloss": 1.4700961341812129,
            "mae": 0.3349903947187595,
            "precision": 0.6777996070726916,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8161627791167397,
            "auditor_fn_violation": 0.007072702039073344,
            "auditor_fp_violation": 0.01776891512791525,
            "ave_precision_score": 0.8176258485972518,
            "fpr": 0.23793859649122806,
            "logloss": 0.796276224520237,
            "mae": 0.3172058843529636,
            "precision": 0.6751497005988024,
            "recall": 0.9148073022312373
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.813153224690917,
            "auditor_fn_violation": 0.002771619945186692,
            "auditor_fp_violation": 0.02689108427857056,
            "ave_precision_score": 0.8135521282797834,
            "fpr": 0.24807903402854006,
            "logloss": 0.7950478598681707,
            "mae": 0.3297433863750748,
            "precision": 0.6554878048780488,
            "recall": 0.9327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 7376,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8099308678824761,
            "auditor_fn_violation": 0.007379630618127469,
            "auditor_fp_violation": 0.021429992044550525,
            "ave_precision_score": 0.8112664130560818,
            "fpr": 0.2675438596491228,
            "logloss": 0.9177967216739049,
            "mae": 0.3316504725892293,
            "precision": 0.6524216524216524,
            "recall": 0.9290060851926978
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7888478793169973,
            "auditor_fn_violation": 0.0030549728433629944,
            "auditor_fp_violation": 0.024456641053787052,
            "ave_precision_score": 0.7891309386594151,
            "fpr": 0.2810098792535675,
            "logloss": 1.0397656012471235,
            "mae": 0.3492298519747939,
            "precision": 0.6316546762589929,
            "recall": 0.9522776572668112
        }
    }
]