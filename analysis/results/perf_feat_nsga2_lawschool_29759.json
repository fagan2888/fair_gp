[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.587445133735764,
            "auditor_fn_violation": 0.04106772307111867,
            "auditor_fp_violation": 0.04139683661054201,
            "ave_precision_score": 0.5886892312729426,
            "fpr": 0.1524122807017544,
            "logloss": 0.6856374820631358,
            "mae": 0.48804096825290144,
            "precision": 0.5669781931464174,
            "recall": 0.3913978494623656
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6186903650942306,
            "auditor_fn_violation": 0.04928178432653392,
            "auditor_fp_violation": 0.035277102917995434,
            "ave_precision_score": 0.6199986632020007,
            "fpr": 0.12952799121844127,
            "logloss": 0.6796921131411735,
            "mae": 0.48541362887876094,
            "precision": 0.6445783132530121,
            "recall": 0.4376278118609407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.49999061387835153,
            "auditor_fn_violation": 0.03991228070175439,
            "auditor_fp_violation": 0.040420542407472816,
            "ave_precision_score": 0.5018342484784694,
            "fpr": 0.18311403508771928,
            "logloss": 0.708507304272589,
            "mae": 0.501818428763695,
            "precision": 0.5269121813031161,
            "recall": 0.4
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5545691063066802,
            "auditor_fn_violation": 0.05052538952453428,
            "auditor_fp_violation": 0.037243589410106075,
            "ave_precision_score": 0.559071855287864,
            "fpr": 0.1712403951701427,
            "logloss": 0.7036229181677895,
            "mae": 0.5007360244065556,
            "precision": 0.5795148247978437,
            "recall": 0.4396728016359918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8165934441903342,
            "mae": 0.5081292201934399,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8274678109662104,
            "mae": 0.5169776399117925,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4418859649122807,
            "auc_prc": 0.4037815723018134,
            "auditor_fn_violation": 0.010233918128654968,
            "auditor_fp_violation": 0.011583068409278226,
            "ave_precision_score": 0.4079192829945481,
            "fpr": 0.3881578947368421,
            "logloss": 0.717728501983947,
            "mae": 0.5081014960448731,
            "precision": 0.46686746987951805,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.4132113427212811,
            "auditor_fn_violation": 0.008527899182677531,
            "auditor_fp_violation": 0.013827833587381206,
            "ave_precision_score": 0.4171251610456147,
            "fpr": 0.38199780461031835,
            "logloss": 0.7175025322880589,
            "mae": 0.5089324558834606,
            "precision": 0.4949201741654572,
            "recall": 0.6973415132924335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7689941424599435,
            "auditor_fn_violation": 0.014919354838709674,
            "auditor_fp_violation": 0.01962155108128263,
            "ave_precision_score": 0.7694770927198602,
            "fpr": 0.17543859649122806,
            "logloss": 0.968768815358744,
            "mae": 0.3075070177210358,
            "precision": 0.6911196911196911,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8115553216196456,
            "auditor_fn_violation": 0.009129498809147011,
            "auditor_fp_violation": 0.026474734810452556,
            "ave_precision_score": 0.811910625971594,
            "fpr": 0.15148188803512624,
            "logloss": 0.8773641012914076,
            "mae": 0.2884629794646104,
            "precision": 0.7315175097276264,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5376766805280155,
            "auditor_fn_violation": 0.039186002641011124,
            "auditor_fp_violation": 0.046256230621295975,
            "ave_precision_score": 0.5360130470643285,
            "fpr": 0.13048245614035087,
            "logloss": 5.3560036436817,
            "mae": 0.4972584452070081,
            "precision": 0.5509433962264151,
            "recall": 0.3139784946236559
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6150206286782796,
            "auditor_fn_violation": 0.04435674857849642,
            "auditor_fp_violation": 0.03631236961622299,
            "ave_precision_score": 0.6135437082569479,
            "fpr": 0.10537870472008781,
            "logloss": 5.2481501108229995,
            "mae": 0.4914567940137025,
            "precision": 0.6390977443609023,
            "recall": 0.3476482617586912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6838006960194827,
            "auditor_fn_violation": 0.0029428409734012454,
            "auditor_fp_violation": 0.014148906942972661,
            "ave_precision_score": 0.679404760336296,
            "fpr": 0.42653508771929827,
            "logloss": 2.4928794046166054,
            "mae": 0.4245612293443982,
            "precision": 0.5412735849056604,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.687984721585261,
            "auditor_fn_violation": 0.005569286094294008,
            "auditor_fp_violation": 0.00985324184142213,
            "ave_precision_score": 0.6827674499937724,
            "fpr": 0.40285400658616904,
            "logloss": 2.434910495731151,
            "mae": 0.4072074752942068,
            "precision": 0.566193853427896,
            "recall": 0.9795501022494888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7125501503194057,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.7059086112384736,
            "fpr": 0.48026315789473684,
            "logloss": 2.510737096283204,
            "mae": 0.46944648819452706,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7424499697479249,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.740703519110066,
            "fpr": 0.45993413830954993,
            "logloss": 2.1839973842510636,
            "mae": 0.4466218776616516,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4418859649122807,
            "auc_prc": 0.4037815723018134,
            "auditor_fn_violation": 0.010233918128654968,
            "auditor_fp_violation": 0.011583068409278226,
            "ave_precision_score": 0.4079192829945481,
            "fpr": 0.3881578947368421,
            "logloss": 0.7177300973576073,
            "mae": 0.5081022226235323,
            "precision": 0.46686746987951805,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.4132113427212811,
            "auditor_fn_violation": 0.008527899182677531,
            "auditor_fp_violation": 0.013827833587381206,
            "ave_precision_score": 0.4171251610456147,
            "fpr": 0.38199780461031835,
            "logloss": 0.7175040712393828,
            "mae": 0.5089331254706555,
            "precision": 0.4949201741654572,
            "recall": 0.6973415132924335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7172683973265277,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5583390550852485,
            "fpr": 0.48026315789473684,
            "logloss": 7.874409657889088,
            "mae": 0.48135964624714433,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.732310816814912,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.57635040426177,
            "fpr": 0.45993413830954993,
            "logloss": 7.518729629670513,
            "mae": 0.4599341404032367,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7566749256830385,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5144026448174653,
            "fpr": 0.48026315789473684,
            "logloss": 16.625957303772168,
            "mae": 0.48135964912280704,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.769273127753304,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.538546255506608,
            "fpr": 0.45993413830954993,
            "logloss": 15.885930121614521,
            "mae": 0.45993413830954993,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7399015181427205,
            "auditor_fn_violation": 0.003617242029805697,
            "auditor_fp_violation": 0.0092576239255858,
            "ave_precision_score": 0.736368060511334,
            "fpr": 0.43859649122807015,
            "logloss": 1.6786802161789243,
            "mae": 0.4129772342532082,
            "precision": 0.531615925058548,
            "recall": 0.9763440860215054
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7839409098711155,
            "auditor_fn_violation": 0.0008193427748558292,
            "auditor_fp_violation": 0.004505230958115928,
            "ave_precision_score": 0.7823399195528895,
            "fpr": 0.4149286498353458,
            "logloss": 1.4222993965000064,
            "mae": 0.39003276481041976,
            "precision": 0.5584112149532711,
            "recall": 0.9775051124744376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5225583628781496,
            "auditor_fn_violation": 0.005812582531597814,
            "auditor_fp_violation": 0.010780937242434948,
            "ave_precision_score": 0.5240936023311868,
            "fpr": 0.05482456140350877,
            "logloss": 0.692907536809839,
            "mae": 0.49944914181373623,
            "precision": 0.5238095238095238,
            "recall": 0.11827956989247312
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.5470326236305167,
            "auditor_fn_violation": 0.007623254968247674,
            "auditor_fp_violation": 0.004375172327685321,
            "ave_precision_score": 0.5482903893989182,
            "fpr": 0.0570801317233809,
            "logloss": 0.6947369142842247,
            "mae": 0.5003628610059799,
            "precision": 0.5398230088495575,
            "recall": 0.12474437627811862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7148959218306532,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5555757984016098,
            "fpr": 0.48026315789473684,
            "logloss": 7.87668974736418,
            "mae": 0.4813596465085682,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7280241004367496,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5719055092371381,
            "fpr": 0.45993413830954993,
            "logloss": 7.521328009245645,
            "mae": 0.45993414079580297,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.525317610153766,
            "auditor_fn_violation": 0.027600924353895506,
            "auditor_fp_violation": 0.03576474743906747,
            "ave_precision_score": 0.5301655048767819,
            "fpr": 0.10416666666666667,
            "logloss": 5.651761477334003,
            "mae": 0.4987041457637587,
            "precision": 0.5410628019323671,
            "recall": 0.24086021505376345
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6128572508134026,
            "auditor_fn_violation": 0.03751691998949446,
            "auditor_fp_violation": 0.02627184334698082,
            "ave_precision_score": 0.611442033226846,
            "fpr": 0.08122941822173436,
            "logloss": 5.510331153095197,
            "mae": 0.49607734911328716,
            "precision": 0.6509433962264151,
            "recall": 0.2822085889570552
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7696376930100555,
            "auditor_fn_violation": 0.009825976230899832,
            "auditor_fp_violation": 0.02176792652772872,
            "ave_precision_score": 0.770113553274755,
            "fpr": 0.17982456140350878,
            "logloss": 0.9570214085447205,
            "mae": 0.30813385149095446,
            "precision": 0.6888045540796964,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.810869668020346,
            "auditor_fn_violation": 0.002754338588350971,
            "auditor_fp_violation": 0.02252355361797098,
            "ave_precision_score": 0.811226984772523,
            "fpr": 0.15477497255762898,
            "logloss": 0.8712140862813547,
            "mae": 0.28860599052208114,
            "precision": 0.7293666026871402,
            "recall": 0.7770961145194274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7365751829008429,
            "auditor_fn_violation": 0.005164119977362762,
            "auditor_fp_violation": 0.0187433768986224,
            "ave_precision_score": 0.7363135200254782,
            "fpr": 0.3991228070175439,
            "logloss": 2.2301527022520387,
            "mae": 0.4133221130601292,
            "precision": 0.5560975609756098,
            "recall": 0.9806451612903225
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.8087222213410672,
            "auditor_fn_violation": 0.001584810956296481,
            "auditor_fp_violation": 0.010948335509647753,
            "ave_precision_score": 0.8088746677724324,
            "fpr": 0.39846322722283206,
            "logloss": 1.9176639104734123,
            "mae": 0.3978148913591429,
            "precision": 0.567342073897497,
            "recall": 0.9734151329243353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7126105594641843,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.7059255425941893,
            "fpr": 0.48026315789473684,
            "logloss": 2.5132295988854,
            "mae": 0.4695034152215445,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7424671909343212,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.7406547851831577,
            "fpr": 0.45993413830954993,
            "logloss": 2.186464065704707,
            "mae": 0.4466900610284211,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6755288641974745,
            "auditor_fn_violation": 0.009302490096208264,
            "auditor_fp_violation": 0.027257741669610265,
            "ave_precision_score": 0.6681037678647151,
            "fpr": 0.33881578947368424,
            "logloss": 1.8706882489323262,
            "mae": 0.3979612112600814,
            "precision": 0.5846774193548387,
            "recall": 0.9354838709677419
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6924182952149107,
            "auditor_fn_violation": 0.005353787720633297,
            "auditor_fp_violation": 0.019982207979357118,
            "ave_precision_score": 0.6850511658852267,
            "fpr": 0.31613611416026344,
            "logloss": 1.7795944324153998,
            "mae": 0.3785996136432422,
            "precision": 0.6165113182423435,
            "recall": 0.9468302658486708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7221205633978917,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5664521319198039,
            "fpr": 0.48026315789473684,
            "logloss": 7.863898388839774,
            "mae": 0.48135964539751674,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7328768253185927,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5801337792504024,
            "fpr": 0.45993413830954993,
            "logloss": 7.510044338011914,
            "mae": 0.459934139879815,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7333589289615218,
            "auditor_fn_violation": 0.005484814186002641,
            "auditor_fp_violation": 0.029752443188508185,
            "ave_precision_score": 0.7324530070555824,
            "fpr": 0.39144736842105265,
            "logloss": 2.3332055991313707,
            "mae": 0.40617513146320877,
            "precision": 0.55980271270037,
            "recall": 0.9763440860215054
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.80304092803434,
            "auditor_fn_violation": 0.0037914245115931388,
            "auditor_fp_violation": 0.019696078992409796,
            "ave_precision_score": 0.8028677106194868,
            "fpr": 0.3907793633369923,
            "logloss": 2.053651426956142,
            "mae": 0.39456392808369345,
            "precision": 0.5721153846153846,
            "recall": 0.9734151329243353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6470205891859719,
            "auditor_fn_violation": 0.0009809469911337485,
            "auditor_fp_violation": 0.002345068487774252,
            "ave_precision_score": 0.6484909004416635,
            "fpr": 0.4857456140350877,
            "logloss": 0.9588755464368444,
            "mae": 0.4804568962896602,
            "precision": 0.5110375275938189,
            "recall": 0.9956989247311828
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7093959475429961,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00210174746775847,
            "ave_precision_score": 0.7108598887018643,
            "fpr": 0.4588364434687157,
            "logloss": 0.9020753518713185,
            "mae": 0.45990159803373754,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6867453178606339,
            "auditor_fn_violation": 0.0029428409734012454,
            "auditor_fp_violation": 0.013511126810314389,
            "ave_precision_score": 0.6819285487485961,
            "fpr": 0.4342105263157895,
            "logloss": 2.61446615933432,
            "mae": 0.4292208084773556,
            "precision": 0.5368421052631579,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.69077884009135,
            "auditor_fn_violation": 0.0021460046377045836,
            "auditor_fp_violation": 0.010724634665307136,
            "ave_precision_score": 0.6851600605139764,
            "fpr": 0.4094401756311745,
            "logloss": 2.5592332032308134,
            "mae": 0.4112707205727206,
            "precision": 0.5647607934655776,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6914307111116653,
            "auditor_fn_violation": 0.0023816261082814563,
            "auditor_fp_violation": 0.013722084854193661,
            "ave_precision_score": 0.6864467758817234,
            "fpr": 0.43640350877192985,
            "logloss": 2.7792515104012807,
            "mae": 0.43356383011108496,
            "precision": 0.5361305361305362,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6926788304692499,
            "auditor_fn_violation": 0.0021460046377045836,
            "auditor_fp_violation": 0.006240213088060097,
            "ave_precision_score": 0.686645576109381,
            "fpr": 0.4138309549945115,
            "logloss": 2.7336270684472725,
            "mae": 0.41481739247187727,
            "precision": 0.562137049941928,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7172683973265277,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5583390550852485,
            "fpr": 0.48026315789473684,
            "logloss": 7.874409657889088,
            "mae": 0.48135964624714433,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.732310816814912,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.57635040426177,
            "fpr": 0.45993413830954993,
            "logloss": 7.518729629670513,
            "mae": 0.4599341404032367,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6953055928585866,
            "auditor_fn_violation": 0.0023816261082814563,
            "auditor_fp_violation": 0.013722084854193661,
            "ave_precision_score": 0.6904433990010295,
            "fpr": 0.43640350877192985,
            "logloss": 2.764003131487815,
            "mae": 0.43246278494532575,
            "precision": 0.5361305361305362,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6974162979362969,
            "auditor_fn_violation": 0.0024714969729212827,
            "auditor_fp_violation": 0.006939928519776716,
            "ave_precision_score": 0.6917596409994884,
            "fpr": 0.4127332601536773,
            "logloss": 2.7112901720881446,
            "mae": 0.4134756698882423,
            "precision": 0.5622817229336438,
            "recall": 0.9877300613496932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6882789685710007,
            "auditor_fn_violation": 0.0029428409734012454,
            "auditor_fp_violation": 0.013126005730209205,
            "ave_precision_score": 0.6835178986205677,
            "fpr": 0.43530701754385964,
            "logloss": 2.6644843210112032,
            "mae": 0.4302781045864684,
            "precision": 0.5362149532710281,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6873258044713952,
            "auditor_fn_violation": 0.00408100045119972,
            "auditor_fp_violation": 0.010724634665307136,
            "ave_precision_score": 0.6812536913885904,
            "fpr": 0.4094401756311745,
            "logloss": 2.654578714408455,
            "mae": 0.4121094732561537,
            "precision": 0.5642523364485982,
            "recall": 0.9877300613496932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7453295491283408,
            "auditor_fn_violation": 0.007071778909639692,
            "auditor_fp_violation": 0.03171974959770793,
            "ave_precision_score": 0.7446156669768906,
            "fpr": 0.3081140350877193,
            "logloss": 1.144293362437815,
            "mae": 0.3684506098675787,
            "precision": 0.6031073446327684,
            "recall": 0.9182795698924732
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7921648321524374,
            "auditor_fn_violation": 0.008000377122153906,
            "auditor_fp_violation": 0.02656317467914537,
            "ave_precision_score": 0.7914083373403057,
            "fpr": 0.29637760702524696,
            "logloss": 0.9741245004675563,
            "mae": 0.3434467925522712,
            "precision": 0.6306429548563611,
            "recall": 0.9427402862985685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8359864551503896,
            "mae": 0.5033667131072818,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.849555205622949,
            "mae": 0.5136870338277877,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6761199362279702,
            "auditor_fn_violation": 0.010328239954725524,
            "auditor_fp_violation": 0.026975646610934496,
            "ave_precision_score": 0.6688556714475906,
            "fpr": 0.3366228070175439,
            "logloss": 1.868301556137023,
            "mae": 0.3968043462700096,
            "precision": 0.5862533692722371,
            "recall": 0.9354838709677419
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.692028805574704,
            "auditor_fn_violation": 0.004060797478669028,
            "auditor_fp_violation": 0.020442615531081412,
            "ave_precision_score": 0.6844823182225145,
            "fpr": 0.3150384193194292,
            "logloss": 1.7956134979547722,
            "mae": 0.37702690282454215,
            "precision": 0.616822429906542,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7537357413791282,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011234742336826379,
            "ave_precision_score": 0.5116653354399462,
            "fpr": 0.48793859649122806,
            "logloss": 16.675456241365108,
            "mae": 0.48698800972973305,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7706386492280232,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010768854599653634,
            "ave_precision_score": 0.542218355697663,
            "fpr": 0.4610318331503842,
            "logloss": 15.64891513355846,
            "mae": 0.46012492482596445,
            "precision": 0.5379537953795379,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6640188310171924,
            "auditor_fn_violation": 0.003442746651575175,
            "auditor_fp_violation": 0.01862808587464186,
            "ave_precision_score": 0.6607376143060197,
            "fpr": 0.4331140350877193,
            "logloss": 1.651528407153222,
            "mae": 0.42483483032699215,
            "precision": 0.536928487690504,
            "recall": 0.9849462365591398
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6711802395964007,
            "auditor_fn_violation": 0.0013715573573614022,
            "auditor_fp_violation": 0.015065991749080496,
            "ave_precision_score": 0.6674250536355173,
            "fpr": 0.4127332601536773,
            "logloss": 1.6299493335355066,
            "mae": 0.40473395150919517,
            "precision": 0.5632984901277585,
            "recall": 0.9918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 29759,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7711715363283225,
            "auditor_fn_violation": 0.00881909073759668,
            "auditor_fp_violation": 0.02242287766395855,
            "ave_precision_score": 0.7716516510791992,
            "fpr": 0.18421052631578946,
            "logloss": 0.9513706861044303,
            "mae": 0.3076763283689927,
            "precision": 0.6848030018761726,
            "recall": 0.7849462365591398
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8104090790330867,
            "auditor_fn_violation": 0.0005185429616210879,
            "auditor_fp_violation": 0.022312858636673417,
            "ave_precision_score": 0.8107268615306457,
            "fpr": 0.15697036223929747,
            "logloss": 0.8717982471396328,
            "mae": 0.28889468592205686,
            "precision": 0.7270992366412213,
            "recall": 0.7791411042944786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.733367846181288,
            "auditor_fn_violation": 0.005484814186002641,
            "auditor_fp_violation": 0.029752443188508185,
            "ave_precision_score": 0.7324611089839362,
            "fpr": 0.39144736842105265,
            "logloss": 2.3331915471974494,
            "mae": 0.40617488354610704,
            "precision": 0.55980271270037,
            "recall": 0.9763440860215054
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.8030370197420691,
            "auditor_fn_violation": 0.0037914245115931388,
            "auditor_fp_violation": 0.019696078992409796,
            "ave_precision_score": 0.8028693304511044,
            "fpr": 0.3907793633369923,
            "logloss": 2.053643160723955,
            "mae": 0.39456360118477185,
            "precision": 0.5721153846153846,
            "recall": 0.9734151329243353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 29759,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6764430555471819,
            "auditor_fn_violation": 0.009941520467836258,
            "auditor_fp_violation": 0.02633541347776601,
            "ave_precision_score": 0.668969731794213,
            "fpr": 0.3344298245614035,
            "logloss": 1.8622013339289736,
            "mae": 0.3961143138606036,
            "precision": 0.5872801082543978,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6924441964886489,
            "auditor_fn_violation": 0.003973251264369365,
            "auditor_fp_violation": 0.02107990282019135,
            "ave_precision_score": 0.6846078562995113,
            "fpr": 0.31613611416026344,
            "logloss": 1.7902022975611727,
            "mae": 0.3759520719754055,
            "precision": 0.6154873164218959,
            "recall": 0.9427402862985685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7219429525880148,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.003056438635739239,
            "ave_precision_score": 0.710077620566562,
            "fpr": 0.4824561403508772,
            "logloss": 3.3707095447540727,
            "mae": 0.4802025666689141,
            "precision": 0.5132743362831859,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7433189323841782,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010300643530103478,
            "ave_precision_score": 0.7385715045197092,
            "fpr": 0.4610318331503842,
            "logloss": 2.986615882082321,
            "mae": 0.45733425672177297,
            "precision": 0.5379537953795379,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7314754150371705,
            "auditor_fn_violation": 0.005227787209960386,
            "auditor_fp_violation": 0.028530848934416587,
            "ave_precision_score": 0.7292715970308632,
            "fpr": 0.39364035087719296,
            "logloss": 2.3910206431156364,
            "mae": 0.4071339235005066,
            "precision": 0.5595092024539877,
            "recall": 0.9806451612903225
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.803159241382051,
            "auditor_fn_violation": 0.004417716660044581,
            "auditor_fp_violation": 0.018879310793305633,
            "ave_precision_score": 0.8031859124337613,
            "fpr": 0.3918770581778266,
            "logloss": 2.0698802441819084,
            "mae": 0.39564493025499703,
            "precision": 0.5719424460431655,
            "recall": 0.9754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.641246049456589,
            "auditor_fn_violation": 0.0005612148651197888,
            "auditor_fp_violation": 0.002345068487774252,
            "ave_precision_score": 0.6427408181744279,
            "fpr": 0.4857456140350877,
            "logloss": 0.957059476900669,
            "mae": 0.4811244239344409,
            "precision": 0.5115766262403528,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7436891686363014,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00210174746775847,
            "ave_precision_score": 0.7451927303731969,
            "fpr": 0.4588364434687157,
            "logloss": 0.898589068489208,
            "mae": 0.4602954100437143,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 29759,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7629636480249031,
            "auditor_fn_violation": 0.007418411620448972,
            "auditor_fp_violation": 0.016898720514933862,
            "ave_precision_score": 0.763652691556497,
            "fpr": 0.3673245614035088,
            "logloss": 1.4384494222430577,
            "mae": 0.38235211295006966,
            "precision": 0.5743329097839899,
            "recall": 0.9720430107526882
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7557782533768702,
            "auditor_fn_violation": 0.009751301408147187,
            "auditor_fp_violation": 0.018018322659855077,
            "ave_precision_score": 0.7564287461347419,
            "fpr": 0.34357848518111966,
            "logloss": 1.3846551764432253,
            "mae": 0.3669490075948751,
            "precision": 0.5997442455242967,
            "recall": 0.9591002044989775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5314089367787953,
            "auditor_fn_violation": 0.06319562346727033,
            "auditor_fp_violation": 0.08057125475882099,
            "ave_precision_score": 0.5325525071915633,
            "fpr": 0.21600877192982457,
            "logloss": 0.69226739867391,
            "mae": 0.4938147810600257,
            "precision": 0.5206812652068127,
            "recall": 0.46021505376344085
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.574709238921491,
            "auditor_fn_violation": 0.06869459615380298,
            "auditor_fp_violation": 0.07282763069591772,
            "ave_precision_score": 0.5790221994678455,
            "fpr": 0.21514818880351264,
            "logloss": 0.6889011645809138,
            "mae": 0.49497886858962303,
            "precision": 0.5585585585585585,
            "recall": 0.5071574642126789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6789585140205712,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.6707616187517726,
            "fpr": 0.4725877192982456,
            "logloss": 2.4474807405234174,
            "mae": 0.45110603692336826,
            "precision": 0.5184357541899441,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6947851077288751,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.0031058000946826768,
            "ave_precision_score": 0.6869674858193304,
            "fpr": 0.45115257958287597,
            "logloss": 2.320925704773527,
            "mae": 0.4291144904734732,
            "precision": 0.542825361512792,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6645104040874131,
            "auditor_fn_violation": 0.003848330503678551,
            "auditor_fp_violation": 0.018471093841987526,
            "ave_precision_score": 0.6613004932378437,
            "fpr": 0.4407894736842105,
            "logloss": 1.6445395636283977,
            "mae": 0.4274604725733138,
            "precision": 0.5331010452961672,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6698356096479077,
            "auditor_fn_violation": 0.0003861012528087745,
            "auditor_fp_violation": 0.009879253567508232,
            "ave_precision_score": 0.6663279705703582,
            "fpr": 0.42371020856201974,
            "logloss": 1.6278129932887258,
            "mae": 0.40809519847386755,
            "precision": 0.5563218390804597,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6633578500166162,
            "auditor_fn_violation": 0.0035488587059045464,
            "auditor_fp_violation": 0.017227422583303904,
            "ave_precision_score": 0.6600089517800758,
            "fpr": 0.45285087719298245,
            "logloss": 1.650899796302905,
            "mae": 0.42783657057831687,
            "precision": 0.5269186712485682,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6700783188022257,
            "auditor_fn_violation": 0.0007968950275995054,
            "auditor_fp_violation": 0.009926074674463254,
            "ave_precision_score": 0.666291306425757,
            "fpr": 0.4313940724478595,
            "logloss": 1.6308511567707973,
            "mae": 0.4086611325209541,
            "precision": 0.5523917995444191,
            "recall": 0.9918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7527721691775291,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5189760932015441,
            "fpr": 0.4901315789473684,
            "logloss": 16.014768143997674,
            "mae": 0.48952338275940793,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7698869259714313,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5499821626211178,
            "fpr": 0.4632272228320527,
            "logloss": 15.02907572648122,
            "mae": 0.46269463138444233,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6646920484687554,
            "auditor_fn_violation": 0.003848330503678551,
            "auditor_fp_violation": 0.019999313159857153,
            "ave_precision_score": 0.6615959323142548,
            "fpr": 0.43640350877192985,
            "logloss": 1.6404644994059365,
            "mae": 0.4257691605506759,
            "precision": 0.5355892648774796,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6697548005088722,
            "auditor_fn_violation": 0.000653229445159031,
            "auditor_fp_violation": 0.012646901223071372,
            "ave_precision_score": 0.6661662003448335,
            "fpr": 0.42151481888035125,
            "logloss": 1.6260386003843783,
            "mae": 0.4077132337621355,
            "precision": 0.5586206896551724,
            "recall": 0.9938650306748467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5469888787660733,
            "auditor_fn_violation": 0.08704018109790607,
            "auditor_fp_violation": 0.09556399387731072,
            "ave_precision_score": 0.5488149529754475,
            "fpr": 0.31798245614035087,
            "logloss": 0.7056733765793893,
            "mae": 0.4931665338706552,
            "precision": 0.5440251572327044,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5105087758135035,
            "auditor_fn_violation": 0.08335297511218262,
            "auditor_fp_violation": 0.09025028482840067,
            "ave_precision_score": 0.5126715080720599,
            "fpr": 0.30735455543358947,
            "logloss": 0.7064253027481971,
            "mae": 0.4931511248571289,
            "precision": 0.5679012345679012,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7690031948903459,
            "auditor_fn_violation": 0.011799660441426149,
            "auditor_fp_violation": 0.01962155108128263,
            "ave_precision_score": 0.7694861507023354,
            "fpr": 0.17543859649122806,
            "logloss": 0.9682808849752806,
            "mae": 0.307501167416378,
            "precision": 0.6917148362235067,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8116101996189977,
            "auditor_fn_violation": 0.009129498809147011,
            "auditor_fp_violation": 0.026474734810452556,
            "ave_precision_score": 0.811967272510963,
            "fpr": 0.15148188803512624,
            "logloss": 0.8768287872513965,
            "mae": 0.28843993292375497,
            "precision": 0.7315175097276264,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7676799062059884,
            "auditor_fn_violation": 0.016678456894925486,
            "auditor_fp_violation": 0.021049197378233055,
            "ave_precision_score": 0.7681606659661218,
            "fpr": 0.16557017543859648,
            "logloss": 0.968607319894999,
            "mae": 0.30827185427116266,
            "precision": 0.6961770623742455,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.811602482793333,
            "auditor_fn_violation": 0.0007160831374767428,
            "auditor_fp_violation": 0.023298703055337343,
            "ave_precision_score": 0.81195760481241,
            "fpr": 0.141602634467618,
            "logloss": 0.8817509815625805,
            "mae": 0.2903276845133745,
            "precision": 0.7399193548387096,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5225577550537,
            "auditor_fn_violation": 0.005812582531597814,
            "auditor_fp_violation": 0.010780937242434948,
            "ave_precision_score": 0.5240881888988225,
            "fpr": 0.05482456140350877,
            "logloss": 0.6929075165940555,
            "mae": 0.4994491431535336,
            "precision": 0.5238095238095238,
            "recall": 0.11827956989247312
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.5470310770986013,
            "auditor_fn_violation": 0.007623254968247674,
            "auditor_fp_violation": 0.004375172327685321,
            "ave_precision_score": 0.5482984888487006,
            "fpr": 0.0570801317233809,
            "logloss": 0.6947368617117499,
            "mae": 0.5003628460884618,
            "precision": 0.5398230088495575,
            "recall": 0.12474437627811862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7072737132554789,
            "auditor_fn_violation": 0.011778438030560272,
            "auditor_fp_violation": 0.035124514305898975,
            "ave_precision_score": 0.7041613909377189,
            "fpr": 0.3157894736842105,
            "logloss": 0.6406412707673227,
            "mae": 0.42568992222802254,
            "precision": 0.5926449787835927,
            "recall": 0.9010752688172043
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8103851979953118,
            "auditor_fn_violation": 0.010011695276320547,
            "auditor_fp_violation": 0.03489212937192088,
            "ave_precision_score": 0.8055199194578457,
            "fpr": 0.2810098792535675,
            "logloss": 0.5842324155062243,
            "mae": 0.403138711732893,
            "precision": 0.639943741209564,
            "recall": 0.9304703476482618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7365751829008429,
            "auditor_fn_violation": 0.005164119977362762,
            "auditor_fp_violation": 0.0187433768986224,
            "ave_precision_score": 0.7363135200254782,
            "fpr": 0.3991228070175439,
            "logloss": 2.230150155342663,
            "mae": 0.41332200768241345,
            "precision": 0.5560975609756098,
            "recall": 0.9806451612903225
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.8087248407523222,
            "auditor_fn_violation": 0.001584810956296481,
            "auditor_fp_violation": 0.010948335509647753,
            "ave_precision_score": 0.8088799065949424,
            "fpr": 0.39846322722283206,
            "logloss": 1.9176598763941728,
            "mae": 0.3978148300212937,
            "precision": 0.567342073897497,
            "recall": 0.9734151329243353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7527721691775291,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5189760932015441,
            "fpr": 0.4901315789473684,
            "logloss": 16.014770582393798,
            "mae": 0.48952341779020797,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7698869259714313,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5499821626211178,
            "fpr": 0.4632272228320527,
            "logloss": 15.029080694887234,
            "mae": 0.4626946629205991,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7537357413791282,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011234742336826379,
            "ave_precision_score": 0.5116653354399462,
            "fpr": 0.48793859649122806,
            "logloss": 16.676079653637665,
            "mae": 0.48705398084661156,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7706386492280232,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010768854599653634,
            "ave_precision_score": 0.542218355697663,
            "fpr": 0.4610318331503842,
            "logloss": 15.650671250896481,
            "mae": 0.4602653009042095,
            "precision": 0.5379537953795379,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 29759,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6754245748885979,
            "auditor_fn_violation": 0.009969817015657426,
            "auditor_fp_violation": 0.026475234506848792,
            "ave_precision_score": 0.6680900278575308,
            "fpr": 0.3432017543859649,
            "logloss": 1.88781391174582,
            "mae": 0.40111306721442624,
            "precision": 0.582109479305741,
            "recall": 0.9376344086021505
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6903535989377427,
            "auditor_fn_violation": 0.005353787720633297,
            "auditor_fp_violation": 0.01849433724723105,
            "ave_precision_score": 0.6824518427183479,
            "fpr": 0.32491767288693746,
            "logloss": 1.8196591552572448,
            "mae": 0.381905373590707,
            "precision": 0.6100131752305665,
            "recall": 0.9468302658486708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 29759,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6102675919173325,
            "auditor_fn_violation": 0.09033201282776836,
            "auditor_fp_violation": 0.10882246163507202,
            "ave_precision_score": 0.5982433226749878,
            "fpr": 0.29714912280701755,
            "logloss": 0.6850686438731775,
            "mae": 0.49364436492977437,
            "precision": 0.5586319218241043,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5655722870908004,
            "auditor_fn_violation": 0.08780885294256295,
            "auditor_fp_violation": 0.09644627798211435,
            "ave_precision_score": 0.557547258624645,
            "fpr": 0.305159165751921,
            "logloss": 0.6859134215228816,
            "mae": 0.4939893706896957,
            "precision": 0.5683229813664596,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6794202968405905,
            "auditor_fn_violation": 0.008156479909451049,
            "auditor_fp_violation": 0.030905353428313513,
            "ave_precision_score": 0.6735940270923436,
            "fpr": 0.3168859649122807,
            "logloss": 1.7412456006716004,
            "mae": 0.3897952561413771,
            "precision": 0.596931659693166,
            "recall": 0.9204301075268817
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6939771795330849,
            "auditor_fn_violation": 0.01032371896318345,
            "auditor_fp_violation": 0.02168337486538932,
            "ave_precision_score": 0.6882032564316356,
            "fpr": 0.29637760702524696,
            "logloss": 1.6473317069473705,
            "mae": 0.3709372742884638,
            "precision": 0.625,
            "recall": 0.9202453987730062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5910752703983573,
            "auditor_fn_violation": 0.002475947934352009,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.5925479728716233,
            "fpr": 0.4725877192982456,
            "logloss": 0.8532512476632775,
            "mae": 0.47957911530280845,
            "precision": 0.5162738496071829,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6323395699809662,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002252615479057968,
            "ave_precision_score": 0.6316923843103314,
            "fpr": 0.4500548847420417,
            "logloss": 0.8158293624599843,
            "mae": 0.4630180686777693,
            "precision": 0.5434298440979956,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7180441472436242,
            "auditor_fn_violation": 0.0035488587059045464,
            "auditor_fp_violation": 0.016800600494524906,
            "ave_precision_score": 0.7158797601460152,
            "fpr": 0.4517543859649123,
            "logloss": 1.447900276138015,
            "mae": 0.4284190515611778,
            "precision": 0.5275229357798165,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.745998249781458,
            "auditor_fn_violation": 0.000653229445159031,
            "auditor_fp_violation": 0.010901514402692757,
            "ave_precision_score": 0.7456847789360659,
            "fpr": 0.433589462129528,
            "logloss": 1.2757624591779528,
            "mae": 0.4080291556932531,
            "precision": 0.5516458569807038,
            "recall": 0.9938650306748467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6944192854295924,
            "auditor_fn_violation": 0.0023816261082814563,
            "auditor_fp_violation": 0.013722084854193661,
            "ave_precision_score": 0.6889702088849188,
            "fpr": 0.43640350877192985,
            "logloss": 2.772478245098365,
            "mae": 0.4323711724661489,
            "precision": 0.5361305361305362,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6973546887602815,
            "auditor_fn_violation": 0.0024714969729212827,
            "auditor_fp_violation": 0.007990802253655949,
            "ave_precision_score": 0.6915691350360179,
            "fpr": 0.4105378704720088,
            "logloss": 2.6992749740298545,
            "mae": 0.4126780247255903,
            "precision": 0.5635939323220537,
            "recall": 0.9877300613496932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7148984136505263,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5555757984016098,
            "fpr": 0.48026315789473684,
            "logloss": 7.876058865626348,
            "mae": 0.4813596463778563,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7280253161125753,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5719063777617706,
            "fpr": 0.45993413830954993,
            "logloss": 7.520696435057611,
            "mae": 0.45993414073037525,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7066772961621579,
            "auditor_fn_violation": 0.011247877758913413,
            "auditor_fp_violation": 0.03567643942069941,
            "ave_precision_score": 0.703631667107461,
            "fpr": 0.31469298245614036,
            "logloss": 0.6489490441944766,
            "mae": 0.4191116065019486,
            "precision": 0.5929078014184397,
            "recall": 0.8989247311827957
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8113434934188728,
            "auditor_fn_violation": 0.010011695276320547,
            "auditor_fp_violation": 0.03489212937192088,
            "ave_precision_score": 0.8066427554438168,
            "fpr": 0.2810098792535675,
            "logloss": 0.5838778114888149,
            "mae": 0.3937614511968246,
            "precision": 0.639943741209564,
            "recall": 0.9304703476482618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 29759,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6090485411406603,
            "auditor_fn_violation": 0.09033201282776836,
            "auditor_fp_violation": 0.10882246163507202,
            "ave_precision_score": 0.5979530892295919,
            "fpr": 0.29714912280701755,
            "logloss": 0.6850686453332083,
            "mae": 0.49364436587743593,
            "precision": 0.5586319218241043,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5701851250576733,
            "auditor_fn_violation": 0.08780885294256295,
            "auditor_fp_violation": 0.09644627798211435,
            "ave_precision_score": 0.5594261955605171,
            "fpr": 0.305159165751921,
            "logloss": 0.6859134234810365,
            "mae": 0.4939893717692529,
            "precision": 0.5683229813664596,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6807966373379104,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.6716681113875247,
            "fpr": 0.4725877192982456,
            "logloss": 2.6389116874798004,
            "mae": 0.45750272158010485,
            "precision": 0.5184357541899441,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7006470388652789,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002195389681668493,
            "ave_precision_score": 0.6910267537372148,
            "fpr": 0.4500548847420417,
            "logloss": 2.5031245000641484,
            "mae": 0.4353858010207521,
            "precision": 0.5434298440979956,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7148718111945919,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5569647117000907,
            "fpr": 0.48026315789473684,
            "logloss": 7.864565185490488,
            "mae": 0.4813596455282287,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7293640856318019,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5751167522259155,
            "fpr": 0.45993413830954993,
            "logloss": 7.50811862721278,
            "mae": 0.45993413948724876,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.756674322526894,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5144026448174653,
            "fpr": 0.48026315789473684,
            "logloss": 16.625957303772168,
            "mae": 0.48135964912280704,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.769273127753304,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.538546255506608,
            "fpr": 0.45993413830954993,
            "logloss": 15.885930121614521,
            "mae": 0.45993413830954993,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6020307582111488,
            "auditor_fn_violation": 0.002475947934352009,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.603985620134863,
            "fpr": 0.4725877192982456,
            "logloss": 0.789052816336389,
            "mae": 0.47846501671888847,
            "precision": 0.5162738496071829,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6250275443015896,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002273424859926856,
            "ave_precision_score": 0.6260754211432367,
            "fpr": 0.4489571899012075,
            "logloss": 0.7609476126296786,
            "mae": 0.4660891818718905,
            "precision": 0.5440356744704571,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6646920484687554,
            "auditor_fn_violation": 0.003848330503678551,
            "auditor_fp_violation": 0.019999313159857153,
            "ave_precision_score": 0.6615959323142548,
            "fpr": 0.43640350877192985,
            "logloss": 1.640294818355603,
            "mae": 0.42576632190397695,
            "precision": 0.5355892648774796,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6697530158522988,
            "auditor_fn_violation": 0.000653229445159031,
            "auditor_fp_violation": 0.012646901223071372,
            "ave_precision_score": 0.6661777737985065,
            "fpr": 0.42151481888035125,
            "logloss": 1.6259931706805886,
            "mae": 0.4077127958053946,
            "precision": 0.5586206896551724,
            "recall": 0.9938650306748467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.4595738980242672,
            "auditor_fn_violation": 0.07729673646481795,
            "auditor_fp_violation": 0.0958043879273127,
            "ave_precision_score": 0.463439551379122,
            "fpr": 0.2576754385964912,
            "logloss": 0.7002610861137258,
            "mae": 0.4976875743616307,
            "precision": 0.5498084291187739,
            "recall": 0.6172043010752688
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.4682491590005863,
            "auditor_fn_violation": 0.07851773035317042,
            "auditor_fp_violation": 0.08712367535284907,
            "ave_precision_score": 0.4717954600995008,
            "fpr": 0.2678375411635565,
            "logloss": 0.70330837555483,
            "mae": 0.5003556083769227,
            "precision": 0.5595667870036101,
            "recall": 0.6339468302658486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6228486788001919,
            "auditor_fn_violation": 0.0009809469911337485,
            "auditor_fp_violation": 0.002345068487774252,
            "ave_precision_score": 0.6243622369451618,
            "fpr": 0.4857456140350877,
            "logloss": 0.9258480287885957,
            "mae": 0.48109039589109126,
            "precision": 0.5110375275938189,
            "recall": 0.9956989247311828
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7195079223925277,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00210174746775847,
            "ave_precision_score": 0.7211069906838781,
            "fpr": 0.4588364434687157,
            "logloss": 0.8690778545276888,
            "mae": 0.4605772591121372,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7169837733267659,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5566376592147638,
            "fpr": 0.48026315789473684,
            "logloss": 7.879787010988474,
            "mae": 0.4813596467046361,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7310411023795931,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5732994413214553,
            "fpr": 0.45993413830954993,
            "logloss": 7.52361060103977,
            "mae": 0.4599341405995198,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6955185309171207,
            "auditor_fn_violation": 0.0023816261082814563,
            "auditor_fp_violation": 0.013722084854193661,
            "ave_precision_score": 0.689929840167091,
            "fpr": 0.43640350877192985,
            "logloss": 2.785507500431561,
            "mae": 0.43264855579981615,
            "precision": 0.5361305361305362,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6983981434282103,
            "auditor_fn_violation": 0.0024714969729212827,
            "auditor_fp_violation": 0.006175183772844806,
            "ave_precision_score": 0.6926289245544512,
            "fpr": 0.411635565312843,
            "logloss": 2.709486038044682,
            "mae": 0.41288301707616354,
            "precision": 0.5629370629370629,
            "recall": 0.9877300613496932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7425671062330674,
            "auditor_fn_violation": 0.0035417845689492545,
            "auditor_fp_violation": 0.017816142705757692,
            "ave_precision_score": 0.7422611295433147,
            "fpr": 0.40131578947368424,
            "logloss": 2.1996407546736063,
            "mae": 0.41352731169674856,
            "precision": 0.5558252427184466,
            "recall": 0.9849462365591398
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.8157442229831539,
            "auditor_fn_violation": 0.0017576586101701764,
            "auditor_fp_violation": 0.013650953849995583,
            "ave_precision_score": 0.8159972867217862,
            "fpr": 0.39846322722283206,
            "logloss": 1.8840973627164055,
            "mae": 0.3973441725341635,
            "precision": 0.5678571428571428,
            "recall": 0.9754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5376766805280155,
            "auditor_fn_violation": 0.039186002641011124,
            "auditor_fp_violation": 0.046256230621295975,
            "ave_precision_score": 0.5360130470643285,
            "fpr": 0.13048245614035087,
            "logloss": 5.3561296360999044,
            "mae": 0.49725860863340654,
            "precision": 0.5509433962264151,
            "recall": 0.3139784946236559
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6150206286782796,
            "auditor_fn_violation": 0.04435674857849642,
            "auditor_fp_violation": 0.03631236961622299,
            "ave_precision_score": 0.6135437082569479,
            "fpr": 0.10537870472008781,
            "logloss": 5.248259192518781,
            "mae": 0.4914575032500655,
            "precision": 0.6390977443609023,
            "recall": 0.3476482617586912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6971365110188849,
            "auditor_fn_violation": 0.005883323901150727,
            "auditor_fp_violation": 0.022435142666509672,
            "ave_precision_score": 0.692434126576926,
            "fpr": 0.4100877192982456,
            "logloss": 2.4627239502009757,
            "mae": 0.41683907857118974,
            "precision": 0.548854041013269,
            "recall": 0.978494623655914
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6994819540227111,
            "auditor_fn_violation": 0.005569286094294008,
            "auditor_fp_violation": 0.0130240712513201,
            "ave_precision_score": 0.6947505564930769,
            "fpr": 0.3896816684961581,
            "logloss": 2.3928345658683776,
            "mae": 0.3990998181088604,
            "precision": 0.5743405275779376,
            "recall": 0.9795501022494888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6955322941032922,
            "auditor_fn_violation": 0.0023816261082814563,
            "auditor_fp_violation": 0.012880705679186793,
            "ave_precision_score": 0.690778469195104,
            "fpr": 0.43530701754385964,
            "logloss": 2.7534573585375917,
            "mae": 0.43230022722796163,
            "precision": 0.5367561260210035,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6980817619507782,
            "auditor_fn_violation": 0.0024714969729212827,
            "auditor_fp_violation": 0.007990802253655949,
            "ave_precision_score": 0.6924024423615724,
            "fpr": 0.4105378704720088,
            "logloss": 2.6982586921254472,
            "mae": 0.4125814488023656,
            "precision": 0.5635939323220537,
            "recall": 0.9877300613496932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.698974872467864,
            "auditor_fn_violation": 0.005883323901150727,
            "auditor_fp_violation": 0.02289385376192158,
            "ave_precision_score": 0.6941724234567013,
            "fpr": 0.41118421052631576,
            "logloss": 2.464348899988756,
            "mae": 0.4164743348699884,
            "precision": 0.5481927710843374,
            "recall": 0.978494623655914
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.701407780922064,
            "auditor_fn_violation": 0.005569286094294008,
            "auditor_fp_violation": 0.0130240712513201,
            "ave_precision_score": 0.6960673861075413,
            "fpr": 0.3896816684961581,
            "logloss": 2.410587748219267,
            "mae": 0.39854563034496043,
            "precision": 0.5743405275779376,
            "recall": 0.9795501022494888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7066579964654387,
            "auditor_fn_violation": 0.011247877758913413,
            "auditor_fp_violation": 0.03567643942069941,
            "ave_precision_score": 0.7036408574392319,
            "fpr": 0.31469298245614036,
            "logloss": 0.6489490916601112,
            "mae": 0.41911158511369684,
            "precision": 0.5929078014184397,
            "recall": 0.8989247311827957
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8113434934188728,
            "auditor_fn_violation": 0.010011695276320547,
            "auditor_fp_violation": 0.03489212937192088,
            "ave_precision_score": 0.8066427554438168,
            "fpr": 0.2810098792535675,
            "logloss": 0.5838778281925654,
            "mae": 0.39376142011406146,
            "precision": 0.639943741209564,
            "recall": 0.9304703476482618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.5597743727634577,
            "auditor_fn_violation": 0.08750707413695528,
            "auditor_fp_violation": 0.09995486479061187,
            "ave_precision_score": 0.5644691979342431,
            "fpr": 0.2675438596491228,
            "logloss": 0.6797254933078276,
            "mae": 0.4884204044611308,
            "precision": 0.5734265734265734,
            "recall": 0.7053763440860215
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.5254627760302821,
            "auditor_fn_violation": 0.08882573589327444,
            "auditor_fp_violation": 0.08611442038070764,
            "ave_precision_score": 0.5298466526550275,
            "fpr": 0.2722283205268935,
            "logloss": 0.6829959238454826,
            "mae": 0.49062149283914747,
            "precision": 0.5900826446280992,
            "recall": 0.7300613496932515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.6065473267755416,
            "auditor_fn_violation": 0.0005612148651197888,
            "auditor_fp_violation": 0.0018839043918521346,
            "ave_precision_score": 0.5941332287485062,
            "fpr": 0.48464912280701755,
            "logloss": 1.4308101187996194,
            "mae": 0.4830019523700078,
            "precision": 0.5121412803532008,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6349938506682433,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00210174746775847,
            "ave_precision_score": 0.6596911085503168,
            "fpr": 0.4588364434687157,
            "logloss": 1.35323432618879,
            "mae": 0.4583578541564104,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7537357413791282,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011234742336826379,
            "ave_precision_score": 0.5116653354399462,
            "fpr": 0.48793859649122806,
            "logloss": 16.6802620861206,
            "mae": 0.487739076453931,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7706386492280232,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005306392121568411,
            "ave_precision_score": 0.542218355697663,
            "fpr": 0.4621295279912184,
            "logloss": 15.65709127466855,
            "mae": 0.46109525534261986,
            "precision": 0.5373626373626373,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6645104040874131,
            "auditor_fn_violation": 0.003848330503678551,
            "auditor_fp_violation": 0.018471093841987526,
            "ave_precision_score": 0.6613004932378437,
            "fpr": 0.4407894736842105,
            "logloss": 1.6445969766333217,
            "mae": 0.4274607516923233,
            "precision": 0.5331010452961672,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6698329992508241,
            "auditor_fn_violation": 0.0003861012528087745,
            "auditor_fp_violation": 0.009879253567508232,
            "ave_precision_score": 0.6663253632040566,
            "fpr": 0.42371020856201974,
            "logloss": 1.6278568426217037,
            "mae": 0.4080948687836315,
            "precision": 0.5563218390804597,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7666108885292849,
            "auditor_fn_violation": 0.008441803433314469,
            "auditor_fp_violation": 0.02384316495937832,
            "ave_precision_score": 0.7673097082938387,
            "fpr": 0.3355263157894737,
            "logloss": 1.244425863302491,
            "mae": 0.3628981012023353,
            "precision": 0.59254327563249,
            "recall": 0.956989247311828
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7562394548938473,
            "auditor_fn_violation": 0.01268073242509748,
            "auditor_fp_violation": 0.022520952445362393,
            "ave_precision_score": 0.7572121574410041,
            "fpr": 0.30735455543358947,
            "logloss": 1.2102226292779037,
            "mae": 0.3474046320667983,
            "precision": 0.6221322537112011,
            "recall": 0.9427402862985685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7690063372091843,
            "auditor_fn_violation": 0.014919354838709674,
            "auditor_fp_violation": 0.01962155108128263,
            "ave_precision_score": 0.769485514640742,
            "fpr": 0.17543859649122806,
            "logloss": 0.9685802683307612,
            "mae": 0.3075062290535546,
            "precision": 0.6911196911196911,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8115828684939532,
            "auditor_fn_violation": 0.009129498809147011,
            "auditor_fp_violation": 0.026474734810452556,
            "ave_precision_score": 0.8119381396363783,
            "fpr": 0.15148188803512624,
            "logloss": 0.8771788604907772,
            "mae": 0.2884557035396357,
            "precision": 0.7315175097276264,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5159215665609178,
            "auditor_fn_violation": 0.04132475004716093,
            "auditor_fp_violation": 0.0484369480748852,
            "ave_precision_score": 0.5176919218089293,
            "fpr": 0.13815789473684212,
            "logloss": 0.6953368642176493,
            "mae": 0.49552773056437444,
            "precision": 0.5743243243243243,
            "recall": 0.3655913978494624
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5612243044274645,
            "auditor_fn_violation": 0.048574680287959714,
            "auditor_fp_violation": 0.03984476201871804,
            "ave_precision_score": 0.5659591358514312,
            "fpr": 0.11525795828759605,
            "logloss": 0.6897586747423137,
            "mae": 0.4954886058504917,
            "precision": 0.6601941747572816,
            "recall": 0.4171779141104294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 29759,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7630130683226084,
            "auditor_fn_violation": 0.007418411620448972,
            "auditor_fp_violation": 0.016898720514933862,
            "ave_precision_score": 0.763699496745742,
            "fpr": 0.3673245614035088,
            "logloss": 1.4389343123998544,
            "mae": 0.3824049871506789,
            "precision": 0.5743329097839899,
            "recall": 0.9720430107526882
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7557554035170579,
            "auditor_fn_violation": 0.009751301408147187,
            "auditor_fp_violation": 0.018018322659855077,
            "ave_precision_score": 0.7564049180956711,
            "fpr": 0.34357848518111966,
            "logloss": 1.3850601380059195,
            "mae": 0.36699774793714485,
            "precision": 0.5997442455242967,
            "recall": 0.9591002044989775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6782906935348917,
            "auditor_fn_violation": 0.008760139596302586,
            "auditor_fp_violation": 0.02904352604105342,
            "ave_precision_score": 0.6730927105357531,
            "fpr": 0.3201754385964912,
            "logloss": 1.7437159875397303,
            "mae": 0.3922812175169064,
            "precision": 0.5955678670360111,
            "recall": 0.9247311827956989
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6957267725377055,
            "auditor_fn_violation": 0.00930010168829507,
            "auditor_fp_violation": 0.02012527247283075,
            "ave_precision_score": 0.690161107804028,
            "fpr": 0.29747530186608123,
            "logloss": 1.6435411606326462,
            "mae": 0.3732184554919453,
            "precision": 0.6262068965517241,
            "recall": 0.9284253578732107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6935729876270555,
            "auditor_fn_violation": 0.002523108847387286,
            "auditor_fp_violation": 0.01705816554809843,
            "ave_precision_score": 0.6887195577737273,
            "fpr": 0.4375,
            "logloss": 2.806733217800111,
            "mae": 0.43327302136073403,
            "precision": 0.5355064027939465,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6925925192462847,
            "auditor_fn_violation": 0.0021460046377045836,
            "auditor_fp_violation": 0.010162781381846956,
            "ave_precision_score": 0.6867400574228094,
            "fpr": 0.4138309549945115,
            "logloss": 2.7638108078059958,
            "mae": 0.41487930407263196,
            "precision": 0.562137049941928,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.6154034173256259,
            "auditor_fn_violation": 0.0019524617996604415,
            "auditor_fp_violation": 0.002973036618391634,
            "ave_precision_score": 0.6171838510120129,
            "fpr": 0.4824561403508772,
            "logloss": 1.3358510660403664,
            "mae": 0.4830865655257775,
            "precision": 0.51165371809101,
            "recall": 0.9913978494623656
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7039728961523706,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.0003381524391195614,
            "ave_precision_score": 0.7052922620830646,
            "fpr": 0.4522502744237102,
            "logloss": 1.2488571297917634,
            "mae": 0.4554591595995701,
            "precision": 0.5422222222222223,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.688884782598218,
            "auditor_fn_violation": 0.0029428409734012454,
            "auditor_fp_violation": 0.013827563876133294,
            "ave_precision_score": 0.6843100830776128,
            "fpr": 0.43640350877192985,
            "logloss": 2.6662050302575713,
            "mae": 0.4304194862044556,
            "precision": 0.5355892648774796,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6871353030929519,
            "auditor_fn_violation": 0.003443484429120116,
            "auditor_fp_violation": 0.010880705021823861,
            "ave_precision_score": 0.6810014277212451,
            "fpr": 0.4094401756311745,
            "logloss": 2.6599321312260815,
            "mae": 0.4128302296596038,
            "precision": 0.5637426900584795,
            "recall": 0.9856850715746421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6628177763164256,
            "auditor_fn_violation": 0.003848330503678551,
            "auditor_fp_violation": 0.01586600730012952,
            "ave_precision_score": 0.6594568720999889,
            "fpr": 0.44298245614035087,
            "logloss": 1.6412731314329252,
            "mae": 0.42643267569834725,
            "precision": 0.5318655851680185,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6705427391468914,
            "auditor_fn_violation": 0.000653229445159031,
            "auditor_fp_violation": 0.011876954130922223,
            "ave_precision_score": 0.6669356131740508,
            "fpr": 0.42041712403951703,
            "logloss": 1.61604280328077,
            "mae": 0.4061473501369799,
            "precision": 0.5592635212888377,
            "recall": 0.9938650306748467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7537357413791282,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006034381255151421,
            "ave_precision_score": 0.5116653354399462,
            "fpr": 0.4868421052631579,
            "logloss": 16.672616543901906,
            "mae": 0.48649671341276224,
            "precision": 0.5115511551155115,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7706386492280232,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0007439353660630344,
            "ave_precision_score": 0.542218355697663,
            "fpr": 0.4588364434687157,
            "logloss": 15.646892070739876,
            "mae": 0.4594065978526088,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7537345217280031,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011234742336826379,
            "ave_precision_score": 0.5116641158236375,
            "fpr": 0.48793859649122806,
            "logloss": 16.676757309485698,
            "mae": 0.4872152564409924,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7706386492280232,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010768854599653634,
            "ave_precision_score": 0.542218355697663,
            "fpr": 0.4610318331503842,
            "logloss": 15.651076571813503,
            "mae": 0.46041157149171,
            "precision": 0.5379537953795379,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7672892615744206,
            "auditor_fn_violation": 0.011000282965478213,
            "auditor_fp_violation": 0.031192354488009735,
            "ave_precision_score": 0.7680229704301921,
            "fpr": 0.31359649122807015,
            "logloss": 1.1621396503652228,
            "mae": 0.3541715282498309,
            "precision": 0.6033287101248266,
            "recall": 0.9354838709677419
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7530522096605932,
            "auditor_fn_violation": 0.014088206178069003,
            "auditor_fp_violation": 0.02170418424625821,
            "ave_precision_score": 0.7540528310254372,
            "fpr": 0.2864983534577388,
            "logloss": 1.1458388385010587,
            "mae": 0.3396856680533803,
            "precision": 0.6339410939691444,
            "recall": 0.9243353783231084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7537345217280031,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011234742336826379,
            "ave_precision_score": 0.5116641158236375,
            "fpr": 0.48793859649122806,
            "logloss": 16.676752005140887,
            "mae": 0.4872140310492301,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7706386492280232,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010768854599653634,
            "ave_precision_score": 0.542218355697663,
            "fpr": 0.4610318331503842,
            "logloss": 15.651068947786534,
            "mae": 0.4604101823877981,
            "precision": 0.5379537953795379,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7666105347583543,
            "auditor_fn_violation": 0.008441803433314469,
            "auditor_fp_violation": 0.02384316495937832,
            "ave_precision_score": 0.7673138933397792,
            "fpr": 0.3355263157894737,
            "logloss": 1.2438693017882905,
            "mae": 0.36286515229698413,
            "precision": 0.59254327563249,
            "recall": 0.956989247311828
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7562871334564742,
            "auditor_fn_violation": 0.01268073242509748,
            "auditor_fp_violation": 0.023220667877079004,
            "ave_precision_score": 0.757218464610421,
            "fpr": 0.3062568605927552,
            "logloss": 1.209765799214586,
            "mae": 0.34738043976831917,
            "precision": 0.6229729729729729,
            "recall": 0.9427402862985685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6794202968405905,
            "auditor_fn_violation": 0.008156479909451049,
            "auditor_fp_violation": 0.030905353428313513,
            "ave_precision_score": 0.6735940270923436,
            "fpr": 0.3168859649122807,
            "logloss": 1.7413294354199045,
            "mae": 0.3897940644814649,
            "precision": 0.596931659693166,
            "recall": 0.9204301075268817
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6939771775262518,
            "auditor_fn_violation": 0.01032371896318345,
            "auditor_fp_violation": 0.02168337486538932,
            "ave_precision_score": 0.6882033942341811,
            "fpr": 0.29637760702524696,
            "logloss": 1.6473606548273723,
            "mae": 0.3709356461771233,
            "precision": 0.625,
            "recall": 0.9202453987730062
        }
    }
]