[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8615763382750564,
            "auditor_fn_violation": 0.015576625386996909,
            "auditor_fp_violation": 0.014045650249476904,
            "ave_precision_score": 0.8617900513527952,
            "fpr": 0.0756578947368421,
            "logloss": 0.6489075096047567,
            "mae": 0.28478321836761106,
            "precision": 0.8266331658291457,
            "recall": 0.6911764705882353
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8605989926395069,
            "auditor_fn_violation": 0.023327163584088477,
            "auditor_fp_violation": 0.014685788020676212,
            "ave_precision_score": 0.8608024877880389,
            "fpr": 0.07025246981339188,
            "logloss": 0.7077211638952546,
            "mae": 0.2894394293212753,
            "precision": 0.8337662337662337,
            "recall": 0.6715481171548117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8089074309740504,
            "auditor_fn_violation": 0.006302521008403364,
            "auditor_fp_violation": 0.016678738129727987,
            "ave_precision_score": 0.8095348778013833,
            "fpr": 0.1425438596491228,
            "logloss": 0.9221887737713145,
            "mae": 0.2843690620665121,
            "precision": 0.7389558232931727,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.819795992625719,
            "auditor_fn_violation": 0.010802419521515278,
            "auditor_fp_violation": 0.020663534983002208,
            "ave_precision_score": 0.8201290233713426,
            "fpr": 0.13172338090010977,
            "logloss": 0.9491402033976065,
            "mae": 0.2753293845211831,
            "precision": 0.7540983606557377,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8121607421916708,
            "auditor_fn_violation": 0.009142801857585143,
            "auditor_fp_violation": 0.01089449541284404,
            "ave_precision_score": 0.8125216730081399,
            "fpr": 0.11732456140350878,
            "logloss": 0.9360629136956866,
            "mae": 0.28402752484741706,
            "precision": 0.7622222222222222,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8235140509105873,
            "auditor_fn_violation": 0.015454992215093078,
            "auditor_fp_violation": 0.024478848459804855,
            "ave_precision_score": 0.8238309968761011,
            "fpr": 0.1207464324917673,
            "logloss": 0.9925748902230902,
            "mae": 0.2759521801038533,
            "precision": 0.7634408602150538,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8303924213640203,
            "auditor_fn_violation": 0.005800346454371223,
            "auditor_fp_violation": 0.01806444149364237,
            "ave_precision_score": 0.8306875845647775,
            "fpr": 0.16337719298245615,
            "logloss": 0.7249459509594729,
            "mae": 0.27766801283970044,
            "precision": 0.7214953271028037,
            "recall": 0.8109243697478992
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8336309105046396,
            "auditor_fn_violation": 0.012306582954039195,
            "auditor_fp_violation": 0.025092340726506675,
            "ave_precision_score": 0.8339259378413688,
            "fpr": 0.15806805708013172,
            "logloss": 0.7296444672190138,
            "mae": 0.2705950785416074,
            "precision": 0.7318435754189944,
            "recall": 0.8221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8538731825080235,
            "auditor_fn_violation": 0.013835139318885453,
            "auditor_fp_violation": 0.009541485594720752,
            "ave_precision_score": 0.84831753780338,
            "fpr": 0.11732456140350878,
            "logloss": 0.9831420674084911,
            "mae": 0.24804783650217638,
            "precision": 0.7770833333333333,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8401450642680115,
            "auditor_fn_violation": 0.01452723339564321,
            "auditor_fp_violation": 0.019687524558703862,
            "ave_precision_score": 0.833884380962785,
            "fpr": 0.1119648737650933,
            "logloss": 1.0557213793952722,
            "mae": 0.2514357487994322,
            "precision": 0.7834394904458599,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6999497869922131,
            "auditor_fn_violation": 0.0022620890461447717,
            "auditor_fp_violation": 0.009843272171253855,
            "ave_precision_score": 0.6288947063867516,
            "fpr": 0.24342105263157895,
            "logloss": 4.977133300583112,
            "mae": 0.32916810262525403,
            "precision": 0.645933014354067,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.6534927301452531,
            "auditor_fn_violation": 0.006080953846295168,
            "auditor_fp_violation": 0.020283271181327545,
            "ave_precision_score": 0.5803572233977304,
            "fpr": 0.2601536772777168,
            "logloss": 5.858591839967295,
            "mae": 0.3472066366235061,
            "precision": 0.6291079812206573,
            "recall": 0.8410041841004184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8190508325557226,
            "auditor_fn_violation": 0.00181980687011647,
            "auditor_fp_violation": 0.012705214872042493,
            "ave_precision_score": 0.8192608836322647,
            "fpr": 0.13596491228070176,
            "logloss": 0.977449448860837,
            "mae": 0.28213880432750166,
            "precision": 0.7474541751527495,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8212821867153075,
            "auditor_fn_violation": 0.00948426713942562,
            "auditor_fp_violation": 0.019956244311887306,
            "ave_precision_score": 0.8214762443963781,
            "fpr": 0.1251372118551043,
            "logloss": 1.0109160143069258,
            "mae": 0.2710847600884604,
            "precision": 0.7625,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8227522918461022,
            "auditor_fn_violation": 0.005001013563320071,
            "auditor_fp_violation": 0.015999718332528574,
            "ave_precision_score": 0.8229775456874094,
            "fpr": 0.17653508771929824,
            "logloss": 0.9646348736333865,
            "mae": 0.2832041872568305,
            "precision": 0.710431654676259,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8266110130644282,
            "auditor_fn_violation": 0.01627022583119383,
            "auditor_fp_violation": 0.029369040949341268,
            "ave_precision_score": 0.8268045090812199,
            "fpr": 0.1690450054884742,
            "logloss": 0.9886806640535396,
            "mae": 0.2699888674575213,
            "precision": 0.7225225225225225,
            "recall": 0.8389121338912134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8649058931083843,
            "auditor_fn_violation": 0.022399749373433597,
            "auditor_fp_violation": 0.009302571221632064,
            "ave_precision_score": 0.8650819053274005,
            "fpr": 0.047149122807017545,
            "logloss": 0.9249517979978279,
            "mae": 0.2881890511923462,
            "precision": 0.8746355685131195,
            "recall": 0.6302521008403361
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8470867643921718,
            "auditor_fn_violation": 0.039154177900050074,
            "auditor_fp_violation": 0.012987276373195968,
            "ave_precision_score": 0.8473747836791643,
            "fpr": 0.048298572996706916,
            "logloss": 1.0144246223129862,
            "mae": 0.3041255685862078,
            "precision": 0.8670694864048338,
            "recall": 0.600418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7259914377798862,
            "auditor_fn_violation": 0.0041003243402624205,
            "auditor_fp_violation": 0.012649887333011449,
            "ave_precision_score": 0.7197538768586886,
            "fpr": 0.33114035087719296,
            "logloss": 1.701082618098253,
            "mae": 0.36981496249456286,
            "precision": 0.5962566844919787,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7149653794334688,
            "auditor_fn_violation": 0.0033711632350307036,
            "auditor_fp_violation": 0.012868127048671248,
            "ave_precision_score": 0.7098234637127121,
            "fpr": 0.300768386388584,
            "logloss": 1.8863757972115476,
            "mae": 0.3564686823243628,
            "precision": 0.6246575342465753,
            "recall": 0.9539748953974896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6121318403948156,
            "auditor_fn_violation": 0.044458572902845356,
            "auditor_fp_violation": 0.038694068887815875,
            "ave_precision_score": 0.5801552821860898,
            "fpr": 0.1513157894736842,
            "logloss": 5.426611273571422,
            "mae": 0.37107758769376387,
            "precision": 0.676056338028169,
            "recall": 0.6050420168067226
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6461442613437713,
            "auditor_fn_violation": 0.05286158481414971,
            "auditor_fp_violation": 0.03201060682497471,
            "ave_precision_score": 0.6103350399107549,
            "fpr": 0.13830954994511527,
            "logloss": 5.119285871179206,
            "mae": 0.3662023254211922,
            "precision": 0.685785536159601,
            "recall": 0.5753138075313807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8281731576987762,
            "auditor_fn_violation": 0.009458388618605339,
            "auditor_fp_violation": 0.010874376307741835,
            "ave_precision_score": 0.8284711046674267,
            "fpr": 0.21052631578947367,
            "logloss": 1.0635798613621952,
            "mae": 0.28579207387491884,
            "precision": 0.6836902800658978,
            "recall": 0.8718487394957983
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8264712400931782,
            "auditor_fn_violation": 0.013521395863665384,
            "auditor_fp_violation": 0.03318942461016623,
            "ave_precision_score": 0.826798510737909,
            "fpr": 0.19319429198682767,
            "logloss": 1.1156899743035311,
            "mae": 0.27293084295584197,
            "precision": 0.7027027027027027,
            "recall": 0.8702928870292888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8353578916414193,
            "auditor_fn_violation": 0.015028379772961814,
            "auditor_fp_violation": 0.012428577176887175,
            "ave_precision_score": 0.835576404563218,
            "fpr": 0.06359649122807018,
            "logloss": 0.7298328308953592,
            "mae": 0.34711884142240723,
            "precision": 0.8370786516853933,
            "recall": 0.6260504201680672
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.835968330729415,
            "auditor_fn_violation": 0.023120484639161547,
            "auditor_fp_violation": 0.009684051482648564,
            "ave_precision_score": 0.8361237245213433,
            "fpr": 0.0570801317233809,
            "logloss": 0.821525857758223,
            "mae": 0.347576225126063,
            "precision": 0.8375,
            "recall": 0.5606694560669456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7917806960026775,
            "auditor_fn_violation": 0.0015019165560961282,
            "auditor_fp_violation": 0.017926122646064708,
            "ave_precision_score": 0.788858702072408,
            "fpr": 0.15789473684210525,
            "logloss": 1.363058067613667,
            "mae": 0.2827636244851631,
            "precision": 0.7198443579766537,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7920176939007029,
            "auditor_fn_violation": 0.012887580432556072,
            "auditor_fp_violation": 0.025383876307790598,
            "ave_precision_score": 0.7870033906585527,
            "fpr": 0.15367727771679474,
            "logloss": 1.437198436910344,
            "mae": 0.27587379301260523,
            "precision": 0.7307692307692307,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8268894159836909,
            "auditor_fn_violation": 0.007025836650449658,
            "auditor_fp_violation": 0.014581321422823115,
            "ave_precision_score": 0.8272406472005547,
            "fpr": 0.14364035087719298,
            "logloss": 0.915171437221514,
            "mae": 0.27575887992767023,
            "precision": 0.7364185110663984,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8286087982477213,
            "auditor_fn_violation": 0.012134350499933404,
            "auditor_fp_violation": 0.021958967000707305,
            "ave_precision_score": 0.8289239561450316,
            "fpr": 0.13172338090010977,
            "logloss": 0.978304322394396,
            "mae": 0.26869847100577243,
            "precision": 0.7540983606557377,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8582618099855607,
            "auditor_fn_violation": 0.0004514963880288958,
            "auditor_fp_violation": 0.017053456462256564,
            "ave_precision_score": 0.8585930959781063,
            "fpr": 0.13486842105263158,
            "logloss": 0.5018732942851123,
            "mae": 0.3203618263309054,
            "precision": 0.7544910179640718,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8562404755792266,
            "auditor_fn_violation": 0.008850451708316307,
            "auditor_fp_violation": 0.012799679564369787,
            "ave_precision_score": 0.8565102315078,
            "fpr": 0.10757409440175632,
            "logloss": 0.48641515947216324,
            "mae": 0.31610154583600364,
            "precision": 0.7905982905982906,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6316437276795517,
            "auditor_fn_violation": 0.003093671679197984,
            "auditor_fp_violation": 0.01396265894093031,
            "ave_precision_score": 0.6427384338101418,
            "fpr": 0.07017543859649122,
            "logloss": 7.930717787862277,
            "mae": 0.444588949837632,
            "precision": 0.6995305164319249,
            "recall": 0.3130252100840336
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6293179805447897,
            "auditor_fn_violation": 0.007339398977628158,
            "auditor_fp_violation": 0.008289750876508066,
            "ave_precision_score": 0.6434535032037549,
            "fpr": 0.059275521405049394,
            "logloss": 8.106555058817937,
            "mae": 0.4444153991583207,
            "precision": 0.7352941176470589,
            "recall": 0.3138075313807531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8489792136797105,
            "auditor_fn_violation": 0.015092879256965949,
            "auditor_fp_violation": 0.00806776114598423,
            "ave_precision_score": 0.8494236217899489,
            "fpr": 0.05263157894736842,
            "logloss": 0.6279916777021806,
            "mae": 0.3010831871133473,
            "precision": 0.8567164179104477,
            "recall": 0.6029411764705882
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8526519078181677,
            "auditor_fn_violation": 0.013732667674035163,
            "auditor_fp_violation": 0.009661235654548083,
            "ave_precision_score": 0.8529087244357817,
            "fpr": 0.043907793633369926,
            "logloss": 0.6284580101040126,
            "mae": 0.3002162241004848,
            "precision": 0.8757763975155279,
            "recall": 0.5899581589958159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8068133613201629,
            "auditor_fn_violation": 0.009430745982603572,
            "auditor_fp_violation": 0.013741348784806056,
            "ave_precision_score": 0.8074531662122475,
            "fpr": 0.14035087719298245,
            "logloss": 0.9484208995626354,
            "mae": 0.2839309714734319,
            "precision": 0.7366255144032922,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8231643411523294,
            "auditor_fn_violation": 0.01607043618443111,
            "auditor_fp_violation": 0.0204784732661872,
            "ave_precision_score": 0.8234992703041639,
            "fpr": 0.13172338090010977,
            "logloss": 0.974972564505449,
            "mae": 0.2734485326414614,
            "precision": 0.7530864197530864,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8119447841167847,
            "auditor_fn_violation": 0.008633716644552564,
            "auditor_fp_violation": 0.0028870915821664314,
            "ave_precision_score": 0.8123222814916898,
            "fpr": 0.10087719298245613,
            "logloss": 0.6278863671202298,
            "mae": 0.307396741251182,
            "precision": 0.7804295942720764,
            "recall": 0.6869747899159664
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8254859599429294,
            "auditor_fn_violation": 0.009488860004868437,
            "auditor_fp_violation": 0.015606026420728945,
            "ave_precision_score": 0.8258754932560752,
            "fpr": 0.07244785949506037,
            "logloss": 0.6092397090258957,
            "mae": 0.29621282523523595,
            "precision": 0.8290155440414507,
            "recall": 0.6694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.825449957636868,
            "auditor_fn_violation": 0.0055469556243550105,
            "auditor_fp_violation": 0.015174835023338162,
            "ave_precision_score": 0.8256778592178896,
            "fpr": 0.18311403508771928,
            "logloss": 0.9737832991385016,
            "mae": 0.28167533114185117,
            "precision": 0.7054673721340388,
            "recall": 0.8403361344537815
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8287727160835688,
            "auditor_fn_violation": 0.016433272554413975,
            "auditor_fp_violation": 0.028737803038561292,
            "ave_precision_score": 0.828934806097058,
            "fpr": 0.1712403951701427,
            "logloss": 1.0061851223404017,
            "mae": 0.26991262115008374,
            "precision": 0.7209302325581395,
            "recall": 0.8430962343096234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8693642832082157,
            "auditor_fn_violation": 0.007290745245466608,
            "auditor_fp_violation": 0.014053194913890232,
            "ave_precision_score": 0.869551699523711,
            "fpr": 0.13157894736842105,
            "logloss": 0.6128022725591082,
            "mae": 0.28060576328374537,
            "precision": 0.7642436149312377,
            "recall": 0.8172268907563025
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8583631421264659,
            "auditor_fn_violation": 0.0105681833839314,
            "auditor_fp_violation": 0.021152807741156975,
            "ave_precision_score": 0.8586634477466217,
            "fpr": 0.13172338090010977,
            "logloss": 0.6805168591270091,
            "mae": 0.28020416383767194,
            "precision": 0.7609561752988048,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8618695016778866,
            "auditor_fn_violation": 0.009361639392599147,
            "auditor_fp_violation": 0.0077056172541445376,
            "ave_precision_score": 0.8620236102691641,
            "fpr": 0.14473684210526316,
            "logloss": 0.8041054960743086,
            "mae": 0.2764226197435159,
            "precision": 0.7365269461077845,
            "recall": 0.7752100840336135
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8535169710318546,
            "auditor_fn_violation": 0.007660899558625635,
            "auditor_fp_violation": 0.027548844885325118,
            "ave_precision_score": 0.8537461258406398,
            "fpr": 0.13391877058177826,
            "logloss": 0.8471818801917782,
            "mae": 0.2746288618143284,
            "precision": 0.7555110220440882,
            "recall": 0.7887029288702929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 15860,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8696308885082771,
            "auditor_fn_violation": 0.008228291316526613,
            "auditor_fp_violation": 0.014669342507645263,
            "ave_precision_score": 0.8698175694717962,
            "fpr": 0.12609649122807018,
            "logloss": 0.5864629671613913,
            "mae": 0.2793615386736372,
            "precision": 0.7676767676767676,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8606832132847491,
            "auditor_fn_violation": 0.012083828980062373,
            "auditor_fp_violation": 0.015448850716036746,
            "ave_precision_score": 0.8609631253966381,
            "fpr": 0.11525795828759605,
            "logloss": 0.6369256364760525,
            "mae": 0.27711128247556704,
            "precision": 0.7839506172839507,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8262228962660052,
            "auditor_fn_violation": 0.007302263010467345,
            "auditor_fp_violation": 0.016990584258812173,
            "ave_precision_score": 0.8264422890804644,
            "fpr": 0.17105263157894737,
            "logloss": 0.9603040499432813,
            "mae": 0.2793902614244839,
            "precision": 0.7158469945355191,
            "recall": 0.8256302521008403
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8290295594463791,
            "auditor_fn_violation": 0.016653730095669388,
            "auditor_fp_violation": 0.03129571087782631,
            "ave_precision_score": 0.8291912577195187,
            "fpr": 0.16355653128430298,
            "logloss": 0.9954948912185692,
            "mae": 0.2682976053346516,
            "precision": 0.7276051188299817,
            "recall": 0.8326359832635983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 15860,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8041097180603516,
            "auditor_fn_violation": 0.007758366504496539,
            "auditor_fp_violation": 0.008281526637695158,
            "ave_precision_score": 0.8045299677433569,
            "fpr": 0.13267543859649122,
            "logloss": 0.9232473023151048,
            "mae": 0.2875550501939092,
            "precision": 0.7441860465116279,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.814746518119458,
            "auditor_fn_violation": 0.019078763049478944,
            "auditor_fp_violation": 0.018118302603793005,
            "ave_precision_score": 0.8150800690580063,
            "fpr": 0.12952799121844127,
            "logloss": 0.8928033461232486,
            "mae": 0.2798890552795542,
            "precision": 0.7489361702127659,
            "recall": 0.7364016736401674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8015907231959036,
            "auditor_fn_violation": 0.016279209052041877,
            "auditor_fp_violation": 0.012675036214389188,
            "ave_precision_score": 0.8021356954466886,
            "fpr": 0.09649122807017543,
            "logloss": 0.8218222761640676,
            "mae": 0.3469158151147801,
            "precision": 0.7879518072289157,
            "recall": 0.6869747899159664
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8210084354621517,
            "auditor_fn_violation": 0.026523797932291978,
            "auditor_fp_violation": 0.01385934802503657,
            "ave_precision_score": 0.821206133188237,
            "fpr": 0.08781558726673985,
            "logloss": 0.8671291061279708,
            "mae": 0.3392889202042986,
            "precision": 0.7969543147208121,
            "recall": 0.6569037656903766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8177761455589421,
            "auditor_fn_violation": 0.010006634232640428,
            "auditor_fp_violation": 0.005726400289715115,
            "ave_precision_score": 0.8181362173493143,
            "fpr": 0.09978070175438597,
            "logloss": 0.9422388681489564,
            "mae": 0.2895326606735788,
            "precision": 0.7753086419753087,
            "recall": 0.6596638655462185
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8182110021261455,
            "auditor_fn_violation": 0.014113875505789313,
            "auditor_fp_violation": 0.01647809807256954,
            "ave_precision_score": 0.8185492514725838,
            "fpr": 0.09110867178924259,
            "logloss": 0.9480955622004994,
            "mae": 0.28611106187513013,
            "precision": 0.7925,
            "recall": 0.6631799163179917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8142600570538144,
            "auditor_fn_violation": 0.009103641456582639,
            "auditor_fp_violation": 0.014349951714147758,
            "ave_precision_score": 0.8146018252186966,
            "fpr": 0.1118421052631579,
            "logloss": 0.9432492845760844,
            "mae": 0.2813673312874049,
            "precision": 0.7723214285714286,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8220017459130246,
            "auditor_fn_violation": 0.01833931171318475,
            "auditor_fp_violation": 0.025008682690138246,
            "ave_precision_score": 0.8223444036441715,
            "fpr": 0.12184412733260154,
            "logloss": 0.9797166744323162,
            "mae": 0.27804030218825326,
            "precision": 0.7602591792656588,
            "recall": 0.7364016736401674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5594343200958711,
            "auditor_fn_violation": 0.008449432404540769,
            "auditor_fp_violation": 0.0031084017382906814,
            "ave_precision_score": 0.5711007135721031,
            "fpr": 0.07017543859649122,
            "logloss": 8.942352170648487,
            "mae": 0.4606470776424768,
            "precision": 0.6862745098039216,
            "recall": 0.29411764705882354
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5695062425736127,
            "auditor_fn_violation": 0.0071005699746014605,
            "auditor_fp_violation": 0.0019038541003845743,
            "ave_precision_score": 0.5853697690143593,
            "fpr": 0.052689352360043906,
            "logloss": 8.982705672200856,
            "mae": 0.4549446598372841,
            "precision": 0.7362637362637363,
            "recall": 0.2803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5517809135900602,
            "auditor_fn_violation": 0.006869195046439641,
            "auditor_fp_violation": 0.009295026557218734,
            "ave_precision_score": 0.5634582090958673,
            "fpr": 0.08771929824561403,
            "logloss": 8.945068176540154,
            "mae": 0.46790242290227285,
            "precision": 0.6396396396396397,
            "recall": 0.29831932773109243
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5641173856587859,
            "auditor_fn_violation": 0.0016396529630871538,
            "auditor_fp_violation": 0.004492183043783575,
            "ave_precision_score": 0.5799903494102105,
            "fpr": 0.06256860592755215,
            "logloss": 8.978412224582009,
            "mae": 0.45970743902895134,
            "precision": 0.7106598984771574,
            "recall": 0.2928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 15860,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.833085978549774,
            "auditor_fn_violation": 0.009029927760577918,
            "auditor_fp_violation": 0.012504023821020442,
            "ave_precision_score": 0.8336705562598314,
            "fpr": 0.12719298245614036,
            "logloss": 0.8180413394129711,
            "mae": 0.2734368727253091,
            "precision": 0.7583333333333333,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8393786764022481,
            "auditor_fn_violation": 0.01138800986547497,
            "auditor_fp_violation": 0.021895589700428184,
            "ave_precision_score": 0.8396380801362472,
            "fpr": 0.12623490669593854,
            "logloss": 0.8582787557457388,
            "mae": 0.2668166807220879,
            "precision": 0.7604166666666666,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8344040421890595,
            "auditor_fn_violation": 0.007698474126492706,
            "auditor_fp_violation": 0.01000673990020924,
            "ave_precision_score": 0.8348989071880925,
            "fpr": 0.12609649122807018,
            "logloss": 0.8176789843683772,
            "mae": 0.27271649754826693,
            "precision": 0.7604166666666666,
            "recall": 0.7668067226890757
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8391025226314066,
            "auditor_fn_violation": 0.015239127539280486,
            "auditor_fp_violation": 0.0216294050392559,
            "ave_precision_score": 0.8393649118528405,
            "fpr": 0.1251372118551043,
            "logloss": 0.8598685872942652,
            "mae": 0.2665872516107186,
            "precision": 0.7620041753653445,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8502236602988847,
            "auditor_fn_violation": 0.004883532360312547,
            "auditor_fp_violation": 0.010444330436182205,
            "ave_precision_score": 0.850606996570537,
            "fpr": 0.22916666666666666,
            "logloss": 0.6692111574962498,
            "mae": 0.3195099219664004,
            "precision": 0.6774691358024691,
            "recall": 0.9222689075630253
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8531145782604468,
            "auditor_fn_violation": 0.00588346063225386,
            "auditor_fp_violation": 0.03178751872799224,
            "ave_precision_score": 0.8533792514771934,
            "fpr": 0.21075740944017562,
            "logloss": 0.6313370998317765,
            "mae": 0.3044875434329672,
            "precision": 0.6947535771065183,
            "recall": 0.9142259414225942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8459411200762392,
            "auditor_fn_violation": 0.009039141972578513,
            "auditor_fp_violation": 0.013167954289393213,
            "ave_precision_score": 0.8461111821610846,
            "fpr": 0.13596491228070176,
            "logloss": 0.669191115325385,
            "mae": 0.29209679225561813,
            "precision": 0.7489878542510121,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8521563961795562,
            "auditor_fn_violation": 0.011564835185023591,
            "auditor_fp_violation": 0.023292425398579848,
            "ave_precision_score": 0.8522923065305296,
            "fpr": 0.1207464324917673,
            "logloss": 0.7183855241886913,
            "mae": 0.2808364686933392,
            "precision": 0.7750511247443763,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.861599710443872,
            "auditor_fn_violation": 0.011397980244729471,
            "auditor_fp_violation": 0.010409122002253343,
            "ave_precision_score": 0.8627953723948212,
            "fpr": 0.08662280701754387,
            "logloss": 0.49142635000462664,
            "mae": 0.32577379991243216,
            "precision": 0.8123515439429929,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8492096290104926,
            "auditor_fn_violation": 0.008813708784773736,
            "auditor_fp_violation": 0.011516923006720529,
            "ave_precision_score": 0.8494674150485781,
            "fpr": 0.08232711306256861,
            "logloss": 0.5064072625287414,
            "mae": 0.33569534185611355,
            "precision": 0.8214285714285714,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7290034975711326,
            "auditor_fn_violation": 0.008255933952528386,
            "auditor_fp_violation": 0.007869084983099956,
            "ave_precision_score": 0.7282668018651692,
            "fpr": 0.15899122807017543,
            "logloss": 1.4574151766630496,
            "mae": 0.2991913111783203,
            "precision": 0.716796875,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7484679499095506,
            "auditor_fn_violation": 0.011847296409757084,
            "auditor_fp_violation": 0.02017426222484745,
            "ave_precision_score": 0.7486713488691352,
            "fpr": 0.15148188803512624,
            "logloss": 1.4105837476439744,
            "mae": 0.2876011315526203,
            "precision": 0.7256461232604374,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 15860,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.48616841230163665,
            "auditor_fn_violation": 0.009734814978623033,
            "auditor_fp_violation": 0.013555247062610661,
            "ave_precision_score": 0.482127989960125,
            "fpr": 0.26096491228070173,
            "logloss": 5.434398684070318,
            "mae": 0.46897348098696484,
            "precision": 0.5559701492537313,
            "recall": 0.6260504201680672
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5047734328442316,
            "auditor_fn_violation": 0.017191095352479473,
            "auditor_fp_violation": 0.01357541771978614,
            "ave_precision_score": 0.49491999121550434,
            "fpr": 0.265642151481888,
            "logloss": 5.243977125950188,
            "mae": 0.46908586425559107,
            "precision": 0.5575868372943327,
            "recall": 0.6380753138075314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7280037947284363,
            "auditor_fn_violation": 0.0018244139761167608,
            "auditor_fp_violation": 0.007054261226460648,
            "ave_precision_score": 0.7273387958239801,
            "fpr": 0.21820175438596492,
            "logloss": 1.4581514924227714,
            "mae": 0.3110123501882999,
            "precision": 0.6644182124789207,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7348321840949031,
            "auditor_fn_violation": 0.011326006181996888,
            "auditor_fp_violation": 0.029767050395094096,
            "ave_precision_score": 0.7351585747757361,
            "fpr": 0.21075740944017562,
            "logloss": 1.365382365604223,
            "mae": 0.29975079920899506,
            "precision": 0.6767676767676768,
            "recall": 0.8410041841004184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 15860,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.803542625121953,
            "auditor_fn_violation": 0.013673890608875132,
            "auditor_fp_violation": 0.005620774987928535,
            "ave_precision_score": 0.8038787604248308,
            "fpr": 0.09539473684210527,
            "logloss": 1.0677179096291574,
            "mae": 0.30367839013235465,
            "precision": 0.7722513089005235,
            "recall": 0.6197478991596639
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8115473661246689,
            "auditor_fn_violation": 0.01422410427641702,
            "auditor_fp_violation": 0.014865779553468895,
            "ave_precision_score": 0.8119402921917117,
            "fpr": 0.08562019758507135,
            "logloss": 1.0384882567700153,
            "mae": 0.2936885346443374,
            "precision": 0.796875,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.736993821971669,
            "auditor_fn_violation": 0.004303037004275402,
            "auditor_fp_violation": 0.010049492998551433,
            "ave_precision_score": 0.7363046127659734,
            "fpr": 0.21052631578947367,
            "logloss": 1.488124407151822,
            "mae": 0.30159315376660717,
            "precision": 0.673469387755102,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7493635133456039,
            "auditor_fn_violation": 0.015514699465849751,
            "auditor_fp_violation": 0.025241911155165386,
            "ave_precision_score": 0.7494797292513135,
            "fpr": 0.19099890230515917,
            "logloss": 1.4435696849036397,
            "mae": 0.2862335848554436,
            "precision": 0.6979166666666666,
            "recall": 0.8410041841004184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8045726407234048,
            "auditor_fn_violation": 0.009587387586613594,
            "auditor_fp_violation": 0.008771929824561406,
            "ave_precision_score": 0.804892904438882,
            "fpr": 0.11951754385964912,
            "logloss": 0.9831165084261122,
            "mae": 0.29076506370221833,
            "precision": 0.7604395604395604,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.816770307650394,
            "auditor_fn_violation": 0.017868543005295574,
            "auditor_fp_violation": 0.01897262861155546,
            "ave_precision_score": 0.8169418387183836,
            "fpr": 0.1207464324917673,
            "logloss": 1.013984676882556,
            "mae": 0.28001107722727364,
            "precision": 0.7603485838779956,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8187336148293779,
            "auditor_fn_violation": 0.0035451680672268955,
            "auditor_fp_violation": 0.01520501368099147,
            "ave_precision_score": 0.8190732821167602,
            "fpr": 0.1162280701754386,
            "logloss": 0.9258848331405889,
            "mae": 0.27860282753706567,
            "precision": 0.7628635346756152,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8230696843253699,
            "auditor_fn_violation": 0.012239986405118293,
            "auditor_fp_violation": 0.023515513495562322,
            "ave_precision_score": 0.8233796353656264,
            "fpr": 0.11745334796926454,
            "logloss": 0.9273505523818899,
            "mae": 0.27419420355245777,
            "precision": 0.7648351648351648,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8583336314745278,
            "auditor_fn_violation": 0.006961337166445529,
            "auditor_fp_violation": 0.012808325285691298,
            "ave_precision_score": 0.8596146933743019,
            "fpr": 0.12171052631578948,
            "logloss": 0.5683998634837295,
            "mae": 0.28840704818905677,
            "precision": 0.7706611570247934,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.870067895766395,
            "auditor_fn_violation": 0.011339784778325352,
            "auditor_fp_violation": 0.012533494903197512,
            "ave_precision_score": 0.8702632371709121,
            "fpr": 0.09549945115257959,
            "logloss": 0.5387326820571653,
            "mae": 0.2824427098172291,
            "precision": 0.8104575163398693,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8074723161500549,
            "auditor_fn_violation": 0.008718948105558011,
            "auditor_fp_violation": 0.013167954289393213,
            "ave_precision_score": 0.8081071471871529,
            "fpr": 0.13596491228070176,
            "logloss": 0.981867014686959,
            "mae": 0.2851773425543036,
            "precision": 0.7432712215320911,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8237834359562289,
            "auditor_fn_violation": 0.01733806704664974,
            "auditor_fp_violation": 0.019200786892560266,
            "ave_precision_score": 0.8240752347429249,
            "fpr": 0.13062568605927552,
            "logloss": 1.0070773021485178,
            "mae": 0.2754792667369412,
            "precision": 0.7525987525987526,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8351629237641833,
            "auditor_fn_violation": 0.018718671679198,
            "auditor_fp_violation": 0.015149686141960408,
            "ave_precision_score": 0.8356647295167656,
            "fpr": 0.09429824561403509,
            "logloss": 0.6685535940822336,
            "mae": 0.32671353929081787,
            "precision": 0.8045454545454546,
            "recall": 0.7436974789915967
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8488030705231733,
            "auditor_fn_violation": 0.011587799512237689,
            "auditor_fp_violation": 0.011397773682195798,
            "ave_precision_score": 0.8489026709418253,
            "fpr": 0.07464324917672886,
            "logloss": 0.7325711810581389,
            "mae": 0.3198919965636346,
            "precision": 0.8329238329238329,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8491755967517967,
            "auditor_fn_violation": 0.02550493881763232,
            "auditor_fp_violation": 0.014319773056494449,
            "ave_precision_score": 0.8496355660410438,
            "fpr": 0.07785087719298246,
            "logloss": 0.6668663421565234,
            "mae": 0.3218957249270732,
            "precision": 0.8280871670702179,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8501331707994002,
            "auditor_fn_violation": 0.013748742703085032,
            "auditor_fp_violation": 0.013233180298278928,
            "ave_precision_score": 0.8502390264123808,
            "fpr": 0.06805708013172337,
            "logloss": 0.7484294970110105,
            "mae": 0.3225560278779923,
            "precision": 0.8389610389610389,
            "recall": 0.6757322175732218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8072263766132968,
            "auditor_fn_violation": 0.003174296034203159,
            "auditor_fp_violation": 0.015295549653951392,
            "ave_precision_score": 0.8077898358379919,
            "fpr": 0.14144736842105263,
            "logloss": 0.956711575253659,
            "mae": 0.28559493815775067,
            "precision": 0.7378048780487805,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.820726029710652,
            "auditor_fn_violation": 0.010765676597972711,
            "auditor_fp_violation": 0.021474764426574863,
            "ave_precision_score": 0.8210581578689142,
            "fpr": 0.1350164654226125,
            "logloss": 0.980094818753829,
            "mae": 0.2748745691194579,
            "precision": 0.7505070993914807,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8585485722372107,
            "auditor_fn_violation": 0.00629791390240307,
            "auditor_fp_violation": 0.005364256397875426,
            "ave_precision_score": 0.8592229364584915,
            "fpr": 0.0581140350877193,
            "logloss": 0.5272339027376451,
            "mae": 0.338120801804236,
            "precision": 0.8454810495626822,
            "recall": 0.6092436974789915
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8422898683190652,
            "auditor_fn_violation": 0.015073784383338926,
            "auditor_fp_violation": 0.004583446356185502,
            "ave_precision_score": 0.8425564100182596,
            "fpr": 0.05817782656421515,
            "logloss": 0.5508382792876466,
            "mae": 0.35206888327487507,
            "precision": 0.8389057750759878,
            "recall": 0.5774058577405857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8084337308184667,
            "auditor_fn_violation": 0.0030222615361934304,
            "auditor_fp_violation": 0.018268147432802192,
            "ave_precision_score": 0.8088174077392766,
            "fpr": 0.18859649122807018,
            "logloss": 0.9371762846260863,
            "mae": 0.29504227654808796,
            "precision": 0.6906474820143885,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8036668451328963,
            "auditor_fn_violation": 0.012111386172719302,
            "auditor_fp_violation": 0.0318255451081597,
            "ave_precision_score": 0.8040479210486398,
            "fpr": 0.1800219538968167,
            "logloss": 0.9434055003336804,
            "mae": 0.2858041853741213,
            "precision": 0.7055655296229802,
            "recall": 0.8221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 15860,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8605525818414692,
            "auditor_fn_violation": 0.012641898864809082,
            "auditor_fp_violation": 0.0175136809914695,
            "ave_precision_score": 0.860751566312879,
            "fpr": 0.17324561403508773,
            "logloss": 0.6820619643064264,
            "mae": 0.3005952877845215,
            "precision": 0.7228070175438597,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8647930295762192,
            "auditor_fn_violation": 0.005690560283655371,
            "auditor_fp_violation": 0.023591566255897256,
            "ave_precision_score": 0.8649017187189478,
            "fpr": 0.17014270032930845,
            "logloss": 0.7180760734494933,
            "mae": 0.29221143868691724,
            "precision": 0.7266313932980599,
            "recall": 0.8619246861924686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8678628948683672,
            "auditor_fn_violation": 0.011287409700722395,
            "auditor_fp_violation": 0.00801746338322872,
            "ave_precision_score": 0.8680492510274196,
            "fpr": 0.13815789473684212,
            "logloss": 0.6046818288488484,
            "mae": 0.2792593215161779,
            "precision": 0.7553398058252427,
            "recall": 0.8172268907563025
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8637984447950917,
            "auditor_fn_violation": 0.010072153916106722,
            "auditor_fp_violation": 0.0190131900837341,
            "ave_precision_score": 0.8640733105210077,
            "fpr": 0.12403951701427003,
            "logloss": 0.6273887971239732,
            "mae": 0.2723562068481008,
            "precision": 0.7779960707269156,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8463809707544101,
            "auditor_fn_violation": 0.004855889724310778,
            "auditor_fp_violation": 0.011203826653790442,
            "ave_precision_score": 0.8000395755277362,
            "fpr": 0.13486842105263158,
            "logloss": 2.3437190708892266,
            "mae": 0.28168185932455553,
            "precision": 0.7525150905432596,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8435799025361258,
            "auditor_fn_violation": 0.00994814654915055,
            "auditor_fp_violation": 0.010018683628122284,
            "ave_precision_score": 0.7970389251118248,
            "fpr": 0.1163556531284303,
            "logloss": 2.390032392215336,
            "mae": 0.280364234819367,
            "precision": 0.774468085106383,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8193458450825292,
            "auditor_fn_violation": 0.007030443756449954,
            "auditor_fp_violation": 0.014485755673587635,
            "ave_precision_score": 0.8196933626874319,
            "fpr": 0.19078947368421054,
            "logloss": 0.930146615558826,
            "mae": 0.2830045286949155,
            "precision": 0.6947368421052632,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8237550055446772,
            "auditor_fn_violation": 0.013484652940122816,
            "auditor_fp_violation": 0.03054278855051044,
            "ave_precision_score": 0.8240747762336811,
            "fpr": 0.1800219538968167,
            "logloss": 0.9257392741038072,
            "mae": 0.27172105549439135,
            "precision": 0.7107583774250441,
            "recall": 0.8430962343096234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7046668637874498,
            "auditor_fn_violation": 0.005381099808344394,
            "auditor_fp_violation": 0.009154192821503305,
            "ave_precision_score": 0.7039752596464303,
            "fpr": 0.20285087719298245,
            "logloss": 1.473315067496583,
            "mae": 0.3215787612420588,
            "precision": 0.6666666666666666,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7154276411514697,
            "auditor_fn_violation": 0.016598615710355535,
            "auditor_fp_violation": 0.02520895495902024,
            "ave_precision_score": 0.7157913302893741,
            "fpr": 0.18331503841931943,
            "logloss": 1.3755885855766712,
            "mae": 0.3083902617711017,
            "precision": 0.6924493554327809,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8309520304669176,
            "auditor_fn_violation": 0.016673116615067082,
            "auditor_fp_violation": 0.009219579913085469,
            "ave_precision_score": 0.8313426337575794,
            "fpr": 0.1118421052631579,
            "logloss": 0.8109272645557529,
            "mae": 0.27242166746391006,
            "precision": 0.7723214285714286,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.829527695882172,
            "auditor_fn_violation": 0.019544938891925285,
            "auditor_fp_violation": 0.021560957554954463,
            "ave_precision_score": 0.8298069087623563,
            "fpr": 0.1119648737650933,
            "logloss": 0.8355698430687238,
            "mae": 0.2718899681364699,
            "precision": 0.7758241758241758,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8466872378029335,
            "auditor_fn_violation": 0.0067171605484298985,
            "auditor_fp_violation": 0.008543075004023818,
            "ave_precision_score": 0.8469350982933557,
            "fpr": 0.16337719298245615,
            "logloss": 0.7539703292004625,
            "mae": 0.2836199248020468,
            "precision": 0.7225325884543762,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.830167918607201,
            "auditor_fn_violation": 0.015523885196735395,
            "auditor_fp_violation": 0.03178498363598107,
            "ave_precision_score": 0.8304646926442213,
            "fpr": 0.16794731064763996,
            "logloss": 0.8423349004371299,
            "mae": 0.28220144407201614,
            "precision": 0.7156133828996283,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8270993987775228,
            "auditor_fn_violation": 0.009868421052631578,
            "auditor_fp_violation": 0.006478351842910029,
            "ave_precision_score": 0.827448562327362,
            "fpr": 0.12280701754385964,
            "logloss": 0.7403269998100068,
            "mae": 0.27680909624040206,
            "precision": 0.7611940298507462,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8267695229459695,
            "auditor_fn_violation": 0.012543115524344488,
            "auditor_fp_violation": 0.016967370830724308,
            "ave_precision_score": 0.8270794256937691,
            "fpr": 0.11745334796926454,
            "logloss": 0.7502814640611226,
            "mae": 0.27457577227531216,
            "precision": 0.7718550106609808,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8179607982175227,
            "auditor_fn_violation": 0.004406696889282033,
            "auditor_fp_violation": 0.014375100595525511,
            "ave_precision_score": 0.8183306687044729,
            "fpr": 0.15350877192982457,
            "logloss": 0.8171051369752121,
            "mae": 0.27722358409601844,
            "precision": 0.7292069632495164,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8187739042389587,
            "auditor_fn_violation": 0.0071212378690941516,
            "auditor_fp_violation": 0.023756347236622954,
            "ave_precision_score": 0.8191603304444557,
            "fpr": 0.1437980241492865,
            "logloss": 0.8097631976168305,
            "mae": 0.26662200905225075,
            "precision": 0.745136186770428,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7459621130138283,
            "auditor_fn_violation": 0.003800862450243254,
            "auditor_fp_violation": 0.0053894052792531864,
            "ave_precision_score": 0.7451603977262856,
            "fpr": 0.19846491228070176,
            "logloss": 1.4215746786324766,
            "mae": 0.2939838259529639,
            "precision": 0.6911262798634812,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7574250095998458,
            "auditor_fn_violation": 0.016621580037569642,
            "auditor_fp_violation": 0.030066191252411514,
            "ave_precision_score": 0.7575229472262551,
            "fpr": 0.19319429198682767,
            "logloss": 1.3879096257655559,
            "mae": 0.2824624691079592,
            "precision": 0.6996587030716723,
            "recall": 0.8577405857740585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.820426438135101,
            "auditor_fn_violation": 0.007532618310482088,
            "auditor_fp_violation": 0.011327056172541443,
            "ave_precision_score": 0.8217611727912046,
            "fpr": 0.15460526315789475,
            "logloss": 0.8154984878798786,
            "mae": 0.27194286760786957,
            "precision": 0.7298850574712644,
            "recall": 0.8004201680672269
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8305901384746074,
            "auditor_fn_violation": 0.017425331490063336,
            "auditor_fp_violation": 0.027059572127170355,
            "ave_precision_score": 0.8308691439011175,
            "fpr": 0.16136114160263446,
            "logloss": 0.8234683734218056,
            "mae": 0.2694306791744667,
            "precision": 0.7272727272727273,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.857248816127659,
            "auditor_fn_violation": 0.005671347486362968,
            "auditor_fp_violation": 0.013464711089650735,
            "ave_precision_score": 0.8584926475240706,
            "fpr": 0.12828947368421054,
            "logloss": 0.5682758192486665,
            "mae": 0.28852243737990074,
            "precision": 0.7641129032258065,
            "recall": 0.7962184873949579
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8670727561770166,
            "auditor_fn_violation": 0.012065457518291096,
            "auditor_fp_violation": 0.01546913145212606,
            "ave_precision_score": 0.8672810141017778,
            "fpr": 0.09879253567508232,
            "logloss": 0.5358778162178288,
            "mae": 0.2818764502532871,
            "precision": 0.8081023454157783,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8448192452758381,
            "auditor_fn_violation": 0.01253132832080201,
            "auditor_fp_violation": 0.0037421535490101414,
            "ave_precision_score": 0.8452097357869846,
            "fpr": 0.08662280701754387,
            "logloss": 0.6856528354611799,
            "mae": 0.28496478051549384,
            "precision": 0.8034825870646766,
            "recall": 0.6785714285714286
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8519651932190024,
            "auditor_fn_violation": 0.018210711480785752,
            "auditor_fp_violation": 0.017337494264354325,
            "ave_precision_score": 0.8522010343848256,
            "fpr": 0.07793633369923161,
            "logloss": 0.6553162277606215,
            "mae": 0.2837545456561838,
            "precision": 0.8165374677002584,
            "recall": 0.6610878661087866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8386586061279051,
            "auditor_fn_violation": 0.006772445820433441,
            "auditor_fp_violation": 0.008691453404152588,
            "ave_precision_score": 0.8391346704889955,
            "fpr": 0.14692982456140352,
            "logloss": 0.7599359867226861,
            "mae": 0.2725531993420158,
            "precision": 0.7413127413127413,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8465641586585227,
            "auditor_fn_violation": 0.019023648664165095,
            "auditor_fp_violation": 0.021307448353838007,
            "ave_precision_score": 0.8467938732573692,
            "fpr": 0.13611416026344675,
            "logloss": 0.7801512589937649,
            "mae": 0.2684734492183713,
            "precision": 0.7578125,
            "recall": 0.8117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8263484676136226,
            "auditor_fn_violation": 0.0045172674332891035,
            "auditor_fp_violation": 0.017111298889425402,
            "ave_precision_score": 0.8267311477410315,
            "fpr": 0.16228070175438597,
            "logloss": 0.8107844824333642,
            "mae": 0.27780468995033264,
            "precision": 0.7212806026365348,
            "recall": 0.8046218487394958
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8293904003061213,
            "auditor_fn_violation": 0.013751039135806442,
            "auditor_fp_violation": 0.027513353597168812,
            "ave_precision_score": 0.8296953045057842,
            "fpr": 0.1602634467618002,
            "logloss": 0.8152746314926644,
            "mae": 0.27099271097589195,
            "precision": 0.7296296296296296,
            "recall": 0.8242677824267782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.776220010842722,
            "auditor_fn_violation": 0.009905277900633945,
            "auditor_fp_violation": 0.014075828907130215,
            "ave_precision_score": 0.7766502254054807,
            "fpr": 0.15899122807017543,
            "logloss": 0.6235854450818413,
            "mae": 0.34260064270557977,
            "precision": 0.7064777327935222,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7883122533289776,
            "auditor_fn_violation": 0.010209939879391363,
            "auditor_fp_violation": 0.0231808813500886,
            "ave_precision_score": 0.7888177969365269,
            "fpr": 0.12623490669593854,
            "logloss": 0.5858543222147117,
            "mae": 0.33026293997407985,
            "precision": 0.7553191489361702,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8275837970221631,
            "auditor_fn_violation": 0.004554124281291465,
            "auditor_fp_violation": 0.01614055206824401,
            "ave_precision_score": 0.8278769569466602,
            "fpr": 0.15570175438596492,
            "logloss": 0.7723331189531023,
            "mae": 0.280022878587728,
            "precision": 0.7295238095238096,
            "recall": 0.8046218487394958
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8257922238745348,
            "auditor_fn_violation": 0.011264002498518803,
            "auditor_fp_violation": 0.029526216654033457,
            "ave_precision_score": 0.8261094839867306,
            "fpr": 0.16136114160263446,
            "logloss": 0.7820359634560606,
            "mae": 0.27457957778866343,
            "precision": 0.7247191011235955,
            "recall": 0.8096234309623431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8446906063525977,
            "auditor_fn_violation": 0.006258753501400561,
            "auditor_fp_violation": 0.012109186383389673,
            "ave_precision_score": 0.8449244839818673,
            "fpr": 0.13048245614035087,
            "logloss": 0.6002933511349251,
            "mae": 0.279125902987672,
            "precision": 0.7531120331950207,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.847260693772109,
            "auditor_fn_violation": 0.009314331118041237,
            "auditor_fp_violation": 0.028086284391691998,
            "ave_precision_score": 0.8475301098879485,
            "fpr": 0.1350164654226125,
            "logloss": 0.5765745245782616,
            "mae": 0.27439452908397827,
            "precision": 0.7505070993914807,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8430275549653983,
            "auditor_fn_violation": 0.010186311366651924,
            "auditor_fp_violation": 0.010922159182359581,
            "ave_precision_score": 0.8434314314095206,
            "fpr": 0.12609649122807018,
            "logloss": 0.6514563804831894,
            "mae": 0.3210841832986804,
            "precision": 0.7704590818363274,
            "recall": 0.8109243697478992
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.85303996151846,
            "auditor_fn_violation": 0.005929389286682068,
            "auditor_fp_violation": 0.012348433186382497,
            "ave_precision_score": 0.8531395431101358,
            "fpr": 0.10757409440175632,
            "logloss": 0.7007876997233282,
            "mae": 0.31017787438411143,
            "precision": 0.7919320594479831,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7496737820818695,
            "auditor_fn_violation": 0.006827731092436976,
            "auditor_fp_violation": 0.00919443103170772,
            "ave_precision_score": 0.7488656684715184,
            "fpr": 0.2324561403508772,
            "logloss": 1.5055985944092252,
            "mae": 0.2997352991910702,
            "precision": 0.6692667706708268,
            "recall": 0.9012605042016807
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7600997902962268,
            "auditor_fn_violation": 0.013085073646597377,
            "auditor_fp_violation": 0.033341530130836114,
            "ave_precision_score": 0.7601933564152483,
            "fpr": 0.21405049396267836,
            "logloss": 1.4611047109270299,
            "mae": 0.2869033652042311,
            "precision": 0.6839546191247974,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7840653998078332,
            "auditor_fn_violation": 0.006915266106442591,
            "auditor_fp_violation": 0.007605021728633514,
            "ave_precision_score": 0.785183686784244,
            "fpr": 0.1513157894736842,
            "logloss": 1.0960954060937256,
            "mae": 0.3038512861004442,
            "precision": 0.7142857142857143,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7935234259136785,
            "auditor_fn_violation": 0.018431169022041168,
            "auditor_fp_violation": 0.030086471988500823,
            "ave_precision_score": 0.7938841129566049,
            "fpr": 0.15697036223929747,
            "logloss": 1.1240692036036095,
            "mae": 0.2997801161023559,
            "precision": 0.7145708582834331,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7664947671062987,
            "auditor_fn_violation": 0.005406438891346016,
            "auditor_fp_violation": 0.014407794141316602,
            "ave_precision_score": 0.7674867401264874,
            "fpr": 0.18311403508771928,
            "logloss": 0.6212463236927904,
            "mae": 0.34786512142684506,
            "precision": 0.6996402877697842,
            "recall": 0.8172268907563025
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8057914684156087,
            "auditor_fn_violation": 0.011789885591721823,
            "auditor_fp_violation": 0.011889581532361714,
            "ave_precision_score": 0.8066260371399474,
            "fpr": 0.16245883644346873,
            "logloss": 0.568257716538895,
            "mae": 0.3371595455564632,
            "precision": 0.725925925925926,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8138490430356417,
            "auditor_fn_violation": 0.012204223794781074,
            "auditor_fp_violation": 0.012333011427651698,
            "ave_precision_score": 0.8141446135889623,
            "fpr": 0.13925438596491227,
            "logloss": 0.9430137951605128,
            "mae": 0.2826373989903499,
            "precision": 0.7402862985685071,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8244384329211959,
            "auditor_fn_violation": 0.01434351877793036,
            "auditor_fp_violation": 0.02323665337433423,
            "ave_precision_score": 0.8245914917614475,
            "fpr": 0.13391877058177826,
            "logloss": 0.9754935327506804,
            "mae": 0.27260239408288944,
            "precision": 0.7550200803212851,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8349442850301754,
            "auditor_fn_violation": 0.01258661359280555,
            "auditor_fp_violation": 0.006981329470465154,
            "ave_precision_score": 0.8356892183427325,
            "fpr": 0.09210526315789473,
            "logloss": 0.8296815612337411,
            "mae": 0.2766710584676046,
            "precision": 0.7941176470588235,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8306244338889449,
            "auditor_fn_violation": 0.0223534761102104,
            "auditor_fp_violation": 0.01846054002530022,
            "ave_precision_score": 0.8309033695640831,
            "fpr": 0.09879253567508232,
            "logloss": 0.8768117491361231,
            "mae": 0.27796900929059454,
            "precision": 0.7872340425531915,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8189086576539725,
            "auditor_fn_violation": 0.0010642414860681153,
            "auditor_fp_violation": 0.011259154192821513,
            "ave_precision_score": 0.8192778049859069,
            "fpr": 0.1524122807017544,
            "logloss": 0.8101980074785161,
            "mae": 0.27618368630887463,
            "precision": 0.7311411992263056,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8205543481755614,
            "auditor_fn_violation": 0.0076471209622971745,
            "auditor_fp_violation": 0.024192383062543264,
            "ave_precision_score": 0.820843712913648,
            "fpr": 0.14270032930845225,
            "logloss": 0.801284936063958,
            "mae": 0.26590492886253125,
            "precision": 0.7470817120622568,
            "recall": 0.803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 15860,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8062786626446719,
            "auditor_fn_violation": 0.005307386112339679,
            "auditor_fp_violation": 0.01438516014807662,
            "ave_precision_score": 0.8068521981078428,
            "fpr": 0.14035087719298245,
            "logloss": 0.894433697866812,
            "mae": 0.2860448661838387,
            "precision": 0.7371663244353183,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8202676826238064,
            "auditor_fn_violation": 0.014591533511842706,
            "auditor_fp_violation": 0.01942641008155391,
            "ave_precision_score": 0.820571477317303,
            "fpr": 0.13611416026344675,
            "logloss": 0.864147644852244,
            "mae": 0.2779198021680551,
            "precision": 0.7427385892116183,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7132941941911937,
            "auditor_fn_violation": 0.017778822055137863,
            "auditor_fp_violation": 0.011950748430709804,
            "ave_precision_score": 0.7146519920353391,
            "fpr": 0.09539473684210527,
            "logloss": 4.128665237582829,
            "mae": 0.3884465491028377,
            "precision": 0.7255520504731862,
            "recall": 0.4831932773109244
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7033845651083088,
            "auditor_fn_violation": 0.005665299523719858,
            "auditor_fp_violation": 0.018379417080942952,
            "ave_precision_score": 0.7050693994507711,
            "fpr": 0.08122941822173436,
            "logloss": 4.224764390339898,
            "mae": 0.388920521273507,
            "precision": 0.7508417508417509,
            "recall": 0.4665271966527197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6240291604409699,
            "auditor_fn_violation": 0.00783668730650156,
            "auditor_fp_violation": 0.007592447287944633,
            "ave_precision_score": 0.6343781825606485,
            "fpr": 0.04057017543859649,
            "logloss": 8.536770906473608,
            "mae": 0.44599939424612406,
            "precision": 0.7823529411764706,
            "recall": 0.27941176470588236
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6164869648402771,
            "auditor_fn_violation": 0.005084302045202988,
            "auditor_fp_violation": 0.006994318858802981,
            "ave_precision_score": 0.6305442169146513,
            "fpr": 0.050493962678375415,
            "logloss": 8.66031231753513,
            "mae": 0.4487155788936543,
            "precision": 0.7386363636363636,
            "recall": 0.2719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8512998297955434,
            "auditor_fn_violation": 0.011577657378740972,
            "auditor_fp_violation": 0.015622485111862228,
            "ave_precision_score": 0.851530729357227,
            "fpr": 0.18201754385964913,
            "logloss": 0.7342907961520873,
            "mae": 0.2799701040140557,
            "precision": 0.7097902097902098,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8380040016471891,
            "auditor_fn_violation": 0.013346866976838182,
            "auditor_fp_violation": 0.03245424792692851,
            "ave_precision_score": 0.8382749977374189,
            "fpr": 0.17014270032930845,
            "logloss": 0.8035362657120633,
            "mae": 0.2782673476536789,
            "precision": 0.7275922671353251,
            "recall": 0.8661087866108786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8114764359754276,
            "auditor_fn_violation": 0.003639613740232942,
            "auditor_fp_violation": 0.014888137775631746,
            "ave_precision_score": 0.8123783402782949,
            "fpr": 0.13596491228070176,
            "logloss": 0.952660209214443,
            "mae": 0.28432917637614585,
            "precision": 0.7453798767967146,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8286617105168428,
            "auditor_fn_violation": 0.016442458285299617,
            "auditor_fp_violation": 0.019314866033062678,
            "ave_precision_score": 0.8289291691334175,
            "fpr": 0.13172338090010977,
            "logloss": 0.9787922032450861,
            "mae": 0.2749481167398353,
            "precision": 0.7510373443983402,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7855783065424904,
            "auditor_fn_violation": 0.0029692798171900357,
            "auditor_fp_violation": 0.021396668276195085,
            "ave_precision_score": 0.7851761625127603,
            "fpr": 0.2532894736842105,
            "logloss": 1.0188709026948002,
            "mae": 0.33816443174044,
            "precision": 0.65,
            "recall": 0.9012605042016807
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7944525463605497,
            "auditor_fn_violation": 0.003371163235030703,
            "auditor_fp_violation": 0.019271769468872876,
            "ave_precision_score": 0.7948759027410452,
            "fpr": 0.24259055982436883,
            "logloss": 0.9682463591948706,
            "mae": 0.32651630382776325,
            "precision": 0.6646433990895296,
            "recall": 0.9163179916317992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8343915953689369,
            "auditor_fn_violation": 0.007698474126492706,
            "auditor_fp_violation": 0.01000673990020924,
            "ave_precision_score": 0.8348864958490444,
            "fpr": 0.12609649122807018,
            "logloss": 0.8176199608766346,
            "mae": 0.2727288132572617,
            "precision": 0.7604166666666666,
            "recall": 0.7668067226890757
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8391968644306478,
            "auditor_fn_violation": 0.015239127539280486,
            "auditor_fp_violation": 0.022341765894393146,
            "ave_precision_score": 0.8394609608988055,
            "fpr": 0.12623490669593854,
            "logloss": 0.8596489929674465,
            "mae": 0.2665603910490769,
            "precision": 0.7604166666666666,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8676953199105237,
            "auditor_fn_violation": 0.010483469703670941,
            "auditor_fp_violation": 0.014536053436343156,
            "ave_precision_score": 0.8679065382960098,
            "fpr": 0.14912280701754385,
            "logloss": 0.5974800575390854,
            "mae": 0.2808024759460466,
            "precision": 0.743879472693032,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8638558234980971,
            "auditor_fn_violation": 0.010237497072048282,
            "auditor_fp_violation": 0.022704284051989668,
            "ave_precision_score": 0.8641361651205861,
            "fpr": 0.13611416026344675,
            "logloss": 0.6388086929143572,
            "mae": 0.27516329238918225,
            "precision": 0.762906309751434,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7289392414944474,
            "auditor_fn_violation": 0.0028379772961816385,
            "auditor_fp_violation": 0.008062731369708672,
            "ave_precision_score": 0.7283016822087307,
            "fpr": 0.21710526315789475,
            "logloss": 1.448537370775506,
            "mae": 0.3091186836564426,
            "precision": 0.6666666666666666,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7375058859911956,
            "auditor_fn_violation": 0.013695924750492583,
            "auditor_fp_violation": 0.03152386915883112,
            "ave_precision_score": 0.7377633206598339,
            "fpr": 0.2074643249176729,
            "logloss": 1.3535720451472617,
            "mae": 0.29754550428726606,
            "precision": 0.6802030456852792,
            "recall": 0.8410041841004184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8674578110185487,
            "auditor_fn_violation": 0.013609391124871004,
            "auditor_fp_violation": 0.00781627233220667,
            "ave_precision_score": 0.8676441044432447,
            "fpr": 0.14912280701754385,
            "logloss": 0.6172297608752991,
            "mae": 0.28865485955356307,
            "precision": 0.7443609022556391,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8552654624608509,
            "auditor_fn_violation": 0.010446472449696641,
            "auditor_fp_violation": 0.029914085731741636,
            "ave_precision_score": 0.8555759995095473,
            "fpr": 0.1525795828759605,
            "logloss": 0.6803576240476649,
            "mae": 0.28655738937417286,
            "precision": 0.7406716417910447,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7297172129062688,
            "auditor_fn_violation": 0.004137181188264783,
            "auditor_fp_violation": 0.006438113632705627,
            "ave_precision_score": 0.7290983040832332,
            "fpr": 0.2236842105263158,
            "logloss": 1.4587647705583742,
            "mae": 0.30957105818015007,
            "precision": 0.6622516556291391,
            "recall": 0.8403361344537815
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7389595863975034,
            "auditor_fn_violation": 0.013553545921765131,
            "auditor_fp_violation": 0.029800006591239225,
            "ave_precision_score": 0.7391915637868572,
            "fpr": 0.20856201975850713,
            "logloss": 1.357028177482963,
            "mae": 0.29726714029022994,
            "precision": 0.680672268907563,
            "recall": 0.8472803347280334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7321862822555969,
            "auditor_fn_violation": 0.0048374613003096005,
            "auditor_fp_violation": 0.009780399967809444,
            "ave_precision_score": 0.7314515970913066,
            "fpr": 0.23135964912280702,
            "logloss": 1.5621318092650036,
            "mae": 0.30870005355267804,
            "precision": 0.6613162118780096,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7433544250737972,
            "auditor_fn_violation": 0.013094259377483021,
            "auditor_fp_violation": 0.0313616232701166,
            "ave_precision_score": 0.7434959348526581,
            "fpr": 0.21734357848518113,
            "logloss": 1.5065462004149006,
            "mae": 0.29524237714975426,
            "precision": 0.6775244299674267,
            "recall": 0.8702928870292888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8194920342059311,
            "auditor_fn_violation": 0.007012015332448771,
            "auditor_fp_violation": 0.011852667793336552,
            "ave_precision_score": 0.8198051077497477,
            "fpr": 0.18530701754385964,
            "logloss": 0.9374196651581701,
            "mae": 0.2832536136117528,
            "precision": 0.7040280210157618,
            "recall": 0.8445378151260504
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8138935250021433,
            "auditor_fn_violation": 0.01210220044183366,
            "auditor_fp_violation": 0.03082418376374972,
            "ave_precision_score": 0.8142276987795372,
            "fpr": 0.18990120746432493,
            "logloss": 1.036240834563896,
            "mae": 0.28229096961007216,
            "precision": 0.7001733102253033,
            "recall": 0.8451882845188284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8557234504192335,
            "auditor_fn_violation": 0.009831564204629226,
            "auditor_fp_violation": 0.009863391276356038,
            "ave_precision_score": 0.8559415041851459,
            "fpr": 0.13925438596491227,
            "logloss": 0.7102188316928818,
            "mae": 0.2721308187462124,
            "precision": 0.7475149105367793,
            "recall": 0.7899159663865546
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8519785572199873,
            "auditor_fn_violation": 0.015941835952032114,
            "auditor_fp_violation": 0.02880371543085156,
            "ave_precision_score": 0.8522028014794548,
            "fpr": 0.14270032930845225,
            "logloss": 0.7795237461458635,
            "mae": 0.2684162737800916,
            "precision": 0.7470817120622568,
            "recall": 0.803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 15860,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6372909825474606,
            "auditor_fn_violation": 0.00515995872033024,
            "auditor_fp_violation": 0.005210848221471114,
            "ave_precision_score": 0.6306651112530557,
            "fpr": 0.32894736842105265,
            "logloss": 2.0920077729040023,
            "mae": 0.38477214611518273,
            "precision": 0.5912806539509536,
            "recall": 0.9117647058823529
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6624551978649547,
            "auditor_fn_violation": 0.004689315617120367,
            "auditor_fp_violation": 0.0060816857347837485,
            "ave_precision_score": 0.6571707378988043,
            "fpr": 0.3194291986827662,
            "logloss": 1.936732745531489,
            "mae": 0.37124494540809894,
            "precision": 0.6040816326530613,
            "recall": 0.9288702928870293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8200995313632226,
            "auditor_fn_violation": 0.007417440660474716,
            "auditor_fp_violation": 0.014078343795267992,
            "ave_precision_score": 0.8204659169289201,
            "fpr": 0.15899122807017543,
            "logloss": 0.782823016350771,
            "mae": 0.2760614717206253,
            "precision": 0.7279549718574109,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8211713948575593,
            "auditor_fn_violation": 0.008841265977430663,
            "auditor_fp_violation": 0.026075956426838513,
            "ave_precision_score": 0.8215450135711032,
            "fpr": 0.14818880351262348,
            "logloss": 0.7736697531415069,
            "mae": 0.2659930335152166,
            "precision": 0.7448015122873346,
            "recall": 0.8242677824267782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 15860,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7781223041354159,
            "auditor_fn_violation": 0.013922674332891056,
            "auditor_fp_violation": 0.011729438274585549,
            "ave_precision_score": 0.7785542215370017,
            "fpr": 0.15789473684210525,
            "logloss": 0.6178098730872416,
            "mae": 0.3418341291168569,
            "precision": 0.7096774193548387,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7887845124741224,
            "auditor_fn_violation": 0.012910544759770177,
            "auditor_fp_violation": 0.024765313857066443,
            "ave_precision_score": 0.7892936708851447,
            "fpr": 0.12733260153677278,
            "logloss": 0.5818353062630044,
            "mae": 0.32974572833130367,
            "precision": 0.7552742616033755,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6911294792852031,
            "auditor_fn_violation": 0.005758882500368571,
            "auditor_fp_violation": 0.007783578786415583,
            "ave_precision_score": 0.6921216857086471,
            "fpr": 0.17214912280701755,
            "logloss": 0.7067558227290178,
            "mae": 0.39230547543066724,
            "precision": 0.6680761099365751,
            "recall": 0.6638655462184874
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7050300224881086,
            "auditor_fn_violation": 0.0030955913084614373,
            "auditor_fp_violation": 0.02106661461277737,
            "ave_precision_score": 0.7058846970361327,
            "fpr": 0.14818880351262348,
            "logloss": 0.6759896524788324,
            "mae": 0.3838831142082291,
            "precision": 0.7071583514099783,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 15860,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.793022706668662,
            "auditor_fn_violation": 0.005196815568332597,
            "auditor_fp_violation": 0.0196412763560277,
            "ave_precision_score": 0.7927815374734907,
            "fpr": 0.24451754385964913,
            "logloss": 1.0025565499287443,
            "mae": 0.3290450197640447,
            "precision": 0.6590214067278287,
            "recall": 0.9054621848739496
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8019795587433214,
            "auditor_fn_violation": 0.006168218289708768,
            "auditor_fp_violation": 0.023533259139640484,
            "ave_precision_score": 0.8022635474550347,
            "fpr": 0.23380900109769484,
            "logloss": 0.9484823839616413,
            "mae": 0.3178188675395024,
            "precision": 0.6707882534775889,
            "recall": 0.9079497907949791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6341378590364575,
            "auditor_fn_violation": 0.0034645437122217313,
            "auditor_fp_violation": 0.00914916304522775,
            "ave_precision_score": 0.6443704969949302,
            "fpr": 0.05482456140350877,
            "logloss": 8.515689978413045,
            "mae": 0.44100981853305454,
            "precision": 0.7448979591836735,
            "recall": 0.3067226890756303
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6281383348536232,
            "auditor_fn_violation": 0.007885949965323873,
            "auditor_fp_violation": 0.008393689648965811,
            "ave_precision_score": 0.6411497719262731,
            "fpr": 0.06256860592755215,
            "logloss": 8.647513101293283,
            "mae": 0.44634264372383514,
            "precision": 0.7259615384615384,
            "recall": 0.3158995815899582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8320372956181091,
            "auditor_fn_violation": 0.007574082264484742,
            "auditor_fp_violation": 0.011108260904554973,
            "ave_precision_score": 0.8323346307741444,
            "fpr": 0.20723684210526316,
            "logloss": 1.0258543794024457,
            "mae": 0.28333785970767256,
            "precision": 0.6870860927152318,
            "recall": 0.8718487394957983
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8289547704703452,
            "auditor_fn_violation": 0.014766062398669904,
            "auditor_fp_violation": 0.03316153859804342,
            "ave_precision_score": 0.8292746354737686,
            "fpr": 0.19099890230515917,
            "logloss": 1.0849608099018209,
            "mae": 0.2718485753784049,
            "precision": 0.7030716723549488,
            "recall": 0.8619246861924686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8292081777290697,
            "auditor_fn_violation": 0.0011817226890756334,
            "auditor_fp_violation": 0.02221400692097216,
            "ave_precision_score": 0.8296643496521292,
            "fpr": 0.18092105263157895,
            "logloss": 0.6967059148528141,
            "mae": 0.3208106011963473,
            "precision": 0.7125435540069687,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8419860419441241,
            "auditor_fn_violation": 0.011312227585668425,
            "auditor_fp_violation": 0.019000514623678275,
            "ave_precision_score": 0.8422427535729657,
            "fpr": 0.18221734357848518,
            "logloss": 0.7487728715989135,
            "mae": 0.31949444257358595,
            "precision": 0.7118055555555556,
            "recall": 0.8577405857740585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8191730348989508,
            "auditor_fn_violation": 0.006118236768391566,
            "auditor_fp_violation": 0.014284564622565596,
            "ave_precision_score": 0.8199105482566342,
            "fpr": 0.14473684210526316,
            "logloss": 0.6756409952316194,
            "mae": 0.3351128018346795,
            "precision": 0.736,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.840681359216387,
            "auditor_fn_violation": 0.006250889867679553,
            "auditor_fp_violation": 0.009095910136058385,
            "ave_precision_score": 0.8408115056226285,
            "fpr": 0.1141602634467618,
            "logloss": 0.722836018614226,
            "mae": 0.321797937598799,
            "precision": 0.7777777777777778,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8106616891702197,
            "auditor_fn_violation": 0.010734556980687015,
            "auditor_fp_violation": 0.014795086914534043,
            "ave_precision_score": 0.8112180720556137,
            "fpr": 0.13706140350877194,
            "logloss": 0.9489602217427203,
            "mae": 0.28340344054743927,
            "precision": 0.7422680412371134,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8239901755170203,
            "auditor_fn_violation": 0.0166353586338981,
            "auditor_fp_violation": 0.019804138791217427,
            "ave_precision_score": 0.8243036371869619,
            "fpr": 0.13062568605927552,
            "logloss": 0.9781501798339863,
            "mae": 0.2742256361880019,
            "precision": 0.7541322314049587,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8290445046962439,
            "auditor_fn_violation": 0.006099808344390388,
            "auditor_fp_violation": 0.018036777724126835,
            "ave_precision_score": 0.8293594414503254,
            "fpr": 0.16337719298245615,
            "logloss": 0.7272749260532153,
            "mae": 0.27768002225691163,
            "precision": 0.7204502814258912,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8338674649640015,
            "auditor_fn_violation": 0.014182768487431628,
            "auditor_fp_violation": 0.02555626256454978,
            "ave_precision_score": 0.8341566154389801,
            "fpr": 0.15916575192096596,
            "logloss": 0.7330890781512538,
            "mae": 0.27044078160502766,
            "precision": 0.7309833024118738,
            "recall": 0.8242677824267782
        }
    }
]