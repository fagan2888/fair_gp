[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5737318540444009,
            "auditor_fn_violation": 0.09488110551327403,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.5752394888710323,
            "fpr": 0.2905701754385965,
            "logloss": 0.7002941740858446,
            "mae": 0.48219182303077296,
            "precision": 0.5655737704918032,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5917164276012328,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.09804277089540538,
            "ave_precision_score": 0.5932966471323038,
            "fpr": 0.2711306256860593,
            "logloss": 0.6812477014155047,
            "mae": 0.4722335369179984,
            "precision": 0.5834738617200674,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5598447720760081,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5485688549003334,
            "fpr": 0.05592105263157895,
            "logloss": 0.6937936060426629,
            "mae": 0.5002560060340584,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5200051857053614,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.5155112724097077,
            "fpr": 0.05598243688254665,
            "logloss": 0.6934358870772082,
            "mae": 0.5000787739827002,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5798673596332194,
            "auditor_fn_violation": 0.00340336584842963,
            "auditor_fp_violation": 0.005281910238779848,
            "ave_precision_score": 0.5725047945188055,
            "fpr": 0.025219298245614034,
            "logloss": 2.226033981341854,
            "mae": 0.5018496189632539,
            "precision": 0.5964912280701754,
            "recall": 0.06924643584521385
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.519371536796228,
            "auditor_fn_violation": 0.00437892520738848,
            "auditor_fp_violation": 0.0018597106790026656,
            "ave_precision_score": 0.5165439271230643,
            "fpr": 0.020856201975850714,
            "logloss": 2.318183327643224,
            "mae": 0.5086697429860328,
            "precision": 0.5581395348837209,
            "recall": 0.05183585313174946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8700470718010915,
            "auditor_fn_violation": 0.012322685532568692,
            "auditor_fp_violation": 0.021447993499187405,
            "ave_precision_score": 0.8703144862102541,
            "fpr": 0.19298245614035087,
            "logloss": 0.5034766937364243,
            "mae": 0.320712092753271,
            "precision": 0.7114754098360656,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8728322194897136,
            "auditor_fn_violation": 0.015434111044991263,
            "auditor_fp_violation": 0.02401207464324918,
            "ave_precision_score": 0.8730302423300341,
            "fpr": 0.18441273326015367,
            "logloss": 0.4993784498716476,
            "mae": 0.31598104995958565,
            "precision": 0.7133105802047781,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.7244913846599491,
            "auditor_fn_violation": 0.010884517811841223,
            "auditor_fp_violation": 0.005107409259490771,
            "ave_precision_score": 0.725703494337757,
            "fpr": 0.03508771929824561,
            "logloss": 0.6895557795193962,
            "mae": 0.4975448042938584,
            "precision": 0.6631578947368421,
            "recall": 0.12830957230142567
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6575907045164144,
            "auditor_fn_violation": 0.011844672623775176,
            "auditor_fp_violation": 0.004978830170926768,
            "ave_precision_score": 0.6585061084491173,
            "fpr": 0.052689352360043906,
            "logloss": 0.6941896898235714,
            "mae": 0.49984942456762566,
            "precision": 0.5051546391752577,
            "recall": 0.10583153347732181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.7647935803818959,
            "auditor_fn_violation": 0.0018691714010076262,
            "auditor_fp_violation": 0.0006980039171563112,
            "ave_precision_score": 0.7665972636306988,
            "fpr": 0.005482456140350877,
            "logloss": 0.6933955601989487,
            "mae": 0.500112139374802,
            "precision": 0.375,
            "recall": 0.006109979633401222
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.7158776192295484,
            "auditor_fn_violation": 0.001728335937296267,
            "auditor_fp_violation": 0.00485141916261565,
            "ave_precision_score": 0.717498099148641,
            "fpr": 0.009879253567508232,
            "logloss": 0.6935047683439689,
            "mae": 0.5001624652504528,
            "precision": 0.25,
            "recall": 0.0064794816414686825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5448910316853455,
            "auditor_fn_violation": 0.004316736341873015,
            "auditor_fp_violation": 0.010264303871317257,
            "ave_precision_score": 0.5375119341685002,
            "fpr": 0.35635964912280704,
            "logloss": 0.6917296964131955,
            "mae": 0.4985894398404318,
            "precision": 0.5357142857142857,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.4984257764803935,
            "auditor_fn_violation": 0.005381786800634436,
            "auditor_fp_violation": 0.009291202759918455,
            "ave_precision_score": 0.498159053191091,
            "fpr": 0.38199780461031835,
            "logloss": 0.6945189283133226,
            "mae": 0.4999650317999717,
            "precision": 0.5070821529745042,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5244151706776434,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5258625959317833,
            "fpr": 0.05592105263157895,
            "logloss": 0.6939229130483491,
            "mae": 0.5003419413247652,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.48588978872194577,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.4894794957061269,
            "fpr": 0.05598243688254665,
            "logloss": 0.6934558212626676,
            "mae": 0.5001086468361604,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5656521209560783,
            "auditor_fn_violation": 0.004370332654446717,
            "auditor_fp_violation": 0.0008490644663916324,
            "ave_precision_score": 0.5668776482587607,
            "fpr": 0.003289473684210526,
            "logloss": 0.9759711684857116,
            "mae": 0.506434601249598,
            "precision": 0.75,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5470530560165553,
            "auditor_fn_violation": 0.004144212919607501,
            "auditor_fp_violation": 0.0011025952642308295,
            "ave_precision_score": 0.5479711415771227,
            "fpr": 0.0021953896816684962,
            "logloss": 0.9610992842706831,
            "mae": 0.4952454862279897,
            "precision": 0.8823529411764706,
            "recall": 0.032397408207343416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7991602544772349,
            "auditor_fn_violation": 0.01787660342301783,
            "auditor_fp_violation": 0.005951264741426016,
            "ave_precision_score": 0.7996622282089069,
            "fpr": 0.13048245614035087,
            "logloss": 0.5653082730829323,
            "mae": 0.38812427845244346,
            "precision": 0.7586206896551724,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7494804322809308,
            "auditor_fn_violation": 0.021873288556234938,
            "auditor_fp_violation": 0.015504939626783754,
            "ave_precision_score": 0.7513752572760211,
            "fpr": 0.15367727771679474,
            "logloss": 0.5900052426341382,
            "mae": 0.39543208002258995,
            "precision": 0.7137014314928425,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5636683855906387,
            "auditor_fn_violation": 0.004370332654446717,
            "auditor_fp_violation": 0.0008490644663916324,
            "ave_precision_score": 0.5650184354251787,
            "fpr": 0.003289473684210526,
            "logloss": 0.9862351422246304,
            "mae": 0.5074508794861143,
            "precision": 0.75,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5384788604144182,
            "auditor_fn_violation": 0.004144212919607501,
            "auditor_fp_violation": 0.0016318409910616278,
            "ave_precision_score": 0.5404914797036315,
            "fpr": 0.003293084522502744,
            "logloss": 0.9744546720819145,
            "mae": 0.49688099184851486,
            "precision": 0.8333333333333334,
            "recall": 0.032397408207343416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6453408022106835,
            "auditor_fn_violation": 0.010344088326723122,
            "auditor_fp_violation": 0.01272294453473351,
            "ave_precision_score": 0.6345510478991969,
            "fpr": 0.06140350877192982,
            "logloss": 0.6623335497104711,
            "mae": 0.46655261431608286,
            "precision": 0.6836158192090396,
            "recall": 0.24643584521384929
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6459735424410507,
            "auditor_fn_violation": 0.01088211516075422,
            "auditor_fp_violation": 0.006284793006115732,
            "ave_precision_score": 0.6333799036881391,
            "fpr": 0.05817782656421515,
            "logloss": 0.6474048271747419,
            "mae": 0.4605716422412843,
            "precision": 0.6900584795321637,
            "recall": 0.2548596112311015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.40819408184802475,
            "auditor_fn_violation": 0.0005694608210955177,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.40979957244289666,
            "fpr": 0.0,
            "logloss": 0.6944476012747031,
            "mae": 0.5005891929266223,
            "precision": 1.0,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.69351283319251,
            "mae": 0.5001217510906978,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7995400607844023,
            "auditor_fn_violation": 0.016128023725301036,
            "auditor_fp_violation": 0.008152060674250953,
            "ave_precision_score": 0.8000396887756132,
            "fpr": 0.14035087719298245,
            "logloss": 0.5648848039943422,
            "mae": 0.38909163464089497,
            "precision": 0.7465346534653465,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7478375379848119,
            "auditor_fn_violation": 0.019718203004791452,
            "auditor_fp_violation": 0.008048945428885065,
            "ave_precision_score": 0.7497352212284036,
            "fpr": 0.16794731064763996,
            "logloss": 0.5907129699366781,
            "mae": 0.3969259723759247,
            "precision": 0.697029702970297,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7225938806690915,
            "auditor_fn_violation": 0.0009714331653982214,
            "auditor_fp_violation": 0.0003854648497728885,
            "ave_precision_score": 0.7241759703330457,
            "fpr": 0.005482456140350877,
            "logloss": 0.8040849708963755,
            "mae": 0.4442746956881724,
            "precision": 0.95,
            "recall": 0.1934826883910387
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7187870422421585,
            "auditor_fn_violation": 0.005270357734718238,
            "auditor_fp_violation": 0.0012839109299043444,
            "ave_precision_score": 0.7192173277934236,
            "fpr": 0.006586169045005488,
            "logloss": 0.7307724093086204,
            "mae": 0.43093374241337706,
            "precision": 0.9393939393939394,
            "recall": 0.20086393088552915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5504739606884641,
            "auditor_fn_violation": 0.005002322506878199,
            "auditor_fp_violation": 0.0010287744301371005,
            "ave_precision_score": 0.55165795092461,
            "fpr": 0.009868421052631578,
            "logloss": 0.6953767021091063,
            "mae": 0.5007490986925468,
            "precision": 0.8333333333333334,
            "recall": 0.09164969450101833
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5251493561717155,
            "auditor_fn_violation": 0.0019725315498360595,
            "auditor_fp_violation": 0.003366590873451467,
            "ave_precision_score": 0.526393878271911,
            "fpr": 0.010976948408342482,
            "logloss": 0.6933287520978242,
            "mae": 0.4996718557880686,
            "precision": 0.8113207547169812,
            "recall": 0.09287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.816333710538997,
            "auditor_fn_violation": 0.03587379854932648,
            "auditor_fp_violation": 0.00935012709922074,
            "ave_precision_score": 0.8168073237877163,
            "fpr": 0.09100877192982457,
            "logloss": 0.5506069890791978,
            "mae": 0.3802002039656304,
            "precision": 0.8009592326139089,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7615588363058303,
            "auditor_fn_violation": 0.03280282034078328,
            "auditor_fp_violation": 0.009229947467461195,
            "ave_precision_score": 0.7633539632935098,
            "fpr": 0.10428100987925357,
            "logloss": 0.570234566829942,
            "mae": 0.3873420530515104,
            "precision": 0.7625,
            "recall": 0.6587473002159827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.4599624722186689,
            "auditor_fn_violation": 0.01236511594668954,
            "auditor_fp_violation": 0.019437325499020715,
            "ave_precision_score": 0.4391662908062436,
            "fpr": 0.25219298245614036,
            "logloss": 9.249898135496368,
            "mae": 0.5594186043170796,
            "precision": 0.5085470085470085,
            "recall": 0.4847250509164969
        },
        "train": {
            "accuracy": 0.4489571899012075,
            "auc_prc": 0.43158900329748706,
            "auditor_fn_violation": 0.014006870668787768,
            "auditor_fp_violation": 0.019425278344048932,
            "ave_precision_score": 0.4074464207726365,
            "fpr": 0.2722283205268935,
            "logloss": 9.834879811059066,
            "mae": 0.5769641523486914,
            "precision": 0.4573304157549234,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.46040276247484324,
            "auditor_fn_violation": 0.012836316861399952,
            "auditor_fp_violation": 0.019437325499020715,
            "ave_precision_score": 0.43964038704607145,
            "fpr": 0.25219298245614036,
            "logloss": 9.200745217972534,
            "mae": 0.5585514485363812,
            "precision": 0.509594882729211,
            "recall": 0.48676171079429736
        },
        "train": {
            "accuracy": 0.4500548847420417,
            "auc_prc": 0.4321591034599318,
            "auditor_fn_violation": 0.01414674970898048,
            "auditor_fp_violation": 0.019425278344048932,
            "ave_precision_score": 0.4081549511930734,
            "fpr": 0.2722283205268935,
            "logloss": 9.739716809449599,
            "mae": 0.5761839002996327,
            "precision": 0.4585152838427948,
            "recall": 0.4535637149028078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.45809208140689583,
            "auditor_fn_violation": 0.011337853289027065,
            "auditor_fp_violation": 0.018830478809851236,
            "ave_precision_score": 0.4372628889535662,
            "fpr": 0.2543859649122807,
            "logloss": 9.349542619896988,
            "mae": 0.561630104553153,
            "precision": 0.5042735042735043,
            "recall": 0.48065173116089616
        },
        "train": {
            "accuracy": 0.4456641053787047,
            "auc_prc": 0.4295812867024948,
            "auditor_fn_violation": 0.010694819496767375,
            "auditor_fp_violation": 0.018660812294182233,
            "ave_precision_score": 0.40543726981396744,
            "fpr": 0.2810098792535675,
            "logloss": 9.933319658945424,
            "mae": 0.5811098275362833,
            "precision": 0.4553191489361702,
            "recall": 0.46220302375809935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.590031845924889,
            "auditor_fn_violation": 0.09488110551327403,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.591423485076138,
            "fpr": 0.2905701754385965,
            "logloss": 0.703380811822895,
            "mae": 0.48278760700895074,
            "precision": 0.5655737704918032,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5686549156501528,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.09804277089540538,
            "ave_precision_score": 0.5700944374828183,
            "fpr": 0.2711306256860593,
            "logloss": 0.684169975803346,
            "mae": 0.4728637883351742,
            "precision": 0.5834738617200674,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5900619477121047,
            "auditor_fn_violation": 0.09488110551327403,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.5914516874001295,
            "fpr": 0.2905701754385965,
            "logloss": 0.7033804957000723,
            "mae": 0.48278782751999405,
            "precision": 0.5655737704918032,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.568600738754062,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.09804277089540538,
            "ave_precision_score": 0.570040306773548,
            "fpr": 0.2711306256860593,
            "logloss": 0.6841697277602082,
            "mae": 0.4728640469054883,
            "precision": 0.5834738617200674,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.45960033753481594,
            "auditor_fn_violation": 0.0076553399792761,
            "auditor_fp_violation": 0.01939825811559779,
            "ave_precision_score": 0.43883648444566786,
            "fpr": 0.24890350877192982,
            "logloss": 9.23252076810403,
            "mae": 0.561074866614949,
            "precision": 0.5032822757111597,
            "recall": 0.4684317718940937
        },
        "train": {
            "accuracy": 0.4489571899012075,
            "auc_prc": 0.4312808346337774,
            "auditor_fn_violation": 0.0088858752990211,
            "auditor_fp_violation": 0.016190998902305166,
            "ave_precision_score": 0.4072294038790887,
            "fpr": 0.2689352360043908,
            "logloss": 9.792507431043946,
            "mae": 0.5774528410969191,
            "precision": 0.4567627494456763,
            "recall": 0.4449244060475162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5677781803957727,
            "auditor_fn_violation": 0.004370332654446717,
            "auditor_fp_violation": 0.0008490644663916324,
            "ave_precision_score": 0.568814545209586,
            "fpr": 0.003289473684210526,
            "logloss": 0.9857254096136261,
            "mae": 0.5073174497259683,
            "precision": 0.75,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5491622199357867,
            "auditor_fn_violation": 0.004144212919607501,
            "auditor_fp_violation": 0.0011025952642308295,
            "ave_precision_score": 0.5500825148350721,
            "fpr": 0.0021953896816684962,
            "logloss": 0.9708588114970382,
            "mae": 0.4961918553523515,
            "precision": 0.8823529411764706,
            "recall": 0.032397408207343416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8267092564232529,
            "auditor_fn_violation": 0.02016784578554329,
            "auditor_fp_violation": 0.005261074300954283,
            "ave_precision_score": 0.8271547457794403,
            "fpr": 0.10416666666666667,
            "logloss": 0.5306262316876584,
            "mae": 0.3650864654285997,
            "precision": 0.7974413646055437,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7749151722350757,
            "auditor_fn_violation": 0.022231284065880662,
            "auditor_fp_violation": 0.011207268307981815,
            "ave_precision_score": 0.7767328464812634,
            "fpr": 0.1207464324917673,
            "logloss": 0.5533924751650667,
            "mae": 0.37087454964968036,
            "precision": 0.7560975609756098,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8720033021086249,
            "auditor_fn_violation": 0.0214519241076214,
            "auditor_fp_violation": 0.019124786431637293,
            "ave_precision_score": 0.8722214496586336,
            "fpr": 0.16557017543859648,
            "logloss": 0.9661492747149347,
            "mae": 0.3099819785823713,
            "precision": 0.7369337979094077,
            "recall": 0.8615071283095723
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8694601720478797,
            "auditor_fn_violation": 0.021221309979065562,
            "auditor_fp_violation": 0.02546259996863729,
            "ave_precision_score": 0.8696327574282778,
            "fpr": 0.1712403951701427,
            "logloss": 0.8441460079266528,
            "mae": 0.30162042406303213,
            "precision": 0.7219251336898396,
            "recall": 0.8747300215982722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4594102594110791,
            "auditor_fn_violation": 0.00648292064172651,
            "auditor_fp_violation": 0.019916552069008622,
            "ave_precision_score": 0.4386150939727489,
            "fpr": 0.24671052631578946,
            "logloss": 9.290846386700457,
            "mae": 0.561642338686593,
            "precision": 0.5011086474501109,
            "recall": 0.46028513238289204
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.4310045784997094,
            "auditor_fn_violation": 0.00854210477651362,
            "auditor_fp_violation": 0.017739532695624914,
            "ave_precision_score": 0.40686160842653835,
            "fpr": 0.265642151481888,
            "logloss": 9.87787524524315,
            "mae": 0.5773989863664483,
            "precision": 0.45861297539149887,
            "recall": 0.4427645788336933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5907805015802958,
            "auditor_fn_violation": 0.09524511380283704,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.5920955739143703,
            "fpr": 0.2905701754385965,
            "logloss": 0.7001608753967284,
            "mae": 0.48386118652527793,
            "precision": 0.5662847790507365,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5650937459762257,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.10066694762427475,
            "ave_precision_score": 0.5665391373132267,
            "fpr": 0.27332601536772777,
            "logloss": 0.6804772675817585,
            "mae": 0.4734655009862751,
            "precision": 0.5815126050420169,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5692235824604099,
            "auditor_fn_violation": 0.09195117375924539,
            "auditor_fp_violation": 0.0873546693336667,
            "ave_precision_score": 0.5707367926591067,
            "fpr": 0.29276315789473684,
            "logloss": 0.7044262290799257,
            "mae": 0.4826153977202219,
            "precision": 0.5665584415584416,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.5924689837688274,
            "auditor_fn_violation": 0.07539243183267622,
            "auditor_fp_violation": 0.09243668652971618,
            "ave_precision_score": 0.5938626593060548,
            "fpr": 0.27991218441273324,
            "logloss": 0.6857604739480033,
            "mae": 0.4730420148922243,
            "precision": 0.5785123966942148,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.4614559880941034,
            "auditor_fn_violation": 0.011699628398899486,
            "auditor_fp_violation": 0.019390444638913203,
            "ave_precision_score": 0.44072588030734516,
            "fpr": 0.25109649122807015,
            "logloss": 9.113722174942524,
            "mae": 0.5569132204573125,
            "precision": 0.5096359743040685,
            "recall": 0.4847250509164969
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.4331188973876423,
            "auditor_fn_violation": 0.01351136695013905,
            "auditor_fp_violation": 0.01670064293554965,
            "ave_precision_score": 0.40911547035230933,
            "fpr": 0.270032930845225,
            "logloss": 9.656609084995004,
            "mae": 0.5746461382849486,
            "precision": 0.4593406593406593,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7562334336206258,
            "auditor_fn_violation": 0.0005493622038803817,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7572674970213069,
            "fpr": 0.0,
            "logloss": 0.694448140365166,
            "mae": 0.5005793385207653,
            "precision": 1.0,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6936507454431716,
            "mae": 0.5001802937782949,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.7740197401728572,
            "auditor_fn_violation": 0.001991996283989006,
            "auditor_fp_violation": 0.0015470683835479436,
            "ave_precision_score": 0.7744311199184805,
            "fpr": 0.003289473684210526,
            "logloss": 0.6863390007480467,
            "mae": 0.49064930936877144,
            "precision": 0.90625,
            "recall": 0.059063136456211814
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7125073278295149,
            "auditor_fn_violation": 0.0028497390900275757,
            "auditor_fp_violation": 0.001911165124666771,
            "ave_precision_score": 0.7131519058721322,
            "fpr": 0.003293084522502744,
            "logloss": 0.6881490390141358,
            "mae": 0.4925645612073913,
            "precision": 0.8695652173913043,
            "recall": 0.04319654427645788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.45582902547178006,
            "auditor_fn_violation": 0.01346384035445029,
            "auditor_fp_violation": 0.021356836271200583,
            "ave_precision_score": 0.43499879587334694,
            "fpr": 0.25877192982456143,
            "logloss": 9.4466279181221,
            "mae": 0.5693485508071316,
            "precision": 0.5,
            "recall": 0.48065173116089616
        },
        "train": {
            "accuracy": 0.4456641053787047,
            "auc_prc": 0.42802074147213554,
            "auditor_fn_violation": 0.011733243557858954,
            "auditor_fp_violation": 0.017768935236004393,
            "ave_precision_score": 0.403829790870747,
            "fpr": 0.27442371020856204,
            "logloss": 10.079050756509083,
            "mae": 0.5872832839650997,
            "precision": 0.45414847161572053,
            "recall": 0.44924406047516197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8655550561487046,
            "auditor_fn_violation": 0.013153428377460965,
            "auditor_fp_violation": 0.009383985498187277,
            "ave_precision_score": 0.8667472956379623,
            "fpr": 0.14035087719298245,
            "logloss": 0.7995417558309097,
            "mae": 0.26815071013771286,
            "precision": 0.7620817843866171,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8636869692514788,
            "auditor_fn_violation": 0.011097860799017529,
            "auditor_fp_violation": 0.021287439234749884,
            "ave_precision_score": 0.8638850505347948,
            "fpr": 0.14709110867178923,
            "logloss": 0.6095927901220879,
            "mae": 0.26506160082281227,
            "precision": 0.7485928705440901,
            "recall": 0.8617710583153347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8674307535249067,
            "auditor_fn_violation": 0.0062417372351448895,
            "auditor_fp_violation": 0.015478497312164023,
            "ave_precision_score": 0.8676225094226595,
            "fpr": 0.24451754385964913,
            "logloss": 0.5403252392853034,
            "mae": 0.3484667596905574,
            "precision": 0.6691394658753709,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8652221050155031,
            "auditor_fn_violation": 0.006273219327964194,
            "auditor_fp_violation": 0.02416643798024149,
            "ave_precision_score": 0.8654689897682879,
            "fpr": 0.24478594950603733,
            "logloss": 0.5464183300708944,
            "mae": 0.34892180679789225,
            "precision": 0.6605783866057838,
            "recall": 0.937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.45996297557267773,
            "auditor_fn_violation": 0.01236511594668954,
            "auditor_fp_violation": 0.019437325499020715,
            "ave_precision_score": 0.4391667977774284,
            "fpr": 0.25219298245614036,
            "logloss": 9.24942228835758,
            "mae": 0.5593779943655628,
            "precision": 0.5085470085470085,
            "recall": 0.4847250509164969
        },
        "train": {
            "accuracy": 0.4489571899012075,
            "auc_prc": 0.43159061803083154,
            "auditor_fn_violation": 0.014006870668787768,
            "auditor_fp_violation": 0.019425278344048932,
            "ave_precision_score": 0.40744803593216494,
            "fpr": 0.2722283205268935,
            "logloss": 9.834519820718008,
            "mae": 0.5769857595976902,
            "precision": 0.4573304157549234,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8649519877318304,
            "auditor_fn_violation": 0.009319058848751208,
            "auditor_fp_violation": 0.022966412468225197,
            "ave_precision_score": 0.8652871712107175,
            "fpr": 0.26206140350877194,
            "logloss": 0.6500573202989627,
            "mae": 0.3324154998183969,
            "precision": 0.6580829756795422,
            "recall": 0.9368635437881874
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8671722792951875,
            "auditor_fn_violation": 0.0073803974935572675,
            "auditor_fp_violation": 0.024835345773874865,
            "ave_precision_score": 0.8673786063435505,
            "fpr": 0.25905598243688255,
            "logloss": 0.6581807101877165,
            "mae": 0.32910638557323774,
            "precision": 0.649331352154532,
            "recall": 0.9438444924406048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5914795895566443,
            "auditor_fn_violation": 0.09524511380283704,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.5927799419668123,
            "fpr": 0.2905701754385965,
            "logloss": 0.7003549422873833,
            "mae": 0.483786662583027,
            "precision": 0.5662847790507365,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5641673288885585,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.10066694762427475,
            "ave_precision_score": 0.5656086448108741,
            "fpr": 0.27332601536772777,
            "logloss": 0.6806992443271814,
            "mae": 0.47341280056799545,
            "precision": 0.5815126050420169,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.555511882204744,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5440787043959558,
            "fpr": 0.05592105263157895,
            "logloss": 0.6937605603059771,
            "mae": 0.5002731415524817,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5170432887044136,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.5123388307448439,
            "fpr": 0.05598243688254665,
            "logloss": 0.6933969933748003,
            "mae": 0.5000917274917912,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.555511882204744,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5440787043959558,
            "fpr": 0.05592105263157895,
            "logloss": 0.6938060026127616,
            "mae": 0.5002925763266128,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5170432887044136,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.5123388307448439,
            "fpr": 0.05598243688254665,
            "logloss": 0.6934138110375555,
            "mae": 0.5000968124680671,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.4652493551319029,
            "auditor_fn_violation": 0.0025882552613713528,
            "auditor_fp_violation": 0.025352127349251994,
            "ave_precision_score": 0.4453818620082102,
            "fpr": 0.23464912280701755,
            "logloss": 9.270209493376182,
            "mae": 0.552896187609933,
            "precision": 0.5102974828375286,
            "recall": 0.45417515274949083
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.43201112589252466,
            "auditor_fn_violation": 0.007342464194521972,
            "auditor_fp_violation": 0.01935177199310023,
            "ave_precision_score": 0.40874043172553043,
            "fpr": 0.2601536772777168,
            "logloss": 9.873973060738553,
            "mae": 0.5759386016034648,
            "precision": 0.4576659038901602,
            "recall": 0.4319654427645788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8644243550710424,
            "auditor_fn_violation": 0.0135687997999071,
            "auditor_fp_violation": 0.011191503104554744,
            "ave_precision_score": 0.8651174960640425,
            "fpr": 0.13486842105263158,
            "logloss": 0.8088576823503377,
            "mae": 0.2660266860834063,
            "precision": 0.768361581920904,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8643271106510813,
            "auditor_fn_violation": 0.011775918519273674,
            "auditor_fp_violation": 0.017337697977105222,
            "ave_precision_score": 0.8645163097178789,
            "fpr": 0.14709110867178923,
            "logloss": 0.6126088101478394,
            "mae": 0.261561218099307,
            "precision": 0.74573055028463,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.651231623678198,
            "auditor_fn_violation": 0.009419551934826877,
            "auditor_fp_violation": 0.01272294453473351,
            "ave_precision_score": 0.6402721187821643,
            "fpr": 0.06140350877192982,
            "logloss": 0.6587679935140727,
            "mae": 0.46380825745954846,
            "precision": 0.6888888888888889,
            "recall": 0.2525458248472505
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6430919296964279,
            "auditor_fn_violation": 0.006816139670407057,
            "auditor_fp_violation": 0.006796887251058491,
            "ave_precision_score": 0.6332807257946733,
            "fpr": 0.059275521405049394,
            "logloss": 0.6510188766551992,
            "mae": 0.4583955417283934,
            "precision": 0.6949152542372882,
            "recall": 0.265658747300216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5717539563967935,
            "auditor_fn_violation": 0.09488110551327403,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.5732787537252584,
            "fpr": 0.2905701754385965,
            "logloss": 0.6995713021222023,
            "mae": 0.4824336314443172,
            "precision": 0.5655737704918032,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5918472678342681,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.09804277089540538,
            "ave_precision_score": 0.5934274564989896,
            "fpr": 0.2711306256860593,
            "logloss": 0.6794732864942715,
            "mae": 0.4718622646072693,
            "precision": 0.5834738617200674,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8162236069594249,
            "auditor_fn_violation": 0.03629586951084432,
            "auditor_fp_violation": 0.007667625119806642,
            "ave_precision_score": 0.8167033714488962,
            "fpr": 0.08991228070175439,
            "logloss": 0.5512414139997721,
            "mae": 0.37986840114095494,
            "precision": 0.8019323671497585,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7598491832715454,
            "auditor_fn_violation": 0.0348678143070179,
            "auditor_fp_violation": 0.005998118237415716,
            "ave_precision_score": 0.7616635491867718,
            "fpr": 0.10098792535675083,
            "logloss": 0.5718993034892561,
            "mae": 0.3872782722540797,
            "precision": 0.7682619647355163,
            "recall": 0.6587473002159827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.7772777422330832,
            "auditor_fn_violation": 0.001991996283989006,
            "auditor_fp_violation": 0.0015470683835479436,
            "ave_precision_score": 0.7777985713969128,
            "fpr": 0.003289473684210526,
            "logloss": 0.6867003189619268,
            "mae": 0.49070937630900163,
            "precision": 0.90625,
            "recall": 0.059063136456211814
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7144691936147571,
            "auditor_fn_violation": 0.0028497390900275757,
            "auditor_fp_violation": 0.001911165124666771,
            "ave_precision_score": 0.7152160729838364,
            "fpr": 0.003293084522502744,
            "logloss": 0.6885947923957351,
            "mae": 0.49265519769210064,
            "precision": 0.8695652173913043,
            "recall": 0.04319654427645788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8695865518954264,
            "auditor_fn_violation": 0.009962214599635545,
            "auditor_fp_violation": 0.023341459349085315,
            "ave_precision_score": 0.8698547294681039,
            "fpr": 0.20065789473684212,
            "logloss": 0.5080704844841636,
            "mae": 0.3206207433208954,
            "precision": 0.7043618739903069,
            "recall": 0.8879837067209776
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8725583004089775,
            "auditor_fn_violation": 0.015502865149492763,
            "auditor_fp_violation": 0.023624941194919244,
            "ave_precision_score": 0.8727568016943875,
            "fpr": 0.19099890230515917,
            "logloss": 0.5049499785352067,
            "mae": 0.31637171082174087,
            "precision": 0.7075630252100841,
            "recall": 0.9092872570194385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5905671043418271,
            "auditor_fn_violation": 0.09524511380283704,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.592017055725748,
            "fpr": 0.2905701754385965,
            "logloss": 0.6977031455593142,
            "mae": 0.4842445397945611,
            "precision": 0.5662847790507365,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5851343695959111,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.10066694762427475,
            "ave_precision_score": 0.5865576384589297,
            "fpr": 0.27332601536772777,
            "logloss": 0.6758134412502699,
            "mae": 0.47263307661701376,
            "precision": 0.5815126050420169,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.46537532646620894,
            "auditor_fn_violation": 0.0025882552613713528,
            "auditor_fp_violation": 0.025352127349251994,
            "ave_precision_score": 0.44550790229586873,
            "fpr": 0.23464912280701755,
            "logloss": 9.256648225885769,
            "mae": 0.5526844995762662,
            "precision": 0.5102974828375286,
            "recall": 0.45417515274949083
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.43216244494489,
            "auditor_fn_violation": 0.007342464194521972,
            "auditor_fp_violation": 0.01935177199310023,
            "ave_precision_score": 0.4088918993650704,
            "fpr": 0.2601536772777168,
            "logloss": 9.857202222378822,
            "mae": 0.5757431736910223,
            "precision": 0.4576659038901602,
            "recall": 0.4319654427645788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8616063313139141,
            "auditor_fn_violation": 0.013651427448458217,
            "auditor_fp_violation": 0.015150331291411433,
            "ave_precision_score": 0.8620449246131208,
            "fpr": 0.1524122807017544,
            "logloss": 0.8285464160803468,
            "mae": 0.26791161008599074,
            "precision": 0.7495495495495496,
            "recall": 0.8472505091649695
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8621443157363285,
            "auditor_fn_violation": 0.013781641705765627,
            "auditor_fp_violation": 0.023607789713031204,
            "ave_precision_score": 0.8623439398774823,
            "fpr": 0.16355653128430298,
            "logloss": 0.6404835124402614,
            "mae": 0.2641327096852385,
            "precision": 0.7285974499089253,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8586371227474789,
            "auditor_fn_violation": 0.004707542787722872,
            "auditor_fp_violation": 0.01363972579905822,
            "ave_precision_score": 0.8588289196940345,
            "fpr": 0.24561403508771928,
            "logloss": 0.5483182966968808,
            "mae": 0.36223822052329124,
            "precision": 0.6671619613670133,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.85569526504171,
            "auditor_fn_violation": 0.005064095421213723,
            "auditor_fp_violation": 0.014292084836129848,
            "ave_precision_score": 0.8559793419071561,
            "fpr": 0.2557628979143798,
            "logloss": 0.5520893228168295,
            "mae": 0.36209224654375916,
            "precision": 0.648036253776435,
            "recall": 0.9265658747300216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8672261462291473,
            "auditor_fn_violation": 0.0062417372351448895,
            "auditor_fp_violation": 0.016551548110180437,
            "ave_precision_score": 0.8674180504986874,
            "fpr": 0.24671052631578946,
            "logloss": 0.5426479074848806,
            "mae": 0.34874501831731514,
            "precision": 0.6671597633136095,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8651777743277966,
            "auditor_fn_violation": 0.00565917404983013,
            "auditor_fp_violation": 0.024698133918770588,
            "ave_precision_score": 0.8654252506363942,
            "fpr": 0.24588364434687157,
            "logloss": 0.5487796585156223,
            "mae": 0.34924950291587675,
            "precision": 0.6600910470409712,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.555511882204744,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5440787043959558,
            "fpr": 0.05592105263157895,
            "logloss": 0.6937589051182309,
            "mae": 0.5002724310023743,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5170432887044136,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.5123388307448439,
            "fpr": 0.05598243688254665,
            "logloss": 0.6933963838626414,
            "mae": 0.5000915410882424,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8736358544325927,
            "auditor_fn_violation": 0.021715439311108732,
            "auditor_fp_violation": 0.008128620244197195,
            "ave_precision_score": 0.8739275305344467,
            "fpr": 0.08771929824561403,
            "logloss": 0.4801137908410162,
            "mae": 0.32160493748961017,
            "precision": 0.8210290827740492,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8754342043980662,
            "auditor_fn_violation": 0.02216490079256887,
            "auditor_fp_violation": 0.021106123569076374,
            "ave_precision_score": 0.8756355885212967,
            "fpr": 0.09001097694840834,
            "logloss": 0.4535031848761941,
            "mae": 0.3057826158537455,
            "precision": 0.8148984198645598,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8165752316431814,
            "auditor_fn_violation": 0.036802801300603843,
            "auditor_fp_violation": 0.008196337042130268,
            "ave_precision_score": 0.817047916759548,
            "fpr": 0.08771929824561403,
            "logloss": 0.5525479605469741,
            "mae": 0.37804401410220745,
            "precision": 0.8034398034398035,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7626816369455846,
            "auditor_fn_violation": 0.032468533143034634,
            "auditor_fp_violation": 0.006507762270660186,
            "ave_precision_score": 0.7644747726279799,
            "fpr": 0.09659714599341383,
            "logloss": 0.5706665467782063,
            "mae": 0.3844160692343073,
            "precision": 0.7755102040816326,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.7802268289923339,
            "auditor_fn_violation": 0.0011746525172401656,
            "auditor_fp_violation": 0.0001718964870608825,
            "ave_precision_score": 0.7819294954507134,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6943805176747566,
            "mae": 0.5005494055517933,
            "precision": 0.3333333333333333,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.7349776749647199,
            "auditor_fn_violation": 0.0006235286028928919,
            "auditor_fp_violation": 0.0021684373529872983,
            "ave_precision_score": 0.736425145527025,
            "fpr": 0.005488474204171241,
            "logloss": 0.6935327339026067,
            "mae": 0.5001255782192284,
            "precision": 0.16666666666666666,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5639067016906802,
            "auditor_fn_violation": 0.004370332654446717,
            "auditor_fp_violation": 0.0008490644663916324,
            "ave_precision_score": 0.565235695895401,
            "fpr": 0.003289473684210526,
            "logloss": 0.9911669222293213,
            "mae": 0.5076131226919722,
            "precision": 0.75,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5470600605610842,
            "auditor_fn_violation": 0.004144212919607501,
            "auditor_fp_violation": 0.0011025952642308295,
            "ave_precision_score": 0.5480856396200542,
            "fpr": 0.0021953896816684962,
            "logloss": 0.9756106882763402,
            "mae": 0.49604284737982945,
            "precision": 0.8823529411764706,
            "recall": 0.032397408207343416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.555511882204744,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5440787043959558,
            "fpr": 0.05592105263157895,
            "logloss": 0.6938374186733446,
            "mae": 0.5003059282245343,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5170432887044136,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.5123388307448439,
            "fpr": 0.05598243688254665,
            "logloss": 0.6934255543829122,
            "mae": 0.5001003004520576,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8674527304575067,
            "auditor_fn_violation": 0.0062417372351448895,
            "auditor_fp_violation": 0.015478497312164023,
            "ave_precision_score": 0.8676441111217489,
            "fpr": 0.24451754385964913,
            "logloss": 0.5403691729258088,
            "mae": 0.34848756187497393,
            "precision": 0.6691394658753709,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8651780448036935,
            "auditor_fn_violation": 0.006273219327964194,
            "auditor_fp_violation": 0.02416643798024149,
            "ave_precision_score": 0.8654252092822946,
            "fpr": 0.24478594950603733,
            "logloss": 0.5464569553014841,
            "mae": 0.34894112960469187,
            "precision": 0.6605783866057838,
            "recall": 0.937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944939432837326,
            "mae": 0.50061015872971,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6935369019277312,
            "mae": 0.5001316875317486,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5636529068036313,
            "auditor_fn_violation": 0.004370332654446717,
            "auditor_fp_violation": 0.0008490644663916324,
            "ave_precision_score": 0.5649768756602978,
            "fpr": 0.003289473684210526,
            "logloss": 0.986064933690821,
            "mae": 0.5074420375095909,
            "precision": 0.75,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5384724596767531,
            "auditor_fn_violation": 0.004144212919607501,
            "auditor_fp_violation": 0.0016318409910616278,
            "ave_precision_score": 0.540489553405861,
            "fpr": 0.003293084522502744,
            "logloss": 0.9819477794305224,
            "mae": 0.49691993117528743,
            "precision": 0.8333333333333334,
            "recall": 0.032397408207343416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5942596286207888,
            "auditor_fn_violation": 0.004370332654446717,
            "auditor_fp_violation": 0.0006068466891694795,
            "ave_precision_score": 0.5943873763940808,
            "fpr": 0.0010964912280701754,
            "logloss": 0.991597265481541,
            "mae": 0.5070993386192673,
            "precision": 0.9,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5568564979420692,
            "auditor_fn_violation": 0.006285073483912733,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5559432256499397,
            "fpr": 0.0,
            "logloss": 0.9773342196888458,
            "mae": 0.49621641720132953,
            "precision": 1.0,
            "recall": 0.023758099352051837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.4582181636499031,
            "auditor_fn_violation": 0.01433031407439169,
            "auditor_fp_violation": 0.02023690461307665,
            "ave_precision_score": 0.43742268732733547,
            "fpr": 0.26096491228070173,
            "logloss": 9.197928883225137,
            "mae": 0.5664509499366602,
            "precision": 0.4978902953586498,
            "recall": 0.48065173116089616
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.4305282510924947,
            "auditor_fn_violation": 0.00919645418487268,
            "auditor_fp_violation": 0.017087776383879583,
            "ave_precision_score": 0.40652216322957896,
            "fpr": 0.270032930845225,
            "logloss": 9.714785995838305,
            "mae": 0.5836591842192552,
            "precision": 0.4593406593406593,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8641804972522819,
            "auditor_fn_violation": 0.012903312252117058,
            "auditor_fp_violation": 0.012673459182397805,
            "ave_precision_score": 0.8648770011680604,
            "fpr": 0.14035087719298245,
            "logloss": 0.8097866843147891,
            "mae": 0.26641682263890654,
            "precision": 0.7616387337057728,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8635132213517045,
            "auditor_fn_violation": 0.012219263951748846,
            "auditor_fp_violation": 0.01858240551983692,
            "ave_precision_score": 0.8637071067810104,
            "fpr": 0.15148188803512624,
            "logloss": 0.6148114265067891,
            "mae": 0.2620711235900915,
            "precision": 0.7406015037593985,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6925921421639755,
            "mae": 0.49947569047084506,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.693329432973694,
            "mae": 0.5000723420788507,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.4622160329408256,
            "auditor_fn_violation": 0.013019437596026745,
            "auditor_fp_violation": 0.02040098762345294,
            "ave_precision_score": 0.44152136657533814,
            "fpr": 0.24561403508771928,
            "logloss": 9.055445949496846,
            "mae": 0.5595123521567843,
            "precision": 0.5087719298245614,
            "recall": 0.4725050916496945
        },
        "train": {
            "accuracy": 0.45993413830954993,
            "auc_prc": 0.4343486637276732,
            "auditor_fn_violation": 0.010839440199339492,
            "auditor_fp_violation": 0.019498784694997672,
            "ave_precision_score": 0.41034559157227113,
            "fpr": 0.2579582875960483,
            "logloss": 9.601889092572307,
            "mae": 0.5738886498541711,
            "precision": 0.4671201814058957,
            "recall": 0.4449244060475162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8352923692013945,
            "auditor_fn_violation": 0.005643245078071964,
            "auditor_fp_violation": 0.031128891111388925,
            "ave_precision_score": 0.8355097216648582,
            "fpr": 0.2565789473684211,
            "logloss": 0.5658059779618411,
            "mae": 0.37248035148194614,
            "precision": 0.6523031203566122,
            "recall": 0.8940936863543788
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8249215942153529,
            "auditor_fn_violation": 0.0054837325417918265,
            "auditor_fp_violation": 0.020684687156970364,
            "ave_precision_score": 0.8253313600555057,
            "fpr": 0.26125137211855104,
            "logloss": 0.5745604973290374,
            "mae": 0.3758674233264477,
            "precision": 0.6404833836858006,
            "recall": 0.9157667386609071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4607629952177083,
            "auditor_fn_violation": 0.0005694608210955177,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4622002215216853,
            "fpr": 0.0,
            "logloss": 0.6936906650198517,
            "mae": 0.5002237099892738,
            "precision": 1.0,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6926075720706633,
            "mae": 0.4996818217697311,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.4608033151001283,
            "auditor_fn_violation": 0.016244149069210713,
            "auditor_fp_violation": 0.027073696712089024,
            "ave_precision_score": 0.4400411041024252,
            "fpr": 0.23684210526315788,
            "logloss": 9.331991091773261,
            "mae": 0.5610845889279591,
            "precision": 0.5045871559633027,
            "recall": 0.4480651731160896
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0.4330550881223635,
            "auditor_fn_violation": 0.008700950466223975,
            "auditor_fp_violation": 0.017661125921279604,
            "ave_precision_score": 0.40895979623255174,
            "fpr": 0.25686059275521406,
            "logloss": 9.813306360360489,
            "mae": 0.5722368599239398,
            "precision": 0.45958429561200925,
            "recall": 0.4298056155507559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8651263276357566,
            "auditor_fn_violation": 0.011462911351699002,
            "auditor_fp_violation": 0.01744228445222322,
            "ave_precision_score": 0.8654602572195693,
            "fpr": 0.2543859649122807,
            "logloss": 0.6323054314402623,
            "mae": 0.3287135756517385,
            "precision": 0.6627906976744186,
            "recall": 0.9287169042769857
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8670532914529882,
            "auditor_fn_violation": 0.008708062959793076,
            "auditor_fp_violation": 0.02627607025246981,
            "ave_precision_score": 0.8672596822394917,
            "fpr": 0.24807903402854006,
            "logloss": 0.6387160416225118,
            "mae": 0.3243440243075106,
            "precision": 0.6580937972768532,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.465371533947263,
            "auditor_fn_violation": 0.009678600778933082,
            "auditor_fp_violation": 0.025352127349251994,
            "ave_precision_score": 0.4455041736502399,
            "fpr": 0.23464912280701755,
            "logloss": 9.25062330890192,
            "mae": 0.5526743332223881,
            "precision": 0.5102974828375286,
            "recall": 0.45417515274949083
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.4325969817098215,
            "auditor_fn_violation": 0.011014881707377796,
            "auditor_fp_violation": 0.01807766190998902,
            "ave_precision_score": 0.40932667132286876,
            "fpr": 0.26125137211855104,
            "logloss": 9.847544481650194,
            "mae": 0.5750853283515283,
            "precision": 0.45785876993166286,
            "recall": 0.43412526997840173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8000334180107491,
            "auditor_fn_violation": 0.016128023725301036,
            "auditor_fp_violation": 0.0028102471142226132,
            "ave_precision_score": 0.8005276633310305,
            "fpr": 0.14035087719298245,
            "logloss": 0.5636832231261342,
            "mae": 0.3883206226470831,
            "precision": 0.7465346534653465,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7479750096171167,
            "auditor_fn_violation": 0.019718203004791452,
            "auditor_fp_violation": 0.012545083895248553,
            "ave_precision_score": 0.749870944078247,
            "fpr": 0.16794731064763996,
            "logloss": 0.5896294870604166,
            "mae": 0.39621058179210755,
            "precision": 0.697029702970297,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940591307749525,
            "mae": 0.5003982080113992,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.7733027932044503,
            "auditor_fn_violation": 0.0005500328360119807,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.774155496859203,
            "fpr": 0.0,
            "logloss": 0.6930113658378463,
            "mae": 0.499883032067547,
            "precision": 1.0,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6494813449814146,
            "auditor_fn_violation": 0.014955604387751464,
            "auditor_fp_violation": 0.011457161311830649,
            "ave_precision_score": 0.6410434407444761,
            "fpr": 0.06469298245614036,
            "logloss": 6.612707439542168,
            "mae": 0.4273116197969943,
            "precision": 0.7434782608695653,
            "recall": 0.34826883910386963
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5847452494767431,
            "auditor_fn_violation": 0.009758341176833196,
            "auditor_fp_violation": 0.014867884585228168,
            "ave_precision_score": 0.5769877471770638,
            "fpr": 0.07464324917672886,
            "logloss": 7.406543564285157,
            "mae": 0.43390678929281307,
            "precision": 0.6866359447004609,
            "recall": 0.32181425485961124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8532915118173261,
            "auditor_fn_violation": 0.006302033086790296,
            "auditor_fp_violation": 0.020802079426595003,
            "ave_precision_score": 0.8534856292477466,
            "fpr": 0.22697368421052633,
            "logloss": 0.5414440790945801,
            "mae": 0.35997370759989217,
            "precision": 0.6795665634674922,
            "recall": 0.8940936863543788
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.835949175153395,
            "auditor_fn_violation": 0.00497874549838428,
            "auditor_fp_violation": 0.014613062568605938,
            "ave_precision_score": 0.8363133486155219,
            "fpr": 0.24259055982436883,
            "logloss": 0.5526034224616289,
            "mae": 0.3637707090673868,
            "precision": 0.6584234930448223,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5860226719638891,
            "auditor_fn_violation": 0.09488110551327403,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.5874045706393887,
            "fpr": 0.2905701754385965,
            "logloss": 0.7036836282478353,
            "mae": 0.4827089148916696,
            "precision": 0.5655737704918032,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5663069022733791,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.09804277089540538,
            "ave_precision_score": 0.5679295652522202,
            "fpr": 0.2711306256860593,
            "logloss": 0.6843035259969061,
            "mae": 0.4726928473173198,
            "precision": 0.5834738617200674,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8529345969888293,
            "auditor_fn_violation": 0.0027892414335227125,
            "auditor_fp_violation": 0.01716099929157812,
            "ave_precision_score": 0.8531874485930236,
            "fpr": 0.14144736842105263,
            "logloss": 0.5106261722646431,
            "mae": 0.35326201322880624,
            "precision": 0.7547528517110266,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8476551971364674,
            "auditor_fn_violation": 0.013539816924415533,
            "auditor_fp_violation": 0.011202367884585236,
            "ave_precision_score": 0.8479536860778265,
            "fpr": 0.15697036223929747,
            "logloss": 0.5041164514110023,
            "mae": 0.34807507159509393,
            "precision": 0.730188679245283,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.8333339782495747,
            "auditor_fn_violation": 0.002661950191160183,
            "auditor_fp_violation": 0.02975111472267369,
            "ave_precision_score": 0.8335585817959761,
            "fpr": 0.2543859649122807,
            "logloss": 0.5641402558830322,
            "mae": 0.3725112370591153,
            "precision": 0.6526946107784432,
            "recall": 0.8879837067209776
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8224226247452275,
            "auditor_fn_violation": 0.005708961504813976,
            "auditor_fp_violation": 0.020469068527520787,
            "ave_precision_score": 0.8228452063822119,
            "fpr": 0.2579582875960483,
            "logloss": 0.5745276788786702,
            "mae": 0.3769304939145969,
            "precision": 0.6423135464231354,
            "recall": 0.9114470842332614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8720032997902591,
            "auditor_fn_violation": 0.0214519241076214,
            "auditor_fp_violation": 0.019124786431637293,
            "ave_precision_score": 0.8722219411521761,
            "fpr": 0.16557017543859648,
            "logloss": 0.966149517207722,
            "mae": 0.30998085961918315,
            "precision": 0.7369337979094077,
            "recall": 0.8615071283095723
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8694537942116486,
            "auditor_fn_violation": 0.021221309979065562,
            "auditor_fp_violation": 0.02546259996863729,
            "ave_precision_score": 0.8696263889015463,
            "fpr": 0.1712403951701427,
            "logloss": 0.8441469059172255,
            "mae": 0.30161904768237674,
            "precision": 0.7219251336898396,
            "recall": 0.8747300215982722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8562851295616071,
            "auditor_fn_violation": 0.012137331618251332,
            "auditor_fp_violation": 0.013553777555527783,
            "ave_precision_score": 0.856824848541029,
            "fpr": 0.14473684210526316,
            "logloss": 0.854718510138144,
            "mae": 0.2675216573593548,
            "precision": 0.7577981651376147,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8568575341304175,
            "auditor_fn_violation": 0.01292814247747118,
            "auditor_fp_violation": 0.021848537713658467,
            "ave_precision_score": 0.857081444823478,
            "fpr": 0.15697036223929747,
            "logloss": 0.6601606982532149,
            "mae": 0.2624405942137321,
            "precision": 0.7317073170731707,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.4621918929801613,
            "auditor_fn_violation": 0.014846178582913505,
            "auditor_fp_violation": 0.02197930991373922,
            "ave_precision_score": 0.4414972179532163,
            "fpr": 0.24342105263157895,
            "logloss": 9.055927213095362,
            "mae": 0.5597758733994145,
            "precision": 0.5077605321507761,
            "recall": 0.4663951120162933
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.43437140984481926,
            "auditor_fn_violation": 0.010246732401912782,
            "auditor_fp_violation": 0.018401089854163402,
            "ave_precision_score": 0.41036838524360497,
            "fpr": 0.25686059275521406,
            "logloss": 9.60172584263851,
            "mae": 0.5737885316818986,
            "precision": 0.46938775510204084,
            "recall": 0.4470842332613391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6937334291487212,
            "mae": 0.5002526964730861,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.453149727805546,
            "auditor_fn_violation": 0.0006140452781340646,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.45639035640124404,
            "fpr": 0.0,
            "logloss": 0.6926740277216468,
            "mae": 0.49972210577499987,
            "precision": 1.0,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.585644994272617,
            "auditor_fn_violation": 0.09488110551327403,
            "auditor_fp_violation": 0.08874546818352293,
            "ave_precision_score": 0.587034318571886,
            "fpr": 0.2905701754385965,
            "logloss": 0.7039208416967356,
            "mae": 0.482637759657544,
            "precision": 0.5655737704918032,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5663121859616104,
            "auditor_fn_violation": 0.07884910370726875,
            "auditor_fp_violation": 0.09804277089540538,
            "ave_precision_score": 0.5679325138088099,
            "fpr": 0.2711306256860593,
            "logloss": 0.6845551432764406,
            "mae": 0.47263601870489697,
            "precision": 0.5834738617200674,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 20300,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8721551052306815,
            "auditor_fn_violation": 0.020295137027905814,
            "auditor_fp_violation": 0.016272867441763553,
            "ave_precision_score": 0.8723609529247454,
            "fpr": 0.1513157894736842,
            "logloss": 0.9842664996443722,
            "mae": 0.30826439766291425,
            "precision": 0.7517985611510791,
            "recall": 0.8513238289205702
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8692727499311754,
            "auditor_fn_violation": 0.021486843072312727,
            "auditor_fp_violation": 0.02349262976321154,
            "ave_precision_score": 0.8694407098651521,
            "fpr": 0.1602634467618002,
            "logloss": 0.865555488091726,
            "mae": 0.29918861678964537,
            "precision": 0.7321100917431193,
            "recall": 0.8617710583153347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5673269672340855,
            "auditor_fn_violation": 0.004955425733376223,
            "auditor_fp_violation": 0.0011537900570904697,
            "ave_precision_score": 0.5684894948072291,
            "fpr": 0.0043859649122807015,
            "logloss": 0.9916369392508932,
            "mae": 0.5068874906323719,
            "precision": 0.7142857142857143,
            "recall": 0.020366598778004074
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5463349038844734,
            "auditor_fn_violation": 0.004144212919607501,
            "auditor_fp_violation": 0.0011025952642308295,
            "ave_precision_score": 0.5472791028518178,
            "fpr": 0.0021953896816684962,
            "logloss": 0.9763129890412293,
            "mae": 0.495317650408894,
            "precision": 0.8823529411764706,
            "recall": 0.032397408207343416
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.555511882204744,
            "auditor_fn_violation": 0.0031733483403008664,
            "auditor_fp_violation": 0.012045776555402758,
            "ave_precision_score": 0.5440787043959558,
            "fpr": 0.05592105263157895,
            "logloss": 0.693922223473873,
            "mae": 0.5003416364064865,
            "precision": 0.5565217391304348,
            "recall": 0.13034623217922606
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5170432887044136,
            "auditor_fn_violation": 0.011742726882617783,
            "auditor_fp_violation": 0.0058045515132507455,
            "ave_precision_score": 0.5123388307448439,
            "fpr": 0.05598243688254665,
            "logloss": 0.6934577100643194,
            "mae": 0.5001096030294437,
            "precision": 0.5048543689320388,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.46094125968047184,
            "auditor_fn_violation": 0.016670686390109705,
            "auditor_fp_violation": 0.021421948576905457,
            "ave_precision_score": 0.44024574761395585,
            "fpr": 0.2631578947368421,
            "logloss": 8.942987004155876,
            "mae": 0.5594983371937265,
            "precision": 0.5020746887966805,
            "recall": 0.49287169042769857
        },
        "train": {
            "accuracy": 0.4478594950603732,
            "auc_prc": 0.43210738879058985,
            "auditor_fn_violation": 0.01466596173952626,
            "auditor_fp_violation": 0.02258850164654227,
            "ave_precision_score": 0.4087910451854254,
            "fpr": 0.27552140504939626,
            "logloss": 9.474154460086936,
            "mae": 0.5787062505804407,
            "precision": 0.45670995670995673,
            "recall": 0.4557235421166307
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.43717415770593204,
            "auditor_fn_violation": 0.001991996283989006,
            "auditor_fp_violation": 0.0015470683835479436,
            "ave_precision_score": 0.438475650985234,
            "fpr": 0.003289473684210526,
            "logloss": 0.6871298211748571,
            "mae": 0.4909112673710313,
            "precision": 0.90625,
            "recall": 0.059063136456211814
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.41057704894284996,
            "auditor_fn_violation": 0.0028497390900275757,
            "auditor_fp_violation": 0.001911165124666771,
            "ave_precision_score": 0.4117429262828862,
            "fpr": 0.003293084522502744,
            "logloss": 0.6886262753720925,
            "mae": 0.4926433813166278,
            "precision": 0.8695652173913043,
            "recall": 0.04319654427645788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8730063130430357,
            "auditor_fn_violation": 0.01952469003465895,
            "auditor_fp_violation": 0.015171167229236992,
            "ave_precision_score": 0.8732378212100451,
            "fpr": 0.15021929824561403,
            "logloss": 0.9019065418942731,
            "mae": 0.3046542624871819,
            "precision": 0.7531531531531531,
            "recall": 0.8513238289205702
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8704331326312738,
            "auditor_fn_violation": 0.0205361397652403,
            "auditor_fp_violation": 0.01963109612670536,
            "ave_precision_score": 0.8706048993361626,
            "fpr": 0.15587266739846323,
            "logloss": 0.7685971520878979,
            "mae": 0.29510515365822776,
            "precision": 0.7384898710865562,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8166420285183826,
            "auditor_fn_violation": 0.03528423911101584,
            "auditor_fp_violation": 0.008196337042130268,
            "ave_precision_score": 0.8171141938835763,
            "fpr": 0.08771929824561403,
            "logloss": 0.5521828656973866,
            "mae": 0.3781678852984649,
            "precision": 0.80440097799511,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7627369537927873,
            "auditor_fn_violation": 0.032468533143034634,
            "auditor_fp_violation": 0.006507762270660186,
            "ave_precision_score": 0.7645289318841764,
            "fpr": 0.09659714599341383,
            "logloss": 0.570432724722283,
            "mae": 0.3846048746630141,
            "precision": 0.7755102040816326,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.7647968724367159,
            "auditor_fn_violation": 0.0018691714010076262,
            "auditor_fp_violation": 0.0006980039171563112,
            "ave_precision_score": 0.7665930376182453,
            "fpr": 0.005482456140350877,
            "logloss": 0.6933981534657249,
            "mae": 0.5001139399317795,
            "precision": 0.375,
            "recall": 0.006109979633401222
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.7158331606908843,
            "auditor_fn_violation": 0.001728335937296267,
            "auditor_fp_violation": 0.003567508232711306,
            "ave_precision_score": 0.7174564526057925,
            "fpr": 0.008781558726673985,
            "logloss": 0.6935021391416323,
            "mae": 0.5001615300267509,
            "precision": 0.2727272727272727,
            "recall": 0.0064794816414686825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5811028607479181,
            "auditor_fn_violation": 0.008126540893986497,
            "auditor_fp_violation": 0.004841751052214864,
            "ave_precision_score": 0.5722982882855144,
            "fpr": 0.05482456140350877,
            "logloss": 0.6937079209141471,
            "mae": 0.5000920182322723,
            "precision": 0.5535714285714286,
            "recall": 0.12627291242362526
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5280667721326968,
            "auditor_fn_violation": 0.007223922635036636,
            "auditor_fp_violation": 0.007404539752234592,
            "ave_precision_score": 0.5176647980107967,
            "fpr": 0.06037321624588365,
            "logloss": 0.693564567001007,
            "mae": 0.5000112737507512,
            "precision": 0.5378151260504201,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.4590714699123848,
            "auditor_fn_violation": 0.012592900275127742,
            "auditor_fp_violation": 0.019708192690753013,
            "ave_precision_score": 0.43824301825121287,
            "fpr": 0.24780701754385964,
            "logloss": 9.34854300972504,
            "mae": 0.5654600439165168,
            "precision": 0.5,
            "recall": 0.46028513238289204
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.4311732257946927,
            "auditor_fn_violation": 0.010576277937282037,
            "auditor_fp_violation": 0.017269092049553087,
            "ave_precision_score": 0.4070299145067501,
            "fpr": 0.25686059275521406,
            "logloss": 9.93225296427048,
            "mae": 0.5798204992172167,
            "precision": 0.4645308924485126,
            "recall": 0.43844492440604754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 20300,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.6343209797944573,
            "auditor_fn_violation": 0.004955425733376223,
            "auditor_fp_violation": 0.0006068466891694795,
            "ave_precision_score": 0.5620405097870732,
            "fpr": 0.0010964912280701754,
            "logloss": 1.007067633610776,
            "mae": 0.5073516527190804,
            "precision": 0.9090909090909091,
            "recall": 0.020366598778004074
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6078855715783181,
            "auditor_fn_violation": 0.006285073483912733,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5275261335532524,
            "fpr": 0.0,
            "logloss": 0.992652842157353,
            "mae": 0.4962972076415492,
            "precision": 1.0,
            "recall": 0.023758099352051837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8562851295616071,
            "auditor_fn_violation": 0.012137331618251332,
            "auditor_fp_violation": 0.013553777555527783,
            "ave_precision_score": 0.856824848541029,
            "fpr": 0.14473684210526316,
            "logloss": 0.854718474531894,
            "mae": 0.26752165806810646,
            "precision": 0.7577981651376147,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8568575341304175,
            "auditor_fn_violation": 0.01292814247747118,
            "auditor_fp_violation": 0.021848537713658467,
            "ave_precision_score": 0.857081444823478,
            "fpr": 0.15697036223929747,
            "logloss": 0.6601607171080558,
            "mae": 0.2624406038715475,
            "precision": 0.7317073170731707,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.872795285212626,
            "auditor_fn_violation": 0.027510540608139497,
            "auditor_fp_violation": 0.012287994332624914,
            "ave_precision_score": 0.8730686609730847,
            "fpr": 0.09978070175438597,
            "logloss": 0.48015505255545593,
            "mae": 0.3250729053867409,
            "precision": 0.8047210300429185,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8730514445749984,
            "auditor_fn_violation": 0.021968121803823206,
            "auditor_fp_violation": 0.02117472949662851,
            "ave_precision_score": 0.8732618794137468,
            "fpr": 0.10208562019758508,
            "logloss": 0.456920689802678,
            "mae": 0.31016623027828183,
            "precision": 0.8008565310492506,
            "recall": 0.8077753779697624
        }
    }
]