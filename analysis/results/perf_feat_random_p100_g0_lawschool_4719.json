[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8368749716263804,
            "auditor_fn_violation": 0.01176885696930718,
            "auditor_fp_violation": 0.019361795224403053,
            "ave_precision_score": 0.8371361560136532,
            "fpr": 0.125,
            "logloss": 0.7989279800294022,
            "mae": 0.2657748288259687,
            "precision": 0.7673469387755102,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8151287422628658,
            "auditor_fn_violation": 0.014044803967823077,
            "auditor_fp_violation": 0.013779990591187091,
            "ave_precision_score": 0.8158244461427362,
            "fpr": 0.13391877058177826,
            "logloss": 0.8501393726434945,
            "mae": 0.28270494380954314,
            "precision": 0.7404255319148936,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6294434418321855,
            "auditor_fn_violation": 0.002550291206631674,
            "auditor_fp_violation": 0.008047880985123143,
            "ave_precision_score": 0.5522660696681774,
            "fpr": 0.11074561403508772,
            "logloss": 0.75728745975115,
            "mae": 0.5031127805511156,
            "precision": 0.5860655737704918,
            "recall": 0.29124236252545826
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5580729228233958,
            "auditor_fn_violation": 0.01302060489386975,
            "auditor_fp_violation": 0.010212482358475774,
            "ave_precision_score": 0.5052780795540605,
            "fpr": 0.11855104281009879,
            "logloss": 0.7603675101386166,
            "mae": 0.5036269982154231,
            "precision": 0.4953271028037383,
            "recall": 0.22894168466522677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8507226718614702,
            "auditor_fn_violation": 0.004830367670704257,
            "auditor_fp_violation": 0.015798849856232033,
            "ave_precision_score": 0.8447281372626848,
            "fpr": 0.14035087719298245,
            "logloss": 0.5134690854302015,
            "mae": 0.3395098132130347,
            "precision": 0.7566539923954373,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8159593653683744,
            "auditor_fn_violation": 0.0047060999115679965,
            "auditor_fp_violation": 0.005885408499294341,
            "ave_precision_score": 0.8121499903047928,
            "fpr": 0.13391877058177826,
            "logloss": 0.5191482955232777,
            "mae": 0.3422433043595988,
            "precision": 0.7535353535353535,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7013631055701202,
            "auditor_fn_violation": 0.017610855039839928,
            "auditor_fp_violation": 0.04662561986915032,
            "ave_precision_score": 0.6374108235249452,
            "fpr": 0.29714912280701755,
            "logloss": 0.6861655807073854,
            "mae": 0.4692821216017923,
            "precision": 0.6083815028901735,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6377160434180049,
            "auditor_fn_violation": 0.021994200946909983,
            "auditor_fp_violation": 0.051836678689038726,
            "ave_precision_score": 0.5751157087009189,
            "fpr": 0.30954994511525796,
            "logloss": 0.7114854831264397,
            "mae": 0.4772098650409545,
            "precision": 0.5746606334841629,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7112942623035863,
            "auditor_fn_violation": 0.1331421731518205,
            "auditor_fp_violation": 0.10808382297787222,
            "ave_precision_score": 0.5899269105090034,
            "fpr": 0.17434210526315788,
            "logloss": 0.6807096797735638,
            "mae": 0.49090256296882506,
            "precision": 0.6302325581395349,
            "recall": 0.5519348268839104
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6614012678799708,
            "auditor_fn_violation": 0.12668773545317252,
            "auditor_fp_violation": 0.12088119413517327,
            "ave_precision_score": 0.5339048637081353,
            "fpr": 0.21405049396267836,
            "logloss": 0.6896946785046737,
            "mae": 0.4952569550923537,
            "precision": 0.5558086560364465,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6847518785676099,
            "auditor_fn_violation": 0.12758155572229965,
            "auditor_fp_violation": 0.11226663749635371,
            "ave_precision_score": 0.548161098717666,
            "fpr": 0.25877192982456143,
            "logloss": 0.6919189412229486,
            "mae": 0.4992864333223878,
            "precision": 0.5547169811320755,
            "recall": 0.5987780040733197
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.6456444211381006,
            "auditor_fn_violation": 0.12414620441780685,
            "auditor_fp_violation": 0.11951397600752706,
            "ave_precision_score": 0.5126933521376346,
            "fpr": 0.2579582875960483,
            "logloss": 0.692890658867666,
            "mae": 0.4997780864115735,
            "precision": 0.5164609053497943,
            "recall": 0.5421166306695464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.850152984898455,
            "auditor_fn_violation": 0.008762997105799121,
            "auditor_fp_violation": 0.016637496353710885,
            "ave_precision_score": 0.8503480462691159,
            "fpr": 0.41118421052631576,
            "logloss": 2.288842829738182,
            "mae": 0.42107638693172095,
            "precision": 0.5608899297423887,
            "recall": 0.9755600814663951
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.8274815449525572,
            "auditor_fn_violation": 0.007430184948541109,
            "auditor_fp_violation": 0.013549670691547744,
            "ave_precision_score": 0.8281338066944477,
            "fpr": 0.4270032930845225,
            "logloss": 2.3973807681358745,
            "mae": 0.4433954369808554,
            "precision": 0.5374554102259215,
            "recall": 0.9762419006479481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8339306081735958,
            "auditor_fn_violation": 0.001889270018222747,
            "auditor_fp_violation": 0.01795797391340585,
            "ave_precision_score": 0.8352963344013052,
            "fpr": 0.16885964912280702,
            "logloss": 0.5254114337179903,
            "mae": 0.30291443822518394,
            "precision": 0.7340241796200345,
            "recall": 0.8655804480651731
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7892618132142133,
            "auditor_fn_violation": 0.007482343234714659,
            "auditor_fp_violation": 0.01468166849615807,
            "ave_precision_score": 0.7905661117024853,
            "fpr": 0.17672886937431395,
            "logloss": 0.5717676778532403,
            "mae": 0.31738357944784606,
            "precision": 0.7180385288966725,
            "recall": 0.8855291576673866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7058354023627398,
            "auditor_fn_violation": 0.012126165719798477,
            "auditor_fp_violation": 0.0371140142517815,
            "ave_precision_score": 0.6966695864268921,
            "fpr": 0.23903508771929824,
            "logloss": 1.8194593860276838,
            "mae": 0.3200586426388479,
            "precision": 0.668693009118541,
            "recall": 0.8961303462321792
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6762995081931189,
            "auditor_fn_violation": 0.0018397650032124775,
            "auditor_fp_violation": 0.029880331660655502,
            "ave_precision_score": 0.6615014890366318,
            "fpr": 0.27991218441273324,
            "logloss": 2.08271204653872,
            "mae": 0.3366065855117574,
            "precision": 0.6210995542347697,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 4719,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5681419071404743,
            "auditor_fn_violation": 0.00012505806267196096,
            "auditor_fp_violation": 0.0033259365754052623,
            "ave_precision_score": 0.570023009081333,
            "fpr": 0.0712719298245614,
            "logloss": 0.7027324408694393,
            "mae": 0.49844944118440415,
            "precision": 0.5390070921985816,
            "recall": 0.15478615071283094
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5309293838503152,
            "auditor_fn_violation": 0.009770195332781728,
            "auditor_fp_violation": 0.011800219538968171,
            "ave_precision_score": 0.5322757417491039,
            "fpr": 0.07903402854006586,
            "logloss": 0.6994039367016323,
            "mae": 0.49867156668925,
            "precision": 0.48201438848920863,
            "recall": 0.1447084233261339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7627900049682931,
            "auditor_fn_violation": 0.0027334119412584412,
            "auditor_fp_violation": 0.003190502979539113,
            "ave_precision_score": 0.5396426614737795,
            "fpr": 0.4451754385964912,
            "logloss": 0.6923101195163427,
            "mae": 0.49758830457402947,
            "precision": 0.5396825396825397,
            "recall": 0.9694501018329938
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7533958646190306,
            "auditor_fn_violation": 0.0004054121334398627,
            "auditor_fp_violation": 0.00545907166379175,
            "ave_precision_score": 0.5151668689664074,
            "fpr": 0.4698133918770582,
            "logloss": 0.690409665827277,
            "mae": 0.49679908100781406,
            "precision": 0.5152887882219706,
            "recall": 0.9827213822894169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7731052979653473,
            "auditor_fn_violation": 0.004196144638582202,
            "auditor_fp_violation": 0.008073925907405098,
            "ave_precision_score": 0.774117133540877,
            "fpr": 0.11513157894736842,
            "logloss": 0.5705441715857812,
            "mae": 0.37108598074981974,
            "precision": 0.7770700636942676,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.749042898896548,
            "auditor_fn_violation": 0.0017307067684859672,
            "auditor_fp_violation": 0.011765916575192098,
            "ave_precision_score": 0.7477019162735502,
            "fpr": 0.1207464324917673,
            "logloss": 0.5747503309029185,
            "mae": 0.37429370869944767,
            "precision": 0.7560975609756098,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7277600683289445,
            "auditor_fn_violation": 0.011494175867366991,
            "auditor_fp_violation": 0.010954494311788977,
            "ave_precision_score": 0.7013868056688014,
            "fpr": 0.13267543859649122,
            "logloss": 0.670555741465136,
            "mae": 0.3924600228611668,
            "precision": 0.723744292237443,
            "recall": 0.6456211812627292
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7130231311368438,
            "auditor_fn_violation": 0.00514944534404318,
            "auditor_fp_violation": 0.01772483142543516,
            "ave_precision_score": 0.6575806144882127,
            "fpr": 0.15148188803512624,
            "logloss": 0.6930957605696193,
            "mae": 0.4017157319713827,
            "precision": 0.6745283018867925,
            "recall": 0.6177105831533477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7026659271827246,
            "auditor_fn_violation": 0.008731732590131134,
            "auditor_fp_violation": 0.010141892736592082,
            "ave_precision_score": 0.6713078228466025,
            "fpr": 0.15789473684210525,
            "logloss": 0.6142832992071263,
            "mae": 0.4208226579715285,
            "precision": 0.7142857142857143,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6913156598537229,
            "auditor_fn_violation": 0.0053272576832711785,
            "auditor_fp_violation": 0.015024698133918777,
            "ave_precision_score": 0.6537975082032519,
            "fpr": 0.16245883644346873,
            "logloss": 0.6050235316968914,
            "mae": 0.4163222270399234,
            "precision": 0.6991869918699187,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8738246644632646,
            "auditor_fn_violation": 0.016686318647943694,
            "auditor_fp_violation": 0.006599783306246616,
            "ave_precision_score": 0.8706664231801728,
            "fpr": 0.07785087719298246,
            "logloss": 0.5059578860659155,
            "mae": 0.3395617859225655,
            "precision": 0.8305489260143198,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8479223337896118,
            "auditor_fn_violation": 0.022447029704143983,
            "auditor_fp_violation": 0.013243394229261412,
            "ave_precision_score": 0.8419300975616456,
            "fpr": 0.09330406147091108,
            "logloss": 0.5123508488113772,
            "mae": 0.3399579270602777,
            "precision": 0.7906403940886699,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6357485373315408,
            "auditor_fn_violation": 0.012615232072033447,
            "auditor_fp_violation": 0.03323332083177064,
            "ave_precision_score": 0.6377326320108381,
            "fpr": 0.2719298245614035,
            "logloss": 0.648858233039864,
            "mae": 0.4315918486467318,
            "precision": 0.6363636363636364,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6277844650042159,
            "auditor_fn_violation": 0.007050851958188022,
            "auditor_fp_violation": 0.04338099811823743,
            "ave_precision_score": 0.6290414109342739,
            "fpr": 0.3018660812294182,
            "logloss": 0.6584855529489019,
            "mae": 0.4418039378821523,
            "precision": 0.5967741935483871,
            "recall": 0.8790496760259179
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8711044718576946,
            "auditor_fn_violation": 0.005174277343052131,
            "auditor_fp_violation": 0.008594824353044135,
            "ave_precision_score": 0.8617226023222163,
            "fpr": 0.08662280701754387,
            "logloss": 0.49037108370620736,
            "mae": 0.30388807075653684,
            "precision": 0.8145539906103286,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8590487432162673,
            "auditor_fn_violation": 0.018094183639842297,
            "auditor_fp_violation": 0.01006546965657833,
            "ave_precision_score": 0.848018702563979,
            "fpr": 0.08342480790340286,
            "logloss": 0.490255702437238,
            "mae": 0.3017445844644118,
            "precision": 0.8155339805825242,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.8376072803324329,
            "auditor_fn_violation": 0.00024788294565334393,
            "auditor_fp_violation": 0.0008855273575863652,
            "ave_precision_score": 0.8386963592265613,
            "fpr": 0.006578947368421052,
            "logloss": 8.473487528197568,
            "mae": 0.538027653980595,
            "precision": 0.5,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.8195118089082258,
            "auditor_fn_violation": 0.002152714720253778,
            "auditor_fp_violation": 0.0012888113533009258,
            "ave_precision_score": 0.8204574059321185,
            "fpr": 0.006586169045005488,
            "logloss": 7.989582348347586,
            "mae": 0.5072063594367463,
            "precision": 0.5384615384615384,
            "recall": 0.01511879049676026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7811553060663609,
            "auditor_fn_violation": 0.010714796155357849,
            "auditor_fp_violation": 0.030037608867775144,
            "ave_precision_score": 0.6366490936623831,
            "fpr": 0.23574561403508773,
            "logloss": 0.6487375151398245,
            "mae": 0.4342656525570834,
            "precision": 0.6469622331691297,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7609987648626523,
            "auditor_fn_violation": 0.008546846438893013,
            "auditor_fp_violation": 0.041075348910145845,
            "ave_precision_score": 0.5954511373633817,
            "fpr": 0.27442371020856204,
            "logloss": 0.675253567745522,
            "mae": 0.4448625510057555,
            "precision": 0.6044303797468354,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8764965997726836,
            "auditor_fn_violation": 0.011625933469110672,
            "auditor_fp_violation": 0.0069175313580864305,
            "ave_precision_score": 0.8766709004279672,
            "fpr": 0.05701754385964912,
            "logloss": 0.5083050673777695,
            "mae": 0.33153469867089336,
            "precision": 0.8620689655172413,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8522043806059361,
            "auditor_fn_violation": 0.008162771786160514,
            "auditor_fp_violation": 0.004167810098792538,
            "ave_precision_score": 0.8524756126893702,
            "fpr": 0.05378704720087816,
            "logloss": 0.5019017755788975,
            "mae": 0.33159213666584336,
            "precision": 0.8607954545454546,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8377644848816039,
            "auditor_fn_violation": 0.00591569300032158,
            "auditor_fp_violation": 0.008344793099137392,
            "ave_precision_score": 0.8295089058474675,
            "fpr": 0.09978070175438597,
            "logloss": 0.5430256243715539,
            "mae": 0.32478635447085485,
            "precision": 0.7903225806451613,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8171410322154883,
            "auditor_fn_violation": 0.007607997287769126,
            "auditor_fp_violation": 0.0021561862944958483,
            "ave_precision_score": 0.8090018419096213,
            "fpr": 0.08781558726673985,
            "logloss": 0.531419861957392,
            "mae": 0.32017883861167534,
            "precision": 0.7974683544303798,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7953094681553592,
            "auditor_fn_violation": 0.01260853253296174,
            "auditor_fp_violation": 0.024883318748176866,
            "ave_precision_score": 0.7489964438961371,
            "fpr": 0.13706140350877194,
            "logloss": 4.444688655778026,
            "mae": 0.293024901967952,
            "precision": 0.7479838709677419,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.764777643710535,
            "auditor_fn_violation": 0.011567285374579472,
            "auditor_fp_violation": 0.019023443625529244,
            "ave_precision_score": 0.7083751378965738,
            "fpr": 0.16465422612513722,
            "logloss": 5.0419986941169865,
            "mae": 0.3105742726345105,
            "precision": 0.696969696969697,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7104832743517481,
            "auditor_fn_violation": 0.008937185121663629,
            "auditor_fp_violation": 0.001265783222902865,
            "ave_precision_score": 0.7251250491122164,
            "fpr": 0.09868421052631579,
            "logloss": 0.5879573836912885,
            "mae": 0.36311127993752035,
            "precision": 0.7935779816513762,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.6948656883534721,
            "auditor_fn_violation": 0.004338621077163453,
            "auditor_fp_violation": 0.005645287752861849,
            "ave_precision_score": 0.7052746015610011,
            "fpr": 0.09659714599341383,
            "logloss": 0.5815485762477873,
            "mae": 0.36103410933792396,
            "precision": 0.7879518072289157,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7132753169500855,
            "auditor_fn_violation": 0.0067017722514024405,
            "auditor_fp_violation": 0.012905258990707177,
            "ave_precision_score": 0.7148049606249248,
            "fpr": 0.17105263157894737,
            "logloss": 2.118637547153273,
            "mae": 0.4058456186960302,
            "precision": 0.6462585034013606,
            "recall": 0.5804480651731161
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6685019175421354,
            "auditor_fn_violation": 0.009258095795805056,
            "auditor_fp_violation": 0.024043927395326962,
            "ave_precision_score": 0.6700162055254928,
            "fpr": 0.1964873765093304,
            "logloss": 2.1761945732937775,
            "mae": 0.4203698577358337,
            "precision": 0.5856481481481481,
            "recall": 0.5464362850971922
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5418488950997943,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5428669916760366,
            "fpr": 0.4616228070175439,
            "logloss": 0.7014666461985177,
            "mae": 0.4990009753066197,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5050154911837549,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5072102623040594,
            "fpr": 0.49176728869374314,
            "logloss": 0.6994099782513957,
            "mae": 0.5000828457454426,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8074162307764131,
            "auditor_fn_violation": 0.005754904062600505,
            "auditor_fp_violation": 0.013163103721298499,
            "ave_precision_score": 0.8002880345943635,
            "fpr": 0.07017543859649122,
            "logloss": 0.6196891097810012,
            "mae": 0.3497897877629536,
            "precision": 0.8341968911917098,
            "recall": 0.6558044806517311
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7644278776615129,
            "auditor_fn_violation": 0.003058372234721778,
            "auditor_fp_violation": 0.00789213188019445,
            "ave_precision_score": 0.7615716389570302,
            "fpr": 0.06256860592755215,
            "logloss": 0.6250251383941734,
            "mae": 0.3477129760498854,
            "precision": 0.8362068965517241,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8665143404705987,
            "auditor_fn_violation": 0.003731643262943506,
            "auditor_fp_violation": 0.008084343876317873,
            "ave_precision_score": 0.8542480417927832,
            "fpr": 0.09100877192982457,
            "logloss": 0.4950017701411243,
            "mae": 0.30107190937473716,
            "precision": 0.8122171945701357,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8505282407565123,
            "auditor_fn_violation": 0.005327257683271176,
            "auditor_fp_violation": 0.0020459267680727655,
            "ave_precision_score": 0.8386925672487151,
            "fpr": 0.09330406147091108,
            "logloss": 0.4870600972039311,
            "mae": 0.29891811011095343,
            "precision": 0.8023255813953488,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8622191468924829,
            "auditor_fn_violation": 0.022465787687140467,
            "auditor_fp_violation": 0.011308705254823524,
            "ave_precision_score": 0.8624369081344472,
            "fpr": 0.08333333333333333,
            "logloss": 0.7756865995457571,
            "mae": 0.31926647108537776,
            "precision": 0.8207547169811321,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8122464509967416,
            "auditor_fn_violation": 0.036980224897046665,
            "auditor_fp_violation": 0.020444566410537872,
            "ave_precision_score": 0.81280520267501,
            "fpr": 0.0845225027442371,
            "logloss": 1.1155576237393536,
            "mae": 0.3319548907758219,
            "precision": 0.8020565552699229,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.8301828494127875,
            "auditor_fn_violation": 0.002349305034480294,
            "auditor_fp_violation": 0.009561090969704568,
            "ave_precision_score": 0.8375145066445033,
            "fpr": 0.2850877192982456,
            "logloss": 0.605787909276441,
            "mae": 0.4357029443735404,
            "precision": 0.6408839779005525,
            "recall": 0.945010183299389
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7972914458110038,
            "auditor_fn_violation": 0.005237166098062322,
            "auditor_fp_violation": 0.012402971616747707,
            "ave_precision_score": 0.8159034030779438,
            "fpr": 0.31394072447859495,
            "logloss": 0.62148687008225,
            "mae": 0.4454558497408771,
            "precision": 0.6049723756906077,
            "recall": 0.9460043196544277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6782688598907587,
            "auditor_fn_violation": 0.0065432164933719224,
            "auditor_fp_violation": 0.004701108471892321,
            "ave_precision_score": 0.651343187434861,
            "fpr": 0.23135964912280702,
            "logloss": 2.85888835802777,
            "mae": 0.32871452909845783,
            "precision": 0.6758832565284179,
            "recall": 0.8961303462321792
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6522392494032058,
            "auditor_fn_violation": 0.015811073204154643,
            "auditor_fp_violation": 0.013211541477183628,
            "ave_precision_score": 0.6262980640576095,
            "fpr": 0.2502744237102086,
            "logloss": 2.90927285963169,
            "mae": 0.35118299434339123,
            "precision": 0.6431924882629108,
            "recall": 0.8876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8539077792813765,
            "auditor_fn_violation": 0.010250294779719157,
            "auditor_fp_violation": 0.00677688877776389,
            "ave_precision_score": 0.8321889653551856,
            "fpr": 0.08223684210526316,
            "logloss": 0.5619151066053051,
            "mae": 0.340302741922961,
            "precision": 0.8222748815165877,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8455193089920958,
            "auditor_fn_violation": 0.009627945461399315,
            "auditor_fp_violation": 0.002918202132664261,
            "ave_precision_score": 0.8226930230698202,
            "fpr": 0.07574094401756312,
            "logloss": 0.5428723213870792,
            "mae": 0.3311545737292188,
            "precision": 0.8217054263565892,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6527510953808711,
            "auditor_fn_violation": 0.01701906242183871,
            "auditor_fp_violation": 0.02855565278993209,
            "ave_precision_score": 0.6314369654351839,
            "fpr": 0.1875,
            "logloss": 2.672027814603611,
            "mae": 0.37271315929581506,
            "precision": 0.6862385321100918,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6251560537287251,
            "auditor_fn_violation": 0.013957083213803928,
            "auditor_fp_violation": 0.04298161361141603,
            "ave_precision_score": 0.5918459654650821,
            "fpr": 0.1942919868276619,
            "logloss": 3.486069642683823,
            "mae": 0.37965461625526536,
            "precision": 0.6728280961182994,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7814247520316848,
            "auditor_fn_violation": 0.014131561081930893,
            "auditor_fp_violation": 0.02354981872734092,
            "ave_precision_score": 0.7309556064254761,
            "fpr": 0.1524122807017544,
            "logloss": 4.645245474314856,
            "mae": 0.31758391823319304,
            "precision": 0.7169042769857433,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7552872162610922,
            "auditor_fn_violation": 0.014208391319912852,
            "auditor_fp_violation": 0.019285616277246356,
            "ave_precision_score": 0.6955405432242678,
            "fpr": 0.1877058177826564,
            "logloss": 5.185262832195177,
            "mae": 0.32653586312553445,
            "precision": 0.6620553359683794,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7471892918517571,
            "auditor_fn_violation": 0.007628541822989247,
            "auditor_fp_violation": 0.030451723132058173,
            "ave_precision_score": 0.7324178003335555,
            "fpr": 0.2730263157894737,
            "logloss": 1.5771030417368495,
            "mae": 0.3447421306760557,
            "precision": 0.6468085106382979,
            "recall": 0.9287169042769857
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.6679542613686886,
            "auditor_fn_violation": 0.012781150943709355,
            "auditor_fp_violation": 0.03287204014426848,
            "ave_precision_score": 0.6516524141937104,
            "fpr": 0.3018660812294182,
            "logloss": 2.0229746355374894,
            "mae": 0.3786947894044032,
            "precision": 0.6031746031746031,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6796117407922209,
            "auditor_fn_violation": 0.013403544502804877,
            "auditor_fp_violation": 0.020872400716756265,
            "ave_precision_score": 0.6810048499569957,
            "fpr": 0.24561403508771928,
            "logloss": 0.6860930465814036,
            "mae": 0.40816061151328314,
            "precision": 0.6616314199395771,
            "recall": 0.8920570264765784
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6948435839162022,
            "auditor_fn_violation": 0.01390255409644067,
            "auditor_fp_violation": 0.024627077779520164,
            "ave_precision_score": 0.696592832665511,
            "fpr": 0.2711306256860593,
            "logloss": 0.6571504498842372,
            "mae": 0.4113323968864822,
            "precision": 0.6251896813353566,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8434325488759676,
            "auditor_fn_violation": 0.006949655197055782,
            "auditor_fp_violation": 0.012517189648706089,
            "ave_precision_score": 0.7382977988134385,
            "fpr": 0.08771929824561403,
            "logloss": 0.5446548080655453,
            "mae": 0.3566167351315942,
            "precision": 0.815668202764977,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.83293476963454,
            "auditor_fn_violation": 0.001434352869772614,
            "auditor_fp_violation": 0.0055031754743609905,
            "ave_precision_score": 0.7207893764513362,
            "fpr": 0.09001097694840834,
            "logloss": 0.5389426335964363,
            "mae": 0.3542581507946343,
            "precision": 0.8028846153846154,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7974777318523051,
            "auditor_fn_violation": 0.00856871047271948,
            "auditor_fp_violation": 0.02604231778972372,
            "ave_precision_score": 0.760966291135273,
            "fpr": 0.16337719298245615,
            "logloss": 3.924593517342581,
            "mae": 0.28566469432354924,
            "precision": 0.7214953271028037,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7718524947256383,
            "auditor_fn_violation": 0.010649773704162941,
            "auditor_fp_violation": 0.019912870472008785,
            "ave_precision_score": 0.7289743340403476,
            "fpr": 0.19209659714599342,
            "logloss": 4.383087952182398,
            "mae": 0.30477944064758816,
            "precision": 0.6735074626865671,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8351652650309814,
            "auditor_fn_violation": 0.006335530782148856,
            "auditor_fp_violation": 0.01914562236946286,
            "ave_precision_score": 0.8354411178421701,
            "fpr": 0.11951754385964912,
            "logloss": 0.7546465459174491,
            "mae": 0.2683912582155173,
            "precision": 0.7757201646090535,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8152206134831415,
            "auditor_fn_violation": 0.006043248702562635,
            "auditor_fp_violation": 0.011721812764622867,
            "ave_precision_score": 0.8158654815046854,
            "fpr": 0.13611416026344675,
            "logloss": 0.7912346684988536,
            "mae": 0.28258744671367364,
            "precision": 0.7405857740585774,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8720969737218237,
            "auditor_fn_violation": 0.017458998820881134,
            "auditor_fp_violation": 0.010808642747010046,
            "ave_precision_score": 0.8666792965651327,
            "fpr": 0.1074561403508772,
            "logloss": 0.4797517748693746,
            "mae": 0.3215312141671842,
            "precision": 0.7945492662473794,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8545791121755052,
            "auditor_fn_violation": 0.01928671172826482,
            "auditor_fp_violation": 0.021757879880821705,
            "ave_precision_score": 0.8480486038687339,
            "fpr": 0.1141602634467618,
            "logloss": 0.49095740046463987,
            "mae": 0.3229839868851734,
            "precision": 0.776824034334764,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.749494325039588,
            "auditor_fn_violation": 0.008814360238682246,
            "auditor_fp_violation": 0.0122958078093095,
            "ave_precision_score": 0.8513973920989192,
            "fpr": 0.08881578947368421,
            "logloss": 0.4886816959242075,
            "mae": 0.3158592370240704,
            "precision": 0.8146453089244852,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8463837433965661,
            "auditor_fn_violation": 0.001560006922827077,
            "auditor_fp_violation": 0.003910537870472014,
            "ave_precision_score": 0.827552744418048,
            "fpr": 0.09001097694840834,
            "logloss": 0.4933263525800051,
            "mae": 0.3180276804351126,
            "precision": 0.8038277511961722,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5706711320578592,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5720889739031195,
            "fpr": 0.4616228070175439,
            "logloss": 0.7425556907805463,
            "mae": 0.48504094910203366,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5503951089960736,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5520820367453196,
            "fpr": 0.49176728869374314,
            "logloss": 0.7570040679333614,
            "mae": 0.4951385402260706,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 4719,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.701372176157124,
            "auditor_fn_violation": 0.02103878586486584,
            "auditor_fp_violation": 0.003320727590948872,
            "ave_precision_score": 0.7058410936041312,
            "fpr": 0.07017543859649122,
            "logloss": 1.1675670691706599,
            "mae": 0.4396459245978979,
            "precision": 0.7538461538461538,
            "recall": 0.39918533604887985
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6523827642125942,
            "auditor_fn_violation": 0.012885467516056468,
            "auditor_fp_violation": 0.006157381997804613,
            "ave_precision_score": 0.657300692811339,
            "fpr": 0.07793633369923161,
            "logloss": 1.1258485589673877,
            "mae": 0.44231047700200143,
            "precision": 0.6978723404255319,
            "recall": 0.3542116630669546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8216763105886664,
            "mae": 0.515942236964117,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7950024826217468,
            "mae": 0.5034099130285035,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6742695206852822,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5683276383508464,
            "fpr": 0.15460526315789475,
            "logloss": 0.6848446325585571,
            "mae": 0.49282979821426826,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6376071758101569,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5350247356207626,
            "fpr": 0.14270032930845225,
            "logloss": 0.6881318035291214,
            "mae": 0.4948205731310253,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8691839804136626,
            "auditor_fn_violation": 0.0052010754993389785,
            "auditor_fp_violation": 0.016525503187898492,
            "ave_precision_score": 0.8689302194187603,
            "fpr": 0.13706140350877194,
            "logloss": 0.49212467781695457,
            "mae": 0.31960041239334824,
            "precision": 0.7659176029962547,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8359004956147339,
            "auditor_fn_violation": 0.0015054778054638172,
            "auditor_fp_violation": 0.014534655794260625,
            "ave_precision_score": 0.836059771445572,
            "fpr": 0.1394072447859495,
            "logloss": 0.5074441617720569,
            "mae": 0.3309638711872268,
            "precision": 0.751953125,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8235387806558504,
            "auditor_fn_violation": 0.010223496623432311,
            "auditor_fp_violation": 0.025823540442555328,
            "ave_precision_score": 0.8239038971416321,
            "fpr": 0.17324561403508773,
            "logloss": 0.780442842155785,
            "mae": 0.2820968806258941,
            "precision": 0.7322033898305085,
            "recall": 0.879837067209776
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8054494056641025,
            "auditor_fn_violation": 0.013971308200942173,
            "auditor_fp_violation": 0.012192253410694687,
            "ave_precision_score": 0.8058694013228211,
            "fpr": 0.18221734357848518,
            "logloss": 0.8434517732603785,
            "mae": 0.30071028993331084,
            "precision": 0.7082601054481547,
            "recall": 0.8704103671706264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.6675955784622511,
            "auditor_fn_violation": 0.005766069961053347,
            "auditor_fp_violation": 0.020773430012084843,
            "ave_precision_score": 0.6691373859488331,
            "fpr": 0.21600877192982457,
            "logloss": 0.9419049772642882,
            "mae": 0.33042438323473594,
            "precision": 0.6882911392405063,
            "recall": 0.8859470468431772
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6462520461927778,
            "auditor_fn_violation": 0.003513571823145476,
            "auditor_fp_violation": 0.011996236474831428,
            "ave_precision_score": 0.6478022588863279,
            "fpr": 0.2502744237102086,
            "logloss": 0.9632704885178641,
            "mae": 0.3529976461549349,
            "precision": 0.6369426751592356,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 4719,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7440017860316858,
            "auditor_fn_violation": 0.025612337871154477,
            "auditor_fp_violation": 0.0134339709130308,
            "ave_precision_score": 0.6140127132501692,
            "fpr": 0.17653508771929824,
            "logloss": 0.6611708654478061,
            "mae": 0.4670861583987349,
            "precision": 0.6581740976645435,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7302774640968274,
            "auditor_fn_violation": 0.02306107498227803,
            "auditor_fp_violation": 0.019072447859495065,
            "ave_precision_score": 0.5911499978294632,
            "fpr": 0.18441273326015367,
            "logloss": 0.6576821437055084,
            "mae": 0.46538558039654754,
            "precision": 0.6379310344827587,
            "recall": 0.6393088552915767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.4295166172724666,
            "auditor_fn_violation": 0.101678904491371,
            "auditor_fp_violation": 0.061020648414385134,
            "ave_precision_score": 0.6146122316953888,
            "fpr": 0.17434210526315788,
            "logloss": 0.6664083013717795,
            "mae": 0.4609027838889967,
            "precision": 0.6565874730021598,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.4231356290360897,
            "auditor_fn_violation": 0.0872039128197955,
            "auditor_fp_violation": 0.060887760702524704,
            "ave_precision_score": 0.5893546969267704,
            "fpr": 0.1690450054884742,
            "logloss": 0.6653019591819691,
            "mae": 0.46075502142686353,
            "precision": 0.6401869158878505,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8682999985746049,
            "auditor_fn_violation": 0.003713777825418941,
            "auditor_fp_violation": 0.013616285369004461,
            "ave_precision_score": 0.8683492878578025,
            "fpr": 0.09978070175438597,
            "logloss": 0.48932658145851604,
            "mae": 0.32473366341774207,
            "precision": 0.8,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8304654242904096,
            "auditor_fn_violation": 0.004943183030538681,
            "auditor_fp_violation": 0.008090599027755996,
            "ave_precision_score": 0.8308207570711237,
            "fpr": 0.10318331503841932,
            "logloss": 0.5032919498031957,
            "mae": 0.3321880086168696,
            "precision": 0.7844036697247706,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7797292025397309,
            "auditor_fn_violation": 0.014404009004180518,
            "auditor_fp_violation": 0.02743051214735176,
            "ave_precision_score": 0.7372058554074639,
            "fpr": 0.18421052631578946,
            "logloss": 4.178116844918614,
            "mae": 0.3325285380605712,
            "precision": 0.6894639556377079,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7514055266599723,
            "auditor_fn_violation": 0.02037492324434023,
            "auditor_fp_violation": 0.020478869374313948,
            "ave_precision_score": 0.6992053476877341,
            "fpr": 0.20417124039517015,
            "logloss": 4.859716291686909,
            "mae": 0.3491027249611548,
            "precision": 0.6568265682656826,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8694185467699007,
            "auditor_fn_violation": 0.004184978740129348,
            "auditor_fp_violation": 0.005315768637746388,
            "ave_precision_score": 0.8695950182480312,
            "fpr": 0.18530701754385964,
            "logloss": 0.5105722799506054,
            "mae": 0.3252214910452287,
            "precision": 0.7197346600331676,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8335240318887953,
            "auditor_fn_violation": 0.005969752935681724,
            "auditor_fp_violation": 0.004356476399560924,
            "ave_precision_score": 0.8342167269489625,
            "fpr": 0.19099890230515917,
            "logloss": 0.5326573369969223,
            "mae": 0.33754246166889873,
            "precision": 0.7015437392795884,
            "recall": 0.8833693304535637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8526460212934538,
            "auditor_fn_violation": 0.028484206953228286,
            "auditor_fp_violation": 0.012621369337833897,
            "ave_precision_score": 0.8538288773261942,
            "fpr": 0.06578947368421052,
            "logloss": 0.6742159326464778,
            "mae": 0.316508242293616,
            "precision": 0.8469387755102041,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8046105344058605,
            "auditor_fn_violation": 0.041591491561026386,
            "auditor_fp_violation": 0.01691626156499922,
            "ave_precision_score": 0.805028373854844,
            "fpr": 0.06256860592755215,
            "logloss": 0.9238651971032036,
            "mae": 0.32639144225427086,
            "precision": 0.8352601156069365,
            "recall": 0.6241900647948164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.6856743043602713,
            "auditor_fn_violation": 0.0006252903133597841,
            "auditor_fp_violation": 0.0037504688086010753,
            "ave_precision_score": 0.6872416915656315,
            "fpr": 0.009868421052631578,
            "logloss": 8.006482723323076,
            "mae": 0.5471480455874947,
            "precision": 0.1,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.6594769076984432,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.001609789085777011,
            "ave_precision_score": 0.6612824980190113,
            "fpr": 0.003293084522502744,
            "logloss": 7.52370942627963,
            "mae": 0.5115253728149699,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6919874020218789,
            "mae": 0.4993480055740005,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.693011756527335,
            "mae": 0.4998601335463749,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5864430249451104,
            "auditor_fn_violation": 0.0015252617286597493,
            "auditor_fp_violation": 0.0025758428136850448,
            "ave_precision_score": 0.5872583004404874,
            "fpr": 0.046052631578947366,
            "logloss": 3.9924891972553502,
            "mae": 0.5025522653912186,
            "precision": 0.6379310344827587,
            "recall": 0.15071283095723015
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5563331917767775,
            "auditor_fn_violation": 0.004992970485522527,
            "auditor_fp_violation": 0.0026070252469813397,
            "ave_precision_score": 0.5577622969826418,
            "fpr": 0.048298572996706916,
            "logloss": 4.196121405878251,
            "mae": 0.479618562421624,
            "precision": 0.5849056603773585,
            "recall": 0.13390928725701945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7498849985962506,
            "auditor_fn_violation": 0.011067638546468006,
            "auditor_fp_violation": 0.023495124390548818,
            "ave_precision_score": 0.750112258339859,
            "fpr": 0.13596491228070176,
            "logloss": 0.7240232271233484,
            "mae": 0.35095233953427196,
            "precision": 0.7225950782997763,
            "recall": 0.6578411405295316
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7150132521583644,
            "auditor_fn_violation": 0.00808453435690019,
            "auditor_fp_violation": 0.016190998902305163,
            "ave_precision_score": 0.715719961045224,
            "fpr": 0.15367727771679474,
            "logloss": 0.7391702399699112,
            "mae": 0.3543556729243694,
            "precision": 0.6943231441048034,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.84078385578937,
            "auditor_fn_violation": 0.00451102297495266,
            "auditor_fp_violation": 0.01210828436887944,
            "ave_precision_score": 0.8410591454097953,
            "fpr": 0.10307017543859649,
            "logloss": 0.6867035961737404,
            "mae": 0.28643944681523653,
            "precision": 0.793859649122807,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8165313340879288,
            "auditor_fn_violation": 0.005789569765264014,
            "auditor_fp_violation": 0.011290575505723694,
            "ave_precision_score": 0.816941988245479,
            "fpr": 0.10428100987925357,
            "logloss": 0.7014247147461465,
            "mae": 0.2823436454786743,
            "precision": 0.7835990888382688,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8370178291527155,
            "auditor_fn_violation": 0.011295422874906215,
            "auditor_fp_violation": 0.011121181814393467,
            "ave_precision_score": 0.8369036513826185,
            "fpr": 0.08114035087719298,
            "logloss": 4.443880914585811,
            "mae": 0.301205214853972,
            "precision": 0.8121827411167513,
            "recall": 0.6517311608961304
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8082183566340568,
            "auditor_fn_violation": 0.006512673278124581,
            "auditor_fp_violation": 0.007429041869217503,
            "ave_precision_score": 0.8094011329542152,
            "fpr": 0.06805708013172337,
            "logloss": 4.383535792798772,
            "mae": 0.28708940706871444,
            "precision": 0.8243626062322946,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6665520175810928,
            "auditor_fn_violation": 0.009616071747597103,
            "auditor_fp_violation": 0.005860107513439182,
            "ave_precision_score": 0.6679073412402964,
            "fpr": 0.10307017543859649,
            "logloss": 0.9959288959447696,
            "mae": 0.42215066174404664,
            "precision": 0.7388888888888889,
            "recall": 0.5417515274949084
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6844549054545364,
            "auditor_fn_violation": 0.004710841573947416,
            "auditor_fp_violation": 0.0014603261721812808,
            "ave_precision_score": 0.6843354399239747,
            "fpr": 0.07464324917672886,
            "logloss": 0.8486696017851764,
            "mae": 0.407002851653243,
            "precision": 0.7687074829931972,
            "recall": 0.48812095032397407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8117329607441552,
            "auditor_fn_violation": 0.005587415585807697,
            "auditor_fp_violation": 0.0050501104304704805,
            "ave_precision_score": 0.8108454492207318,
            "fpr": 0.09758771929824561,
            "logloss": 0.5374594466193839,
            "mae": 0.3266582913745783,
            "precision": 0.8035320088300221,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.7806864514821693,
            "auditor_fn_violation": 0.006228173535359762,
            "auditor_fp_violation": 0.005650188176258433,
            "ave_precision_score": 0.7786047764597753,
            "fpr": 0.10318331503841932,
            "logloss": 0.5491456085192187,
            "mae": 0.3260574384166171,
            "precision": 0.7868480725623582,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5834673457558464,
            "auditor_fn_violation": 0.059413745667631405,
            "auditor_fp_violation": 0.05274617660540902,
            "ave_precision_score": 0.5854190010414593,
            "fpr": 0.2850877192982456,
            "logloss": 0.6769613780823903,
            "mae": 0.4858762515676126,
            "precision": 0.5666666666666667,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5678047082170243,
            "auditor_fn_violation": 0.06010768315263649,
            "auditor_fp_violation": 0.055504645601379965,
            "ave_precision_score": 0.5690207277549452,
            "fpr": 0.28869374313940727,
            "logloss": 0.7468419373584789,
            "mae": 0.4842434582902624,
            "precision": 0.5252707581227437,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6148756892284022,
            "auditor_fn_violation": 0.06515525065208848,
            "auditor_fp_violation": 0.04722465308163522,
            "ave_precision_score": 0.6225464097605854,
            "fpr": 0.2050438596491228,
            "logloss": 0.7621610605347159,
            "mae": 0.4561764319966498,
            "precision": 0.5987124463519313,
            "recall": 0.5682281059063137
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6228365140037719,
            "auditor_fn_violation": 0.06432539183912488,
            "auditor_fp_violation": 0.0515034498980712,
            "ave_precision_score": 0.6257780661220879,
            "fpr": 0.1877058177826564,
            "logloss": 0.7167088559414714,
            "mae": 0.43571356052592086,
            "precision": 0.6059907834101382,
            "recall": 0.5680345572354212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8366169204275518,
            "auditor_fn_violation": 0.007648640440204383,
            "auditor_fp_violation": 0.012665645705713218,
            "ave_precision_score": 0.8177669218289407,
            "fpr": 0.08991228070175439,
            "logloss": 0.573393519947929,
            "mae": 0.34905321886847224,
            "precision": 0.8066037735849056,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8338346270809297,
            "auditor_fn_violation": 0.0070603352829468535,
            "auditor_fp_violation": 0.009006978202916738,
            "ave_precision_score": 0.8107675852956685,
            "fpr": 0.08342480790340286,
            "logloss": 0.5414551356088363,
            "mae": 0.3376577385797336,
            "precision": 0.8109452736318408,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8272102105135511,
            "auditor_fn_violation": 0.00747668560403045,
            "auditor_fp_violation": 0.008032254031753968,
            "ave_precision_score": 0.8278385009896547,
            "fpr": 0.08881578947368421,
            "logloss": 0.5351271889783045,
            "mae": 0.35671116817301435,
            "precision": 0.7954545454545454,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8112480172626909,
            "auditor_fn_violation": 0.0161785520385592,
            "auditor_fp_violation": 0.006110827975537088,
            "ave_precision_score": 0.8120647129405799,
            "fpr": 0.0801317233809001,
            "logloss": 0.5373874264003939,
            "mae": 0.3583912106535503,
            "precision": 0.7949438202247191,
            "recall": 0.6112311015118791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7679693213270375,
            "auditor_fn_violation": 0.0022733769250008937,
            "auditor_fp_violation": 0.002622723673792561,
            "ave_precision_score": 0.5488610791873598,
            "fpr": 0.4342105263157895,
            "logloss": 14.873155444932559,
            "mae": 0.4487875553926355,
            "precision": 0.5463917525773195,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7530104738189382,
            "auditor_fn_violation": 0.0029564264935643784,
            "auditor_fp_violation": 0.004628449898071201,
            "ave_precision_score": 0.5195772438977894,
            "fpr": 0.45773874862788144,
            "logloss": 15.79990540654867,
            "mae": 0.47628085596566666,
            "precision": 0.5206896551724138,
            "recall": 0.978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.853644701219727,
            "auditor_fn_violation": 0.006949655197055782,
            "auditor_fp_violation": 0.012517189648706089,
            "ave_precision_score": 0.7785306954783648,
            "fpr": 0.08771929824561403,
            "logloss": 0.5259416040824811,
            "mae": 0.3470535772084667,
            "precision": 0.815668202764977,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8406379745673933,
            "auditor_fn_violation": 0.001434352869772614,
            "auditor_fp_violation": 0.0055031754743609905,
            "ave_precision_score": 0.7587338193399746,
            "fpr": 0.09001097694840834,
            "logloss": 0.5220502878007506,
            "mae": 0.3471661100959411,
            "precision": 0.8028846153846154,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.779607486363761,
            "auditor_fn_violation": 0.0066481759388287475,
            "auditor_fp_violation": 0.024706213276659585,
            "ave_precision_score": 0.6782085715298763,
            "fpr": 0.15350877192982457,
            "logloss": 0.6287411755858165,
            "mae": 0.43615828551226415,
            "precision": 0.7171717171717171,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7588911667970654,
            "auditor_fn_violation": 0.011740356051428074,
            "auditor_fp_violation": 0.0164703230359103,
            "ave_precision_score": 0.6389988357561844,
            "fpr": 0.18660812294182216,
            "logloss": 0.6259507174977827,
            "mae": 0.43975176770817287,
            "precision": 0.6666666666666666,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8554982215208781,
            "auditor_fn_violation": 0.005900060742487588,
            "auditor_fp_violation": 0.014639850814685173,
            "ave_precision_score": 0.843457694351472,
            "fpr": 0.08552631578947369,
            "logloss": 0.5184005044453016,
            "mae": 0.31019907069469155,
            "precision": 0.8147268408551069,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8479438559161196,
            "auditor_fn_violation": 0.0038028132282897226,
            "auditor_fp_violation": 0.0054198682766191005,
            "ave_precision_score": 0.8353070217133518,
            "fpr": 0.08342480790340286,
            "logloss": 0.4945427853061892,
            "mae": 0.305794061197027,
            "precision": 0.812807881773399,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6917737070435523,
            "mae": 0.4992064667636888,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930204922398547,
            "mae": 0.4998297705085034,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7982357300402352,
            "auditor_fn_violation": 0.0033520027155465046,
            "auditor_fp_violation": 0.019202921198483148,
            "ave_precision_score": 0.7803381334998394,
            "fpr": 0.13048245614035087,
            "logloss": 2.4071678559603122,
            "mae": 0.26885954288801656,
            "precision": 0.7634194831013916,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.776425325314508,
            "auditor_fn_violation": 0.004677649937291517,
            "auditor_fp_violation": 0.01030804061470912,
            "ave_precision_score": 0.7579085651184567,
            "fpr": 0.145993413830955,
            "logloss": 2.458289495024737,
            "mae": 0.28799818892472423,
            "precision": 0.7307692307692307,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5325066711597292,
            "auditor_fn_violation": 0.006324364883696002,
            "auditor_fp_violation": 0.015004479726632498,
            "ave_precision_score": 0.5351043916282234,
            "fpr": 0.18640350877192982,
            "logloss": 0.6935738184130825,
            "mae": 0.5001579889733541,
            "precision": 0.5184135977337111,
            "recall": 0.3727087576374745
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.501679373817747,
            "auditor_fn_violation": 0.0075676931575441204,
            "auditor_fp_violation": 0.007845577857926927,
            "ave_precision_score": 0.5049053702994456,
            "fpr": 0.1778265642151482,
            "logloss": 0.6934193798063739,
            "mae": 0.5000753009816556,
            "precision": 0.5221238938053098,
            "recall": 0.38228941684665224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8438498106339479,
            "auditor_fn_violation": 0.004647246936077474,
            "auditor_fp_violation": 0.011063882985373176,
            "ave_precision_score": 0.8290804754382257,
            "fpr": 0.09100877192982457,
            "logloss": 0.5197322451322329,
            "mae": 0.32448831844355974,
            "precision": 0.8109339407744874,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8264289765904882,
            "auditor_fn_violation": 0.0017544150803830325,
            "auditor_fp_violation": 0.007495197585071355,
            "ave_precision_score": 0.8102845124253868,
            "fpr": 0.09330406147091108,
            "logloss": 0.5178504494823913,
            "mae": 0.32460940103368624,
            "precision": 0.7980997624703088,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.740913393450646,
            "auditor_fn_violation": 0.057214063672419366,
            "auditor_fp_violation": 0.011741050964703922,
            "ave_precision_score": 0.73982384525604,
            "fpr": 0.025219298245614034,
            "logloss": 1.2903213637269157,
            "mae": 0.4308356000630193,
            "precision": 0.8413793103448276,
            "recall": 0.2484725050916497
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7202384918062678,
            "auditor_fn_violation": 0.06407882539539538,
            "auditor_fp_violation": 0.012924866708483614,
            "ave_precision_score": 0.7210502688891413,
            "fpr": 0.027442371020856202,
            "logloss": 1.1304380670286622,
            "mae": 0.4197112928256134,
            "precision": 0.8226950354609929,
            "recall": 0.2505399568034557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 4719,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8624708854110471,
            "auditor_fn_violation": 0.003916997177260876,
            "auditor_fp_violation": 0.010217423011209733,
            "ave_precision_score": 0.8589156319298846,
            "fpr": 0.07785087719298246,
            "logloss": 0.4943668270323053,
            "mae": 0.3027033571096693,
            "precision": 0.8317535545023697,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.847143779397731,
            "auditor_fn_violation": 0.0035894384212160923,
            "auditor_fp_violation": 0.009372059745962051,
            "ave_precision_score": 0.8447322410116445,
            "fpr": 0.0801317233809001,
            "logloss": 0.5092398966036795,
            "mae": 0.30682376810195156,
            "precision": 0.8170426065162907,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8069200827399051,
            "auditor_fn_violation": 0.0085597777539572,
            "auditor_fp_violation": 0.016483831312247364,
            "ave_precision_score": 0.7731983174770349,
            "fpr": 0.08991228070175439,
            "logloss": 2.4981552580243576,
            "mae": 0.29315486845643823,
            "precision": 0.7939698492462312,
            "recall": 0.6435845213849287
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.770324444408613,
            "auditor_fn_violation": 0.010787281913165945,
            "auditor_fp_violation": 0.008009742041712401,
            "ave_precision_score": 0.7252361175993657,
            "fpr": 0.11525795828759605,
            "logloss": 3.0258367484502373,
            "mae": 0.30492584083748514,
            "precision": 0.7355163727959698,
            "recall": 0.6306695464362851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 4719,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6235696099050914,
            "auditor_fn_violation": 0.0009357022903491046,
            "auditor_fp_violation": 0.002153915072717423,
            "ave_precision_score": 0.5519359049706576,
            "fpr": 0.03289473684210526,
            "logloss": 0.6961366382190448,
            "mae": 0.5001296619312805,
            "precision": 0.6551724137931034,
            "recall": 0.11608961303462322
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5988049680825406,
            "auditor_fn_violation": 0.00431728359645608,
            "auditor_fp_violation": 0.0003577309079504481,
            "ave_precision_score": 0.5223741989264993,
            "fpr": 0.03293084522502744,
            "logloss": 0.6928345336695421,
            "mae": 0.4984884618011709,
            "precision": 0.6341463414634146,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8204848950435506,
            "auditor_fn_violation": 0.006949655197055782,
            "auditor_fp_violation": 0.012517189648706089,
            "ave_precision_score": 0.7697944997148023,
            "fpr": 0.08771929824561403,
            "logloss": 0.5401066629829776,
            "mae": 0.3539738392032552,
            "precision": 0.815668202764977,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.7942884994694115,
            "auditor_fn_violation": 0.001434352869772614,
            "auditor_fp_violation": 0.0055031754743609905,
            "ave_precision_score": 0.7417309653208459,
            "fpr": 0.09001097694840834,
            "logloss": 0.5379828152169603,
            "mae": 0.3533432269560911,
            "precision": 0.8028846153846154,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.6002524181387097,
            "auditor_fn_violation": 0.0004421695787329992,
            "auditor_fp_violation": 0.013772554902696172,
            "ave_precision_score": 0.6022342105119293,
            "fpr": 0.08223684210526316,
            "logloss": 2.0006114408704887,
            "mae": 0.4979952285457974,
            "precision": 0.5967741935483871,
            "recall": 0.22606924643584522
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5722938823231313,
            "auditor_fn_violation": 0.014568757660748295,
            "auditor_fp_violation": 0.017411204328053948,
            "ave_precision_score": 0.5731793544073809,
            "fpr": 0.08122941822173436,
            "logloss": 2.4082711191294854,
            "mae": 0.4859596584082659,
            "precision": 0.5819209039548022,
            "recall": 0.2224622030237581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.8312413666775613,
            "auditor_fn_violation": 0.005069317897595328,
            "auditor_fp_violation": 0.0029456807100887625,
            "ave_precision_score": 0.8314341040839524,
            "fpr": 0.021929824561403508,
            "logloss": 0.5843520599147249,
            "mae": 0.4100144870023717,
            "precision": 0.9130434782608695,
            "recall": 0.42769857433808556
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7833300628652691,
            "auditor_fn_violation": 0.0056994781800551704,
            "auditor_fp_violation": 0.0009139289634624446,
            "ave_precision_score": 0.7837772981332559,
            "fpr": 0.025246981339187707,
            "logloss": 0.6103561475170306,
            "mae": 0.4186988698337002,
            "precision": 0.8915094339622641,
            "recall": 0.408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6711937207816766,
            "mae": 0.4780334134079647,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6652934006488713,
            "mae": 0.4756710986339954,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7684651516795257,
            "auditor_fn_violation": 0.0006409225711937685,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5378715040270579,
            "fpr": 0.4616228070175439,
            "logloss": 15.982127488125458,
            "mae": 0.46271929824561403,
            "precision": 0.5378704720087816,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7525132251627649,
            "auditor_fn_violation": 0.0010716156977474732,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5071553889213333,
            "fpr": 0.49176728869374314,
            "logloss": 17.061259711699815,
            "mae": 0.49396267837541163,
            "precision": 0.5071507150715071,
            "recall": 0.9956803455723542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7198475493712545,
            "auditor_fn_violation": 0.007034516025297461,
            "auditor_fp_violation": 0.00560226278284786,
            "ave_precision_score": 0.7219410329378803,
            "fpr": 0.05482456140350877,
            "logloss": 0.8342076534075484,
            "mae": 0.4190639396608611,
            "precision": 0.782608695652174,
            "recall": 0.3665987780040733
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6519598379598844,
            "auditor_fn_violation": 0.0030512597411526707,
            "auditor_fp_violation": 0.010482005645287753,
            "ave_precision_score": 0.664362750209375,
            "fpr": 0.054884742041712405,
            "logloss": 0.8266241403031671,
            "mae": 0.4199077415864804,
            "precision": 0.7448979591836735,
            "recall": 0.31533477321814257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7544985653758102,
            "auditor_fn_violation": 0.011900614571050855,
            "auditor_fp_violation": 0.022526253281660216,
            "ave_precision_score": 0.7550666213208116,
            "fpr": 0.13486842105263158,
            "logloss": 0.9463626238439966,
            "mae": 0.32880641542118716,
            "precision": 0.7248322147651006,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7381766443959178,
            "auditor_fn_violation": 0.010045211750787712,
            "auditor_fp_violation": 0.01720293633369924,
            "ave_precision_score": 0.7388875853737017,
            "fpr": 0.15477497255762898,
            "logloss": 0.9676475335923319,
            "mae": 0.3348424463353343,
            "precision": 0.6934782608695652,
            "recall": 0.6889848812095032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7899955471975517,
            "auditor_fn_violation": 0.009019812770214748,
            "auditor_fp_violation": 0.023289369504521405,
            "ave_precision_score": 0.6640657691011427,
            "fpr": 0.14912280701754385,
            "logloss": 0.6232131310983259,
            "mae": 0.4347282144518798,
            "precision": 0.7172557172557172,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7632967250970555,
            "auditor_fn_violation": 0.015716239956566375,
            "auditor_fp_violation": 0.017425905598243696,
            "ave_precision_score": 0.6207463970002824,
            "fpr": 0.18441273326015367,
            "logloss": 0.6323719671153224,
            "mae": 0.4396267981482128,
            "precision": 0.6646706586826348,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8606104209401202,
            "auditor_fn_violation": 0.01594936935005539,
            "auditor_fp_violation": 0.023591490602992038,
            "ave_precision_score": 0.8543418008592357,
            "fpr": 0.08771929824561403,
            "logloss": 0.4945755413166398,
            "mae": 0.31713930550113056,
            "precision": 0.81859410430839,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8463888639259803,
            "auditor_fn_violation": 0.017513329998364136,
            "auditor_fp_violation": 0.02291192959071664,
            "ave_precision_score": 0.8397485481422517,
            "fpr": 0.09110867178924259,
            "logloss": 0.49373513757079307,
            "mae": 0.3195781174691396,
            "precision": 0.8028503562945368,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.860863563554923,
            "auditor_fn_violation": 0.003834369528709761,
            "auditor_fp_violation": 0.0007110263782972904,
            "ave_precision_score": 0.858687263928571,
            "fpr": 0.08552631578947369,
            "logloss": 0.4895348250455313,
            "mae": 0.3191192957588978,
            "precision": 0.8206896551724138,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8310121833949937,
            "auditor_fn_violation": 0.007418330792592582,
            "auditor_fp_violation": 0.008815861690450056,
            "ave_precision_score": 0.8315507886325666,
            "fpr": 0.0867178924259056,
            "logloss": 0.5001566413907703,
            "mae": 0.3215008806580377,
            "precision": 0.8110047846889952,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.636504707940752,
            "auditor_fn_violation": 0.0073337621038339264,
            "auditor_fp_violation": 0.004602137767220907,
            "ave_precision_score": 0.5798711449523337,
            "fpr": 0.07236842105263158,
            "logloss": 0.6893210211190417,
            "mae": 0.49425421975422323,
            "precision": 0.6796116504854369,
            "recall": 0.285132382892057
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.5550674238289459,
            "auditor_fn_violation": 0.008034746901916353,
            "auditor_fp_violation": 0.013358554179081075,
            "ave_precision_score": 0.5355485986086272,
            "fpr": 0.09001097694840834,
            "logloss": 0.6904649858566504,
            "mae": 0.4948198482574145,
            "precision": 0.6057692307692307,
            "recall": 0.27213822894168466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 4719,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5650225621891507,
            "auditor_fn_violation": 0.004868331725443959,
            "auditor_fp_violation": 0.003385839896653761,
            "ave_precision_score": 0.5657166616934388,
            "fpr": 0.40131578947368424,
            "logloss": 0.690012522693894,
            "mae": 0.49775736089469047,
            "precision": 0.5464684014869888,
            "recall": 0.8981670061099797
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5374669151275366,
            "auditor_fn_violation": 0.005464765892274173,
            "auditor_fp_violation": 0.0034670495530813887,
            "ave_precision_score": 0.5382211368518894,
            "fpr": 0.43578485181119647,
            "logloss": 0.6931922575557953,
            "mae": 0.4993467136285177,
            "precision": 0.5128834355828221,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8472786984592472,
            "auditor_fn_violation": 0.005511487476328296,
            "auditor_fp_violation": 0.013676188690252949,
            "ave_precision_score": 0.83579606953896,
            "fpr": 0.09978070175438597,
            "logloss": 0.5067766924655572,
            "mae": 0.31616884618670793,
            "precision": 0.8,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8328817778657871,
            "auditor_fn_violation": 0.009563933019277226,
            "auditor_fp_violation": 0.006532264387643093,
            "ave_precision_score": 0.8212705227779156,
            "fpr": 0.08562019758507135,
            "logloss": 0.49636168872435427,
            "mae": 0.3124027627588758,
            "precision": 0.8156028368794326,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8107589667199202,
            "auditor_fn_violation": 0.005198842319648413,
            "auditor_fp_violation": 0.008982893695045218,
            "ave_precision_score": 0.811007224712784,
            "fpr": 0.05921052631578947,
            "logloss": 0.7792200766369155,
            "mae": 0.3598537256230453,
            "precision": 0.8491620111731844,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7701789377978184,
            "auditor_fn_violation": 0.002188277188099376,
            "auditor_fp_violation": 0.007723067273012388,
            "ave_precision_score": 0.7705979803927507,
            "fpr": 0.059275521405049394,
            "logloss": 0.7945887292237853,
            "mae": 0.3603150282754398,
            "precision": 0.8378378378378378,
            "recall": 0.6025917926565875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.6985756647952981,
            "auditor_fn_violation": 0.007449887447743598,
            "auditor_fp_violation": 0.0017970996374546823,
            "ave_precision_score": 0.703175535296278,
            "fpr": 0.021929824561403508,
            "logloss": 0.8637476174747027,
            "mae": 0.46706984136580376,
            "precision": 0.7701149425287356,
            "recall": 0.1364562118126273
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.6411350533401174,
            "auditor_fn_violation": 0.0038478590208941526,
            "auditor_fp_violation": 0.007274678532225185,
            "ave_precision_score": 0.6460701383720565,
            "fpr": 0.025246981339187707,
            "logloss": 0.8658009157041271,
            "mae": 0.4633756321451078,
            "precision": 0.6714285714285714,
            "recall": 0.10151187904967603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 4719,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.6289768729785394,
            "auditor_fn_violation": 0.0006565548290277833,
            "auditor_fp_violation": 0.009206880026670002,
            "ave_precision_score": 0.545799153404642,
            "fpr": 0.16337719298245615,
            "logloss": 0.6940961026372897,
            "mae": 0.49960808315428723,
            "precision": 0.5329153605015674,
            "recall": 0.34623217922606925
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6220876414722892,
            "auditor_fn_violation": 0.008805267038571063,
            "auditor_fp_violation": 0.005958914850243064,
            "ave_precision_score": 0.5395343667723721,
            "fpr": 0.14050493962678376,
            "logloss": 0.6907872111947239,
            "mae": 0.4980020941481501,
            "precision": 0.5570934256055363,
            "recall": 0.34773218142548595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7350717833031846,
            "auditor_fn_violation": 0.004325669060635303,
            "auditor_fp_violation": 0.011381631037212986,
            "ave_precision_score": 0.7344777895874005,
            "fpr": 0.13267543859649122,
            "logloss": 1.3261426260339764,
            "mae": 0.30928948771737824,
            "precision": 0.7520491803278688,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7055324919193356,
            "auditor_fn_violation": 0.01186126844210312,
            "auditor_fp_violation": 0.015779363336992317,
            "ave_precision_score": 0.704839245289221,
            "fpr": 0.13830954994511527,
            "logloss": 1.3363369508533978,
            "mae": 0.30531145467301457,
            "precision": 0.7375,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7562416139078272,
            "auditor_fn_violation": 0.003930396255404295,
            "auditor_fp_violation": 0.0069748301871067385,
            "ave_precision_score": 0.6706787368784995,
            "fpr": 0.4440789473684211,
            "logloss": 0.6604017214250896,
            "mae": 0.47770473086520243,
            "precision": 0.543918918918919,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.7134787137854651,
            "auditor_fn_violation": 0.0033855469389013093,
            "auditor_fp_violation": 0.010290889132821078,
            "ave_precision_score": 0.63889469638918,
            "fpr": 0.4632272228320527,
            "logloss": 0.6651166950479704,
            "mae": 0.47943933633627406,
            "precision": 0.5193621867881549,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8463247421055702,
            "auditor_fn_violation": 0.02242782363240076,
            "auditor_fp_violation": 0.013644934783514607,
            "ave_precision_score": 0.8255040626171615,
            "fpr": 0.08771929824561403,
            "logloss": 0.5153137173268547,
            "mae": 0.3421202730305754,
            "precision": 0.813953488372093,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.815650546332631,
            "auditor_fn_violation": 0.02071632293565802,
            "auditor_fp_violation": 0.021258036694370392,
            "ave_precision_score": 0.7887077404427555,
            "fpr": 0.1163556531284303,
            "logloss": 0.5349723479092758,
            "mae": 0.35532742224298375,
            "precision": 0.7546296296296297,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7946667068050521,
            "auditor_fn_violation": 0.0031398506449422984,
            "auditor_fp_violation": 0.013066737508855272,
            "ave_precision_score": 0.7959954138795162,
            "fpr": 0.07675438596491228,
            "logloss": 0.7526770273704114,
            "mae": 0.34256803259413704,
            "precision": 0.8118279569892473,
            "recall": 0.615071283095723
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7917742139399399,
            "auditor_fn_violation": 0.008767333739535749,
            "auditor_fp_violation": 0.008744805551199625,
            "ave_precision_score": 0.7923892801013169,
            "fpr": 0.07574094401756312,
            "logloss": 0.7306845060435126,
            "mae": 0.33059491507927247,
            "precision": 0.8093922651933702,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.559314888095031,
            "auditor_fn_violation": 0.007454353807124749,
            "auditor_fp_violation": 0.010602887860982626,
            "ave_precision_score": 0.5663143673322577,
            "fpr": 0.08114035087719298,
            "logloss": 2.6812920831797284,
            "mae": 0.5115233702569468,
            "precision": 0.612565445026178,
            "recall": 0.23828920570264767
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5071078744049528,
            "auditor_fn_violation": 0.006491335797417223,
            "auditor_fp_violation": 0.009690587266739848,
            "ave_precision_score": 0.5144735821680223,
            "fpr": 0.09330406147091108,
            "logloss": 2.6887336169223612,
            "mae": 0.5017239717301368,
            "precision": 0.5086705202312138,
            "recall": 0.1900647948164147
        }
    }
]