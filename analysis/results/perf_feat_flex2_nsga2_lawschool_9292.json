[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.36766069246895,
            "mae": 0.5317982456140351,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.781214192330527,
            "mae": 0.5148188803512623,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.36766069246895,
            "mae": 0.5317982456140351,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.781214192330527,
            "mae": 0.5148188803512623,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6864848384085822,
            "auditor_fn_violation": 0.014322210164586725,
            "auditor_fp_violation": 0.004491248613336634,
            "ave_precision_score": 0.5221116325525967,
            "fpr": 0.34210526315789475,
            "logloss": 0.6955258642625565,
            "mae": 0.5005615436259592,
            "precision": 0.517774343122102,
            "recall": 0.6907216494845361
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.6688983255363367,
            "auditor_fn_violation": 0.021825169276715062,
            "auditor_fp_violation": 0.01719804699723342,
            "ave_precision_score": 0.5021899793405067,
            "fpr": 0.35236004390779363,
            "logloss": 0.6967447599800339,
            "mae": 0.501166965906497,
            "precision": 0.49607535321821034,
            "recall": 0.673773987206823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.8209301917949069,
            "auditor_fn_violation": 0.005923313438234778,
            "auditor_fp_violation": 0.001378959694317763,
            "ave_precision_score": 0.8212289645806918,
            "fpr": 0.025219298245614034,
            "logloss": 0.6126794910610415,
            "mae": 0.42597746709770146,
            "precision": 0.8935185185185185,
            "recall": 0.3979381443298969
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7795261847062729,
            "auditor_fn_violation": 0.010314586702679178,
            "auditor_fp_violation": 0.00301990254853947,
            "ave_precision_score": 0.7797982789307865,
            "fpr": 0.03293084522502744,
            "logloss": 0.7947370915595393,
            "mae": 0.4217826373155436,
            "precision": 0.8734177215189873,
            "recall": 0.44136460554371004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7672067109133551,
            "auditor_fn_violation": 0.007112497739193361,
            "auditor_fp_violation": 0.011966391388306834,
            "ave_precision_score": 0.7676715247898125,
            "fpr": 0.05263157894736842,
            "logloss": 0.6471246002005174,
            "mae": 0.43121280908638643,
            "precision": 0.8188679245283019,
            "recall": 0.44742268041237115
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7376658606665732,
            "auditor_fn_violation": 0.01023735017869724,
            "auditor_fp_violation": 0.008523277587654162,
            "ave_precision_score": 0.7380145156725161,
            "fpr": 0.050493962678375415,
            "logloss": 0.830991493853171,
            "mae": 0.4260982514176608,
            "precision": 0.8327272727272728,
            "recall": 0.488272921108742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.766381805028034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.532763610056068,
            "fpr": 0.4682017543859649,
            "logloss": 0.6920067642959428,
            "mae": 0.4993314805130164,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7574094401756312,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5148188803512623,
            "fpr": 0.48518111964873767,
            "logloss": 0.6928766891480402,
            "mae": 0.499833015264978,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.767073149754208,
            "auditor_fn_violation": 0.004740911557243644,
            "auditor_fp_violation": 0.011108714408973252,
            "ave_precision_score": 0.7675382450341972,
            "fpr": 0.06907894736842106,
            "logloss": 0.6454035441660652,
            "mae": 0.4309929710336355,
            "precision": 0.79,
            "recall": 0.488659793814433
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7378369528538518,
            "auditor_fn_violation": 0.011789102160516221,
            "auditor_fp_violation": 0.007924760717425535,
            "ave_precision_score": 0.7383883674042384,
            "fpr": 0.06037321624588365,
            "logloss": 0.8302855683677802,
            "mae": 0.42641387301823896,
            "precision": 0.819078947368421,
            "recall": 0.5309168443496801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5239806047023581,
            "auditor_fn_violation": 0.001035449448363176,
            "auditor_fp_violation": 0.0012120465097169167,
            "ave_precision_score": 0.5264791907377983,
            "fpr": 0.46600877192982454,
            "logloss": 0.6916962401513164,
            "mae": 0.4990227152838519,
            "precision": 0.5319383259911894,
            "recall": 0.9958762886597938
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5314861520725664,
            "auditor_fn_violation": 0.0011632288611825616,
            "auditor_fp_violation": 0.003054671163407542,
            "ave_precision_score": 0.534021265580731,
            "fpr": 0.47859495060373214,
            "logloss": 0.6927336871613207,
            "mae": 0.4995084045092963,
            "precision": 0.5150166852057843,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.4183312680995624,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5502398210753787,
            "fpr": 0.4682017543859649,
            "logloss": 0.6918901991994246,
            "mae": 0.4992219504426446,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.3980054617570216,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5249963915363736,
            "fpr": 0.48518111964873767,
            "logloss": 0.692721270554666,
            "mae": 0.4996374031584035,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7672021294154006,
            "auditor_fn_violation": 0.006275999276541884,
            "auditor_fp_violation": 0.011966391388306834,
            "ave_precision_score": 0.767668118487872,
            "fpr": 0.05263157894736842,
            "logloss": 0.6473341774187914,
            "mae": 0.4312080325864508,
            "precision": 0.816793893129771,
            "recall": 0.44123711340206184
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7376445061173826,
            "auditor_fn_violation": 0.014017258852358874,
            "auditor_fp_violation": 0.007813004455349649,
            "ave_precision_score": 0.7379932006163993,
            "fpr": 0.04939626783754116,
            "logloss": 0.831077143235511,
            "mae": 0.42604520241484684,
            "precision": 0.8351648351648352,
            "recall": 0.4861407249466951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7258613673358654,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5535145854326537,
            "fpr": 0.4682017543859649,
            "logloss": 0.6806111327594855,
            "mae": 0.4882768583402299,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6655297405755559,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5352934135300335,
            "fpr": 0.48518111964873767,
            "logloss": 0.6850635080449131,
            "mae": 0.49137441537513693,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7673888184101213,
            "auditor_fn_violation": 0.008918882257189372,
            "auditor_fp_violation": 0.011450244463618066,
            "ave_precision_score": 0.7678536852153386,
            "fpr": 0.0625,
            "logloss": 0.6460888502536178,
            "mae": 0.43107496349108837,
            "precision": 0.7985865724381626,
            "recall": 0.465979381443299
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7377332051302188,
            "auditor_fn_violation": 0.013467241181578386,
            "auditor_fp_violation": 0.011260064272268056,
            "ave_precision_score": 0.7380803140694614,
            "fpr": 0.054884742041712405,
            "logloss": 0.8304965852706904,
            "mae": 0.4262510525441166,
            "precision": 0.8257839721254355,
            "recall": 0.5053304904051172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6979931383803085,
            "auditor_fn_violation": 0.004738650750587809,
            "auditor_fp_violation": 0.008425263979621185,
            "ave_precision_score": 0.698854576546488,
            "fpr": 0.4232456140350877,
            "logloss": 0.795349628643195,
            "mae": 0.4396129581995852,
            "precision": 0.5448113207547169,
            "recall": 0.9525773195876288
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.685756340636553,
            "auditor_fn_violation": 0.0036933101467728005,
            "auditor_fp_violation": 0.0034445763444278413,
            "ave_precision_score": 0.6863076113989297,
            "fpr": 0.44017563117453345,
            "logloss": 0.9675283142225501,
            "mae": 0.4387531994740042,
            "precision": 0.5254437869822485,
            "recall": 0.9466950959488273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7662589905478305,
            "auditor_fn_violation": 0.009122354856212695,
            "auditor_fp_violation": 0.02068696330991414,
            "ave_precision_score": 0.7667245185701357,
            "fpr": 0.3125,
            "logloss": 0.6458845147365803,
            "mae": 0.4308313744193691,
            "precision": 0.5808823529411765,
            "recall": 0.8144329896907216
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7395488801977192,
            "auditor_fn_violation": 0.005518900713618674,
            "auditor_fp_violation": 0.02764104882010223,
            "ave_precision_score": 0.7398933643315713,
            "fpr": 0.31833150384193193,
            "logloss": 0.8319924055576943,
            "mae": 0.42843215308701404,
            "precision": 0.558599695585997,
            "recall": 0.7825159914712153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.525497899772003,
            "auditor_fn_violation": 0.001035449448363176,
            "auditor_fp_violation": 0.0012120465097169167,
            "ave_precision_score": 0.5272295922561663,
            "fpr": 0.46600877192982454,
            "logloss": 0.6919411774398767,
            "mae": 0.4992040582981549,
            "precision": 0.5319383259911894,
            "recall": 0.9958762886597938
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5462059870790492,
            "auditor_fn_violation": 0.0011632288611825616,
            "auditor_fp_violation": 0.003054671163407542,
            "ave_precision_score": 0.5475106969008059,
            "fpr": 0.47859495060373214,
            "logloss": 0.6927220888758179,
            "mae": 0.4995752309666769,
            "precision": 0.5150166852057843,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7669090895813335,
            "auditor_fn_violation": 0.007164496292277087,
            "auditor_fp_violation": 0.02831104400345125,
            "ave_precision_score": 0.767374522223928,
            "fpr": 0.13048245614035087,
            "logloss": 0.6444393760255259,
            "mae": 0.43080966741498355,
            "precision": 0.728310502283105,
            "recall": 0.6577319587628866
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7381367881457179,
            "auditor_fn_violation": 0.0043720553575231965,
            "auditor_fp_violation": 0.03746069904783665,
            "ave_precision_score": 0.7386876897564524,
            "fpr": 0.11855104281009879,
            "logloss": 0.8323908120078544,
            "mae": 0.42743907541132015,
            "precision": 0.7410071942446043,
            "recall": 0.6588486140724946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7669156370692035,
            "auditor_fn_violation": 0.011062126966901786,
            "auditor_fp_violation": 0.01980103948395579,
            "ave_precision_score": 0.7673809881395997,
            "fpr": 0.11293859649122807,
            "logloss": 0.6443276468514462,
            "mae": 0.4308290749646829,
            "precision": 0.7469287469287469,
            "recall": 0.6268041237113402
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7380859409466154,
            "auditor_fn_violation": 0.002513697780503167,
            "auditor_fp_violation": 0.028559933641615055,
            "ave_precision_score": 0.7386382850203701,
            "fpr": 0.10208562019758508,
            "logloss": 0.8318501301513458,
            "mae": 0.4272298294767671,
            "precision": 0.7669172932330827,
            "recall": 0.652452025586354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7987486473823915,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.006828033197748471,
            "ave_precision_score": 0.7593406743339226,
            "fpr": 0.44627192982456143,
            "logloss": 0.6907741020637794,
            "mae": 0.49871920170099066,
            "precision": 0.5401129943502825,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7982650391819918,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005294763349906382,
            "ave_precision_score": 0.761017727196166,
            "fpr": 0.4566410537870472,
            "logloss": 0.6915376953829058,
            "mae": 0.49897753094802444,
            "precision": 0.5256556442417332,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5483045305977943,
            "auditor_fn_violation": 0.0012660517272562852,
            "auditor_fp_violation": 0.0013430091622498878,
            "ave_precision_score": 0.5727245725672611,
            "fpr": 0.46271929824561403,
            "logloss": 0.6912636383156542,
            "mae": 0.4988255132512565,
            "precision": 0.532150776053215,
            "recall": 0.9896907216494846
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5372187731298368,
            "auditor_fn_violation": 0.0003276701017415664,
            "auditor_fp_violation": 0.0007053061873233718,
            "ave_precision_score": 0.5653734567596039,
            "fpr": 0.47200878155872666,
            "logloss": 0.6920832098742689,
            "mae": 0.49923152297440787,
            "precision": 0.5179372197309418,
            "recall": 0.9850746268656716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5630016611691845,
            "auditor_fn_violation": 0.017921414360643876,
            "auditor_fp_violation": 0.02282858786310038,
            "ave_precision_score": 0.5648752941692521,
            "fpr": 0.39364035087719296,
            "logloss": 0.6933378015028943,
            "mae": 0.49210913605138396,
            "precision": 0.5545905707196029,
            "recall": 0.9216494845360824
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5714203368440669,
            "auditor_fn_violation": 0.011566754591477301,
            "auditor_fp_violation": 0.011647485980797791,
            "ave_precision_score": 0.5731181424080926,
            "fpr": 0.42151481888035125,
            "logloss": 0.6821676936633754,
            "mae": 0.4901193371932017,
            "precision": 0.5351089588377724,
            "recall": 0.9424307036247335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.767360931378449,
            "auditor_fn_violation": 0.007585006330258635,
            "auditor_fp_violation": 0.011450244463618066,
            "ave_precision_score": 0.7678258003426538,
            "fpr": 0.0625,
            "logloss": 0.6461527757208583,
            "mae": 0.43111114442661536,
            "precision": 0.7978723404255319,
            "recall": 0.4639175257731959
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7377164538211042,
            "auditor_fn_violation": 0.013467241181578386,
            "auditor_fp_violation": 0.011260064272268056,
            "ave_precision_score": 0.7380648722549895,
            "fpr": 0.054884742041712405,
            "logloss": 0.8305469376477654,
            "mae": 0.4262656804630863,
            "precision": 0.8257839721254355,
            "recall": 0.5053304904051172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5697289687191427,
            "auditor_fn_violation": 0.0012660517272562852,
            "auditor_fp_violation": 0.0013430091622498878,
            "ave_precision_score": 0.5711505652466273,
            "fpr": 0.46271929824561403,
            "logloss": 0.691216936095323,
            "mae": 0.49880271904954787,
            "precision": 0.532150776053215,
            "recall": 0.9896907216494846
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5536707395664413,
            "auditor_fn_violation": 0.0003276701017415664,
            "auditor_fp_violation": 0.0007053061873233718,
            "ave_precision_score": 0.5557521402870051,
            "fpr": 0.47200878155872666,
            "logloss": 0.6920850797868159,
            "mae": 0.49923256559769746,
            "precision": 0.5179372197309418,
            "recall": 0.9850746268656716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6483091604868292,
            "auditor_fn_violation": 0.08731913546753482,
            "auditor_fp_violation": 0.0751725625539258,
            "ave_precision_score": 0.650148312691197,
            "fpr": 0.2916666666666667,
            "logloss": 0.7367074905961971,
            "mae": 0.4847402213219127,
            "precision": 0.572347266881029,
            "recall": 0.734020618556701
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6639660531270815,
            "auditor_fn_violation": 0.07891232250227614,
            "auditor_fp_violation": 0.08807386840575968,
            "ave_precision_score": 0.6657624751640121,
            "fpr": 0.29308452250274425,
            "logloss": 0.7554510366445119,
            "mae": 0.48381715625966715,
            "precision": 0.563011456628478,
            "recall": 0.7334754797441365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5845171384736281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.536968866353584,
            "fpr": 0.4682017543859649,
            "logloss": 0.6915780247941453,
            "mae": 0.4983496160099381,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6465477146180654,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5325837021572395,
            "fpr": 0.48518111964873767,
            "logloss": 0.6884166061708049,
            "mae": 0.4969195813823872,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7673611007059804,
            "auditor_fn_violation": 0.006517905588714052,
            "auditor_fp_violation": 0.011450244463618066,
            "ave_precision_score": 0.7678259789638513,
            "fpr": 0.0625,
            "logloss": 0.6460533035765037,
            "mae": 0.43107104543981817,
            "precision": 0.7992957746478874,
            "recall": 0.46804123711340206
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7377372433034284,
            "auditor_fn_violation": 0.012418696856005378,
            "auditor_fp_violation": 0.011260064272268056,
            "ave_precision_score": 0.7380843516137003,
            "fpr": 0.054884742041712405,
            "logloss": 0.8304831522883379,
            "mae": 0.4262585437783248,
            "precision": 0.8263888888888888,
            "recall": 0.5074626865671642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.58377444556564,
            "auditor_fn_violation": 0.003988062940857299,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.5413613824926794,
            "fpr": 0.4506578947368421,
            "logloss": 0.6994838198693938,
            "mae": 0.49028892279194114,
            "precision": 0.5376827896512936,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6439279538813395,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.535556045310503,
            "fpr": 0.47091108671789245,
            "logloss": 0.7039711708097588,
            "mae": 0.492832677162832,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5630336238941317,
            "auditor_fn_violation": 0.02406628685114849,
            "auditor_fp_violation": 0.02953336209375899,
            "ave_precision_score": 0.5649044077539702,
            "fpr": 0.38377192982456143,
            "logloss": 0.693874927684555,
            "mae": 0.4925454607674558,
            "precision": 0.5558375634517766,
            "recall": 0.9030927835051547
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.571170493711964,
            "auditor_fn_violation": 0.01933253600275243,
            "auditor_fp_violation": 0.022403405337479084,
            "ave_precision_score": 0.5728678476886533,
            "fpr": 0.40504939626783754,
            "logloss": 0.6822140471932455,
            "mae": 0.4903675115142839,
            "precision": 0.5381727158948686,
            "recall": 0.9168443496801706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.555793428083304,
            "auditor_fn_violation": 0.0008817145957677702,
            "auditor_fp_violation": 0.005305271375159223,
            "ave_precision_score": 0.5701782713267154,
            "fpr": 0.43201754385964913,
            "logloss": 0.6948491090057672,
            "mae": 0.4889583455586577,
            "precision": 0.5439814814814815,
            "recall": 0.9690721649484536
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.58051908299093,
            "auditor_fn_violation": 0.003108184965091432,
            "auditor_fp_violation": 0.0074305496918010685,
            "ave_precision_score": 0.5862344489232543,
            "fpr": 0.4456641053787047,
            "logloss": 0.6831096553674246,
            "mae": 0.4876608859776273,
            "precision": 0.5300925925925926,
            "recall": 0.976545842217484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.5840373336590654,
            "auditor_fn_violation": 0.06728160607704829,
            "auditor_fp_violation": 0.06494463618061548,
            "ave_precision_score": 0.5870706835123721,
            "fpr": 0.28399122807017546,
            "logloss": 0.7532611694081057,
            "mae": 0.4868001454865168,
            "precision": 0.5849358974358975,
            "recall": 0.7525773195876289
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5615653311018861,
            "auditor_fn_violation": 0.05178123807807442,
            "auditor_fp_violation": 0.088282480094968,
            "ave_precision_score": 0.5618350330737623,
            "fpr": 0.300768386388584,
            "logloss": 0.7614537468027319,
            "mae": 0.4928382874357092,
            "precision": 0.5650793650793651,
            "recall": 0.7590618336886994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 9292,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6687467442667883,
            "auditor_fn_violation": 0.01141029119189727,
            "auditor_fp_violation": 0.031300073955380266,
            "ave_precision_score": 0.6683465313977801,
            "fpr": 0.21710526315789475,
            "logloss": 1.4571659374417631,
            "mae": 0.322123362556618,
            "precision": 0.6710963455149501,
            "recall": 0.8329896907216495
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7288705600827496,
            "auditor_fn_violation": 0.008877519256469731,
            "auditor_fp_violation": 0.03242918378193125,
            "ave_precision_score": 0.7303906003089409,
            "fpr": 0.20636663007683864,
            "logloss": 1.049525930567622,
            "mae": 0.2988106869274262,
            "precision": 0.6887417218543046,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.767330558505389,
            "auditor_fn_violation": 0.009278350515463926,
            "auditor_fp_violation": 0.013350486872920004,
            "ave_precision_score": 0.7677953259151108,
            "fpr": 0.05701754385964912,
            "logloss": 0.6467091062391243,
            "mae": 0.43114181738659657,
            "precision": 0.8074074074074075,
            "recall": 0.44948453608247424
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7376127349374678,
            "auditor_fn_violation": 0.011833571674324006,
            "auditor_fp_violation": 0.009824617172715579,
            "ave_precision_score": 0.738164333621201,
            "fpr": 0.052689352360043906,
            "logloss": 0.8307629028024497,
            "mae": 0.4261379490275882,
            "precision": 0.8297872340425532,
            "recall": 0.4989339019189765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7378397949542547,
            "auditor_fn_violation": 0.011168384879725084,
            "auditor_fp_violation": 0.0022469082542421717,
            "ave_precision_score": 0.7360552159617337,
            "fpr": 0.15350877192982457,
            "logloss": 1.331854234487811,
            "mae": 0.33679074070057874,
            "precision": 0.7052631578947368,
            "recall": 0.6907216494845361
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7592609206555221,
            "auditor_fn_violation": 0.011988044722287887,
            "auditor_fp_violation": 0.0173098032593093,
            "ave_precision_score": 0.7608529899331233,
            "fpr": 0.14928649835345773,
            "logloss": 1.0328739886714313,
            "mae": 0.3172738723663417,
            "precision": 0.7195876288659794,
            "recall": 0.744136460554371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7676600441501104,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003050659435473934,
            "ave_precision_score": 0.5353200883002207,
            "fpr": 0.4616228070175439,
            "logloss": 0.6916207834157441,
            "mae": 0.4991812785074376,
            "precision": 0.5353200883002207,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7583323068615175,
            "auditor_fn_violation": 0.0006155516911288001,
            "auditor_fp_violation": 0.002488439435556396,
            "ave_precision_score": 0.5176929738188897,
            "fpr": 0.47859495060373214,
            "logloss": 0.692098116851574,
            "mae": 0.49941177134587134,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 9292,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6687342733655578,
            "auditor_fn_violation": 0.01141029119189727,
            "auditor_fp_violation": 0.031300073955380266,
            "ave_precision_score": 0.6683465313977801,
            "fpr": 0.21710526315789475,
            "logloss": 1.4571778431971922,
            "mae": 0.322123552559378,
            "precision": 0.6710963455149501,
            "recall": 0.8329896907216495
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7288705600827496,
            "auditor_fn_violation": 0.008877519256469731,
            "auditor_fp_violation": 0.03242918378193125,
            "ave_precision_score": 0.7303906003089409,
            "fpr": 0.20636663007683864,
            "logloss": 1.0495274436946531,
            "mae": 0.2988108310582842,
            "precision": 0.6887417218543046,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7669883190343452,
            "auditor_fn_violation": 0.0030973051184662744,
            "auditor_fp_violation": 0.0387392661982826,
            "ave_precision_score": 0.7674643182703723,
            "fpr": 0.23464912280701755,
            "logloss": 0.6452945066318095,
            "mae": 0.4307404490777631,
            "precision": 0.6239015817223199,
            "recall": 0.7319587628865979
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7383826272963026,
            "auditor_fn_violation": 0.005092929581354639,
            "auditor_fp_violation": 0.045790265781225956,
            "ave_precision_score": 0.7389290725227895,
            "fpr": 0.24039517014270034,
            "logloss": 0.8346945636983872,
            "mae": 0.42815545838228664,
            "precision": 0.6164623467600701,
            "recall": 0.7505330490405118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6677283894085053,
            "auditor_fn_violation": 0.012181226261530113,
            "auditor_fp_violation": 0.02818521714121369,
            "ave_precision_score": 0.6672570471739943,
            "fpr": 0.20833333333333334,
            "logloss": 1.4040057349539852,
            "mae": 0.3201409143589227,
            "precision": 0.6790540540540541,
            "recall": 0.8288659793814434
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7229869833606053,
            "auditor_fn_violation": 0.007049588188897133,
            "auditor_fp_violation": 0.032583159076346915,
            "ave_precision_score": 0.7244936291717231,
            "fpr": 0.2030735455543359,
            "logloss": 1.006466804961884,
            "mae": 0.30154493190138515,
            "precision": 0.6875,
            "recall": 0.8678038379530917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6734932413612011,
            "auditor_fn_violation": 0.010187194791101467,
            "auditor_fp_violation": 0.03061187805579523,
            "ave_precision_score": 0.6730014782556231,
            "fpr": 0.2225877192982456,
            "logloss": 1.4748913762823113,
            "mae": 0.3212251422707756,
            "precision": 0.6672131147540984,
            "recall": 0.8391752577319588
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7349961432102821,
            "auditor_fn_violation": 0.011297597007903872,
            "auditor_fp_violation": 0.031594737025097984,
            "ave_precision_score": 0.7365636800650893,
            "fpr": 0.20856201975850713,
            "logloss": 1.0414559555398963,
            "mae": 0.297802563050605,
            "precision": 0.6875,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6940115819473273,
            "auditor_fn_violation": 0.01394239464640984,
            "auditor_fp_violation": 0.025637865154690003,
            "ave_precision_score": 0.6175280791961386,
            "fpr": 0.24342105263157895,
            "logloss": 6.681937412842017,
            "mae": 0.3523589148978103,
            "precision": 0.6413570274636511,
            "recall": 0.8185567010309278
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.734647014605162,
            "auditor_fn_violation": 0.009200508356757849,
            "auditor_fp_violation": 0.03404344090080515,
            "ave_precision_score": 0.6654156348250504,
            "fpr": 0.24478594950603733,
            "logloss": 5.124080808411082,
            "mae": 0.3165623051808911,
            "precision": 0.6515625,
            "recall": 0.8891257995735607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7782684101926178,
            "auditor_fn_violation": 0.008536805932356667,
            "auditor_fp_violation": 0.019898619499568605,
            "ave_precision_score": 0.7485850672172638,
            "fpr": 0.17653508771929824,
            "logloss": 2.2079692188210145,
            "mae": 0.3177976074244526,
            "precision": 0.7093862815884476,
            "recall": 0.8103092783505155
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.801721558173256,
            "auditor_fn_violation": 0.004341628848075757,
            "auditor_fp_violation": 0.01961943267554425,
            "ave_precision_score": 0.7770439435009362,
            "fpr": 0.18221734357848518,
            "logloss": 1.8293224144917242,
            "mae": 0.30316417313046395,
            "precision": 0.7067137809187279,
            "recall": 0.8528784648187633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7399283015067604,
            "auditor_fn_violation": 0.013316151202749146,
            "auditor_fp_violation": 0.013781893257734504,
            "ave_precision_score": 0.7388692817806464,
            "fpr": 0.17434210526315788,
            "logloss": 1.3307748507144705,
            "mae": 0.3368435480242274,
            "precision": 0.6994328922495274,
            "recall": 0.7628865979381443
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.763543121913618,
            "auditor_fn_violation": 0.009993938103117788,
            "auditor_fp_violation": 0.016579662347080183,
            "ave_precision_score": 0.7633759029812831,
            "fpr": 0.17453347969264543,
            "logloss": 1.0645213133216755,
            "mae": 0.3218230942545739,
            "precision": 0.7055555555555556,
            "recall": 0.8123667377398721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.766381805028034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.532763610056068,
            "fpr": 0.4682017543859649,
            "logloss": 0.6920067642959428,
            "mae": 0.4993314805130164,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7574094401756312,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5148188803512623,
            "fpr": 0.48518111964873767,
            "logloss": 0.6928766891480402,
            "mae": 0.499833015264978,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6897606457807195,
            "auditor_fn_violation": 0.00597305118466269,
            "auditor_fp_violation": 0.029779880027938705,
            "ave_precision_score": 0.6852683988303728,
            "fpr": 0.2236842105263158,
            "logloss": 1.7305901431078734,
            "mae": 0.32567334370782064,
            "precision": 0.6699029126213593,
            "recall": 0.8536082474226804
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7383253572037826,
            "auditor_fn_violation": 0.010628213800060385,
            "auditor_fp_violation": 0.027948999408933552,
            "ave_precision_score": 0.736712016947413,
            "fpr": 0.2239297475301866,
            "logloss": 1.2306529664254737,
            "mae": 0.3077971916214719,
            "precision": 0.6725521669341894,
            "recall": 0.8933901918976546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5483045305977943,
            "auditor_fn_violation": 0.0012660517272562852,
            "auditor_fp_violation": 0.0013430091622498878,
            "ave_precision_score": 0.5727245725672611,
            "fpr": 0.46271929824561403,
            "logloss": 0.6912636381216399,
            "mae": 0.49882551315322254,
            "precision": 0.532150776053215,
            "recall": 0.9896907216494846
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5372187731298368,
            "auditor_fn_violation": 0.0003276701017415664,
            "auditor_fp_violation": 0.0007053061873233718,
            "ave_precision_score": 0.5653734567596039,
            "fpr": 0.47200878155872666,
            "logloss": 0.6920832098059152,
            "mae": 0.49923152294169404,
            "precision": 0.5179372197309418,
            "recall": 0.9850746268656716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7401201251829961,
            "auditor_fn_violation": 0.011075691806836683,
            "auditor_fp_violation": 0.022158367229549284,
            "ave_precision_score": 0.6884239377426683,
            "fpr": 0.20175438596491227,
            "logloss": 3.821446145480048,
            "mae": 0.32324158478063447,
            "precision": 0.6805555555555556,
            "recall": 0.8082474226804124
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7789765126798134,
            "auditor_fn_violation": 0.01159952160165146,
            "auditor_fp_violation": 0.02420888983812728,
            "ave_precision_score": 0.7396637038661904,
            "fpr": 0.20087815587266739,
            "logloss": 2.756430987034195,
            "mae": 0.3013079033457553,
            "precision": 0.6855670103092784,
            "recall": 0.8507462686567164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.765431793353184,
            "auditor_fn_violation": 0.0008975402423584827,
            "auditor_fp_violation": 0.017484798060725587,
            "ave_precision_score": 0.7659035422710907,
            "fpr": 0.08333333333333333,
            "logloss": 0.6452878630281328,
            "mae": 0.43026699625848264,
            "precision": 0.7764705882352941,
            "recall": 0.5443298969072164
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7385767951879472,
            "auditor_fn_violation": 0.0017483540428639283,
            "auditor_fp_violation": 0.018526704779691157,
            "ave_precision_score": 0.7390879025554982,
            "fpr": 0.08122941822173436,
            "logloss": 0.8281852503053303,
            "mae": 0.4264161385741385,
            "precision": 0.7861271676300579,
            "recall": 0.579957356076759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6864848384085822,
            "auditor_fn_violation": 0.014322210164586725,
            "auditor_fp_violation": 0.004491248613336634,
            "ave_precision_score": 0.5221116325525967,
            "fpr": 0.34210526315789475,
            "logloss": 0.6955258642625565,
            "mae": 0.5005615436259592,
            "precision": 0.517774343122102,
            "recall": 0.6907216494845361
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.6688983255363367,
            "auditor_fn_violation": 0.021825169276715062,
            "auditor_fp_violation": 0.01719804699723342,
            "ave_precision_score": 0.5021899793405067,
            "fpr": 0.35236004390779363,
            "logloss": 0.6967447599800339,
            "mae": 0.501166965906497,
            "precision": 0.49607535321821034,
            "recall": 0.673773987206823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7349581052447678,
            "auditor_fn_violation": 0.016888225718936518,
            "auditor_fp_violation": 0.011558096059821691,
            "ave_precision_score": 0.7357957507589634,
            "fpr": 0.1611842105263158,
            "logloss": 1.0990310432573458,
            "mae": 0.33728292472309696,
            "precision": 0.711764705882353,
            "recall": 0.7484536082474227
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7631178798677624,
            "auditor_fn_violation": 0.0031760594861664744,
            "auditor_fp_violation": 0.015869389214775667,
            "ave_precision_score": 0.7656786818549344,
            "fpr": 0.1602634467618002,
            "logloss": 0.8958824531640144,
            "mae": 0.3195870885306809,
            "precision": 0.7170542635658915,
            "recall": 0.7889125799573561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7647803083838116,
            "auditor_fn_violation": 0.003660245975764171,
            "auditor_fp_violation": 0.01206140350877193,
            "ave_precision_score": 0.7652468401028715,
            "fpr": 0.0668859649122807,
            "logloss": 0.6452931418572018,
            "mae": 0.43002731644078485,
            "precision": 0.7932203389830509,
            "recall": 0.4824742268041237
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7382681904598491,
            "auditor_fn_violation": 0.010139049148174754,
            "auditor_fp_violation": 0.012352792168121155,
            "ave_precision_score": 0.7388181732658785,
            "fpr": 0.05817782656421515,
            "logloss": 0.8285157343145202,
            "mae": 0.4244990358056332,
            "precision": 0.8233333333333334,
            "recall": 0.5266524520255863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.698296777562635,
            "auditor_fn_violation": 0.009893289925845544,
            "auditor_fp_violation": 0.02627983894161634,
            "ave_precision_score": 0.6987275450420339,
            "fpr": 0.20394736842105263,
            "logloss": 1.174909933402903,
            "mae": 0.3118722483709412,
            "precision": 0.6868686868686869,
            "recall": 0.8412371134020619
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7635583448024861,
            "auditor_fn_violation": 0.011871019685951615,
            "auditor_fp_violation": 0.02515260938454585,
            "ave_precision_score": 0.7651378768134083,
            "fpr": 0.1964873765093304,
            "logloss": 0.850205334411165,
            "mae": 0.2917041094491697,
            "precision": 0.6960950764006791,
            "recall": 0.8742004264392325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7683593037749847,
            "auditor_fn_violation": 0.011258817145957679,
            "auditor_fp_violation": 0.01870968404618102,
            "ave_precision_score": 0.7688144512675064,
            "fpr": 0.3201754385964912,
            "logloss": 0.6455245776729798,
            "mae": 0.4292411170554466,
            "precision": 0.5761973875181422,
            "recall": 0.8185567010309278
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7779853945406485,
            "auditor_fn_violation": 0.001916870095188165,
            "auditor_fp_violation": 0.024506906536996286,
            "ave_precision_score": 0.7793807905551791,
            "fpr": 0.32930845225027444,
            "logloss": 0.637921216078031,
            "mae": 0.4228983498619196,
            "precision": 0.5575221238938053,
            "recall": 0.8059701492537313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6053353092804044,
            "auditor_fn_violation": 0.0901880991137638,
            "auditor_fp_violation": 0.07775586507251737,
            "ave_precision_score": 0.6085252235292171,
            "fpr": 0.22807017543859648,
            "logloss": 0.7246808751958018,
            "mae": 0.47053510988776553,
            "precision": 0.6075471698113207,
            "recall": 0.6639175257731958
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5644151932603065,
            "auditor_fn_violation": 0.07914169157349524,
            "auditor_fp_violation": 0.09029409281233393,
            "ave_precision_score": 0.5675715101200108,
            "fpr": 0.2524698133918771,
            "logloss": 0.7390085542789302,
            "mae": 0.47693500710542913,
            "precision": 0.5732838589981447,
            "recall": 0.6588486140724946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6734932413612011,
            "auditor_fn_violation": 0.010187194791101467,
            "auditor_fp_violation": 0.03061187805579523,
            "ave_precision_score": 0.6730014782556231,
            "fpr": 0.2225877192982456,
            "logloss": 1.4748921800337487,
            "mae": 0.321225287887615,
            "precision": 0.6672131147540984,
            "recall": 0.8391752577319588
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7349961483336315,
            "auditor_fn_violation": 0.011297597007903872,
            "auditor_fp_violation": 0.031594737025097984,
            "ave_precision_score": 0.7365620508399655,
            "fpr": 0.20856201975850713,
            "logloss": 1.0414571429788122,
            "mae": 0.29780269088356953,
            "precision": 0.6875,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6669442072043189,
            "auditor_fn_violation": 0.014116476758907578,
            "auditor_fp_violation": 0.02721198488023338,
            "ave_precision_score": 0.6664951901794947,
            "fpr": 0.21162280701754385,
            "logloss": 1.4517504625183788,
            "mae": 0.3221785237776872,
            "precision": 0.6756302521008404,
            "recall": 0.8288659793814434
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7174460677938064,
            "auditor_fn_violation": 0.009680311005736568,
            "auditor_fp_violation": 0.03215103486298682,
            "ave_precision_score": 0.7189678773762416,
            "fpr": 0.20636663007683864,
            "logloss": 1.0447375915279358,
            "mae": 0.30557401058213024,
            "precision": 0.6850921273031826,
            "recall": 0.8720682302771855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7692011035600852,
            "auditor_fn_violation": 0.004168927473322502,
            "auditor_fp_violation": 0.0018899708287111227,
            "ave_precision_score": 0.5895268980750612,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6626584756979413,
            "mae": 0.47185509246692325,
            "precision": 0.9411764705882353,
            "recall": 0.13195876288659794
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7313028260518324,
            "auditor_fn_violation": 0.0005008671555192574,
            "auditor_fp_violation": 0.003059638108388674,
            "ave_precision_score": 0.5793211412898315,
            "fpr": 0.013172338090010977,
            "logloss": 0.6615557594805535,
            "mae": 0.46808217621268344,
            "precision": 0.8620689655172413,
            "recall": 0.15991471215351813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 9292,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7353726075589677,
            "auditor_fn_violation": 0.015002712967986984,
            "auditor_fp_violation": 0.013412116356464932,
            "ave_precision_score": 0.7363189224413588,
            "fpr": 0.16337719298245615,
            "logloss": 1.103108780720631,
            "mae": 0.338114586169629,
            "precision": 0.7106796116504854,
            "recall": 0.7546391752577319
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7633461352079836,
            "auditor_fn_violation": 0.0023194362201849465,
            "auditor_fp_violation": 0.017786629977499746,
            "ave_precision_score": 0.7652096880270165,
            "fpr": 0.16136114160263446,
            "logloss": 0.9017385009100978,
            "mae": 0.3208539734756716,
            "precision": 0.7183908045977011,
            "recall": 0.7995735607675906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7648776969225402,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5545201548572639,
            "fpr": 0.4682017543859649,
            "logloss": 0.6918902024208486,
            "mae": 0.49922195514827444,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7495468641190957,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5293070471538385,
            "fpr": 0.48518111964873767,
            "logloss": 0.692721267533245,
            "mae": 0.4996374047286686,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.565161803927267,
            "auditor_fn_violation": 0.09385060589618377,
            "auditor_fp_violation": 0.09167899256337565,
            "ave_precision_score": 0.5699280108660254,
            "fpr": 0.2708333333333333,
            "logloss": 0.686619005835486,
            "mae": 0.48426743457910787,
            "precision": 0.5876460767946577,
            "recall": 0.7257731958762886
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5487586522772244,
            "auditor_fn_violation": 0.08347395841866409,
            "auditor_fp_violation": 0.09814683282753278,
            "ave_precision_score": 0.5527254123692105,
            "fpr": 0.2843029637760702,
            "logloss": 0.6932515768223885,
            "mae": 0.48661497971359907,
            "precision": 0.5647058823529412,
            "recall": 0.7164179104477612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7671424717911303,
            "auditor_fn_violation": 0.003660245975764171,
            "auditor_fp_violation": 0.011108714408973252,
            "ave_precision_score": 0.7676078371064474,
            "fpr": 0.06907894736842106,
            "logloss": 0.6456606365862532,
            "mae": 0.4310818381892061,
            "precision": 0.7878787878787878,
            "recall": 0.4824742268041237
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7376165975485194,
            "auditor_fn_violation": 0.010139049148174754,
            "auditor_fp_violation": 0.007924760717425535,
            "ave_precision_score": 0.7379650653540233,
            "fpr": 0.06037321624588365,
            "logloss": 0.8303939301210567,
            "mae": 0.4264504717046878,
            "precision": 0.8178807947019867,
            "recall": 0.5266524520255863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5229777898497949,
            "auditor_fn_violation": 0.09814387773557606,
            "auditor_fp_violation": 0.07987694646452197,
            "ave_precision_score": 0.5253379080032735,
            "fpr": 0.2817982456140351,
            "logloss": 0.6938199181145783,
            "mae": 0.4997585399174376,
            "precision": 0.5451327433628319,
            "recall": 0.6350515463917525
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5430962204038438,
            "auditor_fn_violation": 0.08684661996587552,
            "auditor_fp_violation": 0.06822098931610135,
            "ave_precision_score": 0.544953253998494,
            "fpr": 0.270032930845225,
            "logloss": 0.6918843554191499,
            "mae": 0.4987287597585588,
            "precision": 0.5676625659050967,
            "recall": 0.6886993603411514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.766381805028034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.532763610056068,
            "fpr": 0.4682017543859649,
            "logloss": 0.6920067642959428,
            "mae": 0.4993314805130164,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7574094401756312,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5148188803512623,
            "fpr": 0.48518111964873767,
            "logloss": 0.6928766891480402,
            "mae": 0.499833015264978,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6695600293437529,
            "auditor_fn_violation": 0.012059142702116117,
            "auditor_fp_violation": 0.030152224824355967,
            "ave_precision_score": 0.6676746473541375,
            "fpr": 0.21052631578947367,
            "logloss": 1.472900156247472,
            "mae": 0.3202696509434035,
            "precision": 0.6773109243697479,
            "recall": 0.8309278350515464
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7180764139894286,
            "auditor_fn_violation": 0.007604286861131071,
            "auditor_fp_violation": 0.03198712567860887,
            "ave_precision_score": 0.7186197955309312,
            "fpr": 0.20636663007683864,
            "logloss": 1.0568794023102421,
            "mae": 0.301698738329145,
            "precision": 0.68561872909699,
            "recall": 0.8742004264392325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6918004516939127,
            "auditor_fn_violation": 0.013062940857297884,
            "auditor_fp_violation": 0.025637865154690003,
            "ave_precision_score": 0.6141904307027493,
            "fpr": 0.24342105263157895,
            "logloss": 6.791361358637456,
            "mae": 0.35430955576874373,
            "precision": 0.6407766990291263,
            "recall": 0.8164948453608247
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7341568437462251,
            "auditor_fn_violation": 0.011014396419970093,
            "auditor_fp_violation": 0.03405337479076744,
            "ave_precision_score": 0.6646969310926243,
            "fpr": 0.24478594950603733,
            "logloss": 5.166615402669632,
            "mae": 0.3180956756601105,
            "precision": 0.6521060842433697,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7987486473823915,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.006828033197748471,
            "ave_precision_score": 0.7593406743339226,
            "fpr": 0.44627192982456143,
            "logloss": 0.6907694739163516,
            "mae": 0.4987165675939698,
            "precision": 0.5401129943502825,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7982650391819918,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005294763349906382,
            "ave_precision_score": 0.761017727196166,
            "fpr": 0.4566410537870472,
            "logloss": 0.6915330544681981,
            "mae": 0.49897430887860866,
            "precision": 0.5256556442417332,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7814140575532061,
            "auditor_fn_violation": 0.008948272743714961,
            "auditor_fp_violation": 0.013219524220387035,
            "ave_precision_score": 0.7816548560025083,
            "fpr": 0.17763157894736842,
            "logloss": 0.9519630855443083,
            "mae": 0.32062461346742094,
            "precision": 0.7086330935251799,
            "recall": 0.8123711340206186
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7986048498989432,
            "auditor_fn_violation": 0.0003651181133691744,
            "auditor_fp_violation": 0.01175179182540196,
            "ave_precision_score": 0.7988066129289555,
            "fpr": 0.18551042810098792,
            "logloss": 0.8291901699030984,
            "mae": 0.3068378072453014,
            "precision": 0.7035087719298245,
            "recall": 0.8550106609808102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.605280575427143,
            "auditor_fn_violation": 0.0901880991137638,
            "auditor_fp_violation": 0.07775586507251737,
            "ave_precision_score": 0.608470306344196,
            "fpr": 0.22807017543859648,
            "logloss": 0.7247165634465135,
            "mae": 0.47054897171032634,
            "precision": 0.6075471698113207,
            "recall": 0.6639175257731958
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5645189126309637,
            "auditor_fn_violation": 0.07914169157349524,
            "auditor_fp_violation": 0.09029409281233393,
            "ave_precision_score": 0.5676602571469123,
            "fpr": 0.2524698133918771,
            "logloss": 0.7390464984393226,
            "mae": 0.4769482412830437,
            "precision": 0.5732838589981447,
            "recall": 0.6588486140724946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5630326790109755,
            "auditor_fn_violation": 0.02406628685114849,
            "auditor_fp_violation": 0.02953336209375899,
            "ave_precision_score": 0.5649025179876581,
            "fpr": 0.38377192982456143,
            "logloss": 0.6938749285867396,
            "mae": 0.49254546037532,
            "precision": 0.5558375634517766,
            "recall": 0.9030927835051547
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.571170493711964,
            "auditor_fn_violation": 0.01933253600275243,
            "auditor_fp_violation": 0.022403405337479084,
            "ave_precision_score": 0.5728678476886533,
            "fpr": 0.40504939626783754,
            "logloss": 0.6822140488367059,
            "mae": 0.4903675122994165,
            "precision": 0.5381727158948686,
            "recall": 0.9168443496801706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6864848384085822,
            "auditor_fn_violation": 0.014322210164586725,
            "auditor_fp_violation": 0.004491248613336634,
            "ave_precision_score": 0.5221116325525967,
            "fpr": 0.34210526315789475,
            "logloss": 0.6955258642625565,
            "mae": 0.5005615436259592,
            "precision": 0.517774343122102,
            "recall": 0.6907216494845361
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.6688983255363367,
            "auditor_fn_violation": 0.021825169276715062,
            "auditor_fp_violation": 0.01719804699723342,
            "ave_precision_score": 0.5021899793405067,
            "fpr": 0.35236004390779363,
            "logloss": 0.6967447599800339,
            "mae": 0.501166965906497,
            "precision": 0.49607535321821034,
            "recall": 0.673773987206823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7812853971644904,
            "auditor_fn_violation": 0.008948272743714961,
            "auditor_fp_violation": 0.014069497514277505,
            "ave_precision_score": 0.7815272617678927,
            "fpr": 0.1787280701754386,
            "logloss": 0.9531139940245912,
            "mae": 0.32089681540230125,
            "precision": 0.7073608617594255,
            "recall": 0.8123711340206186
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7983806155369888,
            "auditor_fn_violation": 0.00047512164752527695,
            "auditor_fp_violation": 0.01175179182540196,
            "ave_precision_score": 0.7985765609126685,
            "fpr": 0.18551042810098792,
            "logloss": 0.8300235951209683,
            "mae": 0.30704414367059607,
            "precision": 0.7024647887323944,
            "recall": 0.8507462686567164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7418647942827699,
            "auditor_fn_violation": 0.011075691806836683,
            "auditor_fp_violation": 0.022158367229549284,
            "ave_precision_score": 0.689802269152685,
            "fpr": 0.20175438596491227,
            "logloss": 3.828427033867536,
            "mae": 0.32228078874413646,
            "precision": 0.6805555555555556,
            "recall": 0.8082474226804124
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7802264782674322,
            "auditor_fn_violation": 0.01159952160165146,
            "auditor_fp_violation": 0.024228757618051863,
            "ave_precision_score": 0.7407977157843848,
            "fpr": 0.19758507135016465,
            "logloss": 2.7607237811808805,
            "mae": 0.3000476384321146,
            "precision": 0.689119170984456,
            "recall": 0.8507462686567164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7428086322591562,
            "auditor_fn_violation": 0.009565472960752398,
            "auditor_fp_violation": 0.021228789186079962,
            "ave_precision_score": 0.6907589471170333,
            "fpr": 0.19956140350877194,
            "logloss": 3.8065593100778417,
            "mae": 0.3206373546230103,
            "precision": 0.6840277777777778,
            "recall": 0.8123711340206186
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7805386202923056,
            "auditor_fn_violation": 0.010742898335669939,
            "auditor_fp_violation": 0.023632724220313806,
            "ave_precision_score": 0.7418036804807174,
            "fpr": 0.19978046103183314,
            "logloss": 2.7302293101842294,
            "mae": 0.3005037029865852,
            "precision": 0.6862068965517242,
            "recall": 0.8486140724946695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.767402465088163,
            "auditor_fn_violation": 0.007585006330258635,
            "auditor_fp_violation": 0.011450244463618066,
            "ave_precision_score": 0.7678673242132236,
            "fpr": 0.0625,
            "logloss": 0.6461067305037846,
            "mae": 0.43107677723336163,
            "precision": 0.7978723404255319,
            "recall": 0.4639175257731959
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7377392151511393,
            "auditor_fn_violation": 0.013467241181578386,
            "auditor_fp_violation": 0.011260064272268056,
            "ave_precision_score": 0.7380876146430123,
            "fpr": 0.054884742041712405,
            "logloss": 0.8305035937001128,
            "mae": 0.42624769096058535,
            "precision": 0.8257839721254355,
            "recall": 0.5053304904051172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5254993534736425,
            "auditor_fn_violation": 0.001035449448363176,
            "auditor_fp_violation": 0.0012120465097169167,
            "ave_precision_score": 0.5272296341196844,
            "fpr": 0.46600877192982454,
            "logloss": 0.6919411758370929,
            "mae": 0.4992040575792392,
            "precision": 0.5319383259911894,
            "recall": 0.9958762886597938
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5462035676487254,
            "auditor_fn_violation": 0.0011632288611825616,
            "auditor_fp_violation": 0.003054671163407542,
            "ave_precision_score": 0.5475080080437852,
            "fpr": 0.47859495060373214,
            "logloss": 0.6927220886860629,
            "mae": 0.49957523090124917,
            "precision": 0.5150166852057843,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7793362547263188,
            "auditor_fn_violation": 0.017272562850425034,
            "auditor_fp_violation": 0.020666420148732503,
            "ave_precision_score": 0.7792802378769144,
            "fpr": 0.2708333333333333,
            "logloss": 1.0538689436107533,
            "mae": 0.34519318788568,
            "precision": 0.6372980910425844,
            "recall": 0.8948453608247423
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7936817090652873,
            "auditor_fn_violation": 0.005855932818267142,
            "auditor_fp_violation": 0.018740283413880635,
            "ave_precision_score": 0.7936876001003212,
            "fpr": 0.265642151481888,
            "logloss": 0.9492796873447126,
            "mae": 0.33603929240883074,
            "precision": 0.644640234948605,
            "recall": 0.9360341151385928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7857166824930606,
            "auditor_fn_violation": 0.011356031832157719,
            "auditor_fp_violation": 0.013848658531574841,
            "ave_precision_score": 0.7857117183057853,
            "fpr": 0.18201754385964913,
            "logloss": 0.938188817438701,
            "mae": 0.3163418000764011,
            "precision": 0.7056737588652482,
            "recall": 0.8206185567010309
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8042260876430198,
            "auditor_fn_violation": 0.006693832078434861,
            "auditor_fp_violation": 0.01713596018496903,
            "ave_precision_score": 0.8039423547219635,
            "fpr": 0.18331503841931943,
            "logloss": 0.8161602028260396,
            "mae": 0.30141609685436727,
            "precision": 0.7100694444444444,
            "recall": 0.8720682302771855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6934981555087737,
            "auditor_fn_violation": 0.017344908663411103,
            "auditor_fp_violation": 0.02460813920046017,
            "ave_precision_score": 0.6170148969346367,
            "fpr": 0.24232456140350878,
            "logloss": 6.684855662073807,
            "mae": 0.3531826899511425,
            "precision": 0.6429725363489499,
            "recall": 0.8206185567010309
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7342758577521721,
            "auditor_fn_violation": 0.010490124257183585,
            "auditor_fp_violation": 0.0345898048487317,
            "ave_precision_score": 0.6651603965801993,
            "fpr": 0.24807903402854006,
            "logloss": 5.119269034680589,
            "mae": 0.31748072972756586,
            "precision": 0.6490683229813664,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6916349465425651,
            "auditor_fn_violation": 0.009059052269849883,
            "auditor_fp_violation": 0.02671124532643084,
            "ave_precision_score": 0.6920254136362733,
            "fpr": 0.20614035087719298,
            "logloss": 1.2504392371946653,
            "mae": 0.3127887011620078,
            "precision": 0.6861435726210351,
            "recall": 0.8474226804123711
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7567534828134438,
            "auditor_fn_violation": 0.010218626172883428,
            "auditor_fp_violation": 0.025410890523565686,
            "ave_precision_score": 0.7583995343116509,
            "fpr": 0.20197585071350166,
            "logloss": 0.8804084716577273,
            "mae": 0.29301033721620556,
            "precision": 0.6907563025210084,
            "recall": 0.8763326226012793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.777362468261175,
            "auditor_fn_violation": 0.007851781515644782,
            "auditor_fp_violation": 0.022743847323226107,
            "ave_precision_score": 0.7773538077402297,
            "fpr": 0.26206140350877194,
            "logloss": 1.0550777838567265,
            "mae": 0.3446157891364572,
            "precision": 0.6495601173020528,
            "recall": 0.9134020618556701
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7980974389071316,
            "auditor_fn_violation": 0.004559295415661228,
            "auditor_fp_violation": 0.020270102468074955,
            "ave_precision_score": 0.7984842455412223,
            "fpr": 0.27442371020856204,
            "logloss": 0.9225276402235201,
            "mae": 0.3370688796851275,
            "precision": 0.6366279069767442,
            "recall": 0.9339019189765458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6950089791072944,
            "auditor_fn_violation": 0.008783233857840479,
            "auditor_fp_violation": 0.025607050412917543,
            "ave_precision_score": 0.6928129830292266,
            "fpr": 0.20394736842105263,
            "logloss": 1.3051825031244706,
            "mae": 0.3141143760226192,
            "precision": 0.6879194630872483,
            "recall": 0.845360824742268
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7425702616875175,
            "auditor_fn_violation": 0.011992725723741337,
            "auditor_fp_violation": 0.027372833791120096,
            "ave_precision_score": 0.7431866341060213,
            "fpr": 0.20417124039517015,
            "logloss": 0.9330382584660895,
            "mae": 0.2949062830122842,
            "precision": 0.6889632107023411,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7403057637154367,
            "auditor_fn_violation": 0.01354449267498644,
            "auditor_fp_violation": 0.016722133201857104,
            "ave_precision_score": 0.7397373764324349,
            "fpr": 0.17434210526315788,
            "logloss": 1.3350906327607526,
            "mae": 0.33634590044707613,
            "precision": 0.7005649717514124,
            "recall": 0.7670103092783506
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7638420926898242,
            "auditor_fn_violation": 0.010960564903255402,
            "auditor_fp_violation": 0.019500225995996646,
            "ave_precision_score": 0.7636200352920989,
            "fpr": 0.17672886937431395,
            "logloss": 1.0688394525794676,
            "mae": 0.32182511754988574,
            "precision": 0.7051282051282052,
            "recall": 0.8208955223880597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7648776969225402,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5545201548572639,
            "fpr": 0.4682017543859649,
            "logloss": 0.6918903617144374,
            "mae": 0.4992220827231282,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7495468641190957,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5293070471538385,
            "fpr": 0.48518111964873767,
            "logloss": 0.6927212919676932,
            "mae": 0.49963746492216277,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5406556958499312,
            "auditor_fn_violation": 0.009825465726171103,
            "auditor_fp_violation": 0.011255084432392473,
            "ave_precision_score": 0.5424512432582622,
            "fpr": 0.38596491228070173,
            "logloss": 0.7130093533065318,
            "mae": 0.4907102168714924,
            "precision": 0.5504469987228607,
            "recall": 0.8886597938144329
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5415533763062956,
            "auditor_fn_violation": 0.0027500883539024377,
            "auditor_fp_violation": 0.009064674590599571,
            "ave_precision_score": 0.5421840967133034,
            "fpr": 0.40285400658616904,
            "logloss": 0.9100113497580428,
            "mae": 0.4913524496133479,
            "precision": 0.5372005044136192,
            "recall": 0.908315565031983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7019233247526766,
            "auditor_fn_violation": 0.014453336950623985,
            "auditor_fp_violation": 0.02904802991084269,
            "ave_precision_score": 0.6933713070430898,
            "fpr": 0.2225877192982456,
            "logloss": 1.8589280033994957,
            "mae": 0.3202970059450141,
            "precision": 0.6677577741407529,
            "recall": 0.8412371134020619
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7476830374875847,
            "auditor_fn_violation": 0.010333310708492978,
            "auditor_fp_violation": 0.02769568521489488,
            "ave_precision_score": 0.7455561966838746,
            "fpr": 0.2239297475301866,
            "logloss": 1.2652345142429873,
            "mae": 0.3018811679227751,
            "precision": 0.6725521669341894,
            "recall": 0.8933901918976546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.4183312680995624,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5502398210753787,
            "fpr": 0.4682017543859649,
            "logloss": 0.6918903775651214,
            "mae": 0.4992220933761513,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.3980054617570216,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5249963915363736,
            "fpr": 0.48518111964873767,
            "logloss": 0.6927212985362743,
            "mae": 0.4996374709415122,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7370283498100818,
            "auditor_fn_violation": 0.014740459395912465,
            "auditor_fp_violation": 0.021708985578700855,
            "ave_precision_score": 0.7357168171101617,
            "fpr": 0.1787280701754386,
            "logloss": 1.3533300182679036,
            "mae": 0.34078405675175516,
            "precision": 0.6970260223048327,
            "recall": 0.7731958762886598
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.762601128402843,
            "auditor_fn_violation": 0.01023266917724378,
            "auditor_fp_violation": 0.026255271170361257,
            "ave_precision_score": 0.763265610047152,
            "fpr": 0.1800219538968167,
            "logloss": 1.0633306186462215,
            "mae": 0.3220202258014206,
            "precision": 0.7028985507246377,
            "recall": 0.8272921108742004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 9292,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6687467984295034,
            "auditor_fn_violation": 0.01141029119189727,
            "auditor_fp_violation": 0.031300073955380266,
            "ave_precision_score": 0.6683403026855435,
            "fpr": 0.21710526315789475,
            "logloss": 1.4571518084548314,
            "mae": 0.3221228956845125,
            "precision": 0.6710963455149501,
            "recall": 0.8329896907216495
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7288705600827496,
            "auditor_fn_violation": 0.008877519256469731,
            "auditor_fp_violation": 0.03242918378193125,
            "ave_precision_score": 0.7303906003089409,
            "fpr": 0.20636663007683864,
            "logloss": 1.049522391150881,
            "mae": 0.29881031568332167,
            "precision": 0.6887417218543046,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7692870736581061,
            "auditor_fn_violation": 0.013230240549828179,
            "auditor_fp_violation": 0.013068018406672422,
            "ave_precision_score": 0.7690377998974186,
            "fpr": 0.18421052631578946,
            "logloss": 1.024283666943157,
            "mae": 0.3348397031858925,
            "precision": 0.7026548672566372,
            "recall": 0.8185567010309278
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.787683673909318,
            "auditor_fn_violation": 0.012231456797867338,
            "auditor_fp_violation": 0.021447268428607624,
            "ave_precision_score": 0.7886640589534075,
            "fpr": 0.19319429198682767,
            "logloss": 0.8781189762625337,
            "mae": 0.31397856149800457,
            "precision": 0.6986301369863014,
            "recall": 0.8699360341151386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.743034563973016,
            "auditor_fn_violation": 0.012748688732139633,
            "auditor_fp_violation": 0.017613192818110864,
            "ave_precision_score": 0.7424505652000067,
            "fpr": 0.17543859649122806,
            "logloss": 1.275371711229793,
            "mae": 0.33199905665184276,
            "precision": 0.7031539888682746,
            "recall": 0.7814432989690722
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7469871033656836,
            "auditor_fn_violation": 0.011798464163423122,
            "auditor_fp_violation": 0.023677426725144172,
            "ave_precision_score": 0.7471066661104566,
            "fpr": 0.1756311745334797,
            "logloss": 1.2008672759771752,
            "mae": 0.3117064068726169,
            "precision": 0.7106690777576854,
            "recall": 0.837953091684435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7075519588546193,
            "auditor_fn_violation": 0.004738650750587809,
            "auditor_fp_violation": 0.008425263979621185,
            "ave_precision_score": 0.7082887810379779,
            "fpr": 0.4232456140350877,
            "logloss": 0.7617093585033968,
            "mae": 0.4396497964284734,
            "precision": 0.5448113207547169,
            "recall": 0.9525773195876288
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6914262148770544,
            "auditor_fn_violation": 0.0036933101467728005,
            "auditor_fp_violation": 0.0034445763444278413,
            "ave_precision_score": 0.6920970334972878,
            "fpr": 0.44017563117453345,
            "logloss": 0.9655910044458864,
            "mae": 0.43884131950741384,
            "precision": 0.5254437869822485,
            "recall": 0.9466950959488273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7441843636531242,
            "auditor_fn_violation": 0.014509857117019352,
            "auditor_fp_violation": 0.015343173507539344,
            "ave_precision_score": 0.7452296491497772,
            "fpr": 0.19407894736842105,
            "logloss": 1.1342793073983588,
            "mae": 0.3188133214053121,
            "precision": 0.694300518134715,
            "recall": 0.8288659793814434
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8126965411100245,
            "auditor_fn_violation": 0.009340938400361376,
            "auditor_fp_violation": 0.032061629853326126,
            "ave_precision_score": 0.8131614622897838,
            "fpr": 0.19538968166849616,
            "logloss": 0.810190854327374,
            "mae": 0.28593495100685423,
            "precision": 0.7013422818791947,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6916433702319772,
            "auditor_fn_violation": 0.009059052269849883,
            "auditor_fp_violation": 0.02671124532643084,
            "ave_precision_score": 0.6920146857238163,
            "fpr": 0.20614035087719298,
            "logloss": 1.2504244470258739,
            "mae": 0.3127876982630837,
            "precision": 0.6861435726210351,
            "recall": 0.8474226804123711
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7567535145326412,
            "auditor_fn_violation": 0.010218626172883428,
            "auditor_fp_violation": 0.025410890523565686,
            "ave_precision_score": 0.7583964575495122,
            "fpr": 0.20197585071350166,
            "logloss": 0.8803969214299827,
            "mae": 0.2930094292655243,
            "precision": 0.6907563025210084,
            "recall": 0.8763326226012793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6706441037470245,
            "auditor_fn_violation": 0.012108880448544043,
            "auditor_fp_violation": 0.0312743950039032,
            "ave_precision_score": 0.6688454983433185,
            "fpr": 0.2138157894736842,
            "logloss": 1.4700478748830421,
            "mae": 0.3214975103452962,
            "precision": 0.6755407653910149,
            "recall": 0.8371134020618557
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7211921208524831,
            "auditor_fn_violation": 0.01092077639090107,
            "auditor_fp_violation": 0.031112943361926392,
            "ave_precision_score": 0.7217325389980603,
            "fpr": 0.20856201975850713,
            "logloss": 1.0477536310695035,
            "mae": 0.300944126000124,
            "precision": 0.6859504132231405,
            "recall": 0.8848614072494669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6977195934198086,
            "auditor_fn_violation": 0.009859377826008323,
            "auditor_fp_violation": 0.026703541640987715,
            "ave_precision_score": 0.695191827719384,
            "fpr": 0.20394736842105263,
            "logloss": 1.3123546944834765,
            "mae": 0.31347491340291234,
            "precision": 0.6868686868686869,
            "recall": 0.8412371134020619
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7445137014567944,
            "auditor_fn_violation": 0.011992725723741337,
            "auditor_fp_violation": 0.025333902876357846,
            "ave_precision_score": 0.7451102187269684,
            "fpr": 0.2030735455543359,
            "logloss": 0.9377060562670012,
            "mae": 0.2944514636439054,
            "precision": 0.6901172529313233,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7790590025907288,
            "auditor_fn_violation": 0.01694474588533189,
            "auditor_fp_violation": 0.019736842105263167,
            "ave_precision_score": 0.7790220860372641,
            "fpr": 0.2675438596491228,
            "logloss": 1.0676312231392575,
            "mae": 0.34409696507831905,
            "precision": 0.6395864106351551,
            "recall": 0.8927835051546392
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7933942130281629,
            "auditor_fn_violation": 0.006434036497768333,
            "auditor_fp_violation": 0.0162170753634562,
            "ave_precision_score": 0.7932095777452535,
            "fpr": 0.2645444566410538,
            "logloss": 0.9591326015940258,
            "mae": 0.334556764100839,
            "precision": 0.643491124260355,
            "recall": 0.9275053304904051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7672435568819999,
            "auditor_fn_violation": 0.01394917706637728,
            "auditor_fp_violation": 0.01312964789021735,
            "ave_precision_score": 0.7672685139259787,
            "fpr": 0.16666666666666666,
            "logloss": 0.9419589377919724,
            "mae": 0.33785216273975405,
            "precision": 0.7076923076923077,
            "recall": 0.7587628865979381
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7816749583526922,
            "auditor_fn_violation": 0.004262051823367093,
            "auditor_fp_violation": 0.018943928158107796,
            "ave_precision_score": 0.7841471036556151,
            "fpr": 0.16245883644346873,
            "logloss": 0.8243325475708291,
            "mae": 0.3181393018894185,
            "precision": 0.7180952380952381,
            "recall": 0.8038379530916845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 9292,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7443636611500088,
            "auditor_fn_violation": 0.012617561946102368,
            "auditor_fp_violation": 0.013211820534943918,
            "ave_precision_score": 0.743834818324888,
            "fpr": 0.16885964912280702,
            "logloss": 1.2799135631082037,
            "mae": 0.32942409565184677,
            "precision": 0.7066666666666667,
            "recall": 0.7649484536082474
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7711698129162335,
            "auditor_fn_violation": 0.011922510701939573,
            "auditor_fp_violation": 0.01878995286369214,
            "ave_precision_score": 0.7724460288080278,
            "fpr": 0.16355653128430298,
            "logloss": 0.9989699011998657,
            "mae": 0.3083111441506035,
            "precision": 0.7214953271028037,
            "recall": 0.8230277185501066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6905124785875536,
            "auditor_fn_violation": 0.013062940857297884,
            "auditor_fp_violation": 0.025637865154690003,
            "ave_precision_score": 0.6132388848578317,
            "fpr": 0.24342105263157895,
            "logloss": 6.787142625785396,
            "mae": 0.35430456426801027,
            "precision": 0.6407766990291263,
            "recall": 0.8164948453608247
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7343477853345401,
            "auditor_fn_violation": 0.011014396419970093,
            "auditor_fp_violation": 0.03405337479076744,
            "ave_precision_score": 0.6648877986089982,
            "fpr": 0.24478594950603733,
            "logloss": 5.160351191694696,
            "mae": 0.3177064590568321,
            "precision": 0.6521060842433697,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7618970052974067,
            "auditor_fn_violation": 0.02436923494302768,
            "auditor_fp_violation": 0.028043982908089907,
            "ave_precision_score": 0.7617939287626607,
            "fpr": 0.18859649122807018,
            "logloss": 1.0423173522481737,
            "mae": 0.33829862997840887,
            "precision": 0.6867030965391621,
            "recall": 0.777319587628866
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7850890689262838,
            "auditor_fn_violation": 0.006209348428002686,
            "auditor_fp_violation": 0.028480462521916654,
            "ave_precision_score": 0.7856861570187781,
            "fpr": 0.18880351262349068,
            "logloss": 0.8839674341140592,
            "mae": 0.31522495066678197,
            "precision": 0.6950354609929078,
            "recall": 0.835820895522388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7373868314151121,
            "auditor_fn_violation": 0.01415038885874481,
            "auditor_fp_violation": 0.024117671227248453,
            "ave_precision_score": 0.7359050535399052,
            "fpr": 0.17434210526315788,
            "logloss": 1.3616611989218952,
            "mae": 0.3387422691875718,
            "precision": 0.6988636363636364,
            "recall": 0.7608247422680412
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7615251879515208,
            "auditor_fn_violation": 0.013799592284773407,
            "auditor_fp_violation": 0.030184124650451248,
            "ave_precision_score": 0.7621354470571682,
            "fpr": 0.1734357848518112,
            "logloss": 1.0680384343923097,
            "mae": 0.32110740444984415,
            "precision": 0.7084870848708487,
            "recall": 0.8187633262260128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7457542165494225,
            "auditor_fn_violation": 0.010051546391752578,
            "auditor_fp_violation": 0.022856834709725136,
            "ave_precision_score": 0.6917241046685245,
            "fpr": 0.20285087719298245,
            "logloss": 3.8816439490079704,
            "mae": 0.3247754228800304,
            "precision": 0.6821305841924399,
            "recall": 0.8185567010309278
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7863821890810465,
            "auditor_fn_violation": 0.009525837957772686,
            "auditor_fp_violation": 0.02419150553069324,
            "ave_precision_score": 0.7461942329450489,
            "fpr": 0.2052689352360044,
            "logloss": 2.7856497160991327,
            "mae": 0.30329043646873394,
            "precision": 0.6835871404399323,
            "recall": 0.8614072494669509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.778838899548101,
            "auditor_fn_violation": 0.007725176342919154,
            "auditor_fp_violation": 0.010014791076050782,
            "ave_precision_score": 0.7792836091028914,
            "fpr": 0.0581140350877193,
            "logloss": 0.6417737223216466,
            "mae": 0.42449653077416216,
            "precision": 0.8072727272727273,
            "recall": 0.4577319587628866
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7453477021902148,
            "auditor_fn_violation": 0.012205711289873373,
            "auditor_fp_violation": 0.010025778444452172,
            "ave_precision_score": 0.745647258465539,
            "fpr": 0.05817782656421515,
            "logloss": 0.8229669407280414,
            "mae": 0.4192700651552075,
            "precision": 0.8172413793103448,
            "recall": 0.5053304904051172
        }
    }
]