[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.4987711739108541,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5004827798700835,
            "fpr": 0.06030701754385965,
            "logloss": 0.6719379351331988,
            "mae": 0.48493116706805794,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5003553786189441,
            "auditor_fn_violation": 0.07519093624319162,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.5025859551722036,
            "fpr": 0.06695938529088913,
            "logloss": 0.6721503766590923,
            "mae": 0.4843862254323865,
            "precision": 0.7024390243902439,
            "recall": 0.3044397463002114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 24481,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.216174831087763,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6961547438754006,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.5890434306794344,
            "fpr": 0.07236842105263158,
            "logloss": 0.6740824372194324,
            "mae": 0.4760317597187838,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6873513151569682,
            "auditor_fn_violation": 0.08250116615572414,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.5791646309815675,
            "fpr": 0.07683863885839737,
            "logloss": 0.6683575505691433,
            "mae": 0.4771466094761349,
            "precision": 0.6929824561403509,
            "recall": 0.33403805496828753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.600976090769362,
            "auditor_fn_violation": 0.06006993835941205,
            "auditor_fp_violation": 0.043251618024178776,
            "ave_precision_score": 0.6027032534915647,
            "fpr": 0.09539473684210527,
            "logloss": 0.7153023114116075,
            "mae": 0.44476432063241017,
            "precision": 0.7175324675324676,
            "recall": 0.4594594594594595
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6016397243415171,
            "auditor_fn_violation": 0.06028735005326027,
            "auditor_fp_violation": 0.03613120210115835,
            "ave_precision_score": 0.6035890481647314,
            "fpr": 0.10647639956092206,
            "logloss": 0.7275501804925979,
            "mae": 0.4450767435763199,
            "precision": 0.6978193146417445,
            "recall": 0.47357293868921774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.60875769331351,
            "auditor_fn_violation": 0.0012651821862348178,
            "auditor_fp_violation": 0.007125920950869052,
            "ave_precision_score": 0.6102522647765574,
            "fpr": 0.4473684210526316,
            "logloss": 0.8688320653580005,
            "mae": 0.46861191587359236,
            "precision": 0.5363636363636364,
            "recall": 0.9812889812889813
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6157634146998023,
            "auditor_fn_violation": 0.0014666873983239853,
            "auditor_fp_violation": 0.007698900801467613,
            "ave_precision_score": 0.6169841514906995,
            "fpr": 0.45334796926454446,
            "logloss": 0.8757548554105036,
            "mae": 0.4714544701065897,
            "precision": 0.5306818181818181,
            "recall": 0.9873150105708245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6525915648950705,
            "auditor_fn_violation": 0.01393524090892512,
            "auditor_fp_violation": 0.022871127935848907,
            "ave_precision_score": 0.6428382826822452,
            "fpr": 0.41228070175438597,
            "logloss": 0.7647865798945402,
            "mae": 0.4485349465945834,
            "precision": 0.5453446191051995,
            "recall": 0.9376299376299376
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6500041187310133,
            "auditor_fn_violation": 0.006609376124092893,
            "auditor_fp_violation": 0.006420762973098955,
            "ave_precision_score": 0.6394773694589737,
            "fpr": 0.433589462129528,
            "logloss": 0.7902644682387626,
            "mae": 0.45097672828073426,
            "precision": 0.536928487690504,
            "recall": 0.9682875264270613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7619960410240925,
            "auditor_fn_violation": 4.1032935769778176e-05,
            "auditor_fp_violation": 0.0003078316440753918,
            "ave_precision_score": 0.5288917943739457,
            "fpr": 0.4649122807017544,
            "logloss": 0.7132798798439783,
            "mae": 0.4981637097664481,
            "precision": 0.5288888888888889,
            "recall": 0.9896049896049897
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7556198675149041,
            "auditor_fn_violation": 0.0022650109189307106,
            "auditor_fp_violation": 0.0005989704725100089,
            "ave_precision_score": 0.5183657623165421,
            "fpr": 0.47530186608122943,
            "logloss": 0.7779554877423912,
            "mae": 0.5004304286469,
            "precision": 0.5183537263626251,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6726547735471006,
            "mae": 0.4789372608065605,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6741867221628624,
            "mae": 0.4791736293637268,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6631528574922113,
            "auditor_fn_violation": 0.004819090345406136,
            "auditor_fp_violation": 0.01064436032075548,
            "ave_precision_score": 0.6641078900392012,
            "fpr": 0.4024122807017544,
            "logloss": 0.6912346736732012,
            "mae": 0.4685448977377331,
            "precision": 0.5529841656516443,
            "recall": 0.9438669438669439
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6519544878023713,
            "auditor_fn_violation": 0.0036226250455438924,
            "auditor_fp_violation": 0.007819196126490532,
            "ave_precision_score": 0.6525904680581092,
            "fpr": 0.4281009879253567,
            "logloss": 0.7041425696544095,
            "mae": 0.4748951494039479,
            "precision": 0.5329341317365269,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6727085657528176,
            "mae": 0.4789931168616341,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6742052455248286,
            "mae": 0.4792200744348352,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6022960238620486,
            "auditor_fn_violation": 0.0012651821862348178,
            "auditor_fp_violation": 0.007125920950869052,
            "ave_precision_score": 0.6038335005795556,
            "fpr": 0.4473684210526316,
            "logloss": 0.9543207258613762,
            "mae": 0.46713662036416825,
            "precision": 0.5363636363636364,
            "recall": 0.9812889812889813
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6141136629903672,
            "auditor_fn_violation": 0.0014666873983239853,
            "auditor_fp_violation": 0.007698900801467613,
            "ave_precision_score": 0.6153316539277704,
            "fpr": 0.45334796926454446,
            "logloss": 0.9614653203131647,
            "mae": 0.47011930033417354,
            "precision": 0.5306818181818181,
            "recall": 0.9873150105708245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7654439024183732,
            "auditor_fn_violation": 0.012779479884743051,
            "auditor_fp_violation": 0.013651442992632396,
            "ave_precision_score": 0.7670289029642001,
            "fpr": 0.12828947368421054,
            "logloss": 1.378039854986478,
            "mae": 0.330208238808476,
            "precision": 0.7297921478060047,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.759652371840216,
            "auditor_fn_violation": 0.01826165053387886,
            "auditor_fp_violation": 0.017322526803302117,
            "ave_precision_score": 0.7601799950813299,
            "fpr": 0.14270032930845225,
            "logloss": 1.245964403101489,
            "mae": 0.32027034783889197,
            "precision": 0.7167755991285403,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6928397119801779,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5865301262831395,
            "fpr": 0.06030701754385965,
            "logloss": 0.6718909939748676,
            "mae": 0.48490774961547894,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6834115472682962,
            "auditor_fn_violation": 0.07519093624319162,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.5782200287491132,
            "fpr": 0.06695938529088913,
            "logloss": 0.6721077856804506,
            "mae": 0.48436510553082573,
            "precision": 0.7024390243902439,
            "recall": 0.3044397463002114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5818250529678325,
            "auditor_fn_violation": 0.0012651821862348178,
            "auditor_fp_violation": 0.007125920950869052,
            "ave_precision_score": 0.5921927676445616,
            "fpr": 0.4473684210526316,
            "logloss": 0.8068214503832771,
            "mae": 0.4702957357819143,
            "precision": 0.5363636363636364,
            "recall": 0.9812889812889813
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6328426274212292,
            "auditor_fn_violation": 0.0014666873983239853,
            "auditor_fp_violation": 0.007698900801467613,
            "ave_precision_score": 0.5796570298645907,
            "fpr": 0.45334796926454446,
            "logloss": 0.814043251111726,
            "mae": 0.4731542452368333,
            "precision": 0.5306818181818181,
            "recall": 0.9873150105708245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.672680110325094,
            "mae": 0.47895620518216964,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6742027542476364,
            "mae": 0.47918995635831396,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6726405924535133,
            "mae": 0.47892810920612855,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6741771935648707,
            "mae": 0.47916595263224665,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7619960410240925,
            "auditor_fn_violation": 4.1032935769778176e-05,
            "auditor_fp_violation": 0.0003078316440753918,
            "ave_precision_score": 0.5288917943739457,
            "fpr": 0.4649122807017544,
            "logloss": 0.7138157380379421,
            "mae": 0.4981585448374427,
            "precision": 0.5288888888888889,
            "recall": 0.9896049896049897
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7556198675149041,
            "auditor_fn_violation": 0.0022650109189307106,
            "auditor_fp_violation": 0.0005989704725100089,
            "ave_precision_score": 0.5183657623165421,
            "fpr": 0.47530186608122943,
            "logloss": 0.7784255475281202,
            "mae": 0.5004460871815104,
            "precision": 0.5183537263626251,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7619960410240925,
            "auditor_fn_violation": 4.1032935769778176e-05,
            "auditor_fp_violation": 0.0003078316440753918,
            "ave_precision_score": 0.5288917943739457,
            "fpr": 0.4649122807017544,
            "logloss": 0.7133515242870009,
            "mae": 0.49816412029658114,
            "precision": 0.5288888888888889,
            "recall": 0.9896049896049897
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7556198675149041,
            "auditor_fn_violation": 0.0022650109189307106,
            "auditor_fp_violation": 0.0005989704725100089,
            "ave_precision_score": 0.5183657623165421,
            "fpr": 0.47530186608122943,
            "logloss": 0.7779957329850028,
            "mae": 0.5004312599351284,
            "precision": 0.5183537263626251,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 24481,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6656025367454899,
            "auditor_fn_violation": 0.014785534522376628,
            "auditor_fp_violation": 0.0272367403427362,
            "ave_precision_score": 0.6595905667113994,
            "fpr": 0.20175438596491227,
            "logloss": 2.0572489524095907,
            "mae": 0.3345577584845195,
            "precision": 0.6702508960573477,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6816685499945219,
            "auditor_fn_violation": 0.008342944931922036,
            "auditor_fp_violation": 0.0243598033171436,
            "ave_precision_score": 0.6740671314433817,
            "fpr": 0.19538968166849616,
            "logloss": 1.873802260193004,
            "mae": 0.3190736827460504,
            "precision": 0.6751824817518248,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 24481,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7821128440733316,
            "auditor_fn_violation": 0.01876344968450232,
            "auditor_fp_violation": 0.026063927219440713,
            "ave_precision_score": 0.7820010304971904,
            "fpr": 0.10087719298245613,
            "logloss": 1.1763547875948266,
            "mae": 0.3147542675982059,
            "precision": 0.7682619647355163,
            "recall": 0.6340956340956341
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7704068030130639,
            "auditor_fn_violation": 0.02409823092436117,
            "auditor_fp_violation": 0.01940263346515696,
            "ave_precision_score": 0.7709695739718327,
            "fpr": 0.10976948408342481,
            "logloss": 1.0650331216639373,
            "mae": 0.31289040851888494,
            "precision": 0.7566909975669099,
            "recall": 0.6575052854122622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.49866518473233895,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5003965464024681,
            "fpr": 0.06030701754385965,
            "logloss": 0.6729266901921889,
            "mae": 0.48542194622323703,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.4999766080184863,
            "auditor_fn_violation": 0.07519093624319162,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.502120959269582,
            "fpr": 0.06695938529088913,
            "logloss": 0.673047163089123,
            "mae": 0.48482776671222744,
            "precision": 0.7024390243902439,
            "recall": 0.3044397463002114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.773055712801595,
            "auditor_fn_violation": 0.01365484918116498,
            "auditor_fp_violation": 0.018146802621402693,
            "ave_precision_score": 0.7746065425971167,
            "fpr": 0.12828947368421054,
            "logloss": 1.2945697499002642,
            "mae": 0.3265472439754255,
            "precision": 0.7328767123287672,
            "recall": 0.6673596673596673
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7677652939259918,
            "auditor_fn_violation": 0.015616043517914704,
            "auditor_fp_violation": 0.017931521886230702,
            "ave_precision_score": 0.7687533539806048,
            "fpr": 0.141602634467618,
            "logloss": 1.1546858202070713,
            "mae": 0.31673369336784585,
            "precision": 0.7213822894168467,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7744990685333848,
            "auditor_fn_violation": 0.015318962687383742,
            "auditor_fp_violation": 0.018960902837139255,
            "ave_precision_score": 0.7760277397602884,
            "fpr": 0.1337719298245614,
            "logloss": 1.264182714821182,
            "mae": 0.32613602915812373,
            "precision": 0.7282850779510023,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7684062025486078,
            "auditor_fn_violation": 0.015616043517914704,
            "auditor_fp_violation": 0.01829742016650878,
            "ave_precision_score": 0.7693858984530878,
            "fpr": 0.1437980241492865,
            "logloss": 1.1471421061175693,
            "mae": 0.31614236483683006,
            "precision": 0.7182795698924731,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6727040902941792,
            "mae": 0.478983464046267,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6742084147307494,
            "mae": 0.479212336790156,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6726771823731155,
            "mae": 0.47895356038944764,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6742016899707687,
            "mae": 0.4791878687236233,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7065499770175467,
            "auditor_fn_violation": 0.022960207170733483,
            "auditor_fp_violation": 0.03250295111328205,
            "ave_precision_score": 0.7071210060118011,
            "fpr": 0.10416666666666667,
            "logloss": 2.2854300418136884,
            "mae": 0.4140237948102942,
            "precision": 0.6843853820598007,
            "recall": 0.4282744282744283
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7056887595273134,
            "auditor_fn_violation": 0.019278120597907192,
            "auditor_fp_violation": 0.0201043561944574,
            "ave_precision_score": 0.706506278066422,
            "fpr": 0.10757409440175632,
            "logloss": 2.234445023788481,
            "mae": 0.39708089778028927,
            "precision": 0.69375,
            "recall": 0.4693446088794926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7591368157047587,
            "auditor_fn_violation": 0.012097877229456194,
            "auditor_fp_violation": 0.010051593601172306,
            "ave_precision_score": 0.7606019157494885,
            "fpr": 0.06798245614035088,
            "logloss": 1.682827686503296,
            "mae": 0.34770066610961475,
            "precision": 0.7933333333333333,
            "recall": 0.49480249480249483
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7506731825159634,
            "auditor_fn_violation": 0.017314801707112748,
            "auditor_fp_violation": 0.0062703938168202945,
            "ave_precision_score": 0.751198061776889,
            "fpr": 0.07574094401756312,
            "logloss": 1.5857021180008157,
            "mae": 0.3486395158597915,
            "precision": 0.7730263157894737,
            "recall": 0.49682875264270615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8102883792100399,
            "auditor_fn_violation": 0.014523379654958611,
            "auditor_fp_violation": 0.007993446493263326,
            "ave_precision_score": 0.8105355917164906,
            "fpr": 0.06798245614035088,
            "logloss": 1.0035119670795702,
            "mae": 0.31024404463985017,
            "precision": 0.8154761904761905,
            "recall": 0.5696465696465697
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8063357516240977,
            "auditor_fn_violation": 0.021334267805051266,
            "auditor_fp_violation": 0.009458219929927977,
            "ave_precision_score": 0.8066959413336969,
            "fpr": 0.07574094401756312,
            "logloss": 0.9206378834685657,
            "mae": 0.3105511411851019,
            "precision": 0.7976539589442815,
            "recall": 0.5750528541226215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7596790822809794,
            "auditor_fn_violation": 0.019372104898420697,
            "auditor_fp_violation": 0.00744392884764115,
            "ave_precision_score": 0.7611246228117166,
            "fpr": 0.06140350877192982,
            "logloss": 1.7333896084295244,
            "mae": 0.35162886302678603,
            "precision": 0.8021201413427562,
            "recall": 0.47193347193347196
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7504718425772674,
            "auditor_fn_violation": 0.02078193932277103,
            "auditor_fp_violation": 0.006363121463192136,
            "ave_precision_score": 0.7510158602914705,
            "fpr": 0.07135016465422613,
            "logloss": 1.5966859303957641,
            "mae": 0.3517455825228492,
            "precision": 0.7758620689655172,
            "recall": 0.47568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6538119919077241,
            "auditor_fn_violation": 0.014573531020899439,
            "auditor_fp_violation": 0.02622674726258803,
            "ave_precision_score": 0.6533213212025722,
            "fpr": 0.11513157894736842,
            "logloss": 2.9455071760522507,
            "mae": 0.36026549143979036,
            "precision": 0.7388059701492538,
            "recall": 0.6174636174636174
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6674881708174367,
            "auditor_fn_violation": 0.018767564857984285,
            "auditor_fp_violation": 0.019447744212040558,
            "ave_precision_score": 0.6664510732884684,
            "fpr": 0.12294182217343579,
            "logloss": 2.4369886126467226,
            "mae": 0.35909328130124235,
            "precision": 0.7171717171717171,
            "recall": 0.6004228329809725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7173276868997042,
            "auditor_fn_violation": 0.007002954371375428,
            "auditor_fp_violation": 0.024064293564537792,
            "ave_precision_score": 0.6913158445256185,
            "fpr": 0.16776315789473684,
            "logloss": 2.8868900442098133,
            "mae": 0.2957538142771703,
            "precision": 0.711864406779661,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7300384499746984,
            "auditor_fn_violation": 0.007755805831010689,
            "auditor_fp_violation": 0.013593371727591235,
            "ave_precision_score": 0.7081501967832766,
            "fpr": 0.15916575192096596,
            "logloss": 2.605250723005376,
            "mae": 0.29536202337226575,
            "precision": 0.7134387351778656,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7802354347996725,
            "auditor_fn_violation": 0.009143505854032175,
            "auditor_fp_violation": 0.019553669556722435,
            "ave_precision_score": 0.7817564251965414,
            "fpr": 0.13267543859649122,
            "logloss": 1.2215032626730535,
            "mae": 0.32430510789985634,
            "precision": 0.7328918322295805,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7767970316928797,
            "auditor_fn_violation": 0.022554960165048748,
            "auditor_fp_violation": 0.017322526803302107,
            "ave_precision_score": 0.7777393031158951,
            "fpr": 0.1437980241492865,
            "logloss": 1.0970707406317144,
            "mae": 0.31362630171273803,
            "precision": 0.7194860813704497,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7633851042900767,
            "auditor_fn_violation": 0.013025677499361713,
            "auditor_fp_violation": 0.01645754467374934,
            "ave_precision_score": 0.7649002064193062,
            "fpr": 0.12390350877192982,
            "logloss": 1.4781755986996712,
            "mae": 0.33496620502841273,
            "precision": 0.7303102625298329,
            "recall": 0.6361746361746362
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7562664816055723,
            "auditor_fn_violation": 0.02117181825143942,
            "auditor_fp_violation": 0.010352916409786028,
            "ave_precision_score": 0.7572160774614205,
            "fpr": 0.12843029637760703,
            "logloss": 1.3430071792475542,
            "mae": 0.32666829119117635,
            "precision": 0.7259953161592506,
            "recall": 0.6553911205073996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6538598268475412,
            "auditor_fn_violation": 0.018293850530692636,
            "auditor_fp_violation": 0.019693593031302154,
            "ave_precision_score": 0.6533802149804367,
            "fpr": 0.2050438596491228,
            "logloss": 3.0867985045776813,
            "mae": 0.3516123972877521,
            "precision": 0.6593806921675774,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6697681191106625,
            "auditor_fn_violation": 0.02116253541980446,
            "auditor_fp_violation": 0.02407410192021413,
            "ave_precision_score": 0.6680808330983294,
            "fpr": 0.2074643249176729,
            "logloss": 2.5873955393570727,
            "mae": 0.3426637993671019,
            "precision": 0.6506469500924215,
            "recall": 0.7441860465116279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7593067790481952,
            "auditor_fn_violation": 0.017621366305576834,
            "auditor_fp_violation": 0.00744392884764115,
            "ave_precision_score": 0.7607528360629939,
            "fpr": 0.06140350877192982,
            "logloss": 1.7498062416193885,
            "mae": 0.35208570616954554,
            "precision": 0.8,
            "recall": 0.4656964656964657
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.750517190783531,
            "auditor_fn_violation": 0.02297500829653078,
            "auditor_fp_violation": 0.005438351152078353,
            "ave_precision_score": 0.7510573432493135,
            "fpr": 0.07025246981339188,
            "logloss": 1.612139796217301,
            "mae": 0.3520900905747825,
            "precision": 0.775438596491228,
            "recall": 0.46723044397463004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6748544118392913,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5853664638442095,
            "fpr": 0.06030701754385965,
            "logloss": 0.6733663122656108,
            "mae": 0.485452163866476,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6774964891636368,
            "auditor_fn_violation": 0.07571309552265824,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.577508439835736,
            "fpr": 0.06695938529088913,
            "logloss": 0.6741200208124134,
            "mae": 0.4855911800091929,
            "precision": 0.7038834951456311,
            "recall": 0.30655391120507397
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6632810103965935,
            "auditor_fn_violation": 0.007016632016632018,
            "auditor_fp_violation": 0.009435930313021538,
            "ave_precision_score": 0.6642356629455174,
            "fpr": 0.40899122807017546,
            "logloss": 0.7038021835042676,
            "mae": 0.4684827059115234,
            "precision": 0.5522208883553421,
            "recall": 0.9563409563409564
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6515181653861141,
            "auditor_fn_violation": 0.003682963451171147,
            "auditor_fp_violation": 0.00852843731360491,
            "ave_precision_score": 0.6521548834633406,
            "fpr": 0.433589462129528,
            "logloss": 0.7181882430027204,
            "mae": 0.4752119691259382,
            "precision": 0.5347467608951708,
            "recall": 0.959830866807611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7429060460028114,
            "auditor_fn_violation": 0.014708027865922613,
            "auditor_fp_violation": 0.02929997557699353,
            "ave_precision_score": 0.7284832603125515,
            "fpr": 0.12390350877192982,
            "logloss": 1.7670833923014788,
            "mae": 0.32641081868017263,
            "precision": 0.7378190255220418,
            "recall": 0.6611226611226612
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.73354142380331,
            "auditor_fn_violation": 0.009150551284163722,
            "auditor_fp_violation": 0.01899162443799528,
            "ave_precision_score": 0.7179007368975505,
            "fpr": 0.11855104281009879,
            "logloss": 1.7725591412244193,
            "mae": 0.3288587484967271,
            "precision": 0.7372262773722628,
            "recall": 0.6405919661733616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6330159706822716,
            "auditor_fn_violation": 0.07781212386475547,
            "auditor_fp_violation": 0.033184760043961405,
            "ave_precision_score": 0.6180918941766305,
            "fpr": 0.07785087719298246,
            "logloss": 0.6728632429925456,
            "mae": 0.4790385396857011,
            "precision": 0.6939655172413793,
            "recall": 0.33471933471933474
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6178938373743772,
            "auditor_fn_violation": 0.08401426771222294,
            "auditor_fp_violation": 0.045276152955505765,
            "ave_precision_score": 0.6090486353800111,
            "fpr": 0.07903402854006586,
            "logloss": 0.6736824486728465,
            "mae": 0.47893055628997433,
            "precision": 0.6936170212765957,
            "recall": 0.34460887949260044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6894603327998134,
            "auditor_fn_violation": 0.010258233942444484,
            "auditor_fp_violation": 0.009598750356168844,
            "ave_precision_score": 0.6841865732436945,
            "fpr": 0.08881578947368421,
            "logloss": 2.744690038839827,
            "mae": 0.34353380356063445,
            "precision": 0.7582089552238805,
            "recall": 0.5280665280665281
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7106400130901217,
            "auditor_fn_violation": 0.01475274017586325,
            "auditor_fp_violation": 0.006510984466866162,
            "ave_precision_score": 0.7048250505145339,
            "fpr": 0.08562019758507135,
            "logloss": 2.404914373735255,
            "mae": 0.33576565842941647,
            "precision": 0.7657657657657657,
            "recall": 0.5391120507399577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7597276085663568,
            "auditor_fn_violation": 0.01489495568442937,
            "auditor_fp_violation": 0.005978548459315342,
            "ave_precision_score": 0.7611649688126326,
            "fpr": 0.03289473684210526,
            "logloss": 2.0857414719407883,
            "mae": 0.38512598763027656,
            "precision": 0.8461538461538461,
            "recall": 0.34303534303534305
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7481408051090698,
            "auditor_fn_violation": 0.02411679658763109,
            "auditor_fp_violation": 0.004786751474870809,
            "ave_precision_score": 0.7490933499522676,
            "fpr": 0.04061470911086718,
            "logloss": 1.958566081840216,
            "mae": 0.3888081688545537,
            "precision": 0.8112244897959183,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7599047671807599,
            "auditor_fn_violation": 0.014828847065689177,
            "auditor_fp_violation": 0.009621646924736436,
            "ave_precision_score": 0.761345300913997,
            "fpr": 0.03508771929824561,
            "logloss": 2.011657107332584,
            "mae": 0.3784903369825177,
            "precision": 0.8461538461538461,
            "recall": 0.3659043659043659
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7492463999759149,
            "auditor_fn_violation": 0.02389632933630077,
            "auditor_fp_violation": 0.0027442371020856204,
            "ave_precision_score": 0.7501932768719828,
            "fpr": 0.042810098792535674,
            "logloss": 1.8853642009281883,
            "mae": 0.3811245695390949,
            "precision": 0.8169014084507042,
            "recall": 0.3678646934460888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 24481,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.675207846810002,
            "auditor_fn_violation": 0.016898730714520197,
            "auditor_fp_violation": 0.019657976146863678,
            "ave_precision_score": 0.6746829283642313,
            "fpr": 0.20723684210526316,
            "logloss": 2.626398002663481,
            "mae": 0.3456634181250666,
            "precision": 0.6606822262118492,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6978568450142837,
            "auditor_fn_violation": 0.023826708099038536,
            "auditor_fp_violation": 0.02854006586169045,
            "ave_precision_score": 0.6969212561911566,
            "fpr": 0.21514818880351264,
            "logloss": 2.1360020398810122,
            "mae": 0.33169539290703537,
            "precision": 0.6530973451327433,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.49864737175309454,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5003795581451557,
            "fpr": 0.06030701754385965,
            "logloss": 0.6728686636585173,
            "mae": 0.4853933934253036,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.4999838755580174,
            "auditor_fn_violation": 0.07519093624319162,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.5021272566121471,
            "fpr": 0.06695938529088913,
            "logloss": 0.6729942626176854,
            "mae": 0.4848020226417598,
            "precision": 0.7024390243902439,
            "recall": 0.3044397463002114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.709558850372099,
            "auditor_fn_violation": 0.006430772878141314,
            "auditor_fp_violation": 0.014587658240729436,
            "ave_precision_score": 0.711207762019975,
            "fpr": 0.10855263157894737,
            "logloss": 2.1525240264421868,
            "mae": 0.37857595583213816,
            "precision": 0.7211267605633803,
            "recall": 0.5322245322245323
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7010470690055008,
            "auditor_fn_violation": 0.014075093466511033,
            "auditor_fp_violation": 0.012365356951315479,
            "ave_precision_score": 0.7021201246055653,
            "fpr": 0.1207464324917673,
            "logloss": 1.7926203180605225,
            "mae": 0.36992126218068855,
            "precision": 0.6986301369863014,
            "recall": 0.5391120507399577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6971859966376963,
            "auditor_fn_violation": 0.020457198088777055,
            "auditor_fp_violation": 0.029409370293483134,
            "ave_precision_score": 0.6977355591264434,
            "fpr": 0.09758771929824561,
            "logloss": 2.668823537412111,
            "mae": 0.4275606811152918,
            "precision": 0.6843971631205674,
            "recall": 0.40124740124740127
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6982628679738245,
            "auditor_fn_violation": 0.020120537568779982,
            "auditor_fp_violation": 0.018029261837811828,
            "ave_precision_score": 0.6990975998115627,
            "fpr": 0.10318331503841932,
            "logloss": 2.6221856043757117,
            "mae": 0.40789233237177436,
            "precision": 0.6866666666666666,
            "recall": 0.4355179704016913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7018749839964343,
            "auditor_fn_violation": 0.06408888645730752,
            "auditor_fp_violation": 0.025979973134692882,
            "ave_precision_score": 0.600403178791434,
            "fpr": 0.05043859649122807,
            "logloss": 0.6677717027898609,
            "mae": 0.4780793373325938,
            "precision": 0.7430167597765364,
            "recall": 0.2765072765072765
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6869472537379503,
            "auditor_fn_violation": 0.06944718416905894,
            "auditor_fp_violation": 0.034136304627861394,
            "ave_precision_score": 0.5874979389254933,
            "fpr": 0.05817782656421515,
            "logloss": 0.6688545254380365,
            "mae": 0.47864438244167196,
            "precision": 0.7150537634408602,
            "recall": 0.28118393234672306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7806990110049737,
            "auditor_fn_violation": 0.018856913593755697,
            "auditor_fp_violation": 0.019032136606016208,
            "ave_precision_score": 0.7822235579330548,
            "fpr": 0.13486842105263158,
            "logloss": 1.2177528801104263,
            "mae": 0.3236565624869128,
            "precision": 0.7296703296703296,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7790848190887181,
            "auditor_fn_violation": 0.021854106376609127,
            "auditor_fp_violation": 0.019798605576690775,
            "ave_precision_score": 0.7800515667836256,
            "fpr": 0.14928649835345773,
            "logloss": 1.086182954431826,
            "mae": 0.3104502939933313,
            "precision": 0.7130801687763713,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6964323802197279,
            "auditor_fn_violation": 0.019212532370427114,
            "auditor_fp_violation": 0.02115642935645378,
            "ave_precision_score": 0.6968406879795392,
            "fpr": 0.13706140350877194,
            "logloss": 2.2381009337324245,
            "mae": 0.43666479380135215,
            "precision": 0.6355685131195336,
            "recall": 0.45322245322245325
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.701532268211768,
            "auditor_fn_violation": 0.015407179806128074,
            "auditor_fp_violation": 0.022435078116776693,
            "ave_precision_score": 0.7020604214407619,
            "fpr": 0.13172338090010977,
            "logloss": 2.0175642234374305,
            "mae": 0.41962007237172744,
            "precision": 0.6480938416422287,
            "recall": 0.46723044397463004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7604652131734199,
            "auditor_fn_violation": 0.010132855527592384,
            "auditor_fp_violation": 0.01523893841331868,
            "ave_precision_score": 0.7619827324936239,
            "fpr": 0.12609649122807018,
            "logloss": 1.5050304448313547,
            "mae": 0.33627111979100954,
            "precision": 0.7268408551068883,
            "recall": 0.6361746361746362
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7522153535150468,
            "auditor_fn_violation": 0.0215431315168379,
            "auditor_fp_violation": 0.012768847520663231,
            "ave_precision_score": 0.7531813769887119,
            "fpr": 0.132821075740944,
            "logloss": 1.3756586033674394,
            "mae": 0.3285221931430313,
            "precision": 0.7211981566820277,
            "recall": 0.6617336152219874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7595314744488506,
            "auditor_fn_violation": 0.011514297698508228,
            "auditor_fp_violation": 0.0010303455855415814,
            "ave_precision_score": 0.760961630273759,
            "fpr": 0.05701754385964912,
            "logloss": 1.7449582305674487,
            "mae": 0.35183620531443255,
            "precision": 0.8156028368794326,
            "recall": 0.4781704781704782
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7550702218600172,
            "auditor_fn_violation": 0.01642597057806515,
            "auditor_fp_violation": 0.006546070603331181,
            "ave_precision_score": 0.7557020192798214,
            "fpr": 0.06147091108671789,
            "logloss": 1.5695692304320092,
            "mae": 0.3481990597478531,
            "precision": 0.7992831541218638,
            "recall": 0.4714587737843552
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6726400264282334,
            "mae": 0.4789277603686379,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6741767753779235,
            "mae": 0.47916564976737214,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7930039529104171,
            "auditor_fn_violation": 0.011546212204106942,
            "auditor_fp_violation": 0.009308727154312696,
            "ave_precision_score": 0.7923649613044081,
            "fpr": 0.08552631578947369,
            "logloss": 1.1455263051285636,
            "mae": 0.31361031686990093,
            "precision": 0.7815126050420168,
            "recall": 0.58004158004158
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7839851422169541,
            "auditor_fn_violation": 0.015395576266584355,
            "auditor_fp_violation": 0.00990932739876397,
            "ave_precision_score": 0.7843051086943904,
            "fpr": 0.09220636663007684,
            "logloss": 1.0825174672179887,
            "mae": 0.3109019464177787,
            "precision": 0.7692307692307693,
            "recall": 0.5919661733615222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.731046378887011,
            "auditor_fn_violation": 0.005117718933508415,
            "auditor_fp_violation": 0.001264399397565846,
            "ave_precision_score": 0.7174668227946184,
            "fpr": 0.1074561403508772,
            "logloss": 2.289743242909395,
            "mae": 0.2900519701707234,
            "precision": 0.7655502392344498,
            "recall": 0.6652806652806653
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7470402938334527,
            "auditor_fn_violation": 0.008168891838766502,
            "auditor_fp_violation": 0.0006215258459518168,
            "ave_precision_score": 0.7375009135605735,
            "fpr": 0.10318331503841932,
            "logloss": 1.9410350637078007,
            "mae": 0.2935586435550342,
            "precision": 0.7661691542288557,
            "recall": 0.6511627906976745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8322977547466731,
            "auditor_fn_violation": 0.013999069920122557,
            "auditor_fp_violation": 0.012188606667480768,
            "ave_precision_score": 0.8325970885854633,
            "fpr": 0.06140350877192982,
            "logloss": 0.9231404028728145,
            "mae": 0.3005717196859478,
            "precision": 0.8323353293413174,
            "recall": 0.577962577962578
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8217385771084216,
            "auditor_fn_violation": 0.02035028765174529,
            "auditor_fp_violation": 0.008528437313604904,
            "ave_precision_score": 0.8220217163099717,
            "fpr": 0.07354555433589462,
            "logloss": 0.8737322604976708,
            "mae": 0.3036244395621555,
            "precision": 0.8035190615835777,
            "recall": 0.5792811839323467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 24481,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6632361007715322,
            "auditor_fn_violation": 0.016533993507677727,
            "auditor_fp_violation": 0.017001974193023163,
            "ave_precision_score": 0.6627681367396919,
            "fpr": 0.20614035087719298,
            "logloss": 3.0170092498288885,
            "mae": 0.3496584067292789,
            "precision": 0.6612612612612613,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6806621842097219,
            "auditor_fn_violation": 0.025567239030593894,
            "auditor_fp_violation": 0.022705742598078293,
            "ave_precision_score": 0.6795425385246118,
            "fpr": 0.21075740944017562,
            "logloss": 2.5474274404975303,
            "mae": 0.3381753192069549,
            "precision": 0.6509090909090909,
            "recall": 0.7568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6748544118392913,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5853664638442095,
            "fpr": 0.06030701754385965,
            "logloss": 0.6739303299114919,
            "mae": 0.48615458055415695,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6774964891636368,
            "auditor_fn_violation": 0.07571309552265824,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.577508439835736,
            "fpr": 0.06695938529088913,
            "logloss": 0.6745470179113858,
            "mae": 0.4862509670490491,
            "precision": 0.7038834951456311,
            "recall": 0.30655391120507397
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7737621947373319,
            "auditor_fn_violation": 0.012626746179377757,
            "auditor_fp_violation": 0.019154251638376685,
            "ave_precision_score": 0.775260296055463,
            "fpr": 0.13925438596491227,
            "logloss": 1.3087463256959733,
            "mae": 0.3272533670021366,
            "precision": 0.7177777777777777,
            "recall": 0.6715176715176715
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.769064698013016,
            "auditor_fn_violation": 0.016857622249090865,
            "auditor_fp_violation": 0.016898987013117206,
            "ave_precision_score": 0.7699670224698697,
            "fpr": 0.145993413830955,
            "logloss": 1.1976625083895573,
            "mae": 0.31700430481996567,
            "precision": 0.7158119658119658,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.600976090769362,
            "auditor_fn_violation": 0.06006993835941205,
            "auditor_fp_violation": 0.043251618024178776,
            "ave_precision_score": 0.6027032534915647,
            "fpr": 0.09539473684210527,
            "logloss": 0.7153048084610195,
            "mae": 0.44476475849290165,
            "precision": 0.7175324675324676,
            "recall": 0.4594594594594595
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6016397271085436,
            "auditor_fn_violation": 0.06028735005326027,
            "auditor_fp_violation": 0.03613120210115835,
            "ave_precision_score": 0.6035873243071935,
            "fpr": 0.10647639956092206,
            "logloss": 0.7275524366167709,
            "mae": 0.4450772665809067,
            "precision": 0.6978193146417445,
            "recall": 0.47357293868921774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.761436868955143,
            "auditor_fn_violation": 0.014571251413356693,
            "auditor_fp_violation": 0.009621646924736436,
            "ave_precision_score": 0.7620556027483537,
            "fpr": 0.03508771929824561,
            "logloss": 2.054351530096459,
            "mae": 0.38280088470255147,
            "precision": 0.8415841584158416,
            "recall": 0.35343035343035345
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7475099944873937,
            "auditor_fn_violation": 0.024128400127174796,
            "auditor_fp_violation": 0.0027442371020856204,
            "ave_precision_score": 0.7484632015137099,
            "fpr": 0.042810098792535674,
            "logloss": 1.931099254425905,
            "mae": 0.38505955085020055,
            "precision": 0.8115942028985508,
            "recall": 0.35517970401691334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7107312888326491,
            "auditor_fn_violation": 0.006164058795637757,
            "auditor_fp_violation": 0.015399214393291812,
            "ave_precision_score": 0.7123776080453827,
            "fpr": 0.10964912280701754,
            "logloss": 2.1388145260569202,
            "mae": 0.37774420603180214,
            "precision": 0.7206703910614525,
            "recall": 0.5363825363825364
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7023990366404752,
            "auditor_fn_violation": 0.01500337663000722,
            "auditor_fp_violation": 0.01296683357643014,
            "ave_precision_score": 0.7034701092609261,
            "fpr": 0.12294182217343579,
            "logloss": 1.7810010932276232,
            "mae": 0.36825936257541864,
            "precision": 0.6964769647696477,
            "recall": 0.5433403805496829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7422118312611462,
            "auditor_fn_violation": 0.015904821825874483,
            "auditor_fp_violation": 0.010784283795335206,
            "ave_precision_score": 0.7436771160864117,
            "fpr": 0.044956140350877194,
            "logloss": 2.3291425014112925,
            "mae": 0.3812655080804579,
            "precision": 0.8169642857142857,
            "recall": 0.3804573804573805
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.732058077612227,
            "auditor_fn_violation": 0.023420584215008967,
            "auditor_fp_violation": 0.003699081244455138,
            "ave_precision_score": 0.7327086724533495,
            "fpr": 0.050493962678375415,
            "logloss": 2.111796327536356,
            "mae": 0.38767767633259503,
            "precision": 0.7850467289719626,
            "recall": 0.35517970401691334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.4987501215624185,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5004882218570992,
            "fpr": 0.06030701754385965,
            "logloss": 0.6719385134759187,
            "mae": 0.4849314561211749,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5003641730245094,
            "auditor_fn_violation": 0.07519093624319162,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.5025109367350162,
            "fpr": 0.06695938529088913,
            "logloss": 0.6721509023675509,
            "mae": 0.48438648724137234,
            "precision": 0.7024390243902439,
            "recall": 0.3044397463002114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6643557712319643,
            "auditor_fn_violation": 0.016192052376262905,
            "auditor_fp_violation": 0.01787204379859161,
            "ave_precision_score": 0.663826752243469,
            "fpr": 0.20285087719298245,
            "logloss": 2.6779275463927257,
            "mae": 0.34723531301852606,
            "precision": 0.6624087591240876,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6846315279883933,
            "auditor_fn_violation": 0.02297500829653077,
            "auditor_fp_violation": 0.028600213524201917,
            "ave_precision_score": 0.6829199719919707,
            "fpr": 0.21405049396267836,
            "logloss": 2.2290236121167073,
            "mae": 0.33444514446318097,
            "precision": 0.6505376344086021,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6540772375758489,
            "auditor_fn_violation": 0.01705146441988548,
            "auditor_fp_violation": 0.0195689339357675,
            "ave_precision_score": 0.6536037170085981,
            "fpr": 0.20394736842105263,
            "logloss": 3.05752354839363,
            "mae": 0.3521197190961381,
            "precision": 0.6580882352941176,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6705301264493483,
            "auditor_fn_violation": 0.022469093972425355,
            "auditor_fp_violation": 0.022480188863660294,
            "ave_precision_score": 0.6688418831859961,
            "fpr": 0.2074643249176729,
            "logloss": 2.5534238014908754,
            "mae": 0.3412966008638706,
            "precision": 0.6512915129151291,
            "recall": 0.7463002114164905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7933765889595321,
            "auditor_fn_violation": 0.009189098004887486,
            "auditor_fp_violation": 0.005485000203525056,
            "ave_precision_score": 0.7927703655037895,
            "fpr": 0.08881578947368421,
            "logloss": 1.031670031572075,
            "mae": 0.31250300526915065,
            "precision": 0.775623268698061,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7864117054422192,
            "auditor_fn_violation": 0.017435478518367246,
            "auditor_fp_violation": 0.007764060769188363,
            "ave_precision_score": 0.7868125204743357,
            "fpr": 0.09440175631174534,
            "logloss": 0.9603022522240138,
            "mae": 0.31144065470343396,
            "precision": 0.7675675675675676,
            "recall": 0.6004228329809725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7445420906676667,
            "auditor_fn_violation": 0.017156326366852707,
            "auditor_fp_violation": 0.009082305531810966,
            "ave_precision_score": 0.7460014331699487,
            "fpr": 0.043859649122807015,
            "logloss": 2.262749816531321,
            "mae": 0.38127918528691845,
            "precision": 0.820627802690583,
            "recall": 0.3804573804573805
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.731966238648747,
            "auditor_fn_violation": 0.022592091491588605,
            "auditor_fp_violation": 0.003699081244455138,
            "ave_precision_score": 0.7327081823582697,
            "fpr": 0.050493962678375415,
            "logloss": 2.068750902797582,
            "mae": 0.3870698978768603,
            "precision": 0.7819905213270142,
            "recall": 0.3488372093023256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7661049787104269,
            "auditor_fn_violation": 0.008122241674873257,
            "auditor_fp_violation": 0.01564853258436114,
            "ave_precision_score": 0.767433801998189,
            "fpr": 0.12280701754385964,
            "logloss": 1.4270640434441981,
            "mae": 0.335632846181245,
            "precision": 0.7345971563981043,
            "recall": 0.6444906444906445
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7606497080761428,
            "auditor_fn_violation": 0.019229385731823638,
            "auditor_fp_violation": 0.013422953350475417,
            "ave_precision_score": 0.7615674612559686,
            "fpr": 0.13062568605927552,
            "logloss": 1.296710696650183,
            "mae": 0.3251844204982589,
            "precision": 0.7258064516129032,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7896208225495953,
            "auditor_fn_violation": 0.014986139986139997,
            "auditor_fp_violation": 0.004683620303659386,
            "ave_precision_score": 0.789080724548657,
            "fpr": 0.08333333333333333,
            "logloss": 1.0337511037166365,
            "mae": 0.32165655274077953,
            "precision": 0.7784256559766763,
            "recall": 0.5550935550935551
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7797085157755032,
            "auditor_fn_violation": 0.014789871502403094,
            "auditor_fp_violation": 0.006901944273190685,
            "ave_precision_score": 0.7801177441611535,
            "fpr": 0.08781558726673985,
            "logloss": 0.9632179196371521,
            "mae": 0.32266659510455087,
            "precision": 0.7687861271676301,
            "recall": 0.5623678646934461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7241106598036126,
            "auditor_fn_violation": 0.0022066601013969516,
            "auditor_fp_violation": 0.0023888753205519608,
            "ave_precision_score": 0.7084630347654036,
            "fpr": 0.13815789473684212,
            "logloss": 2.3252220214700636,
            "mae": 0.29575251733501473,
            "precision": 0.738045738045738,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7352837078662902,
            "auditor_fn_violation": 0.018860393174333898,
            "auditor_fp_violation": 0.005247883554125379,
            "ave_precision_score": 0.7230041571550947,
            "fpr": 0.13830954994511527,
            "logloss": 2.0592564640230395,
            "mae": 0.30084818899795285,
            "precision": 0.7319148936170212,
            "recall": 0.7272727272727273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7660586146023092,
            "auditor_fn_violation": 0.009654137943611633,
            "auditor_fp_violation": 0.01740139211136891,
            "ave_precision_score": 0.7673876508117623,
            "fpr": 0.12280701754385964,
            "logloss": 1.4330854337208903,
            "mae": 0.33433797284849953,
            "precision": 0.735224586288416,
            "recall": 0.6465696465696466
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7591010505830861,
            "auditor_fn_violation": 0.019719055100567876,
            "auditor_fp_violation": 0.013422953350475417,
            "ave_precision_score": 0.7600302484141259,
            "fpr": 0.13062568605927552,
            "logloss": 1.3101891839287068,
            "mae": 0.32473456543164314,
            "precision": 0.7264367816091954,
            "recall": 0.6680761099365751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6800432766832516,
            "auditor_fn_violation": 0.01616241747820696,
            "auditor_fp_violation": 0.022174054626124474,
            "ave_precision_score": 0.6805413396784548,
            "fpr": 0.15570175438596492,
            "logloss": 2.1595666434926577,
            "mae": 0.44178791270712653,
            "precision": 0.6213333333333333,
            "recall": 0.48440748440748443
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.685502680628029,
            "auditor_fn_violation": 0.01204447404636311,
            "auditor_fp_violation": 0.019136981289064665,
            "ave_precision_score": 0.6860809584135428,
            "fpr": 0.15587266739846323,
            "logloss": 1.9216492558310152,
            "mae": 0.4207627128521349,
            "precision": 0.6282722513089005,
            "recall": 0.507399577167019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 24481,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7637654457204922,
            "auditor_fn_violation": 0.01776042236568553,
            "auditor_fp_violation": 0.02077227581715309,
            "ave_precision_score": 0.7650991281106656,
            "fpr": 0.1425438596491228,
            "logloss": 1.4409742866895434,
            "mae": 0.32108420710927815,
            "precision": 0.7186147186147186,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7564420437682509,
            "auditor_fn_violation": 0.020802825693949686,
            "auditor_fp_violation": 0.0176834127783709,
            "ave_precision_score": 0.757069736774657,
            "fpr": 0.15477497255762898,
            "logloss": 1.3173190144156217,
            "mae": 0.314190218943228,
            "precision": 0.7068607068607069,
            "recall": 0.718816067653277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7677004364251148,
            "auditor_fn_violation": 0.0018214064266695847,
            "auditor_fp_violation": 0.010987808849269348,
            "ave_precision_score": 0.5402400167979655,
            "fpr": 0.4440789473684211,
            "logloss": 15.379193998037795,
            "mae": 0.44964311619867386,
            "precision": 0.5402951191827469,
            "recall": 0.9896049896049897
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7562333634166931,
            "auditor_fn_violation": 0.0012322958995411959,
            "auditor_fp_violation": 0.005879434010495785,
            "ave_precision_score": 0.5225724741486325,
            "fpr": 0.4643249176728869,
            "logloss": 16.102978426999286,
            "mae": 0.4753072180134601,
            "precision": 0.5225733634311512,
            "recall": 0.9788583509513742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7744957923689815,
            "auditor_fn_violation": 0.015318962687383742,
            "auditor_fp_violation": 0.018960902837139255,
            "ave_precision_score": 0.776024451380691,
            "fpr": 0.1337719298245614,
            "logloss": 1.2642593678128882,
            "mae": 0.32614849358155307,
            "precision": 0.7282850779510023,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7683353199496727,
            "auditor_fn_violation": 0.015616043517914704,
            "auditor_fp_violation": 0.01829742016650878,
            "ave_precision_score": 0.7693154620206638,
            "fpr": 0.1437980241492865,
            "logloss": 1.147105490183336,
            "mae": 0.3161266427919666,
            "precision": 0.7182795698924731,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7934377729313808,
            "auditor_fn_violation": 0.009189098004887486,
            "auditor_fp_violation": 0.004767574388407214,
            "ave_precision_score": 0.7928342110857791,
            "fpr": 0.08991228070175439,
            "logloss": 1.0307857144464425,
            "mae": 0.3124065773773143,
            "precision": 0.7734806629834254,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7865701629175156,
            "auditor_fn_violation": 0.017435478518367246,
            "auditor_fp_violation": 0.007764060769188363,
            "ave_precision_score": 0.786928261723506,
            "fpr": 0.09440175631174534,
            "logloss": 0.9596687987297058,
            "mae": 0.31132745586235816,
            "precision": 0.7675675675675676,
            "recall": 0.6004228329809725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6419679290910608,
            "auditor_fn_violation": 0.01900964729912099,
            "auditor_fp_violation": 0.01601233361826842,
            "ave_precision_score": 0.634647558051872,
            "fpr": 0.3048245614035088,
            "logloss": 3.2733015590481775,
            "mae": 0.4095117566783529,
            "precision": 0.5893648449039882,
            "recall": 0.8295218295218295
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6501689998111366,
            "auditor_fn_violation": 0.017463327013272134,
            "auditor_fp_violation": 0.014906595692424918,
            "ave_precision_score": 0.6420660547922854,
            "fpr": 0.31833150384193193,
            "logloss": 2.86364729233507,
            "mae": 0.4050942657610536,
            "precision": 0.5821325648414986,
            "recall": 0.854122621564482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 24481,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6912174889789899,
            "auditor_fn_violation": 0.07781212386475547,
            "auditor_fp_violation": 0.03314659909634876,
            "ave_precision_score": 0.5915260117052421,
            "fpr": 0.0800438596491228,
            "logloss": 0.6706826137656726,
            "mae": 0.4785883741028476,
            "precision": 0.688034188034188,
            "recall": 0.33471933471933474
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6045944559289689,
            "auditor_fn_violation": 0.08286319658948765,
            "auditor_fp_violation": 0.04381255983439344,
            "ave_precision_score": 0.5817007043986837,
            "fpr": 0.08122941822173436,
            "logloss": 0.6704160071367892,
            "mae": 0.47843778051607694,
            "precision": 0.6903765690376569,
            "recall": 0.3488372093023256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 24481,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6788653055973529,
            "auditor_fn_violation": 0.017616807090491314,
            "auditor_fp_violation": 0.024341596450523067,
            "ave_precision_score": 0.6793709223796178,
            "fpr": 0.15570175438596492,
            "logloss": 2.1771842494012823,
            "mae": 0.44283407024763366,
            "precision": 0.6182795698924731,
            "recall": 0.4781704781704782
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6851636427630263,
            "auditor_fn_violation": 0.013295335609174229,
            "auditor_fp_violation": 0.01861570154729862,
            "ave_precision_score": 0.6857439251980947,
            "fpr": 0.15477497255762898,
            "logloss": 1.9382352877955298,
            "mae": 0.42159928842501343,
            "precision": 0.6279683377308707,
            "recall": 0.5031712473572939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6962253748519553,
            "auditor_fn_violation": 0.018013458802932484,
            "auditor_fp_violation": 0.020960536492042166,
            "ave_precision_score": 0.6966334673186342,
            "fpr": 0.13596491228070176,
            "logloss": 2.2438101673938253,
            "mae": 0.436860969022353,
            "precision": 0.6374269005847953,
            "recall": 0.45322245322245325
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7013190367259938,
            "auditor_fn_violation": 0.015395576266584356,
            "auditor_fp_violation": 0.022435078116776693,
            "ave_precision_score": 0.7018476113479387,
            "fpr": 0.13172338090010977,
            "logloss": 2.023080148971333,
            "mae": 0.41976736532435577,
            "precision": 0.6460176991150443,
            "recall": 0.4630021141649049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.741605559522349,
            "auditor_fn_violation": 0.015904821825874483,
            "auditor_fp_violation": 0.010784283795335206,
            "ave_precision_score": 0.7430782086293135,
            "fpr": 0.044956140350877194,
            "logloss": 2.3071594259101125,
            "mae": 0.3809833665399925,
            "precision": 0.8169642857142857,
            "recall": 0.3804573804573805
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7311924295307457,
            "auditor_fn_violation": 0.023420584215008967,
            "auditor_fp_violation": 0.0042855209539419264,
            "ave_precision_score": 0.7318470975321676,
            "fpr": 0.052689352360043906,
            "logloss": 2.0906180701860566,
            "mae": 0.38746518653850004,
            "precision": 0.7777777777777778,
            "recall": 0.35517970401691334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7932126801959787,
            "auditor_fn_violation": 0.009189098004887486,
            "auditor_fp_violation": 0.004767574388407214,
            "ave_precision_score": 0.7926535269679772,
            "fpr": 0.08991228070175439,
            "logloss": 1.0319472719425586,
            "mae": 0.312854447104615,
            "precision": 0.7734806629834254,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7861606126083871,
            "auditor_fn_violation": 0.017435478518367246,
            "auditor_fp_violation": 0.007764060769188363,
            "ave_precision_score": 0.7864986900435554,
            "fpr": 0.09440175631174534,
            "logloss": 0.9620407426738304,
            "mae": 0.31178931208855537,
            "precision": 0.7675675675675676,
            "recall": 0.6004228329809725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6593393698582397,
            "auditor_fn_violation": 0.015736130867709825,
            "auditor_fp_violation": 0.018581837424186926,
            "ave_precision_score": 0.6588939687424414,
            "fpr": 0.1425438596491228,
            "logloss": 2.834925666672614,
            "mae": 0.3529144728324326,
            "precision": 0.7142857142857143,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6788173098832364,
            "auditor_fn_violation": 0.023334718022385553,
            "auditor_fp_violation": 0.021036644963385122,
            "ave_precision_score": 0.6777669929071773,
            "fpr": 0.15148188803512624,
            "logloss": 2.358402692153562,
            "mae": 0.34315279643759683,
            "precision": 0.7012987012987013,
            "recall": 0.6849894291754757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7093752894824267,
            "auditor_fn_violation": 0.006430772878141314,
            "auditor_fp_violation": 0.01642192778931087,
            "ave_precision_score": 0.7110252716833411,
            "fpr": 0.11074561403508772,
            "logloss": 2.1528412951004166,
            "mae": 0.3785735076882307,
            "precision": 0.7170868347338936,
            "recall": 0.5322245322245323
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7011963779609677,
            "auditor_fn_violation": 0.014075093466511033,
            "auditor_fp_violation": 0.011292723636527682,
            "ave_precision_score": 0.7022689529567805,
            "fpr": 0.12184412733260154,
            "logloss": 1.7922935827924034,
            "mae": 0.36993682546732987,
            "precision": 0.6967213114754098,
            "recall": 0.5391120507399577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.731147171222328,
            "auditor_fn_violation": 0.008610077689025065,
            "auditor_fp_violation": 0.001264399397565846,
            "ave_precision_score": 0.717556613335171,
            "fpr": 0.1074561403508772,
            "logloss": 2.289714447544404,
            "mae": 0.29020578736423697,
            "precision": 0.7649880095923262,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7472261390140038,
            "auditor_fn_violation": 0.008788520850400211,
            "auditor_fp_violation": 0.0006215258459518168,
            "ave_precision_score": 0.7376861244299587,
            "fpr": 0.10318331503841932,
            "logloss": 1.9411556798569887,
            "mae": 0.29373028697840353,
            "precision": 0.7655860349127181,
            "recall": 0.6490486257928119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7436903096489123,
            "auditor_fn_violation": 0.008076649524017947,
            "auditor_fp_violation": 0.02331125086498148,
            "ave_precision_score": 0.7408455779099641,
            "fpr": 0.2905701754385965,
            "logloss": 0.8782765992994416,
            "mae": 0.3444308043617038,
            "precision": 0.6246458923512748,
            "recall": 0.9168399168399168
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7306641216900982,
            "auditor_fn_violation": 0.008500753069716389,
            "auditor_fp_violation": 0.0293269977795488,
            "ave_precision_score": 0.7231640166368877,
            "fpr": 0.2854006586169045,
            "logloss": 0.9058529891128,
            "mae": 0.34916218981375324,
            "precision": 0.6193265007320644,
            "recall": 0.8942917547568711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7935991536922681,
            "auditor_fn_violation": 0.015489933253091148,
            "auditor_fp_violation": 0.010847885374689623,
            "ave_precision_score": 0.7930440655026942,
            "fpr": 0.08662280701754387,
            "logloss": 1.1225303082583797,
            "mae": 0.31106723953704063,
            "precision": 0.7799442896935933,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7821082751276687,
            "auditor_fn_violation": 0.017435478518367246,
            "auditor_fp_violation": 0.011322797467783413,
            "ave_precision_score": 0.7824734172723774,
            "fpr": 0.09549945115257959,
            "logloss": 1.0670612780831656,
            "mae": 0.3102740270369165,
            "precision": 0.7654986522911051,
            "recall": 0.6004228329809725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6537058447936837,
            "auditor_fn_violation": 0.016978516978516985,
            "auditor_fp_violation": 0.01919495664916351,
            "ave_precision_score": 0.6532349808125693,
            "fpr": 0.20614035087719298,
            "logloss": 3.0960990653848546,
            "mae": 0.35180975208193244,
            "precision": 0.6588021778584392,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6695900192914496,
            "auditor_fn_violation": 0.021649884080639958,
            "auditor_fp_violation": 0.02407410192021413,
            "ave_precision_score": 0.6679033433004795,
            "fpr": 0.2074643249176729,
            "logloss": 2.595750126911207,
            "mae": 0.34310327142681585,
            "precision": 0.6512915129151291,
            "recall": 0.7463002114164905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7216762851825302,
            "auditor_fn_violation": 0.005097202465623518,
            "auditor_fp_violation": 0.0015086294622868085,
            "ave_precision_score": 0.7065637983972372,
            "fpr": 0.13815789473684212,
            "logloss": 2.3240669861448615,
            "mae": 0.2959031905702199,
            "precision": 0.7375,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7333214390957522,
            "auditor_fn_violation": 0.014481217350540613,
            "auditor_fp_violation": 0.005097514397846724,
            "ave_precision_score": 0.7213037889266654,
            "fpr": 0.13830954994511527,
            "logloss": 2.0572291087604606,
            "mae": 0.30173994453924835,
            "precision": 0.728448275862069,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6541628186650893,
            "auditor_fn_violation": 0.016321990006200535,
            "auditor_fp_violation": 0.019495156103716372,
            "ave_precision_score": 0.6536906490402599,
            "fpr": 0.20065789473684212,
            "logloss": 3.060083429655264,
            "mae": 0.351349402441002,
            "precision": 0.6611111111111111,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6697907125658569,
            "auditor_fn_violation": 0.021772881599803215,
            "auditor_fp_violation": 0.021317334055105275,
            "ave_precision_score": 0.6681030834648988,
            "fpr": 0.20197585071350166,
            "logloss": 2.562156565278926,
            "mae": 0.343522452745389,
            "precision": 0.6560747663551402,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7905669628161643,
            "auditor_fn_violation": 0.015223219170587604,
            "auditor_fp_violation": 0.004813367525542396,
            "ave_precision_score": 0.7900321970752557,
            "fpr": 0.08333333333333333,
            "logloss": 1.0340615031502602,
            "mae": 0.3222248088718241,
            "precision": 0.7764705882352941,
            "recall": 0.5488565488565489
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7816980178587598,
            "auditor_fn_violation": 0.016899394991448196,
            "auditor_fp_violation": 0.006663859775749464,
            "ave_precision_score": 0.7821038628081652,
            "fpr": 0.0845225027442371,
            "logloss": 0.9561496796820221,
            "mae": 0.3229336204670045,
            "precision": 0.7741935483870968,
            "recall": 0.5581395348837209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7245090449113174,
            "auditor_fn_violation": 0.008199748331327278,
            "auditor_fp_violation": 0.0012593112712174861,
            "ave_precision_score": 0.7109177322612562,
            "fpr": 0.11293859649122807,
            "logloss": 2.305784661563275,
            "mae": 0.29344520793515744,
            "precision": 0.7582159624413145,
            "recall": 0.6715176715176715
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7350545054843516,
            "auditor_fn_violation": 0.007837030607816606,
            "auditor_fp_violation": 0.0008270303595326584,
            "ave_precision_score": 0.7255327120971232,
            "fpr": 0.11525795828759605,
            "logloss": 1.9933304964004195,
            "mae": 0.30170354311230785,
            "precision": 0.7469879518072289,
            "recall": 0.6553911205073996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7412385222923579,
            "auditor_fn_violation": 0.015904821825874483,
            "auditor_fp_violation": 0.010784283795335206,
            "ave_precision_score": 0.7427119620362359,
            "fpr": 0.044956140350877194,
            "logloss": 2.3100937854809542,
            "mae": 0.3808912875320298,
            "precision": 0.8169642857142857,
            "recall": 0.3804573804573805
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7307889000485515,
            "auditor_fn_violation": 0.023420584215008967,
            "auditor_fp_violation": 0.0042855209539419264,
            "ave_precision_score": 0.7314443860581202,
            "fpr": 0.052689352360043906,
            "logloss": 2.0925003509081996,
            "mae": 0.387414548830301,
            "precision": 0.7777777777777778,
            "recall": 0.35517970401691334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7932337331608429,
            "auditor_fn_violation": 0.009189098004887486,
            "auditor_fp_violation": 0.004767574388407214,
            "ave_precision_score": 0.7926745660988304,
            "fpr": 0.08991228070175439,
            "logloss": 1.0317940433381998,
            "mae": 0.31284193392868315,
            "precision": 0.7734806629834254,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7861690197516686,
            "auditor_fn_violation": 0.017435478518367246,
            "auditor_fp_violation": 0.007764060769188363,
            "ave_precision_score": 0.7865070813563539,
            "fpr": 0.09440175631174534,
            "logloss": 0.9619183176768237,
            "mae": 0.3117753973881812,
            "precision": 0.7675675675675676,
            "recall": 0.6004228329809725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 24481,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7820852085373662,
            "auditor_fn_violation": 0.01783792902213955,
            "auditor_fp_violation": 0.024504416493670376,
            "ave_precision_score": 0.7819681071042451,
            "fpr": 0.10307017543859649,
            "logloss": 1.1698221532540678,
            "mae": 0.3140804506509763,
            "precision": 0.7655860349127181,
            "recall": 0.6382536382536382
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.770285919831783,
            "auditor_fn_violation": 0.02326973820094082,
            "auditor_fp_violation": 0.01849540622227569,
            "ave_precision_score": 0.7708576407148902,
            "fpr": 0.1119648737650933,
            "logloss": 1.06022947554599,
            "mae": 0.31210669299168353,
            "precision": 0.7553956834532374,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7667996060501168,
            "auditor_fn_violation": 0.013996790312579797,
            "auditor_fp_violation": 0.019207676965034393,
            "ave_precision_score": 0.7684438113960498,
            "fpr": 0.13267543859649122,
            "logloss": 1.411618318382438,
            "mae": 0.32676089970763655,
            "precision": 0.725,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7570283917488567,
            "auditor_fn_violation": 0.018628322383459853,
            "auditor_fp_violation": 0.01488654647158775,
            "ave_precision_score": 0.7575022226706513,
            "fpr": 0.14270032930845225,
            "logloss": 1.3014740191423837,
            "mae": 0.3191326547548457,
            "precision": 0.7155361050328227,
            "recall": 0.6913319238900634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6309080731305956,
            "auditor_fn_violation": 0.07719435022066601,
            "auditor_fp_violation": 0.03761142996702894,
            "ave_precision_score": 0.6156169303860775,
            "fpr": 0.07236842105263158,
            "logloss": 0.6723666425480271,
            "mae": 0.47881155215988036,
            "precision": 0.7066666666666667,
            "recall": 0.3305613305613306
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6192805247997182,
            "auditor_fn_violation": 0.08302332543519075,
            "auditor_fp_violation": 0.04508568535755279,
            "ave_precision_score": 0.6097746388062302,
            "fpr": 0.07683863885839737,
            "logloss": 0.6739273229350875,
            "mae": 0.47906006573322185,
            "precision": 0.6943231441048034,
            "recall": 0.3361522198731501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.4986631669330731,
            "auditor_fn_violation": 0.06882363132363131,
            "auditor_fp_violation": 0.03344171042455327,
            "ave_precision_score": 0.5003945267472034,
            "fpr": 0.06030701754385965,
            "logloss": 0.6729153142697272,
            "mae": 0.4854163560983643,
            "precision": 0.7208121827411168,
            "recall": 0.29521829521829523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.49997372807817364,
            "auditor_fn_violation": 0.07519093624319162,
            "auditor_fp_violation": 0.0392889543830103,
            "ave_precision_score": 0.5021180720983758,
            "fpr": 0.06695938529088913,
            "logloss": 0.673036791079936,
            "mae": 0.48482273020152855,
            "precision": 0.7024390243902439,
            "recall": 0.3044397463002114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6556949535004776,
            "auditor_fn_violation": 0.011724021592442657,
            "auditor_fp_violation": 0.023977795416615787,
            "ave_precision_score": 0.6560725193812018,
            "fpr": 0.1118421052631579,
            "logloss": 2.9365045751170276,
            "mae": 0.3621478203692764,
            "precision": 0.7417721518987341,
            "recall": 0.6091476091476091
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6767588064066343,
            "auditor_fn_violation": 0.020039312791974066,
            "auditor_fp_violation": 0.01801923722739325,
            "ave_precision_score": 0.6764498213139318,
            "fpr": 0.10976948408342481,
            "logloss": 2.3952595395024283,
            "mae": 0.3540362303775077,
            "precision": 0.7422680412371134,
            "recall": 0.6088794926004228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6802821668905288,
            "auditor_fn_violation": 0.017714830214830224,
            "auditor_fp_violation": 0.024120262954369687,
            "ave_precision_score": 0.680780330811573,
            "fpr": 0.16776315789473684,
            "logloss": 2.128142225812655,
            "mae": 0.4393407064530489,
            "precision": 0.6155778894472361,
            "recall": 0.5093555093555093
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6857203564111816,
            "auditor_fn_violation": 0.01037124364416122,
            "auditor_fp_violation": 0.016924048539163645,
            "ave_precision_score": 0.6862988933235747,
            "fpr": 0.16355653128430298,
            "logloss": 1.8918519563588767,
            "mae": 0.41737612357025905,
            "precision": 0.6311881188118812,
            "recall": 0.5391120507399577
        }
    }
]