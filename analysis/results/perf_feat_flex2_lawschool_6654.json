[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8223680006884596,
            "auditor_fn_violation": 0.005382775119617222,
            "auditor_fp_violation": 0.025351676457658956,
            "ave_precision_score": 0.822871292371882,
            "fpr": 0.1787280701754386,
            "logloss": 0.977347877848649,
            "mae": 0.2799644504932287,
            "precision": 0.7036363636363636,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.860307339276458,
            "auditor_fn_violation": 0.007293623100428812,
            "auditor_fp_violation": 0.01903862354172517,
            "ave_precision_score": 0.8605197178966925,
            "fpr": 0.1602634467618002,
            "logloss": 0.8301732390406475,
            "mae": 0.2616648102669592,
            "precision": 0.7311233885819521,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7957897010940091,
            "auditor_fn_violation": 0.008257297577983018,
            "auditor_fp_violation": 0.019691883467210167,
            "ave_precision_score": 0.79631240117586,
            "fpr": 0.13925438596491227,
            "logloss": 1.0260082292311234,
            "mae": 0.28875914970008965,
            "precision": 0.7337526205450734,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8194518391613353,
            "auditor_fn_violation": 0.014737865451367106,
            "auditor_fp_violation": 0.01856125392489725,
            "ave_precision_score": 0.8197574030493912,
            "fpr": 0.1394072447859495,
            "logloss": 0.9223743304208678,
            "mae": 0.2802054987055399,
            "precision": 0.741869918699187,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8583153689771812,
            "auditor_fn_violation": 0.009263380438411045,
            "auditor_fp_violation": 0.003689106022459338,
            "ave_precision_score": 0.8586088843960822,
            "fpr": 0.07017543859649122,
            "logloss": 0.5060270855855131,
            "mae": 0.30000462114855364,
            "precision": 0.8379746835443038,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8792305163816714,
            "auditor_fn_violation": 0.008865996791353543,
            "auditor_fp_violation": 0.01001710361728742,
            "ave_precision_score": 0.879449845495667,
            "fpr": 0.059275521405049394,
            "logloss": 0.4742797116809876,
            "mae": 0.2903169284033631,
            "precision": 0.865,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8051560259451702,
            "auditor_fn_violation": 0.010121100849375026,
            "auditor_fp_violation": 0.015860408424249694,
            "ave_precision_score": 0.805642198618421,
            "fpr": 0.11074561403508772,
            "logloss": 0.9691544447692475,
            "mae": 0.28980247444764207,
            "precision": 0.7629107981220657,
            "recall": 0.6871035940803383
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8309749905508524,
            "auditor_fn_violation": 0.015082464039653942,
            "auditor_fp_violation": 0.015628111199040153,
            "ave_precision_score": 0.8312587484977588,
            "fpr": 0.11745334796926454,
            "logloss": 0.85528427489192,
            "mae": 0.28254810872931013,
            "precision": 0.7579185520361991,
            "recall": 0.6964656964656964
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8080653033662737,
            "auditor_fn_violation": 0.011495771670190278,
            "auditor_fp_violation": 0.036284118610878005,
            "ave_precision_score": 0.8095564455306816,
            "fpr": 0.2236842105263158,
            "logloss": 0.5866809624812146,
            "mae": 0.3249493023995414,
            "precision": 0.6736,
            "recall": 0.8900634249471459
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8048994892347887,
            "auditor_fn_violation": 0.01355345043599709,
            "auditor_fp_violation": 0.03105965843821,
            "ave_precision_score": 0.8062448811468426,
            "fpr": 0.21185510428100987,
            "logloss": 0.5945860099604228,
            "mae": 0.3177225202528768,
            "precision": 0.6912,
            "recall": 0.8981288981288982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8079938369192505,
            "auditor_fn_violation": 0.011762360446570976,
            "auditor_fp_violation": 0.017623786116772573,
            "ave_precision_score": 0.8086870281643209,
            "fpr": 0.15350877192982457,
            "logloss": 0.9767166573552828,
            "mae": 0.2822756250711217,
            "precision": 0.7227722772277227,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.840722090602867,
            "auditor_fn_violation": 0.007567476283173319,
            "auditor_fp_violation": 0.016309703111837243,
            "ave_precision_score": 0.840968257171711,
            "fpr": 0.1437980241492865,
            "logloss": 0.8604457773845561,
            "mae": 0.26769586659046496,
            "precision": 0.7436399217221135,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8033011770260997,
            "auditor_fn_violation": 0.014854790252587069,
            "auditor_fp_violation": 0.015118590896375338,
            "ave_precision_score": 0.8038503684932846,
            "fpr": 0.10416666666666667,
            "logloss": 0.9715459367342829,
            "mae": 0.2851635495107016,
            "precision": 0.7759433962264151,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8305882152635147,
            "auditor_fn_violation": 0.015057360831235697,
            "auditor_fp_violation": 0.0027825287825798397,
            "ave_precision_score": 0.8308386094966678,
            "fpr": 0.10537870472008781,
            "logloss": 0.8684223451101447,
            "mae": 0.2792821001597183,
            "precision": 0.7813211845102506,
            "recall": 0.7130977130977131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7008078654436827,
            "auditor_fn_violation": 0.05863098549757057,
            "auditor_fp_violation": 0.0755529912480518,
            "ave_precision_score": 0.6975713091028086,
            "fpr": 0.24890350877192982,
            "logloss": 2.6734538020079732,
            "mae": 0.35791199121130335,
            "precision": 0.6247933884297521,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7598659890402717,
            "auditor_fn_violation": 0.0612563927602347,
            "auditor_fp_violation": 0.07574094401756311,
            "ave_precision_score": 0.7573095485812196,
            "fpr": 0.23600439077936333,
            "logloss": 2.3725064710812593,
            "mae": 0.3351802815461193,
            "precision": 0.6434494195688225,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8110685757631134,
            "auditor_fn_violation": 0.007731074515040243,
            "auditor_fp_violation": 0.009281461055828642,
            "ave_precision_score": 0.8123536624046641,
            "fpr": 0.10307017543859649,
            "logloss": 0.9124351123144113,
            "mae": 0.2680438053760549,
            "precision": 0.7897091722595079,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8616822218245351,
            "auditor_fn_violation": 0.005454242556328184,
            "auditor_fp_violation": 0.01240650448012662,
            "ave_precision_score": 0.8619048225451891,
            "fpr": 0.09330406147091108,
            "logloss": 0.7103298416281283,
            "mae": 0.254932248551336,
            "precision": 0.8085585585585585,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7946123205757958,
            "auditor_fn_violation": 0.00804170839360558,
            "auditor_fp_violation": 0.0195794868720777,
            "ave_precision_score": 0.7961605064672901,
            "fpr": 0.14473684210526316,
            "logloss": 0.9764019443113497,
            "mae": 0.2820475382644794,
            "precision": 0.7344064386317908,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.841814081214781,
            "auditor_fn_violation": 0.011175491965832259,
            "auditor_fp_violation": 0.013391877058177829,
            "ave_precision_score": 0.842034845457607,
            "fpr": 0.1394072447859495,
            "logloss": 0.824460823543165,
            "mae": 0.26917696617129644,
            "precision": 0.7465069860279441,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8229354243184444,
            "auditor_fn_violation": 0.006578947368421054,
            "auditor_fp_violation": 0.025598948966950412,
            "ave_precision_score": 0.8234166860405576,
            "fpr": 0.17653508771929824,
            "logloss": 0.9691883019065047,
            "mae": 0.27987519864487764,
            "precision": 0.7051282051282052,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8599733621168066,
            "auditor_fn_violation": 0.007293623100428812,
            "auditor_fp_violation": 0.01897225129553519,
            "ave_precision_score": 0.8601864391746974,
            "fpr": 0.1602634467618002,
            "logloss": 0.8255246222096094,
            "mae": 0.26195612299823867,
            "precision": 0.7311233885819521,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8197810968744215,
            "auditor_fn_violation": 0.005691090834909684,
            "auditor_fp_violation": 0.02807666946409304,
            "ave_precision_score": 0.8202392687124015,
            "fpr": 0.18859649122807018,
            "logloss": 0.9930167409131326,
            "mae": 0.28382170623183767,
            "precision": 0.6982456140350877,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8537932286110776,
            "auditor_fn_violation": 0.011531501103400121,
            "auditor_fp_violation": 0.02363617797973094,
            "ave_precision_score": 0.85404139674499,
            "fpr": 0.17453347969264543,
            "logloss": 0.8582050514357198,
            "mae": 0.26478620050111795,
            "precision": 0.7175843694493783,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.811821600311801,
            "auditor_fn_violation": 0.010709914320685443,
            "auditor_fp_violation": 0.01249600367661752,
            "ave_precision_score": 0.8124719651816694,
            "fpr": 0.12171052631578948,
            "logloss": 0.8553212844014494,
            "mae": 0.27974376440365356,
            "precision": 0.7597402597402597,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8495983002106018,
            "auditor_fn_violation": 0.01271591611877013,
            "auditor_fp_violation": 0.012204834962857078,
            "ave_precision_score": 0.8497991668276271,
            "fpr": 0.11964873765093303,
            "logloss": 0.7576155317430577,
            "mae": 0.2700502056065367,
            "precision": 0.7680851063829788,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 6654,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.794401028573245,
            "auditor_fn_violation": 0.013510255554319197,
            "auditor_fp_violation": 0.0076829317028333935,
            "ave_precision_score": 0.7957215324162779,
            "fpr": 0.0625,
            "logloss": 1.1138343924077594,
            "mae": 0.30960131444228123,
            "precision": 0.8213166144200627,
            "recall": 0.5539112050739958
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8081931817954078,
            "auditor_fn_violation": 0.011976512525359955,
            "auditor_fp_violation": 0.0038955402956117762,
            "ave_precision_score": 0.8094864145938018,
            "fpr": 0.06695938529088913,
            "logloss": 0.9980878424310203,
            "mae": 0.30184935749576597,
            "precision": 0.8226744186046512,
            "recall": 0.5883575883575883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.808158068259091,
            "auditor_fn_violation": 0.008122844108156228,
            "auditor_fp_violation": 0.022579227111057837,
            "ave_precision_score": 0.8083194934304666,
            "fpr": 0.14583333333333334,
            "logloss": 0.8255318586200862,
            "mae": 0.27564023318194253,
            "precision": 0.7350597609561753,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8563226487724653,
            "auditor_fn_violation": 0.013516936678297824,
            "auditor_fp_violation": 0.013851377224108443,
            "ave_precision_score": 0.8565775576386129,
            "fpr": 0.13830954994511527,
            "logloss": 0.6888815431653595,
            "mae": 0.2635367150178895,
            "precision": 0.75,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7956001572531657,
            "auditor_fn_violation": 0.010786413708690332,
            "auditor_fp_violation": 0.01619759820964713,
            "ave_precision_score": 0.7688901035664022,
            "fpr": 0.12609649122807018,
            "logloss": 3.3311336866062105,
            "mae": 0.2881346253336693,
            "precision": 0.7505422993492408,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8058152173284949,
            "auditor_fn_violation": 0.011269058469936631,
            "auditor_fp_violation": 0.011344548541086977,
            "ave_precision_score": 0.7764031667844358,
            "fpr": 0.12733260153677278,
            "logloss": 3.095198537357199,
            "mae": 0.27748590752238894,
            "precision": 0.7521367521367521,
            "recall": 0.7318087318087318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7811940086485154,
            "auditor_fn_violation": 0.013178758206297991,
            "auditor_fp_violation": 0.021977280901570563,
            "ave_precision_score": 0.7567686163433928,
            "fpr": 0.14583333333333334,
            "logloss": 1.9266119920413987,
            "mae": 0.29874456011314404,
            "precision": 0.7329317269076305,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7956889849969524,
            "auditor_fn_violation": 0.01592228046673711,
            "auditor_fp_violation": 0.01386414111760652,
            "ave_precision_score": 0.7683787461475897,
            "fpr": 0.132821075740944,
            "logloss": 2.0085528954289638,
            "mae": 0.2810851491815958,
            "precision": 0.7545638945233266,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8005577459594002,
            "auditor_fn_violation": 0.013183394532843739,
            "auditor_fp_violation": 0.022286995963713387,
            "ave_precision_score": 0.8010934959546039,
            "fpr": 0.1162280701754386,
            "logloss": 1.1232481117573079,
            "mae": 0.28497430074525965,
            "precision": 0.7628635346756152,
            "recall": 0.7209302325581395
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8276891359791471,
            "auditor_fn_violation": 0.015947383675155358,
            "auditor_fp_violation": 0.01755545911724913,
            "ave_precision_score": 0.8279485770430515,
            "fpr": 0.11964873765093303,
            "logloss": 0.9919311857734777,
            "mae": 0.275875479924052,
            "precision": 0.7614879649890591,
            "recall": 0.7234927234927235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6836166216277516,
            "auditor_fn_violation": 0.008950428396572832,
            "auditor_fp_violation": 0.03097150621428286,
            "ave_precision_score": 0.6718646724410003,
            "fpr": 0.16557017543859648,
            "logloss": 2.1209218540027908,
            "mae": 0.30731249029131524,
            "precision": 0.7015810276679841,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6924879060574658,
            "auditor_fn_violation": 0.00775004507166966,
            "auditor_fp_violation": 0.039624230975416744,
            "ave_precision_score": 0.677837202263917,
            "fpr": 0.1668496158068057,
            "logloss": 2.1518240433960787,
            "mae": 0.3058308796351941,
            "precision": 0.7071290944123314,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8224958900274206,
            "auditor_fn_violation": 0.009523014724973116,
            "auditor_fp_violation": 0.025588958158494195,
            "ave_precision_score": 0.8229372119383085,
            "fpr": 0.16885964912280702,
            "logloss": 0.9256148745994691,
            "mae": 0.2789501960861165,
            "precision": 0.7099811676082862,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8637888518625061,
            "auditor_fn_violation": 0.006392189707228133,
            "auditor_fp_violation": 0.017389528501774186,
            "ave_precision_score": 0.8639864232977795,
            "fpr": 0.15148188803512624,
            "logloss": 0.7741014414527387,
            "mae": 0.2588806268224776,
            "precision": 0.7391304347826086,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.777294045809843,
            "auditor_fn_violation": 0.019982567412187978,
            "auditor_fp_violation": 0.031176317787635376,
            "ave_precision_score": 0.7742338644401041,
            "fpr": 0.13267543859649122,
            "logloss": 1.351323113627813,
            "mae": 0.28320980696573533,
            "precision": 0.7392241379310345,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.795060580671337,
            "auditor_fn_violation": 0.0315638614211611,
            "auditor_fp_violation": 0.015112449901718023,
            "ave_precision_score": 0.7934669862958563,
            "fpr": 0.13172338090010977,
            "logloss": 1.2261766931126006,
            "mae": 0.2931494932466016,
            "precision": 0.7430406852248393,
            "recall": 0.7214137214137214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8363691675111404,
            "auditor_fn_violation": 0.008936519416935582,
            "auditor_fp_violation": 0.01038044998601287,
            "ave_precision_score": 0.8365897764309204,
            "fpr": 0.10416666666666667,
            "logloss": 0.5550572180096016,
            "mae": 0.32008530118981615,
            "precision": 0.7759433962264151,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8488404053988534,
            "auditor_fn_violation": 0.014466294378478791,
            "auditor_fp_violation": 0.005524213105965841,
            "ave_precision_score": 0.84910258694964,
            "fpr": 0.09220636663007684,
            "logloss": 0.5395885029906583,
            "mae": 0.32319369539848514,
            "precision": 0.7966101694915254,
            "recall": 0.683991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7402900584057512,
            "auditor_fn_violation": 0.055974370386855085,
            "auditor_fp_violation": 0.06598429444910682,
            "ave_precision_score": 0.7392236105863829,
            "fpr": 0.2138157894736842,
            "logloss": 2.0901700732409743,
            "mae": 0.325755999999016,
            "precision": 0.656084656084656,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7831239226703499,
            "auditor_fn_violation": 0.060631094659634725,
            "auditor_fp_violation": 0.06355397850560336,
            "ave_precision_score": 0.7829398437463115,
            "fpr": 0.19319429198682767,
            "logloss": 1.918226503488198,
            "mae": 0.30777313021606434,
            "precision": 0.6823104693140795,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7788036937240995,
            "auditor_fn_violation": 0.014168613923815885,
            "auditor_fp_violation": 0.031181313191863493,
            "ave_precision_score": 0.7776143237331448,
            "fpr": 0.13486842105263158,
            "logloss": 3.6387184425471215,
            "mae": 0.30158152118083403,
            "precision": 0.7266666666666667,
            "recall": 0.6913319238900634
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7893302631099334,
            "auditor_fn_violation": 0.02448247453735929,
            "auditor_fp_violation": 0.021121690960610624,
            "ave_precision_score": 0.7881391862253287,
            "fpr": 0.13062568605927552,
            "logloss": 3.7035152867947962,
            "mae": 0.3021005021550612,
            "precision": 0.7390350877192983,
            "recall": 0.7006237006237006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8189688647857896,
            "auditor_fn_violation": 0.008516931864545094,
            "auditor_fp_violation": 0.006031950605442993,
            "ave_precision_score": 0.8202475952689272,
            "fpr": 0.08991228070175439,
            "logloss": 0.6029021008159834,
            "mae": 0.30286417390242715,
            "precision": 0.7955112219451371,
            "recall": 0.6744186046511628
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8500341845501742,
            "auditor_fn_violation": 0.021401626231483537,
            "auditor_fp_violation": 0.003601970745156105,
            "ave_precision_score": 0.8505603123111793,
            "fpr": 0.0889132821075741,
            "logloss": 0.5636035327718215,
            "mae": 0.2987083484848203,
            "precision": 0.7969924812030075,
            "recall": 0.6611226611226612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7937291113987157,
            "auditor_fn_violation": 0.009631968398798266,
            "auditor_fp_violation": 0.023311053830475964,
            "ave_precision_score": 0.7951366822851997,
            "fpr": 0.1611842105263158,
            "logloss": 0.8886657601795559,
            "mae": 0.29406666309340773,
            "precision": 0.7140077821011673,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8239265001883149,
            "auditor_fn_violation": 0.011684402463765807,
            "auditor_fp_violation": 0.015434100017869457,
            "ave_precision_score": 0.8242198301037051,
            "fpr": 0.15148188803512624,
            "logloss": 0.8041941542209698,
            "mae": 0.27934855770735656,
            "precision": 0.7335907335907336,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8164765959650477,
            "auditor_fn_violation": 0.00988464819554171,
            "auditor_fp_violation": 0.01071514206929625,
            "ave_precision_score": 0.8168010607690694,
            "fpr": 0.11732456140350878,
            "logloss": 0.5719219790896221,
            "mae": 0.31934532643958446,
            "precision": 0.7622222222222222,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8065843857728057,
            "auditor_fn_violation": 0.007562912063460915,
            "auditor_fp_violation": 0.019258162509892023,
            "ave_precision_score": 0.8071240644715686,
            "fpr": 0.10537870472008781,
            "logloss": 0.5571774573445342,
            "mae": 0.320863889307438,
            "precision": 0.7793103448275862,
            "recall": 0.7047817047817048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8134357153574254,
            "auditor_fn_violation": 0.012780034123363381,
            "auditor_fp_violation": 0.02613095951724414,
            "ave_precision_score": 0.8139365324622854,
            "fpr": 0.17434210526315788,
            "logloss": 1.0305782278829212,
            "mae": 0.2839631736742161,
            "precision": 0.7033582089552238,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8427038096183098,
            "auditor_fn_violation": 0.012834585831292749,
            "auditor_fp_violation": 0.0180073009470809,
            "ave_precision_score": 0.8429411378394802,
            "fpr": 0.15587266739846323,
            "logloss": 0.8966839736063432,
            "mae": 0.26477343301878364,
            "precision": 0.7365491651205937,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7981337518839232,
            "auditor_fn_violation": 0.009805830644263937,
            "auditor_fp_violation": 0.01818826679454902,
            "ave_precision_score": 0.7988819862869784,
            "fpr": 0.15460526315789475,
            "logloss": 0.9835043533199977,
            "mae": 0.2855465160652234,
            "precision": 0.7196819085487077,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8251453179226089,
            "auditor_fn_violation": 0.011479012576707418,
            "auditor_fp_violation": 0.014489571899012078,
            "ave_precision_score": 0.8254264251886172,
            "fpr": 0.14489571899012074,
            "logloss": 0.8905007365314146,
            "mae": 0.2746219174714032,
            "precision": 0.7411764705882353,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8109682412504553,
            "auditor_fn_violation": 0.006618356144059941,
            "auditor_fp_violation": 0.022501798345522125,
            "ave_precision_score": 0.8115423775368684,
            "fpr": 0.16776315789473684,
            "logloss": 0.7376625850993527,
            "mae": 0.2923426332875335,
            "precision": 0.711864406779661,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8390186245421751,
            "auditor_fn_violation": 0.007300469429997427,
            "auditor_fp_violation": 0.015801700150613947,
            "ave_precision_score": 0.8392721899154673,
            "fpr": 0.15367727771679474,
            "logloss": 0.6766376420495724,
            "mae": 0.2777766696026297,
            "precision": 0.7343453510436433,
            "recall": 0.8045738045738046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6830817289533095,
            "auditor_fn_violation": 0.006270631653128592,
            "auditor_fp_violation": 0.03331684849938057,
            "ave_precision_score": 0.6711355008581746,
            "fpr": 0.16228070175438597,
            "logloss": 2.1483634017589393,
            "mae": 0.30758991709098016,
            "precision": 0.7063492063492064,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6929160673497801,
            "auditor_fn_violation": 0.006170825051176317,
            "auditor_fp_violation": 0.036387307584305514,
            "ave_precision_score": 0.6786214923242584,
            "fpr": 0.1668496158068057,
            "logloss": 2.1541231318878022,
            "mae": 0.30524800680885594,
            "precision": 0.7054263565891473,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8051656305662476,
            "auditor_fn_violation": 0.013058213716108456,
            "auditor_fp_violation": 0.024674799184750032,
            "ave_precision_score": 0.8060865662015779,
            "fpr": 0.14802631578947367,
            "logloss": 0.9882644796057835,
            "mae": 0.28318055595398095,
            "precision": 0.7272727272727273,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8383734835688803,
            "auditor_fn_violation": 0.011358060754328596,
            "auditor_fp_violation": 0.01557450284634826,
            "ave_precision_score": 0.8386100356505067,
            "fpr": 0.1437980241492865,
            "logloss": 0.8747832493371046,
            "mae": 0.2719962316075542,
            "precision": 0.7390438247011952,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8136925495112869,
            "auditor_fn_violation": 0.0103621898297541,
            "auditor_fp_violation": 0.018243216241058225,
            "ave_precision_score": 0.814253390345185,
            "fpr": 0.1337719298245614,
            "logloss": 0.9003878696312153,
            "mae": 0.28164588736621565,
            "precision": 0.7436974789915967,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8447841709885059,
            "auditor_fn_violation": 0.008840893582935296,
            "auditor_fp_violation": 0.014640185842289336,
            "ave_precision_score": 0.8450160936896542,
            "fpr": 0.1350164654226125,
            "logloss": 0.7914143060057125,
            "mae": 0.2715163722685421,
            "precision": 0.7474332648870636,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7268999043593836,
            "auditor_fn_violation": 0.012270038203330745,
            "auditor_fp_violation": 0.022546756983575122,
            "ave_precision_score": 0.7059335426555103,
            "fpr": 0.16885964912280702,
            "logloss": 2.26570536772478,
            "mae": 0.28660100809949424,
            "precision": 0.7094339622641509,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7541285541510325,
            "auditor_fn_violation": 0.012606374845672322,
            "auditor_fp_violation": 0.01692492277844435,
            "ave_precision_score": 0.7326399455158336,
            "fpr": 0.17014270032930845,
            "logloss": 2.1310938075457875,
            "mae": 0.2777510539495004,
            "precision": 0.7150735294117647,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8175368371483219,
            "auditor_fn_violation": 0.008649067171098996,
            "auditor_fp_violation": 0.02502447748071774,
            "ave_precision_score": 0.8187475782218167,
            "fpr": 0.18421052631578946,
            "logloss": 0.97908589233789,
            "mae": 0.2810417148711665,
            "precision": 0.6989247311827957,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8622042407384489,
            "auditor_fn_violation": 0.009222005928921407,
            "auditor_fp_violation": 0.020544762974497744,
            "ave_precision_score": 0.8624158941597656,
            "fpr": 0.1668496158068057,
            "logloss": 0.8195392740972339,
            "mae": 0.2609372555058515,
            "precision": 0.7251356238698011,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7871343800285513,
            "auditor_fn_violation": 0.019006620674307334,
            "auditor_fp_violation": 0.037707808815889386,
            "ave_precision_score": 0.787807937516435,
            "fpr": 0.15679824561403508,
            "logloss": 1.0893826963786253,
            "mae": 0.2922314056146782,
            "precision": 0.7134268537074149,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8231623676973998,
            "auditor_fn_violation": 0.025920203746767966,
            "auditor_fp_violation": 0.023710208562019764,
            "ave_precision_score": 0.823437583400059,
            "fpr": 0.1437980241492865,
            "logloss": 0.9774227244560091,
            "mae": 0.2811207761604396,
            "precision": 0.7342799188640974,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8406710232235843,
            "auditor_fn_violation": 0.01564528392863767,
            "auditor_fp_violation": 0.003826479638732368,
            "ave_precision_score": 0.8419790774855607,
            "fpr": 0.09100877192982457,
            "logloss": 0.5182866435995588,
            "mae": 0.2994372677037558,
            "precision": 0.8047058823529412,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8709341743595066,
            "auditor_fn_violation": 0.014103438911342319,
            "auditor_fp_violation": 0.002399611977637661,
            "ave_precision_score": 0.871121475984654,
            "fpr": 0.0845225027442371,
            "logloss": 0.4804771406084606,
            "mae": 0.293045587978519,
            "precision": 0.817966903073286,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8550200861722478,
            "auditor_fn_violation": 0.007028671043358925,
            "auditor_fp_violation": 0.018887623386484437,
            "ave_precision_score": 0.8553483433181055,
            "fpr": 0.21052631578947367,
            "logloss": 0.5850585245046848,
            "mae": 0.2995458612347552,
            "precision": 0.6898222940226171,
            "recall": 0.9027484143763214
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.865291555878902,
            "auditor_fn_violation": 0.0037860202514428654,
            "auditor_fp_violation": 0.017652464707834478,
            "ave_precision_score": 0.865542089998327,
            "fpr": 0.19209659714599342,
            "logloss": 0.5463689196814271,
            "mae": 0.28334633498600836,
            "precision": 0.7140522875816994,
            "recall": 0.9085239085239085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8014423883164516,
            "auditor_fn_violation": 0.013373483921219537,
            "auditor_fp_violation": 0.014941254046277424,
            "ave_precision_score": 0.801968760258917,
            "fpr": 0.10087719298245613,
            "logloss": 1.0151523271032286,
            "mae": 0.2892463273714483,
            "precision": 0.7750611246943765,
            "recall": 0.6701902748414377
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8289928113800445,
            "auditor_fn_violation": 0.014050950384649619,
            "auditor_fp_violation": 0.006305363388047894,
            "ave_precision_score": 0.8292546642681746,
            "fpr": 0.10318331503841932,
            "logloss": 0.9394539862886997,
            "mae": 0.28197842470920687,
            "precision": 0.7844036697247706,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8213060029549677,
            "auditor_fn_violation": 0.010039965134824377,
            "auditor_fp_violation": 0.03130120289333813,
            "ave_precision_score": 0.8216322104280425,
            "fpr": 0.1787280701754386,
            "logloss": 0.9309264628484707,
            "mae": 0.27777881799020093,
            "precision": 0.7030965391621129,
            "recall": 0.8160676532769556
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8653008825875808,
            "auditor_fn_violation": 0.007179517607618596,
            "auditor_fp_violation": 0.013478671533964724,
            "ave_precision_score": 0.8654949213005398,
            "fpr": 0.15367727771679474,
            "logloss": 0.7754809639800679,
            "mae": 0.25845319636627906,
            "precision": 0.7388059701492538,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8301768204191123,
            "auditor_fn_violation": 0.010447961870850495,
            "auditor_fp_violation": 0.023600787275706355,
            "ave_precision_score": 0.8305883908075788,
            "fpr": 0.14035087719298245,
            "logloss": 0.8249765357148571,
            "mae": 0.2718405731568617,
            "precision": 0.7424547283702213,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8612716539230991,
            "auditor_fn_violation": 0.00903487292071266,
            "auditor_fp_violation": 0.01529114441069104,
            "ave_precision_score": 0.861477801806937,
            "fpr": 0.13391877058177826,
            "logloss": 0.7175215317300291,
            "mae": 0.25803816928533657,
            "precision": 0.7545271629778671,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7986952038471458,
            "auditor_fn_violation": 0.005906680019287122,
            "auditor_fp_violation": 0.011726711425488557,
            "ave_precision_score": 0.7992942362166694,
            "fpr": 0.1337719298245614,
            "logloss": 0.9993298577883207,
            "mae": 0.28782354052767206,
            "precision": 0.7453027139874739,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8281270247570933,
            "auditor_fn_violation": 0.008352522073707588,
            "auditor_fp_violation": 0.019482807035458096,
            "ave_precision_score": 0.8283930091508465,
            "fpr": 0.1394072447859495,
            "logloss": 0.8942066164369231,
            "mae": 0.2776260488365919,
            "precision": 0.7397540983606558,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8239049343583773,
            "auditor_fn_violation": 0.009309743703868549,
            "auditor_fp_violation": 0.027879350997082684,
            "ave_precision_score": 0.8243139375291082,
            "fpr": 0.17543859649122806,
            "logloss": 0.8992978123086713,
            "mae": 0.27823797780377246,
            "precision": 0.7101449275362319,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8636302227663106,
            "auditor_fn_violation": 0.00819505649362949,
            "auditor_fp_violation": 0.01774691751972022,
            "ave_precision_score": 0.8638839336550703,
            "fpr": 0.15587266739846323,
            "logloss": 0.7437220566599688,
            "mae": 0.25630793066412205,
            "precision": 0.7389705882352942,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7892867952045044,
            "auditor_fn_violation": 0.01424974963836654,
            "auditor_fp_violation": 0.020760899972025744,
            "ave_precision_score": 0.7731575345177251,
            "fpr": 0.1425438596491228,
            "logloss": 2.6009612684336045,
            "mae": 0.2882734692398806,
            "precision": 0.7286012526096033,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8001211256013037,
            "auditor_fn_violation": 0.00975601963527321,
            "auditor_fp_violation": 0.01246266561151814,
            "ave_precision_score": 0.7834375524943754,
            "fpr": 0.13391877058177826,
            "logloss": 2.333208329916171,
            "mae": 0.27414188200915496,
            "precision": 0.7510204081632653,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7982566191325648,
            "auditor_fn_violation": 0.022358684766885503,
            "auditor_fp_violation": 0.031353654637733284,
            "ave_precision_score": 0.7983997939882281,
            "fpr": 0.13925438596491227,
            "logloss": 0.9792081222193568,
            "mae": 0.27701963568540766,
            "precision": 0.7370600414078675,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8447611091344432,
            "auditor_fn_violation": 0.02089271573354999,
            "auditor_fp_violation": 0.019937201643989485,
            "ave_precision_score": 0.844986739190403,
            "fpr": 0.13721185510428102,
            "logloss": 0.825927914422313,
            "mae": 0.26595203535316103,
            "precision": 0.748995983935743,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8325782615650181,
            "auditor_fn_violation": 0.00704953451281481,
            "auditor_fp_violation": 0.024494964632538068,
            "ave_precision_score": 0.8338685951301001,
            "fpr": 0.18092105263157895,
            "logloss": 0.6704215839087379,
            "mae": 0.2874686617181859,
            "precision": 0.7048300536672629,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.862028148767614,
            "auditor_fn_violation": 0.014381856313799237,
            "auditor_fp_violation": 0.014489571899012085,
            "ave_precision_score": 0.8622274422250497,
            "fpr": 0.16136114160263446,
            "logloss": 0.6050835651952226,
            "mae": 0.2685197941111283,
            "precision": 0.7332123411978222,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7938299655271839,
            "auditor_fn_violation": 0.004821779607581329,
            "auditor_fp_violation": 0.023508372297486316,
            "ave_precision_score": 0.7943395096031318,
            "fpr": 0.12609649122807018,
            "logloss": 2.6177307169127784,
            "mae": 0.3009550463755486,
            "precision": 0.7392290249433107,
            "recall": 0.6892177589852009
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8111925096307326,
            "auditor_fn_violation": 0.006022487910523039,
            "auditor_fp_violation": 0.021249329895591362,
            "ave_precision_score": 0.8119045474180862,
            "fpr": 0.1350164654226125,
            "logloss": 2.8452569935442846,
            "mae": 0.3012550069042838,
            "precision": 0.7308533916849015,
            "recall": 0.6943866943866944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8605464556222637,
            "auditor_fn_violation": 0.009499833092244354,
            "auditor_fp_violation": 0.022012248731167333,
            "ave_precision_score": 0.860838870708567,
            "fpr": 0.14583333333333334,
            "logloss": 0.48999019847471337,
            "mae": 0.29702244417791934,
            "precision": 0.7495291902071564,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8783830059678304,
            "auditor_fn_violation": 0.008612682597314871,
            "auditor_fp_violation": 0.016542005973502163,
            "ave_precision_score": 0.8786655164209964,
            "fpr": 0.13172338090010977,
            "logloss": 0.4577522043616864,
            "mae": 0.2889418521396096,
            "precision": 0.7722960151802657,
            "recall": 0.8461538461538461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7932677458411206,
            "auditor_fn_violation": 0.014238158822002156,
            "auditor_fp_violation": 0.024445010590256968,
            "ave_precision_score": 0.7934343619843007,
            "fpr": 0.14364035087719298,
            "logloss": 0.9545360502903001,
            "mae": 0.2836195373694512,
            "precision": 0.7353535353535353,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8414291415048867,
            "auditor_fn_violation": 0.015917716247024708,
            "auditor_fp_violation": 0.01313149363081715,
            "ave_precision_score": 0.8416697980886726,
            "fpr": 0.13830954994511527,
            "logloss": 0.8004201878587028,
            "mae": 0.27029597590868637,
            "precision": 0.7474949899799599,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7663531355832895,
            "auditor_fn_violation": 0.015999962909387638,
            "auditor_fp_violation": 0.016996862886144753,
            "ave_precision_score": 0.7661460549440582,
            "fpr": 0.14802631578947367,
            "logloss": 1.185725031568375,
            "mae": 0.289147547637819,
            "precision": 0.7278225806451613,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8031912635043592,
            "auditor_fn_violation": 0.012309700564365771,
            "auditor_fp_violation": 0.016388839251525296,
            "ave_precision_score": 0.8035674216137478,
            "fpr": 0.14270032930845225,
            "logloss": 1.0321481414869,
            "mae": 0.27974220898578045,
            "precision": 0.7373737373737373,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.856676021564427,
            "auditor_fn_violation": 0.013510255554319202,
            "auditor_fp_violation": 0.01602525676377733,
            "ave_precision_score": 0.856967712304354,
            "fpr": 0.12171052631578948,
            "logloss": 0.4849265097193105,
            "mae": 0.2994642780364589,
            "precision": 0.7720739219712526,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8762684896314517,
            "auditor_fn_violation": 0.008416421149681304,
            "auditor_fp_violation": 0.014270032930845227,
            "ave_precision_score": 0.8765093120305962,
            "fpr": 0.1119648737650933,
            "logloss": 0.4580334835481983,
            "mae": 0.2910337347627242,
            "precision": 0.7888198757763976,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8119192186650103,
            "auditor_fn_violation": 0.015330013723526575,
            "auditor_fp_violation": 0.026500619430124283,
            "ave_precision_score": 0.8124177340953995,
            "fpr": 0.16557017543859648,
            "logloss": 1.0156688461881422,
            "mae": 0.2823241738217509,
            "precision": 0.710172744721689,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8483739440399496,
            "auditor_fn_violation": 0.01619385153962542,
            "auditor_fp_violation": 0.01798687871748398,
            "ave_precision_score": 0.8485908584396931,
            "fpr": 0.15587266739846323,
            "logloss": 0.8723244076519514,
            "mae": 0.26323435032812537,
            "precision": 0.7335834896810507,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8137755901438358,
            "auditor_fn_violation": 0.005494046956715255,
            "auditor_fp_violation": 0.028571214482675942,
            "ave_precision_score": 0.8143438805070327,
            "fpr": 0.18421052631578946,
            "logloss": 1.053512828952459,
            "mae": 0.2853743821646728,
            "precision": 0.6989247311827957,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8403875007930056,
            "auditor_fn_violation": 0.013904895353852545,
            "auditor_fp_violation": 0.018839506803155243,
            "ave_precision_score": 0.8406784909611624,
            "fpr": 0.1756311745334797,
            "logloss": 0.9260125032037794,
            "mae": 0.2655179502794198,
            "precision": 0.718804920913884,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8273863482721042,
            "auditor_fn_violation": 0.018640350877192985,
            "auditor_fp_violation": 0.020693462014946255,
            "ave_precision_score": 0.8279025702516868,
            "fpr": 0.1206140350877193,
            "logloss": 0.8208003721898123,
            "mae": 0.2769407529027341,
            "precision": 0.7619047619047619,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8612612939763062,
            "auditor_fn_violation": 0.018507910933816537,
            "auditor_fp_violation": 0.015949761315191584,
            "ave_precision_score": 0.8614423165082277,
            "fpr": 0.12294182217343579,
            "logloss": 0.7118579729573041,
            "mae": 0.2678650986419194,
            "precision": 0.7642105263157895,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8180068090214897,
            "auditor_fn_violation": 0.0053549571603427205,
            "auditor_fp_violation": 0.03082663949166767,
            "ave_precision_score": 0.8185347848252967,
            "fpr": 0.17763157894736842,
            "logloss": 0.9817521654505329,
            "mae": 0.28134704948283445,
            "precision": 0.7038391224862889,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.859975595172934,
            "auditor_fn_violation": 0.007373496945395964,
            "auditor_fp_violation": 0.017598856355142575,
            "ave_precision_score": 0.8601849362256999,
            "fpr": 0.15806805708013172,
            "logloss": 0.818877356368371,
            "mae": 0.26136729871166586,
            "precision": 0.7333333333333333,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8131227486771538,
            "auditor_fn_violation": 0.010487370646489377,
            "auditor_fp_violation": 0.018420553091156137,
            "ave_precision_score": 0.8137413351330239,
            "fpr": 0.1337719298245614,
            "logloss": 0.9165540143246246,
            "mae": 0.27572174094189905,
            "precision": 0.7468879668049793,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8387665042469075,
            "auditor_fn_violation": 0.01147216624713881,
            "auditor_fp_violation": 0.014709110867178929,
            "ave_precision_score": 0.8390130430193079,
            "fpr": 0.141602634467618,
            "logloss": 0.8331997823575839,
            "mae": 0.26946477306279015,
            "precision": 0.7425149700598802,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7888550757122231,
            "auditor_fn_violation": 0.014305385556915552,
            "auditor_fp_violation": 0.021285417415977302,
            "ave_precision_score": 0.7728232190707097,
            "fpr": 0.14583333333333334,
            "logloss": 2.5371931441237225,
            "mae": 0.28760717050048007,
            "precision": 0.7257731958762886,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.80091143959908,
            "auditor_fn_violation": 0.010728198434016222,
            "auditor_fp_violation": 0.01449212467771169,
            "ave_precision_score": 0.7850157462821511,
            "fpr": 0.1350164654226125,
            "logloss": 2.250485341346171,
            "mae": 0.27377553411595096,
            "precision": 0.7494908350305499,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8057779478606077,
            "auditor_fn_violation": 0.012214402284781722,
            "auditor_fp_violation": 0.028731067417975473,
            "ave_precision_score": 0.806860778581693,
            "fpr": 0.1699561403508772,
            "logloss": 1.0871065540972888,
            "mae": 0.28451519819752097,
            "precision": 0.7069943289224953,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8472413455807465,
            "auditor_fn_violation": 0.012460319814875253,
            "auditor_fp_violation": 0.020820463074056116,
            "ave_precision_score": 0.8474505899625548,
            "fpr": 0.16245883644346873,
            "logloss": 0.93470725895507,
            "mae": 0.2668155093872491,
            "precision": 0.724907063197026,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.721802807901681,
            "auditor_fn_violation": 0.005378138793071479,
            "auditor_fp_violation": 0.020566079207129447,
            "ave_precision_score": 0.7008425783859928,
            "fpr": 0.17105263157894737,
            "logloss": 2.1949127866305527,
            "mae": 0.2937760153109692,
            "precision": 0.7062146892655368,
            "recall": 0.7928118393234672
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7511962102728025,
            "auditor_fn_violation": 0.007645068018284268,
            "auditor_fp_violation": 0.017358895157378807,
            "ave_precision_score": 0.7297147784372244,
            "fpr": 0.1756311745334797,
            "logloss": 2.0173712119055374,
            "mae": 0.2809959582343297,
            "precision": 0.7096188747731398,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.821155537211685,
            "auditor_fn_violation": 0.007974481658692186,
            "auditor_fp_violation": 0.026185908963753352,
            "ave_precision_score": 0.8216025391611299,
            "fpr": 0.17982456140350878,
            "logloss": 0.9636117205322137,
            "mae": 0.28019431648104953,
            "precision": 0.70018281535649,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8602761898310962,
            "auditor_fn_violation": 0.007971409727721479,
            "auditor_fp_violation": 0.016667092129783265,
            "ave_precision_score": 0.8604784611481879,
            "fpr": 0.15697036223929747,
            "logloss": 0.8165047444739526,
            "mae": 0.2620572473010306,
            "precision": 0.7322097378277154,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.818170176355218,
            "auditor_fn_violation": 0.00760125737175921,
            "auditor_fp_violation": 0.027297386404507858,
            "ave_precision_score": 0.8186779063685834,
            "fpr": 0.18092105263157895,
            "logloss": 1.0160950245226026,
            "mae": 0.2822409966284708,
            "precision": 0.6994535519125683,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.85438659238637,
            "auditor_fn_violation": 0.00958714350591409,
            "auditor_fp_violation": 0.020358410129425887,
            "ave_precision_score": 0.8545599837819509,
            "fpr": 0.15697036223929747,
            "logloss": 0.8627566103697542,
            "mae": 0.26372174303928037,
            "precision": 0.7327102803738318,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.709090779169609,
            "auditor_fn_violation": 0.06581265531693928,
            "auditor_fp_violation": 0.0665138072972865,
            "ave_precision_score": 0.7060352307540138,
            "fpr": 0.20614035087719298,
            "logloss": 2.7331146507017454,
            "mae": 0.3431945332550239,
            "precision": 0.6512059369202227,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7537030362355723,
            "auditor_fn_violation": 0.06183604866371058,
            "auditor_fp_violation": 0.06438107880427846,
            "ave_precision_score": 0.7498495549390995,
            "fpr": 0.18660812294182216,
            "logloss": 2.601545891263492,
            "mae": 0.32154025469035313,
            "precision": 0.6810506566604128,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7277664312519906,
            "auditor_fn_violation": 0.05847335039501503,
            "auditor_fp_violation": 0.07566788554529834,
            "ave_precision_score": 0.7267964263175257,
            "fpr": 0.23793859649122806,
            "logloss": 2.3429175984954855,
            "mae": 0.3453921015677199,
            "precision": 0.6365159128978225,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.772269868425134,
            "auditor_fn_violation": 0.06091179417194785,
            "auditor_fp_violation": 0.07296862634978175,
            "ave_precision_score": 0.7709847303779096,
            "fpr": 0.21514818880351264,
            "logloss": 2.169897767073253,
            "mae": 0.3223472667165995,
            "precision": 0.6638078902229846,
            "recall": 0.8045738045738046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7113401464522444,
            "auditor_fn_violation": 0.004942324097770853,
            "auditor_fp_violation": 0.013062982056508018,
            "ave_precision_score": 0.688468720655593,
            "fpr": 0.1787280701754386,
            "logloss": 2.3524797413493674,
            "mae": 0.2994897032982826,
            "precision": 0.6953271028037383,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7371256053225804,
            "auditor_fn_violation": 0.007512705646624418,
            "auditor_fp_violation": 0.012998749138437194,
            "ave_precision_score": 0.7134955673007706,
            "fpr": 0.18221734357848518,
            "logloss": 2.2001330178181595,
            "mae": 0.2904172847938643,
            "precision": 0.7025089605734767,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8193798182679313,
            "auditor_fn_violation": 0.010090964726827644,
            "auditor_fp_violation": 0.012373616273028822,
            "ave_precision_score": 0.8199984191695682,
            "fpr": 0.125,
            "logloss": 0.8370067731851125,
            "mae": 0.2825698880410908,
            "precision": 0.7532467532467533,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.83939502525547,
            "auditor_fn_violation": 0.01230970056436577,
            "auditor_fp_violation": 0.012952799121844133,
            "ave_precision_score": 0.839642866165565,
            "fpr": 0.12952799121844127,
            "logloss": 0.7570081370381548,
            "mae": 0.27537494054595346,
            "precision": 0.7526205450733753,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8258864851691182,
            "auditor_fn_violation": 0.010065464930826008,
            "auditor_fp_violation": 0.02533169484074652,
            "ave_precision_score": 0.8262439912358279,
            "fpr": 0.17763157894736842,
            "logloss": 0.926954658357365,
            "mae": 0.27888992408062063,
            "precision": 0.7027522935779816,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.859409925658555,
            "auditor_fn_violation": 0.005098233418760312,
            "auditor_fp_violation": 0.015822122380210864,
            "ave_precision_score": 0.8596254266887062,
            "fpr": 0.15587266739846323,
            "logloss": 0.7878076704087361,
            "mae": 0.2600612557449866,
            "precision": 0.7365491651205937,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8049964129233009,
            "auditor_fn_violation": 0.014233522495456402,
            "auditor_fp_violation": 0.026505614834352396,
            "ave_precision_score": 0.805784252528639,
            "fpr": 0.16776315789473684,
            "logloss": 1.0781880530556776,
            "mae": 0.2839466018054319,
            "precision": 0.7074569789674953,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8468121867102718,
            "auditor_fn_violation": 0.01581273919363931,
            "auditor_fp_violation": 0.024496464401501036,
            "ave_precision_score": 0.8470230063104764,
            "fpr": 0.15806805708013172,
            "logloss": 0.9266191582027582,
            "mae": 0.2663925378646631,
            "precision": 0.7303370786516854,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7968861826474358,
            "auditor_fn_violation": 0.00915674492785876,
            "auditor_fp_violation": 0.029360488350717345,
            "ave_precision_score": 0.7975431324659709,
            "fpr": 0.1875,
            "logloss": 1.0924848887970513,
            "mae": 0.2922486423726982,
            "precision": 0.6946428571428571,
            "recall": 0.8224101479915433
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8292581969859038,
            "auditor_fn_violation": 0.01129644378821108,
            "auditor_fp_violation": 0.020197585071350173,
            "ave_precision_score": 0.8295571032955191,
            "fpr": 0.1800219538968167,
            "logloss": 0.9803642387501117,
            "mae": 0.273089064568703,
            "precision": 0.7087033747779752,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7165347537450122,
            "auditor_fn_violation": 0.006961444308445532,
            "auditor_fp_violation": 0.01277324861127763,
            "ave_precision_score": 0.693658827131595,
            "fpr": 0.17105263157894737,
            "logloss": 2.3111744748806924,
            "mae": 0.29248567319939756,
            "precision": 0.7073170731707317,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7417709985273212,
            "auditor_fn_violation": 0.007063130004952186,
            "auditor_fp_violation": 0.006381946749036332,
            "ave_precision_score": 0.7181298046101163,
            "fpr": 0.17892425905598244,
            "logloss": 2.1696459413536084,
            "mae": 0.28318430063088673,
            "precision": 0.7068345323741008,
            "recall": 0.817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8297426921110256,
            "auditor_fn_violation": 0.015190923927154043,
            "auditor_fp_violation": 0.014649022898932983,
            "ave_precision_score": 0.8311887599867473,
            "fpr": 0.09978070175438597,
            "logloss": 0.6693671390927594,
            "mae": 0.2759357443098591,
            "precision": 0.7959641255605381,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.86902726681847,
            "auditor_fn_violation": 0.012458037705019048,
            "auditor_fp_violation": 0.010757409440175633,
            "ave_precision_score": 0.8695323645476114,
            "fpr": 0.09110867178924259,
            "logloss": 0.5710562320313964,
            "mae": 0.26061057896242235,
            "precision": 0.8147321428571429,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7355211399894499,
            "auditor_fn_violation": 0.055227921812989134,
            "auditor_fp_violation": 0.06550473564320826,
            "ave_precision_score": 0.7347130400075363,
            "fpr": 0.20833333333333334,
            "logloss": 2.0922900996764655,
            "mae": 0.3278841014396007,
            "precision": 0.6588868940754039,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7795720853140169,
            "auditor_fn_violation": 0.06187484453126605,
            "auditor_fp_violation": 0.06302810609348275,
            "ave_precision_score": 0.7794043147888547,
            "fpr": 0.18660812294182216,
            "logloss": 1.917532808332274,
            "mae": 0.307481685282308,
            "precision": 0.6880733944954128,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6896539555394572,
            "auditor_fn_violation": 0.018206854345165238,
            "auditor_fp_violation": 0.027497202573632265,
            "ave_precision_score": 0.6800958579116696,
            "fpr": 0.19188596491228072,
            "logloss": 1.898900587371991,
            "mae": 0.3374761548992885,
            "precision": 0.6679316888045541,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7213045891636232,
            "auditor_fn_violation": 0.014219826514008736,
            "auditor_fp_violation": 0.01509202767212111,
            "ave_precision_score": 0.7132535397941456,
            "fpr": 0.18441273326015367,
            "logloss": 1.636896317978631,
            "mae": 0.3146492183342816,
            "precision": 0.6928702010968921,
            "recall": 0.7879417879417879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7992279184434397,
            "auditor_fn_violation": 0.003959422870071586,
            "auditor_fp_violation": 0.02306128361907046,
            "ave_precision_score": 0.7998857953428465,
            "fpr": 0.16228070175438597,
            "logloss": 0.9696816868070325,
            "mae": 0.2898223734711608,
            "precision": 0.7109375,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8350219153393434,
            "auditor_fn_violation": 0.010782969070565127,
            "auditor_fp_violation": 0.017356342378679203,
            "ave_precision_score": 0.8352591022338843,
            "fpr": 0.1437980241492865,
            "logloss": 0.8574272980799351,
            "mae": 0.2772465107120132,
            "precision": 0.741106719367589,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 6654,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7913394967338263,
            "auditor_fn_violation": 0.010225418196654429,
            "auditor_fp_violation": 0.02104813571514207,
            "ave_precision_score": 0.7518736692916841,
            "fpr": 0.14583333333333334,
            "logloss": 4.157867448942629,
            "mae": 0.2806635384659713,
            "precision": 0.7366336633663366,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8044087115952578,
            "auditor_fn_violation": 0.009114746765679815,
            "auditor_fp_violation": 0.013402088172976287,
            "ave_precision_score": 0.7610540855450532,
            "fpr": 0.14270032930845225,
            "logloss": 3.972181390183278,
            "mae": 0.27649252295051924,
            "precision": 0.7389558232931727,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7224324522627051,
            "auditor_fn_violation": 0.013398983717221176,
            "auditor_fp_violation": 0.018300663389681497,
            "ave_precision_score": 0.7014672484407846,
            "fpr": 0.17105263157894737,
            "logloss": 2.287453513353467,
            "mae": 0.28983025779666466,
            "precision": 0.7073170731707317,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7462364027361744,
            "auditor_fn_violation": 0.0067322240758025675,
            "auditor_fp_violation": 0.01787966201210017,
            "ave_precision_score": 0.7247566864457848,
            "fpr": 0.1734357848518112,
            "logloss": 2.1753963468679998,
            "mae": 0.2832928430355703,
            "precision": 0.7122040072859745,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 6654,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8336144214779639,
            "auditor_fn_violation": 0.010554597381402764,
            "auditor_fp_violation": 0.013145406226271836,
            "ave_precision_score": 0.8339103902748952,
            "fpr": 0.15021929824561403,
            "logloss": 0.5402342420362567,
            "mae": 0.31001764682188976,
            "precision": 0.732943469785575,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8747001173957232,
            "auditor_fn_violation": 0.013713198125931386,
            "auditor_fp_violation": 0.013682893829933885,
            "ave_precision_score": 0.8748562713334419,
            "fpr": 0.13172338090010977,
            "logloss": 0.48937217804950633,
            "mae": 0.29773277336574117,
            "precision": 0.7674418604651163,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8187417277716467,
            "auditor_fn_violation": 0.009761785542079302,
            "auditor_fp_violation": 0.025344183351316798,
            "ave_precision_score": 0.8191839649886024,
            "fpr": 0.1425438596491228,
            "logloss": 0.8366425867261559,
            "mae": 0.27923393245931327,
            "precision": 0.7346938775510204,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8462820957119057,
            "auditor_fn_violation": 0.013971076539682468,
            "auditor_fp_violation": 0.01531667219768719,
            "ave_precision_score": 0.846507146855686,
            "fpr": 0.13721185510428102,
            "logloss": 0.7479218474376087,
            "mae": 0.26821341613139543,
            "precision": 0.749498997995992,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8482108483021498,
            "auditor_fn_violation": 0.0005494046956715237,
            "auditor_fp_violation": 0.013430144267274114,
            "ave_precision_score": 0.848602155984833,
            "fpr": 0.11403508771929824,
            "logloss": 0.6167964900958325,
            "mae": 0.2733519539474753,
            "precision": 0.7724288840262582,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8783327847099147,
            "auditor_fn_violation": 0.017455858290106378,
            "auditor_fp_violation": 0.011717254231230698,
            "ave_precision_score": 0.8784839416088569,
            "fpr": 0.10428100987925357,
            "logloss": 0.56410782654964,
            "mae": 0.26146311106199543,
            "precision": 0.7902869757174393,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8062667809666573,
            "auditor_fn_violation": 0.010635733095953415,
            "auditor_fp_violation": 0.024844642928505772,
            "ave_precision_score": 0.8068650068897043,
            "fpr": 0.17214912280701755,
            "logloss": 0.9911369651416536,
            "mae": 0.2840327021291601,
            "precision": 0.7059925093632958,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8417594397550988,
            "auditor_fn_violation": 0.00819505649362949,
            "auditor_fp_violation": 0.01884461236055447,
            "ave_precision_score": 0.8420023375834669,
            "fpr": 0.16136114160263446,
            "logloss": 0.8742671235763573,
            "mae": 0.26734706959568383,
            "precision": 0.7287822878228782,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7930223923173578,
            "auditor_fn_violation": 0.010016783502095623,
            "auditor_fp_violation": 0.020790872397394407,
            "ave_precision_score": 0.7934447267275861,
            "fpr": 0.14473684210526316,
            "logloss": 1.038496692257534,
            "mae": 0.28845754393364226,
            "precision": 0.7306122448979592,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8224703069355999,
            "auditor_fn_violation": 0.009671581570593647,
            "auditor_fp_violation": 0.018691445638577595,
            "ave_precision_score": 0.8227613769525567,
            "fpr": 0.14489571899012074,
            "logloss": 0.9282429806305587,
            "mae": 0.27759910188185255,
            "precision": 0.7380952380952381,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8447960064423543,
            "auditor_fn_violation": 0.011620952486925571,
            "auditor_fp_violation": 0.011059824961035851,
            "ave_precision_score": 0.8450736758458639,
            "fpr": 0.10635964912280702,
            "logloss": 0.640715815078661,
            "mae": 0.2781366923198142,
            "precision": 0.7825112107623319,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8713975472057811,
            "auditor_fn_violation": 0.008005641375564542,
            "auditor_fp_violation": 0.007367319327087537,
            "ave_precision_score": 0.8716460260691055,
            "fpr": 0.10098792535675083,
            "logloss": 0.5703648467890806,
            "mae": 0.262463467588039,
            "precision": 0.7973568281938326,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8256163181489117,
            "auditor_fn_violation": 0.005711954304365565,
            "auditor_fp_violation": 0.026545578068177283,
            "ave_precision_score": 0.8260108918977209,
            "fpr": 0.17763157894736842,
            "logloss": 0.9425892643334723,
            "mae": 0.2795239890831869,
            "precision": 0.7038391224862889,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8583554179871038,
            "auditor_fn_violation": 0.003984563808932638,
            "auditor_fp_violation": 0.014321088504837522,
            "ave_precision_score": 0.8585781581286127,
            "fpr": 0.15916575192096596,
            "logloss": 0.8057164444737874,
            "mae": 0.26044577499659366,
            "precision": 0.7349177330895795,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7928513490775789,
            "auditor_fn_violation": 0.009710785950076038,
            "auditor_fp_violation": 0.02333603085161652,
            "ave_precision_score": 0.7933583070238435,
            "fpr": 0.1611842105263158,
            "logloss": 1.0765257683539877,
            "mae": 0.28131069496227323,
            "precision": 0.7167630057803468,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8338840376891974,
            "auditor_fn_violation": 0.017398805543701268,
            "auditor_fp_violation": 0.018277895489240036,
            "ave_precision_score": 0.834125658765966,
            "fpr": 0.150384193194292,
            "logloss": 0.9259623791401985,
            "mae": 0.26780732710210114,
            "precision": 0.7390476190476191,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8185030265129802,
            "auditor_fn_violation": 0.019405344757241944,
            "auditor_fp_violation": 0.020501138952164016,
            "ave_precision_score": 0.8198555860100221,
            "fpr": 0.09868421052631579,
            "logloss": 0.7639732266668162,
            "mae": 0.2959214841584267,
            "precision": 0.7906976744186046,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8573489155561413,
            "auditor_fn_violation": 0.023042463218094396,
            "auditor_fp_violation": 0.01771628417532484,
            "ave_precision_score": 0.8575275072166089,
            "fpr": 0.10976948408342481,
            "logloss": 0.7158839598529735,
            "mae": 0.28701377427676317,
            "precision": 0.7747747747747747,
            "recall": 0.7151767151767152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7302076812425862,
            "auditor_fn_violation": 0.014655428211119762,
            "auditor_fp_violation": 0.02864864324821165,
            "ave_precision_score": 0.7293816407162236,
            "fpr": 0.14912280701754385,
            "logloss": 1.6332042266445213,
            "mae": 0.2957467174245283,
            "precision": 0.7230142566191446,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7743182977438372,
            "auditor_fn_violation": 0.016933255133035598,
            "auditor_fp_violation": 0.014489571899012078,
            "ave_precision_score": 0.7729015654075153,
            "fpr": 0.14489571899012074,
            "logloss": 1.4309063374698352,
            "mae": 0.28683466305406524,
            "precision": 0.7344064386317908,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8021674485582456,
            "auditor_fn_violation": 0.01817903638589073,
            "auditor_fp_violation": 0.03419603964352796,
            "ave_precision_score": 0.8025558399081403,
            "fpr": 0.1425438596491228,
            "logloss": 1.0163389718548645,
            "mae": 0.2776363062256292,
            "precision": 0.7319587628865979,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8338836182883953,
            "auditor_fn_violation": 0.020687325846491605,
            "auditor_fp_violation": 0.022780997115360076,
            "ave_precision_score": 0.8341253426925791,
            "fpr": 0.13611416026344675,
            "logloss": 0.9169552018831537,
            "mae": 0.2685818478593769,
            "precision": 0.7489878542510121,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8056910520695879,
            "auditor_fn_violation": 0.009205426356589157,
            "auditor_fp_violation": 0.008871837909123607,
            "ave_precision_score": 0.8063463880190201,
            "fpr": 0.11403508771929824,
            "logloss": 0.9664781091274252,
            "mae": 0.2878740876843334,
            "precision": 0.7603686635944701,
            "recall": 0.6976744186046512
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8321393006371105,
            "auditor_fn_violation": 0.011659299255347559,
            "auditor_fp_violation": 0.014627421948791262,
            "ave_precision_score": 0.8324202524197268,
            "fpr": 0.1207464324917673,
            "logloss": 0.8553991205041362,
            "mae": 0.28097030184683813,
            "precision": 0.7544642857142857,
            "recall": 0.7027027027027027
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8101604527827004,
            "auditor_fn_violation": 0.00805793553651571,
            "auditor_fp_violation": 0.026018562922111656,
            "ave_precision_score": 0.8107513841973822,
            "fpr": 0.16228070175438597,
            "logloss": 0.9640803493374037,
            "mae": 0.281982909614399,
            "precision": 0.7164750957854407,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8375757753556851,
            "auditor_fn_violation": 0.008306879876583502,
            "auditor_fp_violation": 0.025303142470579233,
            "ave_precision_score": 0.8378160866460747,
            "fpr": 0.14928649835345773,
            "logloss": 0.8543945704175787,
            "mae": 0.265065421448348,
            "precision": 0.7414448669201521,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7968319810282195,
            "auditor_fn_violation": 0.009912466154816215,
            "auditor_fp_violation": 0.023810594253286976,
            "ave_precision_score": 0.7976539477381066,
            "fpr": 0.15789473684210525,
            "logloss": 1.1107142935931444,
            "mae": 0.2856866889457166,
            "precision": 0.71875,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.825959068789319,
            "auditor_fn_violation": 0.009183210061365939,
            "auditor_fp_violation": 0.013856482781507676,
            "ave_precision_score": 0.8262392019951798,
            "fpr": 0.150384193194292,
            "logloss": 0.992815443697789,
            "mae": 0.2733942911678267,
            "precision": 0.732421875,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8588612773356166,
            "auditor_fn_violation": 0.01298171432810356,
            "auditor_fp_violation": 0.017231646884865927,
            "ave_precision_score": 0.8591521578151161,
            "fpr": 0.11732456140350878,
            "logloss": 0.48143482291687906,
            "mae": 0.2996878659994987,
            "precision": 0.7789256198347108,
            "recall": 0.7970401691331924
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8771654286780006,
            "auditor_fn_violation": 0.006675171329397454,
            "auditor_fp_violation": 0.01481888035126235,
            "ave_precision_score": 0.8774539613971779,
            "fpr": 0.10208562019758508,
            "logloss": 0.4512363881979138,
            "mae": 0.2908189115789233,
            "precision": 0.805439330543933,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6871335423336552,
            "auditor_fn_violation": 0.007195578799005969,
            "auditor_fp_violation": 0.032355233185469366,
            "ave_precision_score": 0.675756252687796,
            "fpr": 0.1699561403508772,
            "logloss": 2.046825939701851,
            "mae": 0.3045814611530533,
            "precision": 0.7013487475915221,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6961406033418029,
            "auditor_fn_violation": 0.00445239632945451,
            "auditor_fp_violation": 0.033272917570775794,
            "ave_precision_score": 0.6821148698452051,
            "fpr": 0.17233809001097694,
            "logloss": 2.1093328941702043,
            "mae": 0.3013333723282363,
            "precision": 0.7032136105860114,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7945715313202528,
            "auditor_fn_violation": 0.012117039427320944,
            "auditor_fp_violation": 0.022796527194980622,
            "ave_precision_score": 0.7947052763785076,
            "fpr": 0.14912280701754385,
            "logloss": 0.9677312752730164,
            "mae": 0.2845682482416286,
            "precision": 0.7285429141716567,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8405512429563466,
            "auditor_fn_violation": 0.013610503182402202,
            "auditor_fp_violation": 0.015674061215633216,
            "ave_precision_score": 0.840757570611487,
            "fpr": 0.14270032930845225,
            "logloss": 0.8128952888264209,
            "mae": 0.2703897026898568,
            "precision": 0.7425742574257426,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8342545881661787,
            "auditor_fn_violation": 0.0008299024516894795,
            "auditor_fp_violation": 0.02117551852295888,
            "ave_precision_score": 0.8346483159934346,
            "fpr": 0.14912280701754385,
            "logloss": 0.8460930228403102,
            "mae": 0.2715970357725782,
            "precision": 0.7328094302554028,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8621402147839052,
            "auditor_fn_violation": 0.009187774281078349,
            "auditor_fp_violation": 0.012917060220049523,
            "ave_precision_score": 0.8623453638415437,
            "fpr": 0.13172338090010977,
            "logloss": 0.7365593751226331,
            "mae": 0.2557017397928792,
            "precision": 0.7604790419161677,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7938636030591195,
            "auditor_fn_violation": 0.0143957939245577,
            "auditor_fp_violation": 0.019529532829796584,
            "ave_precision_score": 0.7944022375609715,
            "fpr": 0.14035087719298245,
            "logloss": 1.040726643015112,
            "mae": 0.2879644523985329,
            "precision": 0.732776617954071,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8228804669626816,
            "auditor_fn_violation": 0.010502269558251998,
            "auditor_fp_violation": 0.016072294692773086,
            "ave_precision_score": 0.8231712578408832,
            "fpr": 0.13830954994511527,
            "logloss": 0.9291402178291093,
            "mae": 0.27694117856027517,
            "precision": 0.7428571428571429,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.821339750125684,
            "auditor_fn_violation": 0.011046047995252405,
            "auditor_fp_violation": 0.014923770131479039,
            "ave_precision_score": 0.8220008405926504,
            "fpr": 0.1118421052631579,
            "logloss": 0.8818142348750059,
            "mae": 0.2759050378730342,
            "precision": 0.7681818181818182,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8549685712537822,
            "auditor_fn_violation": 0.008112900538806143,
            "auditor_fp_violation": 0.012866004646057232,
            "ave_precision_score": 0.8552020737548292,
            "fpr": 0.11086717892425905,
            "logloss": 0.753811151325362,
            "mae": 0.26186691386086036,
            "precision": 0.7799564270152506,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7977824486144411,
            "auditor_fn_violation": 0.01088841289269686,
            "auditor_fp_violation": 0.023578307956679867,
            "ave_precision_score": 0.7934747120494096,
            "fpr": 0.14583333333333334,
            "logloss": 1.4212739057453159,
            "mae": 0.2840483478652129,
            "precision": 0.7296747967479674,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.815088290701402,
            "auditor_fn_violation": 0.013720044455500001,
            "auditor_fp_violation": 0.017343578485181126,
            "ave_precision_score": 0.8124155920088005,
            "fpr": 0.14050493962678376,
            "logloss": 1.2226829715196432,
            "mae": 0.27363913607945056,
            "precision": 0.7424547283702213,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7918654577574993,
            "auditor_fn_violation": 0.03358091317087645,
            "auditor_fp_violation": 0.04087989050073932,
            "ave_precision_score": 0.7747047532701259,
            "fpr": 0.1611842105263158,
            "logloss": 2.7556325935157524,
            "mae": 0.2836246270116699,
            "precision": 0.7111984282907662,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7997959963720843,
            "auditor_fn_violation": 0.030607657391411507,
            "auditor_fp_violation": 0.03316570086539198,
            "ave_precision_score": 0.7821652906970096,
            "fpr": 0.16355653128430298,
            "logloss": 2.5322380856617968,
            "mae": 0.2806570730594204,
            "precision": 0.7172675521821632,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8084249613865035,
            "auditor_fn_violation": 0.010536052075219772,
            "auditor_fp_violation": 0.017873556328178074,
            "ave_precision_score": 0.8089810530442305,
            "fpr": 0.13815789473684212,
            "logloss": 0.9457477819184142,
            "mae": 0.2846567030595679,
            "precision": 0.7358490566037735,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8405823381890166,
            "auditor_fn_violation": 0.009767430184554225,
            "auditor_fp_violation": 0.015035866540729586,
            "ave_precision_score": 0.8408219013059127,
            "fpr": 0.13611416026344675,
            "logloss": 0.8274067033295064,
            "mae": 0.27249857818352663,
            "precision": 0.7453798767967146,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6815650885947884,
            "auditor_fn_violation": 0.009993601869366863,
            "auditor_fp_violation": 0.02962524477480718,
            "ave_precision_score": 0.6703431271237029,
            "fpr": 0.13706140350877194,
            "logloss": 2.150535952174337,
            "mae": 0.3168798663480864,
            "precision": 0.7159090909090909,
            "recall": 0.6659619450317125
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6903165514954628,
            "auditor_fn_violation": 0.0077044028745455765,
            "auditor_fp_violation": 0.03964975876241288,
            "ave_precision_score": 0.6763024500996101,
            "fpr": 0.150384193194292,
            "logloss": 2.187206833576173,
            "mae": 0.3179250496501453,
            "precision": 0.7066381156316917,
            "recall": 0.6860706860706861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8036126857323469,
            "auditor_fn_violation": 0.011092411260709915,
            "auditor_fp_violation": 0.021118071374335617,
            "ave_precision_score": 0.8044798563019093,
            "fpr": 0.13706140350877194,
            "logloss": 0.988943089299051,
            "mae": 0.2815435300591683,
            "precision": 0.7390396659707724,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8307551764927821,
            "auditor_fn_violation": 0.014635170507837908,
            "auditor_fp_violation": 0.018890562377147528,
            "ave_precision_score": 0.831020446383087,
            "fpr": 0.13172338090010977,
            "logloss": 0.886386241090226,
            "mae": 0.27041182949702125,
            "precision": 0.7535934291581109,
            "recall": 0.762993762993763
        }
    }
]