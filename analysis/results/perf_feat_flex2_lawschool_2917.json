[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8459148442460999,
            "auditor_fn_violation": 0.008364143830651009,
            "auditor_fp_violation": 0.017651459255615676,
            "ave_precision_score": 0.8462595982431236,
            "fpr": 0.1118421052631579,
            "logloss": 0.6964137848295993,
            "mae": 0.2647531612215678,
            "precision": 0.7852631578947369,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8561524748796496,
            "auditor_fn_violation": 0.014489571899012078,
            "auditor_fp_violation": 0.012846265472892414,
            "ave_precision_score": 0.8563407355627544,
            "fpr": 0.11745334796926454,
            "logloss": 0.6540087659403492,
            "mae": 0.265206126098038,
            "precision": 0.7698924731182796,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8515257748440493,
            "auditor_fn_violation": 0.027412280701754388,
            "auditor_fp_violation": 0.026254303984259725,
            "ave_precision_score": 0.8518220161523486,
            "fpr": 0.125,
            "logloss": 0.7755760609553529,
            "mae": 0.2696765944315379,
            "precision": 0.7610062893081762,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.833075733466039,
            "auditor_fn_violation": 0.027687600719340455,
            "auditor_fp_violation": 0.023156134023312954,
            "ave_precision_score": 0.8343527171624038,
            "fpr": 0.132821075740944,
            "logloss": 0.79111780490754,
            "mae": 0.27421423701030795,
            "precision": 0.7436440677966102,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8343864850633624,
            "auditor_fn_violation": 0.026714513556618823,
            "auditor_fp_violation": 0.03296390801770782,
            "ave_precision_score": 0.8348039725667793,
            "fpr": 0.13486842105263158,
            "logloss": 0.8037075867968154,
            "mae": 0.2660314487995355,
            "precision": 0.757396449704142,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8363922813616083,
            "auditor_fn_violation": 0.026891188079501135,
            "auditor_fp_violation": 0.026543804495819553,
            "ave_precision_score": 0.8366722973742764,
            "fpr": 0.14050493962678376,
            "logloss": 0.781017942808204,
            "mae": 0.26909972749727906,
            "precision": 0.7344398340248963,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8518846846573026,
            "auditor_fn_violation": 0.02606205596636219,
            "auditor_fp_violation": 0.025237231513362848,
            "ave_precision_score": 0.8522275321617871,
            "fpr": 0.11074561403508772,
            "logloss": 0.6699736083298483,
            "mae": 0.25660383243400264,
            "precision": 0.7891440501043842,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8529631428974869,
            "auditor_fn_violation": 0.01944321180839386,
            "auditor_fp_violation": 0.022877354381196317,
            "ave_precision_score": 0.8532078794224016,
            "fpr": 0.12403951701427003,
            "logloss": 0.6705608882086581,
            "mae": 0.2648296133679652,
            "precision": 0.7626050420168067,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.846386459691357,
            "auditor_fn_violation": 0.008645063070900393,
            "auditor_fp_violation": 0.02292383997376619,
            "ave_precision_score": 0.8466867543970635,
            "fpr": 0.12280701754385964,
            "logloss": 0.676528425302755,
            "mae": 0.2691109763399497,
            "precision": 0.7723577235772358,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8525686226492629,
            "auditor_fn_violation": 0.016951210967606326,
            "auditor_fp_violation": 0.01729678333096869,
            "ave_precision_score": 0.8527657908916314,
            "fpr": 0.12623490669593854,
            "logloss": 0.6385555710770503,
            "mae": 0.2715148541160572,
            "precision": 0.7584033613445378,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8454541765105209,
            "auditor_fn_violation": 0.022446353487023354,
            "auditor_fp_violation": 0.023574561403508776,
            "ave_precision_score": 0.845815541099848,
            "fpr": 0.11732456140350878,
            "logloss": 0.7131305216713961,
            "mae": 0.26323117774001653,
            "precision": 0.7770833333333333,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8327032523946201,
            "auditor_fn_violation": 0.021402713875329896,
            "auditor_fp_violation": 0.019412521686318143,
            "ave_precision_score": 0.8329895598565609,
            "fpr": 0.12952799121844127,
            "logloss": 0.7338804000358194,
            "mae": 0.27152242300837753,
            "precision": 0.75,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8396829563560553,
            "auditor_fn_violation": 0.009904668696534733,
            "auditor_fp_violation": 0.018217638137399572,
            "ave_precision_score": 0.8400628271906935,
            "fpr": 0.12828947368421054,
            "logloss": 0.6409842418614508,
            "mae": 0.269061263941256,
            "precision": 0.7650602409638554,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8460770767904424,
            "auditor_fn_violation": 0.013036877875610165,
            "auditor_fp_violation": 0.013488454291339668,
            "ave_precision_score": 0.8462955047991199,
            "fpr": 0.13721185510428102,
            "logloss": 0.6213499115624432,
            "mae": 0.272736130112108,
            "precision": 0.745417515274949,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8424243704409647,
            "auditor_fn_violation": 0.025312182833115843,
            "auditor_fp_violation": 0.02533458353828497,
            "ave_precision_score": 0.8427533488876116,
            "fpr": 0.10855263157894737,
            "logloss": 0.7671737827806335,
            "mae": 0.26694378146645914,
            "precision": 0.7847826086956522,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8361780338856797,
            "auditor_fn_violation": 0.02113179344652825,
            "auditor_fp_violation": 0.02280517036671969,
            "ave_precision_score": 0.8365050072535358,
            "fpr": 0.12184412733260154,
            "logloss": 0.7764970935520353,
            "mae": 0.27821366050130814,
            "precision": 0.756043956043956,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8271412278013575,
            "auditor_fn_violation": 0.012609649122807024,
            "auditor_fp_violation": 0.022729135923921964,
            "ave_precision_score": 0.8277692977482547,
            "fpr": 0.1337719298245614,
            "logloss": 0.7780927901569482,
            "mae": 0.2792571748012308,
            "precision": 0.7484536082474227,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8314982416639525,
            "auditor_fn_violation": 0.019228343882102903,
            "auditor_fp_violation": 0.01638328218224722,
            "ave_precision_score": 0.831730874278563,
            "fpr": 0.13391877058177826,
            "logloss": 0.7422222359418744,
            "mae": 0.2831897681714726,
            "precision": 0.735357917570499,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8310823697080915,
            "auditor_fn_violation": 0.02346581847179933,
            "auditor_fp_violation": 0.026994691752746353,
            "ave_precision_score": 0.8316041758766867,
            "fpr": 0.12609649122807018,
            "logloss": 0.7794532651055845,
            "mae": 0.2759364388877189,
            "precision": 0.7589098532494759,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8348990988338664,
            "auditor_fn_violation": 0.026496485040988397,
            "auditor_fp_violation": 0.02665830327740317,
            "ave_precision_score": 0.835136272770217,
            "fpr": 0.13830954994511527,
            "logloss": 0.7697246411403171,
            "mae": 0.28218074359603945,
            "precision": 0.738045738045738,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8419343172483377,
            "auditor_fn_violation": 0.02954862621429608,
            "auditor_fp_violation": 0.020100631251024757,
            "ave_precision_score": 0.8422813149311889,
            "fpr": 0.1162280701754386,
            "logloss": 0.7164361724893731,
            "mae": 0.2659978865192907,
            "precision": 0.778705636743215,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8348708603201543,
            "auditor_fn_violation": 0.022131396407968802,
            "auditor_fp_violation": 0.02284997423777415,
            "ave_precision_score": 0.8351739220676959,
            "fpr": 0.12403951701427003,
            "logloss": 0.7145830732569404,
            "mae": 0.2735776469506334,
            "precision": 0.7590618336886994,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8165583538090778,
            "auditor_fn_violation": 0.012636834855734386,
            "auditor_fp_violation": 0.02396909329398262,
            "ave_precision_score": 0.8124453300663275,
            "fpr": 0.12390350877192982,
            "logloss": 2.9664402260578253,
            "mae": 0.27755527568136984,
            "precision": 0.7600849256900213,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8163248577126729,
            "auditor_fn_violation": 0.025802835322418664,
            "auditor_fp_violation": 0.023238274453579462,
            "ave_precision_score": 0.8118879893359736,
            "fpr": 0.13172338090010977,
            "logloss": 3.0281566623716683,
            "mae": 0.28341623220048767,
            "precision": 0.7345132743362832,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8494161566982525,
            "auditor_fn_violation": 0.013855661881977677,
            "auditor_fp_violation": 0.026925520577143796,
            "ave_precision_score": 0.8497963814656607,
            "fpr": 0.13925438596491227,
            "logloss": 0.6040768796688927,
            "mae": 0.2698006873778739,
            "precision": 0.751953125,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8527649149574502,
            "auditor_fn_violation": 0.010930237989583582,
            "auditor_fp_violation": 0.01799871064415522,
            "ave_precision_score": 0.8529543526983223,
            "fpr": 0.145993413830955,
            "logloss": 0.6077771089042993,
            "mae": 0.2777863544407668,
            "precision": 0.7334669338677354,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8265192461994659,
            "auditor_fn_violation": 0.03376468029578079,
            "auditor_fp_violation": 0.018058800623052967,
            "ave_precision_score": 0.826813301902886,
            "fpr": 0.09758771929824561,
            "logloss": 1.8315295552126132,
            "mae": 0.28104969701977106,
            "precision": 0.789598108747045,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8260770680335973,
            "auditor_fn_violation": 0.03282341126188197,
            "auditor_fp_violation": 0.02493584334575396,
            "ave_precision_score": 0.8260278940124836,
            "fpr": 0.10098792535675083,
            "logloss": 1.7176658269978957,
            "mae": 0.2859764128641567,
            "precision": 0.775609756097561,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.833418987682875,
            "auditor_fn_violation": 0.02523742206756561,
            "auditor_fp_violation": 0.030671011641252674,
            "ave_precision_score": 0.8337716376862914,
            "fpr": 0.13596491228070176,
            "logloss": 0.8388411532184586,
            "mae": 0.26705932461528553,
            "precision": 0.7559055118110236,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8366618547725068,
            "auditor_fn_violation": 0.02687250391199757,
            "auditor_fp_violation": 0.023813257465445017,
            "ave_precision_score": 0.8369244687802928,
            "fpr": 0.14489571899012074,
            "logloss": 0.8064787941469566,
            "mae": 0.26934232382856627,
            "precision": 0.7349397590361446,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8389309215209282,
            "auditor_fn_violation": 0.010162933159344648,
            "auditor_fp_violation": 0.026354217904574522,
            "ave_precision_score": 0.8394837835815552,
            "fpr": 0.11293859649122807,
            "logloss": 0.5811088090751906,
            "mae": 0.2844727990611972,
            "precision": 0.7784946236559139,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.844884262586179,
            "auditor_fn_violation": 0.019989723707873042,
            "auditor_fp_violation": 0.011171098516245141,
            "ave_precision_score": 0.8451168998827716,
            "fpr": 0.1119648737650933,
            "logloss": 0.5657893754553229,
            "mae": 0.28801551893969146,
            "precision": 0.7728285077951003,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8241682254509506,
            "auditor_fn_violation": 0.011877899811512256,
            "auditor_fp_violation": 0.023005820626332187,
            "ave_precision_score": 0.8255042248867865,
            "fpr": 0.12171052631578948,
            "logloss": 0.8518932866303428,
            "mae": 0.27304394022876727,
            "precision": 0.7628205128205128,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8323093008356945,
            "auditor_fn_violation": 0.017161407852021394,
            "auditor_fp_violation": 0.014439291999273181,
            "ave_precision_score": 0.8325519916771028,
            "fpr": 0.12623490669593854,
            "logloss": 0.8257062297283646,
            "mae": 0.2747533097405342,
            "precision": 0.7516198704103672,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8504189608920975,
            "auditor_fn_violation": 0.014238527620704657,
            "auditor_fp_violation": 0.017318412854566333,
            "ave_precision_score": 0.8507623554339585,
            "fpr": 0.12280701754385964,
            "logloss": 0.5085268589828517,
            "mae": 0.31371914619363417,
            "precision": 0.7690721649484537,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8621447679840458,
            "auditor_fn_violation": 0.010358035359787002,
            "auditor_fp_violation": 0.009834449696453777,
            "ave_precision_score": 0.8623399564172768,
            "fpr": 0.11855104281009879,
            "logloss": 0.47263720687170924,
            "mae": 0.30149327229573486,
            "precision": 0.7782340862422998,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8707184487757722,
            "auditor_fn_violation": 0.027197060316079467,
            "auditor_fp_violation": 0.01709808985079522,
            "ave_precision_score": 0.8709157611754531,
            "fpr": 0.08991228070175439,
            "logloss": 0.4975262658799573,
            "mae": 0.30569461612270843,
            "precision": 0.8140589569160998,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.84525995424157,
            "auditor_fn_violation": 0.020370413620758112,
            "auditor_fp_violation": 0.016002449278284314,
            "ave_precision_score": 0.8454934198212721,
            "fpr": 0.10976948408342481,
            "logloss": 0.5165827196765085,
            "mae": 0.31568772690081875,
            "precision": 0.7787610619469026,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.839664533824301,
            "auditor_fn_violation": 0.02801489778164419,
            "auditor_fp_violation": 0.027145843580914906,
            "ave_precision_score": 0.8401142493952762,
            "fpr": 0.12171052631578948,
            "logloss": 0.8979205218596712,
            "mae": 0.26021694924046457,
            "precision": 0.7730061349693251,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.842540685417744,
            "auditor_fn_violation": 0.026816451409486887,
            "auditor_fp_violation": 0.02557554306025375,
            "ave_precision_score": 0.8427776174555601,
            "fpr": 0.1350164654226125,
            "logloss": 0.8863276760065968,
            "mae": 0.2670374443596193,
            "precision": 0.7458677685950413,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8256441254319307,
            "auditor_fn_violation": 0.009152530085544444,
            "auditor_fp_violation": 0.02093324725364814,
            "ave_precision_score": 0.8260954244735866,
            "fpr": 0.12390350877192982,
            "logloss": 0.868399537315218,
            "mae": 0.27270833328045013,
            "precision": 0.7650727650727651,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8237057810499553,
            "auditor_fn_violation": 0.01839923394913236,
            "auditor_fp_violation": 0.017719931002038582,
            "ave_precision_score": 0.8239668400312933,
            "fpr": 0.13830954994511527,
            "logloss": 0.8461190770212742,
            "mae": 0.2804165183558965,
            "precision": 0.7330508474576272,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6739321428405198,
            "auditor_fn_violation": 0.019147817891837036,
            "auditor_fp_violation": 0.01142092966060011,
            "ave_precision_score": 0.6753459042020129,
            "fpr": 0.19956140350877194,
            "logloss": 0.8606990392695659,
            "mae": 0.3458809442159499,
            "precision": 0.6829268292682927,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7168096220042666,
            "auditor_fn_violation": 0.008064553798724805,
            "auditor_fp_violation": 0.011474769197836476,
            "ave_precision_score": 0.71793003809332,
            "fpr": 0.1668496158068057,
            "logloss": 0.7378610988462426,
            "mae": 0.31619622353011995,
            "precision": 0.7158878504672898,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8394549530331553,
            "auditor_fn_violation": 0.008805911990720608,
            "auditor_fp_violation": 0.020172364322020006,
            "ave_precision_score": 0.83974640414061,
            "fpr": 0.125,
            "logloss": 0.7328586220800846,
            "mae": 0.2691811367443398,
            "precision": 0.7668711656441718,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8417135493000554,
            "auditor_fn_violation": 0.011894808136954952,
            "auditor_fp_violation": 0.01989540785212732,
            "ave_precision_score": 0.841932752438801,
            "fpr": 0.132821075740944,
            "logloss": 0.6992873510299331,
            "mae": 0.2749436716696247,
            "precision": 0.7479166666666667,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6888083293486665,
            "auditor_fn_violation": 0.02855861244019139,
            "auditor_fp_violation": 0.031091162485653384,
            "ave_precision_score": 0.6852567983009747,
            "fpr": 0.1600877192982456,
            "logloss": 2.12661767419895,
            "mae": 0.29735900889714983,
            "precision": 0.7176015473887815,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7223163309341447,
            "auditor_fn_violation": 0.023308498960693185,
            "auditor_fp_violation": 0.017451107775711832,
            "ave_precision_score": 0.7158611900102465,
            "fpr": 0.15806805708013172,
            "logloss": 1.6498834712993702,
            "mae": 0.29446174962381194,
            "precision": 0.7114228456913828,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.835822255701972,
            "auditor_fn_violation": 0.02715401623894447,
            "auditor_fp_violation": 0.031406275618953934,
            "ave_precision_score": 0.8362935362776488,
            "fpr": 0.11951754385964912,
            "logloss": 0.8178168830305667,
            "mae": 0.2643173832793256,
            "precision": 0.7738589211618258,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8229026715873671,
            "auditor_fn_violation": 0.02343928813321812,
            "auditor_fp_violation": 0.02502047287996794,
            "ave_precision_score": 0.8232056997153567,
            "fpr": 0.14050493962678376,
            "logloss": 0.8279322980336478,
            "mae": 0.281749575090355,
            "precision": 0.7316561844863732,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6870581386095627,
            "auditor_fn_violation": 0.01708170218935769,
            "auditor_fp_violation": 0.023367047876701103,
            "ave_precision_score": 0.6874511377558851,
            "fpr": 0.15460526315789475,
            "logloss": 1.2613239101429365,
            "mae": 0.30378317805730126,
            "precision": 0.7218934911242604,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7308541394906785,
            "auditor_fn_violation": 0.015040754840367142,
            "auditor_fp_violation": 0.017197219173069888,
            "ave_precision_score": 0.7319947075098394,
            "fpr": 0.16136114160263446,
            "logloss": 0.9586657009553121,
            "mae": 0.29576373717044235,
            "precision": 0.712890625,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8216726370068492,
            "auditor_fn_violation": 0.019211251268667538,
            "auditor_fp_violation": 0.031454951631414985,
            "ave_precision_score": 0.8222961307618948,
            "fpr": 0.13925438596491227,
            "logloss": 0.8693059133686195,
            "mae": 0.26613399032295765,
            "precision": 0.7529182879377432,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8223075788801787,
            "auditor_fn_violation": 0.017481374220519888,
            "auditor_fp_violation": 0.025344056393139035,
            "ave_precision_score": 0.8226217618420711,
            "fpr": 0.14489571899012074,
            "logloss": 0.8567913096061688,
            "mae": 0.27693940660414784,
            "precision": 0.7344064386317908,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8417001687645518,
            "auditor_fn_violation": 0.011073655212411198,
            "auditor_fp_violation": 0.020559210526315787,
            "ave_precision_score": 0.8422806043279442,
            "fpr": 0.11732456140350878,
            "logloss": 0.693975028184604,
            "mae": 0.2665505727357475,
            "precision": 0.7766179540709812,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8422495413526172,
            "auditor_fn_violation": 0.013672139570731249,
            "auditor_fp_violation": 0.01135778131230539,
            "ave_precision_score": 0.8424623882969595,
            "fpr": 0.13172338090010977,
            "logloss": 0.6817542218711946,
            "mae": 0.2748406645682104,
            "precision": 0.7468354430379747,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8485016980874052,
            "auditor_fn_violation": 0.026666938523995945,
            "auditor_fp_violation": 0.0174644408919495,
            "ave_precision_score": 0.8487859734677119,
            "fpr": 0.10635964912280702,
            "logloss": 0.6982037329522448,
            "mae": 0.2685983135492684,
            "precision": 0.7918454935622318,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8460867007644255,
            "auditor_fn_violation": 0.030434173342364017,
            "auditor_fp_violation": 0.02851766392616323,
            "ave_precision_score": 0.8463556984654301,
            "fpr": 0.12733260153677278,
            "logloss": 0.6825990265922842,
            "mae": 0.27287236985071567,
            "precision": 0.7557894736842106,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8717537451199298,
            "auditor_fn_violation": 0.026721309989850662,
            "auditor_fp_violation": 0.016862395474667977,
            "ave_precision_score": 0.872042506987459,
            "fpr": 0.07236842105263158,
            "logloss": 0.48197521622904793,
            "mae": 0.2942372611427696,
            "precision": 0.8401937046004843,
            "recall": 0.7169421487603306
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.856536935871427,
            "auditor_fn_violation": 0.02382231356704113,
            "auditor_fp_violation": 0.020550042190311913,
            "ave_precision_score": 0.8567353593357816,
            "fpr": 0.09659714599341383,
            "logloss": 0.5016976188365733,
            "mae": 0.30410084663864745,
            "precision": 0.794392523364486,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8352267623744192,
            "auditor_fn_violation": 0.020588661736987094,
            "auditor_fp_violation": 0.026495122151172328,
            "ave_precision_score": 0.835583693681649,
            "fpr": 0.13706140350877194,
            "logloss": 0.8074250967527201,
            "mae": 0.2689261071681724,
            "precision": 0.7479838709677419,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8359770729276057,
            "auditor_fn_violation": 0.020907583436485508,
            "auditor_fp_violation": 0.01910885100472682,
            "ave_precision_score": 0.8362155609370296,
            "fpr": 0.14270032930845225,
            "logloss": 0.7763456655678193,
            "mae": 0.27138520482887035,
            "precision": 0.7379032258064516,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7931238578971632,
            "auditor_fn_violation": 0.04530955487893287,
            "auditor_fp_violation": 0.042804148221019835,
            "ave_precision_score": 0.7935645935447913,
            "fpr": 0.14802631578947367,
            "logloss": 0.6602199457096446,
            "mae": 0.33619503817380486,
            "precision": 0.7294589178356713,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8077606266234987,
            "auditor_fn_violation": 0.041819837914846905,
            "auditor_fp_violation": 0.03571615254224632,
            "ave_precision_score": 0.8082611692336419,
            "fpr": 0.14050493962678376,
            "logloss": 0.5965030940815482,
            "mae": 0.3127831941601671,
            "precision": 0.744,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8266837117304929,
            "auditor_fn_violation": 0.010330578512396693,
            "auditor_fp_violation": 0.02078209542547959,
            "ave_precision_score": 0.8271677658052606,
            "fpr": 0.12828947368421054,
            "logloss": 0.7954970559280792,
            "mae": 0.27133571931621225,
            "precision": 0.7607361963190185,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8198095408161319,
            "auditor_fn_violation": 0.01870285167106524,
            "auditor_fp_violation": 0.014837548630868377,
            "ave_precision_score": 0.8200882481103525,
            "fpr": 0.13611416026344675,
            "logloss": 0.788622695202304,
            "mae": 0.282436891864721,
            "precision": 0.7394957983193278,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8227321187681772,
            "auditor_fn_violation": 0.034625561838480506,
            "auditor_fp_violation": 0.0056310460731267414,
            "ave_precision_score": 0.8231282202171969,
            "fpr": 0.049342105263157895,
            "logloss": 1.248663475990875,
            "mae": 0.3272316580293463,
            "precision": 0.8562300319488818,
            "recall": 0.5537190082644629
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8093733441296438,
            "auditor_fn_violation": 0.025816848448046336,
            "auditor_fp_violation": 0.01051397507411307,
            "ave_precision_score": 0.8097085045885293,
            "fpr": 0.0570801317233809,
            "logloss": 1.122987649155037,
            "mae": 0.3321040023438135,
            "precision": 0.8338658146964856,
            "recall": 0.5553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8094442652685925,
            "auditor_fn_violation": 0.050669675221110634,
            "auditor_fp_violation": 0.02950278734218725,
            "ave_precision_score": 0.809897856339539,
            "fpr": 0.08552631578947369,
            "logloss": 0.6456512502988395,
            "mae": 0.3546805197111497,
            "precision": 0.7925531914893617,
            "recall": 0.6157024793388429
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8170604531775715,
            "auditor_fn_violation": 0.03791951794847841,
            "auditor_fp_violation": 0.02670310714845763,
            "ave_precision_score": 0.8173270303520607,
            "fpr": 0.09659714599341383,
            "logloss": 0.5865059204023588,
            "mae": 0.34411881854872517,
            "precision": 0.772020725388601,
            "recall": 0.6340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8244168423320011,
            "auditor_fn_violation": 0.02834565753226041,
            "auditor_fp_violation": 0.02614158058698148,
            "ave_precision_score": 0.825041256509915,
            "fpr": 0.11951754385964912,
            "logloss": 0.9489732809630944,
            "mae": 0.2740173551153802,
            "precision": 0.7695560253699789,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8341766448146035,
            "auditor_fn_violation": 0.029826937898498267,
            "auditor_fp_violation": 0.022411891943019433,
            "ave_precision_score": 0.8344056371217135,
            "fpr": 0.12952799121844127,
            "logloss": 0.8697298614400356,
            "mae": 0.2765173191766071,
            "precision": 0.7484008528784648,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 2917,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8414515385330802,
            "auditor_fn_violation": 0.01111896476729013,
            "auditor_fp_violation": 0.021609587637317598,
            "ave_precision_score": 0.8417459167426228,
            "fpr": 0.13486842105263158,
            "logloss": 0.7242637877062877,
            "mae": 0.2685157103455944,
            "precision": 0.7549800796812749,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.844381816292784,
            "auditor_fn_violation": 0.015554569446715093,
            "auditor_fp_violation": 0.018503998745491617,
            "ave_precision_score": 0.8445959549269875,
            "fpr": 0.13830954994511527,
            "logloss": 0.6903652793989964,
            "mae": 0.27260669759572215,
            "precision": 0.7454545454545455,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8264170420822274,
            "auditor_fn_violation": 0.01654931491953023,
            "auditor_fp_violation": 0.019675356615838663,
            "ave_precision_score": 0.8268893444181105,
            "fpr": 0.11293859649122807,
            "logloss": 0.8762142872843206,
            "mae": 0.27701953512800936,
            "precision": 0.7751091703056768,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8285960681150488,
            "auditor_fn_violation": 0.013863652287642768,
            "auditor_fp_violation": 0.014740473576917042,
            "ave_precision_score": 0.8288462855334768,
            "fpr": 0.11525795828759605,
            "logloss": 0.8476266910298864,
            "mae": 0.2802255817958132,
            "precision": 0.7624434389140271,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8249433633787985,
            "auditor_fn_violation": 0.027951464404813692,
            "auditor_fp_violation": 0.03134222823413675,
            "ave_precision_score": 0.8257548320895416,
            "fpr": 0.1337719298245614,
            "logloss": 0.8649118003031099,
            "mae": 0.27021084902360143,
            "precision": 0.7520325203252033,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8173581567920102,
            "auditor_fn_violation": 0.029177663077749497,
            "auditor_fp_violation": 0.029637760702524697,
            "ave_precision_score": 0.8177084594735929,
            "fpr": 0.13830954994511527,
            "logloss": 0.884202411792275,
            "mae": 0.2799708324718596,
            "precision": 0.7347368421052631,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 2917,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8386510825940229,
            "auditor_fn_violation": 0.02143595041322314,
            "auditor_fp_violation": 0.02867785702574193,
            "ave_precision_score": 0.8390231608939165,
            "fpr": 0.1337719298245614,
            "logloss": 0.7693472017934376,
            "mae": 0.2672358161621393,
            "precision": 0.756,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8340892187444446,
            "auditor_fn_violation": 0.02052922904453839,
            "auditor_fp_violation": 0.024657063703637332,
            "ave_precision_score": 0.8343670947395296,
            "fpr": 0.1350164654226125,
            "logloss": 0.7669707954543058,
            "mae": 0.26745801112658346,
            "precision": 0.7453416149068323,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.845092434217095,
            "auditor_fn_violation": 0.013823945193562424,
            "auditor_fp_violation": 0.021673635022134784,
            "ave_precision_score": 0.8455329038790671,
            "fpr": 0.12280701754385964,
            "logloss": 0.69213751972049,
            "mae": 0.26521409034521143,
            "precision": 0.7676348547717843,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.843032240060156,
            "auditor_fn_violation": 0.015412102669500431,
            "auditor_fp_violation": 0.02094580971795964,
            "ave_precision_score": 0.8432512141437274,
            "fpr": 0.13172338090010977,
            "logloss": 0.6922440772560736,
            "mae": 0.27531095496281743,
            "precision": 0.7484276729559748,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8294008989986033,
            "auditor_fn_violation": 0.022382920110192838,
            "auditor_fp_violation": 0.025503668634202333,
            "ave_precision_score": 0.8298858445878339,
            "fpr": 0.11293859649122807,
            "logloss": 0.8457827546807213,
            "mae": 0.27288850546339516,
            "precision": 0.774617067833698,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8179540495542332,
            "auditor_fn_violation": 0.025326389051077848,
            "auditor_fp_violation": 0.021326642621922538,
            "ave_precision_score": 0.8182779939121976,
            "fpr": 0.1251372118551043,
            "logloss": 0.859245339604498,
            "mae": 0.2782983554099846,
            "precision": 0.75,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8344641212209896,
            "auditor_fn_violation": 0.006696752211106279,
            "auditor_fp_violation": 0.02346439990162322,
            "ave_precision_score": 0.834888401705125,
            "fpr": 0.12828947368421054,
            "logloss": 0.7549813802270509,
            "mae": 0.2691644739329622,
            "precision": 0.7587628865979381,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8345367463665991,
            "auditor_fn_violation": 0.015155195366326462,
            "auditor_fp_violation": 0.018267533870481963,
            "ave_precision_score": 0.8347773742178752,
            "fpr": 0.13721185510428102,
            "logloss": 0.7307869284834416,
            "mae": 0.2767693325459272,
            "precision": 0.7417355371900827,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8423098619576848,
            "auditor_fn_violation": 0.0073401478903871295,
            "auditor_fp_violation": 0.018368789965568132,
            "ave_precision_score": 0.8430658448152195,
            "fpr": 0.1162280701754386,
            "logloss": 0.7101430996988587,
            "mae": 0.26296811832146505,
            "precision": 0.7800829875518672,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8420305304777159,
            "auditor_fn_violation": 0.012203096900763717,
            "auditor_fp_violation": 0.011870536725484191,
            "ave_precision_score": 0.8422458182943215,
            "fpr": 0.132821075740944,
            "logloss": 0.7013062476175582,
            "mae": 0.2741907626359079,
            "precision": 0.7468619246861925,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8273514159115646,
            "auditor_fn_violation": 0.03508771929824562,
            "auditor_fp_violation": 0.02044392523364486,
            "ave_precision_score": 0.8276408799829739,
            "fpr": 0.09210526315789473,
            "logloss": 1.7809291982544198,
            "mae": 0.2796792908231433,
            "precision": 0.8023529411764706,
            "recall": 0.7045454545454546
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8224507530385936,
            "auditor_fn_violation": 0.032685615526543206,
            "auditor_fp_violation": 0.02833844844194539,
            "ave_precision_score": 0.8224293018904927,
            "fpr": 0.10867178924259056,
            "logloss": 1.6759618211722367,
            "mae": 0.2865983341687822,
            "precision": 0.7631578947368421,
            "recall": 0.6787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7037053968241691,
            "auditor_fn_violation": 0.023914383065100773,
            "auditor_fp_violation": 0.00725016396130514,
            "ave_precision_score": 0.7050952445626432,
            "fpr": 0.17434210526315788,
            "logloss": 0.7449143843183562,
            "mae": 0.3467766604332147,
            "precision": 0.702803738317757,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.735938340658657,
            "auditor_fn_violation": 0.012441320036434127,
            "auditor_fp_violation": 0.004368377427809776,
            "ave_precision_score": 0.7369294610854465,
            "fpr": 0.15806805708013172,
            "logloss": 0.6614897823021,
            "mae": 0.3234912267373415,
            "precision": 0.7181996086105675,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8289990022855886,
            "auditor_fn_violation": 0.013697078439901401,
            "auditor_fp_violation": 0.019437100344318742,
            "ave_precision_score": 0.8297961013303597,
            "fpr": 0.11513157894736842,
            "logloss": 0.7693069565113942,
            "mae": 0.27259142477025916,
            "precision": 0.7717391304347826,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8312034448948414,
            "auditor_fn_violation": 0.01734824952705701,
            "auditor_fp_violation": 0.016348434726982632,
            "ave_precision_score": 0.8314501462173072,
            "fpr": 0.12623490669593854,
            "logloss": 0.7626335973894081,
            "mae": 0.2784273515925945,
            "precision": 0.7505422993492408,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8341632108288504,
            "auditor_fn_violation": 0.011130292156009861,
            "auditor_fp_violation": 0.02746351860960814,
            "ave_precision_score": 0.8345828271150186,
            "fpr": 0.13157894736842105,
            "logloss": 0.6846349590092462,
            "mae": 0.2783460515543228,
            "precision": 0.7565922920892495,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8333402624962685,
            "auditor_fn_violation": 0.011911156783520567,
            "auditor_fp_violation": 0.013612909488713168,
            "ave_precision_score": 0.8336011256757735,
            "fpr": 0.1350164654226125,
            "logloss": 0.6664474515821801,
            "mae": 0.2788912610998461,
            "precision": 0.7494908350305499,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8260954816152271,
            "auditor_fn_violation": 0.0264607800492968,
            "auditor_fp_violation": 0.03252070011477292,
            "ave_precision_score": 0.8265562645522728,
            "fpr": 0.13706140350877194,
            "logloss": 0.8655432133404266,
            "mae": 0.2720562542920703,
            "precision": 0.7484909456740443,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.817005858846509,
            "auditor_fn_violation": 0.025802835322418664,
            "auditor_fp_violation": 0.030705586295989313,
            "ave_precision_score": 0.81735913687633,
            "fpr": 0.1394072447859495,
            "logloss": 0.8818771723017758,
            "mae": 0.28154968728142105,
            "precision": 0.7326315789473684,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8308623134744084,
            "auditor_fn_violation": 0.017969769464984783,
            "auditor_fp_violation": 0.022688145597638966,
            "ave_precision_score": 0.8314175585039385,
            "fpr": 0.13815789473684212,
            "logloss": 0.8950448307916504,
            "mae": 0.26077838407932985,
            "precision": 0.7553398058252427,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8160732495853875,
            "auditor_fn_violation": 0.01785038652871523,
            "auditor_fp_violation": 0.02171494283772785,
            "ave_precision_score": 0.8173912692911838,
            "fpr": 0.14709110867178923,
            "logloss": 0.9374767594182702,
            "mae": 0.2759201307655153,
            "precision": 0.7335984095427436,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8490735807155237,
            "auditor_fn_violation": 0.05170273307235031,
            "auditor_fp_violation": 0.037495900967371695,
            "ave_precision_score": 0.8493670925640868,
            "fpr": 0.11403508771929824,
            "logloss": 0.5845486220949839,
            "mae": 0.3062435454182214,
            "precision": 0.7724288840262582,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8464156479033178,
            "auditor_fn_violation": 0.04535114557302007,
            "auditor_fp_violation": 0.034665750676413996,
            "ave_precision_score": 0.846678826409408,
            "fpr": 0.11964873765093303,
            "logloss": 0.5710292168387406,
            "mae": 0.30374641582414696,
            "precision": 0.7714884696016772,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8475498924854334,
            "auditor_fn_violation": 0.03053863998840076,
            "auditor_fp_violation": 0.015176668306279714,
            "ave_precision_score": 0.8480815712788088,
            "fpr": 0.10416666666666667,
            "logloss": 0.6581949055610279,
            "mae": 0.26285108194351336,
            "precision": 0.7930283224400871,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8374023071399852,
            "auditor_fn_violation": 0.022318238083004423,
            "auditor_fp_violation": 0.020176676598191418,
            "ave_precision_score": 0.8377449309825594,
            "fpr": 0.11525795828759605,
            "logloss": 0.6793000570735774,
            "mae": 0.2734761760902602,
            "precision": 0.7702407002188184,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8545710685764363,
            "auditor_fn_violation": 0.024127337973031755,
            "auditor_fp_violation": 0.029802529103131657,
            "ave_precision_score": 0.8549492085124724,
            "fpr": 0.12390350877192982,
            "logloss": 0.6325131677688681,
            "mae": 0.25174262558191896,
            "precision": 0.7784313725490196,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.852150765487273,
            "auditor_fn_violation": 0.02143541116846113,
            "auditor_fp_violation": 0.024793964420748184,
            "ave_precision_score": 0.8524055538663956,
            "fpr": 0.14270032930845225,
            "logloss": 0.6434330798760337,
            "mae": 0.2662065859625163,
            "precision": 0.7440944881889764,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8306760778101979,
            "auditor_fn_violation": 0.023583623314484565,
            "auditor_fp_violation": 0.029238912116740446,
            "ave_precision_score": 0.8311223998319226,
            "fpr": 0.13048245614035087,
            "logloss": 0.8452389069780973,
            "mae": 0.26979486876794595,
            "precision": 0.7561475409836066,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8300488579758482,
            "auditor_fn_violation": 0.024125931288974004,
            "auditor_fp_violation": 0.026434283922130875,
            "ave_precision_score": 0.8303085492177105,
            "fpr": 0.13611416026344675,
            "logloss": 0.8314065038648553,
            "mae": 0.2742679347486591,
            "precision": 0.7416666666666667,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8134438734031273,
            "auditor_fn_violation": 0.04382566695664782,
            "auditor_fp_violation": 0.03555910805050008,
            "ave_precision_score": 0.8139475639618248,
            "fpr": 0.13486842105263158,
            "logloss": 0.6399032203174366,
            "mae": 0.3199782117991475,
            "precision": 0.7448132780082988,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8373314494089156,
            "auditor_fn_violation": 0.040051848564822384,
            "auditor_fp_violation": 0.031101353823637032,
            "ave_precision_score": 0.8376098502314278,
            "fpr": 0.132821075740944,
            "logloss": 0.5741491075610512,
            "mae": 0.29718230771533466,
            "precision": 0.7550607287449392,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8390227459569755,
            "auditor_fn_violation": 0.027811004784688995,
            "auditor_fp_violation": 0.028137297097884897,
            "ave_precision_score": 0.839483123431727,
            "fpr": 0.11951754385964912,
            "logloss": 0.9535244871399277,
            "mae": 0.26062884879412623,
            "precision": 0.7743271221532091,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8422283094149041,
            "auditor_fn_violation": 0.026998622042646615,
            "auditor_fp_violation": 0.025291785210242168,
            "ave_precision_score": 0.8424595617898707,
            "fpr": 0.12843029637760703,
            "logloss": 0.9115295885053016,
            "mae": 0.26824568281795924,
            "precision": 0.7505330490405118,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.801177571178753,
            "auditor_fn_violation": 0.03507865738726983,
            "auditor_fp_violation": 0.028529267092966066,
            "ave_precision_score": 0.8015060432776707,
            "fpr": 0.12171052631578948,
            "logloss": 1.9964347407902114,
            "mae": 0.2898928869486006,
            "precision": 0.753880266075388,
            "recall": 0.7024793388429752
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.80127753801798,
            "auditor_fn_violation": 0.029133288179928534,
            "auditor_fp_violation": 0.02486365933127734,
            "ave_precision_score": 0.801305257909709,
            "fpr": 0.1207464324917673,
            "logloss": 1.8774765876655444,
            "mae": 0.2940160330023631,
            "precision": 0.7465437788018433,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8241829636359456,
            "auditor_fn_violation": 0.012054607075540097,
            "auditor_fp_violation": 0.023774389244138387,
            "ave_precision_score": 0.8247735322980314,
            "fpr": 0.13596491228070176,
            "logloss": 0.8897159941310546,
            "mae": 0.27325176343102786,
            "precision": 0.7484787018255578,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8226289772322801,
            "auditor_fn_violation": 0.015535885279211528,
            "auditor_fp_violation": 0.012831330849207593,
            "ave_precision_score": 0.8228913276577574,
            "fpr": 0.13721185510428102,
            "logloss": 0.8668995761505023,
            "mae": 0.27919562674114656,
            "precision": 0.7357293868921776,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8341686729833451,
            "auditor_fn_violation": 0.009385874293170943,
            "auditor_fp_violation": 0.019972536481390406,
            "ave_precision_score": 0.8345041365762564,
            "fpr": 0.14473684210526316,
            "logloss": 0.7771824397904912,
            "mae": 0.2708428043193397,
            "precision": 0.7436893203883496,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8330959877953635,
            "auditor_fn_violation": 0.008816591540743166,
            "auditor_fp_violation": 0.012350933787345902,
            "ave_precision_score": 0.8333493644410096,
            "fpr": 0.14270032930845225,
            "logloss": 0.7525421902402103,
            "mae": 0.2749764102238635,
            "precision": 0.7405189620758483,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8400041929245561,
            "auditor_fn_violation": 0.01196625344352617,
            "auditor_fp_violation": 0.0195472618462043,
            "ave_precision_score": 0.840311168532443,
            "fpr": 0.12938596491228072,
            "logloss": 0.7347132524908236,
            "mae": 0.2682873116971966,
            "precision": 0.7625754527162978,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8428258613146208,
            "auditor_fn_violation": 0.015005722026297972,
            "auditor_fp_violation": 0.01412815400583944,
            "ave_precision_score": 0.8430421347946477,
            "fpr": 0.13721185510428102,
            "logloss": 0.7029831082456677,
            "mae": 0.27233593757455615,
            "precision": 0.7448979591836735,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8089592046870719,
            "auditor_fn_violation": 0.030955487893286948,
            "auditor_fp_violation": 0.024581386292834895,
            "ave_precision_score": 0.7986374465618848,
            "fpr": 0.10855263157894737,
            "logloss": 1.2940808720489616,
            "mae": 0.2699571666358647,
            "precision": 0.7755102040816326,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7936803884270557,
            "auditor_fn_violation": 0.033876731204895254,
            "auditor_fp_violation": 0.02709638557215788,
            "ave_precision_score": 0.782326970615373,
            "fpr": 0.1141602634467618,
            "logloss": 1.3547922427600718,
            "mae": 0.27879635889103227,
            "precision": 0.7575757575757576,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8134307965207385,
            "auditor_fn_violation": 0.028128171668841535,
            "auditor_fp_violation": 0.019616433021806857,
            "ave_precision_score": 0.8142705489698441,
            "fpr": 0.10197368421052631,
            "logloss": 1.2345654373888852,
            "mae": 0.2852453517403062,
            "precision": 0.7832167832167832,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8235301293823959,
            "auditor_fn_violation": 0.030048812387603055,
            "auditor_fp_violation": 0.017304250642811093,
            "ave_precision_score": 0.8237607414097876,
            "fpr": 0.1163556531284303,
            "logloss": 1.1494159589771356,
            "mae": 0.2886939104524507,
            "precision": 0.7517564402810304,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8164690466771651,
            "auditor_fn_violation": 0.010403073800202986,
            "auditor_fp_violation": 0.022893097229053944,
            "ave_precision_score": 0.8168663122999363,
            "fpr": 0.12719298245614036,
            "logloss": 0.8562248138285387,
            "mae": 0.28178913581488596,
            "precision": 0.7542372881355932,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8149917362863596,
            "auditor_fn_violation": 0.01825443165097975,
            "auditor_fp_violation": 0.01492466726902983,
            "ave_precision_score": 0.8152878181538095,
            "fpr": 0.12403951701427003,
            "logloss": 0.8566061045267672,
            "mae": 0.28406404649149697,
            "precision": 0.7527352297592997,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8261674889921953,
            "auditor_fn_violation": 0.022942493112947663,
            "auditor_fp_violation": 0.025670191834727008,
            "ave_precision_score": 0.8265249266237005,
            "fpr": 0.13706140350877194,
            "logloss": 0.8451961813367567,
            "mae": 0.2674422819434508,
            "precision": 0.755859375,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.835185220895031,
            "auditor_fn_violation": 0.03020529229044538,
            "auditor_fp_violation": 0.02310386284041608,
            "ave_precision_score": 0.8354544413014267,
            "fpr": 0.14709110867178923,
            "logloss": 0.7884926685984427,
            "mae": 0.26942059274103186,
            "precision": 0.7292929292929293,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8398613107206132,
            "auditor_fn_violation": 0.010221835580687257,
            "auditor_fp_violation": 0.019759899163797348,
            "ave_precision_score": 0.8401666994000395,
            "fpr": 0.12609649122807018,
            "logloss": 0.7374105084986415,
            "mae": 0.26906519025723175,
            "precision": 0.7667342799188641,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8429857621922097,
            "auditor_fn_violation": 0.015337365999486183,
            "auditor_fp_violation": 0.016054720461181178,
            "ave_precision_score": 0.8432023157040178,
            "fpr": 0.13391877058177826,
            "logloss": 0.702425030316749,
            "mae": 0.272997775926919,
            "precision": 0.7484536082474227,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8335530575401799,
            "auditor_fn_violation": 0.010253552269102512,
            "auditor_fp_violation": 0.021069027709460567,
            "ave_precision_score": 0.833895050244843,
            "fpr": 0.12280701754385964,
            "logloss": 0.7389412815934975,
            "mae": 0.27136677859767244,
            "precision": 0.7676348547717843,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8352162544899042,
            "auditor_fn_violation": 0.008886657168881523,
            "auditor_fp_violation": 0.012029839378122274,
            "ave_precision_score": 0.8354551637323795,
            "fpr": 0.12843029637760703,
            "logloss": 0.7076686525803528,
            "mae": 0.2750843937683308,
            "precision": 0.7552301255230126,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8227752601205793,
            "auditor_fn_violation": 0.006452080614760043,
            "auditor_fp_violation": 0.02494773733398918,
            "ave_precision_score": 0.8230990737084878,
            "fpr": 0.13925438596491227,
            "logloss": 0.746645576169031,
            "mae": 0.28323035436924987,
            "precision": 0.7485148514851485,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8288475297201658,
            "auditor_fn_violation": 0.014515262629329477,
            "auditor_fp_violation": 0.0159949819664419,
            "ave_precision_score": 0.8291004913585209,
            "fpr": 0.13830954994511527,
            "logloss": 0.6992552625253343,
            "mae": 0.2813288895352731,
            "precision": 0.7433808553971487,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8109631328465086,
            "auditor_fn_violation": 0.015450558213716109,
            "auditor_fp_violation": 0.02004426955238564,
            "ave_precision_score": 0.8119556269748242,
            "fpr": 0.12938596491228072,
            "logloss": 0.7355553166916894,
            "mae": 0.2819685430632445,
            "precision": 0.7551867219917012,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8190048319881313,
            "auditor_fn_violation": 0.016402363547189203,
            "auditor_fp_violation": 0.019041645198145128,
            "ave_precision_score": 0.8202858620254606,
            "fpr": 0.15148188803512624,
            "logloss": 0.7060003266191313,
            "mae": 0.2925801216651866,
            "precision": 0.7189409368635438,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8368006138305997,
            "auditor_fn_violation": 0.013964404813687117,
            "auditor_fp_violation": 0.025408878504672903,
            "ave_precision_score": 0.8371221976974312,
            "fpr": 0.12938596491228072,
            "logloss": 0.7353417477138727,
            "mae": 0.2705226662867597,
            "precision": 0.7591836734693878,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.826093222085315,
            "auditor_fn_violation": 0.017271177336104823,
            "auditor_fp_violation": 0.018613519319180292,
            "ave_precision_score": 0.8263749345567742,
            "fpr": 0.13611416026344675,
            "logloss": 0.7350504359498466,
            "mae": 0.2815959792197798,
            "precision": 0.7411273486430062,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8276564743778986,
            "auditor_fn_violation": 0.026216108452950564,
            "auditor_fp_violation": 0.03164709378586654,
            "ave_precision_score": 0.8280387954148811,
            "fpr": 0.13925438596491227,
            "logloss": 0.8699531492812684,
            "mae": 0.27009261320576017,
            "precision": 0.75049115913556,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8317510134025874,
            "auditor_fn_violation": 0.026881845995749356,
            "auditor_fp_violation": 0.025889170157634957,
            "ave_precision_score": 0.8320315995872969,
            "fpr": 0.14489571899012074,
            "logloss": 0.8317797406998805,
            "mae": 0.2714970305499875,
            "precision": 0.7317073170731707,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8369658390386688,
            "auditor_fn_violation": 0.019854646947948387,
            "auditor_fp_violation": 0.026753873585833747,
            "ave_precision_score": 0.837763163446132,
            "fpr": 0.12828947368421054,
            "logloss": 0.7977537848354309,
            "mae": 0.2633562728438076,
            "precision": 0.766,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8255980722089067,
            "auditor_fn_violation": 0.01707265805637948,
            "auditor_fp_violation": 0.027091407364262948,
            "ave_precision_score": 0.8258943320043862,
            "fpr": 0.141602634467618,
            "logloss": 0.8208937814817159,
            "mae": 0.2779630160789604,
            "precision": 0.7361963190184049,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8728199055259874,
            "auditor_fn_violation": 0.026238763230390025,
            "auditor_fp_violation": 0.015371372356123953,
            "ave_precision_score": 0.8730175540436469,
            "fpr": 0.09210526315789473,
            "logloss": 0.49448281561178875,
            "mae": 0.3047106149044754,
            "precision": 0.8116591928251121,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8463026023804875,
            "auditor_fn_violation": 0.018885022304224963,
            "auditor_fp_violation": 0.01601738390196913,
            "ave_precision_score": 0.8465360394628474,
            "fpr": 0.10428100987925357,
            "logloss": 0.5130610483834948,
            "mae": 0.3148755186881321,
            "precision": 0.7879464285714286,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.860537380759094,
            "auditor_fn_violation": 0.032770135566188206,
            "auditor_fp_violation": 0.03134479012952943,
            "ave_precision_score": 0.8608103561349874,
            "fpr": 0.12828947368421054,
            "logloss": 0.5949833557779352,
            "mae": 0.2617964588920832,
            "precision": 0.7650602409638554,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8542223508256204,
            "auditor_fn_violation": 0.02817338907443305,
            "auditor_fp_violation": 0.02819408041299213,
            "ave_precision_score": 0.8545270209009995,
            "fpr": 0.1394072447859495,
            "logloss": 0.6128858438400867,
            "mae": 0.26984496829715904,
            "precision": 0.7449799196787149,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8514671049151581,
            "auditor_fn_violation": 0.02682552196607221,
            "auditor_fp_violation": 0.025870019675356615,
            "ave_precision_score": 0.8517609382257202,
            "fpr": 0.11513157894736842,
            "logloss": 0.69883938223113,
            "mae": 0.2605219576715861,
            "precision": 0.776595744680851,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.848538446717112,
            "auditor_fn_violation": 0.018838311885466058,
            "auditor_fp_violation": 0.022708095312768357,
            "ave_precision_score": 0.8487789677995458,
            "fpr": 0.1251372118551043,
            "logloss": 0.697501838093293,
            "mae": 0.2691722883083477,
            "precision": 0.7584745762711864,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8186106096418946,
            "auditor_fn_violation": 0.012564339567928086,
            "auditor_fp_violation": 0.024102311854402363,
            "ave_precision_score": 0.8144925725594334,
            "fpr": 0.12171052631578948,
            "logloss": 2.9414579501716847,
            "mae": 0.27726512527246183,
            "precision": 0.7612903225806451,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8179114396820144,
            "auditor_fn_violation": 0.023401919798210997,
            "auditor_fp_violation": 0.021762235812729777,
            "ave_precision_score": 0.8134721007344659,
            "fpr": 0.12952799121844127,
            "logloss": 3.006899437554904,
            "mae": 0.2832970639254184,
            "precision": 0.7342342342342343,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8383911270494124,
            "auditor_fn_violation": 0.02712229955052922,
            "auditor_fp_violation": 0.029246597802918512,
            "ave_precision_score": 0.8387239303017111,
            "fpr": 0.13157894736842105,
            "logloss": 0.9460860606354107,
            "mae": 0.27049779473257735,
            "precision": 0.7540983606557377,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8297769235622083,
            "auditor_fn_violation": 0.027848751664058678,
            "auditor_fp_violation": 0.028156743853780086,
            "ave_precision_score": 0.8301166250699257,
            "fpr": 0.13062568605927552,
            "logloss": 0.8515612365322995,
            "mae": 0.2717173137895356,
            "precision": 0.7494736842105263,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7971154422926064,
            "auditor_fn_violation": 0.020398361606495576,
            "auditor_fp_violation": 0.02631578947368421,
            "ave_precision_score": 0.7985074993640047,
            "fpr": 0.11732456140350878,
            "logloss": 1.3447529356692185,
            "mae": 0.2899081505984707,
            "precision": 0.7584650112866818,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7953559424132088,
            "auditor_fn_violation": 0.028558750029194016,
            "auditor_fp_violation": 0.021261925919288313,
            "ave_precision_score": 0.7956786102848932,
            "fpr": 0.132821075740944,
            "logloss": 1.246814438912138,
            "mae": 0.30221343405306406,
            "precision": 0.7280898876404495,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7974451582877619,
            "auditor_fn_violation": 0.011882430767000149,
            "auditor_fp_violation": 0.02157115920642729,
            "ave_precision_score": 0.7977174742245057,
            "fpr": 0.1513157894736842,
            "logloss": 0.9044474420970255,
            "mae": 0.26929171928910733,
            "precision": 0.7430167597765364,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7930244674586435,
            "auditor_fn_violation": 0.01618983114183619,
            "auditor_fp_violation": 0.008241423170073014,
            "ave_precision_score": 0.7946442049384164,
            "fpr": 0.16575192096597147,
            "logloss": 0.8743324521943652,
            "mae": 0.2760972210466415,
            "precision": 0.7161654135338346,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8379244625629055,
            "auditor_fn_violation": 0.01889861534000291,
            "auditor_fp_violation": 0.025075832103623547,
            "ave_precision_score": 0.8384573092143781,
            "fpr": 0.10526315789473684,
            "logloss": 0.7765734574069334,
            "mae": 0.2678197590993069,
            "precision": 0.788546255506608,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8418874080907275,
            "auditor_fn_violation": 0.014984702337856462,
            "auditor_fp_violation": 0.012440541529454811,
            "ave_precision_score": 0.8421031532181638,
            "fpr": 0.11525795828759605,
            "logloss": 0.7566618764896997,
            "mae": 0.27422382386804645,
            "precision": 0.7661469933184856,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8419368014101098,
            "auditor_fn_violation": 0.015477743946643469,
            "auditor_fp_violation": 0.02157628299721266,
            "ave_precision_score": 0.8423899758046625,
            "fpr": 0.10855263157894737,
            "logloss": 0.8446174902587577,
            "mae": 0.2628539342989056,
            "precision": 0.7861771058315334,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8471214652267571,
            "auditor_fn_violation": 0.01727584837798071,
            "auditor_fp_violation": 0.01214184905575842,
            "ave_precision_score": 0.8473252107519251,
            "fpr": 0.11855104281009879,
            "logloss": 0.8182273329156307,
            "mae": 0.2681249155610016,
            "precision": 0.7636761487964989,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8397790228860544,
            "auditor_fn_violation": 0.0231531825431347,
            "auditor_fp_violation": 0.019188596491228078,
            "ave_precision_score": 0.8402331752642557,
            "fpr": 0.11732456140350878,
            "logloss": 0.8328086143559496,
            "mae": 0.2615391797007108,
            "precision": 0.7766179540709812,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8443857939303545,
            "auditor_fn_violation": 0.02302823644813976,
            "auditor_fp_violation": 0.021884201906155806,
            "ave_precision_score": 0.8446048756594591,
            "fpr": 0.12294182217343579,
            "logloss": 0.8150374498196681,
            "mae": 0.2657038412430848,
            "precision": 0.7606837606837606,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.842067797910401,
            "auditor_fn_violation": 0.024698238364506308,
            "auditor_fp_violation": 0.03008177570093459,
            "ave_precision_score": 0.8424455517401144,
            "fpr": 0.1337719298245614,
            "logloss": 0.7315154886220143,
            "mae": 0.26476477438130974,
            "precision": 0.7584158415841584,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8381985401509917,
            "auditor_fn_violation": 0.023411261881962773,
            "auditor_fp_violation": 0.023312947572003556,
            "ave_precision_score": 0.838468568744925,
            "fpr": 0.13611416026344675,
            "logloss": 0.7281258601316067,
            "mae": 0.2701248215494983,
            "precision": 0.7484787018255578,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8277890623929913,
            "auditor_fn_violation": 0.02144274684645498,
            "auditor_fp_violation": 0.032177406132152815,
            "ave_precision_score": 0.8282728842671683,
            "fpr": 0.15350877192982457,
            "logloss": 0.9342748021446443,
            "mae": 0.26645340560519243,
            "precision": 0.7383177570093458,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8231540664939824,
            "auditor_fn_violation": 0.023191722913795922,
            "auditor_fp_violation": 0.031024191601265474,
            "ave_precision_score": 0.823439197669605,
            "fpr": 0.16575192096597147,
            "logloss": 0.9371865013391731,
            "mae": 0.2769924272980154,
            "precision": 0.7156308851224106,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 2917,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8355165192149039,
            "auditor_fn_violation": 0.013735591561548507,
            "auditor_fp_violation": 0.020948618626004264,
            "ave_precision_score": 0.8361088713452036,
            "fpr": 0.11513157894736842,
            "logloss": 0.7133412074326562,
            "mae": 0.2711605618346554,
            "precision": 0.7746781115879828,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8417490796132475,
            "auditor_fn_violation": 0.016278580937478117,
            "auditor_fp_violation": 0.01367264798345244,
            "ave_precision_score": 0.8419650798413871,
            "fpr": 0.11964873765093303,
            "logloss": 0.6973842757491788,
            "mae": 0.27534703498421415,
            "precision": 0.7625272331154684,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8187158432201982,
            "auditor_fn_violation": 0.014607800492967964,
            "auditor_fp_violation": 0.030942572552877523,
            "ave_precision_score": 0.8192741480294877,
            "fpr": 0.12828947368421054,
            "logloss": 0.7781006513209415,
            "mae": 0.28259925578251305,
            "precision": 0.7567567567567568,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8266039014616978,
            "auditor_fn_violation": 0.024172641707732916,
            "auditor_fp_violation": 0.015994981966441908,
            "ave_precision_score": 0.8268512241581623,
            "fpr": 0.13830954994511527,
            "logloss": 0.7290799055828746,
            "mae": 0.28915294946032666,
            "precision": 0.7352941176470589,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8320409217855403,
            "auditor_fn_violation": 0.007498731332463389,
            "auditor_fp_violation": 0.024835013936710948,
            "ave_precision_score": 0.8323086279089091,
            "fpr": 0.13815789473684212,
            "logloss": 0.6990916746695708,
            "mae": 0.28203643839135956,
            "precision": 0.7504950495049505,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.830043559948173,
            "auditor_fn_violation": 0.018567391456664414,
            "auditor_fp_violation": 0.01531047838088767,
            "ave_precision_score": 0.8303022197363231,
            "fpr": 0.1394072447859495,
            "logloss": 0.6682578814963657,
            "mae": 0.28429626463180957,
            "precision": 0.7408163265306122,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.822014347379509,
            "auditor_fn_violation": 0.02726502464839786,
            "auditor_fp_violation": 0.0324643384161338,
            "ave_precision_score": 0.8224635537565617,
            "fpr": 0.14035087719298245,
            "logloss": 0.895998725257069,
            "mae": 0.272820144274106,
            "precision": 0.747534516765286,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8316912798335352,
            "auditor_fn_violation": 0.031842492467944974,
            "auditor_fp_violation": 0.025926506716847007,
            "ave_precision_score": 0.8319790218858639,
            "fpr": 0.13721185510428102,
            "logloss": 0.8354580049814283,
            "mae": 0.26935432012357496,
            "precision": 0.7412008281573499,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6875620986287816,
            "auditor_fn_violation": 0.03833188342757721,
            "auditor_fp_violation": 0.027156091162485657,
            "ave_precision_score": 0.6279759609971345,
            "fpr": 0.18859649122807018,
            "logloss": 4.460461778486358,
            "mae": 0.3495196536705447,
            "precision": 0.6917562724014337,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7327806664126687,
            "auditor_fn_violation": 0.033360581077609364,
            "auditor_fp_violation": 0.022745431871980408,
            "ave_precision_score": 0.6813597422519484,
            "fpr": 0.1712403951701427,
            "logloss": 3.3535223534727363,
            "mae": 0.317250170098366,
            "precision": 0.712707182320442,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8163512557781403,
            "auditor_fn_violation": 0.011737440191387566,
            "auditor_fp_violation": 0.02464543367765208,
            "ave_precision_score": 0.8122593717926412,
            "fpr": 0.12280701754385964,
            "logloss": 2.9627051205488124,
            "mae": 0.27750841525796743,
            "precision": 0.7611940298507462,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8169438204586636,
            "auditor_fn_violation": 0.023495340635728803,
            "auditor_fp_violation": 0.021951407712737493,
            "ave_precision_score": 0.8125051911000515,
            "fpr": 0.132821075740944,
            "logloss": 3.0233402341907367,
            "mae": 0.28325762960728956,
            "precision": 0.7317073170731707,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8245281080434428,
            "auditor_fn_violation": 0.01439937654052487,
            "auditor_fp_violation": 0.022216756845384496,
            "ave_precision_score": 0.8258540394051274,
            "fpr": 0.12719298245614036,
            "logloss": 0.8707102897220063,
            "mae": 0.2745702252327455,
            "precision": 0.7573221757322176,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8271537040143906,
            "auditor_fn_violation": 0.014774505453441392,
            "auditor_fp_violation": 0.014733006265074644,
            "ave_precision_score": 0.8274019630571054,
            "fpr": 0.13172338090010977,
            "logloss": 0.8484064586309095,
            "mae": 0.2795882765389329,
            "precision": 0.7435897435897436,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6933065777928458,
            "auditor_fn_violation": 0.02355190662606931,
            "auditor_fp_violation": 0.023051934743400556,
            "ave_precision_score": 0.6947515969515523,
            "fpr": 0.1787280701754386,
            "logloss": 0.7742033147049029,
            "mae": 0.3414959898644858,
            "precision": 0.6981481481481482,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7289180820007106,
            "auditor_fn_violation": 0.012553425041455495,
            "auditor_fp_violation": 0.0020211524053456065,
            "ave_precision_score": 0.7300073143274457,
            "fpr": 0.15916575192096596,
            "logloss": 0.6818489573481268,
            "mae": 0.3178648166410864,
            "precision": 0.7211538461538461,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8431166320719994,
            "auditor_fn_violation": 0.025953313034652745,
            "auditor_fp_violation": 0.03035333661255944,
            "ave_precision_score": 0.8434684272941894,
            "fpr": 0.13596491228070176,
            "logloss": 0.7425185973392701,
            "mae": 0.2639839618392744,
            "precision": 0.7559055118110236,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8393963528796756,
            "auditor_fn_violation": 0.022549454655860994,
            "auditor_fp_violation": 0.021700008214043033,
            "ave_precision_score": 0.8396658561737109,
            "fpr": 0.13721185510428102,
            "logloss": 0.7351673769851526,
            "mae": 0.2687427558402137,
            "precision": 0.7469635627530364,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6893109984229655,
            "auditor_fn_violation": 0.0007612005219660757,
            "auditor_fp_violation": 0.009981144449909827,
            "ave_precision_score": 0.687039890519951,
            "fpr": 0.17214912280701755,
            "logloss": 2.773199401746632,
            "mae": 0.4114325527477674,
            "precision": 0.6374133949191686,
            "recall": 0.5702479338842975
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7036213438058304,
            "auditor_fn_violation": 0.010154845038185775,
            "auditor_fp_violation": 0.015245761678253455,
            "ave_precision_score": 0.7006606655958043,
            "fpr": 0.17014270032930845,
            "logloss": 2.4023293320018664,
            "mae": 0.3891275085177316,
            "precision": 0.6327014218009479,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8409642466854069,
            "auditor_fn_violation": 0.006180223285486446,
            "auditor_fp_violation": 0.014044310542711928,
            "ave_precision_score": 0.841709831389484,
            "fpr": 0.08991228070175439,
            "logloss": 0.7630403113790325,
            "mae": 0.2758916567114004,
            "precision": 0.8009708737864077,
            "recall": 0.6818181818181818
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8372683124897917,
            "auditor_fn_violation": 0.015694700702991806,
            "auditor_fp_violation": 0.010033578012251371,
            "ave_precision_score": 0.837487251687504,
            "fpr": 0.10098792535675083,
            "logloss": 0.7684447261584458,
            "mae": 0.28468639857288053,
            "precision": 0.7777777777777778,
            "recall": 0.6851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8094908925927334,
            "auditor_fn_violation": 0.0036157024793388452,
            "auditor_fp_violation": 0.016081017379898345,
            "ave_precision_score": 0.8056942372017043,
            "fpr": 0.11293859649122807,
            "logloss": 0.9267541092248757,
            "mae": 0.27514773827524996,
            "precision": 0.7813163481953291,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8113996122594719,
            "auditor_fn_violation": 0.01538174089730715,
            "auditor_fp_violation": 0.009737374642502449,
            "ave_precision_score": 0.8087789377014103,
            "fpr": 0.11964873765093303,
            "logloss": 0.8332304832173227,
            "mae": 0.2822620374286236,
            "precision": 0.7604395604395604,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.836524997154441,
            "auditor_fn_violation": 0.02460308829926055,
            "auditor_fp_violation": 0.025977619281849485,
            "ave_precision_score": 0.8368990720240539,
            "fpr": 0.11842105263157894,
            "logloss": 0.9201882588680517,
            "mae": 0.26144555603106834,
            "precision": 0.775,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8383164014054194,
            "auditor_fn_violation": 0.021685311908821264,
            "auditor_fp_violation": 0.02364150929306959,
            "ave_precision_score": 0.8385574200480078,
            "fpr": 0.13172338090010977,
            "logloss": 0.9072624013101305,
            "mae": 0.26740831825989486,
            "precision": 0.7494780793319415,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8379186423598718,
            "auditor_fn_violation": 0.02783819051761636,
            "auditor_fp_violation": 0.029776910149204788,
            "ave_precision_score": 0.8383478487710139,
            "fpr": 0.12609649122807018,
            "logloss": 0.7901696272204229,
            "mae": 0.2658951812933068,
            "precision": 0.7614107883817427,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.831830526486736,
            "auditor_fn_violation": 0.022152416096410305,
            "auditor_fp_violation": 0.023544434239118263,
            "ave_precision_score": 0.8321213155802502,
            "fpr": 0.132821075740944,
            "logloss": 0.7943708259302683,
            "mae": 0.26904809664859636,
            "precision": 0.7457983193277311,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7997472869391519,
            "auditor_fn_violation": 0.022634388139770915,
            "auditor_fp_violation": 0.026751311690441062,
            "ave_precision_score": 0.8010299480312647,
            "fpr": 0.1074561403508772,
            "logloss": 1.3031809094953344,
            "mae": 0.29202707116294474,
            "precision": 0.7726218097447796,
            "recall": 0.6880165289256198
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7970407405321761,
            "auditor_fn_violation": 0.031256276712520736,
            "auditor_fp_violation": 0.021431184987716272,
            "ave_precision_score": 0.7973666228208879,
            "fpr": 0.11964873765093303,
            "logloss": 1.2221328080115432,
            "mae": 0.3017692139486479,
            "precision": 0.744131455399061,
            "recall": 0.674468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.83964536097513,
            "auditor_fn_violation": 0.02801489778164419,
            "auditor_fp_violation": 0.027145843580914906,
            "ave_precision_score": 0.840095064589168,
            "fpr": 0.12171052631578948,
            "logloss": 0.8982260210121371,
            "mae": 0.26022499072928384,
            "precision": 0.7730061349693251,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8425060580996462,
            "auditor_fn_violation": 0.026816451409486887,
            "auditor_fp_violation": 0.02557554306025375,
            "ave_precision_score": 0.8427430629906236,
            "fpr": 0.1350164654226125,
            "logloss": 0.8866602307197493,
            "mae": 0.26705809291930394,
            "precision": 0.7458677685950413,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8404397180118078,
            "auditor_fn_violation": 0.011146150500217491,
            "auditor_fp_violation": 0.019091244466305956,
            "ave_precision_score": 0.840747315148572,
            "fpr": 0.12280701754385964,
            "logloss": 0.753714954138991,
            "mae": 0.26794890401418675,
            "precision": 0.7704918032786885,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8409629523490203,
            "auditor_fn_violation": 0.014013125627671251,
            "auditor_fp_violation": 0.012044774001807094,
            "ave_precision_score": 0.8411823442366446,
            "fpr": 0.13172338090010977,
            "logloss": 0.7236700953087254,
            "mae": 0.2734619275968428,
            "precision": 0.75,
            "recall": 0.7659574468085106
        }
    }
]