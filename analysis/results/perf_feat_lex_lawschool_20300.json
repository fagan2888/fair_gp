[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5777406595209539,
            "auditor_fn_violation": 0.0482478472147783,
            "auditor_fp_violation": 0.03889548693586699,
            "ave_precision_score": 0.5797810717209813,
            "fpr": 0.19846491228070176,
            "logloss": 1.596465923072951,
            "mae": 0.4540619360878136,
            "precision": 0.5829493087557603,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.5994460670692612,
            "auditor_fn_violation": 0.03889111483595034,
            "auditor_fp_violation": 0.03264662066802572,
            "ave_precision_score": 0.6014702397142428,
            "fpr": 0.18221734357848518,
            "logloss": 1.350247197104407,
            "mae": 0.41938528541463643,
            "precision": 0.607565011820331,
            "recall": 0.5550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7804951745598755,
            "auditor_fn_violation": 0.07343141458534319,
            "auditor_fp_violation": 0.02243249156144518,
            "ave_precision_score": 0.7776864756487716,
            "fpr": 0.0668859649122807,
            "logloss": 5.518963042609235,
            "mae": 0.34135511360087323,
            "precision": 0.8145896656534954,
            "recall": 0.5458248472505092
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8042071476227901,
            "auditor_fn_violation": 0.06536855756259587,
            "auditor_fp_violation": 0.026462286341539912,
            "ave_precision_score": 0.7976244923404787,
            "fpr": 0.07574094401756312,
            "logloss": 4.494318586416023,
            "mae": 0.30395680545357157,
            "precision": 0.8022922636103151,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8354962267159334,
            "auditor_fn_violation": 0.013229356486940373,
            "auditor_fp_violation": 0.0074618702337792215,
            "ave_precision_score": 0.8357862428511778,
            "fpr": 0.12828947368421054,
            "logloss": 0.8720302256000757,
            "mae": 0.27722737431135125,
            "precision": 0.7572614107883817,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8340855768055686,
            "auditor_fn_violation": 0.005097287057869619,
            "auditor_fp_violation": 0.014720871883330726,
            "ave_precision_score": 0.8344898645542024,
            "fpr": 0.12733260153677278,
            "logloss": 0.788307060662925,
            "mae": 0.26126955651849904,
            "precision": 0.7547568710359408,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7185681103723564,
            "auditor_fn_violation": 0.0006074248758352126,
            "auditor_fp_violation": 0.004643809642872032,
            "ave_precision_score": 0.7189245657233871,
            "fpr": 0.16447368421052633,
            "logloss": 1.3570170916163524,
            "mae": 0.3989860709249751,
            "precision": 0.6583143507972665,
            "recall": 0.5885947046843177
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6920075340431353,
            "auditor_fn_violation": 0.014964686469429327,
            "auditor_fp_violation": 0.008864865924415872,
            "ave_precision_score": 0.6925691636001597,
            "fpr": 0.18111964873765093,
            "logloss": 1.254444911285626,
            "mae": 0.3902736210903375,
            "precision": 0.6206896551724138,
            "recall": 0.5831533477321814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7158385908432499,
            "auditor_fn_violation": 0.004761139100296566,
            "auditor_fp_violation": 0.006274221777722224,
            "ave_precision_score": 0.7161968977657871,
            "fpr": 0.15789473684210525,
            "logloss": 1.4220859660305198,
            "mae": 0.4039764996014266,
            "precision": 0.6538461538461539,
            "recall": 0.5539714867617108
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6907531113480976,
            "auditor_fn_violation": 0.017124513683252216,
            "auditor_fp_violation": 0.007933785479065394,
            "ave_precision_score": 0.6913253670998857,
            "fpr": 0.1734357848518112,
            "logloss": 1.2950964628791406,
            "mae": 0.39446934848635257,
            "precision": 0.619277108433735,
            "recall": 0.5550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8267946774301977,
            "auditor_fn_violation": 0.011791188766212884,
            "auditor_fp_violation": 0.0075191690627995165,
            "ave_precision_score": 0.8271805765945277,
            "fpr": 0.15679824561403508,
            "logloss": 1.0446509133133564,
            "mae": 0.27542372225130474,
            "precision": 0.7346938775510204,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8252486626918456,
            "auditor_fn_violation": 0.007655413911563256,
            "auditor_fp_violation": 0.019327269876117305,
            "ave_precision_score": 0.8255287933840237,
            "fpr": 0.15806805708013172,
            "logloss": 0.8835055968260045,
            "mae": 0.26530729246504087,
            "precision": 0.7272727272727273,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.750163963272869,
            "auditor_fn_violation": 0.0530893807839354,
            "auditor_fp_violation": 0.04060403383756303,
            "ave_precision_score": 0.7507884829420721,
            "fpr": 0.14364035087719298,
            "logloss": 1.2907758364373687,
            "mae": 0.33439758295586797,
            "precision": 0.7088888888888889,
            "recall": 0.6496945010183299
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7801077830342624,
            "auditor_fn_violation": 0.04294997783272838,
            "auditor_fp_violation": 0.028750784067743458,
            "ave_precision_score": 0.7804548241636244,
            "fpr": 0.1163556531284303,
            "logloss": 1.0985124888439872,
            "mae": 0.30457292109015693,
            "precision": 0.7395577395577395,
            "recall": 0.6501079913606912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 20300,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6639257017220676,
            "auditor_fn_violation": 0.07461946618072676,
            "auditor_fp_violation": 0.061400904279701636,
            "ave_precision_score": 0.6636158564695012,
            "fpr": 0.17982456140350878,
            "logloss": 3.0471442167430807,
            "mae": 0.3934502093197117,
            "precision": 0.6434782608695652,
            "recall": 0.6028513238289206
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6701389941321184,
            "auditor_fn_violation": 0.06822303831500286,
            "auditor_fp_violation": 0.0765103104908264,
            "ave_precision_score": 0.6702181984314763,
            "fpr": 0.20417124039517015,
            "logloss": 2.585563454032294,
            "mae": 0.3753951236727216,
            "precision": 0.6242424242424243,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7680839897497433,
            "auditor_fn_violation": 0.009332457926894635,
            "auditor_fp_violation": 0.017887652623244585,
            "ave_precision_score": 0.7427688210455001,
            "fpr": 0.20394736842105263,
            "logloss": 2.301975413290696,
            "mae": 0.29668724022037046,
            "precision": 0.6879194630872483,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7822422444739194,
            "auditor_fn_violation": 0.0053319993456505945,
            "auditor_fp_violation": 0.023771953896816692,
            "ave_precision_score": 0.7533188247967927,
            "fpr": 0.2052689352360044,
            "logloss": 2.234603549127409,
            "mae": 0.2872900095892722,
            "precision": 0.6764705882352942,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8622197992907371,
            "auditor_fn_violation": 0.016775645835566518,
            "auditor_fp_violation": 0.003922365295661959,
            "ave_precision_score": 0.8623224801482255,
            "fpr": 0.04057017543859649,
            "logloss": 0.8719097932494116,
            "mae": 0.33289230546634235,
            "precision": 0.8814102564102564,
            "recall": 0.560081466395112
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8579823582935939,
            "auditor_fn_violation": 0.0064344358488642684,
            "auditor_fp_violation": 0.006213736866865298,
            "ave_precision_score": 0.8582136299268347,
            "fpr": 0.04171240395170143,
            "logloss": 0.6074727471629371,
            "mae": 0.31500700574509316,
            "precision": 0.879746835443038,
            "recall": 0.6004319654427646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8540969834185483,
            "auditor_fn_violation": 0.005299335405724088,
            "auditor_fp_violation": 0.008365629036962955,
            "ave_precision_score": 0.8552311537367124,
            "fpr": 0.11403508771929824,
            "logloss": 0.8637000047485709,
            "mae": 0.2463036984486191,
            "precision": 0.7855670103092783,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8478161443134611,
            "auditor_fn_violation": 0.008817121194519594,
            "auditor_fp_violation": 0.015441234122628199,
            "ave_precision_score": 0.8480608698675485,
            "fpr": 0.12403951701427003,
            "logloss": 0.9194651123620389,
            "mae": 0.24969012674454039,
            "precision": 0.7635983263598326,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8593938077542259,
            "auditor_fn_violation": 0.0029299317540286613,
            "auditor_fp_violation": 0.007821290161270164,
            "ave_precision_score": 0.859811865170424,
            "fpr": 0.11293859649122807,
            "logloss": 0.8026759316982506,
            "mae": 0.2434363685115879,
            "precision": 0.789795918367347,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8533239808609163,
            "auditor_fn_violation": 0.009386120680049218,
            "auditor_fp_violation": 0.01690156029480948,
            "ave_precision_score": 0.8535642108142251,
            "fpr": 0.1251372118551043,
            "logloss": 0.8386249547314731,
            "mae": 0.24653832109237425,
            "precision": 0.7620041753653445,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6400096486308735,
            "auditor_fn_violation": 0.03244363454461,
            "auditor_fp_violation": 0.07392851189732053,
            "ave_precision_score": 0.5177966182539823,
            "fpr": 0.3333333333333333,
            "logloss": 9.95280142773785,
            "mae": 0.41077149194390894,
            "precision": 0.5841313269493844,
            "recall": 0.869653767820774
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6219374018015059,
            "auditor_fn_violation": 0.02550303110767604,
            "auditor_fp_violation": 0.0768092363180179,
            "ave_precision_score": 0.499221538383262,
            "fpr": 0.3446761800219539,
            "logloss": 9.89625145867933,
            "mae": 0.4123742476382277,
            "precision": 0.5650969529085873,
            "recall": 0.8812095032397408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8560520896728412,
            "auditor_fn_violation": 0.005455657984064032,
            "auditor_fp_violation": 0.0112670333791724,
            "ave_precision_score": 0.8566120938343503,
            "fpr": 0.1118421052631579,
            "logloss": 0.793099260617279,
            "mae": 0.2498456375914394,
            "precision": 0.7870563674321504,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8620778050749516,
            "auditor_fn_violation": 0.0007041368633429229,
            "auditor_fp_violation": 0.013640328524384513,
            "ave_precision_score": 0.8622782992981097,
            "fpr": 0.11745334796926454,
            "logloss": 0.7687288556123049,
            "mae": 0.24240103666210702,
            "precision": 0.773784355179704,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7606302451202849,
            "auditor_fn_violation": 0.00985278879479759,
            "auditor_fp_violation": 0.0054381797724715655,
            "ave_precision_score": 0.7563805763515092,
            "fpr": 0.14144736842105263,
            "logloss": 1.2799682354825537,
            "mae": 0.2871260472513291,
            "precision": 0.7445544554455445,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7801414806009765,
            "auditor_fn_violation": 0.010884485991943915,
            "auditor_fp_violation": 0.01639681668496158,
            "ave_precision_score": 0.7768485758567882,
            "fpr": 0.145993413830955,
            "logloss": 1.0484348232717118,
            "mae": 0.2757388193674637,
            "precision": 0.7318548387096774,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7865942114254184,
            "auditor_fn_violation": 0.055936684889412946,
            "auditor_fp_violation": 0.04570623411259741,
            "ave_precision_score": 0.7862488168427364,
            "fpr": 0.16666666666666666,
            "logloss": 1.8373568821816249,
            "mae": 0.3062932325988223,
            "precision": 0.7042801556420234,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.764587966497549,
            "auditor_fn_violation": 0.04672908274912102,
            "auditor_fp_violation": 0.05244923161361142,
            "ave_precision_score": 0.7633498551232905,
            "fpr": 0.16136114160263446,
            "logloss": 1.817999087955321,
            "mae": 0.2831980053578857,
            "precision": 0.7089108910891089,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5668593751100645,
            "auditor_fn_violation": 0.11724863329402938,
            "auditor_fp_violation": 0.07953077468016836,
            "ave_precision_score": 0.5680568792529783,
            "fpr": 0.23793859649122806,
            "logloss": 1.629466591231493,
            "mae": 0.4933769889580353,
            "precision": 0.5209713024282561,
            "recall": 0.48065173116089616
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5503484769100359,
            "auditor_fn_violation": 0.10769737762362107,
            "auditor_fp_violation": 0.08513995609220637,
            "ave_precision_score": 0.5519289096331805,
            "fpr": 0.21514818880351264,
            "logloss": 1.523116791625098,
            "mae": 0.4781525299678392,
            "precision": 0.5136476426799007,
            "recall": 0.4470842332613391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.82764297232668,
            "auditor_fn_violation": 0.011849251438167717,
            "auditor_fp_violation": 0.00741238488144352,
            "ave_precision_score": 0.8280125710714114,
            "fpr": 0.15570175438596492,
            "logloss": 1.040524920443787,
            "mae": 0.2746421942173373,
            "precision": 0.7355679702048417,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8262647119339398,
            "auditor_fn_violation": 0.005225311942113788,
            "auditor_fp_violation": 0.021199231613611418,
            "ave_precision_score": 0.8265413991548045,
            "fpr": 0.15367727771679474,
            "logloss": 0.8776476204072272,
            "mae": 0.264250000254209,
            "precision": 0.7318007662835249,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8248957316806832,
            "auditor_fn_violation": 0.012300353735662996,
            "auditor_fp_violation": 0.012491144726424137,
            "ave_precision_score": 0.8251516549432885,
            "fpr": 0.1074561403508772,
            "logloss": 0.6551825662098709,
            "mae": 0.32239936820970844,
            "precision": 0.7694117647058824,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.828049928367606,
            "auditor_fn_violation": 0.01924877842922951,
            "auditor_fp_violation": 0.012258409126548533,
            "ave_precision_score": 0.8283193369450698,
            "fpr": 0.10428100987925357,
            "logloss": 0.5817752914701944,
            "mae": 0.3015585762792871,
            "precision": 0.7743467933491687,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7717695659270414,
            "auditor_fn_violation": 0.029388644727909398,
            "auditor_fp_violation": 0.02651112639079886,
            "ave_precision_score": 0.7732456740181188,
            "fpr": 0.12719298245614036,
            "logloss": 0.6332353927793316,
            "mae": 0.3513366249609502,
            "precision": 0.7439293598233996,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7545778668405888,
            "auditor_fn_violation": 0.009357670705772744,
            "auditor_fp_violation": 0.013951505410067436,
            "ave_precision_score": 0.7550894701549749,
            "fpr": 0.12843029637760703,
            "logloss": 0.6300440012434821,
            "mae": 0.3521549175426969,
            "precision": 0.7334851936218679,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8277818254012889,
            "auditor_fn_violation": 0.05394022224604281,
            "auditor_fp_violation": 0.0510167937658874,
            "ave_precision_score": 0.8280790670842911,
            "fpr": 0.13925438596491227,
            "logloss": 1.0356671207547659,
            "mae": 0.2772233510634616,
            "precision": 0.7465069860279441,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8004857079309455,
            "auditor_fn_violation": 0.04550573385523231,
            "auditor_fp_violation": 0.05963570252469814,
            "ave_precision_score": 0.8011627048204332,
            "fpr": 0.16136114160263446,
            "logloss": 1.077739828576016,
            "mae": 0.2794044572435436,
            "precision": 0.7123287671232876,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8465767838189853,
            "auditor_fn_violation": 0.010234662521885162,
            "auditor_fp_violation": 0.01242342792849106,
            "ave_precision_score": 0.8468103899913106,
            "fpr": 0.09100877192982457,
            "logloss": 0.7101681806752217,
            "mae": 0.2792938897035352,
            "precision": 0.8023809523809524,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.85274617353858,
            "auditor_fn_violation": 0.019962398617331255,
            "auditor_fp_violation": 0.0062333385604516275,
            "ave_precision_score": 0.8529485162039747,
            "fpr": 0.08781558726673985,
            "logloss": 0.6454807239214516,
            "mae": 0.26134067391892796,
            "precision": 0.8048780487804879,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7840660417274065,
            "auditor_fn_violation": 0.042881516418337096,
            "auditor_fp_violation": 0.0322826811684794,
            "ave_precision_score": 0.7847624681695301,
            "fpr": 0.13815789473684212,
            "logloss": 1.0301017645087338,
            "mae": 0.3124599706607336,
            "precision": 0.7260869565217392,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8085811493516963,
            "auditor_fn_violation": 0.026565163480664684,
            "auditor_fp_violation": 0.02144425278344049,
            "ave_precision_score": 0.808968455618585,
            "fpr": 0.12403951701427003,
            "logloss": 0.8940398118855423,
            "mae": 0.2839964796229273,
            "precision": 0.7378190255220418,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7271505571342082,
            "auditor_fn_violation": 0.05535829134955515,
            "auditor_fp_violation": 0.04148174771846481,
            "ave_precision_score": 0.7277980614951794,
            "fpr": 0.15789473684210525,
            "logloss": 1.3550359332743933,
            "mae": 0.3473254024973137,
            "precision": 0.6923076923076923,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7540528620750455,
            "auditor_fn_violation": 0.048118389826289194,
            "auditor_fp_violation": 0.034332366316449744,
            "ave_precision_score": 0.754382608030465,
            "fpr": 0.14489571899012074,
            "logloss": 1.180581591034035,
            "mae": 0.32082582304981233,
            "precision": 0.6986301369863014,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 20300,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7746274783805389,
            "auditor_fn_violation": 0.029212223532354312,
            "auditor_fp_violation": 0.02600845939075718,
            "ave_precision_score": 0.776091732167578,
            "fpr": 0.12609649122807018,
            "logloss": 0.6286097833088413,
            "mae": 0.34912325312912446,
            "precision": 0.7461368653421634,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.758460867832299,
            "auditor_fn_violation": 0.007800034614135375,
            "auditor_fp_violation": 0.011138662380429678,
            "ave_precision_score": 0.7589485837277407,
            "fpr": 0.1251372118551043,
            "logloss": 0.6256734956568089,
            "mae": 0.3501557403563038,
            "precision": 0.7391304347826086,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7411257809723746,
            "auditor_fn_violation": 0.054628041590738564,
            "auditor_fp_violation": 0.0391116597908072,
            "ave_precision_score": 0.741356638602152,
            "fpr": 0.15021929824561403,
            "logloss": 1.3417183483557749,
            "mae": 0.33772194235648445,
            "precision": 0.7047413793103449,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7711157262035362,
            "auditor_fn_violation": 0.046435099681597376,
            "auditor_fp_violation": 0.03388152736396425,
            "ave_precision_score": 0.7711609359735567,
            "fpr": 0.13611416026344675,
            "logloss": 1.1478752589412309,
            "mae": 0.31266653129677324,
            "precision": 0.7129629629629629,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8069380414832058,
            "auditor_fn_violation": 0.02178243470182585,
            "auditor_fp_violation": 0.013345418177272167,
            "ave_precision_score": 0.8083145393730625,
            "fpr": 0.11403508771929824,
            "logloss": 0.5703169597002973,
            "mae": 0.332500869998496,
            "precision": 0.7744034707158352,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7906410425016334,
            "auditor_fn_violation": 0.010915306797410112,
            "auditor_fp_violation": 0.012594088129214373,
            "ave_precision_score": 0.7910546659992161,
            "fpr": 0.12623490669593854,
            "logloss": 0.574024699132809,
            "mae": 0.3350570391982172,
            "precision": 0.7444444444444445,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8549828704637155,
            "auditor_fn_violation": 0.021635044842248183,
            "auditor_fp_violation": 0.01535608617743885,
            "ave_precision_score": 0.8553804566457501,
            "fpr": 0.08442982456140351,
            "logloss": 0.7973769507951531,
            "mae": 0.32909705748540563,
            "precision": 0.8213457076566125,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8384905944463341,
            "auditor_fn_violation": 0.03144433406908128,
            "auditor_fp_violation": 0.020660185039987455,
            "ave_precision_score": 0.8391746611110031,
            "fpr": 0.08562019758507135,
            "logloss": 0.548027260804381,
            "mae": 0.3144063546948961,
            "precision": 0.8164705882352942,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6966402662828004,
            "auditor_fn_violation": 0.01591140529531568,
            "auditor_fp_violation": 0.020072821602700342,
            "ave_precision_score": 0.6940430273986185,
            "fpr": 0.18530701754385964,
            "logloss": 1.3551876047470521,
            "mae": 0.34592731507263136,
            "precision": 0.6780952380952381,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7215341010567646,
            "auditor_fn_violation": 0.020197110905112222,
            "auditor_fp_violation": 0.026697506664575828,
            "ave_precision_score": 0.7189146410881202,
            "fpr": 0.18990120746432493,
            "logloss": 1.163439198204391,
            "mae": 0.3342476901650661,
            "precision": 0.6627680311890838,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7736348386341068,
            "auditor_fn_violation": 0.031367241933754966,
            "auditor_fp_violation": 0.026302767012543235,
            "ave_precision_score": 0.7751078308922952,
            "fpr": 0.13048245614035087,
            "logloss": 0.6289284467144112,
            "mae": 0.3494237992359048,
            "precision": 0.740174672489083,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7563037001226338,
            "auditor_fn_violation": 0.009298399926030066,
            "auditor_fp_violation": 0.010878939940410849,
            "ave_precision_score": 0.7568143098473513,
            "fpr": 0.13172338090010977,
            "logloss": 0.626277100588088,
            "mae": 0.3506591824286144,
            "precision": 0.7285067873303167,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 20300,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7567089007335546,
            "auditor_fn_violation": 0.04534024725765534,
            "auditor_fp_violation": 0.033845376505396506,
            "ave_precision_score": 0.7572675195438013,
            "fpr": 0.15350877192982457,
            "logloss": 1.1412724779802177,
            "mae": 0.32772355965683797,
            "precision": 0.7083333333333334,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7851019727117274,
            "auditor_fn_violation": 0.037269466302190905,
            "auditor_fp_violation": 0.023029539752234592,
            "ave_precision_score": 0.7855502557841918,
            "fpr": 0.1394072447859495,
            "logloss": 0.9887671367954457,
            "mae": 0.3031477467617964,
            "precision": 0.7165178571428571,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.839631398914103,
            "auditor_fn_violation": 0.02306427984421339,
            "auditor_fp_violation": 0.0213438138100596,
            "ave_precision_score": 0.8399526840626219,
            "fpr": 0.13048245614035087,
            "logloss": 0.7684556537862455,
            "mae": 0.27135874361224144,
            "precision": 0.7605633802816901,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8274446256221032,
            "auditor_fn_violation": 0.022729158615719093,
            "auditor_fp_violation": 0.027373765093304067,
            "ave_precision_score": 0.8287547503411687,
            "fpr": 0.12733260153677278,
            "logloss": 0.7676053269342579,
            "mae": 0.2623202145140092,
            "precision": 0.7547568710359408,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8124982039305579,
            "auditor_fn_violation": 0.021393861435666565,
            "auditor_fp_violation": 0.009738196441221826,
            "ave_precision_score": 0.8128930964072505,
            "fpr": 0.13157894736842105,
            "logloss": 1.0259018129195787,
            "mae": 0.28589944161956726,
            "precision": 0.7515527950310559,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8174143267603555,
            "auditor_fn_violation": 0.018245916835983533,
            "auditor_fp_violation": 0.026156009879253567,
            "ave_precision_score": 0.8177812102646144,
            "fpr": 0.13062568605927552,
            "logloss": 0.9616924449931222,
            "mae": 0.26777674620594977,
            "precision": 0.7440860215053764,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7715340873796838,
            "auditor_fn_violation": 0.04719155322113839,
            "auditor_fp_violation": 0.03172271533941743,
            "ave_precision_score": 0.7719470548460158,
            "fpr": 0.13267543859649122,
            "logloss": 1.1730689581942597,
            "mae": 0.3210520343156234,
            "precision": 0.7305122494432071,
            "recall": 0.6680244399185336
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7969274527124862,
            "auditor_fn_violation": 0.036657791855246535,
            "auditor_fp_violation": 0.024989709110867182,
            "ave_precision_score": 0.7973472713388324,
            "fpr": 0.11525795828759605,
            "logloss": 1.009126279445116,
            "mae": 0.2935138716043799,
            "precision": 0.7469879518072289,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8707893399268013,
            "auditor_fn_violation": 0.01845276378318505,
            "auditor_fp_violation": 0.01048568571071384,
            "ave_precision_score": 0.8712071611126946,
            "fpr": 0.09649122807017543,
            "logloss": 0.770450281013961,
            "mae": 0.23913481032325706,
            "precision": 0.811965811965812,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8663256400462936,
            "auditor_fn_violation": 0.017093692877786018,
            "auditor_fp_violation": 0.020709189273953273,
            "ave_precision_score": 0.866560731264148,
            "fpr": 0.10976948408342481,
            "logloss": 0.7600781895713052,
            "mae": 0.23127173137443613,
            "precision": 0.7849462365591398,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7658138569485914,
            "auditor_fn_violation": 0.05059938542894916,
            "auditor_fp_violation": 0.03094136767095888,
            "ave_precision_score": 0.7666126565788887,
            "fpr": 0.12719298245614036,
            "logloss": 1.168176111180673,
            "mae": 0.32441714819326434,
            "precision": 0.7363636363636363,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7938815875014855,
            "auditor_fn_violation": 0.03790484906103231,
            "auditor_fp_violation": 0.022698761172965348,
            "ave_precision_score": 0.7943056953150212,
            "fpr": 0.1141602634467618,
            "logloss": 1.0169148308351432,
            "mae": 0.2942571873293762,
            "precision": 0.7463414634146341,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7206097933330431,
            "auditor_fn_violation": 0.009995712294994106,
            "auditor_fp_violation": 0.022640850939700807,
            "ave_precision_score": 0.7213705528983894,
            "fpr": 0.17982456140350878,
            "logloss": 1.048554821190822,
            "mae": 0.34701474394574894,
            "precision": 0.6821705426356589,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7407873719016698,
            "auditor_fn_violation": 0.016131135414765064,
            "auditor_fp_violation": 0.030764858083738442,
            "ave_precision_score": 0.7414925029633873,
            "fpr": 0.18221734357848518,
            "logloss": 0.879808638076084,
            "mae": 0.334980452933956,
            "precision": 0.6666666666666666,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5873511745897084,
            "auditor_fn_violation": 0.09792046307214064,
            "auditor_fp_violation": 0.07968704421386007,
            "ave_precision_score": 0.5885655034135105,
            "fpr": 0.22478070175438597,
            "logloss": 1.1160004213259185,
            "mae": 0.465265631893262,
            "precision": 0.5464601769911505,
            "recall": 0.5030549898167006
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5876110675753553,
            "auditor_fn_violation": 0.0902717683792761,
            "auditor_fp_violation": 0.08165085463384036,
            "ave_precision_score": 0.5891215278189363,
            "fpr": 0.20636663007683864,
            "logloss": 0.9698820681243456,
            "mae": 0.44101739962434644,
            "precision": 0.5627906976744186,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8476318463409731,
            "auditor_fn_violation": 0.008463751027262663,
            "auditor_fp_violation": 0.012636996291203071,
            "ave_precision_score": 0.8479156225736257,
            "fpr": 0.12609649122807018,
            "logloss": 0.78878705609862,
            "mae": 0.2694106763413643,
            "precision": 0.7633744855967078,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8442808470955491,
            "auditor_fn_violation": 0.011375248048213221,
            "auditor_fp_violation": 0.01796495217186765,
            "ave_precision_score": 0.8445814647917895,
            "fpr": 0.12952799121844127,
            "logloss": 0.7599323340540529,
            "mae": 0.2535090320697661,
            "precision": 0.7536534446764092,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7410590074152977,
            "auditor_fn_violation": 0.0418319219637689,
            "auditor_fp_violation": 0.03045953660874276,
            "ave_precision_score": 0.7421475656706092,
            "fpr": 0.13925438596491227,
            "logloss": 1.0819580626978056,
            "mae": 0.33039003467980416,
            "precision": 0.7239130434782609,
            "recall": 0.6782077393075356
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7701894729782353,
            "auditor_fn_violation": 0.03382701941473662,
            "auditor_fp_violation": 0.01893278579269249,
            "ave_precision_score": 0.7707091238248562,
            "fpr": 0.1394072447859495,
            "logloss": 0.9775610960042826,
            "mae": 0.3104659655490087,
            "precision": 0.7133182844243793,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 20300,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8268060987645609,
            "auditor_fn_violation": 0.047935202058098404,
            "auditor_fp_violation": 0.04796953785889904,
            "ave_precision_score": 0.8271229963803296,
            "fpr": 0.14144736842105263,
            "logloss": 1.021195701113291,
            "mae": 0.27960098454412635,
            "precision": 0.7440476190476191,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8000161167684265,
            "auditor_fn_violation": 0.04641376220089001,
            "auditor_fp_violation": 0.06026540693115885,
            "ave_precision_score": 0.8005983374191611,
            "fpr": 0.16245883644346873,
            "logloss": 1.0742333290236685,
            "mae": 0.2842283246445251,
            "precision": 0.7086614173228346,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7477567043345448,
            "auditor_fn_violation": 0.05496078536463358,
            "auditor_fp_violation": 0.04060403383756303,
            "ave_precision_score": 0.7482529236991481,
            "fpr": 0.14364035087719298,
            "logloss": 1.3071035937063915,
            "mae": 0.3364044972786029,
            "precision": 0.7069351230425056,
            "recall": 0.6435845213849287
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7781999244574671,
            "auditor_fn_violation": 0.04443648898867454,
            "auditor_fp_violation": 0.031090736239611106,
            "ave_precision_score": 0.7785537969950003,
            "fpr": 0.12184412733260154,
            "logloss": 1.1083956564496944,
            "mae": 0.30601907466931655,
            "precision": 0.7286063569682152,
            "recall": 0.6436285097192225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8267061262988888,
            "auditor_fn_violation": 0.011791188766212884,
            "auditor_fp_violation": 0.0075191690627995165,
            "ave_precision_score": 0.8270781072060744,
            "fpr": 0.15679824561403508,
            "logloss": 1.0445716118073334,
            "mae": 0.2754209403045328,
            "precision": 0.7346938775510204,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8252420016706152,
            "auditor_fn_violation": 0.007655413911563256,
            "auditor_fp_violation": 0.019327269876117305,
            "ave_precision_score": 0.8255218983543686,
            "fpr": 0.15806805708013172,
            "logloss": 0.8832979963682155,
            "mae": 0.26534820488950617,
            "precision": 0.7272727272727273,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.825778324849041,
            "auditor_fn_violation": 0.010652267124021873,
            "auditor_fp_violation": 0.009626203275409428,
            "ave_precision_score": 0.8262454882899734,
            "fpr": 0.1524122807017544,
            "logloss": 1.051155880018981,
            "mae": 0.2750504443297224,
            "precision": 0.7382297551789078,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8335958780771298,
            "auditor_fn_violation": 0.004843608120570994,
            "auditor_fp_violation": 0.019633546338403637,
            "ave_precision_score": 0.8339062692880511,
            "fpr": 0.15477497255762898,
            "logloss": 0.8696606013228174,
            "mae": 0.26463521107523463,
            "precision": 0.7272727272727273,
            "recall": 0.8120950323974082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6239452684372904,
            "auditor_fn_violation": 0.03188310644227677,
            "auditor_fp_violation": 0.022271013043297087,
            "ave_precision_score": 0.6239367540324597,
            "fpr": 0.25877192982456143,
            "logloss": 1.6181488560294999,
            "mae": 0.39553126844806225,
            "precision": 0.6105610561056105,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6496632608062688,
            "auditor_fn_violation": 0.023416699660734064,
            "auditor_fp_violation": 0.04189126940567667,
            "ave_precision_score": 0.6487135170977342,
            "fpr": 0.2623490669593853,
            "logloss": 1.5264967585634464,
            "mae": 0.38363896701626504,
            "precision": 0.596964586846543,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.869639701632414,
            "auditor_fn_violation": 0.021784667881516416,
            "auditor_fp_violation": 0.01260053340000834,
            "ave_precision_score": 0.8700247801407688,
            "fpr": 0.10307017543859649,
            "logloss": 0.7924416161826346,
            "mae": 0.2418736359087509,
            "precision": 0.8008474576271186,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8656806770327244,
            "auditor_fn_violation": 0.018765128866529316,
            "auditor_fp_violation": 0.02009173592598401,
            "ave_precision_score": 0.8658812613620376,
            "fpr": 0.10976948408342481,
            "logloss": 0.7837134158349043,
            "mae": 0.23685629862674315,
            "precision": 0.7807017543859649,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7488126807089092,
            "auditor_fn_violation": 0.049507360560260116,
            "auditor_fp_violation": 0.03658790682168605,
            "ave_precision_score": 0.7496046394357072,
            "fpr": 0.15021929824561403,
            "logloss": 1.177001454949718,
            "mae": 0.3332197490411781,
            "precision": 0.7085106382978723,
            "recall": 0.6782077393075356
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7768120539138395,
            "auditor_fn_violation": 0.04000303466392283,
            "auditor_fp_violation": 0.02449476634781245,
            "ave_precision_score": 0.7771924944762085,
            "fpr": 0.13721185510428102,
            "logloss": 1.0249105264444671,
            "mae": 0.30778196190245044,
            "precision": 0.7146118721461188,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8315525816930138,
            "auditor_fn_violation": 0.011844785078786581,
            "auditor_fp_violation": 0.015014897695545273,
            "ave_precision_score": 0.8321536958487192,
            "fpr": 0.12280701754385964,
            "logloss": 0.9146769868270755,
            "mae": 0.26937575610778525,
            "precision": 0.7671517671517671,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8291201546507214,
            "auditor_fn_violation": 0.007529759858508795,
            "auditor_fp_violation": 0.018234475458679636,
            "ave_precision_score": 0.829494275141109,
            "fpr": 0.1207464324917673,
            "logloss": 0.9365308224125344,
            "mae": 0.26161311882841504,
            "precision": 0.7629310344827587,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7162769901280124,
            "auditor_fn_violation": 0.00641815843069997,
            "auditor_fp_violation": 0.01039713297495521,
            "ave_precision_score": 0.7166354804415689,
            "fpr": 0.15679824561403508,
            "logloss": 1.43262475651646,
            "mae": 0.4028592055695763,
            "precision": 0.6529126213592233,
            "recall": 0.5478615071283096
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6923688930197036,
            "auditor_fn_violation": 0.02151529304658921,
            "auditor_fp_violation": 0.007458444409596987,
            "ave_precision_score": 0.6929302556329588,
            "fpr": 0.1712403951701427,
            "logloss": 1.3007422568087097,
            "mae": 0.3930829489862643,
            "precision": 0.6231884057971014,
            "recall": 0.5572354211663066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7421334295541264,
            "auditor_fn_violation": 0.0556664701468539,
            "auditor_fp_violation": 0.03974976038671501,
            "ave_precision_score": 0.7426461865185374,
            "fpr": 0.14144736842105263,
            "logloss": 1.3284590256123898,
            "mae": 0.34025437377344575,
            "precision": 0.7101123595505618,
            "recall": 0.6435845213849287
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7724576015161918,
            "auditor_fn_violation": 0.045325550684814586,
            "auditor_fp_violation": 0.030480633526736706,
            "ave_precision_score": 0.7728283981036531,
            "fpr": 0.11855104281009879,
            "logloss": 1.1338879846894652,
            "mae": 0.30948988722592213,
            "precision": 0.7333333333333333,
            "recall": 0.6414686825053996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6549744349656862,
            "auditor_fn_violation": 0.06119805624039734,
            "auditor_fp_violation": 0.04194795182731177,
            "ave_precision_score": 0.6558992644900388,
            "fpr": 0.16557017543859648,
            "logloss": 1.488286496799107,
            "mae": 0.3952956505267358,
            "precision": 0.6591422121896162,
            "recall": 0.594704684317719
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6719458859856422,
            "auditor_fn_violation": 0.04979456747741191,
            "auditor_fp_violation": 0.03841931942919869,
            "ave_precision_score": 0.6730128413564446,
            "fpr": 0.15806805708013172,
            "logloss": 1.2988982021279334,
            "mae": 0.37189609563317594,
            "precision": 0.6579572446555819,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7803457666077118,
            "auditor_fn_violation": 0.033234180155072,
            "auditor_fp_violation": 0.02478955702796183,
            "ave_precision_score": 0.7818307688265265,
            "fpr": 0.12390350877192982,
            "logloss": 0.623431986058567,
            "mae": 0.3477713010006323,
            "precision": 0.7466367713004485,
            "recall": 0.6782077393075356
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7700367095252604,
            "auditor_fn_violation": 0.012849905048210855,
            "auditor_fp_violation": 0.010687823427944177,
            "ave_precision_score": 0.7704851676502005,
            "fpr": 0.12952799121844127,
            "logloss": 0.6142463277011018,
            "mae": 0.3464255947026738,
            "precision": 0.728735632183908,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8298405523049903,
            "auditor_fn_violation": 0.00699208561117662,
            "auditor_fp_violation": 0.015918656498729006,
            "ave_precision_score": 0.8301417375279754,
            "fpr": 0.14692982456140352,
            "logloss": 0.6684975630576968,
            "mae": 0.26924348732615744,
            "precision": 0.7550274223034735,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8362172545497817,
            "auditor_fn_violation": 0.010128190842427448,
            "auditor_fp_violation": 0.023767053473420105,
            "ave_precision_score": 0.8356642769542227,
            "fpr": 0.1437980241492865,
            "logloss": 0.6307638158290301,
            "mae": 0.2608779636682594,
            "precision": 0.746615087040619,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8229778313136398,
            "auditor_fn_violation": 0.006942955657984066,
            "auditor_fp_violation": 0.01819758719839981,
            "ave_precision_score": 0.8227857495322745,
            "fpr": 0.18969298245614036,
            "logloss": 0.9942749168762354,
            "mae": 0.28609369958741565,
            "precision": 0.7022375215146299,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.833717102980182,
            "auditor_fn_violation": 0.010656886197732064,
            "auditor_fp_violation": 0.0262001136898228,
            "ave_precision_score": 0.8339645404467134,
            "fpr": 0.18111964873765093,
            "logloss": 0.9603093888490534,
            "mae": 0.27642990025319525,
            "precision": 0.701627486437613,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7184067428644614,
            "auditor_fn_violation": 0.0006074248758352126,
            "auditor_fp_violation": 0.004643809642872032,
            "ave_precision_score": 0.7187614291232455,
            "fpr": 0.16447368421052633,
            "logloss": 1.3606430026723324,
            "mae": 0.3991570187109599,
            "precision": 0.6583143507972665,
            "recall": 0.5885947046843177
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6917723067135446,
            "auditor_fn_violation": 0.014964686469429327,
            "auditor_fp_violation": 0.008948173122157756,
            "ave_precision_score": 0.6923345181944291,
            "fpr": 0.1800219538968167,
            "logloss": 1.2580309528141593,
            "mae": 0.3904786944941369,
            "precision": 0.6221198156682027,
            "recall": 0.5831533477321814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7953340609665667,
            "auditor_fn_violation": 0.026722228177368062,
            "auditor_fp_violation": 0.014345543192899116,
            "ave_precision_score": 0.7967553602719879,
            "fpr": 0.1162280701754386,
            "logloss": 0.6131889169364256,
            "mae": 0.33147667112978907,
            "precision": 0.7639198218262806,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7944606505235862,
            "auditor_fn_violation": 0.005965011273302305,
            "auditor_fp_violation": 0.01317233809001098,
            "ave_precision_score": 0.7948508909547143,
            "fpr": 0.12294182217343579,
            "logloss": 0.5889611878118624,
            "mae": 0.32956511767791447,
            "precision": 0.744874715261959,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.591568179959453,
            "auditor_fn_violation": 0.01139591596098189,
            "auditor_fp_violation": 0.007763991332249867,
            "ave_precision_score": 0.5930429902720464,
            "fpr": 0.07346491228070176,
            "logloss": 2.3104326062257314,
            "mae": 0.47785006704988453,
            "precision": 0.680952380952381,
            "recall": 0.29124236252545826
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6001997817493897,
            "auditor_fn_violation": 0.008399854905131192,
            "auditor_fp_violation": 0.0071546181590089394,
            "ave_precision_score": 0.602175917444367,
            "fpr": 0.06037321624588365,
            "logloss": 2.106475677673073,
            "mae": 0.45231373597228747,
            "precision": 0.7027027027027027,
            "recall": 0.28077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.800360492621575,
            "auditor_fn_violation": 0.022966019937828278,
            "auditor_fp_violation": 0.022620015001875233,
            "ave_precision_score": 0.7752315412017245,
            "fpr": 0.15460526315789475,
            "logloss": 1.8230897468132106,
            "mae": 0.28817443178270585,
            "precision": 0.7436363636363637,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8119053246604642,
            "auditor_fn_violation": 0.02000744440993568,
            "auditor_fp_violation": 0.027368864669907483,
            "ave_precision_score": 0.7833152114801886,
            "fpr": 0.14709110867178923,
            "logloss": 1.8662286054166648,
            "mae": 0.2727827727365198,
            "precision": 0.7437858508604207,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8569314986049654,
            "auditor_fn_violation": 0.004439561224854396,
            "auditor_fp_violation": 0.01008459390757178,
            "ave_precision_score": 0.8571498203630747,
            "fpr": 0.11293859649122807,
            "logloss": 0.7794662705625592,
            "mae": 0.24998855367686745,
            "precision": 0.7876288659793814,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8598445424111133,
            "auditor_fn_violation": 0.00521582861735496,
            "auditor_fp_violation": 0.009884153990904818,
            "ave_precision_score": 0.8600471436833057,
            "fpr": 0.12184412733260154,
            "logloss": 0.7708825005509714,
            "mae": 0.2451933552628087,
            "precision": 0.7648305084745762,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7137678661167142,
            "auditor_fn_violation": 0.05311841211991283,
            "auditor_fp_violation": 0.04158071842313623,
            "ave_precision_score": 0.7145894644680693,
            "fpr": 0.14802631578947367,
            "logloss": 1.312307651650887,
            "mae": 0.3589922092012245,
            "precision": 0.6945701357466063,
            "recall": 0.6252545824847251
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7484796247672718,
            "auditor_fn_violation": 0.04619327490024727,
            "auditor_fp_violation": 0.029235925984005023,
            "ave_precision_score": 0.7491375421079025,
            "fpr": 0.12843029637760703,
            "logloss": 1.1035659205760842,
            "mae": 0.32485856920630524,
            "precision": 0.7139364303178484,
            "recall": 0.6306695464362851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6405698950572405,
            "auditor_fn_violation": 0.03244363454461,
            "auditor_fp_violation": 0.0745978663999667,
            "ave_precision_score": 0.5183567560838851,
            "fpr": 0.33223684210526316,
            "logloss": 9.93384724771546,
            "mae": 0.4079947429589952,
            "precision": 0.584931506849315,
            "recall": 0.869653767820774
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6225536019256523,
            "auditor_fn_violation": 0.023928799197710727,
            "auditor_fp_violation": 0.07695624901991535,
            "ave_precision_score": 0.49983524192598483,
            "fpr": 0.3424807903402854,
            "logloss": 9.874318929191546,
            "mae": 0.4100726180494066,
            "precision": 0.5684647302904564,
            "recall": 0.8876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.831437332679898,
            "auditor_fn_violation": 0.008890288348161648,
            "auditor_fp_violation": 0.009423052881610206,
            "ave_precision_score": 0.8326988747999188,
            "fpr": 0.11732456140350878,
            "logloss": 0.7086385380989415,
            "mae": 0.2853598650438035,
            "precision": 0.7820773930753564,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8231368840663598,
            "auditor_fn_violation": 0.007415959961402871,
            "auditor_fp_violation": 0.015157009565626475,
            "ave_precision_score": 0.8239249748524893,
            "fpr": 0.14270032930845225,
            "logloss": 0.5966798750390038,
            "mae": 0.27966939558976545,
            "precision": 0.7455968688845401,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5968782749942175,
            "auditor_fn_violation": 0.10965135598670814,
            "auditor_fp_violation": 0.07749666624994792,
            "ave_precision_score": 0.5844339166606366,
            "fpr": 0.20175438596491227,
            "logloss": 3.7590424602222927,
            "mae": 0.4632330006939265,
            "precision": 0.5789473684210527,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5953459999128314,
            "auditor_fn_violation": 0.10044500501430798,
            "auditor_fp_violation": 0.07984749882389838,
            "ave_precision_score": 0.5857227738893392,
            "fpr": 0.19758507135016465,
            "logloss": 3.2504180251353887,
            "mae": 0.444262786505893,
            "precision": 0.5683453237410072,
            "recall": 0.5118790496760259
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8510059531128844,
            "auditor_fn_violation": 0.027110801443527358,
            "auditor_fp_violation": 0.01068362712005668,
            "ave_precision_score": 0.8512291337444418,
            "fpr": 0.08333333333333333,
            "logloss": 1.0683353469181405,
            "mae": 0.2546920982541349,
            "precision": 0.8186157517899761,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8555474175358159,
            "auditor_fn_violation": 0.017582084102865627,
            "auditor_fp_violation": 0.004454484867492552,
            "ave_precision_score": 0.855707360751673,
            "fpr": 0.09001097694840834,
            "logloss": 0.951061729978964,
            "mae": 0.24451701940499937,
            "precision": 0.8,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7978438883951765,
            "auditor_fn_violation": 0.033285543287955126,
            "auditor_fp_violation": 0.022601783556277878,
            "ave_precision_score": 0.7983254480355111,
            "fpr": 0.12171052631578948,
            "logloss": 0.9945191113332499,
            "mae": 0.30449542199347746,
            "precision": 0.7511210762331838,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8162104890255177,
            "auditor_fn_violation": 0.020943922729869877,
            "auditor_fp_violation": 0.012741100831111813,
            "ave_precision_score": 0.8165238005447424,
            "fpr": 0.11964873765093303,
            "logloss": 0.8804763049071935,
            "mae": 0.2810984137229978,
            "precision": 0.745920745920746,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8357842864581997,
            "auditor_fn_violation": 0.014359345410369099,
            "auditor_fp_violation": 0.020552048172688252,
            "ave_precision_score": 0.836120463650461,
            "fpr": 0.1206140350877193,
            "logloss": 0.7683042137431272,
            "mae": 0.27591311728920753,
            "precision": 0.7679324894514767,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8327407238049422,
            "auditor_fn_violation": 0.012894950840815286,
            "auditor_fp_violation": 0.019758507135016472,
            "ave_precision_score": 0.8330464812719824,
            "fpr": 0.12294182217343579,
            "logloss": 0.7733563663120699,
            "mae": 0.26816532484809524,
            "precision": 0.7601713062098501,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8388488331007378,
            "auditor_fn_violation": 0.010761692928859829,
            "auditor_fp_violation": 0.014527857648872777,
            "ave_precision_score": 0.8392223434351969,
            "fpr": 0.20285087719298245,
            "logloss": 0.9252263838952045,
            "mae": 0.2735801045728531,
            "precision": 0.702572347266881,
            "recall": 0.890020366598778
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8382143048435644,
            "auditor_fn_violation": 0.00839985490513119,
            "auditor_fp_violation": 0.030735455543358946,
            "ave_precision_score": 0.8384771478410378,
            "fpr": 0.21514818880351264,
            "logloss": 0.9829095485492721,
            "mae": 0.2822069671242851,
            "precision": 0.6733333333333333,
            "recall": 0.8725701943844493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7510967751506532,
            "auditor_fn_violation": 0.07080966162861328,
            "auditor_fp_violation": 0.054306267450097936,
            "ave_precision_score": 0.7520660062753868,
            "fpr": 0.15021929824561403,
            "logloss": 0.8242998712845643,
            "mae": 0.35491590588284644,
            "precision": 0.7034632034632035,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.719993088273301,
            "auditor_fn_violation": 0.06712534347416861,
            "auditor_fp_violation": 0.0639603261721813,
            "ave_precision_score": 0.7207760552963239,
            "fpr": 0.1712403951701427,
            "logloss": 0.8366308061178813,
            "mae": 0.3634546209199247,
            "precision": 0.6645161290322581,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8446273714843399,
            "auditor_fn_violation": 0.014524600707471332,
            "auditor_fp_violation": 0.007693670042088594,
            "ave_precision_score": 0.8448951344294993,
            "fpr": 0.11403508771929824,
            "logloss": 0.8194737552165794,
            "mae": 0.27838768496027494,
            "precision": 0.7699115044247787,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8427625405251746,
            "auditor_fn_violation": 0.011180839890657263,
            "auditor_fp_violation": 0.01356927238513408,
            "ave_precision_score": 0.8431271165393834,
            "fpr": 0.11306256860592755,
            "logloss": 0.7651753270496231,
            "mae": 0.2535677370255276,
            "precision": 0.7716186252771619,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 20300,
        "test": {
            "accuracy": 0.3717105263157895,
            "auc_prc": 0.42808237427153994,
            "auditor_fn_violation": 0.054947386286490166,
            "auditor_fp_violation": 0.05153248322707007,
            "ave_precision_score": 0.4246995624639438,
            "fpr": 0.2730263157894737,
            "logloss": 5.3881413088988825,
            "mae": 0.6131237233184287,
            "precision": 0.4014423076923077,
            "recall": 0.34012219959266804
        },
        "train": {
            "accuracy": 0.42590559824368823,
            "auc_prc": 0.4276190603048238,
            "auditor_fn_violation": 0.05476857131341678,
            "auditor_fp_violation": 0.0604369217500392,
            "ave_precision_score": 0.42186353546602307,
            "fpr": 0.2524698133918771,
            "logloss": 5.040717244789182,
            "mae": 0.5689077451350059,
            "precision": 0.425,
            "recall": 0.367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.870719275594478,
            "auditor_fn_violation": 0.01962518312073463,
            "auditor_fp_violation": 0.010582051923157062,
            "ave_precision_score": 0.8711455893990858,
            "fpr": 0.09539473684210527,
            "logloss": 0.7657502882805922,
            "mae": 0.23960074148591523,
            "precision": 0.8141025641025641,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.866740977811715,
            "auditor_fn_violation": 0.0173995301012582,
            "auditor_fp_violation": 0.019763407558413045,
            "ave_precision_score": 0.8669700468850794,
            "fpr": 0.10647639956092206,
            "logloss": 0.7503974579295971,
            "mae": 0.23118819119307304,
            "precision": 0.7891304347826087,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8267946774301977,
            "auditor_fn_violation": 0.011791188766212884,
            "auditor_fp_violation": 0.0075191690627995165,
            "ave_precision_score": 0.8271805765945277,
            "fpr": 0.15679824561403508,
            "logloss": 1.0446488946753698,
            "mae": 0.27542379415889334,
            "precision": 0.7346938775510204,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8252418876619747,
            "auditor_fn_violation": 0.007655413911563256,
            "auditor_fp_violation": 0.019327269876117305,
            "ave_precision_score": 0.8255220286962671,
            "fpr": 0.15806805708013172,
            "logloss": 0.8835049143832258,
            "mae": 0.2653073039527996,
            "precision": 0.7272727272727273,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8456418603411047,
            "auditor_fn_violation": 0.014098063386572345,
            "auditor_fp_violation": 0.008040067508438562,
            "ave_precision_score": 0.8459002569554579,
            "fpr": 0.12719298245614036,
            "logloss": 0.7799811876527434,
            "mae": 0.27419538138529437,
            "precision": 0.7603305785123967,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8406940147881817,
            "auditor_fn_violation": 0.006237656860118596,
            "auditor_fp_violation": 0.015441234122628197,
            "ave_precision_score": 0.8410405701645564,
            "fpr": 0.12843029637760703,
            "logloss": 0.7453293186162817,
            "mae": 0.2572615351011199,
            "precision": 0.7526427061310782,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8069397826308952,
            "auditor_fn_violation": 0.017948065173116097,
            "auditor_fp_violation": 0.015066987540109187,
            "ave_precision_score": 0.8073468270807055,
            "fpr": 0.10855263157894737,
            "logloss": 0.9809038410362932,
            "mae": 0.2954097296512019,
            "precision": 0.7713625866050808,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.808832169884383,
            "auditor_fn_violation": 0.016913509707368313,
            "auditor_fp_violation": 0.021995550415555908,
            "ave_precision_score": 0.809239469840834,
            "fpr": 0.11086717892425905,
            "logloss": 0.9687316763134136,
            "mae": 0.2808831392869824,
            "precision": 0.7629107981220657,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7401043657208132,
            "auditor_fn_violation": 0.07776155000535963,
            "auditor_fp_violation": 0.06633641705213152,
            "ave_precision_score": 0.7351218072475217,
            "fpr": 0.19846491228070176,
            "logloss": 2.9044978989477346,
            "mae": 0.33706451042863045,
            "precision": 0.6703096539162113,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7357396830192757,
            "auditor_fn_violation": 0.06454824997095732,
            "auditor_fp_violation": 0.0718353065704877,
            "ave_precision_score": 0.7298795433988352,
            "fpr": 0.20087815587266739,
            "logloss": 2.773656697516021,
            "mae": 0.3195773955114958,
            "precision": 0.659217877094972,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7833268024849738,
            "auditor_fn_violation": 0.04204407403437311,
            "auditor_fp_violation": 0.02593032462391132,
            "ave_precision_score": 0.7838819854633539,
            "fpr": 0.13706140350877194,
            "logloss": 1.0165766782262518,
            "mae": 0.31076594142951647,
            "precision": 0.7306034482758621,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8091121271825323,
            "auditor_fn_violation": 0.030455697462973545,
            "auditor_fp_violation": 0.019008742355339506,
            "ave_precision_score": 0.8094791263923922,
            "fpr": 0.1207464324917673,
            "logloss": 0.8809260513185179,
            "mae": 0.28684410769914,
            "precision": 0.7465437788018433,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7980593575322585,
            "auditor_fn_violation": 0.033285543287955126,
            "auditor_fp_violation": 0.022601783556277878,
            "ave_precision_score": 0.7985673390900172,
            "fpr": 0.12171052631578948,
            "logloss": 0.99254895424718,
            "mae": 0.3047491003725637,
            "precision": 0.7511210762331838,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8167147001214035,
            "auditor_fn_violation": 0.020943922729869877,
            "auditor_fp_violation": 0.010930394386074958,
            "ave_precision_score": 0.8169778280239623,
            "fpr": 0.11964873765093303,
            "logloss": 0.8772372085974158,
            "mae": 0.2810588958970627,
            "precision": 0.745920745920746,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8326920347350137,
            "auditor_fn_violation": 0.010808589702361815,
            "auditor_fp_violation": 0.012874005083968833,
            "ave_precision_score": 0.8330557306531959,
            "fpr": 0.13157894736842105,
            "logloss": 0.7840673985912545,
            "mae": 0.2768379702518333,
            "precision": 0.7565922920892495,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8323348645729032,
            "auditor_fn_violation": 0.010642661210593823,
            "auditor_fp_violation": 0.020932158538497732,
            "ave_precision_score": 0.8326399330578559,
            "fpr": 0.132821075740944,
            "logloss": 0.7796796970066253,
            "mae": 0.2676360044672103,
            "precision": 0.7473903966597077,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8357563389093987,
            "auditor_fn_violation": 0.013229356486940373,
            "auditor_fp_violation": 0.007524378047255917,
            "ave_precision_score": 0.8360456268476109,
            "fpr": 0.12719298245614036,
            "logloss": 0.8669101783536065,
            "mae": 0.2772037299501262,
            "precision": 0.7588357588357588,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8344009185853551,
            "auditor_fn_violation": 0.005097287057869619,
            "auditor_fp_violation": 0.014720871883330726,
            "ave_precision_score": 0.8348059216495105,
            "fpr": 0.12733260153677278,
            "logloss": 0.7837507039934226,
            "mae": 0.26113730742425145,
            "precision": 0.7547568710359408,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5891486211327144,
            "auditor_fn_violation": 0.05297995497909743,
            "auditor_fp_violation": 0.034493895070217113,
            "ave_precision_score": 0.5910159648344964,
            "fpr": 0.21710526315789475,
            "logloss": 0.9170549171590935,
            "mae": 0.45635612479695975,
            "precision": 0.5975609756097561,
            "recall": 0.5987780040733197
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6178120706691729,
            "auditor_fn_violation": 0.04833413546455253,
            "auditor_fp_violation": 0.03006654774972558,
            "ave_precision_score": 0.6198947204910279,
            "fpr": 0.20965971459934138,
            "logloss": 0.8374379858117044,
            "mae": 0.4311288897719686,
            "precision": 0.600418410041841,
            "recall": 0.6198704103671706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7593262793780832,
            "auditor_fn_violation": 0.05446948583270805,
            "auditor_fp_violation": 0.031113264158019755,
            "ave_precision_score": 0.7539481647398358,
            "fpr": 0.09649122807017543,
            "logloss": 2.8372118075898975,
            "mae": 0.3452392881554304,
            "precision": 0.7569060773480663,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7583379170818209,
            "auditor_fn_violation": 0.06066719931340729,
            "auditor_fp_violation": 0.025291085149756937,
            "ave_precision_score": 0.7545884243138377,
            "fpr": 0.08562019758507135,
            "logloss": 2.543451120320338,
            "mae": 0.3246059547698428,
            "precision": 0.7657657657657657,
            "recall": 0.550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7556063396056338,
            "auditor_fn_violation": 0.09025172401472112,
            "auditor_fp_violation": 0.08804225528191024,
            "ave_precision_score": 0.7560767263471151,
            "fpr": 0.15679824561403508,
            "logloss": 1.378355576323602,
            "mae": 0.33048091351239356,
            "precision": 0.6995798319327731,
            "recall": 0.6782077393075356
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7149033977058064,
            "auditor_fn_violation": 0.07878034960276722,
            "auditor_fp_violation": 0.10048073153520463,
            "ave_precision_score": 0.7167009090810954,
            "fpr": 0.1942919868276619,
            "logloss": 1.393618259627127,
            "mae": 0.3438665964430582,
            "precision": 0.6495049504950495,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 20300,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6042665340691807,
            "auditor_fn_violation": 0.014147193339764894,
            "auditor_fp_violation": 0.018689836229528703,
            "ave_precision_score": 0.6055467106015259,
            "fpr": 0.2565789473684211,
            "logloss": 1.1609741528933875,
            "mae": 0.4244642741389119,
            "precision": 0.5944540727902946,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6241525048032248,
            "auditor_fn_violation": 0.012750330138243166,
            "auditor_fp_violation": 0.012368668652971627,
            "ave_precision_score": 0.6252880359777608,
            "fpr": 0.2711306256860593,
            "logloss": 1.0357351543200213,
            "mae": 0.40545908162506017,
            "precision": 0.5862646566164154,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8458838329246708,
            "auditor_fn_violation": 0.011081037624611436,
            "auditor_fp_violation": 0.006753448347710135,
            "ave_precision_score": 0.8461514433633899,
            "fpr": 0.12719298245614036,
            "logloss": 0.8023183206585155,
            "mae": 0.2729811246471583,
            "precision": 0.7627811860940695,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8417239602566061,
            "auditor_fn_violation": 0.013608571028917027,
            "auditor_fp_violation": 0.01112641132193822,
            "ave_precision_score": 0.8421043230493022,
            "fpr": 0.12623490669593854,
            "logloss": 0.7695666297280817,
            "mae": 0.2533221730924138,
            "precision": 0.7578947368421053,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8505997574937296,
            "auditor_fn_violation": 0.010605370350519885,
            "auditor_fp_violation": 0.0033103096220360897,
            "ave_precision_score": 0.8517865027603764,
            "fpr": 0.11074561403508772,
            "logloss": 0.5850423970398868,
            "mae": 0.2848396495341659,
            "precision": 0.7804347826086957,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8536131195788732,
            "auditor_fn_violation": 0.012499022032134247,
            "auditor_fp_violation": 0.007985239924729498,
            "ave_precision_score": 0.8538656209029656,
            "fpr": 0.11086717892425905,
            "logloss": 0.5447697084346288,
            "mae": 0.2681140645999951,
            "precision": 0.7785087719298246,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5498563603137188,
            "auditor_fn_violation": 0.004640547397005758,
            "auditor_fp_violation": 0.019848835271075543,
            "ave_precision_score": 0.5512083703111181,
            "fpr": 0.2916666666666667,
            "logloss": 1.1038433868763244,
            "mae": 0.46123963444074295,
            "precision": 0.5702746365105008,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5594357860979836,
            "auditor_fn_violation": 0.01391914991476862,
            "auditor_fp_violation": 0.015340775442998285,
            "ave_precision_score": 0.5606273857821367,
            "fpr": 0.3106476399560922,
            "logloss": 0.9990723045429715,
            "mae": 0.4527625030390831,
            "precision": 0.5457463884430177,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8269123418235323,
            "auditor_fn_violation": 0.015632257833994353,
            "auditor_fp_violation": 0.006289848731091389,
            "ave_precision_score": 0.8272880869042185,
            "fpr": 0.15570175438596492,
            "logloss": 1.0449131547144106,
            "mae": 0.2753902972049096,
            "precision": 0.7384898710865562,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8243441399875074,
            "auditor_fn_violation": 0.003523055147904309,
            "auditor_fp_violation": 0.01822957503528306,
            "ave_precision_score": 0.8246190949416154,
            "fpr": 0.15806805708013172,
            "logloss": 0.8841752567262219,
            "mae": 0.2661479420314878,
            "precision": 0.7262357414448669,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8738102663772687,
            "auditor_fn_violation": 0.01585334262336085,
            "auditor_fp_violation": 0.009412634912697419,
            "ave_precision_score": 0.8743090852969294,
            "fpr": 0.09539473684210527,
            "logloss": 0.7239168140828136,
            "mae": 0.23864431730231142,
            "precision": 0.8125,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8689330733467902,
            "auditor_fn_violation": 0.016413264326340177,
            "auditor_fp_violation": 0.020385761329778894,
            "ave_precision_score": 0.8691523710752722,
            "fpr": 0.10537870472008781,
            "logloss": 0.7114399993037394,
            "mae": 0.23108116526018416,
            "precision": 0.7894736842105263,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8393965068936078,
            "auditor_fn_violation": 0.009593739950691398,
            "auditor_fp_violation": 0.013079759969996257,
            "ave_precision_score": 0.8397332253759235,
            "fpr": 0.12938596491228072,
            "logloss": 0.7453629401843115,
            "mae": 0.27256028681333744,
            "precision": 0.7606490872210954,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8364716397484158,
            "auditor_fn_violation": 0.012328322186475359,
            "auditor_fp_violation": 0.02517837541163557,
            "ave_precision_score": 0.836792592331483,
            "fpr": 0.13062568605927552,
            "logloss": 0.742782987091187,
            "mae": 0.2635555421524894,
            "precision": 0.750524109014675,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.588118436435774,
            "auditor_fn_violation": 0.1264582663379426,
            "auditor_fp_violation": 0.08646653748385215,
            "ave_precision_score": 0.5641754874459508,
            "fpr": 0.22478070175438597,
            "logloss": 5.125106029304579,
            "mae": 0.4993883155170194,
            "precision": 0.5319634703196348,
            "recall": 0.4745417515274949
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5816836456840722,
            "auditor_fn_violation": 0.120473786904951,
            "auditor_fp_violation": 0.09484034420573936,
            "ave_precision_score": 0.5643729697127022,
            "fpr": 0.22502744237102085,
            "logloss": 4.376036657487281,
            "mae": 0.49173447427568967,
            "precision": 0.5060240963855421,
            "recall": 0.4535637149028078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7798136690628641,
            "auditor_fn_violation": 0.05523993282595492,
            "auditor_fp_violation": 0.04553433762553652,
            "ave_precision_score": 0.7772314435991371,
            "fpr": 0.16885964912280702,
            "logloss": 2.1456662135843123,
            "mae": 0.3119628064490161,
            "precision": 0.7003891050583657,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7600889810143199,
            "auditor_fn_violation": 0.04637819973304441,
            "auditor_fp_violation": 0.05410312450995766,
            "ave_precision_score": 0.7570472505883807,
            "fpr": 0.16575192096597147,
            "logloss": 2.103929814584074,
            "mae": 0.28775941320233045,
            "precision": 0.7033398821218074,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 20300,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7734166693364046,
            "auditor_fn_violation": 0.029462339657698216,
            "auditor_fp_violation": 0.027550318789848732,
            "ave_precision_score": 0.7739682011176439,
            "fpr": 0.13925438596491227,
            "logloss": 0.6458588553512674,
            "mae": 0.3572141001201536,
            "precision": 0.7274678111587983,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.73830399796916,
            "auditor_fn_violation": 0.008539733945323886,
            "auditor_fp_violation": 0.012897914379802422,
            "ave_precision_score": 0.7390348365011501,
            "fpr": 0.13830954994511527,
            "logloss": 0.6485879118812723,
            "mae": 0.3569866740678945,
            "precision": 0.7193763919821826,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 20300,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8272910120179244,
            "auditor_fn_violation": 0.0542595669417944,
            "auditor_fp_violation": 0.051782514480976795,
            "ave_precision_score": 0.8275944577791254,
            "fpr": 0.13925438596491227,
            "logloss": 1.041080854620866,
            "mae": 0.27769047804629954,
            "precision": 0.746,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8000658023480989,
            "auditor_fn_violation": 0.04464275130217903,
            "auditor_fp_violation": 0.05963570252469814,
            "ave_precision_score": 0.8007695776573489,
            "fpr": 0.16136114160263446,
            "logloss": 1.0822572218368005,
            "mae": 0.2797458121146223,
            "precision": 0.7123287671232876,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8685532915354499,
            "auditor_fn_violation": 0.016617090077536003,
            "auditor_fp_violation": 0.011110763845480685,
            "ave_precision_score": 0.8692256735700811,
            "fpr": 0.09758771929824561,
            "logloss": 0.7691185056168798,
            "mae": 0.24126170108440034,
            "precision": 0.8106382978723404,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8654956166513271,
            "auditor_fn_violation": 0.016289981104475423,
            "auditor_fp_violation": 0.020287752861847266,
            "ave_precision_score": 0.8657128386870405,
            "fpr": 0.11086717892425905,
            "logloss": 0.7579581641545966,
            "mae": 0.2332951470012058,
            "precision": 0.7809110629067245,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7827205190388057,
            "auditor_fn_violation": 0.007146175009825988,
            "auditor_fp_violation": 0.022588761095136897,
            "ave_precision_score": 0.7241883607761668,
            "fpr": 0.15460526315789475,
            "logloss": 6.307294496508727,
            "mae": 0.31013492044296953,
            "precision": 0.7110655737704918,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7848104569597458,
            "auditor_fn_violation": 0.015296602835988271,
            "auditor_fp_violation": 0.027638387956719464,
            "ave_precision_score": 0.7231916193194559,
            "fpr": 0.16355653128430298,
            "logloss": 6.110937573287498,
            "mae": 0.30941607861901904,
            "precision": 0.6876310272536688,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 20300,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8719344913102771,
            "auditor_fn_violation": 0.022836495515775185,
            "auditor_fp_violation": 0.028935908655248577,
            "ave_precision_score": 0.8632993739808791,
            "fpr": 0.12280701754385964,
            "logloss": 1.8375931358464506,
            "mae": 0.2330697850376727,
            "precision": 0.7777777777777778,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8487554495984229,
            "auditor_fn_violation": 0.022729158615719086,
            "auditor_fp_violation": 0.03426621060059589,
            "ave_precision_score": 0.8331532553672878,
            "fpr": 0.1394072447859495,
            "logloss": 1.9861379096258147,
            "mae": 0.23985994416813186,
            "precision": 0.746,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8451874053706211,
            "auditor_fn_violation": 0.01422088826955372,
            "auditor_fp_violation": 0.006242967870983877,
            "ave_precision_score": 0.8453986919138898,
            "fpr": 0.1162280701754386,
            "logloss": 0.8096775239812806,
            "mae": 0.2772567824473887,
            "precision": 0.7680525164113785,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8423413331398077,
            "auditor_fn_violation": 0.01036764479258784,
            "auditor_fp_violation": 0.012025639015210915,
            "ave_precision_score": 0.8427299247964577,
            "fpr": 0.1163556531284303,
            "logloss": 0.7584536686124546,
            "mae": 0.2534340489986322,
            "precision": 0.7680525164113785,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8332276706137649,
            "auditor_fn_violation": 0.027392182084539262,
            "auditor_fp_violation": 0.028204046339125727,
            "ave_precision_score": 0.8334607980346573,
            "fpr": 0.12171052631578948,
            "logloss": 0.6742820956414582,
            "mae": 0.30735018791862484,
            "precision": 0.754424778761062,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.829521456093858,
            "auditor_fn_violation": 0.037693845085148406,
            "auditor_fp_violation": 0.0244041085149757,
            "ave_precision_score": 0.8297971112515821,
            "fpr": 0.12733260153677278,
            "logloss": 0.6261293989236009,
            "mae": 0.2925560413336808,
            "precision": 0.7478260869565218,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8124524543423203,
            "auditor_fn_violation": 0.022903490906492307,
            "auditor_fp_violation": 0.020580697587198403,
            "ave_precision_score": 0.8129826949259813,
            "fpr": 0.1513157894736842,
            "logloss": 0.8933918610995358,
            "mae": 0.2915140221625725,
            "precision": 0.7315175097276264,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8276090088339431,
            "auditor_fn_violation": 0.013350150429238995,
            "auditor_fp_violation": 0.011898228006899804,
            "ave_precision_score": 0.8279192738998313,
            "fpr": 0.14270032930845225,
            "logloss": 0.8190897112414197,
            "mae": 0.2708989921433883,
            "precision": 0.7330595482546202,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6401620833405874,
            "auditor_fn_violation": 0.03142977096509094,
            "auditor_fp_violation": 0.0745978663999667,
            "ave_precision_score": 0.517949021863619,
            "fpr": 0.33223684210526316,
            "logloss": 9.944134281476204,
            "mae": 0.40956265493643024,
            "precision": 0.5860655737704918,
            "recall": 0.8737270875763747
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6221890534413975,
            "auditor_fn_violation": 0.02550303110767604,
            "auditor_fp_violation": 0.07618688254665204,
            "ave_precision_score": 0.4994707410654264,
            "fpr": 0.34577387486278816,
            "logloss": 9.887492216602102,
            "mae": 0.4112658222811179,
            "precision": 0.5643153526970954,
            "recall": 0.8812095032397408
        }
    }
]