[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7698570615679539,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6758335341200535,
            "fpr": 0.1206140350877193,
            "logloss": 3.563169054894909,
            "mae": 0.3969145125072253,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7557733788011891,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6620361445492304,
            "fpr": 0.1119648737650933,
            "logloss": 3.275883159491521,
            "mae": 0.41100018398691085,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 21353,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5295063794186521,
            "auditor_fn_violation": 0.006839477308974933,
            "auditor_fp_violation": 0.0060691301852762785,
            "ave_precision_score": 0.5082917981574456,
            "fpr": 0.03179824561403509,
            "logloss": 9.69984396528594,
            "mae": 0.5757756125704762,
            "precision": 0.618421052631579,
            "recall": 0.09710743801652892
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.49229153930061076,
            "auditor_fn_violation": 0.005371698157273978,
            "auditor_fp_violation": 0.008445529693765544,
            "ave_precision_score": 0.47458915100966903,
            "fpr": 0.03293084522502744,
            "logloss": 9.04219438386121,
            "mae": 0.5801870527827517,
            "precision": 0.53125,
            "recall": 0.07234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.769301968396976,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6771926494021505,
            "fpr": 0.1206140350877193,
            "logloss": 3.564244802024458,
            "mae": 0.3961657094197315,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7547662770436333,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6628964307839437,
            "fpr": 0.1119648737650933,
            "logloss": 3.2778018141613137,
            "mae": 0.41029208800402744,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 21353,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7698570615679539,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01416215773077554,
            "ave_precision_score": 0.6758335341200535,
            "fpr": 0.11951754385964912,
            "logloss": 3.5554349119090025,
            "mae": 0.397329089476874,
            "precision": 0.7275,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7557733788011891,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6620361445492304,
            "fpr": 0.1119648737650933,
            "logloss": 3.266155471836589,
            "mae": 0.41138349988719636,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 21353,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8538084265318465,
            "auditor_fn_violation": 0.00802658764680296,
            "auditor_fp_violation": 0.0077164289227742225,
            "ave_precision_score": 0.8535756249968087,
            "fpr": 0.17982456140350878,
            "logloss": 0.6540473295064868,
            "mae": 0.3336791081942226,
            "precision": 0.7107583774250441,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8468506443035031,
            "auditor_fn_violation": 0.014022467711423034,
            "auditor_fp_violation": 0.02684747517741089,
            "ave_precision_score": 0.8464391403808706,
            "fpr": 0.17014270032930845,
            "logloss": 0.6296735911142267,
            "mae": 0.3399278632928459,
            "precision": 0.7150735294117647,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.8180528339442084,
            "auditor_fn_violation": 0.002793334058286215,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7610448781867671,
            "fpr": 0.010964912280701754,
            "logloss": 0.6672907897994188,
            "mae": 0.4531087625216235,
            "precision": 0.9224806201550387,
            "recall": 0.24586776859504134
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8057273036678128,
            "auditor_fn_violation": 0.005007356890954549,
            "auditor_fp_violation": 0.0014660822250598007,
            "ave_precision_score": 0.7425079924347529,
            "fpr": 0.005488474204171241,
            "logloss": 0.6864467592784002,
            "mae": 0.46474749028977136,
            "precision": 0.9484536082474226,
            "recall": 0.19574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7996049101495752,
            "auditor_fn_violation": 0.006320682905611137,
            "auditor_fp_violation": 0.012430316445318907,
            "ave_precision_score": 0.7999432432685436,
            "fpr": 0.20614035087719298,
            "logloss": 0.8216879414359824,
            "mae": 0.3435510172704725,
            "precision": 0.6813559322033899,
            "recall": 0.8305785123966942
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7827894044999801,
            "auditor_fn_violation": 0.010892869654576457,
            "auditor_fp_violation": 0.031156114110481373,
            "ave_precision_score": 0.7832222359770908,
            "fpr": 0.19319429198682767,
            "logloss": 0.7961187302414532,
            "mae": 0.3472624343669637,
            "precision": 0.6906854130052724,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.821618652830358,
            "auditor_fn_violation": 0.0016492677975931632,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7653983700913087,
            "fpr": 0.010964912280701754,
            "logloss": 0.6559089059299433,
            "mae": 0.4438245218214497,
            "precision": 0.9285714285714286,
            "recall": 0.26859504132231404
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.8061036702164779,
            "auditor_fn_violation": 0.003872293715113183,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7439801045588739,
            "fpr": 0.007683863885839737,
            "logloss": 0.6785928376197982,
            "mae": 0.4573502951556189,
            "precision": 0.9396551724137931,
            "recall": 0.23191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 21353,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7988773928019245,
            "auditor_fn_violation": 0.005826808757430769,
            "auditor_fp_violation": 0.011887194622069198,
            "ave_precision_score": 0.7992181494510533,
            "fpr": 0.20175438596491227,
            "logloss": 0.8005883854498489,
            "mae": 0.34315153976281737,
            "precision": 0.684931506849315,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7835593755467585,
            "auditor_fn_violation": 0.01004741107504029,
            "auditor_fp_violation": 0.029187232888032634,
            "ave_precision_score": 0.7843466941685899,
            "fpr": 0.18660812294182216,
            "logloss": 0.7722263417149099,
            "mae": 0.3439969106804928,
            "precision": 0.6958855098389982,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6994182092198059,
            "auditor_fn_violation": 0.013538494997825144,
            "auditor_fp_violation": 0.011771909329398261,
            "ave_precision_score": 0.701312439107974,
            "fpr": 0.16776315789473684,
            "logloss": 0.9308311810567722,
            "mae": 0.3453660048422902,
            "precision": 0.6921529175050302,
            "recall": 0.7107438016528925
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7111058433210723,
            "auditor_fn_violation": 0.025319382488264014,
            "auditor_fp_violation": 0.021433674091663742,
            "ave_precision_score": 0.7129735589535553,
            "fpr": 0.15697036223929747,
            "logloss": 0.8629498343453521,
            "mae": 0.34873613517200275,
            "precision": 0.6904761904761905,
            "recall": 0.6787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7768227387716964,
            "auditor_fn_violation": 0.0017580107293025964,
            "auditor_fp_violation": 0.0252295458271848,
            "ave_precision_score": 0.7142800189007565,
            "fpr": 0.20065789473684212,
            "logloss": 3.613614442764999,
            "mae": 0.334207754492374,
            "precision": 0.6783831282952548,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7725155414506006,
            "auditor_fn_violation": 0.018422589158511807,
            "auditor_fp_violation": 0.03484247705668437,
            "ave_precision_score": 0.7183795130449965,
            "fpr": 0.20856201975850713,
            "logloss": 3.163827314418469,
            "mae": 0.34208771544081823,
            "precision": 0.6594982078853047,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.8241914904814853,
            "auditor_fn_violation": 0.0026483434826736433,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7685229988318986,
            "fpr": 0.010964912280701754,
            "logloss": 0.6519574259630335,
            "mae": 0.44047015538569867,
            "precision": 0.9300699300699301,
            "recall": 0.27479338842975204
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.8065344323301669,
            "auditor_fn_violation": 0.0056075857720064475,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7454643531518156,
            "fpr": 0.007683863885839737,
            "logloss": 0.6755341150933739,
            "mae": 0.4546525525470989,
            "precision": 0.940677966101695,
            "recall": 0.23617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 21353,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7989137758728186,
            "auditor_fn_violation": 0.005826808757430769,
            "auditor_fp_violation": 0.011887194622069198,
            "ave_precision_score": 0.7992418683359342,
            "fpr": 0.20175438596491227,
            "logloss": 0.8000734804142486,
            "mae": 0.34316975073555733,
            "precision": 0.684931506849315,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7837405210185102,
            "auditor_fn_violation": 0.01004741107504029,
            "auditor_fp_violation": 0.029187232888032634,
            "ave_precision_score": 0.7844770801275947,
            "fpr": 0.18660812294182216,
            "logloss": 0.7727020461693792,
            "mae": 0.34396790307795394,
            "precision": 0.6958855098389982,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7698988965587137,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6762192563307186,
            "fpr": 0.1206140350877193,
            "logloss": 3.5636794580024724,
            "mae": 0.3969131851928276,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7554736148647041,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6620361445492304,
            "fpr": 0.1119648737650933,
            "logloss": 3.2765718284908063,
            "mae": 0.41102351462540065,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7961162524043942,
            "auditor_fn_violation": 0.004775627084239532,
            "auditor_fp_violation": 0.010142543859649123,
            "ave_precision_score": 0.7968100543874235,
            "fpr": 0.11732456140350878,
            "logloss": 0.9295935639918319,
            "mae": 0.2910154075845504,
            "precision": 0.7595505617977528,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.811348109105283,
            "auditor_fn_violation": 0.019791204428147705,
            "auditor_fp_violation": 0.023113819256205963,
            "ave_precision_score": 0.8116401255253834,
            "fpr": 0.10318331503841932,
            "logloss": 0.8786634808224569,
            "mae": 0.3002274797847277,
            "precision": 0.7661691542288557,
            "recall": 0.6553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.826073471088679,
            "auditor_fn_violation": 0.007503262287951294,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7706500706730057,
            "fpr": 0.010964912280701754,
            "logloss": 0.647029796363677,
            "mae": 0.4360783145713963,
            "precision": 0.9324324324324325,
            "recall": 0.28512396694214875
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8077083076534894,
            "auditor_fn_violation": 0.007641824508956722,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7474517437242257,
            "fpr": 0.007683863885839737,
            "logloss": 0.6712553031143063,
            "mae": 0.45092323098564774,
            "precision": 0.944,
            "recall": 0.251063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.8181671882273029,
            "auditor_fn_violation": 0.004431274467159631,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7611619713811457,
            "fpr": 0.010964912280701754,
            "logloss": 0.6648593733675825,
            "mae": 0.4511580505048889,
            "precision": 0.9253731343283582,
            "recall": 0.256198347107438
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.8057912895347623,
            "auditor_fn_violation": 0.00507742251909289,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7425763519925928,
            "fpr": 0.007683863885839737,
            "logloss": 0.6848410914534689,
            "mae": 0.46316966535492865,
            "precision": 0.9320388349514563,
            "recall": 0.20425531914893616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6785151152675075,
            "auditor_fn_violation": 0.006588009279396837,
            "auditor_fp_violation": 0.001967535661583867,
            "ave_precision_score": 0.5626322215192375,
            "fpr": 0.023026315789473683,
            "logloss": 0.7100589598524487,
            "mae": 0.4765080141655186,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6382230648970496,
            "auditor_fn_violation": 0.006366630076838651,
            "auditor_fp_violation": 0.0032408133396058755,
            "ave_precision_score": 0.5355370388850081,
            "fpr": 0.020856201975850714,
            "logloss": 0.718117848115609,
            "mae": 0.4855828657500961,
            "precision": 0.7121212121212122,
            "recall": 0.1
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8039213578034139,
            "auditor_fn_violation": 0.0036610120342177818,
            "auditor_fp_violation": 0.016116883915395966,
            "ave_precision_score": 0.8045289925619127,
            "fpr": 0.11951754385964912,
            "logloss": 0.9259316592539263,
            "mae": 0.2748264754986858,
            "precision": 0.7680851063829788,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8166441468367459,
            "auditor_fn_violation": 0.01798117570124017,
            "auditor_fp_violation": 0.0218518435548387,
            "ave_precision_score": 0.8169199668487306,
            "fpr": 0.1207464324917673,
            "logloss": 0.883567450104826,
            "mae": 0.2870232388251334,
            "precision": 0.7560975609756098,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7745039095173082,
            "auditor_fn_violation": 0.0017580107293025964,
            "auditor_fp_violation": 0.024850385309067056,
            "ave_precision_score": 0.7195453046635597,
            "fpr": 0.19956140350877194,
            "logloss": 3.386819238440598,
            "mae": 0.3346270507169098,
            "precision": 0.6795774647887324,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7754720502936973,
            "auditor_fn_violation": 0.018329168320994,
            "auditor_fp_violation": 0.03543986200407715,
            "ave_precision_score": 0.7333692144550705,
            "fpr": 0.2074643249176729,
            "logloss": 2.798131225753833,
            "mae": 0.3425037827074776,
            "precision": 0.6606822262118492,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8125237374953133,
            "auditor_fn_violation": 0.005799623024503411,
            "auditor_fp_violation": 0.016116883915395966,
            "ave_precision_score": 0.8130815194323662,
            "fpr": 0.11951754385964912,
            "logloss": 0.9011909109180742,
            "mae": 0.272855181894886,
            "precision": 0.7710084033613446,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8229544686008982,
            "auditor_fn_violation": 0.016115094471821943,
            "auditor_fp_violation": 0.02169751911009556,
            "ave_precision_score": 0.8232088118869698,
            "fpr": 0.12623490669593854,
            "logloss": 0.8557933577075983,
            "mae": 0.28429183997657803,
            "precision": 0.7516198704103672,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8535030500385834,
            "auditor_fn_violation": 0.003062925909815862,
            "auditor_fp_violation": 0.003368892441383834,
            "ave_precision_score": 0.8533878878514182,
            "fpr": 0.1524122807017544,
            "logloss": 0.5759196865292303,
            "mae": 0.341043253510929,
            "precision": 0.7382297551789078,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8515193038671063,
            "auditor_fn_violation": 0.00981152346030782,
            "auditor_fp_violation": 0.01915365487578127,
            "ave_precision_score": 0.851219131991137,
            "fpr": 0.141602634467618,
            "logloss": 0.5592852321775881,
            "mae": 0.35075353324805864,
            "precision": 0.7409638554216867,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8215083480243881,
            "auditor_fn_violation": 0.032058775554588956,
            "auditor_fp_violation": 0.031155209870470574,
            "ave_precision_score": 0.8221586214773808,
            "fpr": 0.14802631578947367,
            "logloss": 0.9468089253562697,
            "mae": 0.2688009073020047,
            "precision": 0.7393822393822393,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8361377858163321,
            "auditor_fn_violation": 0.03532942522829718,
            "auditor_fp_violation": 0.03489972644747618,
            "ave_precision_score": 0.8364241968729517,
            "fpr": 0.145993413830955,
            "logloss": 0.8509228901402065,
            "mae": 0.26791455998818625,
            "precision": 0.7371541501976284,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7456322601703544,
            "auditor_fn_violation": 0.006748858199217056,
            "auditor_fp_violation": 0.009335546810952616,
            "ave_precision_score": 0.654619966998665,
            "fpr": 0.1118421052631579,
            "logloss": 3.3627467802816273,
            "mae": 0.4110260023163599,
            "precision": 0.7158774373259053,
            "recall": 0.53099173553719
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.726989955664181,
            "auditor_fn_violation": 0.014162598967699742,
            "auditor_fp_violation": 0.017729887417828463,
            "ave_precision_score": 0.6366624566522999,
            "fpr": 0.10647639956092206,
            "logloss": 3.152890676399496,
            "mae": 0.4257130335636118,
            "precision": 0.7015384615384616,
            "recall": 0.4851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.818231724222901,
            "auditor_fn_violation": 0.004431274467159631,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7612262759947401,
            "fpr": 0.010964912280701754,
            "logloss": 0.6641980441769085,
            "mae": 0.4506275568958045,
            "precision": 0.9253731343283582,
            "recall": 0.256198347107438
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.8057912883495765,
            "auditor_fn_violation": 0.00507742251909289,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7425763796955278,
            "fpr": 0.007683863885839737,
            "logloss": 0.6844005958972552,
            "mae": 0.4627442745620673,
            "precision": 0.9320388349514563,
            "recall": 0.20425531914893616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8509108119638915,
            "auditor_fn_violation": 0.00711360011599246,
            "auditor_fp_violation": 0.006817203639940977,
            "ave_precision_score": 0.850401435046216,
            "fpr": 0.1787280701754386,
            "logloss": 0.724389456111171,
            "mae": 0.3260034191536537,
            "precision": 0.7145359019264448,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8460681917527841,
            "auditor_fn_violation": 0.012971483289347692,
            "auditor_fp_violation": 0.027069005428735717,
            "ave_precision_score": 0.8456243361289522,
            "fpr": 0.1756311745334797,
            "logloss": 0.6968828492799827,
            "mae": 0.3322913092770639,
            "precision": 0.7101449275362319,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 21353,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8213453599954359,
            "auditor_fn_violation": 0.029879385964912287,
            "auditor_fp_violation": 0.029771786358419414,
            "ave_precision_score": 0.8219461091161459,
            "fpr": 0.14802631578947367,
            "logloss": 0.9576769450167335,
            "mae": 0.2688253628988866,
            "precision": 0.7403846153846154,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8359075317381603,
            "auditor_fn_violation": 0.033876731204895254,
            "auditor_fp_violation": 0.03556182809750319,
            "ave_precision_score": 0.8361933836108132,
            "fpr": 0.145993413830955,
            "logloss": 0.8617460168944847,
            "mae": 0.2676756888110534,
            "precision": 0.7381889763779528,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.8204514779497829,
            "auditor_fn_violation": 0.0033936856604320814,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7642076303771971,
            "fpr": 0.010964912280701754,
            "logloss": 0.6579345077594434,
            "mae": 0.4455270405466619,
            "precision": 0.9280575539568345,
            "recall": 0.2665289256198347
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.8061354557982741,
            "auditor_fn_violation": 0.003872293715113183,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7440148549060411,
            "fpr": 0.007683863885839737,
            "logloss": 0.6800834768082313,
            "mae": 0.458705666903345,
            "precision": 0.9396551724137931,
            "recall": 0.23191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7902052886751127,
            "auditor_fn_violation": 0.0017580107293025964,
            "auditor_fp_violation": 0.024850385309067056,
            "ave_precision_score": 0.7768132908284568,
            "fpr": 0.19956140350877194,
            "logloss": 2.112148594134048,
            "mae": 0.3345983301356012,
            "precision": 0.6795774647887324,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.792525796424002,
            "auditor_fn_violation": 0.018329168320994,
            "auditor_fp_violation": 0.03543986200407715,
            "ave_precision_score": 0.7844977927999824,
            "fpr": 0.2074643249176729,
            "logloss": 1.8041197053170366,
            "mae": 0.34247862932828904,
            "precision": 0.6606822262118492,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.776890386811688,
            "auditor_fn_violation": 0.0017580107293025964,
            "auditor_fp_violation": 0.026408017707820957,
            "ave_precision_score": 0.7169960802165143,
            "fpr": 0.20175438596491227,
            "logloss": 3.5320377408485486,
            "mae": 0.33423592651291856,
            "precision": 0.6771929824561403,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7710604388258385,
            "auditor_fn_violation": 0.018422589158511807,
            "auditor_fp_violation": 0.03484247705668437,
            "ave_precision_score": 0.7206814988511131,
            "fpr": 0.20856201975850713,
            "logloss": 3.052582088039846,
            "mae": 0.3421090037121594,
            "precision": 0.6594982078853047,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8027590128474391,
            "auditor_fn_violation": 0.012643631288966216,
            "auditor_fp_violation": 0.011497786522380716,
            "ave_precision_score": 0.8033830447306862,
            "fpr": 0.17105263157894737,
            "logloss": 0.9292049617873444,
            "mae": 0.28158866725854365,
            "precision": 0.7148080438756855,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8168917401409252,
            "auditor_fn_violation": 0.0160403578018077,
            "auditor_fp_violation": 0.029301731669616252,
            "ave_precision_score": 0.8171718154975842,
            "fpr": 0.16794731064763996,
            "logloss": 0.8559631048571628,
            "mae": 0.28917123691946955,
            "precision": 0.7091254752851711,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6668729560464611,
            "auditor_fn_violation": 0.0035568000579962347,
            "auditor_fp_violation": 0.02217064272831611,
            "ave_precision_score": 0.649255106307178,
            "fpr": 0.23793859649122806,
            "logloss": 2.660108713613641,
            "mae": 0.35057910833031064,
            "precision": 0.6442622950819672,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6691908834724231,
            "auditor_fn_violation": 0.008108928696545767,
            "auditor_fp_violation": 0.015106371857195142,
            "ave_precision_score": 0.6472140598805655,
            "fpr": 0.24588364434687157,
            "logloss": 2.6782122063403215,
            "mae": 0.35722406825524206,
            "precision": 0.6339869281045751,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8121357387816526,
            "auditor_fn_violation": 0.00724499782514137,
            "auditor_fp_violation": 0.012809476963436631,
            "ave_precision_score": 0.8126908706121636,
            "fpr": 0.12171052631578948,
            "logloss": 0.9140313779937522,
            "mae": 0.2720431244704158,
            "precision": 0.7692307692307693,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.822975109361586,
            "auditor_fn_violation": 0.01590489758740687,
            "auditor_fp_violation": 0.022105732157480632,
            "ave_precision_score": 0.8232296030009556,
            "fpr": 0.12733260153677278,
            "logloss": 0.8670757298412012,
            "mae": 0.2834747057954015,
            "precision": 0.7510729613733905,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8004490148251575,
            "auditor_fn_violation": 0.004875308104973177,
            "auditor_fp_violation": 0.010116924905722254,
            "ave_precision_score": 0.8007409542743884,
            "fpr": 0.1962719298245614,
            "logloss": 0.7943180555891325,
            "mae": 0.3412375081975928,
            "precision": 0.6897746967071057,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7804600713821275,
            "auditor_fn_violation": 0.00816031015718056,
            "auditor_fp_violation": 0.026991843206364146,
            "ave_precision_score": 0.7811203207749258,
            "fpr": 0.18551042810098792,
            "logloss": 0.7741445165357093,
            "mae": 0.34620793066452676,
            "precision": 0.6954954954954955,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.8249003217654687,
            "auditor_fn_violation": 0.007997136436131657,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7694963669720929,
            "fpr": 0.010964912280701754,
            "logloss": 0.6490083999218905,
            "mae": 0.4378677021565014,
            "precision": 0.9319727891156463,
            "recall": 0.2830578512396694
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.8064414753427918,
            "auditor_fn_violation": 0.005642618586075627,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7461509949394438,
            "fpr": 0.007683863885839737,
            "logloss": 0.6730423096775527,
            "mae": 0.4524734057199811,
            "precision": 0.943089430894309,
            "recall": 0.24680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8238345557975999,
            "auditor_fn_violation": 0.0036791358561693594,
            "auditor_fp_violation": 0.0068607558616166605,
            "ave_precision_score": 0.8072709997568388,
            "fpr": 0.11951754385964912,
            "logloss": 0.5853730928487316,
            "mae": 0.37723536874380026,
            "precision": 0.745920745920746,
            "recall": 0.6611570247933884
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7978522322825212,
            "auditor_fn_violation": 0.02140271387532989,
            "auditor_fp_violation": 0.021886691010103272,
            "ave_precision_score": 0.7803667168922965,
            "fpr": 0.1119648737650933,
            "logloss": 0.5958951814540561,
            "mae": 0.391927584596837,
            "precision": 0.7411167512690355,
            "recall": 0.6212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8352334325731363,
            "auditor_fn_violation": 0.003255491518051329,
            "auditor_fp_violation": 0.014997335628791611,
            "ave_precision_score": 0.8186755096331133,
            "fpr": 0.14144736842105263,
            "logloss": 0.5750604440047004,
            "mae": 0.3697830468187468,
            "precision": 0.735655737704918,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8138573677560338,
            "auditor_fn_violation": 0.020164887778218933,
            "auditor_fp_violation": 0.02817665668535984,
            "ave_precision_score": 0.7964377860320633,
            "fpr": 0.1394072447859495,
            "logloss": 0.5808478468584288,
            "mae": 0.38275317911520745,
            "precision": 0.7239130434782609,
            "recall": 0.7085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.809230848087293,
            "auditor_fn_violation": 0.006116789908655938,
            "auditor_fp_violation": 0.009384222823413675,
            "ave_precision_score": 0.809820775070237,
            "fpr": 0.12828947368421054,
            "logloss": 0.9200206964690624,
            "mae": 0.2702586932131159,
            "precision": 0.7602459016393442,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8218777892915292,
            "auditor_fn_violation": 0.014646051801854404,
            "auditor_fp_violation": 0.022387000903544733,
            "ave_precision_score": 0.8221411855097362,
            "fpr": 0.1251372118551043,
            "logloss": 0.8701363859186408,
            "mae": 0.2815433274880565,
            "precision": 0.7537796976241901,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7959677383536721,
            "auditor_fn_violation": 0.011812200956937805,
            "auditor_fp_violation": 0.013782997212657818,
            "ave_precision_score": 0.796431176483839,
            "fpr": 0.17214912280701755,
            "logloss": 0.9341901491136846,
            "mae": 0.2837606646472512,
            "precision": 0.7145454545454546,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8124069809021045,
            "auditor_fn_violation": 0.016498119905644957,
            "auditor_fp_violation": 0.03089226909204956,
            "ave_precision_score": 0.8127039833437523,
            "fpr": 0.1712403951701427,
            "logloss": 0.8625861882321895,
            "mae": 0.29153617463440834,
            "precision": 0.7028571428571428,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.8241914917443303,
            "auditor_fn_violation": 0.0026483434826736433,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7685228990099477,
            "fpr": 0.010964912280701754,
            "logloss": 0.6512966693173049,
            "mae": 0.4398831958114578,
            "precision": 0.9300699300699301,
            "recall": 0.27479338842975204
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.8065344323301669,
            "auditor_fn_violation": 0.0056075857720064475,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7454643531518156,
            "fpr": 0.007683863885839737,
            "logloss": 0.6749831689035802,
            "mae": 0.4541601505371794,
            "precision": 0.940677966101695,
            "recall": 0.23617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8607427979289043,
            "auditor_fn_violation": 0.0056568979266347725,
            "auditor_fp_violation": 0.011169863912116745,
            "ave_precision_score": 0.8610889798045025,
            "fpr": 0.21929824561403508,
            "logloss": 0.6828833080119331,
            "mae": 0.3122622226038131,
            "precision": 0.68,
            "recall": 0.878099173553719
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8541991036387496,
            "auditor_fn_violation": 0.013896349580773994,
            "auditor_fp_violation": 0.02775599811823743,
            "ave_precision_score": 0.8544348445652186,
            "fpr": 0.2074643249176729,
            "logloss": 0.6611796379558024,
            "mae": 0.3131294606864845,
            "precision": 0.6870860927152318,
            "recall": 0.8829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8096592244419041,
            "auditor_fn_violation": 0.006116789908655938,
            "auditor_fp_violation": 0.014146786358419415,
            "ave_precision_score": 0.8102481270825387,
            "fpr": 0.12938596491228072,
            "logloss": 0.9165952920505488,
            "mae": 0.26993437767891953,
            "precision": 0.7586912065439673,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8225481602139924,
            "auditor_fn_violation": 0.015087465259126048,
            "auditor_fp_violation": 0.022795213950929805,
            "ave_precision_score": 0.8228098264188632,
            "fpr": 0.12623490669593854,
            "logloss": 0.8666317412437727,
            "mae": 0.2810815447259634,
            "precision": 0.7526881720430108,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8354793382372688,
            "auditor_fn_violation": 0.003255491518051329,
            "auditor_fp_violation": 0.014997335628791611,
            "ave_precision_score": 0.8199659257822847,
            "fpr": 0.14144736842105263,
            "logloss": 0.5722053127687932,
            "mae": 0.36926854782525387,
            "precision": 0.735655737704918,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8123108145914621,
            "auditor_fn_violation": 0.020776794263960587,
            "auditor_fp_violation": 0.02817665668535984,
            "ave_precision_score": 0.7965314792503919,
            "fpr": 0.1394072447859495,
            "logloss": 0.5785090939682309,
            "mae": 0.3823455291770554,
            "precision": 0.7233115468409586,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 21353,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8059635087109992,
            "auditor_fn_violation": 0.01157206031607946,
            "auditor_fp_violation": 0.0187172077389736,
            "ave_precision_score": 0.8065231667933508,
            "fpr": 0.16776315789473684,
            "logloss": 0.9171887381092331,
            "mae": 0.2784183974113026,
            "precision": 0.7192660550458716,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8220870943492308,
            "auditor_fn_violation": 0.01647476469626551,
            "auditor_fp_violation": 0.030508947084139187,
            "ave_precision_score": 0.8223511837054112,
            "fpr": 0.1734357848518112,
            "logloss": 0.8436551874869975,
            "mae": 0.284949725795734,
            "precision": 0.7030075187969925,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 21353,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8612442261299216,
            "auditor_fn_violation": 0.006105462519936208,
            "auditor_fp_violation": 0.009968334972946387,
            "ave_precision_score": 0.8615906395929681,
            "fpr": 0.23355263157894737,
            "logloss": 0.6986957609288836,
            "mae": 0.3142856042423661,
            "precision": 0.6682242990654206,
            "recall": 0.8863636363636364
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8563794348505367,
            "auditor_fn_violation": 0.015232267557278655,
            "auditor_fp_violation": 0.03255499052895948,
            "ave_precision_score": 0.8566015395195106,
            "fpr": 0.21295279912184412,
            "logloss": 0.6692757691794542,
            "mae": 0.3120117123871551,
            "precision": 0.6830065359477124,
            "recall": 0.8893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8360559803479404,
            "auditor_fn_violation": 0.003375561838480503,
            "auditor_fp_violation": 0.010780455812428268,
            "ave_precision_score": 0.8201531545744114,
            "fpr": 0.12938596491228072,
            "logloss": 0.576229089746676,
            "mae": 0.3706132703084956,
            "precision": 0.7417943107221007,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8120307957733073,
            "auditor_fn_violation": 0.017820024756521946,
            "auditor_fp_violation": 0.022596085635132213,
            "ave_precision_score": 0.7947628106182318,
            "fpr": 0.11745334796926454,
            "logloss": 0.5819020236286616,
            "mae": 0.38352000368217215,
            "precision": 0.7434052757793765,
            "recall": 0.6595744680851063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8262413325760527,
            "auditor_fn_violation": 0.004730317529360599,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.8263385766194871,
            "fpr": 0.010964912280701754,
            "logloss": 0.663122826410662,
            "mae": 0.4496624712962984,
            "precision": 0.9259259259259259,
            "recall": 0.25826446280991733
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.8188431722852233,
            "auditor_fn_violation": 0.004675712917766307,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.8187326115344911,
            "fpr": 0.007683863885839737,
            "logloss": 0.683645193478953,
            "mae": 0.4619272925883826,
            "precision": 0.9351851851851852,
            "recall": 0.2148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7958209118798996,
            "auditor_fn_violation": 0.004775627084239532,
            "auditor_fp_violation": 0.010142543859649123,
            "ave_precision_score": 0.7965607754622532,
            "fpr": 0.11732456140350878,
            "logloss": 0.9308248012696233,
            "mae": 0.2909594479144915,
            "precision": 0.7595505617977528,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.811283138554025,
            "auditor_fn_violation": 0.019543639208725507,
            "auditor_fp_violation": 0.023113819256205963,
            "ave_precision_score": 0.8115753064405735,
            "fpr": 0.10318331503841932,
            "logloss": 0.8795690312491582,
            "mae": 0.30011689359428195,
            "precision": 0.7667493796526055,
            "recall": 0.6574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7942380024529396,
            "auditor_fn_violation": 0.004526424532405395,
            "auditor_fp_violation": 0.009719831119855719,
            "ave_precision_score": 0.7948032106115023,
            "fpr": 0.1162280701754386,
            "logloss": 0.9874889323368472,
            "mae": 0.2939433721390209,
            "precision": 0.7596371882086168,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8086156236522042,
            "auditor_fn_violation": 0.022547119134923056,
            "auditor_fp_violation": 0.022735475456190524,
            "ave_precision_score": 0.8089187717202615,
            "fpr": 0.10318331503841932,
            "logloss": 0.9262051975792728,
            "mae": 0.3011424843964793,
            "precision": 0.7638190954773869,
            "recall": 0.6468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8027528691386525,
            "auditor_fn_violation": 0.013243982891112081,
            "auditor_fp_violation": 0.011497786522380716,
            "ave_precision_score": 0.8033539829467464,
            "fpr": 0.17105263157894737,
            "logloss": 0.9289112838270639,
            "mae": 0.28157263391041687,
            "precision": 0.7142857142857143,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8168742204425665,
            "auditor_fn_violation": 0.0160403578018077,
            "auditor_fp_violation": 0.029301731669616252,
            "ave_precision_score": 0.8171543746562484,
            "fpr": 0.16794731064763996,
            "logloss": 0.85573028130346,
            "mae": 0.2891624063525464,
            "precision": 0.7091254752851711,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7483006265296954,
            "auditor_fn_violation": 0.005817746846454986,
            "auditor_fp_violation": 0.015166420724708977,
            "ave_precision_score": 0.6841786452956617,
            "fpr": 0.12171052631578948,
            "logloss": 3.5134862424990367,
            "mae": 0.38934546565277534,
            "precision": 0.7312348668280871,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7297022642296149,
            "auditor_fn_violation": 0.017591143704603313,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6702919949395169,
            "fpr": 0.1119648737650933,
            "logloss": 3.214707020158685,
            "mae": 0.4040824907017068,
            "precision": 0.7235772357723578,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6906371636532798,
            "auditor_fn_violation": 0.010389480933739306,
            "auditor_fp_violation": 0.011869261354320383,
            "ave_precision_score": 0.6925258073614702,
            "fpr": 0.16337719298245615,
            "logloss": 0.9932346158790759,
            "mae": 0.34560881242844277,
            "precision": 0.6983805668016194,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7021693499717452,
            "auditor_fn_violation": 0.028339211061027172,
            "auditor_fp_violation": 0.02488108305890963,
            "ave_precision_score": 0.7029970768290158,
            "fpr": 0.16136114160263446,
            "logloss": 0.9078157980045684,
            "mae": 0.35119911595401454,
            "precision": 0.6838709677419355,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 21353,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7698988965587137,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01416215773077554,
            "ave_precision_score": 0.6762192563307186,
            "fpr": 0.11951754385964912,
            "logloss": 3.560433423767226,
            "mae": 0.3970873006537818,
            "precision": 0.7275,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7554736148647041,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6620361445492304,
            "fpr": 0.1119648737650933,
            "logloss": 3.272480858802283,
            "mae": 0.41118463913119846,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8128175595810283,
            "auditor_fn_violation": 0.009351892127011745,
            "auditor_fp_violation": 0.016488358747335626,
            "ave_precision_score": 0.8134395680763147,
            "fpr": 0.14802631578947367,
            "logloss": 0.9092143996354493,
            "mae": 0.26823200824486615,
            "precision": 0.7378640776699029,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8253144626690072,
            "auditor_fn_violation": 0.01565266132610879,
            "auditor_fp_violation": 0.027853073172188745,
            "ave_precision_score": 0.8255518830432694,
            "fpr": 0.14489571899012074,
            "logloss": 0.8576894331295486,
            "mae": 0.27831476855962445,
            "precision": 0.7327935222672065,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8525366890349453,
            "auditor_fn_violation": 0.007521386109902858,
            "auditor_fp_violation": 0.0077164289227742225,
            "ave_precision_score": 0.8527238272094144,
            "fpr": 0.17982456140350878,
            "logloss": 0.6506544796091694,
            "mae": 0.33278621303473127,
            "precision": 0.7112676056338029,
            "recall": 0.8347107438016529
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8471515850667606,
            "auditor_fn_violation": 0.012331550552350702,
            "auditor_fp_violation": 0.02391779983123876,
            "ave_precision_score": 0.8471866485653827,
            "fpr": 0.1734357848518112,
            "logloss": 0.6240458264200929,
            "mae": 0.33806107655314793,
            "precision": 0.7116788321167883,
            "recall": 0.8297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8510403932837587,
            "auditor_fn_violation": 0.00711360011599246,
            "auditor_fp_violation": 0.006338129201508452,
            "ave_precision_score": 0.850547719564523,
            "fpr": 0.17763157894736842,
            "logloss": 0.7223702277684902,
            "mae": 0.3259369881268133,
            "precision": 0.7157894736842105,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8462236462365097,
            "auditor_fn_violation": 0.012971483289347692,
            "auditor_fp_violation": 0.027069005428735717,
            "ave_precision_score": 0.8457931922530951,
            "fpr": 0.1756311745334797,
            "logloss": 0.6949812389793142,
            "mae": 0.3322489685598765,
            "precision": 0.7101449275362319,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8003573260451624,
            "auditor_fn_violation": 0.004875308104973177,
            "auditor_fp_violation": 0.010116924905722254,
            "ave_precision_score": 0.8006337720999975,
            "fpr": 0.1962719298245614,
            "logloss": 0.7913652227761039,
            "mae": 0.3413255719627303,
            "precision": 0.6897746967071057,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7795855420818183,
            "auditor_fn_violation": 0.00816031015718056,
            "auditor_fp_violation": 0.02758673904980946,
            "ave_precision_score": 0.7802505906067219,
            "fpr": 0.18660812294182216,
            "logloss": 0.7725935935354606,
            "mae": 0.3463037977103475,
            "precision": 0.6942446043165468,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.822959249653771,
            "auditor_fn_violation": 0.004385964912280699,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7672729682633312,
            "fpr": 0.010964912280701754,
            "logloss": 0.6536891316468133,
            "mae": 0.44196406823762674,
            "precision": 0.9295774647887324,
            "recall": 0.2727272727272727
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.806520996279366,
            "auditor_fn_violation": 0.004250648107060288,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.7454647954790501,
            "fpr": 0.007683863885839737,
            "logloss": 0.6769146963516172,
            "mae": 0.45587027916923967,
            "precision": 0.9401709401709402,
            "recall": 0.23404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.8597152751081318,
            "auditor_fn_violation": 0.0006388647237929535,
            "auditor_fp_violation": 0.0027924659780291976,
            "ave_precision_score": 0.8536587282448187,
            "fpr": 0.46271929824561403,
            "logloss": 4.557460233397823,
            "mae": 0.4637710791031176,
            "precision": 0.5337016574585636,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.8498883877615336,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0028599804356429777,
            "ave_precision_score": 0.8460818548313757,
            "fpr": 0.4774972557628979,
            "logloss": 4.5890897665334185,
            "mae": 0.4774490134545242,
            "precision": 0.5193370165745856,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6385198640281394,
            "auditor_fn_violation": 0.0031376866753661118,
            "auditor_fp_violation": 0.0012835095917363504,
            "ave_precision_score": 0.6362973114052598,
            "fpr": 0.007675438596491228,
            "logloss": 0.6252365622316873,
            "mae": 0.4435604534258968,
            "precision": 0.9444444444444444,
            "recall": 0.24586776859504134
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6002776938152332,
            "auditor_fn_violation": 0.008655440596024955,
            "auditor_fp_violation": 0.0012296173500501554,
            "ave_precision_score": 0.5987582733916208,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6345198317544242,
            "mae": 0.45619994621114596,
            "precision": 0.9777777777777777,
            "recall": 0.18723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.810690588279597,
            "auditor_fn_violation": 0.006116789908655938,
            "auditor_fp_violation": 0.014610489424495823,
            "ave_precision_score": 0.8112756932026424,
            "fpr": 0.13048245614035087,
            "logloss": 0.9113889425753507,
            "mae": 0.26942393281508925,
            "precision": 0.7571428571428571,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8234659969954868,
            "auditor_fn_violation": 0.015528878716397694,
            "auditor_fp_violation": 0.022105732157480632,
            "ave_precision_score": 0.8237270871864893,
            "fpr": 0.12733260153677278,
            "logloss": 0.8611971195506145,
            "mae": 0.2803359889581722,
            "precision": 0.7516059957173448,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6795727958869542,
            "auditor_fn_violation": 0.006588009279396837,
            "auditor_fp_violation": 0.001967535661583867,
            "ave_precision_score": 0.5675354476327725,
            "fpr": 0.023026315789473683,
            "logloss": 0.7098534802978396,
            "mae": 0.4758623927308802,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6382490470798724,
            "auditor_fn_violation": 0.006366630076838651,
            "auditor_fp_violation": 0.0032408133396058755,
            "ave_precision_score": 0.5388645125740775,
            "fpr": 0.020856201975850714,
            "logloss": 0.7184520286980777,
            "mae": 0.484994344634099,
            "precision": 0.7121212121212122,
            "recall": 0.1
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7041797548632572,
            "auditor_fn_violation": 0.0033936856604320814,
            "auditor_fp_violation": 0.0008659206427283167,
            "ave_precision_score": 0.7034440552274577,
            "fpr": 0.010964912280701754,
            "logloss": 0.6590465548529617,
            "mae": 0.4468018702402907,
            "precision": 0.9280575539568345,
            "recall": 0.2665289256198347
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6704463901171084,
            "auditor_fn_violation": 0.006375972160590429,
            "auditor_fp_violation": 0.0018294914013904135,
            "ave_precision_score": 0.6695782883463861,
            "fpr": 0.007683863885839737,
            "logloss": 0.680057451323563,
            "mae": 0.4594222942998982,
            "precision": 0.9391304347826087,
            "recall": 0.2297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8606440831928399,
            "auditor_fn_violation": 0.008076428157169784,
            "auditor_fp_violation": 0.011753976061649454,
            "ave_precision_score": 0.860982771591376,
            "fpr": 0.21929824561403508,
            "logloss": 0.6791492439280342,
            "mae": 0.31209579258626163,
            "precision": 0.6789727126805778,
            "recall": 0.8739669421487604
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.849226299994469,
            "auditor_fn_violation": 0.012798654739939744,
            "auditor_fp_violation": 0.027317915823482714,
            "ave_precision_score": 0.8494715726920379,
            "fpr": 0.20636663007683864,
            "logloss": 0.6731258404313327,
            "mae": 0.31273630920605394,
            "precision": 0.6882255389718076,
            "recall": 0.8829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8117738587796194,
            "auditor_fn_violation": 0.006116789908655938,
            "auditor_fp_violation": 0.015381619937694713,
            "ave_precision_score": 0.8123252421572826,
            "fpr": 0.13157894736842105,
            "logloss": 0.9186292836420406,
            "mae": 0.26869156815464273,
            "precision": 0.7556008146639511,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8239027068720558,
            "auditor_fn_violation": 0.014178947614265362,
            "auditor_fp_violation": 0.022105732157480632,
            "ave_precision_score": 0.8241616354572496,
            "fpr": 0.12733260153677278,
            "logloss": 0.8655161518610172,
            "mae": 0.2796498289204075,
            "precision": 0.7505376344086021,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7132782449067359,
            "auditor_fn_violation": 0.004118638538494993,
            "auditor_fp_violation": 0.02373339891785539,
            "ave_precision_score": 0.7150960817280928,
            "fpr": 0.19078947368421054,
            "logloss": 1.1491099688707156,
            "mae": 0.3381364863467281,
            "precision": 0.6753731343283582,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7317873490553316,
            "auditor_fn_violation": 0.01447789429432235,
            "auditor_fp_violation": 0.026501489728712555,
            "ave_precision_score": 0.7325452041194565,
            "fpr": 0.17892425905598244,
            "logloss": 1.0327600852444865,
            "mae": 0.34541496967921864,
            "precision": 0.6700404858299596,
            "recall": 0.7042553191489361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8017700845629874,
            "auditor_fn_violation": 0.012641365811222275,
            "auditor_fp_violation": 0.015975979668798167,
            "ave_precision_score": 0.8022954635228676,
            "fpr": 0.1611842105263158,
            "logloss": 0.916655300735439,
            "mae": 0.2800767437309339,
            "precision": 0.7252336448598131,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8141734068866593,
            "auditor_fn_violation": 0.019151271691150714,
            "auditor_fp_violation": 0.028798932672227332,
            "ave_precision_score": 0.8144618333697196,
            "fpr": 0.16245883644346873,
            "logloss": 0.8591873445627701,
            "mae": 0.28966381416478226,
            "precision": 0.7115009746588694,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.835528622872012,
            "auditor_fn_violation": 0.0040869218500797526,
            "auditor_fp_violation": 0.015855570585341865,
            "ave_precision_score": 0.8206377065161151,
            "fpr": 0.14583333333333334,
            "logloss": 0.588862266148492,
            "mae": 0.3770184641246471,
            "precision": 0.7302231237322515,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.812533023065171,
            "auditor_fn_violation": 0.02065067613331154,
            "auditor_fp_violation": 0.02522955761155542,
            "ave_precision_score": 0.7967814962679871,
            "fpr": 0.1437980241492865,
            "logloss": 0.5931075772371028,
            "mae": 0.390595381153271,
            "precision": 0.7182795698924731,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8527934955418477,
            "auditor_fn_violation": 0.007358271712338701,
            "auditor_fp_violation": 0.00840301688801443,
            "ave_precision_score": 0.8526693821792634,
            "fpr": 0.15350877192982457,
            "logloss": 0.5761829765670242,
            "mae": 0.34071060609922077,
            "precision": 0.7368421052631579,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8511962090847596,
            "auditor_fn_violation": 0.008788565289487823,
            "auditor_fp_violation": 0.01915365487578127,
            "ave_precision_score": 0.8508785859174572,
            "fpr": 0.141602634467618,
            "logloss": 0.5590043121559488,
            "mae": 0.3502907303993055,
            "precision": 0.7399193548387096,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7964164115897102,
            "auditor_fn_violation": 0.013130709003914746,
            "auditor_fp_violation": 0.013782997212657818,
            "ave_precision_score": 0.7969814412317339,
            "fpr": 0.17214912280701755,
            "logloss": 0.937268289569807,
            "mae": 0.2834664785296872,
            "precision": 0.7140255009107468,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8123741068440584,
            "auditor_fn_violation": 0.017161407852021394,
            "auditor_fp_violation": 0.03142244823286065,
            "ave_precision_score": 0.8126699980216595,
            "fpr": 0.17014270032930845,
            "logloss": 0.8661245021488633,
            "mae": 0.29139993190867375,
            "precision": 0.7036328871892925,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8347301183441085,
            "auditor_fn_violation": 0.013382177033492827,
            "auditor_fp_violation": 0.01673430070503362,
            "ave_precision_score": 0.8351870922037394,
            "fpr": 0.13157894736842105,
            "logloss": 0.8054709176057353,
            "mae": 0.2608561977258892,
            "precision": 0.7595190380761523,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8446916012807273,
            "auditor_fn_violation": 0.02389938575799333,
            "auditor_fp_violation": 0.02514990628523638,
            "ave_precision_score": 0.8449092535167386,
            "fpr": 0.132821075740944,
            "logloss": 0.7648795895105512,
            "mae": 0.26514092774274883,
            "precision": 0.7520491803278688,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8543191331365835,
            "auditor_fn_violation": 0.006479266347687406,
            "auditor_fp_violation": 0.0077164289227742225,
            "ave_precision_score": 0.8538799207687667,
            "fpr": 0.17982456140350878,
            "logloss": 0.6944442063648237,
            "mae": 0.33222710163120117,
            "precision": 0.7117750439367311,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8483493323366208,
            "auditor_fn_violation": 0.012836023074946865,
            "auditor_fp_violation": 0.022267523914066178,
            "ave_precision_score": 0.8479350877582094,
            "fpr": 0.1778265642151482,
            "logloss": 0.664157643750056,
            "mae": 0.33785092671177913,
            "precision": 0.7070524412296564,
            "recall": 0.8319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8054202230854243,
            "auditor_fn_violation": 0.011812200956937805,
            "auditor_fp_violation": 0.01244312592228235,
            "ave_precision_score": 0.805983616973139,
            "fpr": 0.1699561403508772,
            "logloss": 0.9197876205747182,
            "mae": 0.2788693906550113,
            "precision": 0.7171532846715328,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8215880812098184,
            "auditor_fn_violation": 0.01514818880351263,
            "auditor_fp_violation": 0.030508947084139187,
            "ave_precision_score": 0.8218531847401949,
            "fpr": 0.1734357848518112,
            "logloss": 0.8470996597870833,
            "mae": 0.2854938553343006,
            "precision": 0.704119850187266,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.8532258564472902,
            "auditor_fn_violation": 0.0006388647237929535,
            "auditor_fp_violation": 0.0027924659780291976,
            "ave_precision_score": 0.8423541897859556,
            "fpr": 0.46271929824561403,
            "logloss": 5.162322975724211,
            "mae": 0.4638003742113018,
            "precision": 0.5337016574585636,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.8372836529749987,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0028599804356429777,
            "ave_precision_score": 0.8299862744587821,
            "fpr": 0.4774972557628979,
            "logloss": 5.182504553936922,
            "mae": 0.4774810689791436,
            "precision": 0.5193370165745856,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8103290674020298,
            "auditor_fn_violation": 0.008885203711758745,
            "auditor_fp_violation": 0.006430357435645189,
            "ave_precision_score": 0.8108986934584976,
            "fpr": 0.1074561403508772,
            "logloss": 0.8648706550730568,
            "mae": 0.28011555429001533,
            "precision": 0.78125,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.822037457385852,
            "auditor_fn_violation": 0.01887568022047318,
            "auditor_fp_violation": 0.02061226978899866,
            "ave_precision_score": 0.8222949154529294,
            "fpr": 0.10757409440175632,
            "logloss": 0.8397118969319638,
            "mae": 0.29147275235154724,
            "precision": 0.7615571776155717,
            "recall": 0.6659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 21353,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8142127603044751,
            "auditor_fn_violation": 0.006116789908655938,
            "auditor_fp_violation": 0.018471265781275625,
            "ave_precision_score": 0.8147649482213442,
            "fpr": 0.13267543859649122,
            "logloss": 0.9000630602968723,
            "mae": 0.2711153263022399,
            "precision": 0.7540650406504065,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8246516732546341,
            "auditor_fn_violation": 0.01525095172478222,
            "auditor_fp_violation": 0.021824463411416528,
            "ave_precision_score": 0.824902169237819,
            "fpr": 0.12952799121844127,
            "logloss": 0.853047179133787,
            "mae": 0.282129265356757,
            "precision": 0.7484008528784648,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8548601796648836,
            "auditor_fn_violation": 0.006479266347687406,
            "auditor_fp_violation": 0.0077164289227742225,
            "ave_precision_score": 0.8547285766387969,
            "fpr": 0.17982456140350878,
            "logloss": 0.6950264232363703,
            "mae": 0.33248331000734316,
            "precision": 0.7117750439367311,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8486572950254504,
            "auditor_fn_violation": 0.01361608706822057,
            "auditor_fp_violation": 0.022267523914066178,
            "ave_precision_score": 0.848537204520941,
            "fpr": 0.1778265642151482,
            "logloss": 0.6633935375764255,
            "mae": 0.33777952555701973,
            "precision": 0.7065217391304348,
            "recall": 0.8297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.726271150385132,
            "auditor_fn_violation": 0.01437898724082935,
            "auditor_fp_violation": 0.0216326446958518,
            "ave_precision_score": 0.7145377869442656,
            "fpr": 0.24561403508771928,
            "logloss": 1.8438163700141343,
            "mae": 0.33861085397366925,
            "precision": 0.6483516483516484,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7228523048815215,
            "auditor_fn_violation": 0.013541350398206321,
            "auditor_fp_violation": 0.015191001391409106,
            "ave_precision_score": 0.7127363640401364,
            "fpr": 0.2524698133918771,
            "logloss": 1.7191065152014198,
            "mae": 0.3498358995464626,
            "precision": 0.6337579617834395,
            "recall": 0.8468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7281387975205333,
            "auditor_fn_violation": 0.013382177033492827,
            "auditor_fp_violation": 0.017543859649122806,
            "ave_precision_score": 0.7176139190832186,
            "fpr": 0.23464912280701755,
            "logloss": 1.7752788535892388,
            "mae": 0.3345988691097087,
            "precision": 0.6565008025682183,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7240683047500462,
            "auditor_fn_violation": 0.013812270827007969,
            "auditor_fp_violation": 0.012843776368944949,
            "ave_precision_score": 0.7141672956048299,
            "fpr": 0.23929747530186607,
            "logloss": 1.6840783391627334,
            "mae": 0.3463301897378261,
            "precision": 0.6437908496732027,
            "recall": 0.8382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.692250022519187,
            "auditor_fn_violation": 0.019079853559518644,
            "auditor_fp_violation": 0.012983685850139367,
            "ave_precision_score": 0.6941754673813536,
            "fpr": 0.14035087719298245,
            "logloss": 0.9649065911820269,
            "mae": 0.3420676006968698,
            "precision": 0.7180616740088106,
            "recall": 0.6735537190082644
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7013698649361235,
            "auditor_fn_violation": 0.03611883130532265,
            "auditor_fp_violation": 0.02037082670609408,
            "ave_precision_score": 0.7032703612461237,
            "fpr": 0.13172338090010977,
            "logloss": 0.9035851609696794,
            "mae": 0.34953519660051063,
            "precision": 0.7122302158273381,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7145784829629241,
            "auditor_fn_violation": 0.0026959185152965093,
            "auditor_fp_violation": 0.013770187735694382,
            "ave_precision_score": 0.7020586295855213,
            "fpr": 0.22478070175438597,
            "logloss": 1.9340652094061757,
            "mae": 0.34014218624166426,
            "precision": 0.6622734761120264,
            "recall": 0.8305785123966942
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7099260498087259,
            "auditor_fn_violation": 0.008685802368218231,
            "auditor_fp_violation": 0.0013515834434761954,
            "ave_precision_score": 0.6990846837356562,
            "fpr": 0.24039517014270034,
            "logloss": 1.770789118040492,
            "mae": 0.3566513368939116,
            "precision": 0.6409836065573771,
            "recall": 0.8319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 21353,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7995127560328951,
            "auditor_fn_violation": 0.006320682905611137,
            "auditor_fp_violation": 0.01320913264469586,
            "ave_precision_score": 0.7998664774126854,
            "fpr": 0.20394736842105263,
            "logloss": 0.8146428858514045,
            "mae": 0.3436682027266279,
            "precision": 0.6836734693877551,
            "recall": 0.8305785123966942
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7812783227954253,
            "auditor_fn_violation": 0.009309386458649602,
            "auditor_fp_violation": 0.02969003188542157,
            "ave_precision_score": 0.7817934497589049,
            "fpr": 0.19209659714599342,
            "logloss": 0.7912889138866405,
            "mae": 0.3473403501793595,
            "precision": 0.691358024691358,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8557034379366674,
            "auditor_fn_violation": 0.005403164419312751,
            "auditor_fp_violation": 0.005543941629775378,
            "ave_precision_score": 0.8555677107574897,
            "fpr": 0.17982456140350878,
            "logloss": 0.69643672087521,
            "mae": 0.3309975614313755,
            "precision": 0.7117750439367311,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8476748298679413,
            "auditor_fn_violation": 0.013749211761683443,
            "auditor_fp_violation": 0.02582943166289568,
            "ave_precision_score": 0.8472514241762694,
            "fpr": 0.1778265642151482,
            "logloss": 0.6668478842956509,
            "mae": 0.33740473712020597,
            "precision": 0.7070524412296564,
            "recall": 0.8319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.8579755745979395,
            "auditor_fn_violation": 0.0006388647237929535,
            "auditor_fp_violation": 0.0027924659780291976,
            "ave_precision_score": 0.8525785522080408,
            "fpr": 0.46271929824561403,
            "logloss": 4.294376278611254,
            "mae": 0.463738830073768,
            "precision": 0.5337016574585636,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.8503402387205516,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0028599804356429777,
            "ave_precision_score": 0.8475626229822368,
            "fpr": 0.4774972557628979,
            "logloss": 4.3003724167646995,
            "mae": 0.4774141576515483,
            "precision": 0.5193370165745856,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8087367681018868,
            "auditor_fn_violation": 0.008894265622734522,
            "auditor_fp_violation": 0.009891478111165766,
            "ave_precision_score": 0.8093322446604978,
            "fpr": 0.10635964912280702,
            "logloss": 0.8647302977402378,
            "mae": 0.2812457883601203,
            "precision": 0.781038374717833,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8215801065963988,
            "auditor_fn_violation": 0.019151271691150714,
            "auditor_fp_violation": 0.018476618602069447,
            "ave_precision_score": 0.8218402173077594,
            "fpr": 0.10647639956092206,
            "logloss": 0.8407981533934717,
            "mae": 0.292055738490617,
            "precision": 0.7628361858190709,
            "recall": 0.6638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 21353,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7698988965587137,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01416215773077554,
            "ave_precision_score": 0.6762192563307186,
            "fpr": 0.11951754385964912,
            "logloss": 3.560620472165291,
            "mae": 0.39707126716772717,
            "precision": 0.7275,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7554736148647041,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6620361445492304,
            "fpr": 0.1119648737650933,
            "logloss": 3.2727187901496477,
            "mae": 0.41116930516569594,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8558325274219427,
            "auditor_fn_violation": 0.005403164419312751,
            "auditor_fp_violation": 0.005543941629775378,
            "ave_precision_score": 0.8551316452624165,
            "fpr": 0.17982456140350878,
            "logloss": 0.7136785141972039,
            "mae": 0.33003853650338816,
            "precision": 0.7117750439367311,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8485245581379828,
            "auditor_fn_violation": 0.013749211761683443,
            "auditor_fp_violation": 0.02582943166289568,
            "ave_precision_score": 0.8481443700693184,
            "fpr": 0.1778265642151482,
            "logloss": 0.681603808879545,
            "mae": 0.33612292406326066,
            "precision": 0.7070524412296564,
            "recall": 0.8319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 21353,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.679469698519499,
            "auditor_fn_violation": 0.011463317384370023,
            "auditor_fp_violation": 0.012927324151500254,
            "ave_precision_score": 0.6802236696427655,
            "fpr": 0.17434210526315788,
            "logloss": 1.1737414767874255,
            "mae": 0.347754846289685,
            "precision": 0.6888454011741683,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6898976903900378,
            "auditor_fn_violation": 0.02784408062218278,
            "auditor_fp_violation": 0.022075862910110995,
            "ave_precision_score": 0.6904980044745782,
            "fpr": 0.1690450054884742,
            "logloss": 1.0451589321909258,
            "mae": 0.35099199445539936,
            "precision": 0.6798336798336798,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8027506351765645,
            "auditor_fn_violation": 0.012643631288966216,
            "auditor_fp_violation": 0.011497786522380716,
            "ave_precision_score": 0.8033575069899,
            "fpr": 0.17105263157894737,
            "logloss": 0.9290810520528557,
            "mae": 0.28160224730968825,
            "precision": 0.7148080438756855,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8168490225049774,
            "auditor_fn_violation": 0.0160403578018077,
            "auditor_fp_violation": 0.029301731669616252,
            "ave_precision_score": 0.8171293199999252,
            "fpr": 0.16794731064763996,
            "logloss": 0.8559699162535085,
            "mae": 0.2891794603130928,
            "precision": 0.7091254752851711,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.824318969766062,
            "auditor_fn_violation": 0.0038467812092214076,
            "auditor_fp_violation": 0.009435460731267421,
            "ave_precision_score": 0.8078778065981751,
            "fpr": 0.13267543859649122,
            "logloss": 0.5823533994319954,
            "mae": 0.3767650881945564,
            "precision": 0.7363834422657952,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.796840608164367,
            "auditor_fn_violation": 0.02106639886026579,
            "auditor_fp_violation": 0.02515737359707879,
            "ave_precision_score": 0.779612631847321,
            "fpr": 0.132821075740944,
            "logloss": 0.5935714369654169,
            "mae": 0.3917339353215943,
            "precision": 0.7192575406032483,
            "recall": 0.6595744680851063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8350767184777677,
            "auditor_fn_violation": 0.003255491518051329,
            "auditor_fp_violation": 0.014997335628791611,
            "ave_precision_score": 0.8185879172080456,
            "fpr": 0.14144736842105263,
            "logloss": 0.5721810842470955,
            "mae": 0.3692609626767144,
            "precision": 0.735655737704918,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8123313376967575,
            "auditor_fn_violation": 0.020776794263960587,
            "auditor_fp_violation": 0.02817665668535984,
            "ave_precision_score": 0.7950991852903118,
            "fpr": 0.1394072447859495,
            "logloss": 0.5784917330401239,
            "mae": 0.38233933587171115,
            "precision": 0.7233115468409586,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8097185844450845,
            "auditor_fn_violation": 0.005083732057416269,
            "auditor_fp_violation": 0.004698516150188555,
            "ave_precision_score": 0.8102124790072287,
            "fpr": 0.11074561403508772,
            "logloss": 0.9083356395120663,
            "mae": 0.28093320906706515,
            "precision": 0.7770419426048565,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8201644652430773,
            "auditor_fn_violation": 0.01881262115514866,
            "auditor_fp_violation": 0.021446119611401103,
            "ave_precision_score": 0.8204267712374547,
            "fpr": 0.11306256860592755,
            "logloss": 0.869888028941853,
            "mae": 0.29154245630754283,
            "precision": 0.7535885167464115,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8107648846142824,
            "auditor_fn_violation": 0.009999818761780488,
            "auditor_fp_violation": 0.01038848581734711,
            "ave_precision_score": 0.811331944359622,
            "fpr": 0.10635964912280702,
            "logloss": 0.8617231907092864,
            "mae": 0.2804550132300183,
            "precision": 0.7825112107623319,
            "recall": 0.7210743801652892
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8221872279501685,
            "auditor_fn_violation": 0.023037578531891537,
            "auditor_fp_violation": 0.02049030369557264,
            "ave_precision_score": 0.8224438281770442,
            "fpr": 0.10757409440175632,
            "logloss": 0.8386308831060263,
            "mae": 0.29189013498483807,
            "precision": 0.7603911980440098,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8112594905555988,
            "auditor_fn_violation": 0.010321516601420909,
            "auditor_fp_violation": 0.004626783079193311,
            "ave_precision_score": 0.8116742383358041,
            "fpr": 0.11951754385964912,
            "logloss": 0.9010820545104699,
            "mae": 0.28205093292857436,
            "precision": 0.7655913978494624,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8212293198862869,
            "auditor_fn_violation": 0.02710372048485414,
            "auditor_fp_violation": 0.02131668620613266,
            "ave_precision_score": 0.8214906101451096,
            "fpr": 0.1163556531284303,
            "logloss": 0.8625395910147466,
            "mae": 0.2887770378206038,
            "precision": 0.7540603248259861,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7516449186853287,
            "auditor_fn_violation": 0.005817746846454986,
            "auditor_fp_violation": 0.015166420724708977,
            "ave_precision_score": 0.6875935532891855,
            "fpr": 0.12171052631578948,
            "logloss": 3.5126818199871517,
            "mae": 0.3890900832453841,
            "precision": 0.7312348668280871,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7340763899405992,
            "auditor_fn_violation": 0.017591143704603313,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6747836883676256,
            "fpr": 0.1119648737650933,
            "logloss": 3.2128667341164556,
            "mae": 0.4036754893157406,
            "precision": 0.7235772357723578,
            "recall": 0.5680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7307623323147707,
            "auditor_fn_violation": 0.01325757575757576,
            "auditor_fp_violation": 0.008054599114608953,
            "ave_precision_score": 0.7202465476738097,
            "fpr": 0.22149122807017543,
            "logloss": 1.7235799680277988,
            "mae": 0.3310337889630765,
            "precision": 0.6672158154859967,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7269144135485108,
            "auditor_fn_violation": 0.014017796669547144,
            "auditor_fp_violation": 0.01161913722678973,
            "ave_precision_score": 0.7176507088329916,
            "fpr": 0.23380900109769484,
            "logloss": 1.6128703641446287,
            "mae": 0.3455778072089707,
            "precision": 0.6473509933774835,
            "recall": 0.8319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.8130571073984089,
            "auditor_fn_violation": 0.0021204871683340567,
            "auditor_fp_violation": 0.0017113461223151336,
            "ave_precision_score": 0.7493815446970398,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6967836371136488,
            "mae": 0.4717429478391351,
            "precision": 0.9607843137254902,
            "recall": 0.2024793388429752
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.7933694912499694,
            "auditor_fn_violation": 0.004528575098675787,
            "auditor_fp_violation": 0.0007019273131865261,
            "ave_precision_score": 0.7189865188889824,
            "fpr": 0.003293084522502744,
            "logloss": 0.7036068408623037,
            "mae": 0.48011278834615134,
            "precision": 0.9594594594594594,
            "recall": 0.15106382978723404
        }
    }
]