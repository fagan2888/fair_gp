[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8389386710426822,
            "auditor_fn_violation": 0.006382560879811467,
            "auditor_fp_violation": 0.009895647697120907,
            "ave_precision_score": 0.8392317624106311,
            "fpr": 0.08881578947368421,
            "logloss": 0.7064405921589507,
            "mae": 0.28089643476944537,
            "precision": 0.7954545454545454,
            "recall": 0.6716417910447762
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8584338602380057,
            "auditor_fn_violation": 0.006156144261998264,
            "auditor_fp_violation": 0.007673556892029086,
            "ave_precision_score": 0.8586696640112241,
            "fpr": 0.08122941822173436,
            "logloss": 0.6822849352684465,
            "mae": 0.26528123900916156,
            "precision": 0.8190709046454768,
            "recall": 0.6907216494845361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8524191409051103,
            "auditor_fn_violation": 0.009295627127520294,
            "auditor_fp_violation": 0.013212348025820761,
            "ave_precision_score": 0.8526379248338205,
            "fpr": 0.13925438596491227,
            "logloss": 0.5248364321183849,
            "mae": 0.29727995805354257,
            "precision": 0.7413441955193483,
            "recall": 0.7761194029850746
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8711532490569985,
            "auditor_fn_violation": 0.009456018649495851,
            "auditor_fp_violation": 0.01030441706219756,
            "ave_precision_score": 0.871373140465118,
            "fpr": 0.12843029637760703,
            "logloss": 0.4909990509833238,
            "mae": 0.27842504760359327,
            "precision": 0.7723735408560312,
            "recall": 0.8185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7303341234307115,
            "auditor_fn_violation": 0.02180591403882842,
            "auditor_fp_violation": 0.02411538156904677,
            "ave_precision_score": 0.730934146545152,
            "fpr": 0.1611842105263158,
            "logloss": 0.7138781786059574,
            "mae": 0.39016227892639177,
            "precision": 0.6711409395973155,
            "recall": 0.6396588486140725
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7458277933783563,
            "auditor_fn_violation": 0.033157174058189146,
            "auditor_fp_violation": 0.021057188355158393,
            "ave_precision_score": 0.7466900092367609,
            "fpr": 0.14709110867178923,
            "logloss": 0.6812026073462203,
            "mae": 0.3794785345859927,
            "precision": 0.7074235807860262,
            "recall": 0.668041237113402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7794147724130361,
            "auditor_fn_violation": 0.002333258519432912,
            "auditor_fp_violation": 0.028031068076511827,
            "ave_precision_score": 0.7797770302010587,
            "fpr": 0.15460526315789475,
            "logloss": 0.6959430943707641,
            "mae": 0.35270056826208734,
            "precision": 0.6873614190687362,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7840729538770445,
            "auditor_fn_violation": 0.00595244831215274,
            "auditor_fp_violation": 0.020722211056312268,
            "ave_precision_score": 0.7848924732854677,
            "fpr": 0.132821075740944,
            "logloss": 0.6798032260509753,
            "mae": 0.35001967853330757,
            "precision": 0.7268623024830699,
            "recall": 0.6639175257731958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8327703745898891,
            "auditor_fn_violation": 0.0184930610107358,
            "auditor_fp_violation": 0.009435269890301374,
            "ave_precision_score": 0.8332681914134549,
            "fpr": 0.12171052631578948,
            "logloss": 0.5106893192153401,
            "mae": 0.31381710058511153,
            "precision": 0.7648305084745762,
            "recall": 0.7697228144989339
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8635875617057112,
            "auditor_fn_violation": 0.015410730249980199,
            "auditor_fp_violation": 0.010020974732404675,
            "ave_precision_score": 0.8638604559161895,
            "fpr": 0.09330406147091108,
            "logloss": 0.47647209763962395,
            "mae": 0.2946219598433835,
            "precision": 0.816414686825054,
            "recall": 0.7793814432989691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7897131501377032,
            "auditor_fn_violation": 0.022993584708038757,
            "auditor_fp_violation": 0.02457080907686825,
            "ave_precision_score": 0.7576203505978046,
            "fpr": 0.13706140350877194,
            "logloss": 3.5066400663274018,
            "mae": 0.27595560931371116,
            "precision": 0.7373949579831933,
            "recall": 0.7484008528784648
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7888519662404236,
            "auditor_fn_violation": 0.022868265302658237,
            "auditor_fp_violation": 0.018722654257046126,
            "ave_precision_score": 0.7548726402390614,
            "fpr": 0.13172338090010977,
            "logloss": 3.656493941787131,
            "mae": 0.2795980468788008,
            "precision": 0.7520661157024794,
            "recall": 0.7505154639175258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 29198,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7599614919875293,
            "auditor_fn_violation": 0.024508566191598403,
            "auditor_fp_violation": 0.02622420894222011,
            "ave_precision_score": 0.7604901121728973,
            "fpr": 0.13925438596491227,
            "logloss": 0.6668004190338005,
            "mae": 0.37362422441395293,
            "precision": 0.7060185185185185,
            "recall": 0.650319829424307
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7784234439635382,
            "auditor_fn_violation": 0.03231975737549086,
            "auditor_fp_violation": 0.018050122910901193,
            "ave_precision_score": 0.7792161366283573,
            "fpr": 0.1350164654226125,
            "logloss": 0.6306497894579679,
            "mae": 0.36255853401729454,
            "precision": 0.7272727272727273,
            "recall": 0.6762886597938145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8453461801654061,
            "auditor_fn_violation": 0.013616129876931136,
            "auditor_fp_violation": 0.01560581759138252,
            "ave_precision_score": 0.8456183956678995,
            "fpr": 0.07675438596491228,
            "logloss": 0.6486827758177407,
            "mae": 0.2806595374857855,
            "precision": 0.8148148148148148,
            "recall": 0.6567164179104478
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8568679291904455,
            "auditor_fn_violation": 0.01885319180236967,
            "auditor_fp_violation": 0.014316414402993152,
            "ave_precision_score": 0.8571453100374862,
            "fpr": 0.07683863885839737,
            "logloss": 0.6340323410897966,
            "mae": 0.2677907340210779,
            "precision": 0.8292682926829268,
            "recall": 0.7010309278350515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8440291225903884,
            "auditor_fn_violation": 0.009008061197770551,
            "auditor_fp_violation": 0.017318621044711102,
            "ave_precision_score": 0.8442358981849092,
            "fpr": 0.14912280701754385,
            "logloss": 0.5640158854411101,
            "mae": 0.31206808382921736,
            "precision": 0.7252525252525253,
            "recall": 0.7654584221748401
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8532245129849318,
            "auditor_fn_violation": 0.01673475392397615,
            "auditor_fp_violation": 0.020196554371969107,
            "ave_precision_score": 0.8534973183280496,
            "fpr": 0.13391877058177826,
            "logloss": 0.5523523595828518,
            "mae": 0.2950293984380806,
            "precision": 0.7603143418467584,
            "recall": 0.797938144329897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6879078391756557,
            "auditor_fn_violation": 0.046487487375154304,
            "auditor_fp_violation": 0.036533206605678985,
            "ave_precision_score": 0.6886233239179353,
            "fpr": 0.10307017543859649,
            "logloss": 0.8749902353774672,
            "mae": 0.4107812184057733,
            "precision": 0.6897689768976898,
            "recall": 0.44562899786780386
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7210813878626308,
            "auditor_fn_violation": 0.050874195118087086,
            "auditor_fp_violation": 0.025664414588519043,
            "ave_precision_score": 0.7220957265165904,
            "fpr": 0.08562019758507135,
            "logloss": 0.8352450441993998,
            "mae": 0.3990124043701286,
            "precision": 0.7523809523809524,
            "recall": 0.488659793814433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7174835104323232,
            "auditor_fn_violation": 0.05293784835222385,
            "auditor_fp_violation": 0.030813136113421253,
            "ave_precision_score": 0.7181065789240402,
            "fpr": 0.09868421052631579,
            "logloss": 0.786116401171492,
            "mae": 0.39646890035510296,
            "precision": 0.7204968944099379,
            "recall": 0.4946695095948827
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7613101819493899,
            "auditor_fn_violation": 0.05272103839668654,
            "auditor_fp_violation": 0.020232628850306376,
            "ave_precision_score": 0.7618874542851926,
            "fpr": 0.08122941822173436,
            "logloss": 0.7523395626738718,
            "mae": 0.3844211003848538,
            "precision": 0.7708978328173375,
            "recall": 0.51340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.648272461556361,
            "auditor_fn_violation": 0.04799545505554932,
            "auditor_fp_violation": 0.040344936834184796,
            "ave_precision_score": 0.6491674768665026,
            "fpr": 0.1513157894736842,
            "logloss": 0.8676012388362484,
            "mae": 0.42624157308978683,
            "precision": 0.6358839050131926,
            "recall": 0.5138592750533049
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6832336280243341,
            "auditor_fn_violation": 0.05685380289021919,
            "auditor_fp_violation": 0.032281504614956484,
            "ave_precision_score": 0.6839083746756724,
            "fpr": 0.14818880351262348,
            "logloss": 0.8505655023123869,
            "mae": 0.41890182493723654,
            "precision": 0.6625,
            "recall": 0.5463917525773195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6976127022315162,
            "auditor_fn_violation": 0.03314021995286725,
            "auditor_fp_violation": 0.03188240069700211,
            "ave_precision_score": 0.6983489300831422,
            "fpr": 0.14692982456140352,
            "logloss": 0.7143629892238202,
            "mae": 0.40067057306231235,
            "precision": 0.6817102137767221,
            "recall": 0.6119402985074627
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7350862869956136,
            "auditor_fn_violation": 0.037102085620197595,
            "auditor_fp_violation": 0.017022000278288835,
            "ave_precision_score": 0.7358785349708952,
            "fpr": 0.11855104281009879,
            "logloss": 0.6666884405455559,
            "mae": 0.39190142596432503,
            "precision": 0.7293233082706767,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7322298015879103,
            "auditor_fn_violation": 0.00991751767478399,
            "auditor_fp_violation": 0.0077001900914815255,
            "ave_precision_score": 0.7330439656295811,
            "fpr": 0.039473684210526314,
            "logloss": 0.8381455953773354,
            "mae": 0.39849771000206013,
            "precision": 0.8235294117647058,
            "recall": 0.3582089552238806
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7529934424229292,
            "auditor_fn_violation": 0.0033632464607828727,
            "auditor_fp_violation": 0.010327607798271519,
            "ave_precision_score": 0.7537577679617099,
            "fpr": 0.04061470911086718,
            "logloss": 0.7402468910852211,
            "mae": 0.3958768034959089,
            "precision": 0.8432203389830508,
            "recall": 0.41030927835051545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6426544894191248,
            "auditor_fn_violation": 0.037135749822317,
            "auditor_fp_violation": 0.036580234446160556,
            "ave_precision_score": 0.6435127566925448,
            "fpr": 0.14692982456140352,
            "logloss": 0.8707827665699465,
            "mae": 0.43232622593482994,
            "precision": 0.6426666666666667,
            "recall": 0.5138592750533049
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.680871553310266,
            "auditor_fn_violation": 0.04478594950603733,
            "auditor_fp_violation": 0.027169235684873973,
            "ave_precision_score": 0.6815570470663596,
            "fpr": 0.13721185510428102,
            "logloss": 0.8463242458498871,
            "mae": 0.4244669197441838,
            "precision": 0.6727748691099477,
            "recall": 0.5298969072164949
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7929147605095349,
            "auditor_fn_violation": 0.02251197022406764,
            "auditor_fp_violation": 0.028870143756682908,
            "ave_precision_score": 0.79366824723755,
            "fpr": 0.14692982456140352,
            "logloss": 0.8372550591274573,
            "mae": 0.27899928309115024,
            "precision": 0.7298387096774194,
            "recall": 0.7718550106609808
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7785075918624497,
            "auditor_fn_violation": 0.023961433566829247,
            "auditor_fp_violation": 0.024803780605329746,
            "ave_precision_score": 0.7792904153137123,
            "fpr": 0.12952799121844127,
            "logloss": 0.9030507652554984,
            "mae": 0.2744283092607331,
            "precision": 0.756701030927835,
            "recall": 0.756701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8441490829819773,
            "auditor_fn_violation": 0.026979762839935664,
            "auditor_fp_violation": 0.017321096194210135,
            "ave_precision_score": 0.8443707015613908,
            "fpr": 0.06578947368421052,
            "logloss": 0.6153526369423707,
            "mae": 0.3083153558445542,
            "precision": 0.8275862068965517,
            "recall": 0.6140724946695096
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8582352087932713,
            "auditor_fn_violation": 0.030626817703441337,
            "auditor_fp_violation": 0.015530062924197218,
            "ave_precision_score": 0.8585088826823315,
            "fpr": 0.05598243688254665,
            "logloss": 0.5821966070622635,
            "mae": 0.2963732774833291,
            "precision": 0.856338028169014,
            "recall": 0.6268041237113402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6523100010377487,
            "auditor_fn_violation": 0.033247764934724866,
            "auditor_fp_violation": 0.028409765949863372,
            "ave_precision_score": 0.6530450782784265,
            "fpr": 0.13925438596491227,
            "logloss": 0.8821389160876465,
            "mae": 0.42907914514819967,
            "precision": 0.6530054644808743,
            "recall": 0.509594882729211
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6621932281222301,
            "auditor_fn_violation": 0.04456188396120724,
            "auditor_fp_violation": 0.015073978448075943,
            "ave_precision_score": 0.6638058703345547,
            "fpr": 0.11964873765093303,
            "logloss": 0.8996018935270487,
            "mae": 0.41850726524285886,
            "precision": 0.7093333333333334,
            "recall": 0.5484536082474227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.728960231822988,
            "auditor_fn_violation": 0.031122582575842588,
            "auditor_fp_violation": 0.03258286800522752,
            "ave_precision_score": 0.721701143864576,
            "fpr": 0.1337719298245614,
            "logloss": 1.2045686537197948,
            "mae": 0.311492584840747,
            "precision": 0.7431578947368421,
            "recall": 0.7526652452025586
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7296746142078127,
            "auditor_fn_violation": 0.029123994251247648,
            "auditor_fp_violation": 0.034260447426601316,
            "ave_precision_score": 0.7234793262316991,
            "fpr": 0.1251372118551043,
            "logloss": 1.2269160603341813,
            "mae": 0.3109312848011379,
            "precision": 0.7584745762711864,
            "recall": 0.7381443298969073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6782374939795914,
            "auditor_fn_violation": 0.0405935547824786,
            "auditor_fp_violation": 0.035414439032117544,
            "ave_precision_score": 0.6789876019220566,
            "fpr": 0.11074561403508772,
            "logloss": 0.8193429964421506,
            "mae": 0.41534830096178776,
            "precision": 0.6833855799373041,
            "recall": 0.464818763326226
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.719442399481237,
            "auditor_fn_violation": 0.04646530944809715,
            "auditor_fp_violation": 0.026290564462516045,
            "ave_precision_score": 0.7200233438401178,
            "fpr": 0.09549945115257959,
            "logloss": 0.7864464570374119,
            "mae": 0.4058846702609946,
            "precision": 0.7339449541284404,
            "recall": 0.4948453608247423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.5656268603170195,
            "auditor_fn_violation": 0.0677065798825422,
            "auditor_fp_violation": 0.07195012078729555,
            "ave_precision_score": 0.5614376846304936,
            "fpr": 0.2730263157894737,
            "logloss": 2.4195989890974885,
            "mae": 0.409253161989089,
            "precision": 0.5870646766169154,
            "recall": 0.7547974413646056
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.5886408321702717,
            "auditor_fn_violation": 0.0731291092828771,
            "auditor_fp_violation": 0.06961858969403688,
            "ave_precision_score": 0.5849561165220099,
            "fpr": 0.25905598243688255,
            "logloss": 2.1938313992109424,
            "mae": 0.4123373272145273,
            "precision": 0.5951972555746141,
            "recall": 0.7154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7879358891983861,
            "auditor_fn_violation": 0.016751299891519845,
            "auditor_fp_violation": 0.01897944635856006,
            "ave_precision_score": 0.7538668375617487,
            "fpr": 0.1162280701754386,
            "logloss": 3.69610594239075,
            "mae": 0.28717444274214443,
            "precision": 0.7540603248259861,
            "recall": 0.6929637526652452
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7884453258805988,
            "auditor_fn_violation": 0.00544094514920729,
            "auditor_fp_violation": 0.01265956514793113,
            "ave_precision_score": 0.7521356184296728,
            "fpr": 0.11306256860592755,
            "logloss": 3.8401172914838106,
            "mae": 0.2806311447150003,
            "precision": 0.774617067833698,
            "recall": 0.7298969072164948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6138361445291659,
            "auditor_fn_violation": 0.01650347884636966,
            "auditor_fp_violation": 0.009927824640608304,
            "ave_precision_score": 0.6089544471912137,
            "fpr": 0.16776315789473684,
            "logloss": 2.798492730002176,
            "mae": 0.3660436999100432,
            "precision": 0.6858316221765913,
            "recall": 0.7121535181236673
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6655256151911265,
            "auditor_fn_violation": 0.01783018547647878,
            "auditor_fp_violation": 0.00674850419752324,
            "ave_precision_score": 0.6601758806863118,
            "fpr": 0.141602634467618,
            "logloss": 2.2729575183802515,
            "mae": 0.338589212598959,
            "precision": 0.7378048780487805,
            "recall": 0.7484536082474227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8293596018266188,
            "auditor_fn_violation": 0.022409101110986422,
            "auditor_fp_violation": 0.02626628648370362,
            "ave_precision_score": 0.829688540937372,
            "fpr": 0.12828947368421054,
            "logloss": 0.8482029489289025,
            "mae": 0.27276371468372496,
            "precision": 0.7510638297872341,
            "recall": 0.7526652452025586
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8119002690734433,
            "auditor_fn_violation": 0.025394095080742814,
            "auditor_fp_violation": 0.019851270079312325,
            "ave_precision_score": 0.8123938460645053,
            "fpr": 0.12184412733260154,
            "logloss": 0.8811867854999228,
            "mae": 0.27336505635843067,
            "precision": 0.7668067226890757,
            "recall": 0.7525773195876289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6365713834461217,
            "auditor_fn_violation": 0.01596809187146972,
            "auditor_fp_violation": 0.016053819650706902,
            "ave_precision_score": 0.6374685016299089,
            "fpr": 0.2894736842105263,
            "logloss": 0.8405241012116011,
            "mae": 0.43049882706661646,
            "precision": 0.580952380952381,
            "recall": 0.7803837953091685
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6453013556745706,
            "auditor_fn_violation": 0.013923749816107826,
            "auditor_fp_violation": 0.019304999407347864,
            "ave_precision_score": 0.6469328716921504,
            "fpr": 0.26125137211855104,
            "logloss": 0.8627977124645155,
            "mae": 0.4242188242001902,
            "precision": 0.6167471819645732,
            "recall": 0.7896907216494845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7866430127535944,
            "auditor_fn_violation": 0.01493706280626941,
            "auditor_fp_violation": 0.031689339036077784,
            "ave_precision_score": 0.7529110386044867,
            "fpr": 0.17543859649122806,
            "logloss": 3.7488718098073504,
            "mae": 0.2850336742906414,
            "precision": 0.696969696969697,
            "recall": 0.7846481876332623
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7848991849867932,
            "auditor_fn_violation": 0.011766836036076818,
            "auditor_fp_violation": 0.01985127007931232,
            "ave_precision_score": 0.7475010601174621,
            "fpr": 0.1690450054884742,
            "logloss": 3.9189442202946685,
            "mae": 0.28435932581161255,
            "precision": 0.7126865671641791,
            "recall": 0.7876288659793814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.698281545604194,
            "auditor_fn_violation": 0.021738113941570353,
            "auditor_fp_violation": 0.027404855253257296,
            "ave_precision_score": 0.6995478483796012,
            "fpr": 0.1611842105263158,
            "logloss": 0.7993663626737777,
            "mae": 0.3497444059616518,
            "precision": 0.6943866943866944,
            "recall": 0.7121535181236673
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.71200679823247,
            "auditor_fn_violation": 0.012878110606900766,
            "auditor_fp_violation": 0.00899285209979232,
            "ave_precision_score": 0.7133836184037083,
            "fpr": 0.14928649835345773,
            "logloss": 0.7872361143910797,
            "mae": 0.334888951710376,
            "precision": 0.7312252964426877,
            "recall": 0.7628865979381443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8164664004701329,
            "auditor_fn_violation": 0.025403995062282574,
            "auditor_fp_violation": 0.02380103758267,
            "ave_precision_score": 0.8167297464959636,
            "fpr": 0.14364035087719298,
            "logloss": 0.6296332458848902,
            "mae": 0.33155841529814845,
            "precision": 0.7247899159663865,
            "recall": 0.7356076759061834
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8294562017426288,
            "auditor_fn_violation": 0.024128916903368908,
            "auditor_fp_violation": 0.01741624279154621,
            "ave_precision_score": 0.8297250181785962,
            "fpr": 0.12843029637760703,
            "logloss": 0.6156634881214118,
            "mae": 0.3168872893376697,
            "precision": 0.7602459016393442,
            "recall": 0.7649484536082474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7691873277367482,
            "auditor_fn_violation": 0.03389537276025886,
            "auditor_fp_violation": 0.023328284028355312,
            "ave_precision_score": 0.7695617991534307,
            "fpr": 0.10964912280701754,
            "logloss": 0.7003073452228212,
            "mae": 0.36717699265723797,
            "precision": 0.7442455242966752,
            "recall": 0.6204690831556503
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8073275491093925,
            "auditor_fn_violation": 0.04422012742313307,
            "auditor_fp_violation": 0.023329880490406765,
            "ave_precision_score": 0.8076374010430134,
            "fpr": 0.09549945115257959,
            "logloss": 0.6511410212420768,
            "mae": 0.34717398579925646,
            "precision": 0.7851851851851852,
            "recall": 0.6556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6522609840456222,
            "auditor_fn_violation": 0.051376108180900014,
            "auditor_fp_violation": 0.04262949982178924,
            "ave_precision_score": 0.6530974582722088,
            "fpr": 0.12171052631578948,
            "logloss": 0.9894771818603282,
            "mae": 0.42550516600840743,
            "precision": 0.6595092024539877,
            "recall": 0.4584221748400853
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6898641258630156,
            "auditor_fn_violation": 0.054079011395656754,
            "auditor_fp_violation": 0.029459965059290983,
            "ave_precision_score": 0.690784172311927,
            "fpr": 0.10428100987925357,
            "logloss": 0.919217519268147,
            "mae": 0.41544612195112807,
            "precision": 0.7181008902077152,
            "recall": 0.49896907216494846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8361280115818426,
            "auditor_fn_violation": 0.02249326674896196,
            "auditor_fp_violation": 0.027706823492138932,
            "ave_precision_score": 0.836416074781416,
            "fpr": 0.11293859649122807,
            "logloss": 0.7930165840593402,
            "mae": 0.2705692090432475,
            "precision": 0.7706013363028953,
            "recall": 0.7377398720682303
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8241284960260759,
            "auditor_fn_violation": 0.02059818710604638,
            "auditor_fp_violation": 0.018848914931226587,
            "ave_precision_score": 0.8245885295812132,
            "fpr": 0.11086717892425905,
            "logloss": 0.8040441237666179,
            "mae": 0.26937831163508197,
            "precision": 0.7823275862068966,
            "recall": 0.7484536082474227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 29198,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7837784679658291,
            "auditor_fn_violation": 0.01843695058541878,
            "auditor_fp_violation": 0.019385370876400944,
            "ave_precision_score": 0.7596577929390763,
            "fpr": 0.12719298245614036,
            "logloss": 2.896816524434005,
            "mae": 0.2838024201612632,
            "precision": 0.7456140350877193,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7825049672250062,
            "auditor_fn_violation": 0.016239093779352023,
            "auditor_fp_violation": 0.01696788856078292,
            "ave_precision_score": 0.7546987811802635,
            "fpr": 0.12403951701427003,
            "logloss": 3.157354481888739,
            "mae": 0.2895644751600757,
            "precision": 0.7600849256900213,
            "recall": 0.7381443298969073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8447273849746691,
            "auditor_fn_violation": 0.007897542363371115,
            "auditor_fp_violation": 0.022781275989069743,
            "ave_precision_score": 0.8449502936464505,
            "fpr": 0.1699561403508772,
            "logloss": 0.5796623220139073,
            "mae": 0.3014259429857798,
            "precision": 0.7019230769230769,
            "recall": 0.7782515991471215
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8506666508160126,
            "auditor_fn_violation": 0.010429232632091171,
            "auditor_fp_violation": 0.01157217730090753,
            "ave_precision_score": 0.8509636055800867,
            "fpr": 0.1525795828759605,
            "logloss": 0.5677404042525382,
            "mae": 0.2869114119648467,
            "precision": 0.741635687732342,
            "recall": 0.822680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8427102876146441,
            "auditor_fn_violation": 0.018574888714323126,
            "auditor_fp_violation": 0.02687517326046493,
            "ave_precision_score": 0.8429315489834202,
            "fpr": 0.11074561403508772,
            "logloss": 0.8303388369220956,
            "mae": 0.27093762808838284,
            "precision": 0.7725225225225225,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8366586220427082,
            "auditor_fn_violation": 0.02215306618986726,
            "auditor_fp_violation": 0.0164190411403658,
            "ave_precision_score": 0.8369651846129238,
            "fpr": 0.10537870472008781,
            "logloss": 0.83883682221621,
            "mae": 0.26890898459860085,
            "precision": 0.7861915367483296,
            "recall": 0.7278350515463917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8152096764930415,
            "auditor_fn_violation": 0.005613380466090602,
            "auditor_fp_violation": 0.011096095204150332,
            "ave_precision_score": 0.8155578609196158,
            "fpr": 0.18092105263157895,
            "logloss": 0.6073894274446053,
            "mae": 0.34267590980003626,
            "precision": 0.6802325581395349,
            "recall": 0.7484008528784648
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8475341238574857,
            "auditor_fn_violation": 0.007527696990958169,
            "auditor_fp_violation": 0.005225645861999666,
            "ave_precision_score": 0.8477832662275095,
            "fpr": 0.16465422612513722,
            "logloss": 0.572752832269173,
            "mae": 0.32479802198436125,
            "precision": 0.7252747252747253,
            "recall": 0.8164948453608247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8104445096051122,
            "auditor_fn_violation": 0.018925578872554524,
            "auditor_fp_violation": 0.03348134727337531,
            "ave_precision_score": 0.811031289584325,
            "fpr": 0.13486842105263158,
            "logloss": 0.8783348038340004,
            "mae": 0.2769096288724892,
            "precision": 0.740506329113924,
            "recall": 0.7484008528784648
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7936167691310414,
            "auditor_fn_violation": 0.023597044145438912,
            "auditor_fp_violation": 0.020237782347211703,
            "ave_precision_score": 0.7942931977411523,
            "fpr": 0.12294182217343579,
            "logloss": 0.908842935646539,
            "mae": 0.2739935041007204,
            "precision": 0.7656903765690377,
            "recall": 0.7546391752577319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.830931547383051,
            "auditor_fn_violation": 0.021696031122582577,
            "auditor_fp_violation": 0.02626628648370362,
            "ave_precision_score": 0.8312413885596027,
            "fpr": 0.12828947368421054,
            "logloss": 0.8385926849250759,
            "mae": 0.2728489409177501,
            "precision": 0.7515923566878981,
            "recall": 0.7547974413646056
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8137608707362565,
            "auditor_fn_violation": 0.026231511763441104,
            "auditor_fp_violation": 0.020562452652247185,
            "ave_precision_score": 0.8142375792850866,
            "fpr": 0.1207464324917673,
            "logloss": 0.869699120111962,
            "mae": 0.2730903562669978,
            "precision": 0.7684210526315789,
            "recall": 0.7525773195876289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8506209459050257,
            "auditor_fn_violation": 0.010483297796730635,
            "auditor_fp_violation": 0.02042988396499149,
            "ave_precision_score": 0.8508926577046572,
            "fpr": 0.1074561403508772,
            "logloss": 0.5299647172329761,
            "mae": 0.2982696542603662,
            "precision": 0.7782805429864253,
            "recall": 0.7334754797441365
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.864839880330864,
            "auditor_fn_violation": 0.016454106170855635,
            "auditor_fp_violation": 0.0070190627850528,
            "ave_precision_score": 0.8650877085116331,
            "fpr": 0.09879253567508232,
            "logloss": 0.4984828771929692,
            "mae": 0.285350727737916,
            "precision": 0.8034934497816594,
            "recall": 0.7587628865979381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8216160275502792,
            "auditor_fn_violation": 0.022383383832716125,
            "auditor_fp_violation": 0.01340788483624411,
            "ave_precision_score": 0.8218735836773019,
            "fpr": 0.0668859649122807,
            "logloss": 0.6671275201704394,
            "mae": 0.3272915158439693,
            "precision": 0.8189910979228486,
            "recall": 0.5884861407249466
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8445773583237537,
            "auditor_fn_violation": 0.04054907374925029,
            "auditor_fp_violation": 0.014107697778327486,
            "ave_precision_score": 0.8448098356822104,
            "fpr": 0.06476399560922064,
            "logloss": 0.6438190067308106,
            "mae": 0.31582036627843807,
            "precision": 0.8418230563002681,
            "recall": 0.6474226804123712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8448718509156092,
            "auditor_fn_violation": 0.014728986645718777,
            "auditor_fp_violation": 0.012412874737634152,
            "ave_precision_score": 0.8450873884396531,
            "fpr": 0.10416666666666667,
            "logloss": 0.5565886658911737,
            "mae": 0.30305873866358535,
            "precision": 0.7759433962264151,
            "recall": 0.7014925373134329
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8640820301760035,
            "auditor_fn_violation": 0.012070116672513495,
            "auditor_fp_violation": 0.007699324376555718,
            "ave_precision_score": 0.8642971582442035,
            "fpr": 0.09220636663007684,
            "logloss": 0.5128851480236871,
            "mae": 0.28886375042316054,
            "precision": 0.8090909090909091,
            "recall": 0.734020618556701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8478345274310397,
            "auditor_fn_violation": 0.007483727976658061,
            "auditor_fp_violation": 0.01783840243950735,
            "ave_precision_score": 0.848068030804548,
            "fpr": 0.12938596491228072,
            "logloss": 0.52340285111882,
            "mae": 0.29860161322504974,
            "precision": 0.7546777546777547,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8478577104738539,
            "auditor_fn_violation": 0.020349225389568504,
            "auditor_fp_violation": 0.010786269022845452,
            "ave_precision_score": 0.8482615179594961,
            "fpr": 0.12733260153677278,
            "logloss": 0.5109362975783877,
            "mae": 0.29129723558262705,
            "precision": 0.7712031558185405,
            "recall": 0.8061855670103093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7709787040660695,
            "auditor_fn_violation": 0.012409755732615125,
            "auditor_fp_violation": 0.022778800839570713,
            "ave_precision_score": 0.7715009207882862,
            "fpr": 0.22478070175438597,
            "logloss": 0.9084608178145389,
            "mae": 0.3474966916535891,
            "precision": 0.646551724137931,
            "recall": 0.7995735607675906
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7856342307730313,
            "auditor_fn_violation": 0.01859744022089694,
            "auditor_fp_violation": 0.027998948686631314,
            "ave_precision_score": 0.7860254263852384,
            "fpr": 0.21734357848518113,
            "logloss": 0.8427386289453314,
            "mae": 0.33659432850798643,
            "precision": 0.6710963455149501,
            "recall": 0.8329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8232063527934764,
            "auditor_fn_violation": 0.01200061721467849,
            "auditor_fp_violation": 0.020608094728921635,
            "ave_precision_score": 0.8237771201056069,
            "fpr": 0.13706140350877194,
            "logloss": 0.5383514962580894,
            "mae": 0.30752640167828393,
            "precision": 0.7469635627530364,
            "recall": 0.7867803837953091
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8546063514877678,
            "auditor_fn_violation": 0.011977321850917204,
            "auditor_fp_violation": 0.007225202661265804,
            "ave_precision_score": 0.8548431616236254,
            "fpr": 0.12403951701427003,
            "logloss": 0.4993949306614963,
            "mae": 0.2996754636985488,
            "precision": 0.781431334622824,
            "recall": 0.8329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8149319973432734,
            "auditor_fn_violation": 0.008035480492275466,
            "auditor_fp_violation": 0.014566254801790031,
            "ave_precision_score": 0.815224594121672,
            "fpr": 0.15021929824561403,
            "logloss": 0.6276130044264091,
            "mae": 0.32711254776969373,
            "precision": 0.7198364008179959,
            "recall": 0.7505330490405118
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.819901980374742,
            "auditor_fn_violation": 0.012751366460330213,
            "auditor_fp_violation": 0.015164164643919134,
            "ave_precision_score": 0.8203510274413923,
            "fpr": 0.1437980241492865,
            "logloss": 0.6180425064707513,
            "mae": 0.3128734435943649,
            "precision": 0.744140625,
            "recall": 0.7855670103092783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8211241610515931,
            "auditor_fn_violation": 0.010445890846519288,
            "auditor_fp_violation": 0.018407686824284196,
            "ave_precision_score": 0.82145973217964,
            "fpr": 0.12938596491228072,
            "logloss": 0.6124860670682319,
            "mae": 0.3255683066995596,
            "precision": 0.7473233404710921,
            "recall": 0.744136460554371
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8389243778807802,
            "auditor_fn_violation": 0.017533694705036948,
            "auditor_fp_violation": 0.011188241781460814,
            "ave_precision_score": 0.839202663085336,
            "fpr": 0.1207464324917673,
            "logloss": 0.60069694820661,
            "mae": 0.31221144626803415,
            "precision": 0.7727272727272727,
            "recall": 0.7711340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8532918980029705,
            "auditor_fn_violation": 0.020543429469195382,
            "auditor_fp_violation": 0.022350599976238568,
            "ave_precision_score": 0.8537296098572764,
            "fpr": 0.11293859649122807,
            "logloss": 0.513477835477811,
            "mae": 0.2909865037663462,
            "precision": 0.778969957081545,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.868161115114356,
            "auditor_fn_violation": 0.026441997578281484,
            "auditor_fp_violation": 0.020485150198667305,
            "ave_precision_score": 0.8683849519236546,
            "fpr": 0.10537870472008781,
            "logloss": 0.4939895942937515,
            "mae": 0.2796588344004927,
            "precision": 0.7995824634655533,
            "recall": 0.7896907216494845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.836391178938622,
            "auditor_fn_violation": 0.013508584895073507,
            "auditor_fp_violation": 0.026607857114569727,
            "ave_precision_score": 0.8367177501124312,
            "fpr": 0.1425438596491228,
            "logloss": 0.7085985974676908,
            "mae": 0.2704691984114947,
            "precision": 0.7373737373737373,
            "recall": 0.7782515991471215
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8226509073974664,
            "auditor_fn_violation": 0.01047902497538674,
            "auditor_fp_violation": 0.015597058383966439,
            "ave_precision_score": 0.8231613248158636,
            "fpr": 0.13062568605927552,
            "logloss": 0.7400864114799811,
            "mae": 0.26629342823091123,
            "precision": 0.7615230460921844,
            "recall": 0.7835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7210616883241218,
            "auditor_fn_violation": 0.059827740994276735,
            "auditor_fp_violation": 0.038216308265019205,
            "ave_precision_score": 0.721696248394638,
            "fpr": 0.09210526315789473,
            "logloss": 0.8237881749984024,
            "mae": 0.39906126730177977,
            "precision": 0.7245901639344262,
            "recall": 0.47121535181236673
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7669069307019426,
            "auditor_fn_violation": 0.058515056525626094,
            "auditor_fp_violation": 0.0213870121570992,
            "ave_precision_score": 0.767519734099162,
            "fpr": 0.07135016465422613,
            "logloss": 0.7840571453062503,
            "mae": 0.38554606104136596,
            "precision": 0.7875816993464052,
            "recall": 0.49690721649484537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7341548794330105,
            "auditor_fn_violation": 0.03403331088916322,
            "auditor_fp_violation": 0.028417191398360464,
            "ave_precision_score": 0.7347795556078853,
            "fpr": 0.13925438596491227,
            "logloss": 0.7001660238742805,
            "mae": 0.3807859590321064,
            "precision": 0.6997635933806147,
            "recall": 0.6311300639658849
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.751024777490137,
            "auditor_fn_violation": 0.04240949675783947,
            "auditor_fp_violation": 0.018263993032472187,
            "ave_precision_score": 0.7517569249620147,
            "fpr": 0.1207464324917673,
            "logloss": 0.6561171365381518,
            "mae": 0.37394255439391294,
            "precision": 0.7393364928909952,
            "recall": 0.643298969072165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8667828523610616,
            "auditor_fn_violation": 0.012489245501814237,
            "auditor_fp_violation": 0.007625935606510638,
            "ave_precision_score": 0.8672808714636031,
            "fpr": 0.0756578947368421,
            "logloss": 0.7002477927567342,
            "mae": 0.24816598431640693,
            "precision": 0.8275,
            "recall": 0.7057569296375267
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8715400291602946,
            "auditor_fn_violation": 0.00218407324001042,
            "auditor_fp_violation": 0.0009147457006952119,
            "ave_precision_score": 0.8717847462820771,
            "fpr": 0.07793633369923161,
            "logloss": 0.6938743353097567,
            "mae": 0.23997929487041023,
            "precision": 0.831353919239905,
            "recall": 0.7216494845360825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.836488866088116,
            "auditor_fn_violation": 0.008278625668649236,
            "auditor_fp_violation": 0.01858094728921627,
            "ave_precision_score": 0.8367946995038842,
            "fpr": 0.20065789473684212,
            "logloss": 0.5972492012876373,
            "mae": 0.32588400244869836,
            "precision": 0.6800699300699301,
            "recall": 0.8294243070362474
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8611426980718552,
            "auditor_fn_violation": 0.0058030712822660065,
            "auditor_fp_violation": 0.0161433290559309,
            "ave_precision_score": 0.8613557274492194,
            "fpr": 0.2030735455543359,
            "logloss": 0.5860706745092749,
            "mae": 0.3131813530955345,
            "precision": 0.6937086092715232,
            "recall": 0.8639175257731959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5681103894524533,
            "auditor_fn_violation": 0.004598716941607751,
            "auditor_fp_violation": 0.009791691418161672,
            "ave_precision_score": 0.5669439982261624,
            "fpr": 0.4375,
            "logloss": 5.021339317077685,
            "mae": 0.4931062940481034,
            "precision": 0.5134146341463415,
            "recall": 0.8976545842217484
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5748934112711831,
            "auditor_fn_violation": 0.004958864734572861,
            "auditor_fp_violation": 0.01020392387254373,
            "ave_precision_score": 0.572581364478676,
            "fpr": 0.42151481888035125,
            "logloss": 4.915864946406211,
            "mae": 0.47510628190257564,
            "precision": 0.5328467153284672,
            "recall": 0.9030927835051547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8107164340352546,
            "auditor_fn_violation": 0.013803164627987889,
            "auditor_fp_violation": 0.008601144509128352,
            "ave_precision_score": 0.8110375786232924,
            "fpr": 0.08662280701754387,
            "logloss": 0.6580745569418669,
            "mae": 0.3294474333062298,
            "precision": 0.7948051948051948,
            "recall": 0.652452025586354
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8438980665337725,
            "auditor_fn_violation": 0.02389353491688074,
            "auditor_fp_violation": 0.012476616007792093,
            "ave_precision_score": 0.8441374583721326,
            "fpr": 0.08342480790340286,
            "logloss": 0.6193751495463418,
            "mae": 0.3112647175847758,
            "precision": 0.8203309692671394,
            "recall": 0.7154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5846537910821848,
            "auditor_fn_violation": 0.009262896046085366,
            "auditor_fp_violation": 0.01030157221496181,
            "ave_precision_score": 0.585040895891496,
            "fpr": 0.43640350877192985,
            "logloss": 4.527329701062425,
            "mae": 0.4921682173354352,
            "precision": 0.5134474327628362,
            "recall": 0.8955223880597015
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5940373816037554,
            "auditor_fn_violation": 0.004417938823316396,
            "auditor_fp_violation": 0.01020392387254373,
            "ave_precision_score": 0.5937819990576753,
            "fpr": 0.42151481888035125,
            "logloss": 4.452795369021858,
            "mae": 0.47543383357457564,
            "precision": 0.530562347188264,
            "recall": 0.8948453608247423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8520186591300717,
            "auditor_fn_violation": 0.005615718400478811,
            "auditor_fp_violation": 0.014353391944873476,
            "ave_precision_score": 0.8522359784905755,
            "fpr": 0.13267543859649122,
            "logloss": 0.5253862645167959,
            "mae": 0.3008770661283307,
            "precision": 0.7489626556016598,
            "recall": 0.7697228144989339
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8707110811320661,
            "auditor_fn_violation": 0.012414136498919285,
            "auditor_fp_violation": 0.0002782888328875558,
            "ave_precision_score": 0.8709259664815274,
            "fpr": 0.1207464324917673,
            "logloss": 0.49015574284232966,
            "mae": 0.2803517209710865,
            "precision": 0.78,
            "recall": 0.8041237113402062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8536961612925563,
            "auditor_fn_violation": 0.01133898178281525,
            "auditor_fp_violation": 0.010601065304344385,
            "ave_precision_score": 0.853902640760555,
            "fpr": 0.07346491228070176,
            "logloss": 0.5515593917828869,
            "mae": 0.3016727228120241,
            "precision": 0.8194070080862533,
            "recall": 0.6481876332622601
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8641062046157986,
            "auditor_fn_violation": 0.020165899034707526,
            "auditor_fp_violation": 0.011103209082522946,
            "ave_precision_score": 0.8643556108015752,
            "fpr": 0.06476399560922064,
            "logloss": 0.5350582504869833,
            "mae": 0.29347686724678246,
            "precision": 0.8521303258145363,
            "recall": 0.7010309278350515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7142062439174646,
            "auditor_fn_violation": 0.018062881083305282,
            "auditor_fp_violation": 0.026298463427191002,
            "ave_precision_score": 0.7149896470670118,
            "fpr": 0.1425438596491228,
            "logloss": 0.7055571200127202,
            "mae": 0.39599778800344976,
            "precision": 0.6867469879518072,
            "recall": 0.6076759061833689
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7435297271061375,
            "auditor_fn_violation": 0.024169656093338016,
            "auditor_fp_violation": 0.019127203764114142,
            "ave_precision_score": 0.7440127324153754,
            "fpr": 0.1437980241492865,
            "logloss": 0.6841465762543543,
            "mae": 0.391398193990481,
            "precision": 0.6946386946386947,
            "recall": 0.6144329896907217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8063577713689754,
            "auditor_fn_violation": 0.025813133580219208,
            "auditor_fp_violation": 0.022303572135757007,
            "ave_precision_score": 0.8067334946977531,
            "fpr": 0.10526315789473684,
            "logloss": 0.6327756150397233,
            "mae": 0.3285643511850427,
            "precision": 0.7708830548926014,
            "recall": 0.6886993603411514
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8324148775679648,
            "auditor_fn_violation": 0.02619303586180362,
            "auditor_fp_violation": 0.0232242338038476,
            "ave_precision_score": 0.8327288465426705,
            "fpr": 0.09769484083424808,
            "logloss": 0.616072131680304,
            "mae": 0.3117120584083291,
            "precision": 0.7977272727272727,
            "recall": 0.7237113402061855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 29198,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6058935007290468,
            "auditor_fn_violation": 0.013496895223132459,
            "auditor_fp_violation": 0.012977208823412936,
            "ave_precision_score": 0.6010233466402799,
            "fpr": 0.18530701754385964,
            "logloss": 2.8159539688886883,
            "mae": 0.37354390364483453,
            "precision": 0.6724806201550387,
            "recall": 0.7398720682302772
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.6600377191621607,
            "auditor_fn_violation": 0.012538617357158213,
            "auditor_fp_violation": 0.002824116304118163,
            "ave_precision_score": 0.6546904288318963,
            "fpr": 0.14709110867178923,
            "logloss": 2.2865545818047135,
            "mae": 0.34303303587676076,
            "precision": 0.7325349301397206,
            "recall": 0.756701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8603763907901579,
            "auditor_fn_violation": 0.016489451240040403,
            "auditor_fp_violation": 0.014212308423428775,
            "ave_precision_score": 0.8605893151667152,
            "fpr": 0.09320175438596491,
            "logloss": 0.6302225122424283,
            "mae": 0.26396209212597127,
            "precision": 0.7956730769230769,
            "recall": 0.7057569296375267
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8693849504778646,
            "auditor_fn_violation": 0.01656500729910488,
            "auditor_fp_violation": 0.012623490669593855,
            "ave_precision_score": 0.8696318808536727,
            "fpr": 0.07793633369923161,
            "logloss": 0.5986844135476556,
            "mae": 0.2474146463597192,
            "precision": 0.8321513002364066,
            "recall": 0.7257731958762886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7689678740876167,
            "auditor_fn_violation": 0.010193393932592677,
            "auditor_fp_violation": 0.027988990535028315,
            "ave_precision_score": 0.6383952945244934,
            "fpr": 0.19188596491228072,
            "logloss": 10.857149383137,
            "mae": 0.3343984791845606,
            "precision": 0.6595330739299611,
            "recall": 0.7228144989339019
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7781657516765412,
            "auditor_fn_violation": 0.015148188803512628,
            "auditor_fp_violation": 0.016859665125771098,
            "ave_precision_score": 0.6533527943860743,
            "fpr": 0.18551042810098792,
            "logloss": 10.936917577882518,
            "mae": 0.3369346618914055,
            "precision": 0.6724806201550387,
            "recall": 0.7154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.838902736838598,
            "auditor_fn_violation": 0.021022706018778297,
            "auditor_fp_violation": 0.009450120787295554,
            "ave_precision_score": 0.8391459287652829,
            "fpr": 0.07346491228070176,
            "logloss": 0.7691776303893034,
            "mae": 0.28662199135375677,
            "precision": 0.8149171270718232,
            "recall": 0.6289978678038379
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8486950307208407,
            "auditor_fn_violation": 0.02804214242873471,
            "auditor_fp_violation": 0.008503269893786431,
            "ave_precision_score": 0.8489596006105826,
            "fpr": 0.07025246981339188,
            "logloss": 0.7428300003952094,
            "mae": 0.27370435426590867,
            "precision": 0.8354755784061697,
            "recall": 0.6701030927835051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8380834685498686,
            "auditor_fn_violation": 0.006031870721580069,
            "auditor_fp_violation": 0.007116054809710508,
            "ave_precision_score": 0.8383770484937958,
            "fpr": 0.09210526315789473,
            "logloss": 0.7315918633789512,
            "mae": 0.2801059032660904,
            "precision": 0.7884130982367759,
            "recall": 0.6673773987206824
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8578712644026723,
            "auditor_fn_violation": 0.001118064435818806,
            "auditor_fp_violation": 0.006091433342094277,
            "ave_precision_score": 0.8581127836972042,
            "fpr": 0.07903402854006586,
            "logloss": 0.7055330140289582,
            "mae": 0.2637446948961923,
            "precision": 0.824390243902439,
            "recall": 0.6969072164948453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8091972546726562,
            "auditor_fn_violation": 0.01809795009912842,
            "auditor_fp_violation": 0.02287285652053384,
            "ave_precision_score": 0.8101371041545158,
            "fpr": 0.13048245614035087,
            "logloss": 0.5761321149409032,
            "mae": 0.30267944461813484,
            "precision": 0.750524109014675,
            "recall": 0.7633262260127932
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8056198875169136,
            "auditor_fn_violation": 0.02258082768454288,
            "auditor_fp_violation": 0.01842890493344259,
            "ave_precision_score": 0.8063051440332006,
            "fpr": 0.12403951701427003,
            "logloss": 0.5801529685295985,
            "mae": 0.29577664676838367,
            "precision": 0.7665289256198347,
            "recall": 0.7649484536082474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8482222732016084,
            "auditor_fn_violation": 0.020816967792615874,
            "auditor_fp_violation": 0.012747019920003171,
            "ave_precision_score": 0.848429877586589,
            "fpr": 0.046052631578947366,
            "logloss": 0.6549272915167584,
            "mae": 0.3148569645898916,
            "precision": 0.8604651162790697,
            "recall": 0.5522388059701493
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8564395212573821,
            "auditor_fn_violation": 0.03570563671958991,
            "auditor_fp_violation": 0.006369722174981835,
            "ave_precision_score": 0.8566802896450897,
            "fpr": 0.038419319429198684,
            "logloss": 0.635235007290584,
            "mae": 0.3106367218311673,
            "precision": 0.889937106918239,
            "recall": 0.5835051546391753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6044674969789714,
            "auditor_fn_violation": 0.03838654472000898,
            "auditor_fp_violation": 0.031073026810819377,
            "ave_precision_score": 0.5996120573445051,
            "fpr": 0.21820175438596492,
            "logloss": 2.8117495084144375,
            "mae": 0.38510965552482923,
            "precision": 0.6381818181818182,
            "recall": 0.7484008528784648
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6449783083287086,
            "auditor_fn_violation": 0.033949324974255096,
            "auditor_fp_violation": 0.029416160335595725,
            "ave_precision_score": 0.6404445856905273,
            "fpr": 0.19319429198682767,
            "logloss": 2.326132447840217,
            "mae": 0.3653083825719448,
            "precision": 0.6834532374100719,
            "recall": 0.7835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.633701898521089,
            "auditor_fn_violation": 0.060377155575505936,
            "auditor_fp_violation": 0.04949308938259871,
            "ave_precision_score": 0.6344878271301805,
            "fpr": 0.12390350877192982,
            "logloss": 0.9380588770651295,
            "mae": 0.45156981302275917,
            "precision": 0.6208053691275168,
            "recall": 0.39445628997867804
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6853885586087763,
            "auditor_fn_violation": 0.05833173017076511,
            "auditor_fp_violation": 0.0342140659544534,
            "ave_precision_score": 0.6861548718107873,
            "fpr": 0.0867178924259056,
            "logloss": 0.8933491799738538,
            "mae": 0.43939563727716213,
            "precision": 0.7158273381294964,
            "recall": 0.41030927835051545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7083172796039383,
            "auditor_fn_violation": 0.013875640594022376,
            "auditor_fp_violation": 0.020986792602273183,
            "ave_precision_score": 0.7090691239437731,
            "fpr": 0.20065789473684212,
            "logloss": 0.710241411141348,
            "mae": 0.39625447458411944,
            "precision": 0.6453488372093024,
            "recall": 0.7100213219616205
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7229426415475291,
            "auditor_fn_violation": 0.004105605033553247,
            "auditor_fp_violation": 0.0049782780105440605,
            "ave_precision_score": 0.7237350143995008,
            "fpr": 0.18660812294182216,
            "logloss": 0.6805193538201565,
            "mae": 0.38748834486953654,
            "precision": 0.6768060836501901,
            "recall": 0.734020618556701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.846031642308144,
            "auditor_fn_violation": 0.01633280963603037,
            "auditor_fp_violation": 0.01197477327630589,
            "ave_precision_score": 0.8462696460752733,
            "fpr": 0.0625,
            "logloss": 0.5734408312283472,
            "mae": 0.3118581039141629,
            "precision": 0.8308605341246291,
            "recall": 0.5970149253731343
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8729438544165958,
            "auditor_fn_violation": 0.012314551812328134,
            "auditor_fp_violation": 0.0020562452652247197,
            "ave_precision_score": 0.8731314781056115,
            "fpr": 0.04939626783754116,
            "logloss": 0.5274758024380937,
            "mae": 0.2979357580447713,
            "precision": 0.8760330578512396,
            "recall": 0.6556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8182475228253944,
            "auditor_fn_violation": 0.013775109415329374,
            "auditor_fp_violation": 0.015662746029860206,
            "ave_precision_score": 0.8185701588711491,
            "fpr": 0.09210526315789473,
            "logloss": 0.6100038203373117,
            "mae": 0.3235197294555914,
            "precision": 0.7889447236180904,
            "recall": 0.6695095948827292
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8399462139601985,
            "auditor_fn_violation": 0.021716251541865177,
            "auditor_fp_violation": 0.00986379307679226,
            "ave_precision_score": 0.8402505807803017,
            "fpr": 0.0889132821075741,
            "logloss": 0.5818207926561771,
            "mae": 0.30652014582943626,
            "precision": 0.8120649651972158,
            "recall": 0.7216494845360825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8392062827465854,
            "auditor_fn_violation": 0.028819717203456413,
            "auditor_fp_violation": 0.01503900835610471,
            "ave_precision_score": 0.8394543741687761,
            "fpr": 0.05592105263157895,
            "logloss": 0.6504975439565844,
            "mae": 0.3136262567675083,
            "precision": 0.8425925925925926,
            "recall": 0.582089552238806
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8605823142439821,
            "auditor_fn_violation": 0.026018762660269108,
            "auditor_fp_violation": 0.008804749462747952,
            "ave_precision_score": 0.8608296356557867,
            "fpr": 0.04939626783754116,
            "logloss": 0.6038455260702862,
            "mae": 0.3011020895095564,
            "precision": 0.8706896551724138,
            "recall": 0.6247422680412371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6323726628894415,
            "auditor_fn_violation": 0.044883664384842696,
            "auditor_fp_violation": 0.03136509445170489,
            "ave_precision_score": 0.6332980902863867,
            "fpr": 0.17324561403508773,
            "logloss": 0.8837170617645163,
            "mae": 0.4398656634706672,
            "precision": 0.6089108910891089,
            "recall": 0.5245202558635395
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6827691206079781,
            "auditor_fn_violation": 0.048312152726696624,
            "auditor_fp_violation": 0.030088691681740647,
            "ave_precision_score": 0.6833331697484928,
            "fpr": 0.17014270032930845,
            "logloss": 0.856733432883183,
            "mae": 0.4319261420797314,
            "precision": 0.6344339622641509,
            "recall": 0.554639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7385755986199378,
            "auditor_fn_violation": 0.017017824411775708,
            "auditor_fp_violation": 0.020828383034335277,
            "ave_precision_score": 0.7392486802986299,
            "fpr": 0.11403508771929824,
            "logloss": 0.6752645685254662,
            "mae": 0.38640995055162386,
            "precision": 0.7284595300261096,
            "recall": 0.5948827292110874
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7656573466592298,
            "auditor_fn_violation": 0.026604954338157915,
            "auditor_fp_violation": 0.014571512499806746,
            "ave_precision_score": 0.7661294450381209,
            "fpr": 0.11086717892425905,
            "logloss": 0.6605712125317608,
            "mae": 0.38385609139800253,
            "precision": 0.7468671679197995,
            "recall": 0.6144329896907217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8491589584635926,
            "auditor_fn_violation": 0.01580209852990686,
            "auditor_fp_violation": 0.01196487267830977,
            "ave_precision_score": 0.8494194879659681,
            "fpr": 0.05482456140350877,
            "logloss": 0.5818647907771505,
            "mae": 0.30983460112720584,
            "precision": 0.8507462686567164,
            "recall": 0.6076759061833689
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8684585825053913,
            "auditor_fn_violation": 0.019337535505335714,
            "auditor_fp_violation": 0.006539787572857563,
            "ave_precision_score": 0.8686645884296418,
            "fpr": 0.04720087815587267,
            "logloss": 0.5535922885956809,
            "mae": 0.2977553684511117,
            "precision": 0.8818681318681318,
            "recall": 0.6618556701030928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8402570311120015,
            "auditor_fn_violation": 0.015383608274417388,
            "auditor_fp_violation": 0.013259375866302327,
            "ave_precision_score": 0.841002056458574,
            "fpr": 0.09100877192982457,
            "logloss": 0.5588306029340814,
            "mae": 0.29200391111018625,
            "precision": 0.7950617283950617,
            "recall": 0.6865671641791045
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8655005924637487,
            "auditor_fn_violation": 0.00970724365430535,
            "auditor_fp_violation": 0.005521971934055855,
            "ave_precision_score": 0.8657057691846046,
            "fpr": 0.0845225027442371,
            "logloss": 0.5185531045526259,
            "mae": 0.2833419166764811,
            "precision": 0.8171021377672208,
            "recall": 0.709278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6945202969132914,
            "auditor_fn_violation": 0.046305128492873986,
            "auditor_fp_violation": 0.03651835570868481,
            "ave_precision_score": 0.6952047885545805,
            "fpr": 0.09868421052631579,
            "logloss": 0.9006372387932168,
            "mae": 0.410325223353039,
            "precision": 0.686411149825784,
            "recall": 0.4200426439232409
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7297060393608535,
            "auditor_fn_violation": 0.04864032953478109,
            "auditor_fp_violation": 0.023309266502785465,
            "ave_precision_score": 0.7306673266390179,
            "fpr": 0.07464324917672886,
            "logloss": 0.8549492114882115,
            "mae": 0.397697764231629,
            "precision": 0.7687074829931972,
            "recall": 0.465979381443299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8321194252732865,
            "auditor_fn_violation": 0.020679029663711514,
            "auditor_fp_violation": 0.027127638509365965,
            "ave_precision_score": 0.8324226528985182,
            "fpr": 0.13048245614035087,
            "logloss": 0.8346031069050185,
            "mae": 0.27203960204526845,
            "precision": 0.7494736842105263,
            "recall": 0.7590618336886994
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8149808536177363,
            "auditor_fn_violation": 0.023945590548507936,
            "auditor_fp_violation": 0.019302422658895195,
            "ave_precision_score": 0.8154526183531463,
            "fpr": 0.12403951701427003,
            "logloss": 0.8611218280713714,
            "mae": 0.271775302379308,
            "precision": 0.7650727650727651,
            "recall": 0.7587628865979381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8331060101676415,
            "auditor_fn_violation": 0.023442468110574946,
            "auditor_fp_violation": 0.025852936517365654,
            "ave_precision_score": 0.8333880447353588,
            "fpr": 0.125,
            "logloss": 0.8336379759345456,
            "mae": 0.27389121233973845,
            "precision": 0.7527114967462039,
            "recall": 0.7398720682302772
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8163845603517594,
            "auditor_fn_violation": 0.025518575938981755,
            "auditor_fp_violation": 0.021580268291048896,
            "ave_precision_score": 0.8168394199640712,
            "fpr": 0.11964873765093303,
            "logloss": 0.8638603829631203,
            "mae": 0.27408809136397844,
            "precision": 0.767590618336887,
            "recall": 0.7422680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8519073930166026,
            "auditor_fn_violation": 0.0101980698013691,
            "auditor_fp_violation": 0.013563819254682984,
            "ave_precision_score": 0.8521431201222768,
            "fpr": 0.08333333333333333,
            "logloss": 0.5477810134375602,
            "mae": 0.291727423807571,
            "precision": 0.806615776081425,
            "recall": 0.67590618336887
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.864633674817811,
            "auditor_fn_violation": 0.010741566421854325,
            "auditor_fp_violation": 0.0057203815649108725,
            "ave_precision_score": 0.8648453813582679,
            "fpr": 0.07903402854006586,
            "logloss": 0.5178965577254064,
            "mae": 0.28518431808148553,
            "precision": 0.8265060240963855,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8236963818434266,
            "auditor_fn_violation": 0.01819614334343321,
            "auditor_fp_violation": 0.025830660171874385,
            "ave_precision_score": 0.8242393838390341,
            "fpr": 0.13706140350877194,
            "logloss": 0.7610983215760562,
            "mae": 0.2727081725651686,
            "precision": 0.7401247401247402,
            "recall": 0.7590618336886994
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8130384604684411,
            "auditor_fn_violation": 0.023601570722102144,
            "auditor_fp_violation": 0.01972758615358452,
            "ave_precision_score": 0.8136116485475372,
            "fpr": 0.12403951701427003,
            "logloss": 0.7873582019484989,
            "mae": 0.2698859533047539,
            "precision": 0.7626050420168067,
            "recall": 0.7484536082474227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7123227506363257,
            "auditor_fn_violation": 0.010852691430067707,
            "auditor_fp_violation": 0.02193229971090254,
            "ave_precision_score": 0.7130662871927763,
            "fpr": 0.1611842105263158,
            "logloss": 0.6854945575532901,
            "mae": 0.3971002330702488,
            "precision": 0.6726057906458798,
            "recall": 0.6439232409381663
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7606020433485823,
            "auditor_fn_violation": 0.02020437493634502,
            "auditor_fp_violation": 0.012718830362342372,
            "ave_precision_score": 0.7611278782648093,
            "fpr": 0.1437980241492865,
            "logloss": 0.6262480500326811,
            "mae": 0.3822668360357871,
            "precision": 0.7139737991266376,
            "recall": 0.6742268041237114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.849468951499548,
            "auditor_fn_violation": 0.01311581191785434,
            "auditor_fp_violation": 0.018162647023880242,
            "ave_precision_score": 0.8496776618481232,
            "fpr": 0.13815789473684212,
            "logloss": 0.5379099898650084,
            "mae": 0.3067336623618694,
            "precision": 0.7423312883435583,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8602764243370857,
            "auditor_fn_violation": 0.01888035126234907,
            "auditor_fp_violation": 0.017614652422401227,
            "ave_precision_score": 0.8605438317045206,
            "fpr": 0.13062568605927552,
            "logloss": 0.5321649307990537,
            "mae": 0.2923454228951161,
            "precision": 0.7652859960552268,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8092436068907797,
            "auditor_fn_violation": 0.027863502038678788,
            "auditor_fp_violation": 0.0322734743178488,
            "ave_precision_score": 0.8097565111465954,
            "fpr": 0.13267543859649122,
            "logloss": 0.7748713024427524,
            "mae": 0.2824367392451108,
            "precision": 0.7479166666666667,
            "recall": 0.7654584221748401
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7918771352106498,
            "auditor_fn_violation": 0.02881845032647935,
            "auditor_fp_violation": 0.02597362440283855,
            "ave_precision_score": 0.7925050253305743,
            "fpr": 0.12733260153677278,
            "logloss": 0.791433923758661,
            "mae": 0.2813012148561305,
            "precision": 0.7608247422680412,
            "recall": 0.7608247422680412
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8103820221900615,
            "auditor_fn_violation": 0.025256705195825395,
            "auditor_fp_violation": 0.02564502395944715,
            "ave_precision_score": 0.8094411370472538,
            "fpr": 0.10416666666666667,
            "logloss": 3.282557169946126,
            "mae": 0.2973924362599505,
            "precision": 0.7660098522167488,
            "recall": 0.6631130063965884
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8109877721969456,
            "auditor_fn_violation": 0.022157592766530496,
            "auditor_fp_violation": 0.01311049612714708,
            "ave_precision_score": 0.8095552719366914,
            "fpr": 0.09220636663007684,
            "logloss": 3.2405303966536065,
            "mae": 0.2915367488390794,
            "precision": 0.7971014492753623,
            "recall": 0.6804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8349353271425246,
            "auditor_fn_violation": 0.019856076759061835,
            "auditor_fp_violation": 0.027644944754663187,
            "ave_precision_score": 0.8352114935883638,
            "fpr": 0.12938596491228072,
            "logloss": 0.8378373778166374,
            "mae": 0.27127037027140494,
            "precision": 0.7505285412262156,
            "recall": 0.7569296375266524
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8179387133977164,
            "auditor_fn_violation": 0.026251881358425662,
            "auditor_fp_violation": 0.02161376602093351,
            "ave_precision_score": 0.8183784265616574,
            "fpr": 0.12184412733260154,
            "logloss": 0.8694359979433933,
            "mae": 0.2720104107198023,
            "precision": 0.7653276955602537,
            "recall": 0.7463917525773196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8185227945689927,
            "auditor_fn_violation": 0.010841001758126662,
            "auditor_fp_violation": 0.01241287473763415,
            "ave_precision_score": 0.8188244139659995,
            "fpr": 0.09429824561403509,
            "logloss": 0.6051403056589633,
            "mae": 0.3246825625195159,
            "precision": 0.7886977886977887,
            "recall": 0.6844349680170576
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8388614985547964,
            "auditor_fn_violation": 0.02502065250602601,
            "auditor_fp_violation": 0.00781785480537819,
            "ave_precision_score": 0.8391500217731441,
            "fpr": 0.09330406147091108,
            "logloss": 0.5803294116842356,
            "mae": 0.3083771765183207,
            "precision": 0.8045977011494253,
            "recall": 0.7216494845360825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.818223450014692,
            "auditor_fn_violation": 0.014633131335802196,
            "auditor_fp_violation": 0.014343491346877355,
            "ave_precision_score": 0.8185707946429758,
            "fpr": 0.12280701754385964,
            "logloss": 0.5968242111329392,
            "mae": 0.32148603475236504,
            "precision": 0.7516629711751663,
            "recall": 0.7228144989339019
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8440355954744516,
            "auditor_fn_violation": 0.021410707617096885,
            "auditor_fp_violation": 0.012986812201419276,
            "ave_precision_score": 0.8443114539767153,
            "fpr": 0.11086717892425905,
            "logloss": 0.5699231568905687,
            "mae": 0.3039297340456299,
            "precision": 0.7855626326963907,
            "recall": 0.7628865979381443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8496673360505804,
            "auditor_fn_violation": 0.01680039651367224,
            "auditor_fp_violation": 0.022937210407508617,
            "ave_precision_score": 0.8500532867130169,
            "fpr": 0.1425438596491228,
            "logloss": 0.5196352781975413,
            "mae": 0.30199811727844034,
            "precision": 0.7425742574257426,
            "recall": 0.7995735607675906
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8656291101239273,
            "auditor_fn_violation": 0.017549537723358266,
            "auditor_fp_violation": 0.014228804955602624,
            "ave_precision_score": 0.8659068828977018,
            "fpr": 0.1207464324917673,
            "logloss": 0.49409641821890393,
            "mae": 0.2887795006538896,
            "precision": 0.782608695652174,
            "recall": 0.8164948453608247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 29198,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7178920028929627,
            "auditor_fn_violation": 0.04721458496988743,
            "auditor_fp_violation": 0.03555304740406321,
            "ave_precision_score": 0.7185876047534471,
            "fpr": 0.09978070175438597,
            "logloss": 0.7829391985547892,
            "mae": 0.3926128147697391,
            "precision": 0.7111111111111111,
            "recall": 0.47761194029850745
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7550406876531971,
            "auditor_fn_violation": 0.049939457037129244,
            "auditor_fp_violation": 0.0259427034214066,
            "ave_precision_score": 0.755900402666603,
            "fpr": 0.07574094401756312,
            "logloss": 0.7500661413535507,
            "mae": 0.3813007283317765,
            "precision": 0.7836990595611285,
            "recall": 0.5154639175257731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8293182431441672,
            "auditor_fn_violation": 0.016889238020424198,
            "auditor_fp_violation": 0.008732327432576929,
            "ave_precision_score": 0.8296088228237697,
            "fpr": 0.08771929824561403,
            "logloss": 0.8239718266255402,
            "mae": 0.2869710680417957,
            "precision": 0.7953964194373402,
            "recall": 0.6631130063965884
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8429908659280714,
            "auditor_fn_violation": 0.020810936209218377,
            "auditor_fp_violation": 0.010605896631159076,
            "ave_precision_score": 0.843317441852123,
            "fpr": 0.08562019758507135,
            "logloss": 0.8160752031923864,
            "mae": 0.27056205556032265,
            "precision": 0.8125,
            "recall": 0.6969072164948453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8162845641914177,
            "auditor_fn_violation": 0.02308944001795533,
            "auditor_fp_violation": 0.020514039047958496,
            "ave_precision_score": 0.8169013543511288,
            "fpr": 0.12390350877192982,
            "logloss": 0.5683335289325187,
            "mae": 0.3214129993079073,
            "precision": 0.7538126361655774,
            "recall": 0.7377398720682303
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8649451208749277,
            "auditor_fn_violation": 0.02232733939140177,
            "auditor_fp_violation": 0.02367774153151621,
            "ave_precision_score": 0.8651591370691176,
            "fpr": 0.10867178924259056,
            "logloss": 0.5107483984178691,
            "mae": 0.2963114668871762,
            "precision": 0.7933194154488518,
            "recall": 0.7835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5797456353820815,
            "auditor_fn_violation": 0.001524333221112484,
            "auditor_fp_violation": 0.006957645241772606,
            "ave_precision_score": 0.5750519324506637,
            "fpr": 0.44846491228070173,
            "logloss": 5.510691000099832,
            "mae": 0.4717764954074115,
            "precision": 0.525522041763341,
            "recall": 0.9658848614072495
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5896350839965381,
            "auditor_fn_violation": 0.0010320594792173547,
            "auditor_fp_violation": 0.00799307370015926,
            "ave_precision_score": 0.583924292523608,
            "fpr": 0.433589462129528,
            "logloss": 5.37893762267083,
            "mae": 0.4543604021268344,
            "precision": 0.5454545454545454,
            "recall": 0.977319587628866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7899005475167412,
            "auditor_fn_violation": 0.015664160401002512,
            "auditor_fp_violation": 0.031053225614827137,
            "ave_precision_score": 0.7578695268636768,
            "fpr": 0.22916666666666666,
            "logloss": 3.689307519183571,
            "mae": 0.30242169179515954,
            "precision": 0.6579378068739771,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7868841558474693,
            "auditor_fn_violation": 0.005431891995880818,
            "auditor_fp_violation": 0.019209659714599342,
            "ave_precision_score": 0.7508414918690058,
            "fpr": 0.23380900109769484,
            "logloss": 3.9422929385877405,
            "mae": 0.30533149203196747,
            "precision": 0.6635071090047393,
            "recall": 0.865979381443299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8445667108697088,
            "auditor_fn_violation": 0.01165694085961172,
            "auditor_fp_violation": 0.010093659657043286,
            "ave_precision_score": 0.8448352296794808,
            "fpr": 0.1162280701754386,
            "logloss": 0.524640790452263,
            "mae": 0.3018559124050769,
            "precision": 0.7654867256637168,
            "recall": 0.7377398720682303
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8729728056778776,
            "auditor_fn_violation": 0.008152364570484459,
            "auditor_fp_violation": 0.007993073700159248,
            "ave_precision_score": 0.8731672719080102,
            "fpr": 0.10318331503841932,
            "logloss": 0.4827329698207701,
            "mae": 0.282210438738643,
            "precision": 0.8045738045738046,
            "recall": 0.797938144329897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8179575487547482,
            "auditor_fn_violation": 0.017363838701230695,
            "auditor_fp_violation": 0.017692368619064598,
            "ave_precision_score": 0.8183390091405204,
            "fpr": 0.1118421052631579,
            "logloss": 0.5945872928301889,
            "mae": 0.3202860781231976,
            "precision": 0.7676537585421412,
            "recall": 0.7185501066098081
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8429602286272558,
            "auditor_fn_violation": 0.02621566874511979,
            "auditor_fp_violation": 0.014393716856573027,
            "ave_precision_score": 0.8432453881049247,
            "fpr": 0.10537870472008781,
            "logloss": 0.5700325597121966,
            "mae": 0.30360154562804703,
            "precision": 0.7926565874730022,
            "recall": 0.756701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.853535833979261,
            "auditor_fn_violation": 0.006974058280028436,
            "auditor_fp_violation": 0.011153023642628015,
            "ave_precision_score": 0.8537353221219609,
            "fpr": 0.06798245614035088,
            "logloss": 0.5565734385993601,
            "mae": 0.3047937266796015,
            "precision": 0.8296703296703297,
            "recall": 0.6439232409381663
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8600425705749979,
            "auditor_fn_violation": 0.013636312197992473,
            "auditor_fp_violation": 0.006070819354472978,
            "ave_precision_score": 0.8603844196093162,
            "fpr": 0.06476399560922064,
            "logloss": 0.5279902880709827,
            "mae": 0.2992212288934745,
            "precision": 0.850253807106599,
            "recall": 0.6907216494845361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7360858463264994,
            "auditor_fn_violation": 0.0196222833202409,
            "auditor_fp_violation": 0.03595897192190411,
            "ave_precision_score": 0.7358339971907939,
            "fpr": 0.3925438596491228,
            "logloss": 3.7658999546011636,
            "mae": 0.4426787972261164,
            "precision": 0.5421994884910486,
            "recall": 0.9040511727078892
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7947779166844934,
            "auditor_fn_violation": 0.02647594690325574,
            "auditor_fp_violation": 0.04236947480713041,
            "ave_precision_score": 0.7945110913839593,
            "fpr": 0.36553238199780463,
            "logloss": 3.452723347951676,
            "mae": 0.41677441093964573,
            "precision": 0.5697674418604651,
            "recall": 0.9092783505154639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7714061278072579,
            "auditor_fn_violation": 0.013436108929039021,
            "auditor_fp_violation": 0.022707021504098847,
            "ave_precision_score": 0.7719692467205197,
            "fpr": 0.11403508771929824,
            "logloss": 0.6321965808772864,
            "mae": 0.36997862014329275,
            "precision": 0.7432098765432099,
            "recall": 0.6417910447761194
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8017291219456644,
            "auditor_fn_violation": 0.021659669333574754,
            "auditor_fp_violation": 0.01812484861602841,
            "ave_precision_score": 0.8020339046954518,
            "fpr": 0.1163556531284303,
            "logloss": 0.6076876959621345,
            "mae": 0.3641013914694177,
            "precision": 0.7551963048498845,
            "recall": 0.6742268041237114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6264324433175619,
            "auditor_fn_violation": 0.02965903564882358,
            "auditor_fp_violation": 0.03470159597639698,
            "ave_precision_score": 0.6273652644896317,
            "fpr": 0.14364035087719298,
            "logloss": 0.9210953866239386,
            "mae": 0.44191425976449655,
            "precision": 0.6267806267806267,
            "recall": 0.4690831556503198
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6642243613357197,
            "auditor_fn_violation": 0.03584369730781853,
            "auditor_fp_violation": 0.02252593497317605,
            "ave_precision_score": 0.6649582981445888,
            "fpr": 0.11855104281009879,
            "logloss": 0.8962899534270622,
            "mae": 0.43600148015548107,
            "precision": 0.6795252225519288,
            "recall": 0.47216494845360824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8301924562462608,
            "auditor_fn_violation": 0.013870964725245953,
            "auditor_fp_violation": 0.018863114332105663,
            "ave_precision_score": 0.8304519348955117,
            "fpr": 0.12719298245614036,
            "logloss": 0.5592690469887671,
            "mae": 0.31496812918518563,
            "precision": 0.7526652452025586,
            "recall": 0.7526652452025586
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8625138068339879,
            "auditor_fn_violation": 0.014892437222039909,
            "auditor_fp_violation": 0.008168292594940297,
            "ave_precision_score": 0.8627496661662518,
            "fpr": 0.1141602634467618,
            "logloss": 0.5225866237091309,
            "mae": 0.2969852595864289,
            "precision": 0.7851239669421488,
            "recall": 0.7835051546391752
        }
    }
]