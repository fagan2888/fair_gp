[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8381105553212118,
            "auditor_fn_violation": 0.02307544574266624,
            "auditor_fp_violation": 0.021278701504354715,
            "ave_precision_score": 0.8384931289625357,
            "fpr": 0.1337719298245614,
            "logloss": 0.9055353915858781,
            "mae": 0.2764642902217666,
            "precision": 0.7515274949083504,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8282638008251304,
            "auditor_fn_violation": 0.017925854625373112,
            "auditor_fp_violation": 0.03145581778265643,
            "ave_precision_score": 0.8286265369888425,
            "fpr": 0.1251372118551043,
            "logloss": 0.8178330930108856,
            "mae": 0.2575570019382644,
            "precision": 0.7610062893081762,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8044084219562982,
            "auditor_fn_violation": 0.015580894701111233,
            "auditor_fp_violation": 0.016996916281201816,
            "ave_precision_score": 0.7845070060150138,
            "fpr": 0.14583333333333334,
            "logloss": 2.8464520056841427,
            "mae": 0.28554146996212343,
            "precision": 0.7412451361867705,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7749340287250567,
            "auditor_fn_violation": 0.01616195622023126,
            "auditor_fp_violation": 0.023522032303591033,
            "ave_precision_score": 0.7487990875047965,
            "fpr": 0.1602634467618002,
            "logloss": 2.842870685814938,
            "mae": 0.27668328137168163,
            "precision": 0.7208413001912046,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7851789019951421,
            "auditor_fn_violation": 0.005634312359309685,
            "auditor_fp_violation": 0.006253385839896654,
            "ave_precision_score": 0.7857304947671323,
            "fpr": 0.1074561403508772,
            "logloss": 0.577371461909413,
            "mae": 0.3782026831965212,
            "precision": 0.7822222222222223,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.797663567645315,
            "auditor_fn_violation": 0.0001398790401927094,
            "auditor_fp_violation": 0.007561353300925202,
            "ave_precision_score": 0.7980304759686119,
            "fpr": 0.11745334796926454,
            "logloss": 0.5410246707610294,
            "mae": 0.3626168859521429,
            "precision": 0.76431718061674,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7190970416368471,
            "auditor_fn_violation": 0.008928252402901347,
            "auditor_fp_violation": 0.024336375380255872,
            "ave_precision_score": 0.7025234834202719,
            "fpr": 0.17982456140350878,
            "logloss": 2.6950341492412515,
            "mae": 0.3245979688420635,
            "precision": 0.6951672862453532,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.678137633328119,
            "auditor_fn_violation": 0.002662443426040737,
            "auditor_fp_violation": 0.020954210443782345,
            "ave_precision_score": 0.6570016844057837,
            "fpr": 0.19099890230515917,
            "logloss": 2.858637645575745,
            "mae": 0.31813555142300637,
            "precision": 0.6801470588235294,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8250940440704917,
            "auditor_fn_violation": 0.018993193268303146,
            "auditor_fp_violation": 0.020882818685669043,
            "ave_precision_score": 0.8251994670933805,
            "fpr": 0.17763157894736842,
            "logloss": 0.9275153983581599,
            "mae": 0.2812669692771859,
            "precision": 0.7137809187279152,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8067528674763011,
            "auditor_fn_violation": 0.00935055821220362,
            "auditor_fp_violation": 0.029897483142543525,
            "ave_precision_score": 0.8054367500613411,
            "fpr": 0.18551042810098792,
            "logloss": 0.948767234943348,
            "mae": 0.2667341510027438,
            "precision": 0.7040280210157618,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7487473494491459,
            "auditor_fn_violation": 0.031264515667988726,
            "auditor_fp_violation": 0.009472538233945914,
            "ave_precision_score": 0.7217627621002674,
            "fpr": 0.05701754385964912,
            "logloss": 0.8571051900566418,
            "mae": 0.42695711241022016,
            "precision": 0.7842323651452282,
            "recall": 0.384928716904277
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7432323123557427,
            "auditor_fn_violation": 0.020154435943697507,
            "auditor_fp_violation": 0.010619217500392035,
            "ave_precision_score": 0.7146236833025258,
            "fpr": 0.06805708013172337,
            "logloss": 0.8000015728063539,
            "mae": 0.4097747410168109,
            "precision": 0.7568627450980392,
            "recall": 0.4168466522678186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.834998333706132,
            "auditor_fn_violation": 0.005221174116554118,
            "auditor_fp_violation": 0.011420698420635915,
            "ave_precision_score": 0.8313747740432895,
            "fpr": 0.07675438596491228,
            "logloss": 0.532084294572258,
            "mae": 0.30950124878865226,
            "precision": 0.8325358851674641,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8502346433512319,
            "auditor_fn_violation": 0.004947924692918096,
            "auditor_fp_violation": 0.01127342402383566,
            "ave_precision_score": 0.8459677508568239,
            "fpr": 0.0801317233809001,
            "logloss": 0.47345759824612,
            "mae": 0.2894533820548448,
            "precision": 0.8228155339805825,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.726052028220531,
            "auditor_fn_violation": 0.08460401257726803,
            "auditor_fp_violation": 0.08469548276867943,
            "ave_precision_score": 0.5840415436392801,
            "fpr": 0.2532894736842105,
            "logloss": 0.7081218813696056,
            "mae": 0.4830494532851796,
            "precision": 0.5947368421052631,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.70448030221385,
            "auditor_fn_violation": 0.06690011451114647,
            "auditor_fp_violation": 0.08991296848047672,
            "ave_precision_score": 0.5434749229753201,
            "fpr": 0.29088913282107576,
            "logloss": 0.7187162988343182,
            "mae": 0.4913015914293728,
            "precision": 0.5553691275167785,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8103357402157607,
            "auditor_fn_violation": 0.015143191481759391,
            "auditor_fp_violation": 0.009217297995582787,
            "ave_precision_score": 0.7932967701666302,
            "fpr": 0.11951754385964912,
            "logloss": 1.517707894941337,
            "mae": 0.27964660303877553,
            "precision": 0.7729166666666667,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7847100418728772,
            "auditor_fn_violation": 0.005836986389058139,
            "auditor_fp_violation": 0.01483848204484868,
            "ave_precision_score": 0.766296193954748,
            "fpr": 0.12733260153677278,
            "logloss": 1.6322239731661743,
            "mae": 0.2707972868857343,
            "precision": 0.7583333333333333,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 14289,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7980656860701575,
            "auditor_fn_violation": 0.0015520598849465908,
            "auditor_fp_violation": 0.006328916114514318,
            "ave_precision_score": 0.7984439006092066,
            "fpr": 0.08991228070175439,
            "logloss": 0.5348701528469777,
            "mae": 0.3468521182637727,
            "precision": 0.8106235565819861,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8020818170039421,
            "auditor_fn_violation": 0.004658683287773862,
            "auditor_fp_violation": 0.01186392504312373,
            "ave_precision_score": 0.7920574774683546,
            "fpr": 0.09440175631174534,
            "logloss": 0.5167031702486494,
            "mae": 0.33831485836847425,
            "precision": 0.8009259259259259,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.775472621842497,
            "auditor_fn_violation": 0.003267141887304824,
            "auditor_fp_violation": 0.010324207192565745,
            "ave_precision_score": 0.7320472148044109,
            "fpr": 0.21052631578947367,
            "logloss": 0.6057500353492583,
            "mae": 0.36231805657020266,
            "precision": 0.6898222940226171,
            "recall": 0.869653767820774
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7694339313713073,
            "auditor_fn_violation": 0.00045045792604429347,
            "auditor_fp_violation": 0.017572918300141148,
            "ave_precision_score": 0.7203474246902617,
            "fpr": 0.22502744237102085,
            "logloss": 0.5883165037045318,
            "mae": 0.36060058408131584,
            "precision": 0.6688206785137318,
            "recall": 0.8941684665226782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7524463164101939,
            "auditor_fn_violation": 0.03703951834780434,
            "auditor_fp_violation": 0.02648768596074509,
            "ave_precision_score": 0.756607135965304,
            "fpr": 0.11513157894736842,
            "logloss": 0.6092936272031428,
            "mae": 0.40064428147467734,
            "precision": 0.75,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7484349342240746,
            "auditor_fn_violation": 0.015424627720232438,
            "auditor_fp_violation": 0.024646679473106482,
            "ave_precision_score": 0.7525685695654563,
            "fpr": 0.11745334796926454,
            "logloss": 0.5686873908713387,
            "mae": 0.38735885168993117,
            "precision": 0.7523148148148148,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7973140712788204,
            "auditor_fn_violation": 0.012470075392146356,
            "auditor_fp_violation": 0.019101346001583537,
            "ave_precision_score": 0.7685538593912901,
            "fpr": 0.1425438596491228,
            "logloss": 2.9526392673396704,
            "mae": 0.29475941913746523,
            "precision": 0.7346938775510204,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.769123707164737,
            "auditor_fn_violation": 0.009976457646286217,
            "auditor_fp_violation": 0.015901873921906857,
            "ave_precision_score": 0.7294812510672627,
            "fpr": 0.14270032930845225,
            "logloss": 3.108325052273849,
            "mae": 0.2810107224983502,
            "precision": 0.7297297297297297,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.4341336411292998,
            "auditor_fn_violation": 0.0017441133383356594,
            "auditor_fp_violation": 0.005906988373546695,
            "ave_precision_score": 0.5344005380048901,
            "fpr": 0.020833333333333332,
            "logloss": 0.6942212957975383,
            "mae": 0.5004994869232178,
            "precision": 0.32142857142857145,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5005176522731841,
            "auditor_fn_violation": 0.004924216381021034,
            "auditor_fp_violation": 0.002195389681668497,
            "ave_precision_score": 0.5068895730469936,
            "fpr": 0.021953896816684963,
            "logloss": 0.6934496662036058,
            "mae": 0.5001016385468903,
            "precision": 0.47368421052631576,
            "recall": 0.038876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7769374789985312,
            "auditor_fn_violation": 0.01503376567692143,
            "auditor_fp_violation": 0.016293703379589117,
            "ave_precision_score": 0.7773133138162951,
            "fpr": 0.13486842105263158,
            "logloss": 0.7359353024004183,
            "mae": 0.3757501944073992,
            "precision": 0.716589861751152,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.782884237000173,
            "auditor_fn_violation": 0.011268560644676417,
            "auditor_fp_violation": 0.017670926768072765,
            "ave_precision_score": 0.7833173408157055,
            "fpr": 0.1394072447859495,
            "logloss": 0.6571314847406529,
            "mae": 0.35310792213396264,
            "precision": 0.7126696832579186,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.8070109114712971,
            "auditor_fn_violation": 0.03348652946010648,
            "auditor_fp_violation": 0.0151112639079885,
            "ave_precision_score": 0.8072809135168206,
            "fpr": 0.06578947368421052,
            "logloss": 1.223564764777405,
            "mae": 0.3513833575793379,
            "precision": 0.8064516129032258,
            "recall": 0.5091649694501018
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8237348097676428,
            "auditor_fn_violation": 0.02231189232633069,
            "auditor_fp_violation": 0.00960482985729967,
            "ave_precision_score": 0.8240636261875136,
            "fpr": 0.06147091108671789,
            "logloss": 0.9815023298909807,
            "mae": 0.31332183011930564,
            "precision": 0.8227848101265823,
            "recall": 0.5615550755939525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8487320364101214,
            "auditor_fn_violation": 0.026588237395933828,
            "auditor_fp_violation": 0.025818331458098934,
            "ave_precision_score": 0.8350564405751778,
            "fpr": 0.14802631578947367,
            "logloss": 0.5326311733180696,
            "mae": 0.3256417276902459,
            "precision": 0.7408829174664108,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8571087901436903,
            "auditor_fn_violation": 0.016759405680037368,
            "auditor_fp_violation": 0.033896228634154,
            "ave_precision_score": 0.8366711287302244,
            "fpr": 0.1734357848518112,
            "logloss": 0.5068980735137439,
            "mae": 0.31941083581498636,
            "precision": 0.7084870848708487,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7756746924957431,
            "auditor_fn_violation": 0.02017677850430557,
            "auditor_fp_violation": 0.0006407050881360168,
            "ave_precision_score": 0.7668786484694141,
            "fpr": 0.010964912280701754,
            "logloss": 0.7819952491758714,
            "mae": 0.43499430839948583,
            "precision": 0.9166666666666666,
            "recall": 0.2240325865580448
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7761383314461824,
            "auditor_fn_violation": 0.02944098171377905,
            "auditor_fp_violation": 0.0004851419162615649,
            "ave_precision_score": 0.7717055703556887,
            "fpr": 0.014270032930845226,
            "logloss": 0.7229074596478492,
            "mae": 0.41226915799824543,
            "precision": 0.8984375,
            "recall": 0.24838012958963282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6738735801892785,
            "auditor_fn_violation": 0.05132963518776575,
            "auditor_fp_violation": 0.01480393382506147,
            "ave_precision_score": 0.617874481034627,
            "fpr": 0.18311403508771928,
            "logloss": 0.6910348459018656,
            "mae": 0.47317095948873383,
            "precision": 0.6263982102908278,
            "recall": 0.570264765784114
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.6818692458034166,
            "auditor_fn_violation": 0.04476603452404379,
            "auditor_fp_violation": 0.024933354241806496,
            "ave_precision_score": 0.6303364424114462,
            "fpr": 0.15806805708013172,
            "logloss": 0.6630946476201828,
            "mae": 0.4592883778423169,
            "precision": 0.665893271461717,
            "recall": 0.6198704103671706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 14289,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.4936928296074249,
            "auditor_fn_violation": 0.03593856076035303,
            "auditor_fp_violation": 0.016429136975455266,
            "ave_precision_score": 0.5052171654176674,
            "fpr": 0.15460526315789475,
            "logloss": 1.144982880565152,
            "mae": 0.5390804650776676,
            "precision": 0.4777777777777778,
            "recall": 0.26272912423625255
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5355671603059833,
            "auditor_fn_violation": 0.010239619908343682,
            "auditor_fp_violation": 0.018146267837541162,
            "ave_precision_score": 0.5210967605434506,
            "fpr": 0.13830954994511527,
            "logloss": 1.0656010500568471,
            "mae": 0.5063627753713456,
            "precision": 0.49193548387096775,
            "recall": 0.2634989200863931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6381554839643903,
            "auditor_fn_violation": 0.0381226104977311,
            "auditor_fp_violation": 0.03366306204942285,
            "ave_precision_score": 0.5984009907312686,
            "fpr": 0.21710526315789475,
            "logloss": 0.7295098477013845,
            "mae": 0.47860500139690804,
            "precision": 0.576017130620985,
            "recall": 0.5478615071283096
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5751639890677165,
            "auditor_fn_violation": 0.03963555582951827,
            "auditor_fp_violation": 0.03946801003606712,
            "ave_precision_score": 0.5606255237156633,
            "fpr": 0.24368825466520308,
            "logloss": 0.7192084830905929,
            "mae": 0.4747198938865431,
            "precision": 0.5487804878048781,
            "recall": 0.5831533477321814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.7406150452806959,
            "auditor_fn_violation": 0.03905831278808018,
            "auditor_fp_violation": 0.0462062966204109,
            "ave_precision_score": 0.7411920342030245,
            "fpr": 0.35526315789473684,
            "logloss": 0.7888109955949127,
            "mae": 0.4180998574419503,
            "precision": 0.5748031496062992,
            "recall": 0.8920570264765784
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7175699670102718,
            "auditor_fn_violation": 0.024938773284525824,
            "auditor_fp_violation": 0.05473282891641838,
            "ave_precision_score": 0.7179830435312878,
            "fpr": 0.3929747530186608,
            "logloss": 0.8337022684099115,
            "mae": 0.43423296115335597,
            "precision": 0.5451080050825922,
            "recall": 0.9265658747300216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.836483978030194,
            "auditor_fn_violation": 0.023343427305534712,
            "auditor_fp_violation": 0.025404217193815897,
            "ave_precision_score": 0.8366985219012958,
            "fpr": 0.10087719298245613,
            "logloss": 0.5532773661034828,
            "mae": 0.37008496406774055,
            "precision": 0.7937219730941704,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8328284233686734,
            "auditor_fn_violation": 0.020996081016043423,
            "auditor_fp_violation": 0.016225301866081232,
            "ave_precision_score": 0.8330864271632812,
            "fpr": 0.10208562019758508,
            "logloss": 0.5478590911433475,
            "mae": 0.3686192929826505,
            "precision": 0.786697247706422,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6187251564216856,
            "auditor_fn_violation": 0.012628631150176874,
            "auditor_fp_violation": 0.010720090011251421,
            "ave_precision_score": 0.5357840561079259,
            "fpr": 0.2807017543859649,
            "logloss": 0.6930037659330376,
            "mae": 0.4994089328275438,
            "precision": 0.5508771929824562,
            "recall": 0.639511201629328
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.599477441819499,
            "auditor_fn_violation": 0.005011937135040174,
            "auditor_fp_violation": 0.012616140034498997,
            "ave_precision_score": 0.5066960936522525,
            "fpr": 0.29527991218441274,
            "logloss": 0.6930950508578344,
            "mae": 0.49943910164576594,
            "precision": 0.5255731922398589,
            "recall": 0.6436285097192225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.7220101589905634,
            "auditor_fn_violation": 0.010254761139100298,
            "auditor_fp_violation": 0.022099116556236195,
            "ave_precision_score": 0.57235432180401,
            "fpr": 0.35526315789473684,
            "logloss": 0.66790317266477,
            "mae": 0.46274120693928317,
            "precision": 0.5867346938775511,
            "recall": 0.9368635437881874
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7157760314706944,
            "auditor_fn_violation": 0.005692365686486025,
            "auditor_fp_violation": 0.02240473576917047,
            "ave_precision_score": 0.5541098227901071,
            "fpr": 0.3743139407244786,
            "logloss": 0.6505990216927579,
            "mae": 0.4568909165233733,
            "precision": 0.5661577608142494,
            "recall": 0.9611231101511879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8050634192180759,
            "auditor_fn_violation": 0.0005739271804766524,
            "auditor_fp_violation": 0.009977809726215776,
            "ave_precision_score": 0.8055004716241486,
            "fpr": 0.13157894736842105,
            "logloss": 0.8329651345661032,
            "mae": 0.3055123909927347,
            "precision": 0.7468354430379747,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.782092016329481,
            "auditor_fn_violation": 0.0034139969131777906,
            "auditor_fp_violation": 0.010146326642621923,
            "ave_precision_score": 0.7825054149197348,
            "fpr": 0.13721185510428102,
            "logloss": 0.7714428721804873,
            "mae": 0.29350585492896386,
            "precision": 0.7323340471092077,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7663675545789117,
            "auditor_fn_violation": 0.01066119984278415,
            "auditor_fp_violation": 0.013759532441555204,
            "ave_precision_score": 0.5587228891985565,
            "fpr": 0.3980263157894737,
            "logloss": 0.688609187312492,
            "mae": 0.4971998877365861,
            "precision": 0.56,
            "recall": 0.9409368635437881
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.746864587919793,
            "auditor_fn_violation": 0.013757933393868558,
            "auditor_fp_violation": 0.019072447859495065,
            "ave_precision_score": 0.5244442878068534,
            "fpr": 0.43029637760702527,
            "logloss": 0.6892227969475804,
            "mae": 0.49752390646384914,
            "precision": 0.5259975816203144,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5917443443137651,
            "auditor_fn_violation": 0.017427734305213136,
            "auditor_fp_violation": 0.01752302371129725,
            "ave_precision_score": 0.5784388567301881,
            "fpr": 0.08991228070175439,
            "logloss": 11.658557071822239,
            "mae": 0.4921921412884632,
            "precision": 0.6132075471698113,
            "recall": 0.26476578411405294
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5942677453602566,
            "auditor_fn_violation": 0.013293250480686037,
            "auditor_fp_violation": 0.02113797632115415,
            "ave_precision_score": 0.5767854055046429,
            "fpr": 0.0889132821075741,
            "logloss": 10.186878007117514,
            "mae": 0.45363952319390843,
            "precision": 0.6383928571428571,
            "recall": 0.30885529157667385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 14289,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5446663323128322,
            "auditor_fn_violation": 0.006639243220066478,
            "auditor_fp_violation": 0.0017788681918573168,
            "ave_precision_score": 0.546216903472497,
            "fpr": 0.03837719298245614,
            "logloss": 4.593074045804159,
            "mae": 0.5240229704418368,
            "precision": 0.5569620253164557,
            "recall": 0.08961303462321792
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5308117453346457,
            "auditor_fn_violation": 0.00996460349033769,
            "auditor_fp_violation": 0.008455680570801316,
            "ave_precision_score": 0.5327018600576313,
            "fpr": 0.038419319429198684,
            "logloss": 3.985728902056838,
            "mae": 0.4943580369593271,
            "precision": 0.5977011494252874,
            "recall": 0.11231101511879049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8278095670927132,
            "auditor_fn_violation": 0.008521813699217503,
            "auditor_fp_violation": 0.005685606534150103,
            "ave_precision_score": 0.7784938362089348,
            "fpr": 0.08771929824561403,
            "logloss": 0.5541534751704187,
            "mae": 0.32582471225198295,
            "precision": 0.8130841121495327,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8380157829689527,
            "auditor_fn_violation": 0.004075458815105994,
            "auditor_fp_violation": 0.012496079661282739,
            "ave_precision_score": 0.7884488954839249,
            "fpr": 0.09440175631174534,
            "logloss": 0.5291325885675066,
            "mae": 0.317647749740062,
            "precision": 0.7966903073286052,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7666613894906823,
            "auditor_fn_violation": 0.010382052381462822,
            "auditor_fp_violation": 0.012751593949243674,
            "ave_precision_score": 0.5602812947444858,
            "fpr": 0.39473684210526316,
            "logloss": 0.6831017345998213,
            "mae": 0.4920640742046791,
            "precision": 0.561510353227771,
            "recall": 0.9389002036659878
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7475302781651759,
            "auditor_fn_violation": 0.013978420694511292,
            "auditor_fp_violation": 0.019016092990434396,
            "ave_precision_score": 0.5258321059224783,
            "fpr": 0.4270032930845225,
            "logloss": 0.686054479322683,
            "mae": 0.4935031520482868,
            "precision": 0.5267639902676399,
            "recall": 0.9352051835853131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 14289,
        "test": {
            "accuracy": 0.375,
            "auc_prc": 0.44635732403075806,
            "auditor_fn_violation": 0.013720656018865901,
            "auditor_fp_violation": 0.027506042421969423,
            "ave_precision_score": 0.44760229133883966,
            "fpr": 0.16447368421052633,
            "logloss": 3.229938457066584,
            "mae": 0.610906070531582,
            "precision": 0.3212669683257919,
            "recall": 0.1446028513238289
        },
        "train": {
            "accuracy": 0.3918770581778266,
            "auc_prc": 0.41192713094952293,
            "auditor_fn_violation": 0.01686609308357418,
            "auditor_fp_violation": 0.025658616904500553,
            "ave_precision_score": 0.4131532428619563,
            "fpr": 0.1690450054884742,
            "logloss": 3.123225423268013,
            "mae": 0.6002639268854925,
            "precision": 0.2903225806451613,
            "recall": 0.13606911447084233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7244608717522374,
            "auditor_fn_violation": 0.007492317861864441,
            "auditor_fp_violation": 0.012285389840396716,
            "ave_precision_score": 0.7227254480145439,
            "fpr": 0.06578947368421052,
            "logloss": 1.0563269170101344,
            "mae": 0.36661418628870723,
            "precision": 0.8309859154929577,
            "recall": 0.6008146639511202
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7224415756840314,
            "auditor_fn_violation": 0.008689096310275425,
            "auditor_fp_violation": 0.004768111964873767,
            "ave_precision_score": 0.7190657632321606,
            "fpr": 0.06915477497255763,
            "logloss": 1.0966788325187833,
            "mae": 0.35422517020259414,
            "precision": 0.8240223463687151,
            "recall": 0.6371490280777538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 14289,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7699580825774821,
            "auditor_fn_violation": 0.0040174902633365595,
            "auditor_fp_violation": 0.0071779805809059506,
            "ave_precision_score": 0.7674696068820392,
            "fpr": 0.10087719298245613,
            "logloss": 0.5604161522534447,
            "mae": 0.3318573883857186,
            "precision": 0.7941834451901566,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.7791535931202411,
            "auditor_fn_violation": 0.000998119930866566,
            "auditor_fp_violation": 0.008526736710051748,
            "ave_precision_score": 0.7799503873624316,
            "fpr": 0.09659714599341383,
            "logloss": 0.5132799518629558,
            "mae": 0.31251775720345853,
            "precision": 0.8009049773755657,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8106572378719679,
            "auditor_fn_violation": 0.0034323971844070467,
            "auditor_fp_violation": 0.007344668083510444,
            "ave_precision_score": 0.8059804548301035,
            "fpr": 0.08223684210526316,
            "logloss": 0.5457968556500883,
            "mae": 0.3597817225218342,
            "precision": 0.8226950354609929,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.828128675108057,
            "auditor_fn_violation": 0.0037862174099617565,
            "auditor_fp_violation": 0.010898541633997175,
            "ave_precision_score": 0.816842488732368,
            "fpr": 0.08781558726673985,
            "logloss": 0.5132804071588413,
            "mae": 0.34519627034402445,
            "precision": 0.8099762470308789,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5102032591753773,
            "auditor_fn_violation": 0.08040116839961413,
            "auditor_fp_violation": 0.044578488977788905,
            "ave_precision_score": 0.49876631671159216,
            "fpr": 0.2807017543859649,
            "logloss": 0.7342919227013389,
            "mae": 0.5109495496083247,
            "precision": 0.5133079847908745,
            "recall": 0.5498981670061099
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.46920112491396665,
            "auditor_fn_violation": 0.08019573582302218,
            "auditor_fp_violation": 0.05196899012074644,
            "ave_precision_score": 0.4620217907594487,
            "fpr": 0.3150384193194292,
            "logloss": 0.7380146672136045,
            "mae": 0.5126769777252436,
            "precision": 0.4772313296903461,
            "recall": 0.5658747300215983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.5425325078493053,
            "auditor_fn_violation": 0.004656179654839748,
            "auditor_fp_violation": 0.01786681668541901,
            "ave_precision_score": 0.537179148641894,
            "fpr": 0.14035087719298245,
            "logloss": 0.7017898281126073,
            "mae": 0.5018663981831387,
            "precision": 0.49407114624505927,
            "recall": 0.2545824847250509
        },
        "train": {
            "accuracy": 0.45993413830954993,
            "auc_prc": 0.4944305915665558,
            "auditor_fn_violation": 0.0013324071286152303,
            "auditor_fp_violation": 0.008115101144738906,
            "ave_precision_score": 0.48735761014955425,
            "fpr": 0.150384193194292,
            "logloss": 0.7029029355042185,
            "mae": 0.5024477706324517,
            "precision": 0.44081632653061226,
            "recall": 0.23326133909287258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8464340755482788,
            "auditor_fn_violation": 0.017519294672526532,
            "auditor_fp_violation": 0.02585218985706547,
            "ave_precision_score": 0.8468703274531528,
            "fpr": 0.11732456140350878,
            "logloss": 0.6200475501940064,
            "mae": 0.28833275747234566,
            "precision": 0.7653508771929824,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8606185168162273,
            "auditor_fn_violation": 0.004746404041793016,
            "auditor_fp_violation": 0.014314136741414461,
            "ave_precision_score": 0.8608450001097533,
            "fpr": 0.11306256860592755,
            "logloss": 0.532718267143697,
            "mae": 0.2657448103874779,
            "precision": 0.7765726681127982,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6755144103898371,
            "auditor_fn_violation": 0.01359783113588453,
            "auditor_fp_violation": 0.004318248114347628,
            "ave_precision_score": 0.6895898104131888,
            "fpr": 0.03508771929824561,
            "logloss": 2.4113521689279516,
            "mae": 0.4756563562904008,
            "precision": 0.782312925170068,
            "recall": 0.23421588594704684
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.674994541551526,
            "auditor_fn_violation": 0.005405495112531512,
            "auditor_fp_violation": 0.005189548376979771,
            "ave_precision_score": 0.6988900003441666,
            "fpr": 0.03293084522502744,
            "logloss": 2.1083242851245947,
            "mae": 0.4343791213174096,
            "precision": 0.8136645962732919,
            "recall": 0.28293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 14289,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.5413723797947102,
            "auditor_fn_violation": 0.004240808232393604,
            "auditor_fp_violation": 0.009488165187315082,
            "ave_precision_score": 0.5389183349441624,
            "fpr": 0.05921052631578947,
            "logloss": 1.5050276429446543,
            "mae": 0.5098945020289911,
            "precision": 0.5045871559633027,
            "recall": 0.1120162932790224
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5587257304158434,
            "auditor_fn_violation": 0.005270357734718227,
            "auditor_fp_violation": 0.0018597106790026671,
            "ave_precision_score": 0.5493230208174292,
            "fpr": 0.031833150384193196,
            "logloss": 1.5176938323839844,
            "mae": 0.48552358301874765,
            "precision": 0.6282051282051282,
            "recall": 0.10583153347732181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6451918477422264,
            "auditor_fn_violation": 0.11276440847536356,
            "auditor_fp_violation": 0.07301173063299579,
            "ave_precision_score": 0.5767707334370882,
            "fpr": 0.19517543859649122,
            "logloss": 0.6854546417166099,
            "mae": 0.4945362559928183,
            "precision": 0.6035634743875279,
            "recall": 0.5519348268839104
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6411566141857294,
            "auditor_fn_violation": 0.10819525217345949,
            "auditor_fp_violation": 0.07984749882389838,
            "ave_precision_score": 0.5405584308242282,
            "fpr": 0.22722283205268934,
            "logloss": 0.6863640083512224,
            "mae": 0.49471957243889014,
            "precision": 0.5538793103448276,
            "recall": 0.5550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.4861990379973766,
            "auditor_fn_violation": 0.01925670847179048,
            "auditor_fp_violation": 0.01693701295995333,
            "ave_precision_score": 0.5880125863843814,
            "fpr": 0.3059210526315789,
            "logloss": 0.6705164550332634,
            "mae": 0.47094403579831123,
            "precision": 0.5985611510791367,
            "recall": 0.8472505091649695
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.4395349994774501,
            "auditor_fn_violation": 0.009146666729888833,
            "auditor_fp_violation": 0.0225027442371021,
            "ave_precision_score": 0.5680812383300221,
            "fpr": 0.3216245883644347,
            "logloss": 0.6516322175264421,
            "mae": 0.46244540712443455,
            "precision": 0.5784172661870504,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7677552881385169,
            "auditor_fn_violation": 0.002992460785364634,
            "auditor_fp_violation": 0.008988102679501604,
            "ave_precision_score": 0.5588950333809242,
            "fpr": 0.40460526315789475,
            "logloss": 13.961236761007102,
            "mae": 0.4236234633648756,
            "precision": 0.5638297872340425,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7578489908420059,
            "auditor_fn_violation": 0.0021716813697714283,
            "auditor_fp_violation": 0.012956719460561403,
            "ave_precision_score": 0.5320138064205806,
            "fpr": 0.43468715697036225,
            "logloss": 14.94045149739279,
            "mae": 0.44723681241435403,
            "precision": 0.5352112676056338,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7953534863871267,
            "auditor_fn_violation": 0.004365866295065566,
            "auditor_fp_violation": 0.004112493228320207,
            "ave_precision_score": 0.7422270369260113,
            "fpr": 0.03289473684210526,
            "logloss": 1.097067800162764,
            "mae": 0.3737798339372287,
            "precision": 0.8943661971830986,
            "recall": 0.5173116089613035
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7920113447409489,
            "auditor_fn_violation": 0.0015268152861711835,
            "auditor_fp_violation": 0.00783087658773718,
            "ave_precision_score": 0.7397706231917985,
            "fpr": 0.03293084522502744,
            "logloss": 1.0154031431534545,
            "mae": 0.36467324368058157,
            "precision": 0.8928571428571429,
            "recall": 0.5399568034557235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5948349384159766,
            "auditor_fn_violation": 0.008617840425912038,
            "auditor_fp_violation": 0.007232674917698048,
            "ave_precision_score": 0.5617661510635781,
            "fpr": 0.07675438596491228,
            "logloss": 0.7241719089864058,
            "mae": 0.4987611437641215,
            "precision": 0.5705521472392638,
            "recall": 0.1894093686354379
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.566380220438767,
            "auditor_fn_violation": 0.005322516020891776,
            "auditor_fp_violation": 0.011055355182687788,
            "ave_precision_score": 0.5339672607453185,
            "fpr": 0.09001097694840834,
            "logloss": 0.7127814878852236,
            "mae": 0.4934450534185646,
            "precision": 0.5638297872340425,
            "recall": 0.22894168466522677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.776044385185799,
            "auditor_fn_violation": 0.017342873476971454,
            "auditor_fp_violation": 0.01224632245697379,
            "ave_precision_score": 0.7775495315644931,
            "fpr": 0.05592105263157895,
            "logloss": 0.5817362295743915,
            "mae": 0.3874971473246421,
            "precision": 0.8344155844155844,
            "recall": 0.5234215885947047
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7993404546751808,
            "auditor_fn_violation": 0.017418496750775857,
            "auditor_fp_violation": 0.014191626156499925,
            "ave_precision_score": 0.7997063937003643,
            "fpr": 0.052689352360043906,
            "logloss": 0.5651702806557266,
            "mae": 0.38396806087402136,
            "precision": 0.84,
            "recall": 0.5442764578833693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8182468227566435,
            "auditor_fn_violation": 0.014153892878836604,
            "auditor_fp_violation": 0.018148101846064097,
            "ave_precision_score": 0.8186849980993699,
            "fpr": 0.10526315789473684,
            "logloss": 0.5311277667199084,
            "mae": 0.33202382003921166,
            "precision": 0.7908496732026143,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.7970530358907173,
            "auditor_fn_violation": 0.013497141963000813,
            "auditor_fp_violation": 0.019964324917672895,
            "ave_precision_score": 0.7979373447281115,
            "fpr": 0.12843029637760703,
            "logloss": 0.5033295402321156,
            "mae": 0.3180190052563155,
            "precision": 0.7587628865979381,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8430515409785854,
            "auditor_fn_violation": 0.018222746275056274,
            "auditor_fp_violation": 0.025646434971038048,
            "ave_precision_score": 0.8437616489929269,
            "fpr": 0.1425438596491228,
            "logloss": 0.7512360403005922,
            "mae": 0.28083836035361137,
            "precision": 0.7410358565737052,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8473517246516771,
            "auditor_fn_violation": 0.006216319379411227,
            "auditor_fp_violation": 0.018111964873765096,
            "ave_precision_score": 0.8475590375986415,
            "fpr": 0.14489571899012074,
            "logloss": 0.675631308103322,
            "mae": 0.26425116435865315,
            "precision": 0.7375745526838966,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8333028979987009,
            "auditor_fn_violation": 0.011748758352092053,
            "auditor_fp_violation": 0.0014272617410509658,
            "ave_precision_score": 0.7773571027404448,
            "fpr": 0.049342105263157895,
            "logloss": 0.6651271601220177,
            "mae": 0.3322465008279419,
            "precision": 0.8648648648648649,
            "recall": 0.5865580448065173
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8345989775034518,
            "auditor_fn_violation": 0.011342056411557328,
            "auditor_fp_violation": 0.006135330092519997,
            "ave_precision_score": 0.7761147519733311,
            "fpr": 0.050493962678375415,
            "logloss": 0.6002921389698911,
            "mae": 0.30981550918211936,
            "precision": 0.863905325443787,
            "recall": 0.6306695464362851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7656683852975379,
            "auditor_fn_violation": 0.004743273662772005,
            "auditor_fp_violation": 0.008667750135433607,
            "ave_precision_score": 0.7211381085030374,
            "fpr": 0.31359649122807015,
            "logloss": 0.6259142701686714,
            "mae": 0.4344979771657994,
            "precision": 0.5781710914454278,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.763689058315566,
            "auditor_fn_violation": 0.0019203732636625117,
            "auditor_fp_violation": 0.017210286968794113,
            "ave_precision_score": 0.7205896657046864,
            "fpr": 0.32491767288693746,
            "logloss": 0.6186436459972238,
            "mae": 0.43075008469538684,
            "precision": 0.5601783060921248,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6918369464562897,
            "mae": 0.4992493017200838,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930164124731432,
            "mae": 0.4998389595033832,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7695160297526822,
            "auditor_fn_violation": 0.00681566441562154,
            "auditor_fp_violation": 0.00752177355502771,
            "ave_precision_score": 0.7687216819447511,
            "fpr": 0.14473684210526316,
            "logloss": 1.091537440488597,
            "mae": 0.3250419493772808,
            "precision": 0.7569060773480663,
            "recall": 0.8370672097759674
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7442096824010548,
            "auditor_fn_violation": 0.005189749474268186,
            "auditor_fp_violation": 0.0063705504155559135,
            "ave_precision_score": 0.7442873490939537,
            "fpr": 0.1668496158068057,
            "logloss": 1.2932980040695352,
            "mae": 0.32310885566253006,
            "precision": 0.7251356238698011,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 14289,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8391531013583905,
            "auditor_fn_violation": 0.0031286847464894445,
            "auditor_fp_violation": 0.004393778388965292,
            "ave_precision_score": 0.8395415952862526,
            "fpr": 0.10526315789473684,
            "logloss": 0.5245404696698124,
            "mae": 0.3204137671354897,
            "precision": 0.7917570498915402,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8407799586013849,
            "auditor_fn_violation": 0.00286633490835552,
            "auditor_fp_violation": 0.006017719931002043,
            "ave_precision_score": 0.8410872187963012,
            "fpr": 0.1141602634467618,
            "logloss": 0.4908018915178971,
            "mae": 0.31132469427261733,
            "precision": 0.7758620689655172,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8563621918701688,
            "auditor_fn_violation": 0.009084574981241291,
            "auditor_fp_violation": 0.0054095303579614114,
            "ave_precision_score": 0.8565969538253235,
            "fpr": 0.0800438596491228,
            "logloss": 0.5324619402961199,
            "mae": 0.3217561873013226,
            "precision": 0.8253588516746412,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8584903170151927,
            "auditor_fn_violation": 0.005512182516068315,
            "auditor_fp_violation": 0.0011001450525325407,
            "ave_precision_score": 0.8586912873343198,
            "fpr": 0.09330406147091108,
            "logloss": 0.4886107101323959,
            "mae": 0.3115857252628015,
            "precision": 0.8014018691588785,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 14289,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.589779504922563,
            "auditor_fn_violation": 0.004854932647300532,
            "auditor_fp_violation": 0.011339959161561875,
            "ave_precision_score": 0.5766541978647712,
            "fpr": 0.41776315789473684,
            "logloss": 0.6797443377525249,
            "mae": 0.47755729123590546,
            "precision": 0.5569767441860465,
            "recall": 0.9755600814663951
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.573476454360226,
            "auditor_fn_violation": 0.004924216381021023,
            "auditor_fp_violation": 0.014167124039517021,
            "ave_precision_score": 0.5627395570605256,
            "fpr": 0.4281009879253567,
            "logloss": 0.6731818733273444,
            "mae": 0.4721522585097312,
            "precision": 0.5373665480427047,
            "recall": 0.978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 14289,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8163549941528725,
            "auditor_fn_violation": 0.008139939972129931,
            "auditor_fp_violation": 0.0001797099637454693,
            "ave_precision_score": 0.7466595475204606,
            "fpr": 0.08223684210526316,
            "logloss": 0.5588444982348159,
            "mae": 0.37109559601205483,
            "precision": 0.8157248157248157,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8153533069422547,
            "auditor_fn_violation": 0.0069655020353585765,
            "auditor_fp_violation": 0.009291202759918458,
            "ave_precision_score": 0.7433596418357022,
            "fpr": 0.09001097694840834,
            "logloss": 0.5416349192251552,
            "mae": 0.36078767054821603,
            "precision": 0.8009708737864077,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.764891448226214,
            "auditor_fn_violation": 0.004745506842462587,
            "auditor_fp_violation": 0.010602887860982622,
            "ave_precision_score": 0.7603972312045816,
            "fpr": 0.10964912280701754,
            "logloss": 0.8764980088226444,
            "mae": 0.3621730841103974,
            "precision": 0.7560975609756098,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7428975934556158,
            "auditor_fn_violation": 0.008874021143072558,
            "auditor_fp_violation": 0.007022306727301238,
            "ave_precision_score": 0.7395544865047609,
            "fpr": 0.1163556531284303,
            "logloss": 0.889827440509152,
            "mae": 0.36239888633649414,
            "precision": 0.7389162561576355,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6897329392390752,
            "auditor_fn_violation": 0.010252527959409733,
            "auditor_fp_violation": 0.01735112722423636,
            "ave_precision_score": 0.6835275984661032,
            "fpr": 0.18421052631578946,
            "logloss": 0.644065595862168,
            "mae": 0.4451553200375648,
            "precision": 0.6592292089249493,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6829611408108676,
            "auditor_fn_violation": 0.014687299220233626,
            "auditor_fp_violation": 0.01838638858397366,
            "ave_precision_score": 0.6785878619680067,
            "fpr": 0.18441273326015367,
            "logloss": 0.6321854605658177,
            "mae": 0.43921684945854805,
            "precision": 0.6592292089249493,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.670044655484787,
            "auditor_fn_violation": 0.005781702218887359,
            "auditor_fp_violation": 0.0025992832437388026,
            "ave_precision_score": 0.6708064816578023,
            "fpr": 0.06578947368421052,
            "logloss": 0.6822530918708396,
            "mae": 0.46475759775289033,
            "precision": 0.7101449275362319,
            "recall": 0.29938900203665986
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.688441991292227,
            "auditor_fn_violation": 0.002991988961409981,
            "auditor_fp_violation": 0.011427787360827975,
            "ave_precision_score": 0.6889706350724842,
            "fpr": 0.07244785949506037,
            "logloss": 0.6413111826408925,
            "mae": 0.45062918814235114,
            "precision": 0.7053571428571429,
            "recall": 0.3412526997840173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8211750108295116,
            "auditor_fn_violation": 0.009265462536177514,
            "auditor_fp_violation": 0.008748489394507647,
            "ave_precision_score": 0.7458364934588289,
            "fpr": 0.09100877192982457,
            "logloss": 0.571285876542288,
            "mae": 0.370588371971328,
            "precision": 0.7893401015228426,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8252783721914216,
            "auditor_fn_violation": 0.004080200477485407,
            "auditor_fp_violation": 0.007919084208875646,
            "ave_precision_score": 0.7467155172875111,
            "fpr": 0.09659714599341383,
            "logloss": 0.5386046976551877,
            "mae": 0.35736290970663864,
            "precision": 0.7788944723618091,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8114307868439741,
            "auditor_fn_violation": 0.00872726623074999,
            "auditor_fp_violation": 0.011566549985414848,
            "ave_precision_score": 0.8128159925987739,
            "fpr": 0.08223684210526316,
            "logloss": 0.6176211711141183,
            "mae": 0.33400591187049566,
            "precision": 0.8125,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.845980809884124,
            "auditor_fn_violation": 0.006491335797417219,
            "auditor_fp_violation": 0.009244648737650935,
            "ave_precision_score": 0.8462361046940514,
            "fpr": 0.07574094401756312,
            "logloss": 0.5185881649252263,
            "mae": 0.31444497269011157,
            "precision": 0.823076923076923,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8345664648013418,
            "auditor_fn_violation": 0.0054065280308714745,
            "auditor_fp_violation": 0.0017059424094678507,
            "ave_precision_score": 0.8400894491544538,
            "fpr": 0.09100877192982457,
            "logloss": 0.5079379709507135,
            "mae": 0.3055003160823202,
            "precision": 0.8130630630630631,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8406799778348433,
            "auditor_fn_violation": 0.0067592397218540845,
            "auditor_fp_violation": 0.010001764152422772,
            "ave_precision_score": 0.842447484292369,
            "fpr": 0.09440175631174534,
            "logloss": 0.4688214694720627,
            "mae": 0.291985695292247,
            "precision": 0.8041002277904328,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7569664041845638,
            "auditor_fn_violation": 0.014665291027977293,
            "auditor_fp_violation": 0.008175501104304709,
            "ave_precision_score": 0.7443731007699301,
            "fpr": 0.05701754385964912,
            "logloss": 0.7589398046979278,
            "mae": 0.415453535030936,
            "precision": 0.803030303030303,
            "recall": 0.4317718940936864
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7596684392110049,
            "auditor_fn_violation": 0.00963742878615814,
            "auditor_fp_violation": 0.010499157127175791,
            "ave_precision_score": 0.7459647932695952,
            "fpr": 0.05598243688254665,
            "logloss": 0.7004040556482414,
            "mae": 0.3942470786889604,
            "precision": 0.8152173913043478,
            "recall": 0.48596112311015116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 14289,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.509740858626636,
            "auditor_fn_violation": 0.04644790438417836,
            "auditor_fp_violation": 0.038351148060174194,
            "ave_precision_score": 0.5111674114206657,
            "fpr": 0.14144736842105263,
            "logloss": 1.2887243147857668,
            "mae": 0.5245854479889794,
            "precision": 0.5038461538461538,
            "recall": 0.2668024439918534
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.47026848639703617,
            "auditor_fn_violation": 0.04511454670893069,
            "auditor_fp_violation": 0.033151364277873616,
            "ave_precision_score": 0.4715574865078481,
            "fpr": 0.15697036223929747,
            "logloss": 1.337201428776899,
            "mae": 0.5277894169263926,
            "precision": 0.48188405797101447,
            "recall": 0.28725701943844495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7303860271188312,
            "auditor_fn_violation": 0.004414996248258124,
            "auditor_fp_violation": 0.005883547943492938,
            "ave_precision_score": 0.5849936016580157,
            "fpr": 0.23903508771929824,
            "logloss": 0.6800624145419089,
            "mae": 0.49103819552743644,
            "precision": 0.6064981949458483,
            "recall": 0.6843177189409368
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7184498070660987,
            "auditor_fn_violation": 0.006140452781340616,
            "auditor_fp_violation": 0.009920907166379186,
            "ave_precision_score": 0.5586788858749651,
            "fpr": 0.2623490669593853,
            "logloss": 0.6800755168838392,
            "mae": 0.4910468564795087,
            "precision": 0.579225352112676,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8470272026083296,
            "auditor_fn_violation": 0.018959695572944583,
            "auditor_fp_violation": 0.010527357586364965,
            "ave_precision_score": 0.8475622463340364,
            "fpr": 0.13157894736842105,
            "logloss": 0.5140964167390768,
            "mae": 0.3361412993807901,
            "precision": 0.76,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8501555246679782,
            "auditor_fn_violation": 0.012017743300623772,
            "auditor_fp_violation": 0.01493404030108202,
            "ave_precision_score": 0.8504294866767983,
            "fpr": 0.141602634467618,
            "logloss": 0.4927351547367185,
            "mae": 0.32796801417313604,
            "precision": 0.7514450867052023,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6469359631691567,
            "auditor_fn_violation": 0.014622860613856438,
            "auditor_fp_violation": 0.02948806100762596,
            "ave_precision_score": 0.6443311268619264,
            "fpr": 0.14473684210526316,
            "logloss": 0.7109542731938033,
            "mae": 0.426310486707575,
            "precision": 0.6819277108433734,
            "recall": 0.5763747454175153
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6558685472680148,
            "auditor_fn_violation": 0.014013983162356896,
            "auditor_fp_violation": 0.042075035283048456,
            "ave_precision_score": 0.6379289779319808,
            "fpr": 0.14709110867178923,
            "logloss": 0.6791448763820337,
            "mae": 0.40630661593146955,
            "precision": 0.6778846153846154,
            "recall": 0.6090712742980562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6792149863128698,
            "auditor_fn_violation": 0.018676081752242113,
            "auditor_fp_violation": 0.01675209401175147,
            "ave_precision_score": 0.6745261460256275,
            "fpr": 0.18530701754385964,
            "logloss": 0.6451585699603329,
            "mae": 0.4389176002311471,
            "precision": 0.6768642447418738,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6428148795334195,
            "auditor_fn_violation": 0.012458717901909238,
            "auditor_fp_violation": 0.023531833150384193,
            "ave_precision_score": 0.6365684302805448,
            "fpr": 0.19978046103183314,
            "logloss": 0.644277072514991,
            "mae": 0.43874242951690695,
            "precision": 0.6533333333333333,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8463627850564259,
            "auditor_fn_violation": 0.016212884553542722,
            "auditor_fp_violation": 0.00734987706796683,
            "ave_precision_score": 0.8468760700895874,
            "fpr": 0.0625,
            "logloss": 0.6773764102487259,
            "mae": 0.28651107387696884,
            "precision": 0.8421052631578947,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8553665241787571,
            "auditor_fn_violation": 0.004580445858513543,
            "auditor_fp_violation": 0.010839736553238203,
            "ave_precision_score": 0.8556014780037771,
            "fpr": 0.06147091108671789,
            "logloss": 0.6002812805605034,
            "mae": 0.2696436390096197,
            "precision": 0.8431372549019608,
            "recall": 0.6501079913606912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8254096657131401,
            "auditor_fn_violation": 0.03368974881194841,
            "auditor_fp_violation": 0.02228924448889445,
            "ave_precision_score": 0.8256100246424167,
            "fpr": 0.1162280701754386,
            "logloss": 0.5268807090287901,
            "mae": 0.3378890363383107,
            "precision": 0.7791666666666667,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8417217860391945,
            "auditor_fn_violation": 0.02579464334400998,
            "auditor_fp_violation": 0.02163046887251059,
            "ave_precision_score": 0.8424888050177263,
            "fpr": 0.1207464324917673,
            "logloss": 0.48889666428782314,
            "mae": 0.32654092750797287,
            "precision": 0.7684210526315789,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 14289,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5701436645616256,
            "auditor_fn_violation": 0.004013023903955415,
            "auditor_fp_violation": 0.011563945493186657,
            "ave_precision_score": 0.5623250881049561,
            "fpr": 0.14802631578947367,
            "logloss": 2.245135949830207,
            "mae": 0.5130686039424689,
            "precision": 0.55,
            "recall": 0.3360488798370672
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5574204798196564,
            "auditor_fn_violation": 0.003854971514463271,
            "auditor_fp_violation": 0.016190998902305166,
            "ave_precision_score": 0.5519645032064248,
            "fpr": 0.15367727771679474,
            "logloss": 2.017376683272543,
            "mae": 0.4790152867705971,
            "precision": 0.5527156549520766,
            "recall": 0.37365010799136067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5601767252094642,
            "auditor_fn_violation": 0.001248347447028991,
            "auditor_fp_violation": 0.004417218819019044,
            "ave_precision_score": 0.5518102333552057,
            "fpr": 0.05043859649122807,
            "logloss": 0.8117741552268369,
            "mae": 0.5079306157207802,
            "precision": 0.5740740740740741,
            "recall": 0.12627291242362526
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5461862238588007,
            "auditor_fn_violation": 0.0014367237009623225,
            "auditor_fp_violation": 0.008882017406303904,
            "ave_precision_score": 0.5318245530485021,
            "fpr": 0.05817782656421515,
            "logloss": 0.7825888289503995,
            "mae": 0.4937687341520475,
            "precision": 0.5793650793650794,
            "recall": 0.15766738660907129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8373106393697896,
            "auditor_fn_violation": 0.011420480937578165,
            "auditor_fp_violation": 0.01717662624494729,
            "ave_precision_score": 0.8316693629158509,
            "fpr": 0.1524122807017544,
            "logloss": 0.5340720535026996,
            "mae": 0.3211566442133565,
            "precision": 0.7377358490566037,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8487801738542398,
            "auditor_fn_violation": 0.006892006268477667,
            "auditor_fp_violation": 0.010957346714756162,
            "ave_precision_score": 0.84195810500058,
            "fpr": 0.14928649835345773,
            "logloss": 0.49293794913881545,
            "mae": 0.30633421191530613,
            "precision": 0.7364341085271318,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.523149522945987,
            "auditor_fn_violation": 0.007271233072497947,
            "auditor_fp_violation": 0.013152685752385715,
            "ave_precision_score": 0.5340681752928308,
            "fpr": 0.3475877192982456,
            "logloss": 0.7407693038679389,
            "mae": 0.4915103391466433,
            "precision": 0.5458452722063037,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5235669592988104,
            "auditor_fn_violation": 0.002942201506426138,
            "auditor_fp_violation": 0.00797543907793633,
            "ave_precision_score": 0.510219391118963,
            "fpr": 0.3567508232711306,
            "logloss": 0.7470626465811798,
            "mae": 0.4930782885700628,
            "precision": 0.5220588235294118,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 14289,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8314008333426892,
            "auditor_fn_violation": 0.006364562118126273,
            "auditor_fp_violation": 0.009326686669166988,
            "ave_precision_score": 0.8323289673304944,
            "fpr": 0.2565789473684211,
            "logloss": 0.9689101336631543,
            "mae": 0.3195289885992871,
            "precision": 0.6613603473227206,
            "recall": 0.9307535641547862
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8183860298960237,
            "auditor_fn_violation": 0.004165550400314846,
            "auditor_fp_violation": 0.005919711463070403,
            "ave_precision_score": 0.8186227360215134,
            "fpr": 0.26344676180021953,
            "logloss": 1.031925528639969,
            "mae": 0.33181602438926106,
            "precision": 0.6460176991150443,
            "recall": 0.9460043196544277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7385196752022518,
            "auditor_fn_violation": 0.012635330689248584,
            "auditor_fp_violation": 0.016509876234529316,
            "ave_precision_score": 0.7273217610330824,
            "fpr": 0.0756578947368421,
            "logloss": 0.6812587839804156,
            "mae": 0.41330611843027565,
            "precision": 0.7952522255192879,
            "recall": 0.5458248472505092
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7321731831864722,
            "auditor_fn_violation": 0.007223922635036617,
            "auditor_fp_violation": 0.011217069154774975,
            "ave_precision_score": 0.7161166542249314,
            "fpr": 0.07683863885839737,
            "logloss": 0.6596575849465824,
            "mae": 0.4017144603783553,
            "precision": 0.7885196374622356,
            "recall": 0.5637149028077754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6347468517719566,
            "auditor_fn_violation": 0.029591864079751323,
            "auditor_fp_violation": 0.024026440805100645,
            "ave_precision_score": 0.6997604619116381,
            "fpr": 0.12828947368421054,
            "logloss": 0.6091883566965313,
            "mae": 0.4061231680312439,
            "precision": 0.7310344827586207,
            "recall": 0.6476578411405295
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.5971312710788025,
            "auditor_fn_violation": 0.0187248247363043,
            "auditor_fp_violation": 0.03759604829857301,
            "ave_precision_score": 0.699623200427802,
            "fpr": 0.12294182217343579,
            "logloss": 0.5911697938398781,
            "mae": 0.4029658417146894,
            "precision": 0.7383177570093458,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.8003184118353056,
            "auditor_fn_violation": 0.013387912244970887,
            "auditor_fp_violation": 0.0174422844522232,
            "ave_precision_score": 0.7743872488821386,
            "fpr": 0.17214912280701755,
            "logloss": 0.6372645733351281,
            "mae": 0.3889444684022588,
            "precision": 0.6939571150097466,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8074701599282539,
            "auditor_fn_violation": 0.011500902101267684,
            "auditor_fp_violation": 0.024068429512309867,
            "ave_precision_score": 0.7824979864588474,
            "fpr": 0.18331503841931943,
            "logloss": 0.6015326811152053,
            "mae": 0.3753267294524338,
            "precision": 0.6806883365200764,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8242015942761162,
            "auditor_fn_violation": 0.02036213241862294,
            "auditor_fp_violation": 0.017577718048089348,
            "ave_precision_score": 0.8084210197945029,
            "fpr": 0.13925438596491227,
            "logloss": 0.6283198611439736,
            "mae": 0.3250527868206981,
            "precision": 0.741869918699187,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8180219844224855,
            "auditor_fn_violation": 0.014661220077146852,
            "auditor_fp_violation": 0.01820997334169673,
            "ave_precision_score": 0.7994138315829338,
            "fpr": 0.141602634467618,
            "logloss": 0.5669845640310227,
            "mae": 0.31516284356379326,
            "precision": 0.7266949152542372,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6822771929316214,
            "auditor_fn_violation": 0.006465055204201955,
            "auditor_fp_violation": 0.011477997249656209,
            "ave_precision_score": 0.7159763670670805,
            "fpr": 0.0537280701754386,
            "logloss": 0.6325246737766165,
            "mae": 0.403439729294756,
            "precision": 0.851063829787234,
            "recall": 0.570264765784114
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.6749838258558061,
            "auditor_fn_violation": 1.422498713824478e-05,
            "auditor_fp_violation": 0.0045181903716481125,
            "ave_precision_score": 0.7152718005140362,
            "fpr": 0.054884742041712405,
            "logloss": 0.5919845139342983,
            "mae": 0.38573240644976287,
            "precision": 0.8493975903614458,
            "recall": 0.6090712742980562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 14289,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7760277539730813,
            "auditor_fn_violation": 0.004866098545753386,
            "auditor_fp_violation": 0.013881943576280384,
            "ave_precision_score": 0.7636622272169117,
            "fpr": 0.24232456140350878,
            "logloss": 1.1742303325723507,
            "mae": 0.37720806886883157,
            "precision": 0.6497622820919176,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7262491072922922,
            "auditor_fn_violation": 0.0038834214887397403,
            "auditor_fp_violation": 0.004768111964873791,
            "ave_precision_score": 0.7143211559629399,
            "fpr": 0.27991218441273324,
            "logloss": 1.2568630522085482,
            "mae": 0.4039316620722691,
            "precision": 0.5996860282574569,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4451754385964912,
            "auc_prc": 0.5572191523115869,
            "auditor_fn_violation": 0.03225381427091151,
            "auditor_fp_violation": 0.016851064716422896,
            "ave_precision_score": 0.5276169445705212,
            "fpr": 0.16337719298245615,
            "logloss": 1.234753392256679,
            "mae": 0.5387910607254558,
            "precision": 0.4734982332155477,
            "recall": 0.2729124236252546
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5416055991455424,
            "auditor_fn_violation": 0.011021994200946905,
            "auditor_fp_violation": 0.02015054100674299,
            "ave_precision_score": 0.5114232094523554,
            "fpr": 0.14489571899012074,
            "logloss": 1.153083085822227,
            "mae": 0.5067326537733151,
            "precision": 0.49809885931558934,
            "recall": 0.28293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5722105655289107,
            "auditor_fn_violation": 0.004432861685782715,
            "auditor_fp_violation": 0.008073925907405091,
            "ave_precision_score": 0.5572647454962443,
            "fpr": 0.025219298245614034,
            "logloss": 0.7099952229897306,
            "mae": 0.4965095645829774,
            "precision": 0.6101694915254238,
            "recall": 0.07331975560081466
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5906357498695344,
            "auditor_fn_violation": 0.011308864774901442,
            "auditor_fp_violation": 0.007441292927708954,
            "ave_precision_score": 0.538236607126751,
            "fpr": 0.029637760702524697,
            "logloss": 0.6937922149689483,
            "mae": 0.4894132788827731,
            "precision": 0.6086956521739131,
            "recall": 0.09071274298056156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8558050112257247,
            "auditor_fn_violation": 0.007407457033622752,
            "auditor_fp_violation": 0.009011543109555365,
            "ave_precision_score": 0.8508216625934197,
            "fpr": 0.08662280701754387,
            "logloss": 0.5148353416820518,
            "mae": 0.3096197375316957,
            "precision": 0.8158508158508159,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8531608982554053,
            "auditor_fn_violation": 0.0016666943263638826,
            "auditor_fp_violation": 0.009808197428257804,
            "ave_precision_score": 0.8462706521604293,
            "fpr": 0.0889132821075741,
            "logloss": 0.471665101057404,
            "mae": 0.2940629192768023,
            "precision": 0.8098591549295775,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 14289,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6996745888764382,
            "auditor_fn_violation": 0.009642869903883945,
            "auditor_fp_violation": 0.0014793515856148687,
            "ave_precision_score": 0.6779460108975326,
            "fpr": 0.1074561403508772,
            "logloss": 1.031838004115814,
            "mae": 0.4437007983240683,
            "precision": 0.7159420289855073,
            "recall": 0.5030549898167006
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7128577023545303,
            "auditor_fn_violation": 0.007508422377801442,
            "auditor_fp_violation": 0.009330406147091115,
            "ave_precision_score": 0.6891242695644685,
            "fpr": 0.10757409440175632,
            "logloss": 0.9270397906085174,
            "mae": 0.416745031394093,
            "precision": 0.7231638418079096,
            "recall": 0.5529157667386609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8128931357926172,
            "auditor_fn_violation": 0.00653428377460965,
            "auditor_fp_violation": 0.005003229570362962,
            "ave_precision_score": 0.8036330005831144,
            "fpr": 0.03070175438596491,
            "logloss": 0.5836136201010662,
            "mae": 0.3890481297776364,
            "precision": 0.8939393939393939,
            "recall": 0.48065173116089616
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8165031766187205,
            "auditor_fn_violation": 0.00607881117040825,
            "auditor_fp_violation": 0.0017249490355966783,
            "ave_precision_score": 0.806825593330096,
            "fpr": 0.03512623490669594,
            "logloss": 0.5655392289121618,
            "mae": 0.3837514854027071,
            "precision": 0.8735177865612648,
            "recall": 0.4773218142548596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5561232671477939,
            "auditor_fn_violation": 0.0050157215850216335,
            "auditor_fp_violation": 0.0010834687669291998,
            "ave_precision_score": 0.5575345854836777,
            "fpr": 0.02412280701754386,
            "logloss": 8.411740038834939,
            "mae": 0.5068812586562615,
            "precision": 0.7555555555555555,
            "recall": 0.1384928716904277
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.53001702186538,
            "auditor_fn_violation": 0.007804776276514798,
            "auditor_fp_violation": 0.007580954994511527,
            "ave_precision_score": 0.5314131180827961,
            "fpr": 0.038419319429198684,
            "logloss": 7.23206152376889,
            "mae": 0.47646588098733916,
            "precision": 0.7008547008547008,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6241309678510985,
            "auditor_fn_violation": 0.003410065387501345,
            "auditor_fp_violation": 0.013746509980414224,
            "ave_precision_score": 0.7134972903124912,
            "fpr": 0.1600877192982456,
            "logloss": 0.6087156767107834,
            "mae": 0.386582880133861,
            "precision": 0.7085828343313373,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.764321218379559,
            "auditor_fn_violation": 0.008663017167188642,
            "auditor_fp_violation": 0.004868570644503695,
            "ave_precision_score": 0.6913216892990862,
            "fpr": 0.17453347969264543,
            "logloss": 0.602382510311694,
            "mae": 0.39225121144242137,
            "precision": 0.6735112936344969,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8117371143190842,
            "auditor_fn_violation": 0.011905080930431989,
            "auditor_fp_violation": 0.0208098929032796,
            "ave_precision_score": 0.6504535596458266,
            "fpr": 0.25548245614035087,
            "logloss": 0.6288932541429499,
            "mae": 0.4120792017824817,
            "precision": 0.6598540145985401,
            "recall": 0.9205702647657841
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8095745289984387,
            "auditor_fn_violation": 0.0060693278456494075,
            "auditor_fp_violation": 0.021400148972871274,
            "ave_precision_score": 0.6375694345870145,
            "fpr": 0.265642151481888,
            "logloss": 0.5849541172142868,
            "mae": 0.39763318576352136,
            "precision": 0.644640234948605,
            "recall": 0.9481641468682506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7531445097263106,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.001773659207400931,
            "ave_precision_score": 0.7463292627115291,
            "fpr": 0.4583333333333333,
            "logloss": 2.4197705003356633,
            "mae": 0.4403845852633056,
            "precision": 0.5401540154015402,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7295685763063262,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015607848518112075,
            "ave_precision_score": 0.7268439125326056,
            "fpr": 0.4840834248079034,
            "logloss": 2.569845969615837,
            "mae": 0.46111328267665125,
            "precision": 0.5121681415929203,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7153203770248289,
            "auditor_fn_violation": 0.006210472719476915,
            "auditor_fp_violation": 0.003674938533983414,
            "ave_precision_score": 0.6874504761983805,
            "fpr": 0.04824561403508772,
            "logloss": 0.6668741045122291,
            "mae": 0.48212786309682487,
            "precision": 0.7142857142857143,
            "recall": 0.2240325865580448
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7012318822814658,
            "auditor_fn_violation": 0.0035443926286116752,
            "auditor_fp_violation": 0.00615493178610632,
            "ave_precision_score": 0.6755659389582067,
            "fpr": 0.048298572996706916,
            "logloss": 0.6578329075412165,
            "mae": 0.4778071424701996,
            "precision": 0.7215189873417721,
            "recall": 0.24622030237580994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8418436287606214,
            "auditor_fn_violation": 0.01848849465823418,
            "auditor_fp_violation": 0.023570654665166484,
            "ave_precision_score": 0.8422159538266867,
            "fpr": 0.09210526315789473,
            "logloss": 0.5902347091058097,
            "mae": 0.3151210903905565,
            "precision": 0.8004750593824228,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8383152877108049,
            "auditor_fn_violation": 0.015704385800617837,
            "auditor_fp_violation": 0.020760643719617375,
            "ave_precision_score": 0.8387282679340125,
            "fpr": 0.0889132821075741,
            "logloss": 0.5378840422003267,
            "mae": 0.29301931162355205,
            "precision": 0.80622009569378,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8367175136161209,
            "auditor_fn_violation": 0.02006511951977704,
            "auditor_fp_violation": 0.022567925157311333,
            "ave_precision_score": 0.837034400866224,
            "fpr": 0.1337719298245614,
            "logloss": 0.976663334090608,
            "mae": 0.2769217046074067,
            "precision": 0.7505112474437627,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.819556506689072,
            "auditor_fn_violation": 0.02337876636169875,
            "auditor_fp_violation": 0.03273482828916419,
            "ave_precision_score": 0.8199745965605001,
            "fpr": 0.12733260153677278,
            "logloss": 0.8988755131432076,
            "mae": 0.2606697495410251,
            "precision": 0.7563025210084033,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7287295946329662,
            "auditor_fn_violation": 0.021402794154428847,
            "auditor_fp_violation": 0.03192326124098847,
            "ave_precision_score": 0.551665666253429,
            "fpr": 0.3399122807017544,
            "logloss": 0.6918970098469314,
            "mae": 0.4958727746352292,
            "precision": 0.5552367288378766,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7210953621150831,
            "auditor_fn_violation": 0.013058538192905056,
            "auditor_fp_violation": 0.02564636584600911,
            "ave_precision_score": 0.5304944095817313,
            "fpr": 0.3567508232711306,
            "logloss": 0.6881517227689271,
            "mae": 0.4940525754288444,
            "precision": 0.5357142857142857,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8122312999342197,
            "auditor_fn_violation": 0.0034167649265730545,
            "auditor_fp_violation": 0.011613430845522358,
            "ave_precision_score": 0.8056566983681774,
            "fpr": 0.0712719298245614,
            "logloss": 0.5522817017316638,
            "mae": 0.34280447057333957,
            "precision": 0.8395061728395061,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.837069054544783,
            "auditor_fn_violation": 0.0033286469903483495,
            "auditor_fp_violation": 0.012133448329935709,
            "ave_precision_score": 0.8256403246410301,
            "fpr": 0.07903402854006586,
            "logloss": 0.5082321059511477,
            "mae": 0.3268500375433628,
            "precision": 0.8213399503722084,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 14289,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.6060189454939477,
            "auditor_fn_violation": 0.0018423732447207764,
            "auditor_fp_violation": 0.006013772554902696,
            "ave_precision_score": 0.6074005286325609,
            "fpr": 0.044956140350877194,
            "logloss": 0.7621671248531192,
            "mae": 0.49469676277224434,
            "precision": 0.5858585858585859,
            "recall": 0.11812627291242363
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6064129876231331,
            "auditor_fn_violation": 0.0002584205996780703,
            "auditor_fp_violation": 0.011400835032146778,
            "ave_precision_score": 0.6072460704385937,
            "fpr": 0.05598243688254665,
            "logloss": 0.7328062972897367,
            "mae": 0.48257952508987895,
            "precision": 0.592,
            "recall": 0.15982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7877001830931407,
            "auditor_fn_violation": 0.00978132704469933,
            "auditor_fp_violation": 0.015306600825103142,
            "ave_precision_score": 0.7788135903262187,
            "fpr": 0.17763157894736842,
            "logloss": 0.9711034963182466,
            "mae": 0.31721374601648566,
            "precision": 0.7221269296740995,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7597111599916331,
            "auditor_fn_violation": 0.003608405070733752,
            "auditor_fp_violation": 0.01203543986200408,
            "ave_precision_score": 0.7519140648216375,
            "fpr": 0.18221734357848518,
            "logloss": 1.0077887356492008,
            "mae": 0.31822869492414624,
            "precision": 0.7082601054481547,
            "recall": 0.8704103671706264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7688074023074475,
            "auditor_fn_violation": 0.0014604995176331873,
            "auditor_fp_violation": 0.002560215860315889,
            "ave_precision_score": 0.5404228240477427,
            "fpr": 0.4550438596491228,
            "logloss": 0.6903956797855287,
            "mae": 0.49714117902004273,
            "precision": 0.540420819490587,
            "recall": 0.9938900203665988
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7512340020055885,
            "auditor_fn_violation": 0.0015339277797402995,
            "auditor_fp_violation": 0.0006958601223145765,
            "ave_precision_score": 0.5077837650030693,
            "fpr": 0.48737650933040616,
            "logloss": 0.6953007585581813,
            "mae": 0.4994845455921328,
            "precision": 0.5077605321507761,
            "recall": 0.9892008639308856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7619206857540035,
            "auditor_fn_violation": 0.003081787972987457,
            "auditor_fp_violation": 0.010212214026753347,
            "ave_precision_score": 0.7371871309377787,
            "fpr": 0.09758771929824561,
            "logloss": 0.6131380135008686,
            "mae": 0.37846128150755376,
            "precision": 0.8,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.7615388316418514,
            "auditor_fn_violation": 0.0031081596897056135,
            "auditor_fp_violation": 0.011368982280069006,
            "ave_precision_score": 0.7324106142820143,
            "fpr": 0.10537870472008781,
            "logloss": 0.5775555201812145,
            "mae": 0.36393514362242557,
            "precision": 0.785234899328859,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7055979777563626,
            "auditor_fn_violation": 0.012854182298924509,
            "auditor_fp_violation": 0.009993436679584949,
            "ave_precision_score": 0.705390665858931,
            "fpr": 0.07785087719298246,
            "logloss": 0.8389866153890219,
            "mae": 0.43440791302801746,
            "precision": 0.7078189300411523,
            "recall": 0.35030549898167007
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7037653738450996,
            "auditor_fn_violation": 0.017937708781321653,
            "auditor_fp_violation": 0.005794750666457587,
            "ave_precision_score": 0.7041898537731804,
            "fpr": 0.0889132821075741,
            "logloss": 0.7559651035230402,
            "mae": 0.4093449488478306,
            "precision": 0.6920152091254753,
            "recall": 0.3930885529157667
        }
    }
]