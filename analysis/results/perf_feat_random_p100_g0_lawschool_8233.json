[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8267769704271729,
            "auditor_fn_violation": 0.018146476729012612,
            "auditor_fp_violation": 0.027296995409083463,
            "ave_precision_score": 0.8272969737793818,
            "fpr": 0.13925438596491227,
            "logloss": 0.8482444638387294,
            "mae": 0.2741815990096633,
            "precision": 0.744466800804829,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8243083214825193,
            "auditor_fn_violation": 0.019943013289114138,
            "auditor_fp_violation": 0.031867997839457776,
            "ave_precision_score": 0.8247252732884256,
            "fpr": 0.13391877058177826,
            "logloss": 0.8516004216303239,
            "mae": 0.27170710205699405,
            "precision": 0.7484536082474227,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7337799661374027,
            "auditor_fn_violation": 0.008384533130346537,
            "auditor_fp_violation": 0.01359854074438433,
            "ave_precision_score": 0.676577472644476,
            "fpr": 0.12719298245614036,
            "logloss": 0.6217063834814001,
            "mae": 0.4103148179945716,
            "precision": 0.7321016166281755,
            "recall": 0.6549586776859504
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7364411452588784,
            "auditor_fn_violation": 0.009911950860639472,
            "auditor_fp_violation": 0.014123175797944499,
            "ave_precision_score": 0.6631805665594779,
            "fpr": 0.1437980241492865,
            "logloss": 0.6197338307170381,
            "mae": 0.407736272699354,
            "precision": 0.7133479212253829,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.824465384580787,
            "auditor_fn_violation": 0.02078349282296651,
            "auditor_fp_violation": 0.03355058206263322,
            "ave_precision_score": 0.8257870378339521,
            "fpr": 0.2598684210526316,
            "logloss": 0.6411293250430784,
            "mae": 0.32848336577240334,
            "precision": 0.6514705882352941,
            "recall": 0.9152892561983471
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.8232997825561675,
            "auditor_fn_violation": 0.02239764579489455,
            "auditor_fp_violation": 0.030869867156522342,
            "ave_precision_score": 0.8237179272964484,
            "fpr": 0.2579582875960483,
            "logloss": 0.6574407840943022,
            "mae": 0.33771104963969656,
            "precision": 0.6439393939393939,
            "recall": 0.9042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8545413392812735,
            "auditor_fn_violation": 0.04156472016818907,
            "auditor_fp_violation": 0.024081816691260863,
            "ave_precision_score": 0.8547804367983398,
            "fpr": 0.09539473684210527,
            "logloss": 0.798227388925679,
            "mae": 0.2925345777202183,
            "precision": 0.8075221238938053,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.84810408090604,
            "auditor_fn_violation": 0.047028049606464735,
            "auditor_fp_violation": 0.025821964351053266,
            "ave_precision_score": 0.8493536201440691,
            "fpr": 0.09220636663007684,
            "logloss": 0.7202484459415622,
            "mae": 0.2884451742690571,
            "precision": 0.8073394495412844,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6988158313152789,
            "auditor_fn_violation": 0.010946788458750181,
            "auditor_fp_violation": 0.00723479258894901,
            "ave_precision_score": 0.707281890086659,
            "fpr": 0.04057017543859649,
            "logloss": 5.246917361110732,
            "mae": 0.4574650556475491,
            "precision": 0.783625730994152,
            "recall": 0.2768595041322314
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6775737724297571,
            "auditor_fn_violation": 0.006973865520704396,
            "auditor_fp_violation": 0.0017075253079643874,
            "ave_precision_score": 0.6851442342020444,
            "fpr": 0.038419319429198684,
            "logloss": 5.334777166283665,
            "mae": 0.4625230665171306,
            "precision": 0.7682119205298014,
            "recall": 0.24680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 8233,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7151035044681624,
            "auditor_fn_violation": 0.000598086124401928,
            "auditor_fp_violation": 0.0029205607476635517,
            "ave_precision_score": 0.7164261317370255,
            "fpr": 0.007675438596491228,
            "logloss": 1.331220861763724,
            "mae": 0.5044124623119276,
            "precision": 0.125,
            "recall": 0.002066115702479339
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.6811955648576303,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031238254540747875,
            "ave_precision_score": 0.6827196100442071,
            "fpr": 0.005488474204171241,
            "logloss": 1.32760876001865,
            "mae": 0.4943353440965251,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7620797452471793,
            "auditor_fn_violation": 0.011809935479193852,
            "auditor_fp_violation": 0.0077061813412034755,
            "ave_precision_score": 0.7006763654138909,
            "fpr": 0.21271929824561403,
            "logloss": 0.736890656447032,
            "mae": 0.39477942031072943,
            "precision": 0.6590509666080844,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7497436032668809,
            "auditor_fn_violation": 0.008057547235910975,
            "auditor_fp_violation": 0.006384551625260423,
            "ave_precision_score": 0.6846217733851263,
            "fpr": 0.22722283205268934,
            "logloss": 0.7686688346287981,
            "mae": 0.39722179064504665,
            "precision": 0.6412478336221837,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8301855734356717,
            "auditor_fn_violation": 0.00558213716108453,
            "auditor_fp_violation": 0.002828332513526812,
            "ave_precision_score": 0.8188303738336971,
            "fpr": 0.07894736842105263,
            "logloss": 0.5147325449802339,
            "mae": 0.33702854544185756,
            "precision": 0.8301886792452831,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.817684643696023,
            "auditor_fn_violation": 0.008235046827194809,
            "auditor_fp_violation": 0.013132512426851461,
            "ave_precision_score": 0.8039030864065836,
            "fpr": 0.08122941822173436,
            "logloss": 0.5231110752024333,
            "mae": 0.33971133018495225,
            "precision": 0.815,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8668519860469794,
            "auditor_fn_violation": 0.03049333043352182,
            "auditor_fp_violation": 0.01767707820954255,
            "ave_precision_score": 0.8670419529626789,
            "fpr": 0.07894736842105263,
            "logloss": 0.6438038976711502,
            "mae": 0.2823207981343108,
            "precision": 0.8277511961722488,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8522108178379696,
            "auditor_fn_violation": 0.043249176728869375,
            "auditor_fp_violation": 0.01914867666788633,
            "ave_precision_score": 0.8527515759190516,
            "fpr": 0.09001097694840834,
            "logloss": 0.6347043394374056,
            "mae": 0.2864156186288208,
            "precision": 0.8004866180048662,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.7116887321074645,
            "auditor_fn_violation": 0.0001359286646368027,
            "auditor_fp_violation": 0.003824909821282193,
            "ave_precision_score": 0.5251500519613306,
            "fpr": 0.3782894736842105,
            "logloss": 0.7700690602300809,
            "mae": 0.5037612918266013,
            "precision": 0.5241379310344828,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.7026360426090732,
            "auditor_fn_violation": 0.004087161641404117,
            "auditor_fp_violation": 0.0036515154909384294,
            "ave_precision_score": 0.5184187243452396,
            "fpr": 0.36553238199780463,
            "logloss": 0.7582493441645753,
            "mae": 0.4995232183817451,
            "precision": 0.5194805194805194,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8346881457178369,
            "auditor_fn_violation": 0.004685007974481662,
            "auditor_fp_violation": 0.009625040990326288,
            "ave_precision_score": 0.817316292564275,
            "fpr": 0.0668859649122807,
            "logloss": 0.5656177918536643,
            "mae": 0.3651105290806906,
            "precision": 0.8216374269005848,
            "recall": 0.5805785123966942
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8022522117138031,
            "auditor_fn_violation": 0.013978092813602079,
            "auditor_fp_violation": 0.011830711062324676,
            "ave_precision_score": 0.7853296247985795,
            "fpr": 0.06147091108671789,
            "logloss": 0.5851097237926519,
            "mae": 0.3775600412396385,
            "precision": 0.8187702265372169,
            "recall": 0.5382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8395853307740182,
            "auditor_fn_violation": 0.005500579962302453,
            "auditor_fp_violation": 0.00010247581570749425,
            "ave_precision_score": 0.821822752463596,
            "fpr": 0.07017543859649122,
            "logloss": 0.5147487840998489,
            "mae": 0.34887541259491917,
            "precision": 0.8379746835443038,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8108283762580423,
            "auditor_fn_violation": 0.008204685055001519,
            "auditor_fp_violation": 0.008522691916137111,
            "ave_precision_score": 0.7918375945510235,
            "fpr": 0.07135016465422613,
            "logloss": 0.5252026275002583,
            "mae": 0.35394278580055016,
            "precision": 0.828042328042328,
            "recall": 0.6659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8702767666088169,
            "auditor_fn_violation": 0.004938741481803685,
            "auditor_fp_violation": 0.007447429906542059,
            "ave_precision_score": 0.8704595231641266,
            "fpr": 0.17214912280701755,
            "logloss": 0.5100429607948138,
            "mae": 0.3237502286384258,
            "precision": 0.7279029462738301,
            "recall": 0.8677685950413223
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8401973816841035,
            "auditor_fn_violation": 0.008034192026531519,
            "auditor_fp_violation": 0.011044154214924174,
            "ave_precision_score": 0.8406096699878067,
            "fpr": 0.1877058177826564,
            "logloss": 0.5339073502090371,
            "mae": 0.3371724604667828,
            "precision": 0.7076923076923077,
            "recall": 0.8808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8610095930880656,
            "auditor_fn_violation": 0.009234087284326523,
            "auditor_fp_violation": 0.015366248565338582,
            "ave_precision_score": 0.854838331775465,
            "fpr": 0.08552631578947369,
            "logloss": 0.4956952734093344,
            "mae": 0.316932686886407,
            "precision": 0.8206896551724138,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8569824927924815,
            "auditor_fn_violation": 0.010262279001331252,
            "auditor_fp_violation": 0.015469781033525747,
            "ave_precision_score": 0.8495571578263678,
            "fpr": 0.09659714599341383,
            "logloss": 0.48946246974500457,
            "mae": 0.31579831997433555,
            "precision": 0.7972350230414746,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7474501489194609,
            "auditor_fn_violation": 0.020090256633318836,
            "auditor_fp_violation": 0.040985202492211846,
            "ave_precision_score": 0.7487857950864147,
            "fpr": 0.32127192982456143,
            "logloss": 1.0741364777178068,
            "mae": 0.3486849836094756,
            "precision": 0.6056527590847914,
            "recall": 0.9297520661157025
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7316441968754251,
            "auditor_fn_violation": 0.019735151925637014,
            "auditor_fp_violation": 0.03639567791990564,
            "ave_precision_score": 0.7327642965664393,
            "fpr": 0.3194291986827662,
            "logloss": 1.0758365572772812,
            "mae": 0.36113096984031723,
            "precision": 0.5980662983425414,
            "recall": 0.9212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 8233,
        "test": {
            "accuracy": 0.40789473684210525,
            "auc_prc": 0.5359270168400846,
            "auditor_fn_violation": 0.00662652240104395,
            "auditor_fp_violation": 0.018314990162321694,
            "ave_precision_score": 0.5367880433730806,
            "fpr": 0.11293859649122807,
            "logloss": 5.125228083106404,
            "mae": 0.5856806442210647,
            "precision": 0.31333333333333335,
            "recall": 0.09710743801652892
        },
        "train": {
            "accuracy": 0.4105378704720088,
            "auc_prc": 0.5317495769507001,
            "auditor_fn_violation": 0.012333886073288659,
            "auditor_fp_violation": 0.026591097470821484,
            "ave_precision_score": 0.5320642223838457,
            "fpr": 0.13172338090010977,
            "logloss": 4.712471651899807,
            "mae": 0.5785778131907068,
            "precision": 0.3063583815028902,
            "recall": 0.1127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7655837117726962,
            "auditor_fn_violation": 0.002174858634188778,
            "auditor_fp_violation": 0.004616535497622559,
            "ave_precision_score": 0.5425256485066189,
            "fpr": 0.4440789473684211,
            "logloss": 15.098223802469922,
            "mae": 0.4480614053583786,
            "precision": 0.5423728813559322,
            "recall": 0.9917355371900827
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7554634311668997,
            "auditor_fn_violation": 0.001349931102132331,
            "auditor_fp_violation": 0.0033553121211895,
            "ave_precision_score": 0.5260414585567214,
            "fpr": 0.4588364434687157,
            "logloss": 15.57562575207273,
            "mae": 0.4653879983524938,
            "precision": 0.5255391600454029,
            "recall": 0.9851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.782716682561029,
            "auditor_fn_violation": 0.018117025518341313,
            "auditor_fp_violation": 0.024499405640268902,
            "ave_precision_score": 0.7745088836899339,
            "fpr": 0.1699561403508772,
            "logloss": 0.5650546853448621,
            "mae": 0.38940021527620655,
            "precision": 0.7129629629629629,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7334476135927348,
            "auditor_fn_violation": 0.011539808954387281,
            "auditor_fp_violation": 0.024111949939141415,
            "ave_precision_score": 0.7243548770508401,
            "fpr": 0.18990120746432493,
            "logloss": 0.5922002712165345,
            "mae": 0.40245589984398905,
            "precision": 0.6796296296296296,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.767928514866973,
            "mae": 0.5090439853895652,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7716044315603774,
            "mae": 0.5097151768652458,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7516898834616853,
            "auditor_fn_violation": 0.017627682325648836,
            "auditor_fp_violation": 0.0012348335792752856,
            "ave_precision_score": 0.682379185646643,
            "fpr": 0.28728070175438597,
            "logloss": 0.6390124334648903,
            "mae": 0.43011481677433294,
            "precision": 0.6095380029806259,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7255688126859879,
            "auditor_fn_violation": 0.014466216689632624,
            "auditor_fp_violation": 0.004398246675179403,
            "ave_precision_score": 0.6846814844150213,
            "fpr": 0.3172338090010977,
            "logloss": 0.6275067156125775,
            "mae": 0.4275042805144463,
            "precision": 0.5841726618705037,
            "recall": 0.8638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7783603604809162,
            "auditor_fn_violation": 0.008651859504132232,
            "auditor_fp_violation": 0.01939098622725037,
            "ave_precision_score": 0.6567373579325871,
            "fpr": 0.16337719298245615,
            "logloss": 0.628528616444516,
            "mae": 0.4292144291102886,
            "precision": 0.6921487603305785,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7829581152092574,
            "auditor_fn_violation": 0.007765607118667818,
            "auditor_fp_violation": 0.020863669287693124,
            "ave_precision_score": 0.6568087700586585,
            "fpr": 0.1712403951701427,
            "logloss": 0.619012421413379,
            "mae": 0.42392930843173215,
            "precision": 0.688622754491018,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7801839551927812,
            "auditor_fn_violation": 0.027299006814557058,
            "auditor_fp_violation": 0.040539432693884256,
            "ave_precision_score": 0.774388415981301,
            "fpr": 0.14912280701754385,
            "logloss": 2.2480901606487937,
            "mae": 0.2785730277368391,
            "precision": 0.7414448669201521,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7806754449829599,
            "auditor_fn_violation": 0.03633136371067566,
            "auditor_fp_violation": 0.038693120863420374,
            "ave_precision_score": 0.7725902016964761,
            "fpr": 0.1668496158068057,
            "logloss": 2.3673857645697156,
            "mae": 0.29193728031000216,
            "precision": 0.7099236641221374,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8617765826631667,
            "auditor_fn_violation": 0.007983543569667973,
            "auditor_fp_violation": 0.02019798327594688,
            "ave_precision_score": 0.861961236070249,
            "fpr": 0.15789473684210525,
            "logloss": 0.5665858519802749,
            "mae": 0.2758506655058897,
            "precision": 0.7348066298342542,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8517035819933725,
            "auditor_fn_violation": 0.013335824555667147,
            "auditor_fp_violation": 0.01930797932052441,
            "ave_precision_score": 0.8520314949188321,
            "fpr": 0.1756311745334797,
            "logloss": 0.5858215176466143,
            "mae": 0.2854279704866307,
            "precision": 0.7101449275362319,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.833381264890711,
            "auditor_fn_violation": 0.009016601420907641,
            "auditor_fp_violation": 0.009479012952943108,
            "ave_precision_score": 0.8199845645711494,
            "fpr": 0.09210526315789473,
            "logloss": 0.5102535235172312,
            "mae": 0.31166883634700515,
            "precision": 0.8108108108108109,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8491001533203693,
            "auditor_fn_violation": 0.008681131326342345,
            "auditor_fp_violation": 0.011265684466248998,
            "ave_precision_score": 0.8354750186452314,
            "fpr": 0.08781558726673985,
            "logloss": 0.48680498955221707,
            "mae": 0.3128545010063,
            "precision": 0.8090692124105012,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.847180740513669,
            "auditor_fn_violation": 0.014494526605770636,
            "auditor_fp_violation": 0.007844523692408591,
            "ave_precision_score": 0.8487524925890199,
            "fpr": 0.06359649122807018,
            "logloss": 0.5085881528849329,
            "mae": 0.3139399463165829,
            "precision": 0.8516624040920716,
            "recall": 0.6880165289256198
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8588399595370774,
            "auditor_fn_violation": 0.009634023869023988,
            "auditor_fp_violation": 0.005252009329161597,
            "ave_precision_score": 0.8575079379780494,
            "fpr": 0.06476399560922064,
            "logloss": 0.49964211537391084,
            "mae": 0.3141867783734356,
            "precision": 0.843915343915344,
            "recall": 0.6787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5873974148321832,
            "auditor_fn_violation": 0.004780158039727417,
            "auditor_fp_violation": 0.007939313821938028,
            "ave_precision_score": 0.5882665125695368,
            "fpr": 0.4155701754385965,
            "logloss": 0.6876959183097933,
            "mae": 0.49455881471696655,
            "precision": 0.5268414481897628,
            "recall": 0.871900826446281
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5197526141038187,
            "auditor_fn_violation": 0.005955578391760282,
            "auditor_fp_violation": 0.005503408827856076,
            "ave_precision_score": 0.5212901339478389,
            "fpr": 0.4313940724478595,
            "logloss": 0.6982902720765528,
            "mae": 0.4996542111448085,
            "precision": 0.5006353240152478,
            "recall": 0.8382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7974653175448891,
            "auditor_fn_violation": 0.009070972886762362,
            "auditor_fp_violation": 0.011664309722905403,
            "ave_precision_score": 0.7978586985404279,
            "fpr": 0.14144736842105263,
            "logloss": 0.9959604166423763,
            "mae": 0.3060642885774609,
            "precision": 0.7295597484276729,
            "recall": 0.71900826446281
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8016138987782846,
            "auditor_fn_violation": 0.01036504192260084,
            "auditor_fp_violation": 0.019870516812652617,
            "ave_precision_score": 0.8019361232787967,
            "fpr": 0.15477497255762898,
            "logloss": 0.9874609633796299,
            "mae": 0.3007729591545124,
            "precision": 0.7104722792607803,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7694232152790073,
            "auditor_fn_violation": 0.010856169348992311,
            "auditor_fp_violation": 0.000245941957697988,
            "ave_precision_score": 0.769798511760062,
            "fpr": 0.06578947368421052,
            "logloss": 0.6901293053305075,
            "mae": 0.42369154634427997,
            "precision": 0.8,
            "recall": 0.49586776859504134
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7621660934012771,
            "auditor_fn_violation": 0.013947731041408782,
            "auditor_fp_violation": 0.0068400576476474245,
            "ave_precision_score": 0.7627893763657021,
            "fpr": 0.05598243688254665,
            "logloss": 0.6746993165424158,
            "mae": 0.4150613729569051,
            "precision": 0.8235294117647058,
            "recall": 0.5063829787234042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7026092942546607,
            "auditor_fn_violation": 0.004503769754965929,
            "auditor_fp_violation": 0.010227086407607807,
            "ave_precision_score": 0.7429813250836401,
            "fpr": 0.10526315789473684,
            "logloss": 0.5731906833405334,
            "mae": 0.3679650596673845,
            "precision": 0.7899343544857768,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.724908269628023,
            "auditor_fn_violation": 0.005362356073522198,
            "auditor_fp_violation": 0.007878013993742397,
            "ave_precision_score": 0.7429105378170255,
            "fpr": 0.10428100987925357,
            "logloss": 0.5680574053583286,
            "mae": 0.3704364933605121,
            "precision": 0.7835990888382688,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.828689409589519,
            "auditor_fn_violation": 0.0017104356966797167,
            "auditor_fp_violation": 0.004601164125266437,
            "ave_precision_score": 0.7363592074488098,
            "fpr": 0.05482456140350877,
            "logloss": 0.5798373927542543,
            "mae": 0.3598574485891221,
            "precision": 0.8575498575498576,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8118013261549352,
            "auditor_fn_violation": 0.007917415979634258,
            "auditor_fp_violation": 0.01254259479130108,
            "ave_precision_score": 0.7142985360882652,
            "fpr": 0.06037321624588365,
            "logloss": 0.6070764403416533,
            "mae": 0.36535475351546126,
            "precision": 0.8387096774193549,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5957220461886376,
            "auditor_fn_violation": 0.005165289256198351,
            "auditor_fp_violation": 0.005795007378258731,
            "ave_precision_score": 0.5409843126228384,
            "fpr": 0.047149122807017545,
            "logloss": 0.6920661935588068,
            "mae": 0.49768100507361324,
            "precision": 0.5981308411214953,
            "recall": 0.1322314049586777
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5697941960376627,
            "auditor_fn_violation": 0.003521965574421394,
            "auditor_fp_violation": 0.006954556429231044,
            "ave_precision_score": 0.5276343438502045,
            "fpr": 0.054884742041712405,
            "logloss": 0.6893492572763025,
            "mae": 0.4954870010671972,
            "precision": 0.5535714285714286,
            "recall": 0.13191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6736487315170266,
            "auditor_fn_violation": 0.06761544874583152,
            "auditor_fp_violation": 0.074528098868667,
            "ave_precision_score": 0.657760774161722,
            "fpr": 0.26206140350877194,
            "logloss": 0.6793218906433114,
            "mae": 0.4567882200270169,
            "precision": 0.5914529914529915,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6951284655131402,
            "auditor_fn_violation": 0.05408599388093515,
            "auditor_fp_violation": 0.07767497778474726,
            "ave_precision_score": 0.6793651796699445,
            "fpr": 0.2535675082327113,
            "logloss": 0.6672096813494052,
            "mae": 0.4509791303541037,
            "precision": 0.5996533795493935,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5623493122043055,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006097311034595908,
            "ave_precision_score": 0.5260259041547682,
            "fpr": 0.4682017543859649,
            "logloss": 0.6912417303941296,
            "mae": 0.4985121952925335,
            "precision": 0.531284302963776,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5646185364719307,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005600483881807486,
            "ave_precision_score": 0.5258102220929459,
            "fpr": 0.4829857299670692,
            "logloss": 0.6923755165697382,
            "mae": 0.499078263664612,
            "precision": 0.5164835164835165,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8067631646411983,
            "auditor_fn_violation": 0.04447132811367261,
            "auditor_fp_violation": 0.06506189539268734,
            "ave_precision_score": 0.8073485666331964,
            "fpr": 0.21271929824561403,
            "logloss": 0.7319210495698887,
            "mae": 0.3374304501845534,
            "precision": 0.6750418760469011,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8086590964016713,
            "auditor_fn_violation": 0.050353831422098705,
            "auditor_fp_violation": 0.06985670228574414,
            "ave_precision_score": 0.8090364186175623,
            "fpr": 0.2239297475301866,
            "logloss": 0.7029325659826197,
            "mae": 0.3365498280918905,
            "precision": 0.6559865092748736,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7934468555262649,
            "auditor_fn_violation": 0.008803646512976663,
            "auditor_fp_violation": 0.016501168224299066,
            "ave_precision_score": 0.7948131322040738,
            "fpr": 0.14144736842105263,
            "logloss": 0.9278466313097958,
            "mae": 0.2923936323909542,
            "precision": 0.7334710743801653,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8006649591160291,
            "auditor_fn_violation": 0.013265758927528785,
            "auditor_fp_violation": 0.018414391003382696,
            "ave_precision_score": 0.800995467791791,
            "fpr": 0.15148188803512624,
            "logloss": 0.9436365501610449,
            "mae": 0.28848446218579543,
            "precision": 0.7200811359026369,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7777443863719387,
            "auditor_fn_violation": 0.0017104356966797167,
            "auditor_fp_violation": 0.004601164125266437,
            "ave_precision_score": 0.7675713520757939,
            "fpr": 0.05482456140350877,
            "logloss": 0.5617917836747265,
            "mae": 0.36033540102551087,
            "precision": 0.8575498575498576,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7730975119464643,
            "auditor_fn_violation": 0.007917415979634258,
            "auditor_fp_violation": 0.01254259479130108,
            "ave_precision_score": 0.7595724571956208,
            "fpr": 0.06037321624588365,
            "logloss": 0.5890544232407414,
            "mae": 0.3659795656397481,
            "precision": 0.8387096774193549,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5877577145302496,
            "auditor_fn_violation": 0.008531789183703066,
            "auditor_fp_violation": 0.020054517133956395,
            "ave_precision_score": 0.5892264281120851,
            "fpr": 0.19407894736842105,
            "logloss": 1.472087648313446,
            "mae": 0.4725542512554183,
            "precision": 0.5651105651105651,
            "recall": 0.47520661157024796
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5268936017238219,
            "auditor_fn_violation": 0.005226895859121378,
            "auditor_fp_violation": 0.02466453101547974,
            "ave_precision_score": 0.5288403790739205,
            "fpr": 0.21624588364434688,
            "logloss": 1.6256111433617757,
            "mae": 0.4898761801428669,
            "precision": 0.5230024213075061,
            "recall": 0.4595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8159399636280644,
            "auditor_fn_violation": 0.006669566478178921,
            "auditor_fp_violation": 0.008841101000163965,
            "ave_precision_score": 0.816577759926433,
            "fpr": 0.10416666666666667,
            "logloss": 0.6747440196028307,
            "mae": 0.29274799744500835,
            "precision": 0.7811059907834101,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8231563370532426,
            "auditor_fn_violation": 0.009827872106873446,
            "auditor_fp_violation": 0.014543834365066921,
            "ave_precision_score": 0.8234759392496391,
            "fpr": 0.10647639956092206,
            "logloss": 0.6686404874066604,
            "mae": 0.28858335588406425,
            "precision": 0.7764976958525346,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 8233,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.6921114699981741,
            "auditor_fn_violation": 0.007145316804407716,
            "auditor_fp_violation": 0.0077881619937694695,
            "ave_precision_score": 0.5104029600523665,
            "fpr": 0.39035087719298245,
            "logloss": 0.6937391745478273,
            "mae": 0.500203830010274,
            "precision": 0.5034867503486751,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.6938680801662276,
            "auditor_fn_violation": 0.009491557091809329,
            "auditor_fp_violation": 0.01264215894919989,
            "ave_precision_score": 0.5020343829049094,
            "fpr": 0.40175631174533477,
            "logloss": 0.6937322298361083,
            "mae": 0.5001990922065257,
            "precision": 0.49794238683127573,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7460435578302596,
            "auditor_fn_violation": 0.008248604465709733,
            "auditor_fp_violation": 0.0191219872110182,
            "ave_precision_score": 0.7476791891505116,
            "fpr": 0.20175438596491227,
            "logloss": 0.6012105111563892,
            "mae": 0.40317173217210855,
            "precision": 0.6743362831858407,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7462974756763067,
            "auditor_fn_violation": 0.012004577621038376,
            "auditor_fp_violation": 0.024836279187855165,
            "ave_precision_score": 0.746822076939239,
            "fpr": 0.21405049396267836,
            "logloss": 0.6043448653787132,
            "mae": 0.40053537304786113,
            "precision": 0.6572934973637962,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7491568485563813,
            "auditor_fn_violation": 0.010267145135566194,
            "auditor_fp_violation": 0.013265494343334974,
            "ave_precision_score": 0.7495726660964774,
            "fpr": 0.12609649122807018,
            "logloss": 0.8450315162578412,
            "mae": 0.2985888888679904,
            "precision": 0.7648261758691206,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.721414664346739,
            "auditor_fn_violation": 0.005175514398486589,
            "auditor_fp_violation": 0.018389499963907992,
            "ave_precision_score": 0.7222665137943851,
            "fpr": 0.14928649835345773,
            "logloss": 0.9334889569039151,
            "mae": 0.31566990784028204,
            "precision": 0.7213114754098361,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.3682310221265492,
            "mae": 0.4001444377527948,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7711485772029898,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6954042841191628,
            "fpr": 0.12403951701427003,
            "logloss": 3.5967643941192255,
            "mae": 0.4009442203131256,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7573360112332203,
            "auditor_fn_violation": 0.005500579962302453,
            "auditor_fp_violation": 0.00010247581570749425,
            "ave_precision_score": 0.7384773707754858,
            "fpr": 0.07017543859649122,
            "logloss": 0.5444808017725975,
            "mae": 0.3653021210706548,
            "precision": 0.8379746835443038,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7553479816529148,
            "auditor_fn_violation": 0.008204685055001519,
            "auditor_fp_violation": 0.008415660446395901,
            "ave_precision_score": 0.725903591125016,
            "fpr": 0.07244785949506037,
            "logloss": 0.5502148154929628,
            "mae": 0.36791404182117937,
            "precision": 0.8258575197889182,
            "recall": 0.6659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8393229999863078,
            "auditor_fn_violation": 0.022971944323618973,
            "auditor_fp_violation": 0.03581529758976882,
            "ave_precision_score": 0.8390001486655152,
            "fpr": 0.20394736842105263,
            "logloss": 1.6354872774961131,
            "mae": 0.33945595491262537,
            "precision": 0.671957671957672,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8283861390623238,
            "auditor_fn_violation": 0.01871920031763085,
            "auditor_fp_violation": 0.023783388218075373,
            "ave_precision_score": 0.8292337154151356,
            "fpr": 0.19209659714599342,
            "logloss": 1.465858157764327,
            "mae": 0.33985407060013434,
            "precision": 0.6841155234657039,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7426263008295505,
            "auditor_fn_violation": 0.008651859504132232,
            "auditor_fp_violation": 0.018932406951959337,
            "ave_precision_score": 0.74419312394073,
            "fpr": 0.16447368421052633,
            "logloss": 1.0134035412292701,
            "mae": 0.35072643778182,
            "precision": 0.6907216494845361,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.742823048035504,
            "auditor_fn_violation": 0.007132680944484671,
            "auditor_fp_violation": 0.020863669287693124,
            "ave_precision_score": 0.7434763191329619,
            "fpr": 0.1712403951701427,
            "logloss": 0.9754144121664277,
            "mae": 0.339385458591762,
            "precision": 0.6892430278884463,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6818278922514925,
            "auditor_fn_violation": 0.031580759750616215,
            "auditor_fp_violation": 0.04093652647975078,
            "ave_precision_score": 0.6838991152473458,
            "fpr": 0.24890350877192982,
            "logloss": 0.684727396789913,
            "mae": 0.4290819253528912,
            "precision": 0.6184873949579832,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.702093791201511,
            "auditor_fn_violation": 0.023992806595511132,
            "auditor_fp_violation": 0.027599184569546818,
            "ave_precision_score": 0.6939702680222117,
            "fpr": 0.25686059275521406,
            "logloss": 0.6654025211692716,
            "mae": 0.41960068191965205,
            "precision": 0.6231884057971014,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7455170234684081,
            "auditor_fn_violation": 0.02020353052051617,
            "auditor_fp_violation": 0.016355140186915897,
            "ave_precision_score": 0.7472227905512229,
            "fpr": 0.06578947368421052,
            "logloss": 0.630888110982384,
            "mae": 0.4332202908730036,
            "precision": 0.7841726618705036,
            "recall": 0.45041322314049587
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7480292320162409,
            "auditor_fn_violation": 0.014767498890627563,
            "auditor_fp_violation": 0.010506507762270665,
            "ave_precision_score": 0.7485069321350744,
            "fpr": 0.06915477497255763,
            "logloss": 0.623809593179133,
            "mae": 0.4317135881513979,
            "precision": 0.776595744680851,
            "recall": 0.46595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8190855765950972,
            "auditor_fn_violation": 0.01211124401913876,
            "auditor_fp_violation": 0.009443146417445486,
            "ave_precision_score": 0.8236370364983073,
            "fpr": 0.10307017543859649,
            "logloss": 0.5153148071519601,
            "mae": 0.33955079268075916,
            "precision": 0.7920353982300885,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8415963251849325,
            "auditor_fn_violation": 0.009276689165518374,
            "auditor_fp_violation": 0.012286217084711677,
            "ave_precision_score": 0.8334539903979422,
            "fpr": 0.09440175631174534,
            "logloss": 0.499891889551474,
            "mae": 0.33520778217051345,
            "precision": 0.7976470588235294,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8234974422001379,
            "auditor_fn_violation": 0.029836341887777295,
            "auditor_fp_violation": 0.036460895228726024,
            "ave_precision_score": 0.8237731691559737,
            "fpr": 0.20065789473684212,
            "logloss": 1.1122275645483999,
            "mae": 0.32971449264015074,
            "precision": 0.6833910034602076,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7817983515425109,
            "auditor_fn_violation": 0.026783754116355658,
            "auditor_fp_violation": 0.03548217677118414,
            "ave_precision_score": 0.7826817912651699,
            "fpr": 0.20636663007683864,
            "logloss": 1.0842236846324145,
            "mae": 0.3404335833041557,
            "precision": 0.6666666666666666,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6473576663060672,
            "auditor_fn_violation": 0.011340981586196914,
            "auditor_fp_violation": 0.017372212657812764,
            "ave_precision_score": 0.5451966126676923,
            "fpr": 0.17434210526315788,
            "logloss": 2.367346105862916,
            "mae": 0.5033568437993079,
            "precision": 0.5643835616438356,
            "recall": 0.4256198347107438
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.6022298906425865,
            "auditor_fn_violation": 0.003970385594506851,
            "auditor_fp_violation": 0.021737344773255077,
            "ave_precision_score": 0.5121110584735805,
            "fpr": 0.1964873765093304,
            "logloss": 2.4429024055903192,
            "mae": 0.5152945919752455,
            "precision": 0.5013927576601671,
            "recall": 0.3829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 8233,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6554757977294521,
            "auditor_fn_violation": 0.12015414310569814,
            "auditor_fp_violation": 0.09737764387604525,
            "ave_precision_score": 0.6593673243144171,
            "fpr": 0.19846491228070176,
            "logloss": 1.8502341038245582,
            "mae": 0.46776481078445775,
            "precision": 0.5790697674418605,
            "recall": 0.5144628099173554
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6169007619337507,
            "auditor_fn_violation": 0.11339421257911576,
            "auditor_fp_violation": 0.09856104900796762,
            "ave_precision_score": 0.6061846932006957,
            "fpr": 0.22063666300768386,
            "logloss": 1.8305948150127491,
            "mae": 0.4826299847929819,
            "precision": 0.5421412300683371,
            "recall": 0.5063829787234042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4550438596491228,
            "auc_prc": 0.4754165080020042,
            "auditor_fn_violation": 0.002709511381760191,
            "auditor_fp_violation": 0.003904328578455485,
            "ave_precision_score": 0.6201448218822878,
            "fpr": 0.021929824561403508,
            "logloss": 0.7081815587775744,
            "mae": 0.4659412776103668,
            "precision": 0.25925925925925924,
            "recall": 0.014462809917355372
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.49395695321821825,
            "auditor_fn_violation": 0.0008501296214120537,
            "auditor_fp_violation": 0.0037635251685745647,
            "ave_precision_score": 0.5880321070419144,
            "fpr": 0.02305159165751921,
            "logloss": 0.7065211688653384,
            "mae": 0.4677340438023095,
            "precision": 0.34375,
            "recall": 0.023404255319148935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7295211960883609,
            "auditor_fn_violation": 0.09086831230969987,
            "auditor_fp_violation": 0.053804927037219216,
            "ave_precision_score": 0.6053292730781569,
            "fpr": 0.15570175438596492,
            "logloss": 0.6798138295627901,
            "mae": 0.46098923572061357,
            "precision": 0.6610978520286396,
            "recall": 0.5723140495867769
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7534862650385887,
            "auditor_fn_violation": 0.085891118013873,
            "auditor_fp_violation": 0.048253769125652456,
            "ave_precision_score": 0.6235209934341516,
            "fpr": 0.14818880351262348,
            "logloss": 0.6455061060252665,
            "mae": 0.44488334413679187,
            "precision": 0.6867749419953596,
            "recall": 0.6297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6534666848928833,
            "auditor_fn_violation": 0.006631053356531834,
            "auditor_fp_violation": 0.005679722085587798,
            "ave_precision_score": 0.6669674156731756,
            "fpr": 0.10635964912280702,
            "logloss": 1.0367912077514136,
            "mae": 0.4397902329160468,
            "precision": 0.7473958333333334,
            "recall": 0.5929752066115702
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6091332091680888,
            "auditor_fn_violation": 0.014568979610902212,
            "auditor_fp_violation": 0.007997490983220952,
            "ave_precision_score": 0.626055578773195,
            "fpr": 0.12843029637760703,
            "logloss": 1.128447543019714,
            "mae": 0.45334343134527044,
            "precision": 0.7022900763358778,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6748883092902359,
            "auditor_fn_violation": 0.005158492822966517,
            "auditor_fp_violation": 0.0031690646007542385,
            "ave_precision_score": 0.6798335911261437,
            "fpr": 0.26206140350877194,
            "logloss": 0.7090427449041156,
            "mae": 0.4357336948119235,
            "precision": 0.5989932885906041,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.708500919433995,
            "auditor_fn_violation": 0.014568979610902219,
            "auditor_fp_violation": 0.010406943604371876,
            "ave_precision_score": 0.7134113705154445,
            "fpr": 0.27442371020856204,
            "logloss": 0.6605735261036727,
            "mae": 0.42273284820379725,
            "precision": 0.5921696574225123,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6289700674225029,
            "auditor_fn_violation": 0.0036564810787298855,
            "auditor_fp_violation": 0.012128012788981797,
            "ave_precision_score": 0.5445211402162184,
            "fpr": 0.3442982456140351,
            "logloss": 0.6913534946845076,
            "mae": 0.49701945405257375,
            "precision": 0.5375552282768777,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5975403244490858,
            "auditor_fn_violation": 0.005738374944531379,
            "auditor_fp_violation": 0.006518963238423814,
            "ave_precision_score": 0.5128818190117281,
            "fpr": 0.34906695938529086,
            "logloss": 0.6926913909432527,
            "mae": 0.4977034445193675,
            "precision": 0.5174506828528073,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8001879839644201,
            "auditor_fn_violation": 0.002464839785413956,
            "auditor_fp_violation": 0.01075996064928677,
            "ave_precision_score": 0.8038089224810594,
            "fpr": 0.08771929824561403,
            "logloss": 0.5122119568655981,
            "mae": 0.33778275616401643,
            "precision": 0.8165137614678899,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8405331588571426,
            "auditor_fn_violation": 0.007716561178970972,
            "auditor_fp_violation": 0.012582420454460602,
            "ave_precision_score": 0.8267300866896337,
            "fpr": 0.09440175631174534,
            "logloss": 0.5008691374718633,
            "mae": 0.33614150777410073,
            "precision": 0.7952380952380952,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7251933542207806,
            "auditor_fn_violation": 0.00932017543859649,
            "auditor_fp_violation": 0.026080095097556984,
            "ave_precision_score": 0.7072058668690293,
            "fpr": 0.12719298245614036,
            "logloss": 1.9990108308528411,
            "mae": 0.34359356924081846,
            "precision": 0.7578288100208769,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.6932836004443734,
            "auditor_fn_violation": 0.0054417637854123424,
            "auditor_fp_violation": 0.03565641404750704,
            "ave_precision_score": 0.6743848312371272,
            "fpr": 0.13721185510428102,
            "logloss": 2.178607708524989,
            "mae": 0.3620271053371001,
            "precision": 0.7311827956989247,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7643206227945837,
            "auditor_fn_violation": 0.00631615195012325,
            "auditor_fp_violation": 0.016293654697491392,
            "ave_precision_score": 0.7646724635470129,
            "fpr": 0.12938596491228072,
            "logloss": 1.2612212602228368,
            "mae": 0.38023475066406953,
            "precision": 0.6894736842105263,
            "recall": 0.5413223140495868
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.732518538988722,
            "auditor_fn_violation": 0.008400868813788927,
            "auditor_fp_violation": 0.014845015942710788,
            "ave_precision_score": 0.7329282385989276,
            "fpr": 0.13721185510428102,
            "logloss": 1.4021047837949367,
            "mae": 0.3989413476155647,
            "precision": 0.6639784946236559,
            "recall": 0.5255319148936171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.4613274377030358,
            "auditor_fn_violation": 0.004005364651297671,
            "auditor_fp_violation": 0.005016191178881785,
            "ave_precision_score": 0.5262957063196297,
            "fpr": 0.025219298245614034,
            "logloss": 0.6969612266514308,
            "mae": 0.5015775624727994,
            "precision": 0.3783783783783784,
            "recall": 0.028925619834710745
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5187729172992035,
            "auditor_fn_violation": 0.003419202653151786,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5152054090664923,
            "fpr": 0.02305159165751921,
            "logloss": 0.6948647195510286,
            "mae": 0.5005224861376372,
            "precision": 0.5,
            "recall": 0.04468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.6514552706696616,
            "auditor_fn_violation": 0.002365158764680309,
            "auditor_fp_violation": 0.013016990490244306,
            "ave_precision_score": 0.6358291913653981,
            "fpr": 0.044956140350877194,
            "logloss": 1.0154808082971396,
            "mae": 0.4839798793147661,
            "precision": 0.6132075471698113,
            "recall": 0.13429752066115702
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.6009890432698266,
            "auditor_fn_violation": 0.01102132330616345,
            "auditor_fp_violation": 0.00046297333422941225,
            "ave_precision_score": 0.5916645240006482,
            "fpr": 0.05159165751920966,
            "logloss": 1.0266034804855648,
            "mae": 0.4874286054910603,
            "precision": 0.5104166666666666,
            "recall": 0.10425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7653508771929824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5307017543859649,
            "fpr": 0.4692982456140351,
            "logloss": 0.6915134339915883,
            "mae": 0.4988041713572385,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7579582875960482,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5159165751920965,
            "fpr": 0.4840834248079034,
            "logloss": 0.6926657779057159,
            "mae": 0.49938005182798034,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6189781687759988,
            "auditor_fn_violation": 0.009959040162389445,
            "auditor_fp_violation": 0.038090260698475154,
            "ave_precision_score": 0.6208265270037336,
            "fpr": 0.26535087719298245,
            "logloss": 0.6681215541107115,
            "mae": 0.431638029870667,
            "precision": 0.6230529595015576,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6446261129028878,
            "auditor_fn_violation": 0.003047854824018502,
            "auditor_fp_violation": 0.033363949311887214,
            "ave_precision_score": 0.6459585310974243,
            "fpr": 0.2502744237102086,
            "logloss": 0.6563570668103939,
            "mae": 0.4228205428740907,
            "precision": 0.6340288924558587,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6411953534949374,
            "auditor_fn_violation": 0.09732718935769176,
            "auditor_fp_violation": 0.08858009509755699,
            "ave_precision_score": 0.6272407005514723,
            "fpr": 0.27631578947368424,
            "logloss": 0.6697587134919376,
            "mae": 0.47133282562227624,
            "precision": 0.5778894472361809,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6617531333999902,
            "auditor_fn_violation": 0.0878389424761193,
            "auditor_fp_violation": 0.1018939591936299,
            "ave_precision_score": 0.6408757991099361,
            "fpr": 0.28210757409440174,
            "logloss": 0.6604439462096252,
            "mae": 0.4670308799565689,
            "precision": 0.5773026315789473,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6807322297353914,
            "auditor_fn_violation": 0.004163948093373937,
            "auditor_fp_violation": 0.0084696261682243,
            "ave_precision_score": 0.6782673319369378,
            "fpr": 0.02850877192982456,
            "logloss": 2.4582606600031376,
            "mae": 0.4792358311895954,
            "precision": 0.7592592592592593,
            "recall": 0.16942148760330578
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.6128857924204127,
            "auditor_fn_violation": 0.00418992456267372,
            "auditor_fp_violation": 0.005304280512058466,
            "ave_precision_score": 0.6138619038067763,
            "fpr": 0.03402854006586169,
            "logloss": 2.5506018616250143,
            "mae": 0.48675012765411574,
            "precision": 0.6352941176470588,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8157493211874016,
            "auditor_fn_violation": 0.008287117587356823,
            "auditor_fp_violation": 0.010339809804886047,
            "ave_precision_score": 0.8345462928751191,
            "fpr": 0.10087719298245613,
            "logloss": 0.49727500807115194,
            "mae": 0.32416466442181874,
            "precision": 0.7991266375545851,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8595152272285329,
            "auditor_fn_violation": 0.009351425835532624,
            "auditor_fp_violation": 0.007203466823978039,
            "ave_precision_score": 0.8537325830076983,
            "fpr": 0.09440175631174534,
            "logloss": 0.48852822347847646,
            "mae": 0.3247766459256443,
            "precision": 0.8022988505747126,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.6458721066988112,
            "auditor_fn_violation": 0.010031535450195748,
            "auditor_fp_violation": 0.011723233316937207,
            "ave_precision_score": 0.6399059005297111,
            "fpr": 0.06140350877192982,
            "logloss": 2.287757647303104,
            "mae": 0.4969136297951518,
            "precision": 0.631578947368421,
            "recall": 0.19834710743801653
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.599849358438973,
            "auditor_fn_violation": 0.003755517668215904,
            "auditor_fp_violation": 0.017555650141505563,
            "ave_precision_score": 0.5959933259483108,
            "fpr": 0.07354555433589462,
            "logloss": 2.3196724801943858,
            "mae": 0.49617725358670217,
            "precision": 0.5914634146341463,
            "recall": 0.20638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7636695137651416,
            "auditor_fn_violation": 0.01381714876033059,
            "auditor_fp_violation": 0.011187797179865554,
            "ave_precision_score": 0.7235046510170624,
            "fpr": 0.12171052631578948,
            "logloss": 3.5269599432473533,
            "mae": 0.34135688276166964,
            "precision": 0.7357142857142858,
            "recall": 0.6384297520661157
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7409103369524473,
            "auditor_fn_violation": 0.0068033724922344,
            "auditor_fp_violation": 0.018344696092853535,
            "ave_precision_score": 0.6967355015860165,
            "fpr": 0.12733260153677278,
            "logloss": 4.128195330000634,
            "mae": 0.3497293662427057,
            "precision": 0.7218225419664268,
            "recall": 0.6404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8560686773562619,
            "auditor_fn_violation": 0.008083224590401629,
            "auditor_fp_violation": 0.013157894736842108,
            "ave_precision_score": 0.8562563500208213,
            "fpr": 0.15789473684210525,
            "logloss": 0.5053199404746491,
            "mae": 0.3454471299663119,
            "precision": 0.7318435754189944,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8163573156961285,
            "auditor_fn_violation": 0.016521475115024407,
            "auditor_fp_violation": 0.016868657452003853,
            "ave_precision_score": 0.816864924200048,
            "fpr": 0.1877058177826564,
            "logloss": 0.545814740094692,
            "mae": 0.35838526770539286,
            "precision": 0.6907775768535263,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7529497665473777,
            "auditor_fn_violation": 0.02071552849064811,
            "auditor_fp_violation": 0.01945503361206756,
            "ave_precision_score": 0.6685661517613919,
            "fpr": 0.1513157894736842,
            "logloss": 0.6382432075766767,
            "mae": 0.42635080788545965,
            "precision": 0.6973684210526315,
            "recall": 0.6570247933884298
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7734700994324244,
            "auditor_fn_violation": 0.017035289721372353,
            "auditor_fp_violation": 0.027554380698492354,
            "ave_precision_score": 0.687272189086774,
            "fpr": 0.15916575192096596,
            "logloss": 0.6030899852867201,
            "mae": 0.4124598964214587,
            "precision": 0.697286012526096,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7542027275383589,
            "auditor_fn_violation": 0.01029433086849355,
            "auditor_fp_violation": 0.03728070175438597,
            "ave_precision_score": 0.5866781192619426,
            "fpr": 0.2850877192982456,
            "logloss": 0.6819913017701764,
            "mae": 0.46186057246175777,
            "precision": 0.6,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7564318039975768,
            "auditor_fn_violation": 0.009528925426816453,
            "auditor_fp_violation": 0.038217702009453625,
            "ave_precision_score": 0.5876221853101129,
            "fpr": 0.27552140504939626,
            "logloss": 0.6641113413913736,
            "mae": 0.452921691304635,
            "precision": 0.6034755134281201,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.610625557628828,
            "auditor_fn_violation": 0.006569885457445262,
            "auditor_fp_violation": 0.016969995081160844,
            "ave_precision_score": 0.6141373450767541,
            "fpr": 0.05701754385964912,
            "logloss": 1.0768330627339777,
            "mae": 0.47532831738077985,
            "precision": 0.7291666666666666,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5761149755939438,
            "auditor_fn_violation": 0.005317981175701269,
            "auditor_fp_violation": 0.012968231566318442,
            "ave_precision_score": 0.5801143510466666,
            "fpr": 0.0570801317233809,
            "logloss": 1.1059932918024478,
            "mae": 0.48221791504128836,
            "precision": 0.6848484848484848,
            "recall": 0.2404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7651727911153363,
            "auditor_fn_violation": 0.02271821081629695,
            "auditor_fp_violation": 0.016795786194458106,
            "ave_precision_score": 0.7484386815971643,
            "fpr": 0.18859649122807018,
            "logloss": 0.6083277870526724,
            "mae": 0.42960537612242133,
            "precision": 0.6742424242424242,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7723632041539675,
            "auditor_fn_violation": 0.03598337109092183,
            "auditor_fp_violation": 0.015350304044047192,
            "ave_precision_score": 0.7567587960059184,
            "fpr": 0.1690450054884742,
            "logloss": 0.6042734709609775,
            "mae": 0.4271385216621353,
            "precision": 0.6876267748478702,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5426984443415317,
            "auditor_fn_violation": 0.016338625489343204,
            "auditor_fp_violation": 0.003912014264633548,
            "ave_precision_score": 0.573226369142383,
            "fpr": 0.03179824561403509,
            "logloss": 0.6897720440782692,
            "mae": 0.4897274134451883,
            "precision": 0.5671641791044776,
            "recall": 0.07851239669421488
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5369676596328282,
            "auditor_fn_violation": 0.014400822103370159,
            "auditor_fp_violation": 0.005625374921282089,
            "ave_precision_score": 0.5534640910664012,
            "fpr": 0.031833150384193196,
            "logloss": 0.6907765259681251,
            "mae": 0.49069154815406885,
            "precision": 0.5671641791044776,
            "recall": 0.08085106382978724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 8233,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5493377259187147,
            "auditor_fn_violation": 0.0017693381180223435,
            "auditor_fp_violation": 0.0046011641252664374,
            "ave_precision_score": 0.55083412080764,
            "fpr": 0.03179824561403509,
            "logloss": 0.6982323529597706,
            "mae": 0.5002350483841279,
            "precision": 0.532258064516129,
            "recall": 0.06818181818181818
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5309889748931151,
            "auditor_fn_violation": 0.002312165728565771,
            "auditor_fp_violation": 0.001724949035596676,
            "ave_precision_score": 0.5328047970602804,
            "fpr": 0.021953896816684963,
            "logloss": 0.6962237252467556,
            "mae": 0.498923315812806,
            "precision": 0.5,
            "recall": 0.0425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7862513895735128,
            "auditor_fn_violation": 0.0037697549659272116,
            "auditor_fp_violation": 0.011979422856205938,
            "ave_precision_score": 0.7865477443422346,
            "fpr": 0.10964912280701754,
            "logloss": 0.5973808140894301,
            "mae": 0.4326694573096016,
            "precision": 0.7395833333333334,
            "recall": 0.5867768595041323
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7581466729128428,
            "auditor_fn_violation": 0.015080458696312214,
            "auditor_fp_violation": 0.009388900089856654,
            "ave_precision_score": 0.7585300246041548,
            "fpr": 0.1163556531284303,
            "logloss": 0.6101462888701528,
            "mae": 0.43859609148570394,
            "precision": 0.7203166226912929,
            "recall": 0.5808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8321988691973728,
            "auditor_fn_violation": 0.0032033855299405667,
            "auditor_fp_violation": 0.006363748155435316,
            "ave_precision_score": 0.8324403394513475,
            "fpr": 0.09429824561403509,
            "logloss": 0.5705303845596321,
            "mae": 0.3428452621426499,
            "precision": 0.7866004962779156,
            "recall": 0.6549586776859504
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7953399888014865,
            "auditor_fn_violation": 0.004386108321461118,
            "auditor_fp_violation": 0.004569994847554833,
            "ave_precision_score": 0.7947759504351436,
            "fpr": 0.10867178924259056,
            "logloss": 0.6255711232567194,
            "mae": 0.36568652204637603,
            "precision": 0.7506297229219143,
            "recall": 0.6340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5924390591157966,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5387590077263534,
            "fpr": 0.4692982456140351,
            "logloss": 0.6917281508046229,
            "mae": 0.49917437031603695,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5883918198150175,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5265750455541068,
            "fpr": 0.4840834248079034,
            "logloss": 0.6921302388857006,
            "mae": 0.49937213854261076,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6763101558993765,
            "auditor_fn_violation": 0.008488745106568081,
            "auditor_fp_violation": 0.005487579931136251,
            "ave_precision_score": 0.7251302203102928,
            "fpr": 0.16337719298245615,
            "logloss": 0.6070262855301062,
            "mae": 0.4026409262135674,
            "precision": 0.7112403100775194,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7260381873565265,
            "auditor_fn_violation": 0.00685708947380713,
            "auditor_fp_violation": 0.007464822738462384,
            "ave_precision_score": 0.7447507233808754,
            "fpr": 0.14270032930845225,
            "logloss": 0.582284091914044,
            "mae": 0.3922496494335152,
            "precision": 0.7325102880658436,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.730431113180795,
            "auditor_fn_violation": 0.00719515731477454,
            "auditor_fp_violation": 0.005795007378258731,
            "ave_precision_score": 0.6960000912433006,
            "fpr": 0.11074561403508772,
            "logloss": 0.629288686623519,
            "mae": 0.40523821179215846,
            "precision": 0.7688787185354691,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7188286582557376,
            "auditor_fn_violation": 0.001697923721886171,
            "auditor_fp_violation": 0.0035370167093548054,
            "ave_precision_score": 0.6957480912631595,
            "fpr": 0.09989023051591657,
            "logloss": 0.6347150227256608,
            "mae": 0.41127916254536645,
            "precision": 0.7713567839195979,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8098533605121747,
            "auditor_fn_violation": 0.016415651732637378,
            "auditor_fp_violation": 0.00629457697983276,
            "ave_precision_score": 0.7423161745117238,
            "fpr": 0.0712719298245614,
            "logloss": 0.601799254720078,
            "mae": 0.36531310564462555,
            "precision": 0.8036253776435045,
            "recall": 0.5495867768595041
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.8015353116969958,
            "auditor_fn_violation": 0.007389588247658647,
            "auditor_fp_violation": 0.004278769685700843,
            "ave_precision_score": 0.73243638680471,
            "fpr": 0.06695938529088913,
            "logloss": 0.5939853928210119,
            "mae": 0.3642297879139495,
            "precision": 0.8025889967637541,
            "recall": 0.5276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7239390860366347,
            "auditor_fn_violation": 0.01665805785123967,
            "auditor_fp_violation": 0.022375594359731108,
            "ave_precision_score": 0.7251937247730589,
            "fpr": 0.15460526315789475,
            "logloss": 1.103278775173364,
            "mae": 0.3747063536164269,
            "precision": 0.7,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7166861380287883,
            "auditor_fn_violation": 0.014456874605880845,
            "auditor_fp_violation": 0.01948719480474225,
            "ave_precision_score": 0.7184375044723432,
            "fpr": 0.16575192096597147,
            "logloss": 1.1353108036064317,
            "mae": 0.36646249137908776,
            "precision": 0.6937119675456389,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7080361532039763,
            "auditor_fn_violation": 0.005591199072060318,
            "auditor_fp_violation": 0.00443720282013445,
            "ave_precision_score": 0.6985896365517088,
            "fpr": 0.20614035087719298,
            "logloss": 1.369085202645991,
            "mae": 0.34802381581373576,
            "precision": 0.6907894736842105,
            "recall": 0.8677685950413223
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6718930971068248,
            "auditor_fn_violation": 0.004941962304692069,
            "auditor_fp_violation": 0.008579941306928924,
            "ave_precision_score": 0.6608495061461133,
            "fpr": 0.2327113062568606,
            "logloss": 1.5488290629086596,
            "mae": 0.3707969646265017,
            "precision": 0.6547231270358306,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8398583142430288,
            "auditor_fn_violation": 0.004141293315934467,
            "auditor_fp_violation": 0.010585751762584035,
            "ave_precision_score": 0.8287659957208816,
            "fpr": 0.10087719298245613,
            "logloss": 0.5180020710464794,
            "mae": 0.3234695950114544,
            "precision": 0.7964601769911505,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8380623708076284,
            "auditor_fn_violation": 0.008006165775276181,
            "auditor_fp_violation": 0.013545703682131474,
            "ave_precision_score": 0.8256542647016354,
            "fpr": 0.11086717892425905,
            "logloss": 0.5347541416100257,
            "mae": 0.3342392658640996,
            "precision": 0.7699316628701595,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.5430986581163143,
            "auditor_fn_violation": 0.014213607365521245,
            "auditor_fp_violation": 0.021765863256271528,
            "ave_precision_score": 0.584985782301049,
            "fpr": 0.3026315789473684,
            "logloss": 0.6721867694088054,
            "mae": 0.4811832883901763,
            "precision": 0.5970802919708029,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.4998230319408513,
            "auditor_fn_violation": 0.0073031739729546696,
            "auditor_fp_violation": 0.02536148012077132,
            "ave_precision_score": 0.5744766974670645,
            "fpr": 0.3106476399560922,
            "logloss": 0.6718655135516236,
            "mae": 0.48118021196054966,
            "precision": 0.5874635568513119,
            "recall": 0.8574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6483003950749867,
            "auditor_fn_violation": 0.1081357836740612,
            "auditor_fp_violation": 0.07998237415969832,
            "ave_precision_score": 0.556170748421073,
            "fpr": 0.1524122807017544,
            "logloss": 0.7008157748970335,
            "mae": 0.49142369131247204,
            "precision": 0.5850746268656717,
            "recall": 0.4049586776859504
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6880071141168012,
            "auditor_fn_violation": 0.11280566130275359,
            "auditor_fp_violation": 0.0846220669021359,
            "ave_precision_score": 0.5838063969005926,
            "fpr": 0.14709110867178923,
            "logloss": 0.6764931975163436,
            "mae": 0.47932362419059327,
            "precision": 0.6318681318681318,
            "recall": 0.48936170212765956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8173584710087947,
            "auditor_fn_violation": 0.008708496447730897,
            "auditor_fp_violation": 0.021391826528939166,
            "ave_precision_score": 0.8168027439743539,
            "fpr": 0.16776315789473684,
            "logloss": 1.2000972069551405,
            "mae": 0.2895093365035454,
            "precision": 0.7085714285714285,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8087671209596279,
            "auditor_fn_violation": 0.011532802391573446,
            "auditor_fp_violation": 0.022705606208820884,
            "ave_precision_score": 0.8081036287500921,
            "fpr": 0.17892425905598244,
            "logloss": 1.5745832670620543,
            "mae": 0.2965118155627795,
            "precision": 0.6953271028037383,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 8233,
        "test": {
            "accuracy": 0.42543859649122806,
            "auc_prc": 0.5700537754121238,
            "auditor_fn_violation": 0.008987150210236335,
            "auditor_fp_violation": 0.0028206468273487516,
            "ave_precision_score": 0.5680549708845306,
            "fpr": 0.43969298245614036,
            "logloss": 8.54630982715346,
            "mae": 0.5734752302259989,
            "precision": 0.473753280839895,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.41931942919868276,
            "auc_prc": 0.5689028761249693,
            "auditor_fn_violation": 0.023187051871920033,
            "auditor_fp_violation": 0.0073403675410888955,
            "ave_precision_score": 0.5688806144154462,
            "fpr": 0.44127332601536773,
            "logloss": 8.469960706009786,
            "mae": 0.5787179158715569,
            "precision": 0.4604026845637584,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.4716760905554178,
            "auditor_fn_violation": 0.09614007901986371,
            "auditor_fp_violation": 0.09547927939006394,
            "ave_precision_score": 0.47367356221880796,
            "fpr": 0.29714912280701755,
            "logloss": 5.622650401325138,
            "mae": 0.4865491939218421,
            "precision": 0.5586319218241043,
            "recall": 0.7086776859504132
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.4866014873030089,
            "auditor_fn_violation": 0.08391526730037134,
            "auditor_fp_violation": 0.10084604643174505,
            "ave_precision_score": 0.48842810274644244,
            "fpr": 0.29308452250274425,
            "logloss": 4.613062012720252,
            "mae": 0.4638728583814284,
            "precision": 0.5700483091787439,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7707274040075317,
            "auditor_fn_violation": 0.014172828766130203,
            "auditor_fp_violation": 0.016560091818330874,
            "ave_precision_score": 0.7224569263092432,
            "fpr": 0.16228070175438597,
            "logloss": 4.861454000384772,
            "mae": 0.3242529932611789,
            "precision": 0.6967213114754098,
            "recall": 0.7024793388429752
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7657910822476554,
            "auditor_fn_violation": 0.0090151108204685,
            "auditor_fp_violation": 0.02143367409166375,
            "ave_precision_score": 0.713332577915223,
            "fpr": 0.17233809001097694,
            "logloss": 4.89946858997867,
            "mae": 0.31911273948799196,
            "precision": 0.6872509960159362,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4451754385964912,
            "auc_prc": 0.4447806258232285,
            "auditor_fn_violation": 0.015890060896041756,
            "auditor_fp_violation": 0.009714707329070343,
            "ave_precision_score": 0.43785007906829104,
            "fpr": 0.17982456140350878,
            "logloss": 3.1833182483238627,
            "mae": 0.5538122228493816,
            "precision": 0.46405228758169936,
            "recall": 0.29338842975206614
        },
        "train": {
            "accuracy": 0.42590559824368823,
            "auc_prc": 0.4229787621235463,
            "auditor_fn_violation": 0.011957867202279471,
            "auditor_fp_violation": 0.017558139245453033,
            "ave_precision_score": 0.4101188445856083,
            "fpr": 0.18990120746432493,
            "logloss": 3.1800251444602816,
            "mae": 0.5616607672231257,
            "precision": 0.40955631399317405,
            "recall": 0.2553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7659257887569935,
            "auditor_fn_violation": 0.0010466507177033493,
            "auditor_fp_violation": 0.00252602885718972,
            "ave_precision_score": 0.5337782759464731,
            "fpr": 0.4616228070175439,
            "logloss": 15.948553148922983,
            "mae": 0.46453510785246627,
            "precision": 0.5337763012181617,
            "recall": 0.9958677685950413
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7584772457850036,
            "auditor_fn_violation": 0.0014994044421608242,
            "auditor_fp_violation": 0.0030068375685437018,
            "ave_precision_score": 0.5200329910708384,
            "fpr": 0.47310647639956094,
            "logloss": 16.34886668210072,
            "mae": 0.47779304238545384,
            "precision": 0.5200445434298441,
            "recall": 0.9936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7763234985559629,
            "auditor_fn_violation": 0.01169892706974047,
            "auditor_fp_violation": 0.03025342269224464,
            "ave_precision_score": 0.7642543582857326,
            "fpr": 0.20723684210526316,
            "logloss": 0.560248066261929,
            "mae": 0.3672275389626361,
            "precision": 0.6881188118811881,
            "recall": 0.8615702479338843
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8141636558522685,
            "auditor_fn_violation": 0.014755821285937828,
            "auditor_fp_violation": 0.02906028858671167,
            "ave_precision_score": 0.7972827847983583,
            "fpr": 0.1986827661909989,
            "logloss": 0.5374592333767776,
            "mae": 0.35956722085745485,
            "precision": 0.6947723440134908,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5849694290794883,
            "auditor_fn_violation": 0.010147074815137026,
            "auditor_fp_violation": 0.011336387112641432,
            "ave_precision_score": 0.5772239794690708,
            "fpr": 0.26644736842105265,
            "logloss": 4.106426128718354,
            "mae": 0.4524761394427828,
            "precision": 0.5660714285714286,
            "recall": 0.6549586776859504
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5373137254329436,
            "auditor_fn_violation": 0.020160216736343044,
            "auditor_fp_violation": 0.012477878088666882,
            "ave_precision_score": 0.5297529693371312,
            "fpr": 0.287596048298573,
            "logloss": 4.437659517535565,
            "mae": 0.4853893786580997,
            "precision": 0.5270758122743683,
            "recall": 0.6212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8106199480292093,
            "auditor_fn_violation": 0.02224925692329999,
            "auditor_fp_violation": 0.024174044925397615,
            "ave_precision_score": 0.807412871508287,
            "fpr": 0.13815789473684212,
            "logloss": 0.9864638079360851,
            "mae": 0.31254676254047853,
            "precision": 0.7485029940119761,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8270549469019236,
            "auditor_fn_violation": 0.024009155242076745,
            "auditor_fp_violation": 0.03265455468685828,
            "ave_precision_score": 0.8252749412835573,
            "fpr": 0.16355653128430298,
            "logloss": 0.9328489438849522,
            "mae": 0.31882609265002954,
            "precision": 0.7129094412331407,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 8233,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5605222212556877,
            "auditor_fn_violation": 0.0030040234884732495,
            "auditor_fp_violation": 0.0009581488768650607,
            "ave_precision_score": 0.5598752417085305,
            "fpr": 0.019736842105263157,
            "logloss": 0.8976070733039155,
            "mae": 0.5080774695563474,
            "precision": 0.6170212765957447,
            "recall": 0.05991735537190083
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5254647530781793,
            "auditor_fn_violation": 0.0055865660835649434,
            "auditor_fp_violation": 0.0006720580658168867,
            "ave_precision_score": 0.5255694452312724,
            "fpr": 0.012074643249176729,
            "logloss": 0.9066163391485872,
            "mae": 0.5075373220064245,
            "precision": 0.5925925925925926,
            "recall": 0.03404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6898918767629799,
            "auditor_fn_violation": 0.02562708423952443,
            "auditor_fp_violation": 0.027045929660600106,
            "ave_precision_score": 0.6906198678392359,
            "fpr": 0.22916666666666666,
            "logloss": 3.005525364699253,
            "mae": 0.41668772061603276,
            "precision": 0.6333333333333333,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6772213997027975,
            "auditor_fn_violation": 0.026741714739472643,
            "auditor_fp_violation": 0.0254560660707752,
            "ave_precision_score": 0.6780652546172647,
            "fpr": 0.21075740944017562,
            "logloss": 3.2251887433772133,
            "mae": 0.4187189959721318,
            "precision": 0.6342857142857142,
            "recall": 0.7085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.795993062458266,
            "auditor_fn_violation": 0.012858851674641151,
            "auditor_fp_violation": 0.02126116986391212,
            "ave_precision_score": 0.7536400618504236,
            "fpr": 0.13267543859649122,
            "logloss": 3.013324560533479,
            "mae": 0.3086741964260074,
            "precision": 0.7441860465116279,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7863256648602622,
            "auditor_fn_violation": 0.019039166686129348,
            "auditor_fp_violation": 0.023073993593046453,
            "ave_precision_score": 0.7385216016580924,
            "fpr": 0.14270032930845225,
            "logloss": 3.120518008957933,
            "mae": 0.3128000449284769,
            "precision": 0.726890756302521,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6441469340114966,
            "auditor_fn_violation": 0.009048318109322924,
            "auditor_fp_violation": 0.016862395474667977,
            "ave_precision_score": 0.6426551701334323,
            "fpr": 0.15570175438596492,
            "logloss": 0.7254583914284735,
            "mae": 0.4602722776645239,
            "precision": 0.6223404255319149,
            "recall": 0.4834710743801653
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6499500331425723,
            "auditor_fn_violation": 0.007964126398393162,
            "auditor_fp_violation": 0.010374585253054763,
            "ave_precision_score": 0.637682898322791,
            "fpr": 0.1437980241492865,
            "logloss": 0.7106942196035614,
            "mae": 0.4520112606078288,
            "precision": 0.6469002695417789,
            "recall": 0.5106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7219151481752248,
            "auditor_fn_violation": 0.011218645788023784,
            "auditor_fp_violation": 0.013490941137891463,
            "ave_precision_score": 0.7223977314069618,
            "fpr": 0.13815789473684212,
            "logloss": 0.8726003653539979,
            "mae": 0.38687663969158803,
            "precision": 0.7149321266968326,
            "recall": 0.6528925619834711
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7169966820154368,
            "auditor_fn_violation": 0.009575635845575355,
            "auditor_fp_violation": 0.01984562577317792,
            "ave_precision_score": 0.7178050581490848,
            "fpr": 0.14928649835345773,
            "logloss": 0.7953241034565602,
            "mae": 0.377883658247617,
            "precision": 0.7081545064377682,
            "recall": 0.7021276595744681
        }
    }
]