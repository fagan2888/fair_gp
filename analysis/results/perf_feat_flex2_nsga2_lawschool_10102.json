[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.64810285090831,
            "mae": 0.5109649122807017,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.50156188882153,
            "mae": 0.535675082327113,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.64810285090831,
            "mae": 0.5109649122807017,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.50156188882153,
            "mae": 0.535675082327113,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.64810285090831,
            "mae": 0.5109649122807017,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.50156188882153,
            "mae": 0.535675082327113,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5073262424493622,
            "auditor_fn_violation": 0.007906031172351499,
            "auditor_fp_violation": 0.006571571866886948,
            "ave_precision_score": 0.5097237334064294,
            "fpr": 0.06030701754385965,
            "logloss": 0.6998778022554073,
            "mae": 0.5010088913208037,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5491761306746473,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.5514286709322156,
            "fpr": 0.05159165751920966,
            "logloss": 0.6995718171604506,
            "mae": 0.5006780943676878,
            "precision": 0.5765765765765766,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5006067070849658,
            "auditor_fn_violation": 0.006320118966945266,
            "auditor_fp_violation": 0.0072034064983085505,
            "ave_precision_score": 0.4959336756132412,
            "fpr": 0.0581140350877193,
            "logloss": 0.7093944159005496,
            "mae": 0.5026602042152694,
            "precision": 0.49038461538461536,
            "recall": 0.10944206008583691
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5612729212502111,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.00817432328280823,
            "ave_precision_score": 0.5588515449699237,
            "fpr": 0.04939626783754116,
            "logloss": 0.7087762213096102,
            "mae": 0.5022409294622528,
            "precision": 0.5871559633027523,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 10102,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.7606972294465857,
            "auditor_fn_violation": 0.002004743618703414,
            "auditor_fp_violation": 0.0005605381165919285,
            "ave_precision_score": 0.7029761051944774,
            "fpr": 0.013157894736842105,
            "logloss": 0.7658556711694787,
            "mae": 0.4993176483140703,
            "precision": 0.5384615384615384,
            "recall": 0.030042918454935622
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.8177045264236242,
            "auditor_fn_violation": 0.0035112738658653023,
            "auditor_fp_violation": 0.0016634099124698653,
            "ave_precision_score": 0.7625294093534364,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7274664980305895,
            "mae": 0.49782829164935255,
            "precision": 0.84,
            "recall": 0.0430327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5082817787239529,
            "auditor_fn_violation": 0.00499774113395076,
            "auditor_fp_violation": 0.01746518763275903,
            "ave_precision_score": 0.5102333821541083,
            "fpr": 0.1513157894736842,
            "logloss": 0.6948363446984063,
            "mae": 0.4988113408744858,
            "precision": 0.48507462686567165,
            "recall": 0.27896995708154504
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5405506329548442,
            "auditor_fn_violation": 0.005978837883068522,
            "auditor_fp_violation": 0.006542053649510974,
            "ave_precision_score": 0.5421363891357136,
            "fpr": 0.11964873765093303,
            "logloss": 0.6968802692592695,
            "mae": 0.49965335670797284,
            "precision": 0.556910569105691,
            "recall": 0.2807377049180328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5006067070849658,
            "auditor_fn_violation": 0.010235486785633614,
            "auditor_fp_violation": 0.0030706671386987665,
            "ave_precision_score": 0.4959336756132412,
            "fpr": 0.06030701754385965,
            "logloss": 0.707171517697503,
            "mae": 0.5024961060599277,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5612729212502111,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.00817432328280823,
            "ave_precision_score": 0.5588515449699237,
            "fpr": 0.04939626783754116,
            "logloss": 0.7056763797941974,
            "mae": 0.5016481852492176,
            "precision": 0.5871559633027523,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5073262424493622,
            "auditor_fn_violation": 0.007906031172351499,
            "auditor_fp_violation": 0.006571571866886948,
            "ave_precision_score": 0.5097237334064294,
            "fpr": 0.06030701754385965,
            "logloss": 0.6998778019255119,
            "mae": 0.5010088912881258,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5491761306746473,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.5514286709322156,
            "fpr": 0.05159165751920966,
            "logloss": 0.6995718161300705,
            "mae": 0.5006780940405493,
            "precision": 0.5765765765765766,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5082817787239529,
            "auditor_fn_violation": 0.00499774113395076,
            "auditor_fp_violation": 0.01746518763275903,
            "ave_precision_score": 0.5102333821541083,
            "fpr": 0.1513157894736842,
            "logloss": 0.6948363330159455,
            "mae": 0.4988113402209261,
            "precision": 0.48507462686567165,
            "recall": 0.27896995708154504
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5405506329548442,
            "auditor_fn_violation": 0.005978837883068522,
            "auditor_fp_violation": 0.006542053649510974,
            "ave_precision_score": 0.5421363891357136,
            "fpr": 0.11964873765093303,
            "logloss": 0.6968802537954872,
            "mae": 0.4996533547287846,
            "precision": 0.556910569105691,
            "recall": 0.2807377049180328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5006067070849658,
            "auditor_fn_violation": 0.006320118966945266,
            "auditor_fp_violation": 0.0072034064983085505,
            "ave_precision_score": 0.4959336756132412,
            "fpr": 0.0581140350877193,
            "logloss": 0.7093944318934468,
            "mae": 0.5026601707530126,
            "precision": 0.49038461538461536,
            "recall": 0.10944206008583691
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5612729212502111,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.00817432328280823,
            "ave_precision_score": 0.5588515449699237,
            "fpr": 0.04939626783754116,
            "logloss": 0.7087763483009367,
            "mae": 0.5022409511842528,
            "precision": 0.5871559633027523,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.01837211053384534,
            "auditor_fp_violation": 0.0023798284950043284,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.05263157894736842,
            "logloss": 0.7011540072070486,
            "mae": 0.5010201055556536,
            "precision": 0.5294117647058824,
            "recall": 0.11587982832618025
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.01014917852836911,
            "auditor_fp_violation": 0.002506792473394525,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.042810098792535674,
            "logloss": 0.7034581304954192,
            "mae": 0.502015186389898,
            "precision": 0.5666666666666667,
            "recall": 0.10450819672131148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.49865456188305557,
            "auditor_fn_violation": 0.01826387320231911,
            "auditor_fp_violation": 0.03213014318306979,
            "ave_precision_score": 0.5006077155819546,
            "fpr": 0.16776315789473684,
            "logloss": 0.699771851248884,
            "mae": 0.4999374515426002,
            "precision": 0.5048543689320388,
            "recall": 0.33476394849785407
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5378200588028221,
            "auditor_fn_violation": 0.02503104137049901,
            "auditor_fp_violation": 0.015505264004691807,
            "ave_precision_score": 0.539389248402761,
            "fpr": 0.13721185510428102,
            "logloss": 0.701448980358811,
            "mae": 0.5003401988751278,
            "precision": 0.5551601423487544,
            "recall": 0.319672131147541
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5082817787239529,
            "auditor_fn_violation": 0.00499774113395076,
            "auditor_fp_violation": 0.01746518763275903,
            "ave_precision_score": 0.5102333821541083,
            "fpr": 0.1513157894736842,
            "logloss": 0.6948363361328324,
            "mae": 0.49881133950201045,
            "precision": 0.48507462686567165,
            "recall": 0.27896995708154504
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5405506329548442,
            "auditor_fn_violation": 0.005978837883068522,
            "auditor_fp_violation": 0.006542053649510974,
            "ave_precision_score": 0.5421363891357136,
            "fpr": 0.11964873765093303,
            "logloss": 0.6968802630186338,
            "mae": 0.4996533573622499,
            "precision": 0.556910569105691,
            "recall": 0.2807377049180328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 10102,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.4976280083123922,
            "auditor_fn_violation": 0.0016423838566373078,
            "auditor_fp_violation": 0.024880025175045246,
            "ave_precision_score": 0.49961170767975716,
            "fpr": 0.16447368421052633,
            "logloss": 0.7005196537931376,
            "mae": 0.5002139084400576,
            "precision": 0.4755244755244755,
            "recall": 0.2918454935622318
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5350186408622333,
            "auditor_fn_violation": 0.0052567886127656725,
            "auditor_fp_violation": 0.011610134084852074,
            "ave_precision_score": 0.5365777076926999,
            "fpr": 0.13062568605927552,
            "logloss": 0.7023001434777542,
            "mae": 0.5006722471749351,
            "precision": 0.5423076923076923,
            "recall": 0.2889344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 10102,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.4976280083123922,
            "auditor_fn_violation": 0.0016423838566373078,
            "auditor_fp_violation": 0.024880025175045246,
            "ave_precision_score": 0.49961170767975716,
            "fpr": 0.16447368421052633,
            "logloss": 0.700519664546435,
            "mae": 0.5002139088485325,
            "precision": 0.4755244755244755,
            "recall": 0.2918454935622318
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5350186408622333,
            "auditor_fn_violation": 0.0052567886127656725,
            "auditor_fp_violation": 0.011610134084852074,
            "ave_precision_score": 0.5365777076926999,
            "fpr": 0.13062568605927552,
            "logloss": 0.7023001542785708,
            "mae": 0.5006722467169411,
            "precision": 0.5423076923076923,
            "recall": 0.2889344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5006067070849658,
            "auditor_fn_violation": 0.006320118966945266,
            "auditor_fp_violation": 0.0072034064983085505,
            "ave_precision_score": 0.4959336756132412,
            "fpr": 0.0581140350877193,
            "logloss": 0.7093944430886683,
            "mae": 0.502660152551375,
            "precision": 0.49038461538461536,
            "recall": 0.10944206008583691
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5612729212502111,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.00817432328280823,
            "ave_precision_score": 0.5588515449699237,
            "fpr": 0.04939626783754116,
            "logloss": 0.7087764192258008,
            "mae": 0.5022409626341023,
            "precision": 0.5871559633027523,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5073262424493622,
            "auditor_fn_violation": 0.007906031172351499,
            "auditor_fp_violation": 0.006571571866886948,
            "ave_precision_score": 0.5097237334064294,
            "fpr": 0.06030701754385965,
            "logloss": 0.6998778017915788,
            "mae": 0.5010088911900917,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5491761306746473,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.5514286709322156,
            "fpr": 0.05159165751920966,
            "logloss": 0.699571815793752,
            "mae": 0.5006780938442662,
            "precision": 0.5765765765765766,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6952084388385869,
            "mae": 0.5001856025896574,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6985101250854638,
            "mae": 0.501829054758656,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8293654091355622,
            "auditor_fn_violation": 0.009783713575784956,
            "auditor_fp_violation": 0.017012823538667295,
            "ave_precision_score": 0.7920416447427423,
            "fpr": 0.20723684210526316,
            "logloss": 2.6450338642110807,
            "mae": 0.2910940527544687,
            "precision": 0.6752577319587629,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.84512336016752,
            "auditor_fn_violation": 0.004357038743229384,
            "auditor_fp_violation": 0.021564643327027434,
            "ave_precision_score": 0.8091985776332916,
            "fpr": 0.18331503841931943,
            "logloss": 2.597367152637191,
            "mae": 0.26765753807212783,
            "precision": 0.7110726643598616,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6605005701066426,
            "auditor_fn_violation": 0.08589338152247572,
            "auditor_fp_violation": 0.10643340413814807,
            "ave_precision_score": 0.5643991458563467,
            "fpr": 0.30043859649122806,
            "logloss": 0.6821777554607573,
            "mae": 0.4908650550795229,
            "precision": 0.5601926163723917,
            "recall": 0.7489270386266095
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6594967430229639,
            "auditor_fn_violation": 0.0953284986773677,
            "auditor_fp_violation": 0.10360370880724946,
            "ave_precision_score": 0.5733446251389669,
            "fpr": 0.29857299670691545,
            "logloss": 0.6856391452723752,
            "mae": 0.4926119368568341,
            "precision": 0.5682539682539682,
            "recall": 0.7336065573770492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.4949780641647753,
            "auditor_fn_violation": 0.003374181161057151,
            "auditor_fp_violation": 0.005934820234442611,
            "ave_precision_score": 0.49694099817054527,
            "fpr": 0.04276315789473684,
            "logloss": 0.7074890296466212,
            "mae": 0.5016688931602657,
            "precision": 0.4507042253521127,
            "recall": 0.06866952789699571
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.5300885393587582,
            "auditor_fn_violation": 0.002397833402314146,
            "auditor_fp_violation": 0.006025644019898638,
            "ave_precision_score": 0.5316980514653098,
            "fpr": 0.03951701427003293,
            "logloss": 0.7123181021704168,
            "mae": 0.5033590120522041,
            "precision": 0.45454545454545453,
            "recall": 0.06147540983606557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.8302534466253553,
            "auditor_fn_violation": 0.035115955123861155,
            "auditor_fp_violation": 0.10004621980961373,
            "ave_precision_score": 0.7672919588683033,
            "fpr": 0.3026315789473684,
            "logloss": 2.6731143482919615,
            "mae": 0.37561013003026966,
            "precision": 0.5970802919708029,
            "recall": 0.8776824034334764
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8397239684448764,
            "auditor_fn_violation": 0.03363265012326573,
            "auditor_fp_violation": 0.08765729084761245,
            "ave_precision_score": 0.7735991179528723,
            "fpr": 0.2810098792535675,
            "logloss": 2.9526805838686268,
            "mae": 0.35275675353423397,
            "precision": 0.627906976744186,
            "recall": 0.8852459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5625243145031533,
            "auditor_fn_violation": 0.010160191250658845,
            "auditor_fp_violation": 0.0031321296514829674,
            "ave_precision_score": 0.5639930850833155,
            "fpr": 0.01206140350877193,
            "logloss": 0.6951626531382968,
            "mae": 0.4991051189339997,
            "precision": 0.7441860465116279,
            "recall": 0.06866952789699571
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5623260939949193,
            "auditor_fn_violation": 0.005533461697648055,
            "auditor_fp_violation": 0.002218744891047948,
            "ave_precision_score": 0.5642746224655812,
            "fpr": 0.019758507135016465,
            "logloss": 0.7005074111726846,
            "mae": 0.5017616905182044,
            "precision": 0.6538461538461539,
            "recall": 0.06967213114754098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 10102,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.6367045930774177,
            "auditor_fn_violation": 0.001491792786687759,
            "auditor_fp_violation": 0.0007547596569900088,
            "ave_precision_score": 0.601350454244842,
            "fpr": 0.003289473684210526,
            "logloss": 0.7735067641884175,
            "mae": 0.49978021136893513,
            "precision": 0.7272727272727273,
            "recall": 0.017167381974248927
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.6547696842673556,
            "auditor_fn_violation": 0.0009717298590991866,
            "auditor_fp_violation": 0.0005709051181643843,
            "ave_precision_score": 0.6245690602699459,
            "fpr": 0.0010976948408342481,
            "logloss": 0.7408044462552674,
            "mae": 0.5010649345970573,
            "precision": 0.8888888888888888,
            "recall": 0.01639344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 10102,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8620475174147489,
            "auditor_fn_violation": 0.008131917777275809,
            "auditor_fp_violation": 0.011550035402407368,
            "ave_precision_score": 0.8253341570545548,
            "fpr": 0.18201754385964913,
            "logloss": 2.188339917638538,
            "mae": 0.2640730474655836,
            "precision": 0.7056737588652482,
            "recall": 0.8540772532188842
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8629377657500922,
            "auditor_fn_violation": 0.003738460707923202,
            "auditor_fp_violation": 0.020440998253549343,
            "ave_precision_score": 0.8198812653533147,
            "fpr": 0.1734357848518112,
            "logloss": 2.5370170113596626,
            "mae": 0.25115040753308,
            "precision": 0.7275862068965517,
            "recall": 0.8647540983606558
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 10102,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.7658564321344199,
            "auditor_fn_violation": 0.002004743618703414,
            "auditor_fp_violation": 0.0005605381165919285,
            "ave_precision_score": 0.7247828209187346,
            "fpr": 0.013157894736842105,
            "logloss": 0.7659917559963596,
            "mae": 0.4993377547841846,
            "precision": 0.5384615384615384,
            "recall": 0.030042918454935622
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.8212607267690175,
            "auditor_fn_violation": 0.0033560670133702905,
            "auditor_fp_violation": 0.0016634099124698653,
            "ave_precision_score": 0.7794458433505457,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7278184123307522,
            "mae": 0.4979471863624686,
            "precision": 0.8095238095238095,
            "recall": 0.03483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8624542419877752,
            "auditor_fn_violation": 0.009167231383178978,
            "auditor_fp_violation": 0.012621941625363859,
            "ave_precision_score": 0.8256902846267574,
            "fpr": 0.18092105263157895,
            "logloss": 2.2146200733005315,
            "mae": 0.265027509718611,
            "precision": 0.7084805653710248,
            "recall": 0.8605150214592274
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8607143175684576,
            "auditor_fn_violation": 0.004719188065717732,
            "auditor_fp_violation": 0.021105324209231537,
            "ave_precision_score": 0.8153656586039205,
            "fpr": 0.17453347969264543,
            "logloss": 2.6166131766516596,
            "mae": 0.2529404044170731,
            "precision": 0.7268041237113402,
            "recall": 0.8668032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8336881415793913,
            "auditor_fn_violation": 0.003037704239138628,
            "auditor_fp_violation": 0.0035377822358587086,
            "ave_precision_score": 0.7844968814643782,
            "fpr": 0.08223684210526316,
            "logloss": 2.5085031140518144,
            "mae": 0.3337212085862347,
            "precision": 0.8152709359605911,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8398304412983293,
            "auditor_fn_violation": 0.007731100753990391,
            "auditor_fp_violation": 0.010559149662776726,
            "ave_precision_score": 0.786422559574558,
            "fpr": 0.09330406147091108,
            "logloss": 2.7989195772454134,
            "mae": 0.3236522655023655,
            "precision": 0.805045871559633,
            "recall": 0.7192622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8347487029020813,
            "auditor_fn_violation": 0.03575126120021083,
            "auditor_fp_violation": 0.10004621980961373,
            "ave_precision_score": 0.7690245201589744,
            "fpr": 0.3026315789473684,
            "logloss": 2.69389030097687,
            "mae": 0.37399676876457144,
            "precision": 0.5964912280701754,
            "recall": 0.8755364806866953
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8438543093793838,
            "auditor_fn_violation": 0.03363265012326573,
            "auditor_fp_violation": 0.08765729084761245,
            "ave_precision_score": 0.7762886359128363,
            "fpr": 0.2810098792535675,
            "logloss": 2.967467754824471,
            "mae": 0.3518213871283749,
            "precision": 0.627906976744186,
            "recall": 0.8852459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7093668178900282,
            "auditor_fn_violation": 0.02147569836608689,
            "auditor_fp_violation": 0.020693198804185364,
            "ave_precision_score": 0.6965560103319302,
            "fpr": 0.2138157894736842,
            "logloss": 2.1025943031875642,
            "mae": 0.3469525852142012,
            "precision": 0.6402214022140221,
            "recall": 0.7446351931330472
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7610472593150259,
            "auditor_fn_violation": 0.010781252811718345,
            "auditor_fp_violation": 0.018967025039379484,
            "ave_precision_score": 0.7507023454908853,
            "fpr": 0.1690450054884742,
            "logloss": 1.8119673919331856,
            "mae": 0.29441765271057196,
            "precision": 0.7142857142857143,
            "recall": 0.7889344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.004265962653414669,
            "auditor_fp_violation": 0.011023916292974589,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.020833333333333332,
            "logloss": 0.7001983776322187,
            "mae": 0.5013829059245294,
            "precision": 0.2692307692307692,
            "recall": 0.015021459227467811
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.008637598747548205,
            "auditor_fp_violation": 0.007543732629563024,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.018660812294182216,
            "logloss": 0.7032464739931447,
            "mae": 0.5028373168210952,
            "precision": 0.46875,
            "recall": 0.030737704918032786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.80916331813936,
            "auditor_fn_violation": 0.004145960394548603,
            "auditor_fp_violation": 0.02009578317992291,
            "ave_precision_score": 0.7490227269188553,
            "fpr": 0.30043859649122806,
            "logloss": 4.013691107657112,
            "mae": 0.3641185217477702,
            "precision": 0.6017441860465116,
            "recall": 0.8884120171673819
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.817550385575772,
            "auditor_fn_violation": 0.002379838404923434,
            "auditor_fp_violation": 0.014415354233650708,
            "ave_precision_score": 0.7527245864330714,
            "fpr": 0.2843029637760702,
            "logloss": 4.252858404609124,
            "mae": 0.33612765624653124,
            "precision": 0.630527817403709,
            "recall": 0.9057377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 10102,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8317361045736247,
            "auditor_fn_violation": 0.007962502823582565,
            "auditor_fp_violation": 0.025583156321296523,
            "ave_precision_score": 0.7942515853051082,
            "fpr": 0.21710526315789475,
            "logloss": 2.6604384410555983,
            "mae": 0.29453933433776885,
            "precision": 0.6666666666666666,
            "recall": 0.8497854077253219
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8477051035437498,
            "auditor_fn_violation": 0.004950873657123322,
            "auditor_fp_violation": 0.026492592506091824,
            "ave_precision_score": 0.810847771796428,
            "fpr": 0.18660812294182216,
            "logloss": 2.6238511805817257,
            "mae": 0.2686859928068137,
            "precision": 0.7113752122241087,
            "recall": 0.8586065573770492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555325529631114,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121120704381438,
            "fpr": 0.4857456140350877,
            "logloss": 16.79562717564949,
            "mae": 0.4868421054013588,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360550380133,
            "mae": 0.45444566472796566,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8328599201208237,
            "auditor_fn_violation": 0.00960959265115579,
            "auditor_fp_violation": 0.014234717960821337,
            "ave_precision_score": 0.7658749479488269,
            "fpr": 0.19736842105263158,
            "logloss": 4.8512256167426475,
            "mae": 0.2820745676701941,
            "precision": 0.6853146853146853,
            "recall": 0.8412017167381974
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8484485989600079,
            "auditor_fn_violation": 0.010270644760756509,
            "auditor_fp_violation": 0.0289915999096932,
            "ave_precision_score": 0.7826420563061562,
            "fpr": 0.1756311745334797,
            "logloss": 4.947616411604424,
            "mae": 0.25554069359702875,
            "precision": 0.7227036395147314,
            "recall": 0.8545081967213115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.699263351381716,
            "mae": 0.5010405125651967,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7016178537568283,
            "mae": 0.5022168698282063,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6384976786941647,
            "auditor_fn_violation": 0.018847413598373615,
            "auditor_fp_violation": 0.019323814019353323,
            "ave_precision_score": 0.6165213567496648,
            "fpr": 0.26973684210526316,
            "logloss": 3.0487491514286855,
            "mae": 0.4055817306857392,
            "precision": 0.5879396984924623,
            "recall": 0.7532188841201717
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6677708492055562,
            "auditor_fn_violation": 0.01092071404149647,
            "auditor_fp_violation": 0.018813918666780848,
            "ave_precision_score": 0.6434563914666906,
            "fpr": 0.2414928649835346,
            "logloss": 3.008738704641586,
            "mae": 0.3634064418256509,
            "precision": 0.6375617792421746,
            "recall": 0.7930327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.004265962653414669,
            "auditor_fp_violation": 0.011023916292974589,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.020833333333333332,
            "logloss": 0.7001983674322994,
            "mae": 0.5013829039311722,
            "precision": 0.2692307692307692,
            "recall": 0.015021459227467811
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.008637598747548205,
            "auditor_fp_violation": 0.007543732629563024,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.018660812294182216,
            "logloss": 0.703246466904865,
            "mae": 0.502837316657526,
            "precision": 0.46875,
            "recall": 0.030737704918032786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8336046347098565,
            "auditor_fn_violation": 0.03748305850463068,
            "auditor_fp_violation": 0.10173766816143498,
            "ave_precision_score": 0.7679631805636243,
            "fpr": 0.30153508771929827,
            "logloss": 2.5764650818527133,
            "mae": 0.33784041891952876,
            "precision": 0.5967741935483871,
            "recall": 0.8733905579399142
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8409912575041762,
            "auditor_fn_violation": 0.03363265012326573,
            "auditor_fp_violation": 0.09362843937895904,
            "ave_precision_score": 0.7752461463722439,
            "fpr": 0.2843029637760702,
            "logloss": 2.8309193924884997,
            "mae": 0.3234100811894979,
            "precision": 0.6251808972503617,
            "recall": 0.8852459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8624165204162112,
            "auditor_fn_violation": 0.009167231383178978,
            "auditor_fp_violation": 0.011333687357406972,
            "ave_precision_score": 0.8256497408915625,
            "fpr": 0.17982456140350878,
            "logloss": 2.2152866038365726,
            "mae": 0.2650441002251306,
            "precision": 0.7097345132743362,
            "recall": 0.8605150214592274
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8607227744893029,
            "auditor_fn_violation": 0.003738460707923202,
            "auditor_fp_violation": 0.021105324209231537,
            "ave_precision_score": 0.815374116742722,
            "fpr": 0.17453347969264543,
            "logloss": 2.617014940761679,
            "mae": 0.252895034496915,
            "precision": 0.7263339070567987,
            "recall": 0.8647540983606558
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.01837211053384534,
            "auditor_fp_violation": 0.0023798284950043284,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.05263157894736842,
            "logloss": 0.7011539877345158,
            "mae": 0.5010201040851442,
            "precision": 0.5294117647058824,
            "recall": 0.11587982832618025
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.01014917852836911,
            "auditor_fp_violation": 0.002506792473394525,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.042810098792535674,
            "logloss": 0.7034581173416536,
            "mae": 0.502015188647154,
            "precision": 0.5666666666666667,
            "recall": 0.10450819672131148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7079957054458653,
            "auditor_fn_violation": 0.021400402831112116,
            "auditor_fp_violation": 0.01973438360475179,
            "ave_precision_score": 0.6953965120931673,
            "fpr": 0.2138157894736842,
            "logloss": 2.096821978558445,
            "mae": 0.3483754759645479,
            "precision": 0.6415441176470589,
            "recall": 0.7489270386266095
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7599267979484271,
            "auditor_fn_violation": 0.011692249554623823,
            "auditor_fp_violation": 0.01853106113096304,
            "ave_precision_score": 0.7497588482872355,
            "fpr": 0.17233809001097694,
            "logloss": 1.802988873615724,
            "mae": 0.29534397451624056,
            "precision": 0.7092592592592593,
            "recall": 0.7848360655737705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555325502820155,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121132740509078,
            "fpr": 0.4857456140350877,
            "logloss": 16.795581413951435,
            "mae": 0.4868421054073111,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360550407075,
            "mae": 0.45444566475490755,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8293639012485091,
            "auditor_fn_violation": 0.009783713575784956,
            "auditor_fp_violation": 0.017012823538667295,
            "ave_precision_score": 0.7920388256685702,
            "fpr": 0.20723684210526316,
            "logloss": 2.6443480262048107,
            "mae": 0.29097828483229793,
            "precision": 0.6752577319587629,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.845072285741721,
            "auditor_fn_violation": 0.004357038743229384,
            "auditor_fp_violation": 0.02236650551572195,
            "ave_precision_score": 0.80915236040544,
            "fpr": 0.18441273326015367,
            "logloss": 2.5968933279092665,
            "mae": 0.26760179864021966,
            "precision": 0.7098445595854922,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.01837211053384534,
            "auditor_fp_violation": 0.0023798284950043284,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.05263157894736842,
            "logloss": 0.7011539575908756,
            "mae": 0.5010201040524662,
            "precision": 0.5294117647058824,
            "recall": 0.11587982832618025
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.01014917852836911,
            "auditor_fp_violation": 0.002506792473394525,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.042810098792535674,
            "logloss": 0.7034580979444371,
            "mae": 0.5020151950917835,
            "precision": 0.5666666666666667,
            "recall": 0.10450819672131148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8427302671123729,
            "auditor_fn_violation": 0.003037704239138628,
            "auditor_fp_violation": 0.006726457399103144,
            "ave_precision_score": 0.7712413901275391,
            "fpr": 0.08114035087719298,
            "logloss": 2.5107766825516555,
            "mae": 0.33743206035803286,
            "precision": 0.817283950617284,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8451700310063244,
            "auditor_fn_violation": 0.00713051771607493,
            "auditor_fp_violation": 0.010559149662776726,
            "ave_precision_score": 0.7741782242641437,
            "fpr": 0.09330406147091108,
            "logloss": 2.809019390587508,
            "mae": 0.33135887093915634,
            "precision": 0.8045977011494253,
            "recall": 0.7172131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8293896782287152,
            "auditor_fn_violation": 0.009783713575784956,
            "auditor_fp_violation": 0.01674976398395091,
            "ave_precision_score": 0.7920522055610115,
            "fpr": 0.2050438596491228,
            "logloss": 2.6525844176199715,
            "mae": 0.29092483502293315,
            "precision": 0.6775862068965517,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8451611236336596,
            "auditor_fn_violation": 0.004357038743229384,
            "auditor_fp_violation": 0.021564643327027434,
            "ave_precision_score": 0.8092503333820952,
            "fpr": 0.18331503841931943,
            "logloss": 2.604108953180714,
            "mae": 0.26731834893305473,
            "precision": 0.7110726643598616,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7675370241274616,
            "auditor_fn_violation": 0.004825973194789552,
            "auditor_fp_violation": 0.021804441035323734,
            "ave_precision_score": 0.7329615855341949,
            "fpr": 0.28399122807017546,
            "logloss": 3.0895664340119957,
            "mae": 0.3710962591668563,
            "precision": 0.5990712074303406,
            "recall": 0.8304721030042919
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7743268427929095,
            "auditor_fn_violation": 0.0045302405931151165,
            "auditor_fp_violation": 0.013460385672357566,
            "ave_precision_score": 0.7391485684907199,
            "fpr": 0.2623490669593853,
            "logloss": 3.044410305854521,
            "mae": 0.3345157140343397,
            "precision": 0.6406015037593985,
            "recall": 0.8729508196721312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.8318986905295923,
            "auditor_fn_violation": 0.04002428281002937,
            "auditor_fp_violation": 0.10590236802769255,
            "ave_precision_score": 0.7820443688412998,
            "fpr": 0.29385964912280704,
            "logloss": 2.0361230459101756,
            "mae": 0.3403681816549547,
            "precision": 0.6005961251862891,
            "recall": 0.8648068669527897
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.834634023404608,
            "auditor_fn_violation": 0.03843731442658942,
            "auditor_fp_violation": 0.09762477520610974,
            "ave_precision_score": 0.7865786402978798,
            "fpr": 0.27661909989023054,
            "logloss": 2.149246985271256,
            "mae": 0.32856926362875655,
            "precision": 0.6272189349112426,
            "recall": 0.8688524590163934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7905783702631598,
            "auditor_fn_violation": 0.009494296363225662,
            "auditor_fp_violation": 0.026497718511525454,
            "ave_precision_score": 0.7791930667561655,
            "fpr": 0.43859649122807015,
            "logloss": 1.5463025327124131,
            "mae": 0.4526962332688926,
            "precision": 0.5299647473560517,
            "recall": 0.9678111587982833
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7995460845966692,
            "auditor_fn_violation": 0.007652372640405968,
            "auditor_fp_violation": 0.03197068661720553,
            "ave_precision_score": 0.7928456454827877,
            "fpr": 0.40285400658616904,
            "logloss": 1.3795979104851657,
            "mae": 0.42909935352307643,
            "precision": 0.5636147443519619,
            "recall": 0.9713114754098361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8306823879544932,
            "auditor_fn_violation": 0.00960959265115579,
            "auditor_fp_violation": 0.017327511604122423,
            "ave_precision_score": 0.7630750276647985,
            "fpr": 0.19736842105263158,
            "logloss": 4.882970691934855,
            "mae": 0.2806883363830666,
            "precision": 0.6853146853146853,
            "recall": 0.8412017167381974
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8470500917427163,
            "auditor_fn_violation": 0.007332961436720594,
            "auditor_fp_violation": 0.028576396187391818,
            "ave_precision_score": 0.7812830975492271,
            "fpr": 0.1756311745334797,
            "logloss": 4.94974676952297,
            "mae": 0.2558832425501467,
            "precision": 0.7217391304347827,
            "recall": 0.8504098360655737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6372911576590413,
            "auditor_fn_violation": 0.018847413598373615,
            "auditor_fp_violation": 0.019874518133899774,
            "ave_precision_score": 0.6152036127450288,
            "fpr": 0.2730263157894737,
            "logloss": 3.042636125991554,
            "mae": 0.4065291486890324,
            "precision": 0.585,
            "recall": 0.7532188841201717
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.665358438804779,
            "auditor_fn_violation": 0.013091360601752712,
            "auditor_fp_violation": 0.01824041852535208,
            "ave_precision_score": 0.6414526071948712,
            "fpr": 0.24039517014270034,
            "logloss": 3.0043716802253164,
            "mae": 0.3645514011865026,
            "precision": 0.6380165289256199,
            "recall": 0.7909836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8336046347098565,
            "auditor_fn_violation": 0.03748305850463068,
            "auditor_fp_violation": 0.10173766816143498,
            "ave_precision_score": 0.7679631805636243,
            "fpr": 0.30153508771929827,
            "logloss": 2.5764651111332535,
            "mae": 0.337840386690866,
            "precision": 0.5967741935483871,
            "recall": 0.8733905579399142
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8409912575041762,
            "auditor_fn_violation": 0.03363265012326573,
            "auditor_fp_violation": 0.09362843937895904,
            "ave_precision_score": 0.7752461463722439,
            "fpr": 0.2843029637760702,
            "logloss": 2.830919385380428,
            "mae": 0.32341005411878243,
            "precision": 0.6251808972503617,
            "recall": 0.8852459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8293487427916573,
            "auditor_fn_violation": 0.009783713575784956,
            "auditor_fp_violation": 0.017012823538667295,
            "ave_precision_score": 0.7920219164338267,
            "fpr": 0.20723684210526316,
            "logloss": 2.6455903143192248,
            "mae": 0.29122372714671385,
            "precision": 0.6752577319587629,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8450829699050109,
            "auditor_fn_violation": 0.004357038743229384,
            "auditor_fp_violation": 0.02236650551572195,
            "ave_precision_score": 0.8091648242831614,
            "fpr": 0.18441273326015367,
            "logloss": 2.597788599048517,
            "mae": 0.267738838140722,
            "precision": 0.7098445595854922,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 10102,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8305634501707286,
            "auditor_fn_violation": 0.010315488291544314,
            "auditor_fp_violation": 0.026647687042718908,
            "ave_precision_score": 0.791476194294052,
            "fpr": 0.22039473684210525,
            "logloss": 2.6674613590291916,
            "mae": 0.29495711121516727,
            "precision": 0.665,
            "recall": 0.8562231759656652
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.846792033398822,
            "auditor_fn_violation": 0.005090334886901444,
            "auditor_fp_violation": 0.028882608932589083,
            "ave_precision_score": 0.8083602313155568,
            "fpr": 0.18660812294182216,
            "logloss": 2.638119360189854,
            "mae": 0.26927632548910846,
            "precision": 0.7123519458544839,
            "recall": 0.8627049180327869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.004265962653414669,
            "auditor_fp_violation": 0.011023916292974589,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.020833333333333332,
            "logloss": 0.700198323521959,
            "mae": 0.5013828951734722,
            "precision": 0.2692307692307692,
            "recall": 0.015021459227467811
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.008637598747548205,
            "auditor_fp_violation": 0.007543732629563024,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.018660812294182216,
            "logloss": 0.7032464392298444,
            "mae": 0.5028373172790892,
            "precision": 0.46875,
            "recall": 0.030737704918032786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6982452168937986,
            "mae": 0.5008909600345712,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7022697670302175,
            "mae": 0.5028987986196147,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8293743770972606,
            "auditor_fn_violation": 0.009783713575784956,
            "auditor_fp_violation": 0.017012823538667295,
            "ave_precision_score": 0.7920418020178452,
            "fpr": 0.20723684210526316,
            "logloss": 2.648381296430707,
            "mae": 0.290774361889653,
            "precision": 0.6752577319587629,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8451277277349877,
            "auditor_fn_violation": 0.004357038743229384,
            "auditor_fp_violation": 0.02236650551572195,
            "ave_precision_score": 0.8092105971403536,
            "fpr": 0.18441273326015367,
            "logloss": 2.601065419558892,
            "mae": 0.2676064474584467,
            "precision": 0.7098445595854922,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8330863136543185,
            "auditor_fn_violation": 0.008171918530231158,
            "auditor_fp_violation": 0.014721501062072217,
            "ave_precision_score": 0.7647155127726917,
            "fpr": 0.1962719298245614,
            "logloss": 4.809504461695739,
            "mae": 0.27947390289153456,
            "precision": 0.6870629370629371,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8492036204079322,
            "auditor_fn_violation": 0.008030267585611203,
            "auditor_fp_violation": 0.02692077134471511,
            "ave_precision_score": 0.7818841002895178,
            "fpr": 0.17453347969264543,
            "logloss": 4.978188692465971,
            "mae": 0.2549200635680595,
            "precision": 0.7244367417677643,
            "recall": 0.8565573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.8356077912103788,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005949571237510834,
            "ave_precision_score": 0.7816305272655324,
            "fpr": 0.48793859649122806,
            "logloss": 5.33279221896206,
            "mae": 0.4873453005964525,
            "precision": 0.5115257958287596,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.8448939821478816,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00045931911779589486,
            "ave_precision_score": 0.7871477173466914,
            "fpr": 0.4610318331503842,
            "logloss": 5.338150370160692,
            "mae": 0.4594183647739819,
            "precision": 0.5374449339207048,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8315114032461417,
            "auditor_fn_violation": 0.007962502823582565,
            "auditor_fp_violation": 0.023574561403508772,
            "ave_precision_score": 0.7932353457418757,
            "fpr": 0.21820175438596492,
            "logloss": 2.6835681064253296,
            "mae": 0.29452178890538544,
            "precision": 0.6655462184873949,
            "recall": 0.8497854077253219
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8476278945620652,
            "auditor_fn_violation": 0.005488474204171239,
            "auditor_fp_violation": 0.026313535900849346,
            "ave_precision_score": 0.8099767992294711,
            "fpr": 0.18880351262349068,
            "logloss": 2.649225073275707,
            "mae": 0.26875219322809885,
            "precision": 0.7084745762711865,
            "recall": 0.8565573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8329735458168306,
            "auditor_fn_violation": 0.003037704239138628,
            "auditor_fp_violation": 0.0035377822358587086,
            "ave_precision_score": 0.7727050274820031,
            "fpr": 0.08223684210526316,
            "logloss": 2.508867044735423,
            "mae": 0.33356369814071446,
            "precision": 0.8152709359605911,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8404484237888273,
            "auditor_fn_violation": 0.007731100753990391,
            "auditor_fp_violation": 0.010559149662776726,
            "ave_precision_score": 0.777701442911535,
            "fpr": 0.09330406147091108,
            "logloss": 2.799205520371816,
            "mae": 0.32352031634253087,
            "precision": 0.805045871559633,
            "recall": 0.7192622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8374723305216825,
            "auditor_fn_violation": 0.003037704239138628,
            "auditor_fp_violation": 0.006539611360239167,
            "ave_precision_score": 0.7861599492911744,
            "fpr": 0.08114035087719298,
            "logloss": 2.5089928705044753,
            "mae": 0.33389611512206596,
            "precision": 0.817283950617284,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8391918472167876,
            "auditor_fn_violation": 0.007731100753990391,
            "auditor_fp_violation": 0.010559149662776726,
            "ave_precision_score": 0.7841910946209725,
            "fpr": 0.09330406147091108,
            "logloss": 2.79903023798905,
            "mae": 0.3237169513780952,
            "precision": 0.805045871559633,
            "recall": 0.7192622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7948776897672746,
            "auditor_fn_violation": 0.010287252465928771,
            "auditor_fp_violation": 0.021511879474470932,
            "ave_precision_score": 0.7721210204493636,
            "fpr": 0.22587719298245615,
            "logloss": 2.274423182318437,
            "mae": 0.31854643841993824,
            "precision": 0.6478632478632479,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8315783124071325,
            "auditor_fn_violation": 0.007521908909323212,
            "auditor_fp_violation": 0.022491066632412366,
            "ave_precision_score": 0.8138922143499869,
            "fpr": 0.1877058177826564,
            "logloss": 1.9029943272057421,
            "mae": 0.26971455772304576,
            "precision": 0.7101694915254237,
            "recall": 0.8586065573770492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.506369035916556,
            "auditor_fn_violation": 0.007906031172351499,
            "auditor_fp_violation": 0.006571571866886948,
            "ave_precision_score": 0.5089348139156558,
            "fpr": 0.06030701754385965,
            "logloss": 0.7041501239618605,
            "mae": 0.5017324747158247,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.550284996025655,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.5525353781764779,
            "fpr": 0.05159165751920966,
            "logloss": 0.704466229564889,
            "mae": 0.5018828341453188,
            "precision": 0.5765765765765766,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7720891475370069,
            "auditor_fn_violation": 0.005717754687147055,
            "auditor_fp_violation": 0.01933856502242153,
            "ave_precision_score": 0.734317177224723,
            "fpr": 0.28289473684210525,
            "logloss": 3.196999391071313,
            "mae": 0.3694567518311042,
            "precision": 0.6042944785276073,
            "recall": 0.8454935622317596
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7803483701938629,
            "auditor_fn_violation": 0.005900109769484086,
            "auditor_fp_violation": 0.012323765482557572,
            "ave_precision_score": 0.7439969854302743,
            "fpr": 0.2645444566410538,
            "logloss": 3.1169547156289883,
            "mae": 0.3341975216516175,
            "precision": 0.6392215568862275,
            "recall": 0.875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 10102,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5318676837564627,
            "auditor_fn_violation": 0.0051765680295158675,
            "auditor_fp_violation": 0.005334946109668791,
            "ave_precision_score": 0.5342699839674507,
            "fpr": 0.06578947368421052,
            "logloss": 0.6981713202695307,
            "mae": 0.5000190067905605,
            "precision": 0.5,
            "recall": 0.12875536480686695
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5516278811994597,
            "auditor_fn_violation": 0.010171672275107513,
            "auditor_fp_violation": 0.007419171512872614,
            "ave_precision_score": 0.5537862034721761,
            "fpr": 0.054884742041712405,
            "logloss": 0.6988903711860667,
            "mae": 0.500259468832864,
            "precision": 0.5833333333333334,
            "recall": 0.14344262295081966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8343109137380269,
            "auditor_fn_violation": 0.007538965439349447,
            "auditor_fp_violation": 0.016717803477303124,
            "ave_precision_score": 0.7657573870247495,
            "fpr": 0.19517543859649122,
            "logloss": 4.890929325715284,
            "mae": 0.278330102205339,
            "precision": 0.6877192982456141,
            "recall": 0.8412017167381974
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8450705369869425,
            "auditor_fn_violation": 0.009843263572726782,
            "auditor_fp_violation": 0.02687406092595621,
            "ave_precision_score": 0.7743679770494295,
            "fpr": 0.1712403951701427,
            "logloss": 5.118569875957452,
            "mae": 0.25475227462574795,
            "precision": 0.7272727272727273,
            "recall": 0.8524590163934426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7085457827638643,
            "auditor_fn_violation": 0.018070928393946244,
            "auditor_fp_violation": 0.015063232633152391,
            "ave_precision_score": 0.6981660413028001,
            "fpr": 0.20723684210526316,
            "logloss": 1.996861370886659,
            "mae": 0.3507612057709009,
            "precision": 0.6473880597014925,
            "recall": 0.7446351931330472
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7567961379892703,
            "auditor_fn_violation": 0.011984668262223101,
            "auditor_fp_violation": 0.02042802313722743,
            "ave_precision_score": 0.747577950378285,
            "fpr": 0.1712403951701427,
            "logloss": 1.7494513003561687,
            "mae": 0.2976749876993627,
            "precision": 0.7111111111111111,
            "recall": 0.7868852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7028417640485694,
            "auditor_fn_violation": 0.02132510729613734,
            "auditor_fp_violation": 0.021211942412084024,
            "ave_precision_score": 0.6902524945934095,
            "fpr": 0.21929824561403508,
            "logloss": 2.122029669442807,
            "mae": 0.35367001863497183,
            "precision": 0.6370235934664247,
            "recall": 0.7532188841201717
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7552741424345422,
            "auditor_fn_violation": 0.013010383113494454,
            "auditor_fp_violation": 0.017184244056747976,
            "ave_precision_score": 0.7453504505147066,
            "fpr": 0.17233809001097694,
            "logloss": 1.8228894138076823,
            "mae": 0.2988417576924235,
            "precision": 0.7097966728280961,
            "recall": 0.7868852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5258407027198791,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5161998025163148,
            "fpr": 0.48903508771929827,
            "logloss": 0.7206340267010105,
            "mae": 0.4970652219888411,
            "precision": 0.5109649122807017,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5715770254556202,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5456418893884678,
            "fpr": 0.4643249176728869,
            "logloss": 0.7056501548714232,
            "mae": 0.49002251706191396,
            "precision": 0.535675082327113,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7687241312036851,
            "auditor_fn_violation": 0.0077272042767863895,
            "auditor_fp_violation": 0.01899437495082999,
            "ave_precision_score": 0.7349008197343964,
            "fpr": 0.29276315789473684,
            "logloss": 3.070999621664197,
            "mae": 0.37492572987912537,
            "precision": 0.5923664122137404,
            "recall": 0.8326180257510729
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7748212985457182,
            "auditor_fn_violation": 0.0038419319429198687,
            "auditor_fp_violation": 0.012505417111064409,
            "ave_precision_score": 0.7403495535274527,
            "fpr": 0.2623490669593853,
            "logloss": 3.044713639173916,
            "mae": 0.33678504811820126,
            "precision": 0.6400602409638554,
            "recall": 0.8709016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5073262424493622,
            "auditor_fn_violation": 0.007906031172351499,
            "auditor_fp_violation": 0.006571571866886948,
            "ave_precision_score": 0.5097237334064294,
            "fpr": 0.06030701754385965,
            "logloss": 0.6998778012654369,
            "mae": 0.5010088908633119,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5491761306746473,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.5514286709322156,
            "fpr": 0.05159165751920966,
            "logloss": 0.6995718179594785,
            "mae": 0.5006780947602542,
            "precision": 0.5765765765765766,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5479452078308095,
            "auditor_fn_violation": 0.01077667344326482,
            "auditor_fp_violation": 0.00043761309102352346,
            "ave_precision_score": 0.5258791205025626,
            "fpr": 0.051535087719298246,
            "logloss": 0.6938251098431768,
            "mae": 0.49602080871792215,
            "precision": 0.5204081632653061,
            "recall": 0.10944206008583691
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5850077550423891,
            "auditor_fn_violation": 0.009305663025678874,
            "auditor_fp_violation": 0.006409707463027409,
            "ave_precision_score": 0.546912876347797,
            "fpr": 0.04720087815587267,
            "logloss": 0.6976479545369394,
            "mae": 0.4979828422731678,
            "precision": 0.5784313725490197,
            "recall": 0.12090163934426229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5255910283663036,
            "auditor_fn_violation": 0.007906031172351499,
            "auditor_fp_violation": 0.006571571866886948,
            "ave_precision_score": 0.5103712974060617,
            "fpr": 0.06030701754385965,
            "logloss": 0.6998760691946584,
            "mae": 0.5010110958430328,
            "precision": 0.48598130841121495,
            "recall": 0.11158798283261803
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5832983353399849,
            "auditor_fn_violation": 0.007989778841482078,
            "auditor_fp_violation": 0.008171728259543851,
            "ave_precision_score": 0.5408917970931364,
            "fpr": 0.05159165751920966,
            "logloss": 0.6995462022582878,
            "mae": 0.5006698344463051,
            "precision": 0.5765765765765766,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7933295925558213,
            "auditor_fn_violation": 0.010287252465928771,
            "auditor_fp_violation": 0.02203554008339234,
            "ave_precision_score": 0.7705551648108557,
            "fpr": 0.22478070175438597,
            "logloss": 2.274795775012002,
            "mae": 0.31909550257210384,
            "precision": 0.648972602739726,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8298047840181311,
            "auditor_fn_violation": 0.007915549477245326,
            "auditor_fp_violation": 0.01912791648177127,
            "ave_precision_score": 0.8122002920551328,
            "fpr": 0.18660812294182216,
            "logloss": 1.8987133722672502,
            "mae": 0.2703219435448996,
            "precision": 0.7103918228279387,
            "recall": 0.8545081967213115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8298294821859,
            "auditor_fn_violation": 0.00913899555756344,
            "auditor_fp_violation": 0.017012823538667295,
            "ave_precision_score": 0.7924622220175742,
            "fpr": 0.20723684210526316,
            "logloss": 2.654691518398167,
            "mae": 0.29088636197408896,
            "precision": 0.6758147512864494,
            "recall": 0.8454935622317596
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8452362957045305,
            "auditor_fn_violation": 0.004357038743229384,
            "auditor_fp_violation": 0.02236650551572195,
            "ave_precision_score": 0.8093395065825562,
            "fpr": 0.18441273326015367,
            "logloss": 2.607109354013721,
            "mae": 0.26798052816525175,
            "precision": 0.7098445595854922,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8306961593557451,
            "auditor_fn_violation": 0.00960959265115579,
            "auditor_fp_violation": 0.01691448351821257,
            "ave_precision_score": 0.7630898711400487,
            "fpr": 0.1962719298245614,
            "logloss": 4.881991823997273,
            "mae": 0.28058404142045257,
            "precision": 0.6865148861646234,
            "recall": 0.8412017167381974
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8477127675216294,
            "auditor_fn_violation": 0.007332961436720594,
            "auditor_fp_violation": 0.028150812372032916,
            "ave_precision_score": 0.7826274026364337,
            "fpr": 0.17453347969264543,
            "logloss": 4.928931882807709,
            "mae": 0.25569908426664667,
            "precision": 0.7229965156794426,
            "recall": 0.8504098360655737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 10102,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.8104304863084856,
            "auditor_fn_violation": 0.004287139522626311,
            "auditor_fp_violation": 0.02221255212021086,
            "ave_precision_score": 0.750985917134815,
            "fpr": 0.2993421052631579,
            "logloss": 3.952584796821522,
            "mae": 0.3602740337817581,
            "precision": 0.6026200873362445,
            "recall": 0.8884120171673819
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.8189377750193969,
            "auditor_fn_violation": 0.002379838404923434,
            "auditor_fp_violation": 0.014776062467400023,
            "ave_precision_score": 0.7547601146887468,
            "fpr": 0.2810098792535675,
            "logloss": 4.194227817627164,
            "mae": 0.3333435804679025,
            "precision": 0.6332378223495702,
            "recall": 0.9057377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8320983684596376,
            "auditor_fn_violation": 0.013604961975754839,
            "auditor_fp_violation": 0.01784871371253246,
            "ave_precision_score": 0.7954605050720787,
            "fpr": 0.18201754385964913,
            "logloss": 2.5822481992381943,
            "mae": 0.27859771778839953,
            "precision": 0.6954128440366972,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8488203849353354,
            "auditor_fn_violation": 0.006532184052833313,
            "auditor_fp_violation": 0.02465012598837949,
            "ave_precision_score": 0.813497102130924,
            "fpr": 0.15697036223929747,
            "logloss": 2.5449568935391516,
            "mae": 0.2577692257867464,
            "precision": 0.7385740402193784,
            "recall": 0.8278688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8322036922471054,
            "auditor_fn_violation": 0.007962502823582565,
            "auditor_fp_violation": 0.023574561403508772,
            "ave_precision_score": 0.7946785105768469,
            "fpr": 0.21820175438596492,
            "logloss": 2.6639647840136877,
            "mae": 0.2946232890772573,
            "precision": 0.6655462184873949,
            "recall": 0.8497854077253219
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8475636982158837,
            "auditor_fn_violation": 0.005488474204171239,
            "auditor_fp_violation": 0.027411230741683616,
            "ave_precision_score": 0.8099136305902197,
            "fpr": 0.18880351262349068,
            "logloss": 2.6483275331828513,
            "mae": 0.26882118303063396,
            "precision": 0.7084745762711865,
            "recall": 0.8565573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555325502820155,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121132740509078,
            "fpr": 0.4857456140350877,
            "logloss": 16.795580687088695,
            "mae": 0.4868421054074067,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360550407503,
            "mae": 0.45444566475533815,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8318995321541409,
            "auditor_fn_violation": 0.007962502823582565,
            "auditor_fp_violation": 0.024122807017543862,
            "ave_precision_score": 0.793582612937885,
            "fpr": 0.21929824561403508,
            "logloss": 2.6828495612327368,
            "mae": 0.2942524313831341,
            "precision": 0.6644295302013423,
            "recall": 0.8497854077253219
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8479283601311294,
            "auditor_fn_violation": 0.005488474204171239,
            "auditor_fp_violation": 0.026461452226919223,
            "ave_precision_score": 0.8102593861689109,
            "fpr": 0.1877058177826564,
            "logloss": 2.6501031650295013,
            "mae": 0.26851294599459785,
            "precision": 0.7096774193548387,
            "recall": 0.8565573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555325502820155,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121132740509078,
            "fpr": 0.4857456140350877,
            "logloss": 16.79558058305351,
            "mae": 0.4868421054074204,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360550407565,
            "mae": 0.45444566475539977,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8325908363508396,
            "auditor_fn_violation": 0.008171918530231158,
            "auditor_fp_violation": 0.01512223664542523,
            "ave_precision_score": 0.7641322051492818,
            "fpr": 0.19188596491228072,
            "logloss": 4.871418963342608,
            "mae": 0.27675245174476,
            "precision": 0.6919014084507042,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8460342991433871,
            "auditor_fn_violation": 0.006991056486296808,
            "auditor_fp_violation": 0.02516653561799183,
            "ave_precision_score": 0.7781315328534533,
            "fpr": 0.17014270032930845,
            "logloss": 5.021193711507682,
            "mae": 0.25566096808001904,
            "precision": 0.7275922671353251,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7044812421948603,
            "auditor_fn_violation": 0.019082712145169798,
            "auditor_fp_violation": 0.021838860042482894,
            "ave_precision_score": 0.6984311490910711,
            "fpr": 0.21600877192982457,
            "logloss": 1.8707201177882842,
            "mae": 0.3454920392736276,
            "precision": 0.6411657559198543,
            "recall": 0.7553648068669528
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.75005294327897,
            "auditor_fn_violation": 0.01066203595400479,
            "auditor_fp_violation": 0.025150965478405517,
            "ave_precision_score": 0.7431516106100425,
            "fpr": 0.17014270032930845,
            "logloss": 1.7725723819521522,
            "mae": 0.2929413633540905,
            "precision": 0.714548802946593,
            "recall": 0.7950819672131147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7649615941139807,
            "auditor_fn_violation": 0.006376590618176341,
            "auditor_fp_violation": 0.024174435528282603,
            "ave_precision_score": 0.7315159938320075,
            "fpr": 0.28399122807017546,
            "logloss": 3.02088002853308,
            "mae": 0.37180337566720306,
            "precision": 0.5984496124031008,
            "recall": 0.8283261802575107
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.772781486222162,
            "auditor_fn_violation": 0.004534739342462798,
            "auditor_fp_violation": 0.011628299247702763,
            "ave_precision_score": 0.7392074337914994,
            "fpr": 0.26125137211855104,
            "logloss": 2.9645607293615077,
            "mae": 0.3344261195676152,
            "precision": 0.6404833836858006,
            "recall": 0.8688524590163934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8300592366740552,
            "auditor_fn_violation": 0.007835441608312631,
            "auditor_fp_violation": 0.01627527338525687,
            "ave_precision_score": 0.7617238706229947,
            "fpr": 0.19517543859649122,
            "logloss": 4.947053510866209,
            "mae": 0.27951589292349754,
            "precision": 0.6877192982456141,
            "recall": 0.8412017167381974
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.844903775551307,
            "auditor_fn_violation": 0.006514189055442589,
            "auditor_fp_violation": 0.028150812372032916,
            "ave_precision_score": 0.7771345948361624,
            "fpr": 0.17453347969264543,
            "logloss": 5.034971411495815,
            "mae": 0.2556192560499007,
            "precision": 0.7234782608695652,
            "recall": 0.8524590163934426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5125120716563316,
            "auditor_fn_violation": 0.0052659814772983956,
            "auditor_fp_violation": 0.006583864369443789,
            "ave_precision_score": 0.5140497238921853,
            "fpr": 0.0581140350877193,
            "logloss": 0.6965995350102032,
            "mae": 0.49640350687529955,
            "precision": 0.5267857142857143,
            "recall": 0.12660944206008584
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.556305968647903,
            "auditor_fn_violation": 0.011048928397905389,
            "auditor_fp_violation": 0.006274766253279464,
            "ave_precision_score": 0.5582095952335748,
            "fpr": 0.05598243688254665,
            "logloss": 0.7001236280611297,
            "mae": 0.49821000903615836,
            "precision": 0.5565217391304348,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555325502820155,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121132740509078,
            "fpr": 0.4857456140350877,
            "logloss": 16.795581492332506,
            "mae": 0.4868421054073008,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360550407029,
            "mae": 0.4544456647548611,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8427302671123729,
            "auditor_fn_violation": 0.003037704239138628,
            "auditor_fp_violation": 0.006726457399103144,
            "ave_precision_score": 0.7712413901275391,
            "fpr": 0.08114035087719298,
            "logloss": 2.5107764441332048,
            "mae": 0.3374318548788627,
            "precision": 0.817283950617284,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8451700310063244,
            "auditor_fn_violation": 0.00713051771607493,
            "auditor_fp_violation": 0.010559149662776726,
            "ave_precision_score": 0.7741782242641437,
            "fpr": 0.09330406147091108,
            "logloss": 2.8090180591701075,
            "mae": 0.3313580452414428,
            "precision": 0.8045977011494253,
            "recall": 0.7172131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8427302671123729,
            "auditor_fn_violation": 0.003037704239138628,
            "auditor_fp_violation": 0.006726457399103144,
            "ave_precision_score": 0.7712413901275391,
            "fpr": 0.08114035087719298,
            "logloss": 2.5107764237303205,
            "mae": 0.33743179530689593,
            "precision": 0.817283950617284,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8451700310063244,
            "auditor_fn_violation": 0.00713051771607493,
            "auditor_fp_violation": 0.010559149662776726,
            "ave_precision_score": 0.7741782242641437,
            "fpr": 0.09330406147091108,
            "logloss": 2.8090177100657994,
            "mae": 0.3313578152630384,
            "precision": 0.8045977011494253,
            "recall": 0.7172131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 10102,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.4976280083123922,
            "auditor_fn_violation": 0.0016423838566373078,
            "auditor_fp_violation": 0.024880025175045246,
            "ave_precision_score": 0.49961170767975716,
            "fpr": 0.16447368421052633,
            "logloss": 0.7005196640935525,
            "mae": 0.5002139080315828,
            "precision": 0.4755244755244755,
            "recall": 0.2918454935622318
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5350186408622333,
            "auditor_fn_violation": 0.0052567886127656725,
            "auditor_fp_violation": 0.011610134084852074,
            "ave_precision_score": 0.5365777076926999,
            "fpr": 0.13062568605927552,
            "logloss": 0.70230015841541,
            "mae": 0.5006722485652739,
            "precision": 0.5423076923076923,
            "recall": 0.2889344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8555382149599781,
            "auditor_fn_violation": 0.010033130035388903,
            "auditor_fp_violation": 0.013725808354968137,
            "ave_precision_score": 0.8096824213145783,
            "fpr": 0.18969298245614036,
            "logloss": 2.594059701129202,
            "mae": 0.27106944484903517,
            "precision": 0.6996527777777778,
            "recall": 0.8648068669527897
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8624802018880087,
            "auditor_fn_violation": 0.004336794371164817,
            "auditor_fp_violation": 0.02139337179157812,
            "ave_precision_score": 0.8137302911815136,
            "fpr": 0.18331503841931943,
            "logloss": 2.8308966441170704,
            "mae": 0.25541244034853816,
            "precision": 0.7197986577181208,
            "recall": 0.8790983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5020305275345192,
            "auditor_fn_violation": 0.004265962653414669,
            "auditor_fp_violation": 0.011023916292974589,
            "ave_precision_score": 0.5167446301293729,
            "fpr": 0.020833333333333332,
            "logloss": 0.7001983585034359,
            "mae": 0.5013829014149674,
            "precision": 0.2692307692307692,
            "recall": 0.015021459227467811
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5562434427483967,
            "auditor_fn_violation": 0.008637598747548205,
            "auditor_fp_violation": 0.007543732629563024,
            "ave_precision_score": 0.5536417262161832,
            "fpr": 0.018660812294182216,
            "logloss": 0.7032464603434764,
            "mae": 0.5028373154798271,
            "precision": 0.46875,
            "recall": 0.030737704918032786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 10102,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5125120716563316,
            "auditor_fn_violation": 0.0052659814772983956,
            "auditor_fp_violation": 0.006583864369443789,
            "ave_precision_score": 0.5140497238921853,
            "fpr": 0.0581140350877193,
            "logloss": 0.696599538599823,
            "mae": 0.4964035076759102,
            "precision": 0.5267857142857143,
            "recall": 0.12660944206008584
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.556305968647903,
            "auditor_fn_violation": 0.011048928397905389,
            "auditor_fp_violation": 0.006274766253279464,
            "ave_precision_score": 0.5582095952335748,
            "fpr": 0.05598243688254665,
            "logloss": 0.7001236316457714,
            "mae": 0.49821000977222013,
            "precision": 0.5565217391304348,
            "recall": 0.13114754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7733948984417428,
            "auditor_fn_violation": 0.005717754687147055,
            "auditor_fp_violation": 0.01933856502242153,
            "ave_precision_score": 0.7369639791432088,
            "fpr": 0.28289473684210525,
            "logloss": 3.1541394633289848,
            "mae": 0.36937406819692303,
            "precision": 0.6042944785276073,
            "recall": 0.8454935622317596
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7812459640571705,
            "auditor_fn_violation": 0.005900109769484086,
            "auditor_fp_violation": 0.012323765482557572,
            "ave_precision_score": 0.7461407702082705,
            "fpr": 0.2645444566410538,
            "logloss": 3.0734313216173437,
            "mae": 0.3340449919407857,
            "precision": 0.6392215568862275,
            "recall": 0.875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7029708685392664,
            "auditor_fn_violation": 0.02269219185302312,
            "auditor_fp_violation": 0.020742368814412715,
            "ave_precision_score": 0.6898388232145056,
            "fpr": 0.21600877192982457,
            "logloss": 2.139221714611014,
            "mae": 0.3532604413741417,
            "precision": 0.6405109489051095,
            "recall": 0.7532188841201717
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7551662965118253,
            "auditor_fn_violation": 0.011534793327454971,
            "auditor_fp_violation": 0.018689357550090446,
            "ave_precision_score": 0.7445809301227121,
            "fpr": 0.17233809001097694,
            "logloss": 1.8459442352620405,
            "mae": 0.29900890891239296,
            "precision": 0.7108655616942909,
            "recall": 0.7909836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 10102,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8618677501277039,
            "auditor_fn_violation": 0.008223684210526319,
            "auditor_fp_violation": 0.010286366139564167,
            "ave_precision_score": 0.8251508566913672,
            "fpr": 0.18311403508771928,
            "logloss": 2.184486055009398,
            "mae": 0.2647275723127761,
            "precision": 0.7049469964664311,
            "recall": 0.8562231759656652
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8621213036353543,
            "auditor_fn_violation": 0.006406219071098238,
            "auditor_fp_violation": 0.021076778953323324,
            "ave_precision_score": 0.818291107119692,
            "fpr": 0.1690450054884742,
            "logloss": 2.5555830996236772,
            "mae": 0.25182907613023287,
            "precision": 0.7317073170731707,
            "recall": 0.860655737704918
        }
    }
]