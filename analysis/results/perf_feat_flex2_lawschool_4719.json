[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8591086977783019,
            "auditor_fn_violation": 0.007432022010219031,
            "auditor_fp_violation": 0.017192253198316455,
            "ave_precision_score": 0.8579141669066538,
            "fpr": 0.13706140350877194,
            "logloss": 1.5539249859962347,
            "mae": 0.2394971615444478,
            "precision": 0.7632575757575758,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8412970558758263,
            "auditor_fn_violation": 0.010232507414774548,
            "auditor_fp_violation": 0.010477105221891169,
            "ave_precision_score": 0.8392045522856222,
            "fpr": 0.14489571899012074,
            "logloss": 1.6264205392420625,
            "mae": 0.2538093785413474,
            "precision": 0.7391304347826086,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8222943724043426,
            "auditor_fn_violation": 0.009223032122056671,
            "auditor_fp_violation": 0.017642830353794228,
            "ave_precision_score": 0.8222199815052418,
            "fpr": 0.10635964912280702,
            "logloss": 0.8979215604290687,
            "mae": 0.2661864207626241,
            "precision": 0.7886710239651417,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8096823282895036,
            "auditor_fn_violation": 0.009426424810274236,
            "auditor_fp_violation": 0.006240689195546496,
            "ave_precision_score": 0.8099824072556813,
            "fpr": 0.12184412733260154,
            "logloss": 0.9600796161941809,
            "mae": 0.27416544545446747,
            "precision": 0.753880266075388,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8431974694015375,
            "auditor_fn_violation": 0.009772394325937048,
            "auditor_fp_violation": 0.019924365545693212,
            "ave_precision_score": 0.828644392511182,
            "fpr": 0.15021929824561403,
            "logloss": 1.9531314952438554,
            "mae": 0.24453088544613463,
            "precision": 0.7513611615245009,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.829511415305848,
            "auditor_fn_violation": 0.007401734974264629,
            "auditor_fp_violation": 0.014123020228947783,
            "ave_precision_score": 0.8140596786280978,
            "fpr": 0.1712403951701427,
            "logloss": 2.0221330914450175,
            "mae": 0.26308186189707106,
            "precision": 0.7148080438756855,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8056230553680324,
            "auditor_fn_violation": 0.009901918747990146,
            "auditor_fp_violation": 0.018718485644038843,
            "ave_precision_score": 0.8059470520209051,
            "fpr": 0.11842105263157894,
            "logloss": 1.1108215585339258,
            "mae": 0.27209427477704595,
            "precision": 0.7716701902748414,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7820656245786448,
            "auditor_fn_violation": 0.01273610515110493,
            "auditor_fp_violation": 0.012873412262819508,
            "ave_precision_score": 0.783083552800485,
            "fpr": 0.13391877058177826,
            "logloss": 1.1978475384193115,
            "mae": 0.2878037672651459,
            "precision": 0.7359307359307359,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7961333947681128,
            "auditor_fn_violation": 0.01673321542144568,
            "auditor_fp_violation": 0.020216068675251078,
            "ave_precision_score": 0.7679614710332617,
            "fpr": 0.12609649122807018,
            "logloss": 3.3669950234217456,
            "mae": 0.2786308351615135,
            "precision": 0.7568710359408034,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7707591603499581,
            "auditor_fn_violation": 0.00959475382474342,
            "auditor_fp_violation": 0.014037262819507611,
            "ave_precision_score": 0.7373885295730154,
            "fpr": 0.141602634467618,
            "logloss": 3.7142509276400832,
            "mae": 0.285412391190464,
            "precision": 0.7301255230125523,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7889971794253161,
            "auditor_fn_violation": 0.017921267016829247,
            "auditor_fp_violation": 0.019757678043088724,
            "ave_precision_score": 0.7894879516924939,
            "fpr": 0.12390350877192982,
            "logloss": 1.053744672390958,
            "mae": 0.28235603211264876,
            "precision": 0.7600849256900213,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7755177416521847,
            "auditor_fn_violation": 0.013580121054640548,
            "auditor_fp_violation": 0.012900364591500707,
            "ave_precision_score": 0.7769539501685191,
            "fpr": 0.1394072447859495,
            "logloss": 1.0926406334093604,
            "mae": 0.2869775880933025,
            "precision": 0.7320675105485233,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.735883340577804,
            "auditor_fn_violation": 0.006491853360488799,
            "auditor_fp_violation": 0.006714380964287202,
            "ave_precision_score": 0.7157883365355902,
            "fpr": 0.15679824561403508,
            "logloss": 2.559890962799056,
            "mae": 0.26254551667456005,
            "precision": 0.7366482504604052,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7226811595040795,
            "auditor_fn_violation": 0.008376146593234126,
            "auditor_fp_violation": 0.004603947781088291,
            "ave_precision_score": 0.7053853826706407,
            "fpr": 0.16355653128430298,
            "logloss": 2.512294607140561,
            "mae": 0.2657956240429469,
            "precision": 0.7151051625239006,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8678352174620051,
            "auditor_fn_violation": 0.0064159252510094,
            "auditor_fp_violation": 0.01758553152477393,
            "ave_precision_score": 0.863518350342378,
            "fpr": 0.14473684210526316,
            "logloss": 1.733430147605956,
            "mae": 0.23819852602004077,
            "precision": 0.7564575645756457,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8495286395483196,
            "auditor_fn_violation": 0.008606117218635684,
            "auditor_fp_violation": 0.016585482985729972,
            "ave_precision_score": 0.8442504998795762,
            "fpr": 0.16794731064763996,
            "logloss": 1.790272907229635,
            "mae": 0.2594619293941904,
            "precision": 0.7134831460674157,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8507365274676469,
            "auditor_fn_violation": 0.005636545539000253,
            "auditor_fp_violation": 0.017635016877109645,
            "ave_precision_score": 0.8497757850385704,
            "fpr": 0.13486842105263158,
            "logloss": 1.5868757036728744,
            "mae": 0.24047477010970186,
            "precision": 0.7652671755725191,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8309200935654844,
            "auditor_fn_violation": 0.0120295974565723,
            "auditor_fp_violation": 0.011410635878939944,
            "ave_precision_score": 0.8289886405528237,
            "fpr": 0.1437980241492865,
            "logloss": 1.677594246488823,
            "mae": 0.2545863468920659,
            "precision": 0.738,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7995098123540568,
            "auditor_fn_violation": 0.010498177725372494,
            "auditor_fp_violation": 0.02219287827645123,
            "ave_precision_score": 0.7712007530354068,
            "fpr": 0.12171052631578948,
            "logloss": 3.235430741161657,
            "mae": 0.2734856758021428,
            "precision": 0.7672955974842768,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7765382509712453,
            "auditor_fn_violation": 0.009933782684871495,
            "auditor_fp_violation": 0.01161400344989808,
            "ave_precision_score": 0.7464602928505343,
            "fpr": 0.14270032930845225,
            "logloss": 3.490323970002,
            "mae": 0.2868216319588478,
            "precision": 0.7280334728033473,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8437999252848096,
            "auditor_fn_violation": 0.01655679422589059,
            "auditor_fp_violation": 0.015486310788848608,
            "ave_precision_score": 0.844104973600065,
            "fpr": 0.11293859649122807,
            "logloss": 0.7046745194604046,
            "mae": 0.26039557096764254,
            "precision": 0.7854166666666667,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8250129752603073,
            "auditor_fn_violation": 0.014170458020877545,
            "auditor_fp_violation": 0.012327015054100677,
            "ave_precision_score": 0.8254632577348353,
            "fpr": 0.11745334796926454,
            "logloss": 0.7172038399849777,
            "mae": 0.2654676788808065,
            "precision": 0.76431718061674,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7958222034561693,
            "auditor_fn_violation": 0.011815753742809167,
            "auditor_fp_violation": 0.019330541317664707,
            "ave_precision_score": 0.7679828483390411,
            "fpr": 0.12280701754385964,
            "logloss": 3.2495210417013927,
            "mae": 0.27403977976726784,
            "precision": 0.7637130801687764,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7718565503039405,
            "auditor_fn_violation": 0.011643151972650092,
            "auditor_fp_violation": 0.008668848988552615,
            "ave_precision_score": 0.7423526957901098,
            "fpr": 0.13391877058177826,
            "logloss": 3.4804990926880595,
            "mae": 0.2857530551528671,
            "precision": 0.7370689655172413,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8061358350179747,
            "auditor_fn_violation": 0.01346830671383143,
            "auditor_fp_violation": 0.018866941701045963,
            "ave_precision_score": 0.8062665887636936,
            "fpr": 0.11732456140350878,
            "logloss": 1.3306085613066387,
            "mae": 0.2816396177204595,
            "precision": 0.7698924731182796,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.795405743742851,
            "auditor_fn_violation": 0.009651653773296383,
            "auditor_fp_violation": 0.010565312843029643,
            "ave_precision_score": 0.7965264112901952,
            "fpr": 0.12733260153677278,
            "logloss": 1.3308958824251564,
            "mae": 0.2822495228633439,
            "precision": 0.7472766884531591,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8862159720558922,
            "auditor_fn_violation": 0.008570943652410054,
            "auditor_fp_violation": 0.007065987415093553,
            "ave_precision_score": 0.8861702748189882,
            "fpr": 0.09100877192982457,
            "logloss": 1.2551740009398094,
            "mae": 0.22359738108189406,
            "precision": 0.8203463203463204,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8588937995795394,
            "auditor_fn_violation": 0.004317283596456083,
            "auditor_fp_violation": 0.002344852595264237,
            "ave_precision_score": 0.8585931265751109,
            "fpr": 0.09769484083424808,
            "logloss": 1.2875810113977204,
            "mae": 0.21785371581805407,
            "precision": 0.8035320088300221,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6992367788132304,
            "auditor_fn_violation": 0.0174835637974774,
            "auditor_fp_violation": 0.016413510022086096,
            "ave_precision_score": 0.6998689264917753,
            "fpr": 0.11732456140350878,
            "logloss": 1.6064601686259916,
            "mae": 0.3743296534457441,
            "precision": 0.7092391304347826,
            "recall": 0.5315682281059063
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6950025570453626,
            "auditor_fn_violation": 0.013418904533740485,
            "auditor_fp_violation": 0.011609103026501493,
            "ave_precision_score": 0.6957262825349352,
            "fpr": 0.12952799121844127,
            "logloss": 1.546210290046661,
            "mae": 0.3616267320039577,
            "precision": 0.6935064935064935,
            "recall": 0.5766738660907127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7943754442597573,
            "auditor_fn_violation": 0.018084289134240903,
            "auditor_fp_violation": 0.017450097928907782,
            "ave_precision_score": 0.7947505958775418,
            "fpr": 0.1118421052631579,
            "logloss": 1.3273956643439013,
            "mae": 0.28453753586558445,
            "precision": 0.7728285077951003,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7750970513587261,
            "auditor_fn_violation": 0.008013409421208982,
            "auditor_fp_violation": 0.010428100987925354,
            "ave_precision_score": 0.7767300890472566,
            "fpr": 0.12294182217343579,
            "logloss": 1.3834846451500762,
            "mae": 0.2855287925487921,
            "precision": 0.746031746031746,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.4917285404436966,
            "auditor_fn_violation": 0.01460499517633188,
            "auditor_fp_violation": 0.027555527774305127,
            "ave_precision_score": 0.4716041292177242,
            "fpr": 0.24780701754385964,
            "logloss": 8.874136492686198,
            "mae": 0.5068140037681508,
            "precision": 0.5443548387096774,
            "recall": 0.5498981670061099
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.4552332571530028,
            "auditor_fn_violation": 0.015775510736309045,
            "auditor_fp_violation": 0.02843715697036224,
            "ave_precision_score": 0.4341109986540719,
            "fpr": 0.26125137211855104,
            "logloss": 9.4816471891157,
            "mae": 0.5272052364804923,
            "precision": 0.5062240663900415,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7339807211701398,
            "auditor_fn_violation": 0.012970307642834175,
            "auditor_fp_violation": 0.027844626411634803,
            "ave_precision_score": 0.7361876462117203,
            "fpr": 0.19078947368421054,
            "logloss": 1.2849343725536577,
            "mae": 0.3107288251350604,
            "precision": 0.6909413854351687,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7133239482421302,
            "auditor_fn_violation": 0.0062234318729803475,
            "auditor_fp_violation": 0.017504312372588995,
            "ave_precision_score": 0.7151610225930696,
            "fpr": 0.21953896816684962,
            "logloss": 1.4048787335939388,
            "mae": 0.32858468523886647,
            "precision": 0.6515679442508711,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7139777644653672,
            "auditor_fn_violation": 0.002628452495801625,
            "auditor_fp_violation": 0.009967391757302999,
            "ave_precision_score": 0.7132212848684,
            "fpr": 0.09429824561403509,
            "logloss": 5.011985413921079,
            "mae": 0.3800489815573434,
            "precision": 0.7361963190184049,
            "recall": 0.48879837067209775
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.662928623585469,
            "auditor_fn_violation": 0.008345325787767954,
            "auditor_fp_violation": 0.012304963148816059,
            "ave_precision_score": 0.6618733910785628,
            "fpr": 0.09879253567508232,
            "logloss": 5.4439517324397295,
            "mae": 0.3906050111332548,
            "precision": 0.7019867549668874,
            "recall": 0.45788336933045354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6740859820726546,
            "auditor_fn_violation": 0.009915317826133564,
            "auditor_fp_violation": 0.012548443555444428,
            "ave_precision_score": 0.6572629330808767,
            "fpr": 0.18421052631578946,
            "logloss": 2.8709920354831557,
            "mae": 0.3204266205257885,
            "precision": 0.6888888888888889,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6708418559972329,
            "auditor_fn_violation": 0.009016271014454963,
            "auditor_fp_violation": 0.011961933511055354,
            "ave_precision_score": 0.6514847736067049,
            "fpr": 0.18660812294182216,
            "logloss": 2.913794914574841,
            "mae": 0.3223622642561512,
            "precision": 0.6761904761904762,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8219609979537175,
            "auditor_fn_violation": 0.013399078143423735,
            "auditor_fp_violation": 0.014408051006375803,
            "ave_precision_score": 0.8223089311643531,
            "fpr": 0.13048245614035087,
            "logloss": 0.9135996756832229,
            "mae": 0.2637290747851389,
            "precision": 0.7610441767068273,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8093101840099943,
            "auditor_fn_violation": 0.010879744329564506,
            "auditor_fp_violation": 0.009930708013172342,
            "ave_precision_score": 0.8098568979069731,
            "fpr": 0.132821075740944,
            "logloss": 0.9488666078773497,
            "mae": 0.2726318681173719,
            "precision": 0.7414529914529915,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8594124954509268,
            "auditor_fn_violation": 0.008001482831314542,
            "auditor_fp_violation": 0.01717923073717549,
            "ave_precision_score": 0.8580638653241985,
            "fpr": 0.13486842105263158,
            "logloss": 1.6246873657348435,
            "mae": 0.23956724160027634,
            "precision": 0.7657142857142857,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8398454921222067,
            "auditor_fn_violation": 0.0067616105530437925,
            "auditor_fp_violation": 0.009697937901834727,
            "ave_precision_score": 0.8368060442169801,
            "fpr": 0.14270032930845225,
            "logloss": 1.7189726130142622,
            "mae": 0.2531366736117811,
            "precision": 0.7425742574257426,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6311571137914725,
            "auditor_fn_violation": 0.016232983170757845,
            "auditor_fp_violation": 0.01686408717756387,
            "ave_precision_score": 0.6324410604518124,
            "fpr": 0.10964912280701754,
            "logloss": 2.733565581139268,
            "mae": 0.42611318969065953,
            "precision": 0.6774193548387096,
            "recall": 0.42769857433808556
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6188687489024014,
            "auditor_fn_violation": 0.013022975725059444,
            "auditor_fp_violation": 0.009359808687470595,
            "ave_precision_score": 0.6199263495675369,
            "fpr": 0.1207464324917673,
            "logloss": 2.548636790389094,
            "mae": 0.4166322685987123,
            "precision": 0.6496815286624203,
            "recall": 0.4406047516198704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7330891202216812,
            "auditor_fn_violation": 0.006686139993568452,
            "auditor_fp_violation": 0.007553027461766058,
            "ave_precision_score": 0.7346015132163279,
            "fpr": 0.07456140350877193,
            "logloss": 5.934918487675403,
            "mae": 0.3809178909747761,
            "precision": 0.7718120805369127,
            "recall": 0.4684317718940937
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.677513284914918,
            "auditor_fn_violation": 0.003648709200958763,
            "auditor_fp_violation": 0.003910537870472012,
            "ave_precision_score": 0.6813442162888371,
            "fpr": 0.0845225027442371,
            "logloss": 6.34130390279018,
            "mae": 0.39110389506928855,
            "precision": 0.7259786476868327,
            "recall": 0.4406047516198704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8735225177883159,
            "auditor_fn_violation": 0.00439266445135242,
            "auditor_fp_violation": 0.01702035671125558,
            "ave_precision_score": 0.8720011129953711,
            "fpr": 0.14364035087719298,
            "logloss": 1.530067089635907,
            "mae": 0.23915336411200977,
            "precision": 0.7578558225508318,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8495909958285383,
            "auditor_fn_violation": 0.005815648908350782,
            "auditor_fp_violation": 0.015500039203387175,
            "ave_precision_score": 0.8447786816517509,
            "fpr": 0.1525795828759605,
            "logloss": 1.6449534159662211,
            "mae": 0.25405866002537125,
            "precision": 0.7326923076923076,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7969127892959591,
            "auditor_fn_violation": 0.01918078036231108,
            "auditor_fp_violation": 0.016960453390007083,
            "ave_precision_score": 0.7972113725597386,
            "fpr": 0.10964912280701754,
            "logloss": 1.3276952015799026,
            "mae": 0.2844774016220703,
            "precision": 0.7762863534675615,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7795217627023288,
            "auditor_fn_violation": 0.008525508958185648,
            "auditor_fp_violation": 0.009597479222204795,
            "ave_precision_score": 0.7810294996453938,
            "fpr": 0.11964873765093303,
            "logloss": 1.3844012302300994,
            "mae": 0.2848628158650004,
            "precision": 0.7505720823798627,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7983708732412441,
            "auditor_fn_violation": 0.012438810876478372,
            "auditor_fp_violation": 0.01737977663874652,
            "ave_precision_score": 0.798393117739274,
            "fpr": 0.1206140350877193,
            "logloss": 1.5775186731426047,
            "mae": 0.2746055517617683,
            "precision": 0.7674418604651163,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7810447970119019,
            "auditor_fn_violation": 0.006849331307062942,
            "auditor_fp_violation": 0.012155500235220329,
            "ave_precision_score": 0.7822676589513278,
            "fpr": 0.12843029637760703,
            "logloss": 1.628953840348619,
            "mae": 0.2786442466941185,
            "precision": 0.7473002159827213,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8251632047911801,
            "auditor_fn_violation": 0.008414621074070103,
            "auditor_fp_violation": 0.019109159478268117,
            "ave_precision_score": 0.7963796514874827,
            "fpr": 0.13925438596491227,
            "logloss": 3.118862741357578,
            "mae": 0.2454444779548365,
            "precision": 0.759469696969697,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8041142934278522,
            "auditor_fn_violation": 0.007024772815101246,
            "auditor_fp_violation": 0.011917829700486132,
            "ave_precision_score": 0.7756911213469063,
            "fpr": 0.15806805708013172,
            "logloss": 3.2080745088338203,
            "mae": 0.2709603004378452,
            "precision": 0.7214700193423598,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7935784129036259,
            "auditor_fn_violation": 0.012231125165255305,
            "auditor_fp_violation": 0.019773304996457894,
            "ave_precision_score": 0.7936587802092526,
            "fpr": 0.125,
            "logloss": 1.1412425240511828,
            "mae": 0.27249042908424254,
            "precision": 0.7620041753653445,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7727936703857794,
            "auditor_fn_violation": 0.008940404416384348,
            "auditor_fp_violation": 0.01248137839109299,
            "ave_precision_score": 0.7733073101646855,
            "fpr": 0.12952799121844127,
            "logloss": 1.2028294270283122,
            "mae": 0.2818692807336481,
            "precision": 0.7462365591397849,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7875717437298732,
            "auditor_fn_violation": 0.009030978668667592,
            "auditor_fp_violation": 0.015423802975371931,
            "ave_precision_score": 0.789224342061382,
            "fpr": 0.1425438596491228,
            "logloss": 1.140539566814409,
            "mae": 0.2710425813602848,
            "precision": 0.7470817120622568,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7637691264930463,
            "auditor_fn_violation": 0.003734059123788214,
            "auditor_fp_violation": 0.017724831425435163,
            "ave_precision_score": 0.7639569423404868,
            "fpr": 0.16355653128430298,
            "logloss": 1.1956295376670585,
            "mae": 0.28530644771262664,
            "precision": 0.7072691552062869,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7872700252811002,
            "auditor_fn_violation": 0.0159024725765534,
            "auditor_fp_violation": 0.019942596991290584,
            "ave_precision_score": 0.7675144002939861,
            "fpr": 0.12719298245614036,
            "logloss": 2.7291643468923135,
            "mae": 0.28400899012124897,
            "precision": 0.7547568710359408,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7719694575316446,
            "auditor_fn_violation": 0.010784911081976234,
            "auditor_fp_violation": 0.012795005488474205,
            "ave_precision_score": 0.7530441387259152,
            "fpr": 0.13830954994511527,
            "logloss": 2.792216517497361,
            "mae": 0.2891121136044786,
            "precision": 0.7319148936170212,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8251786151301655,
            "auditor_fn_violation": 0.015118626505163114,
            "auditor_fp_violation": 0.014267408426053261,
            "ave_precision_score": 0.8254938274316144,
            "fpr": 0.125,
            "logloss": 0.9512736941446747,
            "mae": 0.2644340656791965,
            "precision": 0.7668711656441718,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8067514264895833,
            "auditor_fn_violation": 0.011512756257216221,
            "auditor_fp_violation": 0.007791673200564534,
            "ave_precision_score": 0.8071116172491415,
            "fpr": 0.12843029637760703,
            "logloss": 0.9820922399348283,
            "mae": 0.2734938099197822,
            "precision": 0.7483870967741936,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7995545172450086,
            "auditor_fn_violation": 0.010498177725372494,
            "auditor_fp_violation": 0.02219287827645123,
            "ave_precision_score": 0.7712389822803478,
            "fpr": 0.12171052631578948,
            "logloss": 3.2442487990153555,
            "mae": 0.27318916561030443,
            "precision": 0.7672955974842768,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7764083752243023,
            "auditor_fn_violation": 0.010038099257218592,
            "auditor_fp_violation": 0.011623804296691237,
            "ave_precision_score": 0.7463260664188915,
            "fpr": 0.14489571899012074,
            "logloss": 3.5024239221931732,
            "mae": 0.28693462299108025,
            "precision": 0.7244258872651357,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7536270948235124,
            "auditor_fn_violation": 0.0007481151963411627,
            "auditor_fp_violation": 8.85527357586391e-05,
            "ave_precision_score": 0.7331619989582613,
            "fpr": 0.1425438596491228,
            "logloss": 2.5671999187710575,
            "mae": 0.25422219251862066,
            "precision": 0.75,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7403160105540031,
            "auditor_fn_violation": 0.0031034180273262018,
            "auditor_fp_violation": 0.002161086717892424,
            "ave_precision_score": 0.7209057543266472,
            "fpr": 0.13830954994511527,
            "logloss": 2.460410400915913,
            "mae": 0.2442233335703553,
            "precision": 0.7509881422924901,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8686862132026132,
            "auditor_fn_violation": 0.006000553828563262,
            "auditor_fp_violation": 0.01353033712547402,
            "ave_precision_score": 0.8675968483092935,
            "fpr": 0.14692982456140352,
            "logloss": 1.4715958089171157,
            "mae": 0.23991729175990495,
            "precision": 0.7518518518518519,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8485419217355568,
            "auditor_fn_violation": 0.009367154030531564,
            "auditor_fp_violation": 0.010428100987925354,
            "ave_precision_score": 0.8461479934656413,
            "fpr": 0.15367727771679474,
            "logloss": 1.5268888662044813,
            "mae": 0.2542237199206319,
            "precision": 0.7318007662835249,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7972623533138437,
            "auditor_fn_violation": 0.01681807624968736,
            "auditor_fp_violation": 0.017450097928907782,
            "ave_precision_score": 0.7976107483462731,
            "fpr": 0.1118421052631579,
            "logloss": 1.3062703381528868,
            "mae": 0.28529834675505283,
            "precision": 0.7718120805369127,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7792033703033656,
            "auditor_fn_violation": 0.007856934562688338,
            "auditor_fp_violation": 0.009597479222204795,
            "ave_precision_score": 0.7806587865253983,
            "fpr": 0.11964873765093303,
            "logloss": 1.3613060363030303,
            "mae": 0.28542948927113526,
            "precision": 0.7488479262672811,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.806871750983645,
            "auditor_fn_violation": 0.013287419158895197,
            "auditor_fp_violation": 0.01837990165437347,
            "ave_precision_score": 0.8071539824146696,
            "fpr": 0.125,
            "logloss": 1.0903089843731184,
            "mae": 0.27036144047315824,
            "precision": 0.7625,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7868237077240388,
            "auditor_fn_violation": 0.01198929332634729,
            "auditor_fp_violation": 0.011143562803826251,
            "ave_precision_score": 0.786971501643849,
            "fpr": 0.13721185510428102,
            "logloss": 1.1415270211909943,
            "mae": 0.2801052742652557,
            "precision": 0.7351694915254238,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7900438318077359,
            "auditor_fn_violation": 0.006219405438239183,
            "auditor_fp_violation": 0.0232372796599575,
            "ave_precision_score": 0.7914611146419794,
            "fpr": 0.14912280701754385,
            "logloss": 0.8860681869430416,
            "mae": 0.2738787725921337,
            "precision": 0.7384615384615385,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.755165141492848,
            "auditor_fn_violation": 0.007954138641466314,
            "auditor_fp_violation": 0.019535537870472006,
            "ave_precision_score": 0.7555833783389653,
            "fpr": 0.17672886937431395,
            "logloss": 0.9950094631525678,
            "mae": 0.29453592320938804,
            "precision": 0.6915708812260536,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5190706321879827,
            "auditor_fn_violation": 0.0002054525315325095,
            "auditor_fp_violation": 0.0011173271658957479,
            "ave_precision_score": 0.5107737635538127,
            "fpr": 0.1600877192982456,
            "logloss": 4.366662491739548,
            "mae": 0.49838031876862937,
            "precision": 0.562874251497006,
            "recall": 0.38289205702647655
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5083735099244568,
            "auditor_fn_violation": 0.010322598999983394,
            "auditor_fp_violation": 0.0020924807903402926,
            "ave_precision_score": 0.49976974802273666,
            "fpr": 0.16136114160263446,
            "logloss": 3.94224531173239,
            "mae": 0.481412928594374,
            "precision": 0.5558912386706949,
            "recall": 0.39740820734341253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8256480372632432,
            "auditor_fn_violation": 0.0148841426376532,
            "auditor_fp_violation": 0.016330166270783854,
            "ave_precision_score": 0.8259029531040367,
            "fpr": 0.11842105263157894,
            "logloss": 0.928563786454344,
            "mae": 0.2692989950330067,
            "precision": 0.7721518987341772,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8073097730579164,
            "auditor_fn_violation": 0.011379989710592635,
            "auditor_fp_violation": 0.009055982436882553,
            "ave_precision_score": 0.8075941336179581,
            "fpr": 0.11855104281009879,
            "logloss": 0.9480007023117482,
            "mae": 0.27400871609393124,
            "precision": 0.76,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 4719,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8762368267054872,
            "auditor_fn_violation": 0.009604905849144245,
            "auditor_fp_violation": 0.020218673167479273,
            "ave_precision_score": 0.8719575783438999,
            "fpr": 0.17982456140350878,
            "logloss": 1.7000864025570328,
            "mae": 0.25089227976051004,
            "precision": 0.7252931323283082,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.863722700384683,
            "auditor_fn_violation": 0.0032456678987086087,
            "auditor_fp_violation": 0.018283479692645446,
            "ave_precision_score": 0.8586538945051724,
            "fpr": 0.19978046103183314,
            "logloss": 1.7616322306419285,
            "mae": 0.2752226122565126,
            "precision": 0.6872852233676976,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7964670353179213,
            "auditor_fn_violation": 0.015065030192589424,
            "auditor_fp_violation": 0.01963005792390715,
            "ave_precision_score": 0.7966605708339733,
            "fpr": 0.11513157894736842,
            "logloss": 1.3658909896191824,
            "mae": 0.2896502692108835,
            "precision": 0.7661469933184856,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7870964866439867,
            "auditor_fn_violation": 0.012008259975864943,
            "auditor_fp_violation": 0.012594088129214368,
            "ave_precision_score": 0.7882612816447588,
            "fpr": 0.12733260153677278,
            "logloss": 1.36144335625257,
            "mae": 0.28822736108027136,
            "precision": 0.7410714285714286,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7987440033955082,
            "auditor_fn_violation": 0.008720566691678288,
            "auditor_fp_violation": 0.02086979622452807,
            "ave_precision_score": 0.7787792484505813,
            "fpr": 0.125,
            "logloss": 2.6373902357125605,
            "mae": 0.27517669653532617,
            "precision": 0.7654320987654321,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7855573189606867,
            "auditor_fn_violation": 0.010026245101270054,
            "auditor_fp_violation": 0.01360112513721186,
            "ave_precision_score": 0.766241550549684,
            "fpr": 0.145993413830955,
            "logloss": 2.6324739608570016,
            "mae": 0.2917111570288879,
            "precision": 0.7211740041928721,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8491930115001466,
            "auditor_fn_violation": 0.007876424768642589,
            "auditor_fp_violation": 0.015887402591990667,
            "ave_precision_score": 0.8482312682952955,
            "fpr": 0.13925438596491227,
            "logloss": 1.5718032739198755,
            "mae": 0.2400745800678067,
            "precision": 0.7603773584905661,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8322534664009402,
            "auditor_fn_violation": 0.007909092848861885,
            "auditor_fp_violation": 0.010577563901521092,
            "ave_precision_score": 0.8302332408613307,
            "fpr": 0.1525795828759605,
            "logloss": 1.6239279990932358,
            "mae": 0.26022883631971433,
            "precision": 0.728515625,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.799590081715366,
            "auditor_fn_violation": 0.011925179547647121,
            "auditor_fp_violation": 0.019010188773596705,
            "ave_precision_score": 0.7702669443979407,
            "fpr": 0.13048245614035087,
            "logloss": 3.3879692886293977,
            "mae": 0.27515544106435647,
            "precision": 0.7571428571428571,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7739449487882121,
            "auditor_fn_violation": 0.009846061930852334,
            "auditor_fp_violation": 0.01679865140348126,
            "ave_precision_score": 0.7379727174398623,
            "fpr": 0.14489571899012074,
            "logloss": 3.8062807353581403,
            "mae": 0.2842411364225017,
            "precision": 0.7272727272727273,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7981458575522411,
            "auditor_fn_violation": 0.02129336834959089,
            "auditor_fp_violation": 0.01816633329166146,
            "ave_precision_score": 0.7985649607579589,
            "fpr": 0.10964912280701754,
            "logloss": 1.2835481462601497,
            "mae": 0.28633174523107213,
            "precision": 0.7757847533632287,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.779743170365222,
            "auditor_fn_violation": 0.00731875588262489,
            "auditor_fp_violation": 0.010036067116198843,
            "ave_precision_score": 0.7814576564382283,
            "fpr": 0.11855104281009879,
            "logloss": 1.3406391025685211,
            "mae": 0.2860995977408354,
            "precision": 0.7505773672055427,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8387901236273851,
            "auditor_fn_violation": 0.0038812663022117413,
            "auditor_fp_violation": 0.020877609701212652,
            "ave_precision_score": 0.8083784985929976,
            "fpr": 0.13706140350877194,
            "logloss": 3.201763623464111,
            "mae": 0.23903194334114006,
            "precision": 0.7623574144486692,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.818192696431683,
            "auditor_fn_violation": 0.006363310913173051,
            "auditor_fp_violation": 0.01207219303747844,
            "ave_precision_score": 0.7863518254909456,
            "fpr": 0.15477497255762898,
            "logloss": 3.3808646193349365,
            "mae": 0.2617286926327446,
            "precision": 0.7267441860465116,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7940227315048953,
            "auditor_fn_violation": 0.014216421910172588,
            "auditor_fp_violation": 0.018179355752802436,
            "ave_precision_score": 0.794475955148799,
            "fpr": 0.1118421052631579,
            "logloss": 1.3166010487079578,
            "mae": 0.28756091996691435,
            "precision": 0.7687074829931972,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7734981132745602,
            "auditor_fn_violation": 0.00961609130545078,
            "auditor_fp_violation": 0.010680472792849307,
            "ave_precision_score": 0.7750108603418719,
            "fpr": 0.12623490669593854,
            "logloss": 1.3856628239135136,
            "mae": 0.29010061272985205,
            "precision": 0.7380410022779044,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8485911476903283,
            "auditor_fn_violation": 0.006029585164540685,
            "auditor_fp_violation": 0.015887402591990667,
            "ave_precision_score": 0.8476058930104157,
            "fpr": 0.13925438596491227,
            "logloss": 1.5811325338107955,
            "mae": 0.2401148947655525,
            "precision": 0.7608286252354048,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8322243137718518,
            "auditor_fn_violation": 0.007024772815101246,
            "auditor_fp_violation": 0.010577563901521092,
            "ave_precision_score": 0.8301213791798198,
            "fpr": 0.1525795828759605,
            "logloss": 1.6341937632779266,
            "mae": 0.26050441830730886,
            "precision": 0.7290448343079922,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8025076696243767,
            "auditor_fn_violation": 0.014464304855825925,
            "auditor_fp_violation": 0.018205400675084395,
            "ave_precision_score": 0.8025932146633983,
            "fpr": 0.11951754385964912,
            "logloss": 1.307236106868156,
            "mae": 0.2756061900667361,
            "precision": 0.7685774946921444,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7852273477606649,
            "auditor_fn_violation": 0.01279063426846819,
            "auditor_fp_violation": 0.011677708954053633,
            "ave_precision_score": 0.7844947560739894,
            "fpr": 0.12952799121844127,
            "logloss": 1.3647276722199637,
            "mae": 0.2809042149277787,
            "precision": 0.7445887445887446,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8102231652329388,
            "auditor_fn_violation": 0.013470539893522001,
            "auditor_fp_violation": 0.018163728799433274,
            "ave_precision_score": 0.8105321240152261,
            "fpr": 0.12719298245614036,
            "logloss": 1.0871319790795377,
            "mae": 0.2825765036077439,
            "precision": 0.7557894736842106,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7944621004838566,
            "auditor_fn_violation": 0.008013409421208983,
            "auditor_fp_violation": 0.012723949349223775,
            "ave_precision_score": 0.7950130194015603,
            "fpr": 0.13721185510428102,
            "logloss": 1.0707712567421928,
            "mae": 0.29156343935976536,
            "precision": 0.7323340471092077,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8802985905382918,
            "auditor_fn_violation": 0.004857165826991107,
            "auditor_fp_violation": 0.01475184398049757,
            "ave_precision_score": 0.8790442769938525,
            "fpr": 0.14473684210526316,
            "logloss": 1.4209172689577154,
            "mae": 0.23943369198148134,
            "precision": 0.756007393715342,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8560572320068884,
            "auditor_fn_violation": 0.007017660321532126,
            "auditor_fp_violation": 0.01124157127175788,
            "ave_precision_score": 0.8521671388967391,
            "fpr": 0.15587266739846323,
            "logloss": 1.506461922425749,
            "mae": 0.25161856945410704,
            "precision": 0.7310606060606061,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6913045607925148,
            "auditor_fn_violation": 0.018890467002536895,
            "auditor_fp_violation": 0.01812205692378215,
            "ave_precision_score": 0.6832508140056095,
            "fpr": 0.15021929824561403,
            "logloss": 2.0712502095612106,
            "mae": 0.3121702384725431,
            "precision": 0.7186858316221766,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6994608376011536,
            "auditor_fn_violation": 0.004362329389060512,
            "auditor_fp_violation": 0.00999931394072448,
            "ave_precision_score": 0.6938867451574293,
            "fpr": 0.145993413830955,
            "logloss": 1.821926735389742,
            "mae": 0.30665195231365744,
            "precision": 0.7176220806794055,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7689163971442174,
            "auditor_fn_violation": 0.017586290063243654,
            "auditor_fp_violation": 0.019088323540442556,
            "ave_precision_score": 0.7692212500269364,
            "fpr": 0.125,
            "logloss": 1.3809440113938463,
            "mae": 0.3016086190406889,
            "precision": 0.748898678414097,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7636939492380244,
            "auditor_fn_violation": 0.012209780626990024,
            "auditor_fp_violation": 0.01335855417908108,
            "ave_precision_score": 0.7649107371620449,
            "fpr": 0.13611416026344675,
            "logloss": 1.3749269316268056,
            "mae": 0.30530681557231704,
            "precision": 0.7268722466960352,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8449250252488929,
            "auditor_fn_violation": 0.02566816736341873,
            "auditor_fp_violation": 0.02350033337500521,
            "ave_precision_score": 0.8451491914512697,
            "fpr": 0.09649122807017543,
            "logloss": 0.7044523807492665,
            "mae": 0.28983464569978423,
            "precision": 0.7919621749408984,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8223953844489342,
            "auditor_fn_violation": 0.021856692737906996,
            "auditor_fp_violation": 0.012956719460561397,
            "ave_precision_score": 0.8227831727939736,
            "fpr": 0.09659714599341383,
            "logloss": 0.747252904116739,
            "mae": 0.2912022054817801,
            "precision": 0.7731958762886598,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8117680638363294,
            "auditor_fn_violation": 0.0024073677064351305,
            "auditor_fp_violation": 0.017528232695753633,
            "ave_precision_score": 0.8122997847938149,
            "fpr": 0.12171052631578948,
            "logloss": 0.981687262099712,
            "mae": 0.2666919031660883,
            "precision": 0.7730061349693251,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7975632840808232,
            "auditor_fn_violation": 0.00884320033760636,
            "auditor_fp_violation": 0.012589187705817783,
            "ave_precision_score": 0.7984490225544947,
            "fpr": 0.13062568605927552,
            "logloss": 0.9749328085594228,
            "mae": 0.2812830667970724,
            "precision": 0.7451820128479657,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7725210352768848,
            "auditor_fn_violation": 0.006027351984850108,
            "auditor_fp_violation": 0.018814851856482063,
            "ave_precision_score": 0.7725285102764186,
            "fpr": 0.14035087719298245,
            "logloss": 1.6276425398753902,
            "mae": 0.2842157214861083,
            "precision": 0.7455268389662028,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7568132671034841,
            "auditor_fn_violation": 0.01037238645496725,
            "auditor_fp_violation": 0.013652579582875966,
            "ave_precision_score": 0.7580915801024077,
            "fpr": 0.15367727771679474,
            "logloss": 1.6980159895487985,
            "mae": 0.29523616631251354,
            "precision": 0.7154471544715447,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7834198291714685,
            "auditor_fn_violation": 0.00610104691463894,
            "auditor_fp_violation": 0.005136058674000918,
            "ave_precision_score": 0.7409039171937182,
            "fpr": 0.20723684210526316,
            "logloss": 3.171010783899516,
            "mae": 0.2866001465208917,
            "precision": 0.6916802610114192,
            "recall": 0.8635437881873728
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7770645238749835,
            "auditor_fn_violation": 0.007432555779730821,
            "auditor_fp_violation": 0.005120942449427636,
            "ave_precision_score": 0.7335790545960165,
            "fpr": 0.21405049396267836,
            "logloss": 3.0366956436438213,
            "mae": 0.2904674812948562,
            "precision": 0.6728187919463087,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8042435567887853,
            "auditor_fn_violation": 0.010011344552828101,
            "auditor_fp_violation": 0.023904029670375464,
            "ave_precision_score": 0.804619806059891,
            "fpr": 0.12828947368421054,
            "logloss": 1.0283929965985492,
            "mae": 0.27326697720406357,
            "precision": 0.7597535934291582,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.779589577228913,
            "auditor_fn_violation": 0.006624102344040798,
            "auditor_fp_violation": 0.016720244629135964,
            "ave_precision_score": 0.7812261319133472,
            "fpr": 0.14489571899012074,
            "logloss": 1.0865176591719816,
            "mae": 0.28707602951730504,
            "precision": 0.7283950617283951,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7951489684041804,
            "auditor_fn_violation": 0.008693768535391435,
            "auditor_fp_violation": 0.022989852898278953,
            "ave_precision_score": 0.7485308732537277,
            "fpr": 0.12938596491228072,
            "logloss": 4.489530730514233,
            "mae": 0.2878603796808432,
            "precision": 0.7541666666666667,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7655530425768811,
            "auditor_fn_violation": 0.009229645821528574,
            "auditor_fp_violation": 0.013275246981339193,
            "ave_precision_score": 0.708465044299428,
            "fpr": 0.145993413830955,
            "logloss": 5.122637196226082,
            "mae": 0.2964966910233155,
            "precision": 0.7194092827004219,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7945968713866419,
            "auditor_fn_violation": 0.01441964126201451,
            "auditor_fp_violation": 0.01823405008959453,
            "ave_precision_score": 0.7950678548199871,
            "fpr": 0.12280701754385964,
            "logloss": 0.8348501974322664,
            "mae": 0.28789455665317193,
            "precision": 0.759656652360515,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7944070997150998,
            "auditor_fn_violation": 0.010701931990336495,
            "auditor_fp_violation": 0.01183942292614082,
            "ave_precision_score": 0.7952390090640253,
            "fpr": 0.13611416026344675,
            "logloss": 0.8498310760581471,
            "mae": 0.29233101351533036,
            "precision": 0.7298474945533769,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7947044546787868,
            "auditor_fn_violation": 0.012988173080358737,
            "auditor_fp_violation": 0.01823405008959453,
            "ave_precision_score": 0.7837832074220177,
            "fpr": 0.12280701754385964,
            "logloss": 2.0449855004046325,
            "mae": 0.2693021719176737,
            "precision": 0.7656903765690377,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7812079146367393,
            "auditor_fn_violation": 0.00888350446783138,
            "auditor_fp_violation": 0.010102222832052688,
            "ave_precision_score": 0.7679342445156002,
            "fpr": 0.13062568605927552,
            "logloss": 2.117861389059148,
            "mae": 0.2773773082217588,
            "precision": 0.746268656716418,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8749635091902273,
            "auditor_fn_violation": 0.008792028441776543,
            "auditor_fp_violation": 0.012535421094303466,
            "ave_precision_score": 0.873878464664856,
            "fpr": 0.14364035087719298,
            "logloss": 1.491232330821502,
            "mae": 0.23914596690747877,
            "precision": 0.7551401869158878,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8520939562997801,
            "auditor_fn_violation": 0.014198907995154022,
            "auditor_fp_violation": 0.013140485337933208,
            "ave_precision_score": 0.8489246723647985,
            "fpr": 0.150384193194292,
            "logloss": 1.5615269126595106,
            "mae": 0.25240384816447226,
            "precision": 0.7339805825242719,
            "recall": 0.816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7676303805671583,
            "auditor_fn_violation": 0.009214099403294393,
            "auditor_fp_violation": 0.025469329499520778,
            "ave_precision_score": 0.7681802260210453,
            "fpr": 0.16337719298245615,
            "logloss": 1.1043179537176555,
            "mae": 0.2946203862848809,
            "precision": 0.7204502814258912,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7446352304539648,
            "auditor_fn_violation": 0.005865436363334627,
            "auditor_fp_violation": 0.018614258271914697,
            "ave_precision_score": 0.7463334388163336,
            "fpr": 0.1942919868276619,
            "logloss": 1.185609471907991,
            "mae": 0.311109289710937,
            "precision": 0.6697761194029851,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.80331402345923,
            "auditor_fn_violation": 0.011145799835637977,
            "auditor_fp_violation": 0.019330541317664707,
            "ave_precision_score": 0.8036999016579722,
            "fpr": 0.12280701754385964,
            "logloss": 1.1321031742340473,
            "mae": 0.27177270930070124,
            "precision": 0.7647058823529411,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7843466800153003,
            "auditor_fn_violation": 0.008596633893876856,
            "auditor_fp_violation": 0.01092549396267838,
            "ave_precision_score": 0.785817901267389,
            "fpr": 0.13062568605927552,
            "logloss": 1.2166623207079057,
            "mae": 0.27950999397445947,
            "precision": 0.7435344827586207,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7963453810363271,
            "auditor_fn_violation": 0.01899096008861257,
            "auditor_fp_violation": 0.018476267866816692,
            "ave_precision_score": 0.7966977457789932,
            "fpr": 0.1206140350877193,
            "logloss": 1.1828526727012905,
            "mae": 0.2814349513186952,
            "precision": 0.7644539614561028,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7780329288948378,
            "auditor_fn_violation": 0.010903452641461576,
            "auditor_fp_violation": 0.013138035126234916,
            "ave_precision_score": 0.7796413178923006,
            "fpr": 0.1251372118551043,
            "logloss": 1.2321893127700028,
            "mae": 0.28467393631943333,
            "precision": 0.7472283813747228,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8320073574699125,
            "auditor_fn_violation": 0.010576339014542468,
            "auditor_fp_violation": 0.011998895695295246,
            "ave_precision_score": 0.8318755645540796,
            "fpr": 0.08881578947368421,
            "logloss": 1.5610676399650476,
            "mae": 0.2847256638684487,
            "precision": 0.8004926108374384,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7946253902712631,
            "auditor_fn_violation": 0.006887264606098256,
            "auditor_fp_violation": 0.008683550258742357,
            "ave_precision_score": 0.7938093064559606,
            "fpr": 0.09769484083424808,
            "logloss": 1.6531892030285527,
            "mae": 0.2945513096885583,
            "precision": 0.7729591836734694,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6804690096876629,
            "auditor_fn_violation": 0.0077602994247329155,
            "auditor_fp_violation": 0.009089677876401222,
            "ave_precision_score": 0.6541239439004642,
            "fpr": 0.20394736842105263,
            "logloss": 3.2674060493166306,
            "mae": 0.2946963032565622,
            "precision": 0.6910299003322259,
            "recall": 0.8472505091649695
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6560694041270347,
            "auditor_fn_violation": 0.006448660836002494,
            "auditor_fp_violation": 0.007130116042026039,
            "ave_precision_score": 0.6357629940885579,
            "fpr": 0.21844127332601537,
            "logloss": 3.0950758069823365,
            "mae": 0.31179883582251433,
            "precision": 0.6627118644067796,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7946034877076878,
            "auditor_fn_violation": 0.017555025547575664,
            "auditor_fp_violation": 0.018622119431595623,
            "ave_precision_score": 0.7950498824392511,
            "fpr": 0.11074561403508772,
            "logloss": 1.3326817055844424,
            "mae": 0.28426495929240286,
            "precision": 0.7740492170022372,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7751372023429203,
            "auditor_fn_violation": 0.0109461276028763,
            "auditor_fp_violation": 0.009550925199937284,
            "ave_precision_score": 0.7767545639498357,
            "fpr": 0.1207464324917673,
            "logloss": 1.3881650451509873,
            "mae": 0.2853460660564183,
            "precision": 0.7505668934240363,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7774848463235464,
            "auditor_fn_violation": 0.011346786007789336,
            "auditor_fp_violation": 0.01160822186106597,
            "ave_precision_score": 0.7780115940343704,
            "fpr": 0.10416666666666667,
            "logloss": 0.9069845094517187,
            "mae": 0.312348368691883,
            "precision": 0.7682926829268293,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7709668158791024,
            "auditor_fn_violation": 0.014533195192902687,
            "auditor_fp_violation": 0.009418613768229571,
            "ave_precision_score": 0.7724080108692097,
            "fpr": 0.1163556531284303,
            "logloss": 0.8859039997526361,
            "mae": 0.30642522577844833,
            "precision": 0.7451923076923077,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8701129292016361,
            "auditor_fn_violation": 0.007320363025690498,
            "auditor_fp_violation": 0.01160822186106597,
            "ave_precision_score": 0.8700725343006326,
            "fpr": 0.10416666666666667,
            "logloss": 1.247879665771862,
            "mae": 0.23160194929559233,
            "precision": 0.8041237113402062,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8488149769769056,
            "auditor_fn_violation": 0.010204057440498066,
            "auditor_fp_violation": 0.0013990708797240099,
            "ave_precision_score": 0.849157535238601,
            "fpr": 0.11745334796926454,
            "logloss": 1.2852749679852342,
            "mae": 0.24147910341010845,
            "precision": 0.7713675213675214,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.807133540940909,
            "auditor_fn_violation": 0.006413692071318825,
            "auditor_fp_violation": 0.019861857732216534,
            "ave_precision_score": 0.8075002172398809,
            "fpr": 0.14692982456140352,
            "logloss": 1.1126338650882517,
            "mae": 0.2735223547863132,
            "precision": 0.7432950191570882,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7956112609243532,
            "auditor_fn_violation": 0.007942284485517783,
            "auditor_fp_violation": 0.01693586325858554,
            "ave_precision_score": 0.7960502690004974,
            "fpr": 0.1668496158068057,
            "logloss": 1.1370804660373348,
            "mae": 0.29026943596995386,
            "precision": 0.7048543689320388,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7671193253534503,
            "auditor_fn_violation": 0.013876978597205852,
            "auditor_fp_violation": 0.015785827395091052,
            "ave_precision_score": 0.767699326710269,
            "fpr": 0.10526315789473684,
            "logloss": 0.9067607733829132,
            "mae": 0.32027228516362455,
            "precision": 0.7593984962406015,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7655721684267401,
            "auditor_fn_violation": 0.021259243278100876,
            "auditor_fp_violation": 0.011966833934451936,
            "ave_precision_score": 0.7670341760704302,
            "fpr": 0.11855104281009879,
            "logloss": 0.8797899144732594,
            "mae": 0.3129780159973634,
            "precision": 0.7365853658536585,
            "recall": 0.652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8825642971316116,
            "auditor_fn_violation": 0.005348465358916644,
            "auditor_fp_violation": 0.012965162311955668,
            "ave_precision_score": 0.8827197702962791,
            "fpr": 0.09868421052631579,
            "logloss": 0.6944155749537384,
            "mae": 0.2328527877830251,
            "precision": 0.8109243697478992,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.856540872727749,
            "auditor_fn_violation": 0.01254406782473868,
            "auditor_fp_violation": 0.006716030265014899,
            "ave_precision_score": 0.8570047631326838,
            "fpr": 0.11086717892425905,
            "logloss": 0.7272715166485811,
            "mae": 0.2388548764451601,
            "precision": 0.7823275862068966,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8013136973591476,
            "auditor_fn_violation": 0.016617090077536003,
            "auditor_fp_violation": 0.02128130599658291,
            "ave_precision_score": 0.7678457628985775,
            "fpr": 0.125,
            "logloss": 3.7354819685944425,
            "mae": 0.2778631104519079,
            "precision": 0.7625,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7722479250706671,
            "auditor_fn_violation": 0.006491335797417226,
            "auditor_fp_violation": 0.011180315979300614,
            "ave_precision_score": 0.7312448146024064,
            "fpr": 0.1350164654226125,
            "logloss": 4.205064449799646,
            "mae": 0.29126700170638803,
            "precision": 0.7354838709677419,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7890994609387744,
            "auditor_fn_violation": 0.008423553792832389,
            "auditor_fp_violation": 0.02347428845272326,
            "ave_precision_score": 0.7603531792968146,
            "fpr": 0.125,
            "logloss": 3.383619458883993,
            "mae": 0.2775388821377339,
            "precision": 0.762993762993763,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7569239202705076,
            "auditor_fn_violation": 0.012091239067504683,
            "auditor_fp_violation": 0.01621550101928808,
            "ave_precision_score": 0.7192398111237754,
            "fpr": 0.141602634467618,
            "logloss": 3.8931821495775547,
            "mae": 0.2930140763454336,
            "precision": 0.7266949152542372,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8855054666449027,
            "auditor_fn_violation": 0.003202379676278277,
            "auditor_fp_violation": 0.007951514772679922,
            "ave_precision_score": 0.8854649941867756,
            "fpr": 0.08881578947368421,
            "logloss": 1.1903710867794173,
            "mae": 0.22779170589058353,
            "precision": 0.8207964601769911,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8489775841789913,
            "auditor_fn_violation": 0.005794311427643424,
            "auditor_fp_violation": 0.006194135173278973,
            "ave_precision_score": 0.8491800345285749,
            "fpr": 0.08781558726673985,
            "logloss": 1.2138022345451547,
            "mae": 0.22911734997728592,
            "precision": 0.8113207547169812,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7940254384975705,
            "auditor_fn_violation": 0.008691535355700868,
            "auditor_fp_violation": 0.01991915656123682,
            "ave_precision_score": 0.7905326959521743,
            "fpr": 0.13157894736842105,
            "logloss": 1.649185148273923,
            "mae": 0.2748249606676292,
            "precision": 0.7565922920892495,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7787360838546212,
            "auditor_fn_violation": 0.0071267185562586466,
            "auditor_fp_violation": 0.013098831739062261,
            "ave_precision_score": 0.7749769906310725,
            "fpr": 0.15148188803512624,
            "logloss": 1.7655814237205731,
            "mae": 0.2940138967264299,
            "precision": 0.7148760330578512,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8725215822524358,
            "auditor_fn_violation": 0.005600814663951124,
            "auditor_fp_violation": 0.019596199524940617,
            "ave_precision_score": 0.8665843770156452,
            "fpr": 0.14583333333333334,
            "logloss": 1.6938319191516484,
            "mae": 0.24003324032759857,
            "precision": 0.7559633027522936,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8531680507401431,
            "auditor_fn_violation": 0.005953157117353773,
            "auditor_fp_violation": 0.01648502430610005,
            "ave_precision_score": 0.8458164225699707,
            "fpr": 0.16245883644346873,
            "logloss": 1.7563689004673406,
            "mae": 0.25764975549152414,
            "precision": 0.7233644859813084,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7956428900939356,
            "auditor_fn_violation": 0.013171293814985533,
            "auditor_fp_violation": 0.01981497687210902,
            "ave_precision_score": 0.7958160110447189,
            "fpr": 0.11842105263157894,
            "logloss": 1.370801488284533,
            "mae": 0.2894479242064663,
            "precision": 0.7626373626373626,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.784746188133371,
            "auditor_fn_violation": 0.011783031012842797,
            "auditor_fp_violation": 0.012439724792222051,
            "ave_precision_score": 0.7859027097162321,
            "fpr": 0.132821075740944,
            "logloss": 1.3741095034852364,
            "mae": 0.2897299550663776,
            "precision": 0.734065934065934,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8158273292061693,
            "auditor_fn_violation": 0.013943973987922971,
            "auditor_fp_violation": 0.014921135975330251,
            "ave_precision_score": 0.816150822440703,
            "fpr": 0.12390350877192982,
            "logloss": 1.007291637503702,
            "mae": 0.2689938989375334,
            "precision": 0.7631027253668763,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7977829180494846,
            "auditor_fn_violation": 0.009661137098055212,
            "auditor_fp_violation": 0.004481437196173758,
            "ave_precision_score": 0.7992916072467358,
            "fpr": 0.12623490669593854,
            "logloss": 1.0905471298452816,
            "mae": 0.27306612508507916,
            "precision": 0.7516198704103672,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8903610397793758,
            "auditor_fn_violation": 0.007360560260120773,
            "auditor_fp_violation": 0.012077030462141104,
            "ave_precision_score": 0.8905035763732844,
            "fpr": 0.09320175438596491,
            "logloss": 0.7718400671747943,
            "mae": 0.22155225234213283,
            "precision": 0.8175965665236051,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8668562839026741,
            "auditor_fn_violation": 0.012122059872970867,
            "auditor_fp_violation": 0.004527991218441276,
            "ave_precision_score": 0.8676153769960809,
            "fpr": 0.09220636663007684,
            "logloss": 0.782276585262493,
            "mae": 0.21896075582261815,
            "precision": 0.8137472283813747,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7549154704586596,
            "auditor_fn_violation": 0.006125611891235219,
            "auditor_fp_violation": 0.008553152477393019,
            "ave_precision_score": 0.7337902265494973,
            "fpr": 0.1425438596491228,
            "logloss": 2.491157281423034,
            "mae": 0.25166700680841,
            "precision": 0.7533206831119544,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.7399129471531924,
            "auditor_fn_violation": 0.0034969760048175307,
            "auditor_fp_violation": 0.0029794574251215357,
            "ave_precision_score": 0.721006908870382,
            "fpr": 0.14050493962678376,
            "logloss": 2.4247204186618183,
            "mae": 0.24248980078349927,
            "precision": 0.7480314960629921,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8737547256349314,
            "auditor_fn_violation": 0.004517722514024372,
            "auditor_fp_violation": 0.017304246364128858,
            "ave_precision_score": 0.8704478200906274,
            "fpr": 0.14144736842105263,
            "logloss": 1.6283391631197481,
            "mae": 0.23814420600834676,
            "precision": 0.7597765363128491,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.85385871483009,
            "auditor_fn_violation": 0.007337722532142547,
            "auditor_fp_violation": 0.012579386859024627,
            "ave_precision_score": 0.8484902857947456,
            "fpr": 0.15148188803512624,
            "logloss": 1.6959184421606721,
            "mae": 0.25223206827402195,
            "precision": 0.7346153846153847,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7340747238216769,
            "auditor_fn_violation": 0.015915871654696826,
            "auditor_fp_violation": 0.020979184898112277,
            "ave_precision_score": 0.7346239734266862,
            "fpr": 0.12828947368421054,
            "logloss": 1.686828189923223,
            "mae": 0.32242445004264964,
            "precision": 0.7259953161592506,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7210439539815368,
            "auditor_fn_violation": 0.011996405819916407,
            "auditor_fp_violation": 0.012006037321624594,
            "ave_precision_score": 0.7223746752126643,
            "fpr": 0.13830954994511527,
            "logloss": 1.674785536911168,
            "mae": 0.32218526671552483,
            "precision": 0.7083333333333334,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8349027078907331,
            "auditor_fn_violation": 0.010629935327116164,
            "auditor_fp_violation": 0.02025253156644581,
            "ave_precision_score": 0.8351922552897518,
            "fpr": 0.125,
            "logloss": 0.7949796267959495,
            "mae": 0.267779343731241,
            "precision": 0.768762677484787,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8204830618689347,
            "auditor_fn_violation": 0.00866301716718865,
            "auditor_fp_violation": 0.014152422769327277,
            "ave_precision_score": 0.8211596189154133,
            "fpr": 0.13611416026344675,
            "logloss": 0.8436543522136545,
            "mae": 0.2794176131322419,
            "precision": 0.7389473684210527,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.798904895391023,
            "auditor_fn_violation": 0.009658502161717939,
            "auditor_fp_violation": 0.022106930032920784,
            "ave_precision_score": 0.7699660887861572,
            "fpr": 0.12280701754385964,
            "logloss": 3.262540032874455,
            "mae": 0.2726095476625771,
            "precision": 0.7671517671517671,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7758713707604912,
            "auditor_fn_violation": 0.009675362085193451,
            "auditor_fp_violation": 0.010967147561549323,
            "ave_precision_score": 0.7450717466825901,
            "fpr": 0.14709110867178923,
            "logloss": 3.521627563646297,
            "mae": 0.28720953583676523,
            "precision": 0.7219917012448133,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7320930150593166,
            "auditor_fn_violation": 0.010737127952263555,
            "auditor_fp_violation": 0.0030785098137267267,
            "ave_precision_score": 0.7152780648249691,
            "fpr": 0.14912280701754385,
            "logloss": 2.477753690721411,
            "mae": 0.26259446733055397,
            "precision": 0.7443609022556391,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7197160269390404,
            "auditor_fn_violation": 0.008601375556256272,
            "auditor_fp_violation": 0.005483573780774664,
            "ave_precision_score": 0.704950324089407,
            "fpr": 0.15148188803512624,
            "logloss": 2.4324173217397504,
            "mae": 0.26299131278453586,
            "precision": 0.7294117647058823,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8845599662869488,
            "auditor_fn_violation": 0.003637849715939548,
            "auditor_fp_violation": 0.00764418468975289,
            "ave_precision_score": 0.8845071473791741,
            "fpr": 0.08662280701754387,
            "logloss": 1.3015017213496913,
            "mae": 0.22449565424669854,
            "precision": 0.8236607142857143,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.851181425300074,
            "auditor_fn_violation": 0.006590910707384909,
            "auditor_fp_violation": 0.004942076995452412,
            "ave_precision_score": 0.8507205537387559,
            "fpr": 0.0867178924259056,
            "logloss": 1.333160136947952,
            "mae": 0.22495380862039563,
            "precision": 0.8123515439429929,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6739077551006747,
            "auditor_fn_violation": 0.012146264337013614,
            "auditor_fp_violation": 0.013160499229070307,
            "ave_precision_score": 0.6571081831191475,
            "fpr": 0.18859649122807018,
            "logloss": 2.8763588635640716,
            "mae": 0.3217357940177508,
            "precision": 0.6832412523020258,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6709599184084691,
            "auditor_fn_violation": 0.00933159156268597,
            "auditor_fp_violation": 0.008379724008154314,
            "ave_precision_score": 0.6510515838129777,
            "fpr": 0.18880351262349068,
            "logloss": 2.9202635068378164,
            "mae": 0.32204394777961143,
            "precision": 0.6748582230623819,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 4719,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8686392697707654,
            "auditor_fn_violation": 0.005904527101868724,
            "auditor_fp_violation": 0.015429011959828322,
            "ave_precision_score": 0.867352931389115,
            "fpr": 0.13596491228070176,
            "logloss": 1.572015600819772,
            "mae": 0.23846987781157292,
            "precision": 0.7651515151515151,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8470349806037042,
            "auditor_fn_violation": 0.008051342720244289,
            "auditor_fp_violation": 0.010535910302650152,
            "ave_precision_score": 0.8437990534194487,
            "fpr": 0.14489571899012074,
            "logloss": 1.6648318542640623,
            "mae": 0.25032294056859083,
            "precision": 0.7416829745596869,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8554125766107217,
            "auditor_fn_violation": 0.004825901311323114,
            "auditor_fp_violation": 0.01446795432762429,
            "ave_precision_score": 0.8545409106990713,
            "fpr": 0.13596491228070176,
            "logloss": 1.4767229328768265,
            "mae": 0.23972535484901292,
            "precision": 0.762906309751434,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8370720878788513,
            "auditor_fn_violation": 0.012698171852069621,
            "auditor_fp_violation": 0.010477105221891169,
            "ave_precision_score": 0.8359420706193625,
            "fpr": 0.14489571899012074,
            "logloss": 1.518885207486401,
            "mae": 0.25379938787715517,
            "precision": 0.7365269461077845,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8189665538118229,
            "auditor_fn_violation": 0.010239128881266307,
            "auditor_fp_violation": 0.01382724923948827,
            "ave_precision_score": 0.7912503986599139,
            "fpr": 0.09868421052631579,
            "logloss": 2.834798977227845,
            "mae": 0.2642070728204229,
            "precision": 0.8060344827586207,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7999793917854141,
            "auditor_fn_violation": 0.005893886337611103,
            "auditor_fp_violation": 0.005174847106790028,
            "ave_precision_score": 0.7703824931302301,
            "fpr": 0.1119648737650933,
            "logloss": 2.91521560097374,
            "mae": 0.27677465564007836,
            "precision": 0.7676537585421412,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7660375409044481,
            "auditor_fn_violation": 0.007708936291849794,
            "auditor_fp_violation": 0.012426032420719262,
            "ave_precision_score": 0.7677517446848771,
            "fpr": 0.1337719298245614,
            "logloss": 1.3933650191719769,
            "mae": 0.28871782392211837,
            "precision": 0.7468879668049793,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7425451585349181,
            "auditor_fn_violation": 0.01141792300962795,
            "auditor_fp_violation": 0.009244648737650941,
            "ave_precision_score": 0.7426851051952779,
            "fpr": 0.145993413830955,
            "logloss": 1.5111746579048573,
            "mae": 0.29412243009448386,
            "precision": 0.7194092827004219,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8296416304457106,
            "auditor_fn_violation": 0.009415085575445748,
            "auditor_fp_violation": 0.019124786431637293,
            "ave_precision_score": 0.830053565186072,
            "fpr": 0.11403508771929824,
            "logloss": 0.8788195629589457,
            "mae": 0.2749904783296104,
            "precision": 0.775377969762419,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8215601062131105,
            "auditor_fn_violation": 0.0080869051880899,
            "auditor_fp_violation": 0.007742668966598714,
            "ave_precision_score": 0.8228427795788174,
            "fpr": 0.1207464324917673,
            "logloss": 0.9254242727382809,
            "mae": 0.27838156940357955,
            "precision": 0.7577092511013216,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7311886376347844,
            "auditor_fn_violation": 0.018001661485689803,
            "auditor_fp_violation": 0.01664791432262367,
            "ave_precision_score": 0.731705003792698,
            "fpr": 0.11403508771929824,
            "logloss": 1.6607590429185373,
            "mae": 0.3401784150017616,
            "precision": 0.7319587628865979,
            "recall": 0.5784114052953157
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7230519418120138,
            "auditor_fn_violation": 0.017278617710583158,
            "auditor_fp_violation": 0.0038223302493335448,
            "ave_precision_score": 0.7239255065549638,
            "fpr": 0.1163556531284303,
            "logloss": 1.6049074180712986,
            "mae": 0.33078703103489265,
            "precision": 0.7253886010362695,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.808561153909448,
            "auditor_fn_violation": 0.008577643191481759,
            "auditor_fp_violation": 0.020554652664916448,
            "ave_precision_score": 0.8089023806796358,
            "fpr": 0.13157894736842105,
            "logloss": 1.0648835820312268,
            "mae": 0.28215832510327377,
            "precision": 0.7494780793319415,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7977508202090842,
            "auditor_fn_violation": 0.008999675196127013,
            "auditor_fp_violation": 0.013358554179081075,
            "ave_precision_score": 0.7963256837059687,
            "fpr": 0.1394072447859495,
            "logloss": 1.1237852180209382,
            "mae": 0.2887531169012815,
            "precision": 0.7286324786324786,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.856591656461584,
            "auditor_fn_violation": 0.006802265337478116,
            "auditor_fp_violation": 0.016236404550568823,
            "ave_precision_score": 0.8556215511236098,
            "fpr": 0.14035087719298245,
            "logloss": 1.4502158568287369,
            "mae": 0.24061533074350394,
            "precision": 0.7584905660377359,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8367713215363453,
            "auditor_fn_violation": 0.014834290753995444,
            "auditor_fp_violation": 0.01264309236318018,
            "ave_precision_score": 0.8357845201708646,
            "fpr": 0.14928649835345773,
            "logloss": 1.4936686419733343,
            "mae": 0.25889342000786686,
            "precision": 0.7333333333333333,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8005751616359691,
            "auditor_fn_violation": 0.01332761639332548,
            "auditor_fp_violation": 0.01933054131766471,
            "ave_precision_score": 0.8005985504684685,
            "fpr": 0.12390350877192982,
            "logloss": 1.5490797254401174,
            "mae": 0.27441170656585556,
            "precision": 0.7640918580375783,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7811346912980988,
            "auditor_fn_violation": 0.008663017167188645,
            "auditor_fp_violation": 0.011217069154774974,
            "ave_precision_score": 0.7823262291347008,
            "fpr": 0.13830954994511527,
            "logloss": 1.6272451847106832,
            "mae": 0.2816568463547499,
            "precision": 0.733615221987315,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6667273227015021,
            "auditor_fn_violation": 0.014955604387751464,
            "auditor_fp_violation": 0.019028420219194073,
            "ave_precision_score": 0.6674794223476284,
            "fpr": 0.12280701754385964,
            "logloss": 2.002808379336587,
            "mae": 0.4004397827029301,
            "precision": 0.68,
            "recall": 0.4847250509164969
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6648482282244834,
            "auditor_fn_violation": 0.01555739426685602,
            "auditor_fp_violation": 0.009712639172024466,
            "ave_precision_score": 0.6653770324526453,
            "fpr": 0.13611416026344675,
            "logloss": 2.023853382060481,
            "mae": 0.38698595774846917,
            "precision": 0.6565096952908587,
            "recall": 0.5118790496760259
        }
    }
]