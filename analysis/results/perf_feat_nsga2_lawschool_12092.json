[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8122793075582013,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.002011910510220506,
            "ave_precision_score": 0.6734571977969068,
            "fpr": 0.015350877192982455,
            "logloss": 0.5996919692910999,
            "mae": 0.41064198651776335,
            "precision": 0.9247311827956989,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8136923048844502,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6782022944075892,
            "fpr": 0.01646542261251372,
            "logloss": 0.6262608403109269,
            "mae": 0.4095840802698357,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.747394472407798,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.00044010542411073594,
            "ave_precision_score": 0.7099631026171902,
            "fpr": 0.01644736842105263,
            "logloss": 0.5978006419339554,
            "mae": 0.41948081036670165,
            "precision": 0.9197860962566845,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.761771700434436,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.7197567001372658,
            "fpr": 0.01646542261251372,
            "logloss": 0.5925212098959878,
            "mae": 0.41595238329419454,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.504081647833214,
            "auditor_fn_violation": 0.0006265664160401002,
            "auditor_fp_violation": 0.0019590978593272187,
            "ave_precision_score": 0.5062952814766156,
            "fpr": 0.4725877192982456,
            "logloss": 0.6939664156769156,
            "mae": 0.4999117429057757,
            "precision": 0.5242825607064018,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5399106342032746,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012168441653589938,
            "ave_precision_score": 0.5420244028163961,
            "fpr": 0.47310647639956094,
            "logloss": 0.6917917630909395,
            "mae": 0.49891849269458677,
            "precision": 0.5258525852585259,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8122793075582013,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.002011910510220506,
            "ave_precision_score": 0.6734571977969068,
            "fpr": 0.015350877192982455,
            "logloss": 0.5996919651348772,
            "mae": 0.41064198651788775,
            "precision": 0.9247311827956989,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8136923048844502,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6782022944075892,
            "fpr": 0.01646542261251372,
            "logloss": 0.626260827828249,
            "mae": 0.40958408026988663,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6533902757351747,
            "auditor_fn_violation": 0.021303258145363414,
            "auditor_fp_violation": 0.02849368260099791,
            "ave_precision_score": 0.6378668440637181,
            "fpr": 0.08552631578947369,
            "logloss": 2.2723758551633186,
            "mae": 0.3909382204325079,
            "precision": 0.7301038062283737,
            "recall": 0.4432773109243697
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.654649608495312,
            "auditor_fn_violation": 0.012203243481575733,
            "auditor_fp_violation": 0.032636774551732355,
            "ave_precision_score": 0.6405277586853457,
            "fpr": 0.08781558726673985,
            "logloss": 2.3188620164287315,
            "mae": 0.3820640628792888,
            "precision": 0.7278911564625851,
            "recall": 0.4476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 12092,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 12092,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.747394472407798,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.00044010542411073594,
            "ave_precision_score": 0.7099631026171902,
            "fpr": 0.01644736842105263,
            "logloss": 0.5977948352447927,
            "mae": 0.41947262502161037,
            "precision": 0.9197860962566845,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.761771700434436,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.7197567001372658,
            "fpr": 0.01646542261251372,
            "logloss": 0.5925143958892579,
            "mae": 0.4159431890978117,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006211773700305923,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4769736842105263,
            "logloss": 0.70459715591734,
            "mae": 0.5007660445152667,
            "precision": 0.5225027442371021,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6949265674809736,
            "mae": 0.49946488232303793,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7540954046758217,
            "auditor_fn_violation": 0.008196041574524547,
            "auditor_fp_violation": 0.0010185296957991358,
            "ave_precision_score": 0.7515306827029995,
            "fpr": 0.09539473684210527,
            "logloss": 0.5940238847552363,
            "mae": 0.40738162487385826,
            "precision": 0.7507163323782235,
            "recall": 0.5504201680672269
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7507206065457732,
            "auditor_fn_violation": 0.01685122330971069,
            "auditor_fp_violation": 0.010477535282143067,
            "ave_precision_score": 0.747686742894833,
            "fpr": 0.12733260153677278,
            "logloss": 0.5936041775992368,
            "mae": 0.4105874139214452,
            "precision": 0.6881720430107527,
            "recall": 0.5355648535564853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4780701754385965,
            "logloss": 0.6952532915744326,
            "mae": 0.5000263791727392,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6922046300340173,
            "mae": 0.4990907003274995,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6033289239184401,
            "auditor_fn_violation": 8.292790800530801e-05,
            "auditor_fp_violation": 0.0063173990020923936,
            "ave_precision_score": 0.6048915382265023,
            "fpr": 0.4517543859649123,
            "logloss": 0.6960899712108458,
            "mae": 0.49981827148350705,
            "precision": 0.5296803652968036,
            "recall": 0.9747899159663865
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6406400880589453,
            "auditor_fn_violation": 0.0014375668836030114,
            "auditor_fp_violation": 0.0017669591317816893,
            "ave_precision_score": 0.6422106424519942,
            "fpr": 0.446761800219539,
            "logloss": 0.691302840997174,
            "mae": 0.49828074596061667,
            "precision": 0.5353881278538812,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4780701754385965,
            "logloss": 0.6946503446139405,
            "mae": 0.5000244139840728,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.692200158928837,
            "mae": 0.49920196453381316,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6033289239184401,
            "auditor_fn_violation": 8.292790800530801e-05,
            "auditor_fp_violation": 0.0063173990020923936,
            "ave_precision_score": 0.6048915382265023,
            "fpr": 0.4517543859649123,
            "logloss": 0.6960900038420575,
            "mae": 0.4998182708299474,
            "precision": 0.5296803652968036,
            "recall": 0.9747899159663865
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6406441594870059,
            "auditor_fn_violation": 0.0014375668836030114,
            "auditor_fp_violation": 0.0017669591317816893,
            "ave_precision_score": 0.6422106424519943,
            "fpr": 0.446761800219539,
            "logloss": 0.6913028435398155,
            "mae": 0.4982807412825353,
            "precision": 0.5353881278538812,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7000199140959091,
            "auditor_fn_violation": 0.012883771929824567,
            "auditor_fp_violation": 0.031345565749235485,
            "ave_precision_score": 0.6926041233972977,
            "fpr": 0.20614035087719298,
            "logloss": 1.5686548151141626,
            "mae": 0.3191916466193702,
            "precision": 0.6753022452504318,
            "recall": 0.8214285714285714
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6788010642909053,
            "auditor_fn_violation": 0.0010701376481773214,
            "auditor_fp_violation": 0.027546309793313954,
            "ave_precision_score": 0.6730318508215101,
            "fpr": 0.19978046103183314,
            "logloss": 1.7854264472732482,
            "mae": 0.31202140441434606,
            "precision": 0.6773049645390071,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006211773700305923,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4769736842105263,
            "logloss": 0.6976407921488424,
            "mae": 0.49985759502701593,
            "precision": 0.5225027442371021,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6923988561122957,
            "mae": 0.49865749416183824,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4780701754385965,
            "logloss": 0.6950654203268596,
            "mae": 0.5000304248380033,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.692203024789322,
            "mae": 0.4991276458510976,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006161475937550379,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.47478070175438597,
            "logloss": 0.6995934720783321,
            "mae": 0.4996012502856422,
            "precision": 0.5236523652365237,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002023003424909311,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47200878155872666,
            "logloss": 0.6926680598373132,
            "mae": 0.49829193773044583,
            "precision": 0.526431718061674,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 12092,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8238005254977621,
            "auditor_fn_violation": 0.012167366946778712,
            "auditor_fp_violation": 0.01868561886367295,
            "ave_precision_score": 0.8242933885391045,
            "fpr": 0.20394736842105263,
            "logloss": 0.5717608172937575,
            "mae": 0.3422219593541517,
            "precision": 0.6793103448275862,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8555497224123634,
            "auditor_fn_violation": 0.008019143063165679,
            "auditor_fp_violation": 0.025987228206447763,
            "ave_precision_score": 0.8557302062593073,
            "fpr": 0.1800219538968167,
            "logloss": 0.5401539761891533,
            "mae": 0.3313520120554701,
            "precision": 0.7092198581560284,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6295572618353038,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6311685368852042,
            "fpr": 0.4780701754385965,
            "logloss": 0.6947928110412577,
            "mae": 0.5000970057751003,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6324500856339936,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.633898391711939,
            "fpr": 0.47530186608122943,
            "logloss": 0.6951328640346518,
            "mae": 0.5003028485829953,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6514067427758142,
            "auditor_fn_violation": 0.02434855521155831,
            "auditor_fp_violation": 0.027776939481731853,
            "ave_precision_score": 0.6356952310196143,
            "fpr": 0.08442982456140351,
            "logloss": 2.320720003956456,
            "mae": 0.39164902535217405,
            "precision": 0.7307692307692307,
            "recall": 0.43907563025210083
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6539933894108276,
            "auditor_fn_violation": 0.011596985243123331,
            "auditor_fp_violation": 0.03362546043608653,
            "ave_precision_score": 0.6393052503469121,
            "fpr": 0.0867178924259056,
            "logloss": 2.3678907882645475,
            "mae": 0.38366255304692015,
            "precision": 0.7303754266211604,
            "recall": 0.4476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6340943621015486,
            "auditor_fn_violation": 0.0003317116320212296,
            "auditor_fp_violation": 0.008339369064864013,
            "ave_precision_score": 0.6356214597716899,
            "fpr": 0.4473684210526316,
            "logloss": 0.6978923618413833,
            "mae": 0.499599781671637,
            "precision": 0.5321100917431193,
            "recall": 0.9747899159663865
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6725440914123637,
            "auditor_fn_violation": 0.0018692962352281968,
            "auditor_fp_violation": 0.0024184777786509766,
            "ave_precision_score": 0.6740804366846374,
            "fpr": 0.442371020856202,
            "logloss": 0.6914510902722736,
            "mae": 0.49788702260518836,
            "precision": 0.5383734249713631,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4780701754385965,
            "logloss": 0.6972019214530482,
            "mae": 0.4999035932123661,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6923488819655191,
            "mae": 0.49873772338768785,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6521638326549217,
            "auditor_fn_violation": 0.02434855521155831,
            "auditor_fp_violation": 0.027776939481731853,
            "ave_precision_score": 0.6364514166239441,
            "fpr": 0.08442982456140351,
            "logloss": 2.317735014873686,
            "mae": 0.391408697992991,
            "precision": 0.7307692307692307,
            "recall": 0.43907563025210083
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6547720163740778,
            "auditor_fn_violation": 0.011596985243123331,
            "auditor_fp_violation": 0.03362546043608653,
            "ave_precision_score": 0.6402489505148519,
            "fpr": 0.0867178924259056,
            "logloss": 2.3441700310181592,
            "mae": 0.3835189210447836,
            "precision": 0.7303754266211604,
            "recall": 0.4476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6322622664356914,
            "auditor_fn_violation": 0.03771837682441398,
            "auditor_fp_violation": 0.04242616288427492,
            "ave_precision_score": 0.6164021033914879,
            "fpr": 0.23464912280701755,
            "logloss": 2.1969679039741337,
            "mae": 0.3993616397779896,
            "precision": 0.6265270506108203,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6360191956257287,
            "auditor_fn_violation": 0.03256800885504457,
            "auditor_fp_violation": 0.044939576081913894,
            "ave_precision_score": 0.62024660200307,
            "fpr": 0.23380900109769484,
            "logloss": 2.3009616295502995,
            "mae": 0.3881008255856315,
            "precision": 0.6383701188455009,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6191968972542253,
            "auditor_fn_violation": 0.023261278195488726,
            "auditor_fp_violation": 0.030068002575245455,
            "ave_precision_score": 0.6018697913254725,
            "fpr": 0.35526315789473684,
            "logloss": 2.404792052353029,
            "mae": 0.4215354383584845,
            "precision": 0.5609756097560976,
            "recall": 0.8697478991596639
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.623315162529093,
            "auditor_fn_violation": 0.02018564362119883,
            "auditor_fp_violation": 0.045517577060459405,
            "ave_precision_score": 0.6053388917276638,
            "fpr": 0.3413830954994512,
            "logloss": 2.543825247927411,
            "mae": 0.4095546205808065,
            "precision": 0.5757162346521146,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6271601599434953,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6287796172958301,
            "fpr": 0.4780701754385965,
            "logloss": 0.6946350762899506,
            "mae": 0.5000663232385066,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6304874123885786,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6319369149800744,
            "fpr": 0.47530186608122943,
            "logloss": 0.6949601439290035,
            "mae": 0.5002621344232402,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4780701754385965,
            "logloss": 0.6968061450237044,
            "mae": 0.49993513517996724,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6923035818143473,
            "mae": 0.4988036271507732,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006211773700305923,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4769736842105263,
            "logloss": 0.6981160563650382,
            "mae": 0.4998021112722263,
            "precision": 0.5225027442371021,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.692457996339819,
            "mae": 0.49856975677900595,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.71494709719897,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.00044010542411073594,
            "ave_precision_score": 0.7101781261708882,
            "fpr": 0.01644736842105263,
            "logloss": 0.5982894812517942,
            "mae": 0.4195385907302823,
            "precision": 0.9197860962566845,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7546591254356134,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.7383554784226353,
            "fpr": 0.01646542261251372,
            "logloss": 0.5914719401920033,
            "mae": 0.4152772823097154,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6311523294549299,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6326510356803561,
            "fpr": 0.4780701754385965,
            "logloss": 0.6924772123023084,
            "mae": 0.4993595790706183,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6356465752762485,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6371256067608051,
            "fpr": 0.47530186608122943,
            "logloss": 0.6919956510995345,
            "mae": 0.49915053658637204,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.631672485791196,
            "auditor_fn_violation": 0.0016562546071060005,
            "auditor_fp_violation": 0.008339369064864013,
            "ave_precision_score": 0.633204131213504,
            "fpr": 0.4473684210526316,
            "logloss": 0.6979096086801589,
            "mae": 0.4996076267408697,
            "precision": 0.5315729047072331,
            "recall": 0.9726890756302521
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6701369832176922,
            "auditor_fn_violation": 0.0018692962352281968,
            "auditor_fp_violation": 0.0017542836717258769,
            "ave_precision_score": 0.6716772976674639,
            "fpr": 0.44017563117453345,
            "logloss": 0.6914453964270956,
            "mae": 0.49788238947268504,
            "precision": 0.539609644087256,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7318239683699277,
            "auditor_fn_violation": 0.010759896063688634,
            "auditor_fp_violation": 0.029182761950748433,
            "ave_precision_score": 0.6927753888674848,
            "fpr": 0.18640350877192982,
            "logloss": 3.0453872690334323,
            "mae": 0.31896249982433683,
            "precision": 0.6892138939670932,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7324420610449093,
            "auditor_fn_violation": 0.013101148675647255,
            "auditor_fp_violation": 0.04164142137538882,
            "ave_precision_score": 0.6899477434137633,
            "fpr": 0.17014270032930845,
            "logloss": 3.164487257811004,
            "mae": 0.3047765006967978,
            "precision": 0.7053231939163498,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6265609697694616,
            "auditor_fn_violation": 0.0026928534571723428,
            "auditor_fp_violation": 0.0035007242877836903,
            "ave_precision_score": 0.6281121453263931,
            "fpr": 0.4605263157894737,
            "logloss": 0.6968851933510899,
            "mae": 0.5002007563843539,
            "precision": 0.5275590551181102,
            "recall": 0.9852941176470589
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6634368075636292,
            "auditor_fn_violation": 0.0020300465257269357,
            "auditor_fp_violation": 0.0018810382722840911,
            "ave_precision_score": 0.6648452507694205,
            "fpr": 0.43468715697036225,
            "logloss": 0.6922712107316725,
            "mae": 0.4988883526016407,
            "precision": 0.5448275862068965,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8195268095387679,
            "auditor_fn_violation": 0.01132426654872476,
            "auditor_fp_violation": 0.016407130210848223,
            "ave_precision_score": 0.8204080486684893,
            "fpr": 0.20723684210526316,
            "logloss": 0.5737091774478957,
            "mae": 0.34177023561629505,
            "precision": 0.6763698630136986,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8546631224124102,
            "auditor_fn_violation": 0.007842317743617063,
            "auditor_fp_violation": 0.028147126599959958,
            "ave_precision_score": 0.8548446924141189,
            "fpr": 0.18441273326015367,
            "logloss": 0.5415439648557182,
            "mae": 0.33074263183788,
            "precision": 0.7047451669595782,
            "recall": 0.8389121338912134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6191985677355163,
            "auditor_fn_violation": 0.023261278195488726,
            "auditor_fp_violation": 0.030068002575245455,
            "ave_precision_score": 0.6018714615251382,
            "fpr": 0.35526315789473684,
            "logloss": 2.404789418387398,
            "mae": 0.42153354381158,
            "precision": 0.5609756097560976,
            "recall": 0.8697478991596639
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6233203327803607,
            "auditor_fn_violation": 0.02018564362119883,
            "auditor_fp_violation": 0.045517577060459405,
            "ave_precision_score": 0.6053440571435807,
            "fpr": 0.3413830954994512,
            "logloss": 2.5438234345110606,
            "mae": 0.4095522694962768,
            "precision": 0.5757162346521146,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7088583280488558,
            "auditor_fn_violation": 0.011121553884711784,
            "auditor_fp_violation": 0.02581281184612909,
            "ave_precision_score": 0.6962290164267558,
            "fpr": 0.16885964912280702,
            "logloss": 1.988414020614782,
            "mae": 0.2968583000295473,
            "precision": 0.7083333333333334,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.6935196284329543,
            "auditor_fn_violation": 0.014913034092840192,
            "auditor_fp_violation": 0.03953475991411109,
            "ave_precision_score": 0.6815498163610546,
            "fpr": 0.1602634467618002,
            "logloss": 2.0861247867951787,
            "mae": 0.2892217505748462,
            "precision": 0.7181467181467182,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7530340686577922,
            "auditor_fn_violation": 0.005583812472357367,
            "auditor_fp_violation": 0.018087075486882345,
            "ave_precision_score": 0.7528177664737394,
            "fpr": 0.13267543859649122,
            "logloss": 0.6346678098440434,
            "mae": 0.3979961229054249,
            "precision": 0.6840731070496083,
            "recall": 0.5504201680672269
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7785679657218898,
            "auditor_fn_violation": 0.010219125610277005,
            "auditor_fp_violation": 0.006976573214724832,
            "ave_precision_score": 0.7786480634294581,
            "fpr": 0.10647639956092206,
            "logloss": 0.6206063413949757,
            "mae": 0.39179481230277474,
            "precision": 0.7335164835164835,
            "recall": 0.5585774058577406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7596175931185394,
            "auditor_fn_violation": 0.0054294744213474865,
            "auditor_fp_violation": 0.017438234347336237,
            "ave_precision_score": 0.7600739937262068,
            "fpr": 0.40899122807017546,
            "logloss": 0.7314077647869159,
            "mae": 0.41878864301645335,
            "precision": 0.5451219512195122,
            "recall": 0.9390756302521008
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7809956872861483,
            "auditor_fn_violation": 0.005876571334089626,
            "auditor_fp_violation": 0.010289938473316905,
            "ave_precision_score": 0.7812724482665738,
            "fpr": 0.4083424807903403,
            "logloss": 0.7091067257734036,
            "mae": 0.4142624131248217,
            "precision": 0.5468940316686967,
            "recall": 0.9393305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8278029655756408,
            "auditor_fn_violation": 0.012351651186790505,
            "auditor_fp_violation": 0.02017946241751167,
            "ave_precision_score": 0.8282988215353952,
            "fpr": 0.20175438596491227,
            "logloss": 0.567609681521936,
            "mae": 0.33974502542926194,
            "precision": 0.6843910806174958,
            "recall": 0.8382352941176471
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8580680044332928,
            "auditor_fn_violation": 0.007288877457757122,
            "auditor_fp_violation": 0.02485404207745721,
            "ave_precision_score": 0.8582432787241301,
            "fpr": 0.18111964873765093,
            "logloss": 0.5344343445912816,
            "mae": 0.3300193810955474,
            "precision": 0.7069271758436945,
            "recall": 0.8326359832635983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7694548701750108,
            "auditor_fn_violation": 0.009896063688633352,
            "auditor_fp_violation": 0.024464831804281353,
            "ave_precision_score": 0.7677808237245433,
            "fpr": 0.18421052631578946,
            "logloss": 1.1886921468323581,
            "mae": 0.28564670227295363,
            "precision": 0.7021276595744681,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7297970176858702,
            "auditor_fn_violation": 0.005518327829549582,
            "auditor_fp_violation": 0.02627876378773168,
            "ave_precision_score": 0.7280910051226536,
            "fpr": 0.18551042810098792,
            "logloss": 1.322665912314048,
            "mae": 0.28361055304014554,
            "precision": 0.700354609929078,
            "recall": 0.8263598326359832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 12092,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8236588367498879,
            "auditor_fn_violation": 0.012167366946778712,
            "auditor_fp_violation": 0.01868561886367295,
            "ave_precision_score": 0.8241536211292313,
            "fpr": 0.20394736842105263,
            "logloss": 0.5711054826866134,
            "mae": 0.34250737516528096,
            "precision": 0.6793103448275862,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8558109191034587,
            "auditor_fn_violation": 0.003991200069811559,
            "auditor_fp_violation": 0.025860473605889535,
            "ave_precision_score": 0.855990624094023,
            "fpr": 0.17892425905598244,
            "logloss": 0.539302909228155,
            "mae": 0.3315802202502503,
            "precision": 0.7104795737122558,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 12092,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6443166299344825,
            "auditor_fn_violation": 0.00800254312251217,
            "auditor_fp_violation": 0.009448434733623048,
            "ave_precision_score": 0.6455900411029165,
            "fpr": 0.10635964912280702,
            "logloss": 0.9089145928099572,
            "mae": 0.42101372738385145,
            "precision": 0.6987577639751553,
            "recall": 0.4726890756302521
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6225742397363159,
            "auditor_fn_violation": 0.007178648687129418,
            "auditor_fp_violation": 0.00838101418890999,
            "ave_precision_score": 0.6238160270530633,
            "fpr": 0.11855104281009879,
            "logloss": 1.0008931549282234,
            "mae": 0.4237686481334997,
            "precision": 0.6940509915014165,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7400999789635155,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013077418316433317,
            "ave_precision_score": 0.7411764632604618,
            "fpr": 0.4758771929824561,
            "logloss": 0.7003738367007935,
            "mae": 0.49937633470746506,
            "precision": 0.5230769230769231,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7857431689509764,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7867065025618614,
            "fpr": 0.47530186608122943,
            "logloss": 0.6927200716153212,
            "mae": 0.4980268048533493,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6993692056824489,
            "auditor_fn_violation": 0.01311643078283945,
            "auditor_fp_violation": 0.03072187349106713,
            "ave_precision_score": 0.6926332915775194,
            "fpr": 0.20065789473684212,
            "logloss": 1.5596676373335079,
            "mae": 0.31889293873172897,
            "precision": 0.680628272251309,
            "recall": 0.819327731092437
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6790221068531901,
            "auditor_fn_violation": 0.002441107982859428,
            "auditor_fp_violation": 0.028058398379569197,
            "ave_precision_score": 0.6731654525366155,
            "fpr": 0.1986827661909989,
            "logloss": 1.7791667001555642,
            "mae": 0.31182876989247427,
            "precision": 0.6779359430604982,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4780701754385965,
            "logloss": 0.6993864241625395,
            "mae": 0.49897812293809757,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6924172542336308,
            "mae": 0.49763022335379103,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013077418316433317,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4758771929824561,
            "logloss": 0.6989096068534355,
            "mae": 0.49969877243826266,
            "precision": 0.5230769230769231,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011002299328454236,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47310647639956094,
            "logloss": 0.6925662273027083,
            "mae": 0.49842128766093374,
            "precision": 0.5258525852585259,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6322622664356914,
            "auditor_fn_violation": 0.03771837682441398,
            "auditor_fp_violation": 0.04242616288427492,
            "ave_precision_score": 0.6164021033914879,
            "fpr": 0.23464912280701755,
            "logloss": 2.1969692529970426,
            "mae": 0.39936204497440975,
            "precision": 0.6265270506108203,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6360204759821693,
            "auditor_fn_violation": 0.03256800885504457,
            "auditor_fp_violation": 0.044939576081913894,
            "ave_precision_score": 0.6202478822639369,
            "fpr": 0.23380900109769484,
            "logloss": 2.300962858777392,
            "mae": 0.38810120318036917,
            "precision": 0.6383701188455009,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7541941213892221,
            "auditor_fn_violation": 0.010061919504643963,
            "auditor_fp_violation": 0.021648157089972645,
            "ave_precision_score": 0.7477718986301344,
            "fpr": 0.33881578947368424,
            "logloss": 0.7175535986030868,
            "mae": 0.4077030956379307,
            "precision": 0.5841184387617766,
            "recall": 0.9117647058823529
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7770714879812474,
            "auditor_fn_violation": 0.003977421473483094,
            "auditor_fp_violation": 0.017570722729381486,
            "ave_precision_score": 0.7708381145941055,
            "fpr": 0.3424807903402854,
            "logloss": 0.698946749755052,
            "mae": 0.40437229251147594,
            "precision": 0.5873015873015873,
            "recall": 0.9288702928870293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8150391904678493,
            "auditor_fn_violation": 0.007196299572460574,
            "auditor_fp_violation": 0.002011910510220506,
            "ave_precision_score": 0.6773490798650792,
            "fpr": 0.015350877192982455,
            "logloss": 0.5960751256003275,
            "mae": 0.40937141721846754,
            "precision": 0.9263157894736842,
            "recall": 0.3697478991596639
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8171057040006884,
            "auditor_fn_violation": 0.01166587822476565,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6830376186415087,
            "fpr": 0.01646542261251372,
            "logloss": 0.6210255144724859,
            "mae": 0.4078125005054665,
            "precision": 0.9246231155778895,
            "recall": 0.38493723849372385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7055519930887643,
            "auditor_fn_violation": 0.00957586982161286,
            "auditor_fp_violation": 0.02710546434894576,
            "ave_precision_score": 0.692864659174636,
            "fpr": 0.1699561403508772,
            "logloss": 1.9992023853538046,
            "mae": 0.3014433876968039,
            "precision": 0.7064393939393939,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6891044418786367,
            "auditor_fn_violation": 0.014097800476739437,
            "auditor_fp_violation": 0.03953475991411109,
            "ave_precision_score": 0.6771380264301835,
            "fpr": 0.1602634467618002,
            "logloss": 2.105762235170109,
            "mae": 0.2941371321309092,
            "precision": 0.7142857142857143,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6126310667332362,
            "auditor_fn_violation": 0.034281475748194026,
            "auditor_fp_violation": 0.030399967809431837,
            "ave_precision_score": 0.5968199764275766,
            "fpr": 0.10197368421052631,
            "logloss": 2.339829281362004,
            "mae": 0.42265963851598015,
            "precision": 0.6970684039087948,
            "recall": 0.4495798319327731
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6188311763231966,
            "auditor_fn_violation": 0.025056377423310624,
            "auditor_fp_violation": 0.03258607271150907,
            "ave_precision_score": 0.6019519984411438,
            "fpr": 0.11525795828759605,
            "logloss": 2.474983252954412,
            "mae": 0.4183890707837171,
            "precision": 0.6893491124260355,
            "recall": 0.4874476987447699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7068774296369,
            "auditor_fn_violation": 0.010260025062656648,
            "auditor_fp_violation": 0.028516316594237888,
            "ave_precision_score": 0.6951756956661749,
            "fpr": 0.16557017543859648,
            "logloss": 1.8999024008685539,
            "mae": 0.3010832360466434,
            "precision": 0.7123809523809523,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6891502004589584,
            "auditor_fn_violation": 0.014417004625015504,
            "auditor_fp_violation": 0.041081166040921456,
            "ave_precision_score": 0.6776172111995693,
            "fpr": 0.15916575192096596,
            "logloss": 2.077454896791115,
            "mae": 0.2949292659635531,
            "precision": 0.7156862745098039,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7585389012182558,
            "auditor_fn_violation": 0.02359529338051011,
            "auditor_fp_violation": 0.01623108804120393,
            "ave_precision_score": 0.7576714048881703,
            "fpr": 0.06359649122807018,
            "logloss": 0.598123690884917,
            "mae": 0.40690072723909426,
            "precision": 0.7950530035335689,
            "recall": 0.4726890756302521
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7517300126502603,
            "auditor_fn_violation": 0.012359400906631636,
            "auditor_fp_violation": 0.02790629285889932,
            "ave_precision_score": 0.750409908397153,
            "fpr": 0.07903402854006586,
            "logloss": 0.5913875134118793,
            "mae": 0.4078120125864523,
            "precision": 0.76,
            "recall": 0.4769874476987448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7603146816983416,
            "auditor_fn_violation": 0.010891198584697039,
            "auditor_fp_violation": 0.019834922742636416,
            "ave_precision_score": 0.7607704635296819,
            "fpr": 0.3607456140350877,
            "logloss": 0.679634306667941,
            "mae": 0.41277325228203837,
            "precision": 0.568241469816273,
            "recall": 0.9096638655462185
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7818977432232532,
            "auditor_fn_violation": 0.009488860004868439,
            "auditor_fp_violation": 0.011070746812755576,
            "ave_precision_score": 0.7821742151896485,
            "fpr": 0.3611416026344676,
            "logloss": 0.6596987301632639,
            "mae": 0.40786282509272975,
            "precision": 0.5699346405228758,
            "recall": 0.9121338912133892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7105347514351589,
            "auditor_fn_violation": 0.010446612855668582,
            "auditor_fp_violation": 0.025209238693062942,
            "ave_precision_score": 0.6988779185082908,
            "fpr": 0.16666666666666666,
            "logloss": 1.8970913373487526,
            "mae": 0.29627696082376465,
            "precision": 0.7115749525616698,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6933888985755009,
            "auditor_fn_violation": 0.014913034092840192,
            "auditor_fp_violation": 0.04071864788332493,
            "ave_precision_score": 0.6818588653483341,
            "fpr": 0.15916575192096596,
            "logloss": 2.0669641464068556,
            "mae": 0.28966410982207547,
            "precision": 0.7195357833655706,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8190534970438592,
            "auditor_fn_violation": 0.012512899896800829,
            "auditor_fp_violation": 0.014973643972316108,
            "ave_precision_score": 0.8197578628487451,
            "fpr": 0.21271929824561403,
            "logloss": 0.5771146693354549,
            "mae": 0.34560064995751244,
            "precision": 0.6711864406779661,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8530526991603575,
            "auditor_fn_violation": 0.00712583073453697,
            "auditor_fp_violation": 0.027675599485883343,
            "ave_precision_score": 0.8532360253224884,
            "fpr": 0.18880351262349068,
            "logloss": 0.5447362694538854,
            "mae": 0.33502386765565795,
            "precision": 0.6987740805604203,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7739333665048183,
            "auditor_fn_violation": 0.008619895326551674,
            "auditor_fp_violation": 0.019676484789956542,
            "ave_precision_score": 0.6990207252593593,
            "fpr": 0.19736842105263158,
            "logloss": 5.943705068079275,
            "mae": 0.306543530751844,
            "precision": 0.6797153024911032,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7857559120133174,
            "auditor_fn_violation": 0.0077803140601389814,
            "auditor_fp_violation": 0.025660201337007527,
            "ave_precision_score": 0.7179046504895041,
            "fpr": 0.19758507135016465,
            "logloss": 5.644576703850824,
            "mae": 0.2968332508702162,
            "precision": 0.6814159292035398,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6534222880269376,
            "auditor_fn_violation": 0.02800890092879258,
            "auditor_fp_violation": 0.028440869950104617,
            "ave_precision_score": 0.637899924879514,
            "fpr": 0.10197368421052631,
            "logloss": 2.1171297977759127,
            "mae": 0.3875579027421756,
            "precision": 0.7248520710059172,
            "recall": 0.5147058823529411
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6545247285784492,
            "auditor_fn_violation": 0.02110192027704165,
            "auditor_fp_violation": 0.03512369981468477,
            "ave_precision_score": 0.6405598609355228,
            "fpr": 0.10208562019758508,
            "logloss": 2.156765798912223,
            "mae": 0.378029060837391,
            "precision": 0.7445054945054945,
            "recall": 0.5669456066945606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6211811095909445,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6227829623943135,
            "fpr": 0.4780701754385965,
            "logloss": 0.6944165371610317,
            "mae": 0.5000108411829722,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.625680170778582,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6271245381716795,
            "fpr": 0.47530186608122943,
            "logloss": 0.6947269924815243,
            "mae": 0.5001958852018404,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6677543163687163,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6693420100756562,
            "fpr": 0.4780701754385965,
            "logloss": 0.6927979236970662,
            "mae": 0.49945332992233726,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.666382924038421,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005349044143557158,
            "ave_precision_score": 0.6678232469349518,
            "fpr": 0.47420417124039516,
            "logloss": 0.6925595793602917,
            "mae": 0.4993715006878557,
            "precision": 0.5252747252747253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8283362583964653,
            "auditor_fn_violation": 0.012351651186790505,
            "auditor_fp_violation": 0.020350474810880415,
            "ave_precision_score": 0.8288209789514229,
            "fpr": 0.20175438596491227,
            "logloss": 0.5675061780625632,
            "mae": 0.33974673507097913,
            "precision": 0.6843910806174958,
            "recall": 0.8382352941176471
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8582752641632475,
            "auditor_fn_violation": 0.0057295996399193555,
            "auditor_fp_violation": 0.02485404207745721,
            "ave_precision_score": 0.8584498882759998,
            "fpr": 0.18111964873765093,
            "logloss": 0.5345828714527759,
            "mae": 0.32997385674951346,
            "precision": 0.7074468085106383,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 12092,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.755546389453445,
            "auditor_fn_violation": 0.01370153324487691,
            "auditor_fp_violation": 0.011105746016417192,
            "ave_precision_score": 0.7573237262375594,
            "fpr": 0.08333333333333333,
            "logloss": 0.5978556449446011,
            "mae": 0.40351985750532005,
            "precision": 0.7668711656441718,
            "recall": 0.5252100840336135
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7531370639162706,
            "auditor_fn_violation": 0.007036269858401961,
            "auditor_fp_violation": 0.011998590488841795,
            "ave_precision_score": 0.7523289799848069,
            "fpr": 0.10867178924259056,
            "logloss": 0.5923338238932921,
            "mae": 0.40587056100442104,
            "precision": 0.7122093023255814,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8283097549778875,
            "auditor_fn_violation": 0.012351651186790505,
            "auditor_fp_violation": 0.019324400450667963,
            "ave_precision_score": 0.8287999104741481,
            "fpr": 0.20065789473684212,
            "logloss": 0.565304297495997,
            "mae": 0.3381299762133909,
            "precision": 0.6855670103092784,
            "recall": 0.8382352941176471
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8590823229867719,
            "auditor_fn_violation": 0.005984503671995921,
            "auditor_fp_violation": 0.02574639446538713,
            "ave_precision_score": 0.8592560053720985,
            "fpr": 0.17672886937431395,
            "logloss": 0.5323343974078135,
            "mae": 0.32806596919126463,
            "precision": 0.7130124777183601,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6685580639784932,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6701397419142501,
            "fpr": 0.4780701754385965,
            "logloss": 0.6928083865527999,
            "mae": 0.4994562746009283,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.667215358694387,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005349044143557158,
            "ave_precision_score": 0.6686504188516784,
            "fpr": 0.47420417124039516,
            "logloss": 0.6925662873733635,
            "mae": 0.49937329955734355,
            "precision": 0.5252747252747253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8236934537600565,
            "auditor_fn_violation": 0.012238777089783284,
            "auditor_fp_violation": 0.017347698374376313,
            "ave_precision_score": 0.8243664118817793,
            "fpr": 0.20833333333333334,
            "logloss": 0.5688361637981089,
            "mae": 0.3400109874262278,
            "precision": 0.6740994854202401,
            "recall": 0.8256302521008403
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8541514968401444,
            "auditor_fn_violation": 0.009700131815238213,
            "auditor_fp_violation": 0.030743060819392445,
            "ave_precision_score": 0.8543317298550455,
            "fpr": 0.18880351262349068,
            "logloss": 0.5364807847089189,
            "mae": 0.3306641733188501,
            "precision": 0.696113074204947,
            "recall": 0.8242677824267782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7778473087553721,
            "auditor_fn_violation": 0.006901444788441695,
            "auditor_fp_violation": 0.017931152422340255,
            "ave_precision_score": 0.7312785056926153,
            "fpr": 0.16885964912280702,
            "logloss": 4.475244998563335,
            "mae": 0.291319267062714,
            "precision": 0.7105263157894737,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.780499228214278,
            "auditor_fn_violation": 0.0037707425285561395,
            "auditor_fp_violation": 0.025546122196505122,
            "ave_precision_score": 0.7359503115199139,
            "fpr": 0.16245883644346873,
            "logloss": 4.369308289295851,
            "mae": 0.28971504416576027,
            "precision": 0.7153846153846154,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8142435161082135,
            "auditor_fn_violation": 0.0034184726522187847,
            "auditor_fp_violation": 0.02018197730564945,
            "ave_precision_score": 0.8156495760844321,
            "fpr": 0.19846491228070176,
            "logloss": 0.5739505427891037,
            "mae": 0.3486629717732093,
            "precision": 0.6802120141342756,
            "recall": 0.8088235294117647
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8479239547969698,
            "auditor_fn_violation": 0.0065655011505127946,
            "auditor_fp_violation": 0.02401999680578407,
            "ave_precision_score": 0.8481158683755412,
            "fpr": 0.18111964873765093,
            "logloss": 0.5454723605155734,
            "mae": 0.3400977035938649,
            "precision": 0.7010869565217391,
            "recall": 0.8096234309623431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7096392553700968,
            "auditor_fn_violation": 0.01002506265664161,
            "auditor_fp_violation": 0.02434411717366812,
            "ave_precision_score": 0.6970209472061626,
            "fpr": 0.16228070175438597,
            "logloss": 1.9910713109410132,
            "mae": 0.29440602776432717,
            "precision": 0.7164750957854407,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.6962005413690359,
            "auditor_fn_violation": 0.01468798368614195,
            "auditor_fp_violation": 0.04035105954170607,
            "ave_precision_score": 0.6838802325991233,
            "fpr": 0.15916575192096596,
            "logloss": 2.0822330956795962,
            "mae": 0.2867584001932606,
            "precision": 0.720616570327553,
            "recall": 0.7824267782426778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7393628306140596,
            "auditor_fn_violation": 7.37136960047182e-05,
            "auditor_fp_violation": 0.005759093835506213,
            "ave_precision_score": 0.7405321291475115,
            "fpr": 0.45394736842105265,
            "logloss": 0.6966319080129053,
            "mae": 0.49427888506467926,
            "precision": 0.5300794551645857,
            "recall": 0.9810924369747899
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.786353782221317,
            "auditor_fn_violation": 7.807871252795903e-05,
            "auditor_fp_violation": 0.00729852990014273,
            "ave_precision_score": 0.7873287897155168,
            "fpr": 0.446761800219539,
            "logloss": 0.6840179448031501,
            "mae": 0.4903898053484612,
            "precision": 0.5369738339021616,
            "recall": 0.9874476987447699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6441240985414197,
            "auditor_fn_violation": 0.009172748046587062,
            "auditor_fp_violation": 0.009214550136809916,
            "ave_precision_score": 0.6456837078131554,
            "fpr": 0.10855263157894737,
            "logloss": 0.9111108532278106,
            "mae": 0.42108000958902075,
            "precision": 0.6953846153846154,
            "recall": 0.47478991596638653
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6233310586997212,
            "auditor_fn_violation": 0.006278447060336475,
            "auditor_fp_violation": 0.008631988298015281,
            "ave_precision_score": 0.6246638852953302,
            "fpr": 0.11964873765093303,
            "logloss": 1.0018309429728638,
            "mae": 0.42297469566522,
            "precision": 0.6938202247191011,
            "recall": 0.5167364016736402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7785459328869546,
            "auditor_fn_violation": 0.011179142709715461,
            "auditor_fp_violation": 0.016824601641718978,
            "ave_precision_score": 0.7320073485931587,
            "fpr": 0.16447368421052633,
            "logloss": 4.479230702740809,
            "mae": 0.28894427195739175,
            "precision": 0.7142857142857143,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7811802200628142,
            "auditor_fn_violation": 0.001001244666535006,
            "auditor_fp_violation": 0.025680482073096842,
            "ave_precision_score": 0.7367271420092654,
            "fpr": 0.15367727771679474,
            "logloss": 4.370821113395509,
            "mae": 0.28640652545934303,
            "precision": 0.7238658777120316,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006211773700305923,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4769736842105263,
            "logloss": 0.6980910020576392,
            "mae": 0.4998047258378121,
            "precision": 0.5225027442371021,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47530186608122943,
            "logloss": 0.6924543660574657,
            "mae": 0.4985738712660437,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 12092,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8236555541872429,
            "auditor_fn_violation": 0.010006634232640426,
            "auditor_fp_violation": 0.020051203122485116,
            "ave_precision_score": 0.824190136596355,
            "fpr": 0.20285087719298245,
            "logloss": 0.5703347357440547,
            "mae": 0.3404450756824461,
            "precision": 0.6799307958477508,
            "recall": 0.8256302521008403
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8563293323667126,
            "auditor_fn_violation": 0.00969324251707398,
            "auditor_fp_violation": 0.025317963915500317,
            "ave_precision_score": 0.856508810247119,
            "fpr": 0.1778265642151482,
            "logloss": 0.5387604278621331,
            "mae": 0.329217947850632,
            "precision": 0.7112299465240641,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7400779044774901,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013077418316433317,
            "ave_precision_score": 0.7413365842431552,
            "fpr": 0.4758771929824561,
            "logloss": 0.6989317636208997,
            "mae": 0.49969586452240483,
            "precision": 0.5230769230769231,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7856754551856366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011002299328454236,
            "ave_precision_score": 0.786625625006218,
            "fpr": 0.47310647639956094,
            "logloss": 0.6925695585107982,
            "mae": 0.49841729388802297,
            "precision": 0.5258525852585259,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7075513803115205,
            "auditor_fn_violation": 0.010260025062656648,
            "auditor_fp_violation": 0.028516316594237888,
            "ave_precision_score": 0.6958576834097691,
            "fpr": 0.16557017543859648,
            "logloss": 1.8944161144893235,
            "mae": 0.30088755398798606,
            "precision": 0.7123809523809523,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6898091102797026,
            "auditor_fn_violation": 0.014417004625015504,
            "auditor_fp_violation": 0.041081166040921456,
            "ave_precision_score": 0.6783798373466141,
            "fpr": 0.15916575192096596,
            "logloss": 2.052000145737291,
            "mae": 0.2946038779011141,
            "precision": 0.7156862745098039,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6251008028953624,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6267326341770344,
            "fpr": 0.4780701754385965,
            "logloss": 0.6945517103279875,
            "mae": 0.500047321055542,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6288635335175256,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6303240151764438,
            "fpr": 0.47530186608122943,
            "logloss": 0.6948701488088648,
            "mae": 0.5002384613688245,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7727688462244671,
            "auditor_fn_violation": 0.008861768391567154,
            "auditor_fp_violation": 0.018275692097215517,
            "ave_precision_score": 0.6978546607682987,
            "fpr": 0.19407894736842105,
            "logloss": 5.963861486784195,
            "mae": 0.3086996674658815,
            "precision": 0.6827956989247311,
            "recall": 0.8004201680672269
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7846853752897709,
            "auditor_fn_violation": 0.008023735928608501,
            "auditor_fp_violation": 0.025305288455444493,
            "ave_precision_score": 0.7168348201053455,
            "fpr": 0.1964873765093304,
            "logloss": 5.669552626056493,
            "mae": 0.2992944932908645,
            "precision": 0.6831858407079646,
            "recall": 0.8075313807531381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6491882497153196,
            "auditor_fn_violation": 0.02892110791685095,
            "auditor_fp_violation": 0.029524786737485924,
            "ave_precision_score": 0.6334805399471195,
            "fpr": 0.10087719298245613,
            "logloss": 2.1651653037209284,
            "mae": 0.3873391626688259,
            "precision": 0.7286135693215339,
            "recall": 0.5189075630252101
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6527411141986388,
            "auditor_fn_violation": 0.018279604462428063,
            "auditor_fp_violation": 0.03479667294524455,
            "ave_precision_score": 0.6380609647326472,
            "fpr": 0.10318331503841932,
            "logloss": 2.2284258432119337,
            "mae": 0.3771745295800491,
            "precision": 0.7431693989071039,
            "recall": 0.5690376569037657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.818586389360564,
            "auditor_fn_violation": 0.006917569659442727,
            "auditor_fp_violation": 0.020511427651698052,
            "ave_precision_score": 0.8190939304548259,
            "fpr": 0.22807017543859648,
            "logloss": 0.5875151540989957,
            "mae": 0.3489126008291925,
            "precision": 0.6550580431177446,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8407622494887914,
            "auditor_fn_violation": 0.010099711108763652,
            "auditor_fp_violation": 0.02749307286107951,
            "ave_precision_score": 0.8409641008903315,
            "fpr": 0.20636663007683864,
            "logloss": 0.5618267708605509,
            "mae": 0.3420789140625729,
            "precision": 0.6775300171526587,
            "recall": 0.8263598326359832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.700362434208647,
            "auditor_fn_violation": 0.013054234851835475,
            "auditor_fp_violation": 0.03226601480766136,
            "ave_precision_score": 0.692929799870954,
            "fpr": 0.20394736842105263,
            "logloss": 1.5652534899674662,
            "mae": 0.319139690147501,
            "precision": 0.6787564766839378,
            "recall": 0.8256302521008403
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6779660569071316,
            "auditor_fn_violation": 0.0016350600976443204,
            "auditor_fp_violation": 0.028058398379569197,
            "ave_precision_score": 0.6721432340787152,
            "fpr": 0.1986827661909989,
            "logloss": 1.785018587133838,
            "mae": 0.3122313117562366,
            "precision": 0.6773618538324421,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.8127184635193518,
            "auditor_fn_violation": 0.009041445525578657,
            "auditor_fp_violation": 0.001564260421696443,
            "ave_precision_score": 0.6723411635936607,
            "fpr": 0.01425438596491228,
            "logloss": 0.6000204343969172,
            "mae": 0.4118655107017657,
            "precision": 0.9285714285714286,
            "recall": 0.3550420168067227
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8136923048844502,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6782022944075892,
            "fpr": 0.01646542261251372,
            "logloss": 0.6260645753993735,
            "mae": 0.40973939708055745,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6552231037116478,
            "auditor_fn_violation": 0.0097578505086245,
            "auditor_fp_violation": 0.002467105263157898,
            "ave_precision_score": 0.656472824621855,
            "fpr": 0.11951754385964912,
            "logloss": 0.9015257104778316,
            "mae": 0.41359247687765543,
            "precision": 0.6840579710144927,
            "recall": 0.4957983193277311
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6318745389825087,
            "auditor_fn_violation": 0.002328582779510309,
            "auditor_fp_violation": 0.005668465736963926,
            "ave_precision_score": 0.6331215946004594,
            "fpr": 0.13062568605927552,
            "logloss": 1.0076788669361543,
            "mae": 0.41701736772237663,
            "precision": 0.6892950391644909,
            "recall": 0.5523012552301255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8102923760489227,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.002011910510220506,
            "ave_precision_score": 0.6734283000715284,
            "fpr": 0.015350877192982455,
            "logloss": 0.6014488013278392,
            "mae": 0.4131650909152518,
            "precision": 0.9247311827956989,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8140324197046794,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6813032766325811,
            "fpr": 0.01646542261251372,
            "logloss": 0.6266434297550251,
            "mae": 0.41141622918509413,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7537995253225978,
            "auditor_fn_violation": 0.009762457614624801,
            "auditor_fp_violation": 0.022385019314340917,
            "ave_precision_score": 0.7475558976699377,
            "fpr": 0.32785087719298245,
            "logloss": 0.7027812903384132,
            "mae": 0.4073464663426357,
            "precision": 0.5904109589041096,
            "recall": 0.9054621848739496
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7775876340156909,
            "auditor_fn_violation": 0.002797055054678066,
            "auditor_fp_violation": 0.022443169574839727,
            "ave_precision_score": 0.7712909485372033,
            "fpr": 0.3238199780461032,
            "logloss": 0.6855277720917694,
            "mae": 0.40370216051738406,
            "precision": 0.5953360768175583,
            "recall": 0.9079497907949791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6450602691351053,
            "auditor_fn_violation": 0.009287925696594429,
            "auditor_fp_violation": 0.009772855303396106,
            "ave_precision_score": 0.646584298980857,
            "fpr": 0.1118421052631579,
            "logloss": 0.9091794695504956,
            "mae": 0.4202727137211089,
            "precision": 0.6946107784431138,
            "recall": 0.48739495798319327
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6242120216425756,
            "auditor_fn_violation": 0.0061452539624946645,
            "auditor_fp_violation": 0.009040138111812767,
            "ave_precision_score": 0.6255434356766709,
            "fpr": 0.1251372118551043,
            "logloss": 1.0005823655660229,
            "mae": 0.4222077635330538,
            "precision": 0.6902173913043478,
            "recall": 0.5313807531380753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.8080611242113678,
            "auditor_fn_violation": 0.010448916408668747,
            "auditor_fp_violation": 0.00044010542411073594,
            "ave_precision_score": 0.6745394841523449,
            "fpr": 0.01644736842105263,
            "logloss": 0.597518436191824,
            "mae": 0.41937179860185114,
            "precision": 0.9197860962566845,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8147996525784168,
            "auditor_fn_violation": 0.011778403428114776,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6843868584005988,
            "fpr": 0.01646542261251372,
            "logloss": 0.5918463852472169,
            "mae": 0.4156601937686049,
            "precision": 0.9226804123711341,
            "recall": 0.37447698744769875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6580622436653616,
            "auditor_fn_violation": 0.023927005012531328,
            "auditor_fp_violation": 0.028051062288749398,
            "ave_precision_score": 0.642537642416936,
            "fpr": 0.10307017543859649,
            "logloss": 2.0855062348370152,
            "mae": 0.3836370498409697,
            "precision": 0.7306590257879656,
            "recall": 0.5357142857142857
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6590940499814861,
            "auditor_fn_violation": 0.013755632001249268,
            "auditor_fp_violation": 0.0346927341727868,
            "ave_precision_score": 0.6451269545241357,
            "fpr": 0.10647639956092206,
            "logloss": 2.1294258931004975,
            "mae": 0.3737696224268145,
            "precision": 0.7440633245382586,
            "recall": 0.5899581589958159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7544210169472814,
            "auditor_fn_violation": 0.003902218782249747,
            "auditor_fp_violation": 0.002806615161757608,
            "ave_precision_score": 0.7518412974993545,
            "fpr": 0.09429824561403509,
            "logloss": 0.5970577581826425,
            "mae": 0.40671354249168773,
            "precision": 0.7521613832853026,
            "recall": 0.5483193277310925
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7504052020310142,
            "auditor_fn_violation": 0.0160681397517097,
            "auditor_fp_violation": 0.010477535282143067,
            "ave_precision_score": 0.7473524609173697,
            "fpr": 0.12733260153677278,
            "logloss": 0.5951902809642958,
            "mae": 0.4100380208073378,
            "precision": 0.6873315363881402,
            "recall": 0.5334728033472803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.669909880201849,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6715107782703451,
            "fpr": 0.4780701754385965,
            "logloss": 0.692828191753306,
            "mae": 0.49946178685416254,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6687995473077086,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005349044143557158,
            "ave_precision_score": 0.6702204697573695,
            "fpr": 0.47420417124039516,
            "logloss": 0.6925790010117997,
            "mae": 0.4993766614621348,
            "precision": 0.5252747252747253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.659546281592543,
            "auditor_fn_violation": 0.0233764558454961,
            "auditor_fp_violation": 0.01353009818123289,
            "ave_precision_score": 0.6487680036826848,
            "fpr": 0.3059210526315789,
            "logloss": 1.7782662978327688,
            "mae": 0.4012277326526186,
            "precision": 0.5915080527086384,
            "recall": 0.8487394957983193
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6527280170484488,
            "auditor_fn_violation": 0.009514120764803955,
            "auditor_fp_violation": 0.013453733303250252,
            "ave_precision_score": 0.6428678994047392,
            "fpr": 0.31394072447859495,
            "logloss": 1.8568838447094635,
            "mae": 0.3969798399968795,
            "precision": 0.5873015873015873,
            "recall": 0.8514644351464435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8136634545387496,
            "auditor_fn_violation": 0.0020639834881321147,
            "auditor_fp_violation": 0.002011910510220506,
            "ave_precision_score": 0.6754028909263187,
            "fpr": 0.015350877192982455,
            "logloss": 0.5981432145206093,
            "mae": 0.4092635498539477,
            "precision": 0.925531914893617,
            "recall": 0.36554621848739494
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.8157462240816309,
            "auditor_fn_violation": 0.012327250848531908,
            "auditor_fp_violation": 0.0019317401125073849,
            "ave_precision_score": 0.6811031175967341,
            "fpr": 0.01646542261251372,
            "logloss": 0.62411910028327,
            "mae": 0.40764875481745605,
            "precision": 0.9238578680203046,
            "recall": 0.3807531380753138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5343387722396302,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5257794321959548,
            "fpr": 0.4780701754385965,
            "logloss": 0.6920407545493636,
            "mae": 0.49914471497922613,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5415250265120767,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5233720303169656,
            "fpr": 0.47530186608122943,
            "logloss": 0.6920531360126889,
            "mae": 0.49915188649090664,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6704131983796339,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6720075156058101,
            "fpr": 0.4780701754385965,
            "logloss": 0.6928357612375516,
            "mae": 0.49946388478080433,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.669379012327197,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005349044143557158,
            "ave_precision_score": 0.6708121561160222,
            "fpr": 0.47420417124039516,
            "logloss": 0.6925838555410962,
            "mae": 0.49937793664822333,
            "precision": 0.5252747252747253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7988031854500017,
            "auditor_fn_violation": 0.007297655904467053,
            "auditor_fp_violation": 0.017548889425398357,
            "ave_precision_score": 0.8002432840332825,
            "fpr": 0.21710526315789475,
            "logloss": 0.5978832649566521,
            "mae": 0.3469895451889259,
            "precision": 0.6655405405405406,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8305118119909611,
            "auditor_fn_violation": 0.007929582187030668,
            "auditor_fp_violation": 0.02852739040163463,
            "ave_precision_score": 0.8309189805628667,
            "fpr": 0.18551042810098792,
            "logloss": 0.5676179808792852,
            "mae": 0.34010540172825726,
            "precision": 0.6982142857142857,
            "recall": 0.8179916317991632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6436729902584404,
            "auditor_fn_violation": 0.009172748046587062,
            "auditor_fp_violation": 0.009214550136809916,
            "ave_precision_score": 0.6449183608353453,
            "fpr": 0.10855263157894737,
            "logloss": 0.9116375314574392,
            "mae": 0.4208100885745105,
            "precision": 0.6953846153846154,
            "recall": 0.47478991596638653
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6220776145739422,
            "auditor_fn_violation": 0.006728547873732949,
            "auditor_fp_violation": 0.008631988298015281,
            "ave_precision_score": 0.6233127131227819,
            "fpr": 0.11964873765093303,
            "logloss": 1.00421852045615,
            "mae": 0.4234928169403262,
            "precision": 0.6929577464788732,
            "recall": 0.5146443514644351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.8098119587073276,
            "auditor_fn_violation": 0.002662907268170452,
            "auditor_fp_violation": 0.002814159826170932,
            "ave_precision_score": 0.6716703177870108,
            "fpr": 0.01644736842105263,
            "logloss": 0.6015444344436275,
            "mae": 0.41188550031666066,
            "precision": 0.9197860962566845,
            "recall": 0.36134453781512604
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8134278917662721,
            "auditor_fn_violation": 0.010186975552177268,
            "auditor_fp_violation": 0.0021345474734005476,
            "ave_precision_score": 0.6793265429382276,
            "fpr": 0.01756311745334797,
            "logloss": 0.6249489289171962,
            "mae": 0.40925141976605894,
            "precision": 0.9191919191919192,
            "recall": 0.3807531380753138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6998919257393178,
            "auditor_fn_violation": 0.01113998230871296,
            "auditor_fp_violation": 0.025908377595364566,
            "ave_precision_score": 0.6869827552937171,
            "fpr": 0.17434210526315788,
            "logloss": 2.0350177324029963,
            "mae": 0.30389113076403734,
            "precision": 0.698292220113852,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.685141302566352,
            "auditor_fn_violation": 0.008280936393406484,
            "auditor_fp_violation": 0.04241969462281634,
            "ave_precision_score": 0.6728140562583762,
            "fpr": 0.16136114160263446,
            "logloss": 2.1312326716487164,
            "mae": 0.29717757816299606,
            "precision": 0.7123287671232876,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6573018817273457,
            "auditor_fn_violation": 0.0070811219224532,
            "auditor_fp_violation": 0.007828846772895545,
            "ave_precision_score": 0.6584568646772281,
            "fpr": 0.10197368421052631,
            "logloss": 0.8806429878906966,
            "mae": 0.4135963721366131,
            "precision": 0.7047619047619048,
            "recall": 0.46638655462184875
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6364578089724504,
            "auditor_fn_violation": 0.013369831304052289,
            "auditor_fp_violation": 0.00918210326443799,
            "ave_precision_score": 0.6375635396553891,
            "fpr": 0.11745334796926454,
            "logloss": 0.9827381941606356,
            "mae": 0.4182558720440708,
            "precision": 0.6925287356321839,
            "recall": 0.50418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6519852902263008,
            "auditor_fn_violation": 0.02913533834586467,
            "auditor_fp_violation": 0.02903941332689522,
            "ave_precision_score": 0.6364640755810983,
            "fpr": 0.09978070175438597,
            "logloss": 2.1313554635505962,
            "mae": 0.38832127789881316,
            "precision": 0.7283582089552239,
            "recall": 0.5126050420168067
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6537742470417008,
            "auditor_fn_violation": 0.019969778945386246,
            "auditor_fp_violation": 0.034806813313289206,
            "ave_precision_score": 0.639660370819013,
            "fpr": 0.10208562019758508,
            "logloss": 2.1894924770725765,
            "mae": 0.3781988627466732,
            "precision": 0.7409470752089137,
            "recall": 0.5564853556485355
        }
    }
]