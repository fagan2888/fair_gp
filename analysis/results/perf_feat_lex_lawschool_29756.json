[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 29756,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.692235018602492,
            "auditor_fn_violation": 0.0008303971225134,
            "auditor_fp_violation": 0.020221925782197434,
            "ave_precision_score": 0.6875786923176965,
            "fpr": 0.2138157894736842,
            "logloss": 2.003927491199735,
            "mae": 0.30465851000534666,
            "precision": 0.6689303904923599,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7193764147554387,
            "auditor_fn_violation": 0.012674224464758464,
            "auditor_fp_violation": 0.02568858271193712,
            "ave_precision_score": 0.7127305337665512,
            "fpr": 0.20856201975850713,
            "logloss": 1.8010963228763786,
            "mae": 0.30660969807702,
            "precision": 0.6746575342465754,
            "recall": 0.8277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6903920036754418,
            "auditor_fn_violation": 0.0011469573515378458,
            "auditor_fp_violation": 0.02285198884307543,
            "ave_precision_score": 0.6842255667270396,
            "fpr": 0.19407894736842105,
            "logloss": 1.9088681992845997,
            "mae": 0.3022035945319488,
            "precision": 0.6867256637168142,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.705681337894007,
            "auditor_fn_violation": 0.014712800597736353,
            "auditor_fp_violation": 0.021557717299418345,
            "ave_precision_score": 0.6991909180905977,
            "fpr": 0.1964873765093304,
            "logloss": 1.791996985017086,
            "mae": 0.30770921914771243,
            "precision": 0.6774774774774774,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8084917713416848,
            "auditor_fn_violation": 0.016016112456874402,
            "auditor_fp_violation": 0.013602554774031857,
            "ave_precision_score": 0.8093616419990672,
            "fpr": 0.11074561403508772,
            "logloss": 0.8813455084566653,
            "mae": 0.2793652106348167,
            "precision": 0.7740492170022372,
            "recall": 0.7238493723849372
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.832869427926723,
            "auditor_fn_violation": 0.017217205213589278,
            "auditor_fp_violation": 0.015693251069306184,
            "ave_precision_score": 0.8331004398600175,
            "fpr": 0.10867178924259056,
            "logloss": 0.8621371303711038,
            "mae": 0.2820676737501457,
            "precision": 0.7697674418604651,
            "recall": 0.6953781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6771431964179908,
            "auditor_fn_violation": 0.008290207736915512,
            "auditor_fp_violation": 0.016624221844934926,
            "ave_precision_score": 0.6683117993405283,
            "fpr": 0.18421052631578946,
            "logloss": 2.017390182772083,
            "mae": 0.31470348461120035,
            "precision": 0.6888888888888889,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.691729472995423,
            "auditor_fn_violation": 0.010345082050383276,
            "auditor_fp_violation": 0.027942011431166966,
            "ave_precision_score": 0.6823449986633298,
            "fpr": 0.18880351262349068,
            "logloss": 1.9301174906772478,
            "mae": 0.31794915672767204,
            "precision": 0.6779026217228464,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7648470724073817,
            "auditor_fn_violation": 0.003807898407105634,
            "auditor_fp_violation": 0.015800590185140278,
            "ave_precision_score": 0.7652862790247119,
            "fpr": 0.19078947368421054,
            "logloss": 1.1400392791960827,
            "mae": 0.28616819246481606,
            "precision": 0.6968641114982579,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7968612254044427,
            "auditor_fn_violation": 0.013366048944275849,
            "auditor_fp_violation": 0.03184576756627175,
            "ave_precision_score": 0.7972874686075355,
            "fpr": 0.18880351262349068,
            "logloss": 1.0541213585541298,
            "mae": 0.29611648554398556,
            "precision": 0.6928571428571428,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.804006757586998,
            "auditor_fn_violation": 0.016876330470527785,
            "auditor_fp_violation": 0.016636854232355083,
            "ave_precision_score": 0.8046641294661012,
            "fpr": 0.1524122807017544,
            "logloss": 0.986357134209355,
            "mae": 0.28126887328725775,
            "precision": 0.728515625,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8343902641041095,
            "auditor_fn_violation": 0.0173694065990831,
            "auditor_fp_violation": 0.02275887303329675,
            "ave_precision_score": 0.8346292148179799,
            "fpr": 0.14050493962678376,
            "logloss": 0.9039487567230411,
            "mae": 0.27079304310497315,
            "precision": 0.7398373983739838,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 29756,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7969156323697698,
            "auditor_fn_violation": 0.007572212434852825,
            "auditor_fp_violation": 0.017144676206645646,
            "ave_precision_score": 0.7974105433757531,
            "fpr": 0.12609649122807018,
            "logloss": 1.0909691451212609,
            "mae": 0.27417802767173194,
            "precision": 0.7573839662447257,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8282751614319093,
            "auditor_fn_violation": 0.011530407991956395,
            "auditor_fp_violation": 0.01617775086112268,
            "ave_precision_score": 0.8285116779566815,
            "fpr": 0.1119648737650933,
            "logloss": 1.0217636677869484,
            "mae": 0.2776807942012375,
            "precision": 0.7702702702702703,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.815043328625852,
            "auditor_fn_violation": 0.009941826323130001,
            "auditor_fp_violation": 0.020585738539898132,
            "ave_precision_score": 0.8155609057622337,
            "fpr": 0.15350877192982457,
            "logloss": 0.85144291710236,
            "mae": 0.2713654278438636,
            "precision": 0.7318007662835249,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8403777940276604,
            "auditor_fn_violation": 0.01569519135865104,
            "auditor_fp_violation": 0.02433854422953178,
            "ave_precision_score": 0.8405957080004434,
            "fpr": 0.14270032930845225,
            "logloss": 0.8200305020320712,
            "mae": 0.27652741230588046,
            "precision": 0.7373737373737373,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.8059675731275646,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002253617915757151,
            "ave_precision_score": 0.652646130251871,
            "fpr": 0.4692982456140351,
            "logloss": 11.21445708822286,
            "mae": 0.46835858375878675,
            "precision": 0.5275938189845475,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.8017735135270673,
            "auditor_fn_violation": 0.0004658284828750381,
            "auditor_fp_violation": 0.003242615794188535,
            "ave_precision_score": 0.6487656110153701,
            "fpr": 0.4665203073545554,
            "logloss": 11.130205471216856,
            "mae": 0.46733996354658486,
            "precision": 0.5277777777777778,
            "recall": 0.9978991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8012084574697298,
            "auditor_fn_violation": 0.009751431402774721,
            "auditor_fp_violation": 0.019509459131700227,
            "ave_precision_score": 0.801661941977723,
            "fpr": 0.14912280701754385,
            "logloss": 1.0016638493340344,
            "mae": 0.2779200187539796,
            "precision": 0.7338551859099804,
            "recall": 0.7845188284518828
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.830886449947956,
            "auditor_fn_violation": 0.017014270032930847,
            "auditor_fp_violation": 0.024116481824949226,
            "ave_precision_score": 0.8311299616790573,
            "fpr": 0.13391877058177826,
            "logloss": 0.9249508703727651,
            "mae": 0.2726292538333546,
            "precision": 0.7453027139874739,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8034506136401075,
            "auditor_fn_violation": 0.018305439330543936,
            "auditor_fp_violation": 0.006808856819468027,
            "ave_precision_score": 0.803972553728353,
            "fpr": 0.07785087719298246,
            "logloss": 1.0574107917766784,
            "mae": 0.30442106961047566,
            "precision": 0.7982954545454546,
            "recall": 0.5878661087866108
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8148147635788968,
            "auditor_fn_violation": 0.014106301137359448,
            "auditor_fp_violation": 0.007961441891567937,
            "ave_precision_score": 0.8151007531900858,
            "fpr": 0.07683863885839737,
            "logloss": 1.0979001756426225,
            "mae": 0.31235468710188713,
            "precision": 0.7947214076246334,
            "recall": 0.569327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8020227871630213,
            "auditor_fn_violation": 0.006764754459370186,
            "auditor_fp_violation": 0.019322499797881802,
            "ave_precision_score": 0.8024934001996663,
            "fpr": 0.15570175438596492,
            "logloss": 0.983913113438296,
            "mae": 0.27446617488114144,
            "precision": 0.7284894837476099,
            "recall": 0.797071129707113
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8313548764701292,
            "auditor_fn_violation": 0.016013430619229038,
            "auditor_fp_violation": 0.023091966640170585,
            "ave_precision_score": 0.8315904378585163,
            "fpr": 0.14928649835345773,
            "logloss": 0.9264567335575499,
            "mae": 0.27579986159990627,
            "precision": 0.728,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7931462799168312,
            "auditor_fn_violation": 0.002158573735594224,
            "auditor_fp_violation": 0.02204098957070095,
            "ave_precision_score": 0.7936670118813016,
            "fpr": 0.16447368421052633,
            "logloss": 1.0205753624932195,
            "mae": 0.2810220932036184,
            "precision": 0.7164461247637051,
            "recall": 0.7928870292887029
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8238981373352894,
            "auditor_fn_violation": 0.012552002140043723,
            "auditor_fp_violation": 0.02240559193509722,
            "ave_precision_score": 0.8241621700178301,
            "fpr": 0.1525795828759605,
            "logloss": 0.951772224054758,
            "mae": 0.279916653831564,
            "precision": 0.7231075697211156,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7984257859275543,
            "auditor_fn_violation": 0.005287473390589449,
            "auditor_fp_violation": 0.019024375454765954,
            "ave_precision_score": 0.798924673184795,
            "fpr": 0.1337719298245614,
            "logloss": 0.9643639105902613,
            "mae": 0.2797465663090416,
            "precision": 0.7484536082474227,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8284939183161842,
            "auditor_fn_violation": 0.014604414762611964,
            "auditor_fp_violation": 0.01574624323403611,
            "ave_precision_score": 0.8287396842799777,
            "fpr": 0.11745334796926454,
            "logloss": 0.909553419628353,
            "mae": 0.27977156087621946,
            "precision": 0.7653508771929824,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7785199878048084,
            "auditor_fn_violation": 0.015447221610511638,
            "auditor_fp_violation": 0.014603039857708795,
            "ave_precision_score": 0.7791694862974673,
            "fpr": 0.10307017543859649,
            "logloss": 0.9809065839506816,
            "mae": 0.2992252628179138,
            "precision": 0.7673267326732673,
            "recall": 0.6485355648535565
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8173343807008253,
            "auditor_fn_violation": 0.019306515141731775,
            "auditor_fp_violation": 0.018887921571596203,
            "ave_precision_score": 0.8176453967575753,
            "fpr": 0.09110867178924259,
            "logloss": 0.9340054976547035,
            "mae": 0.29378313111431964,
            "precision": 0.7860824742268041,
            "recall": 0.6407563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.783285666546705,
            "auditor_fn_violation": 0.01394700139470014,
            "auditor_fp_violation": 0.018481182795698922,
            "ave_precision_score": 0.778811391400023,
            "fpr": 0.17653508771929824,
            "logloss": 1.2145682225507568,
            "mae": 0.28293836763916996,
            "precision": 0.7140319715808171,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8103578753226596,
            "auditor_fn_violation": 0.01785829589794205,
            "auditor_fp_violation": 0.028577917407926118,
            "ave_precision_score": 0.8085415713769748,
            "fpr": 0.15697036223929747,
            "logloss": 1.057200588632481,
            "mae": 0.2833157492686122,
            "precision": 0.7281368821292775,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7929114613767254,
            "auditor_fn_violation": 0.004881450488145052,
            "auditor_fp_violation": 0.020136025547740324,
            "ave_precision_score": 0.7934683089920698,
            "fpr": 0.16337719298245615,
            "logloss": 0.9911057182958912,
            "mae": 0.28218447973065164,
            "precision": 0.718336483931947,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8242353149349682,
            "auditor_fn_violation": 0.012552002140043723,
            "auditor_fp_violation": 0.023354404027404522,
            "ave_precision_score": 0.8244980270121959,
            "fpr": 0.15367727771679474,
            "logloss": 0.9257230743569873,
            "mae": 0.2805229425536107,
            "precision": 0.7216699801192843,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7632255433419547,
            "auditor_fn_violation": 0.0014956323864053443,
            "auditor_fp_violation": 0.006078704826582584,
            "ave_precision_score": 0.5333502672218204,
            "fpr": 0.4550438596491228,
            "logloss": 15.714991111802723,
            "mae": 0.46162593024706683,
            "precision": 0.532130777903044,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7597779815081512,
            "auditor_fn_violation": 0.0036989548838196086,
            "auditor_fp_violation": 0.0026496082364964625,
            "ave_precision_score": 0.5275625896739107,
            "fpr": 0.4665203073545554,
            "logloss": 16.03710978915763,
            "mae": 0.4750765499310163,
            "precision": 0.5240761478163494,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.792549076988954,
            "auditor_fn_violation": 0.013543272406958821,
            "auditor_fp_violation": 0.014944114318053198,
            "ave_precision_score": 0.7930490551218152,
            "fpr": 0.09758771929824561,
            "logloss": 1.0807910250068933,
            "mae": 0.29955105333399396,
            "precision": 0.7780548628428927,
            "recall": 0.6527196652719666
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.823810888913719,
            "auditor_fn_violation": 0.014399173500355137,
            "auditor_fp_violation": 0.010219917483629208,
            "ave_precision_score": 0.8240713088697962,
            "fpr": 0.08781558726673985,
            "logloss": 1.0509852413939935,
            "mae": 0.2961039763288924,
            "precision": 0.7889182058047494,
            "recall": 0.6281512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7663372201246113,
            "auditor_fn_violation": 0.0035326286427365488,
            "auditor_fp_violation": 0.018630244967256855,
            "ave_precision_score": 0.7669678895994367,
            "fpr": 0.14364035087719298,
            "logloss": 1.0961518391267573,
            "mae": 0.29368360935053683,
            "precision": 0.7348178137651822,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8125031837872931,
            "auditor_fn_violation": 0.006752206920089667,
            "auditor_fp_violation": 0.009028855495413664,
            "ave_precision_score": 0.8127854924128407,
            "fpr": 0.13391877058177826,
            "logloss": 0.9868336268427215,
            "mae": 0.2897666367673185,
            "precision": 0.7404255319148936,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7915930153699287,
            "auditor_fn_violation": 2.752697643691384e-05,
            "auditor_fp_violation": 0.01792030479424368,
            "ave_precision_score": 0.7926681232248425,
            "fpr": 0.15679824561403508,
            "logloss": 0.9004525033532729,
            "mae": 0.28139813423362836,
            "precision": 0.7228682170542635,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8346559200563632,
            "auditor_fn_violation": 0.01403481260780932,
            "auditor_fp_violation": 0.019657569678388033,
            "ave_precision_score": 0.8348800963855528,
            "fpr": 0.14270032930845225,
            "logloss": 0.8402316849696687,
            "mae": 0.27777752023484487,
            "precision": 0.74,
            "recall": 0.7773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7783829609943969,
            "auditor_fn_violation": 0.016105575130294356,
            "auditor_fp_violation": 0.011490419597380548,
            "ave_precision_score": 0.7793426756248195,
            "fpr": 0.1118421052631579,
            "logloss": 0.8996288150848978,
            "mae": 0.3035827033398713,
            "precision": 0.7553956834532374,
            "recall": 0.6589958158995816
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.817316246210938,
            "auditor_fn_violation": 0.02189855085832357,
            "auditor_fp_violation": 0.010588339200323005,
            "ave_precision_score": 0.8175880318155989,
            "fpr": 0.09989023051591657,
            "logloss": 0.8581906323439262,
            "mae": 0.2984541523303748,
            "precision": 0.7775061124694377,
            "recall": 0.6680672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8017068026539433,
            "auditor_fn_violation": 0.02219133083755414,
            "auditor_fp_violation": 0.028243491794001138,
            "ave_precision_score": 0.802096441998355,
            "fpr": 0.14583333333333334,
            "logloss": 1.0285817521836618,
            "mae": 0.27897955819155607,
            "precision": 0.734,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8261468544095717,
            "auditor_fn_violation": 0.024977169792175926,
            "auditor_fp_violation": 0.03065975245088762,
            "ave_precision_score": 0.826417624872408,
            "fpr": 0.1394072447859495,
            "logloss": 0.9711002799294017,
            "mae": 0.2725983970233805,
            "precision": 0.7397540983606558,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7866116369367886,
            "auditor_fn_violation": 0.015438045951699333,
            "auditor_fp_violation": 0.020115813727868064,
            "ave_precision_score": 0.7774834327651279,
            "fpr": 0.14802631578947367,
            "logloss": 1.3095668114312997,
            "mae": 0.28214370492092744,
            "precision": 0.7337278106508875,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8102554897278416,
            "auditor_fn_violation": 0.017821398592367792,
            "auditor_fp_violation": 0.021787350013248042,
            "ave_precision_score": 0.8038996678089424,
            "fpr": 0.13391877058177826,
            "logloss": 1.122930996220999,
            "mae": 0.2746372380224279,
            "precision": 0.7489711934156379,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8021702079575358,
            "auditor_fn_violation": 0.001754844747852898,
            "auditor_fp_violation": 0.014997170345217886,
            "ave_precision_score": 0.8022454820285999,
            "fpr": 0.14802631578947367,
            "logloss": 1.1531676157526058,
            "mae": 0.27324385670655676,
            "precision": 0.736328125,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8283288328827351,
            "auditor_fn_violation": 0.014818880351262352,
            "auditor_fp_violation": 0.016079336840909956,
            "ave_precision_score": 0.828559265616451,
            "fpr": 0.1350164654226125,
            "logloss": 1.0627194037797068,
            "mae": 0.27861465046811984,
            "precision": 0.74375,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7897305920348101,
            "auditor_fn_violation": 0.018878918006312854,
            "auditor_fp_violation": 0.016995614035087727,
            "ave_precision_score": 0.790330213969963,
            "fpr": 0.10197368421052631,
            "logloss": 1.0939869283630332,
            "mae": 0.30807485088164815,
            "precision": 0.7657430730478589,
            "recall": 0.6359832635983264
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8170939032923984,
            "auditor_fn_violation": 0.013914896364692972,
            "auditor_fp_violation": 0.012352221254904934,
            "ave_precision_score": 0.8173753973156214,
            "fpr": 0.09110867178924259,
            "logloss": 1.0622882092436057,
            "mae": 0.3002369852430844,
            "precision": 0.7860824742268041,
            "recall": 0.6407563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8015708043548624,
            "auditor_fn_violation": 0.0027939881083461787,
            "auditor_fp_violation": 0.016219985447489697,
            "ave_precision_score": 0.8019385368025562,
            "fpr": 0.18530701754385964,
            "logloss": 1.114870476011355,
            "mae": 0.2795788306975863,
            "precision": 0.7014134275618374,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8300499751875934,
            "auditor_fn_violation": 0.014606720844210358,
            "auditor_fp_violation": 0.0261680356309222,
            "ave_precision_score": 0.8302836318225858,
            "fpr": 0.1756311745334797,
            "logloss": 1.042309554638565,
            "mae": 0.27947872053195905,
            "precision": 0.7047970479704797,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7681835566501116,
            "auditor_fn_violation": 0.006638589150701033,
            "auditor_fp_violation": 0.005583515239712186,
            "ave_precision_score": 0.7533920858198699,
            "fpr": 0.051535087719298246,
            "logloss": 3.4455636482841734,
            "mae": 0.35238457792400085,
            "precision": 0.8134920634920635,
            "recall": 0.42887029288702927
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.797579653097491,
            "auditor_fn_violation": 0.014076322076580371,
            "auditor_fp_violation": 0.008183504296150501,
            "ave_precision_score": 0.7891895576476515,
            "fpr": 0.05598243688254665,
            "logloss": 3.140491302656705,
            "mae": 0.34978923592900335,
            "precision": 0.7992125984251969,
            "recall": 0.4264705882352941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 29756,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8104935008514839,
            "auditor_fn_violation": 0.010301970931512885,
            "auditor_fp_violation": 0.021672123858032175,
            "ave_precision_score": 0.8110261974570505,
            "fpr": 0.17105263157894737,
            "logloss": 0.9440676454426282,
            "mae": 0.2797271097157986,
            "precision": 0.7137614678899082,
            "recall": 0.8138075313807531
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8359848239403587,
            "auditor_fn_violation": 0.01756311745334797,
            "auditor_fp_violation": 0.030321611971182362,
            "ave_precision_score": 0.8362167789348482,
            "fpr": 0.15697036223929747,
            "logloss": 0.8776983983230501,
            "mae": 0.2714167913208257,
            "precision": 0.7291666666666666,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6856555172995512,
            "auditor_fn_violation": 0.006349555898113488,
            "auditor_fp_violation": 0.017559018514026997,
            "ave_precision_score": 0.6731028155961405,
            "fpr": 0.24013157894736842,
            "logloss": 2.203715947516338,
            "mae": 0.31414376335112953,
            "precision": 0.652931854199683,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6919405758094939,
            "auditor_fn_violation": 0.014717412760933133,
            "auditor_fp_violation": 0.030445260355552207,
            "ave_precision_score": 0.6800500803924482,
            "fpr": 0.2414928649835346,
            "logloss": 2.193182010907209,
            "mae": 0.31954515671311046,
            "precision": 0.6507936507936508,
            "recall": 0.8613445378151261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5575092493135043,
            "auditor_fn_violation": 0.016816688688247823,
            "auditor_fp_violation": 0.01323621553884712,
            "ave_precision_score": 0.5579290705612525,
            "fpr": 0.0581140350877193,
            "logloss": 5.037317486884326,
            "mae": 0.5153629341557429,
            "precision": 0.5267857142857143,
            "recall": 0.12343096234309624
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5357596057726948,
            "auditor_fn_violation": 0.01658303277403169,
            "auditor_fp_violation": 0.010737221948849946,
            "ave_precision_score": 0.5339851316586259,
            "fpr": 0.07135016465422613,
            "logloss": 5.047503132635181,
            "mae": 0.5211337244559641,
            "precision": 0.5,
            "recall": 0.13655462184873948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7466253916579673,
            "auditor_fn_violation": 0.012079754826396543,
            "auditor_fp_violation": 0.01900669011237772,
            "ave_precision_score": 0.7483002993919424,
            "fpr": 0.12171052631578948,
            "logloss": 1.0108969216785546,
            "mae": 0.2962288105149755,
            "precision": 0.7549668874172185,
            "recall": 0.7154811715481172
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7837453077360262,
            "auditor_fn_violation": 0.011442776891217516,
            "auditor_fp_violation": 0.01714675044475567,
            "ave_precision_score": 0.7845623824107633,
            "fpr": 0.12184412733260154,
            "logloss": 0.9615862078743415,
            "mae": 0.3043854205819718,
            "precision": 0.7454128440366973,
            "recall": 0.6827731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8038942715666533,
            "auditor_fn_violation": 0.013428576671805036,
            "auditor_fp_violation": 0.021379052469884394,
            "ave_precision_score": 0.8042518956805017,
            "fpr": 0.16666666666666666,
            "logloss": 0.9931882109436265,
            "mae": 0.2822479669540485,
            "precision": 0.7132075471698113,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8334805207553818,
            "auditor_fn_violation": 0.017484710679002664,
            "auditor_fp_violation": 0.03309991546488007,
            "ave_precision_score": 0.8337233053327624,
            "fpr": 0.14709110867178923,
            "logloss": 0.9084472773721352,
            "mae": 0.2714057327160882,
            "precision": 0.7362204724409449,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7945625139495813,
            "auditor_fn_violation": 0.005785252881156867,
            "auditor_fp_violation": 0.02064637399951492,
            "ave_precision_score": 0.7950859292129224,
            "fpr": 0.16447368421052633,
            "logloss": 0.9713181122999294,
            "mae": 0.2826085141074051,
            "precision": 0.7180451127819549,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8245247327050609,
            "auditor_fn_violation": 0.012784916381481238,
            "auditor_fp_violation": 0.023503286775931467,
            "ave_precision_score": 0.8247862893538083,
            "fpr": 0.1525795828759605,
            "logloss": 0.9089629550562065,
            "mae": 0.2797442953237825,
            "precision": 0.7236580516898609,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6801705504394193,
            "auditor_fn_violation": 0.004211627394846954,
            "auditor_fp_violation": 0.01891826340043658,
            "ave_precision_score": 0.673834516027777,
            "fpr": 0.19517543859649122,
            "logloss": 1.9426619987424198,
            "mae": 0.3157739406658736,
            "precision": 0.6798561151079137,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6988985096708702,
            "auditor_fn_violation": 0.009032921620898637,
            "auditor_fp_violation": 0.02744237102085621,
            "ave_precision_score": 0.6918241597276282,
            "fpr": 0.19099890230515917,
            "logloss": 1.8000093468378506,
            "mae": 0.3143744857008823,
            "precision": 0.6830601092896175,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7970290396158565,
            "auditor_fn_violation": 0.004734639947148211,
            "auditor_fp_violation": 0.011697590751071232,
            "ave_precision_score": 0.7974253656682329,
            "fpr": 0.10307017543859649,
            "logloss": 1.114043595160165,
            "mae": 0.2796641961902023,
            "precision": 0.7772511848341233,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8277635789681204,
            "auditor_fn_violation": 0.018547814295861054,
            "auditor_fp_violation": 0.010724604766771395,
            "ave_precision_score": 0.8280008352794648,
            "fpr": 0.09330406147091108,
            "logloss": 1.0635302100493533,
            "mae": 0.28355098572349924,
            "precision": 0.7875,
            "recall": 0.6617647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7412866062522327,
            "auditor_fn_violation": 0.007540097629009765,
            "auditor_fp_violation": 0.02066405934190315,
            "ave_precision_score": 0.7429185032602066,
            "fpr": 0.16776315789473684,
            "logloss": 1.1883453115396823,
            "mae": 0.29121384216236074,
            "precision": 0.7134831460674157,
            "recall": 0.797071129707113
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7693423897918955,
            "auditor_fn_violation": 0.016207141473493898,
            "auditor_fp_violation": 0.024255270827813317,
            "ave_precision_score": 0.7691084137299272,
            "fpr": 0.16355653128430298,
            "logloss": 1.1346508786888845,
            "mae": 0.29872300271635505,
            "precision": 0.7095516569200779,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7920652194362175,
            "auditor_fn_violation": 0.0007799309990457329,
            "auditor_fp_violation": 0.01736700622524052,
            "ave_precision_score": 0.7934046733731606,
            "fpr": 0.15350877192982457,
            "logloss": 0.8946521214316681,
            "mae": 0.28162638612629454,
            "precision": 0.726027397260274,
            "recall": 0.7761506276150628
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8344706130414304,
            "auditor_fn_violation": 0.017069615991292236,
            "auditor_fp_violation": 0.018963624664067535,
            "ave_precision_score": 0.834694804538987,
            "fpr": 0.13721185510428102,
            "logloss": 0.8379840796805944,
            "mae": 0.27764598400522444,
            "precision": 0.7433264887063655,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7928570791841676,
            "auditor_fn_violation": 0.0014956323864053443,
            "auditor_fp_violation": 0.006078704826582584,
            "ave_precision_score": 0.6029770094993524,
            "fpr": 0.4550438596491228,
            "logloss": 13.17354144415549,
            "mae": 0.4616114566919355,
            "precision": 0.532130777903044,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.788878389971302,
            "auditor_fn_violation": 0.0036989548838196086,
            "auditor_fp_violation": 0.0036463656207022734,
            "ave_precision_score": 0.5982684205563763,
            "fpr": 0.4654226125137212,
            "logloss": 13.3658959217573,
            "mae": 0.47469178850922894,
            "precision": 0.5246636771300448,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7630907034815851,
            "auditor_fn_violation": 0.0014956323864053443,
            "auditor_fp_violation": 0.006078704826582584,
            "ave_precision_score": 0.5320958021035137,
            "fpr": 0.4550438596491228,
            "logloss": 15.789540079603832,
            "mae": 0.461622833741189,
            "precision": 0.532130777903044,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7583191897047392,
            "auditor_fn_violation": 0.0036989548838196086,
            "auditor_fp_violation": 0.0026496082364964625,
            "ave_precision_score": 0.5246498922610636,
            "fpr": 0.4665203073545554,
            "logloss": 16.180293658869495,
            "mae": 0.4753014521489407,
            "precision": 0.5240761478163494,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7971651898000596,
            "auditor_fn_violation": 0.005998586948542904,
            "auditor_fp_violation": 0.014663675317325573,
            "ave_precision_score": 0.7976624373235479,
            "fpr": 0.1337719298245614,
            "logloss": 1.0074670887671962,
            "mae": 0.27745591756785637,
            "precision": 0.7505112474437627,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8305581657332,
            "auditor_fn_violation": 0.01437380660277284,
            "auditor_fp_violation": 0.019940194556947656,
            "ave_precision_score": 0.8307979673139194,
            "fpr": 0.12184412733260154,
            "logloss": 0.9360735809370562,
            "mae": 0.27647949233698993,
            "precision": 0.7607758620689655,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7082390866735555,
            "auditor_fn_violation": 0.000848748440138002,
            "auditor_fp_violation": 0.016725280944296223,
            "ave_precision_score": 0.7045874315640672,
            "fpr": 0.19517543859649122,
            "logloss": 1.6807865810762739,
            "mae": 0.2950302855502183,
            "precision": 0.6888111888111889,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7378723585328102,
            "auditor_fn_violation": 0.01259120552721638,
            "auditor_fp_violation": 0.030513393138776393,
            "ave_precision_score": 0.7346415031962323,
            "fpr": 0.19319429198682767,
            "logloss": 1.4799266183534385,
            "mae": 0.30083446974432954,
            "precision": 0.6879432624113475,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7944395627180825,
            "auditor_fn_violation": 0.008267268589884759,
            "auditor_fp_violation": 0.018104737650578063,
            "ave_precision_score": 0.7949445961224388,
            "fpr": 0.1425438596491228,
            "logloss": 0.9860195389302016,
            "mae": 0.28241540357646,
            "precision": 0.7373737373737373,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.82331087360902,
            "auditor_fn_violation": 0.01603879751681134,
            "auditor_fp_violation": 0.0199502883026105,
            "ave_precision_score": 0.8235843868379276,
            "fpr": 0.13062568605927552,
            "logloss": 0.9287554865934761,
            "mae": 0.2806027013613953,
            "precision": 0.7478813559322034,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 29756,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7288067853186848,
            "auditor_fn_violation": 0.0026104749321001247,
            "auditor_fp_violation": 0.02431987226129842,
            "ave_precision_score": 0.7161786587887251,
            "fpr": 0.32456140350877194,
            "logloss": 2.584497624883501,
            "mae": 0.3516878148047255,
            "precision": 0.6026845637583893,
            "recall": 0.9393305439330544
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7329585702994824,
            "auditor_fn_violation": 0.0056545120792554126,
            "auditor_fp_violation": 0.023611794541807035,
            "ave_precision_score": 0.7223530998484071,
            "fpr": 0.3150384193194292,
            "logloss": 2.425821652949448,
            "mae": 0.3572226394289047,
            "precision": 0.6073871409028728,
            "recall": 0.9327731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8119998652317773,
            "auditor_fn_violation": 0.023200653306907435,
            "auditor_fp_violation": 0.017819245694882368,
            "ave_precision_score": 0.8126208468609379,
            "fpr": 0.13267543859649122,
            "logloss": 0.9030966186963341,
            "mae": 0.2807163243663291,
            "precision": 0.7447257383966245,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8392890548221478,
            "auditor_fn_violation": 0.02753461428479186,
            "auditor_fp_violation": 0.019607100950073817,
            "ave_precision_score": 0.8395114872363738,
            "fpr": 0.11964873765093303,
            "logloss": 0.850308862643861,
            "mae": 0.2732513845980464,
            "precision": 0.7593818984547461,
            "recall": 0.7226890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7787207183006586,
            "auditor_fn_violation": 0.018149453130734784,
            "auditor_fp_violation": 0.014011844126445154,
            "ave_precision_score": 0.7793343499808845,
            "fpr": 0.10416666666666667,
            "logloss": 1.0278083730781997,
            "mae": 0.30316258951565156,
            "precision": 0.7648514851485149,
            "recall": 0.6464435146443515
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8199515409314064,
            "auditor_fn_violation": 0.020339639697811076,
            "auditor_fp_violation": 0.01839585147053258,
            "ave_precision_score": 0.8202310993089393,
            "fpr": 0.09001097694840834,
            "logloss": 0.9472134008654777,
            "mae": 0.29491326687606645,
            "precision": 0.7897435897435897,
            "recall": 0.6470588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8154991654052264,
            "auditor_fn_violation": 0.020425016516185862,
            "auditor_fp_violation": 0.02176813000242542,
            "ave_precision_score": 0.8147997377108082,
            "fpr": 0.14912280701754385,
            "logloss": 1.1774589516465508,
            "mae": 0.27430586853819977,
            "precision": 0.7322834645669292,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.834391820517203,
            "auditor_fn_violation": 0.02122748111319171,
            "auditor_fp_violation": 0.0266096370036716,
            "ave_precision_score": 0.8346057514905083,
            "fpr": 0.132821075740944,
            "logloss": 1.0628246948848552,
            "mae": 0.2688416302512844,
            "precision": 0.7489626556016598,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8067918621591036,
            "auditor_fn_violation": 0.01079057476326801,
            "auditor_fp_violation": 0.018913210445468516,
            "ave_precision_score": 0.8074896690111941,
            "fpr": 0.16228070175438597,
            "logloss": 0.99294504371692,
            "mae": 0.28007554694075,
            "precision": 0.7164750957854407,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8320698658456469,
            "auditor_fn_violation": 0.015284708834137387,
            "auditor_fp_violation": 0.02842651122298346,
            "ave_precision_score": 0.8323121978388559,
            "fpr": 0.13172338090010977,
            "logloss": 0.9303073819381107,
            "mae": 0.27037595001574943,
            "precision": 0.75,
            "recall": 0.7563025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7922570905281121,
            "auditor_fn_violation": 0.009739961829259344,
            "auditor_fp_violation": 0.0174731182795699,
            "ave_precision_score": 0.7928398465720335,
            "fpr": 0.14364035087719298,
            "logloss": 1.016841104763117,
            "mae": 0.2814031316810753,
            "precision": 0.738,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8230754879253682,
            "auditor_fn_violation": 0.013559759798540724,
            "auditor_fp_violation": 0.019089796484853077,
            "ave_precision_score": 0.8233500602004185,
            "fpr": 0.12952799121844127,
            "logloss": 0.9548215052569752,
            "mae": 0.27926828219330657,
            "precision": 0.7494692144373672,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7787187914692627,
            "auditor_fn_violation": 0.018149453130734784,
            "auditor_fp_violation": 0.014011844126445154,
            "ave_precision_score": 0.7793324237449277,
            "fpr": 0.10416666666666667,
            "logloss": 1.0278091864026637,
            "mae": 0.30316353303506793,
            "precision": 0.7648514851485149,
            "recall": 0.6464435146443515
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8199515409314064,
            "auditor_fn_violation": 0.020339639697811076,
            "auditor_fp_violation": 0.01839585147053258,
            "ave_precision_score": 0.8202310993089393,
            "fpr": 0.09001097694840834,
            "logloss": 0.9472154050051137,
            "mae": 0.29491423604854083,
            "precision": 0.7897435897435897,
            "recall": 0.6470588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8020158290751471,
            "auditor_fn_violation": 0.025650554209792262,
            "auditor_fp_violation": 0.027942840973401252,
            "ave_precision_score": 0.8027508871598876,
            "fpr": 0.14473684210526316,
            "logloss": 0.9958909051439709,
            "mae": 0.27830514099694703,
            "precision": 0.7333333333333333,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8300661199109612,
            "auditor_fn_violation": 0.02525159350238449,
            "auditor_fp_violation": 0.03468211009753082,
            "ave_precision_score": 0.8303293310125962,
            "fpr": 0.13611416026344675,
            "logloss": 0.9321503940114577,
            "mae": 0.27324745548197005,
            "precision": 0.7448559670781894,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7037295195019959,
            "auditor_fn_violation": 0.0010207920428686832,
            "auditor_fp_violation": 0.021063242784380314,
            "ave_precision_score": 0.7015847674490502,
            "fpr": 0.19188596491228072,
            "logloss": 1.5177079048970883,
            "mae": 0.2946084604779667,
            "precision": 0.6929824561403509,
            "recall": 0.8263598326359832
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7346608456261595,
            "auditor_fn_violation": 0.010727891595716224,
            "auditor_fp_violation": 0.02851987837036477,
            "ave_precision_score": 0.7316171538438653,
            "fpr": 0.19538968166849616,
            "logloss": 1.443072358257334,
            "mae": 0.307732170525383,
            "precision": 0.6810035842293907,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6796649835290142,
            "auditor_fn_violation": 0.002183806797328053,
            "auditor_fp_violation": 0.02140179076724069,
            "ave_precision_score": 0.6732886295516078,
            "fpr": 0.1787280701754386,
            "logloss": 2.0297031361991986,
            "mae": 0.31719023084999914,
            "precision": 0.6947565543071161,
            "recall": 0.7761506276150628
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.704122924529162,
            "auditor_fn_violation": 0.008198120082280989,
            "auditor_fp_violation": 0.02673076195162572,
            "ave_precision_score": 0.6983171473348275,
            "fpr": 0.18331503841931943,
            "logloss": 1.7935592915235592,
            "mae": 0.3136871991822817,
            "precision": 0.6860902255639098,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7282648504039806,
            "auditor_fn_violation": 0.0009129780518241263,
            "auditor_fp_violation": 0.02040888511601585,
            "ave_precision_score": 0.7289857930072534,
            "fpr": 0.19956140350877194,
            "logloss": 1.3665712466552482,
            "mae": 0.2945870567020552,
            "precision": 0.6834782608695652,
            "recall": 0.8221757322175732
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7677703361643657,
            "auditor_fn_violation": 0.012734182586316634,
            "auditor_fp_violation": 0.034909219374944796,
            "ave_precision_score": 0.76714306976667,
            "fpr": 0.18880351262349068,
            "logloss": 1.3032145979316803,
            "mae": 0.2991627830629809,
            "precision": 0.693950177935943,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8129578202591713,
            "auditor_fn_violation": 0.012318321955516406,
            "auditor_fp_violation": 0.010580887703128788,
            "ave_precision_score": 0.8133848124623391,
            "fpr": 0.044956140350877194,
            "logloss": 0.7055590823810098,
            "mae": 0.36086062693459353,
            "precision": 0.8600682593856656,
            "recall": 0.5271966527196653
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8175254442910271,
            "auditor_fn_violation": 0.006586169045005498,
            "auditor_fp_violation": 0.007552645192222769,
            "ave_precision_score": 0.8177958787100433,
            "fpr": 0.04720087815587267,
            "logloss": 0.7145324007362597,
            "mae": 0.3683312058131684,
            "precision": 0.843065693430657,
            "recall": 0.4852941176470588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.8496093509637447,
            "auditor_fn_violation": 0.002275563385451075,
            "auditor_fp_violation": 0.007882609750181922,
            "ave_precision_score": 0.7633522687220219,
            "fpr": 0.4506578947368421,
            "logloss": 7.873477072592724,
            "mae": 0.4570628306593155,
            "precision": 0.5340136054421769,
            "recall": 0.9853556485355649
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.8382493094235413,
            "auditor_fn_violation": 0.0036989548838196086,
            "auditor_fp_violation": 0.003277943904008487,
            "ave_precision_score": 0.7507799112996973,
            "fpr": 0.4621295279912184,
            "logloss": 7.9458451413953854,
            "mae": 0.46926411941503116,
            "precision": 0.5264341957255343,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7553472728518422,
            "auditor_fn_violation": 0.00424374220069001,
            "auditor_fp_violation": 0.023698358800226377,
            "ave_precision_score": 0.7481838399753475,
            "fpr": 0.22916666666666666,
            "logloss": 1.5351204815699482,
            "mae": 0.310516797042893,
            "precision": 0.669826224328594,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.782678081401609,
            "auditor_fn_violation": 0.009162062190408549,
            "auditor_fp_violation": 0.02711180085039808,
            "ave_precision_score": 0.7807842541951904,
            "fpr": 0.2217343578485181,
            "logloss": 1.3299473142571854,
            "mae": 0.3234832425107303,
            "precision": 0.6661157024793388,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7932626841006625,
            "auditor_fn_violation": 0.009772076635102402,
            "auditor_fp_violation": 0.024395666585819393,
            "ave_precision_score": 0.793749644389363,
            "fpr": 0.22807017543859648,
            "logloss": 1.2540669492219805,
            "mae": 0.2985933185654592,
            "precision": 0.6677316293929713,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8285262653808217,
            "auditor_fn_violation": 0.013578208451327844,
            "auditor_fp_violation": 0.03339263408910254,
            "ave_precision_score": 0.8287398381128182,
            "fpr": 0.22063666300768386,
            "logloss": 1.1145538536293076,
            "mae": 0.286727545207437,
            "precision": 0.6737012987012987,
            "recall": 0.8718487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.800135599982872,
            "auditor_fn_violation": 0.009345408500330334,
            "auditor_fp_violation": 0.019170911148839852,
            "ave_precision_score": 0.8005934238288337,
            "fpr": 0.125,
            "logloss": 0.9938389958169093,
            "mae": 0.2793677585963173,
            "precision": 0.7579617834394905,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8282465880178531,
            "auditor_fn_violation": 0.013089319152468897,
            "auditor_fp_violation": 0.022403068498681507,
            "ave_precision_score": 0.8284919754561607,
            "fpr": 0.11306256860592755,
            "logloss": 0.9551186817833924,
            "mae": 0.2773624821277671,
            "precision": 0.7695749440715883,
            "recall": 0.7226890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8051121104464789,
            "auditor_fn_violation": 0.013112016442780592,
            "auditor_fp_violation": 0.0210859810817366,
            "ave_precision_score": 0.8056534790982667,
            "fpr": 0.14035087719298245,
            "logloss": 0.9528207568302991,
            "mae": 0.2816375297108387,
            "precision": 0.7387755102040816,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8294404934629971,
            "auditor_fn_violation": 0.01572286433783173,
            "auditor_fp_violation": 0.02701086339376964,
            "ave_precision_score": 0.8296896808991961,
            "fpr": 0.12184412733260154,
            "logloss": 0.9043606132613704,
            "mae": 0.27453534164516696,
            "precision": 0.7592190889370932,
            "recall": 0.7352941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8006288672869626,
            "auditor_fn_violation": 0.012199038390956473,
            "auditor_fp_violation": 0.025378466327108096,
            "ave_precision_score": 0.8011253452058991,
            "fpr": 0.20723684210526316,
            "logloss": 1.1206104265836034,
            "mae": 0.28930232228492414,
            "precision": 0.6828859060402684,
            "recall": 0.8514644351464435
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8318476893853206,
            "auditor_fn_violation": 0.015572969033936299,
            "auditor_fp_violation": 0.0305159165751921,
            "ave_precision_score": 0.8320994243963113,
            "fpr": 0.19099890230515917,
            "logloss": 1.008240982275762,
            "mae": 0.2782522699468743,
            "precision": 0.6984402079722704,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.749655095475152,
            "auditor_fn_violation": 0.004500660647434489,
            "auditor_fp_violation": 0.010616258387905248,
            "ave_precision_score": 0.7504271872670891,
            "fpr": 0.07894736842105263,
            "logloss": 1.5263249716708884,
            "mae": 0.35526818599554916,
            "precision": 0.7567567567567568,
            "recall": 0.4686192468619247
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7930009674833447,
            "auditor_fn_violation": 0.01920965971459935,
            "auditor_fp_violation": 0.005458192967182713,
            "ave_precision_score": 0.7933593502850296,
            "fpr": 0.06476399560922064,
            "logloss": 1.3840577206142854,
            "mae": 0.33346915048292,
            "precision": 0.8013468013468014,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6505193399319786,
            "auditor_fn_violation": 0.01031573441973134,
            "auditor_fp_violation": 0.028753840245775725,
            "ave_precision_score": 0.6167972003837101,
            "fpr": 0.20285087719298245,
            "logloss": 3.5722016219843677,
            "mae": 0.31643475219882755,
            "precision": 0.6765734265734266,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6407601646381694,
            "auditor_fn_violation": 0.01412244370854818,
            "auditor_fp_violation": 0.027460035075766186,
            "ave_precision_score": 0.6030479060604343,
            "fpr": 0.20965971459934138,
            "logloss": 3.9360711101833656,
            "mae": 0.3325596850513921,
            "precision": 0.6607460035523979,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6872705095908062,
            "auditor_fn_violation": 0.00443184320634222,
            "auditor_fp_violation": 0.016295779772010684,
            "ave_precision_score": 0.6789207909167939,
            "fpr": 0.21710526315789475,
            "logloss": 1.9097397511863934,
            "mae": 0.3071542488376882,
            "precision": 0.6688963210702341,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6935305767056809,
            "auditor_fn_violation": 0.01149812284957891,
            "auditor_fp_violation": 0.02793191768550413,
            "ave_precision_score": 0.6846161663208952,
            "fpr": 0.2217343578485181,
            "logloss": 1.869820734556984,
            "mae": 0.31441046863335365,
            "precision": 0.662771285475793,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8005952161739895,
            "auditor_fn_violation": 0.023457571753651915,
            "auditor_fp_violation": 0.02292525669011238,
            "ave_precision_score": 0.8010623318576926,
            "fpr": 0.14035087719298245,
            "logloss": 1.0395978968817887,
            "mae": 0.27946580065160764,
            "precision": 0.7393075356415478,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8278999852766222,
            "auditor_fn_violation": 0.02424614192548589,
            "auditor_fp_violation": 0.031113971005715585,
            "ave_precision_score": 0.8281672734450976,
            "fpr": 0.13062568605927552,
            "logloss": 0.9707139954047848,
            "mae": 0.27243146918896566,
            "precision": 0.750524109014675,
            "recall": 0.7521008403361344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.810263635512976,
            "auditor_fn_violation": 0.017176833296630698,
            "auditor_fp_violation": 0.01238479262672811,
            "ave_precision_score": 0.8095073358151138,
            "fpr": 0.09320175438596491,
            "logloss": 1.9752526851559467,
            "mae": 0.28194844923424217,
            "precision": 0.7875,
            "recall": 0.6589958158995816
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8199384146105542,
            "auditor_fn_violation": 0.022894778108828607,
            "auditor_fp_violation": 0.01747984405162951,
            "ave_precision_score": 0.8198742875013623,
            "fpr": 0.09110867178924259,
            "logloss": 1.9150815889903572,
            "mae": 0.2895598837137193,
            "precision": 0.7849740932642487,
            "recall": 0.6365546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8011902173171902,
            "auditor_fn_violation": 0.023457571753651915,
            "auditor_fp_violation": 0.02292525669011238,
            "ave_precision_score": 0.801596430997539,
            "fpr": 0.14035087719298245,
            "logloss": 1.0377328849734901,
            "mae": 0.27952357120048654,
            "precision": 0.7393075356415478,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8276048049493954,
            "auditor_fn_violation": 0.02424614192548589,
            "auditor_fp_violation": 0.03160604110677921,
            "ave_precision_score": 0.8278745461763168,
            "fpr": 0.13172338090010977,
            "logloss": 0.9718495451989657,
            "mae": 0.2721935173564497,
            "precision": 0.7489539748953975,
            "recall": 0.7521008403361344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 29756,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7979212930774777,
            "auditor_fn_violation": 0.012164629670410335,
            "auditor_fp_violation": 0.01479505214649528,
            "ave_precision_score": 0.7993719659274366,
            "fpr": 0.14912280701754385,
            "logloss": 0.9166293380305277,
            "mae": 0.2816060014539822,
            "precision": 0.7306930693069307,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8400583267763617,
            "auditor_fn_violation": 0.021354315601103235,
            "auditor_fp_violation": 0.023498239903100047,
            "ave_precision_score": 0.8402743689527541,
            "fpr": 0.12843029637760703,
            "logloss": 0.8487623285574558,
            "mae": 0.27133721053720944,
            "precision": 0.755741127348643,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.778074882252888,
            "auditor_fn_violation": 0.007602033325992811,
            "auditor_fp_violation": 0.018079472875737735,
            "ave_precision_score": 0.7787108806322611,
            "fpr": 0.14692982456140352,
            "logloss": 0.8917268525010824,
            "mae": 0.2849185980796707,
            "precision": 0.7309236947791165,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8393948527978424,
            "auditor_fn_violation": 0.011170659262607355,
            "auditor_fp_violation": 0.02249643564606281,
            "ave_precision_score": 0.839603034870059,
            "fpr": 0.13062568605927552,
            "logloss": 0.8117917521360588,
            "mae": 0.2791740388941833,
            "precision": 0.7468085106382979,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7932407567956115,
            "auditor_fn_violation": 0.005698084122439994,
            "auditor_fp_violation": 0.011151871614520172,
            "ave_precision_score": 0.793726939898518,
            "fpr": 0.11732456140350878,
            "logloss": 1.0089059580245965,
            "mae": 0.2866208178755787,
            "precision": 0.7637969094922737,
            "recall": 0.7238493723849372
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8251582232853322,
            "auditor_fn_violation": 0.013292254333127324,
            "auditor_fp_violation": 0.01513304818501836,
            "ave_precision_score": 0.8254160539622123,
            "fpr": 0.10537870472008781,
            "logloss": 0.9478624238780623,
            "mae": 0.28199657260741906,
            "precision": 0.7762237762237763,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.806740027667149,
            "auditor_fn_violation": 0.011403049988989212,
            "auditor_fp_violation": 0.01978231869997575,
            "ave_precision_score": 0.8074489613776095,
            "fpr": 0.14144736842105263,
            "logloss": 0.865420127580755,
            "mae": 0.2815553689793841,
            "precision": 0.7399193548387096,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8317299586553782,
            "auditor_fn_violation": 0.01549686834118939,
            "auditor_fp_violation": 0.026723191642378588,
            "ave_precision_score": 0.8319683277062676,
            "fpr": 0.13172338090010977,
            "logloss": 0.840974309508095,
            "mae": 0.2806923264479499,
            "precision": 0.7446808510638298,
            "recall": 0.7352941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6825856568399202,
            "auditor_fn_violation": 0.005243889011231007,
            "auditor_fp_violation": 0.021037978009539986,
            "ave_precision_score": 0.6600172509583824,
            "fpr": 0.3125,
            "logloss": 2.9578181789177025,
            "mae": 0.34506183668507445,
            "precision": 0.6132971506105834,
            "recall": 0.9456066945606695
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.6744121918228723,
            "auditor_fn_violation": 0.00765157874346226,
            "auditor_fp_violation": 0.018130890646882922,
            "ave_precision_score": 0.6505296797325202,
            "fpr": 0.31284302963776073,
            "logloss": 3.1349525900264585,
            "mae": 0.3580844777922604,
            "precision": 0.6074380165289256,
            "recall": 0.9264705882352942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6875406239763651,
            "auditor_fn_violation": 0.00020874623797989363,
            "auditor_fp_violation": 0.02909744118360418,
            "ave_precision_score": 0.6779113197627253,
            "fpr": 0.23574561403508773,
            "logloss": 2.0807502895662564,
            "mae": 0.31153073820373667,
            "precision": 0.655448717948718,
            "recall": 0.8556485355648535
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6994507421162917,
            "auditor_fn_violation": 0.014454519458716527,
            "auditor_fp_violation": 0.027724995899415822,
            "ave_precision_score": 0.6894814208430573,
            "fpr": 0.23161361141602635,
            "logloss": 1.9665089524990274,
            "mae": 0.31522904041522587,
            "precision": 0.6574675324675324,
            "recall": 0.8508403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8085988484254549,
            "auditor_fn_violation": 0.008487484401380018,
            "auditor_fp_violation": 0.02179339477726575,
            "ave_precision_score": 0.8093931832428192,
            "fpr": 0.1337719298245614,
            "logloss": 0.8891116744875724,
            "mae": 0.27299838812931143,
            "precision": 0.7530364372469636,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8344289177462518,
            "auditor_fn_violation": 0.0135643719617375,
            "auditor_fp_violation": 0.02451266134221583,
            "ave_precision_score": 0.8346524071110334,
            "fpr": 0.12403951701427003,
            "logloss": 0.8638927535818107,
            "mae": 0.27403764278923554,
            "precision": 0.7580299785867237,
            "recall": 0.7436974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7069576549194415,
            "auditor_fn_violation": 0.011515451809439923,
            "auditor_fp_violation": 0.018973845905085305,
            "ave_precision_score": 0.7039242222436976,
            "fpr": 0.15789473684210525,
            "logloss": 1.759490384881767,
            "mae": 0.2990705022784278,
            "precision": 0.7165354330708661,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7626123817197917,
            "auditor_fn_violation": 0.012591205527216378,
            "auditor_fp_violation": 0.02785873802944851,
            "ave_precision_score": 0.7589952806205558,
            "fpr": 0.14050493962678376,
            "logloss": 1.427430508685287,
            "mae": 0.288377905132595,
            "precision": 0.729957805907173,
            "recall": 0.726890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6773415168611355,
            "auditor_fn_violation": 0.004908977464581961,
            "auditor_fp_violation": 0.015451936292343767,
            "ave_precision_score": 0.6685074767491863,
            "fpr": 0.18201754385964913,
            "logloss": 2.0231316431248034,
            "mae": 0.3147576676550785,
            "precision": 0.6891385767790262,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.692159760506877,
            "auditor_fn_violation": 0.006613842024186183,
            "auditor_fp_violation": 0.0284113706044892,
            "ave_precision_score": 0.6827806512855065,
            "fpr": 0.1877058177826564,
            "logloss": 1.9328797145380574,
            "mae": 0.3181642395668366,
            "precision": 0.6779661016949152,
            "recall": 0.7563025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8012342972107478,
            "auditor_fn_violation": 0.016029875945092857,
            "auditor_fp_violation": 0.02151042929905409,
            "ave_precision_score": 0.8021004381808505,
            "fpr": 0.1600877192982456,
            "logloss": 0.9279753801571562,
            "mae": 0.282642846512523,
            "precision": 0.7213740458015268,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8255813416519197,
            "auditor_fn_violation": 0.014858083738435002,
            "auditor_fp_violation": 0.024825567457763983,
            "ave_precision_score": 0.8258400327824795,
            "fpr": 0.1437980241492865,
            "logloss": 0.8837112967379847,
            "mae": 0.28100135269186377,
            "precision": 0.7348178137651822,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6961690199267323,
            "auditor_fn_violation": 0.0017984291272113346,
            "auditor_fp_violation": 0.0290292262915353,
            "ave_precision_score": 0.6917618180334362,
            "fpr": 0.23903508771929824,
            "logloss": 1.9565483846822556,
            "mae": 0.30992846814219044,
            "precision": 0.6572327044025157,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7274821031442043,
            "auditor_fn_violation": 0.01368428820485384,
            "auditor_fp_violation": 0.029223917130348106,
            "ave_precision_score": 0.7215176211859489,
            "fpr": 0.23161361141602635,
            "logloss": 1.764206086762033,
            "mae": 0.30720258988545956,
            "precision": 0.6640127388535032,
            "recall": 0.8760504201680672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8021737806395695,
            "auditor_fn_violation": 0.011593444909344495,
            "auditor_fp_violation": 0.006685059422750425,
            "ave_precision_score": 0.802626160249928,
            "fpr": 0.11513157894736842,
            "logloss": 0.9742623534217408,
            "mae": 0.279539343994736,
            "precision": 0.7682119205298014,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8276078902537541,
            "auditor_fn_violation": 0.013170032008412585,
            "auditor_fp_violation": 0.020563483351628244,
            "ave_precision_score": 0.8278571281899544,
            "fpr": 0.10757409440175632,
            "logloss": 0.9239527009908538,
            "mae": 0.2774213845346116,
            "precision": 0.7757437070938215,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8078275629081748,
            "auditor_fn_violation": 0.023659436247522578,
            "auditor_fp_violation": 0.01631093863691487,
            "ave_precision_score": 0.8081141569399927,
            "fpr": 0.14473684210526316,
            "logloss": 0.980379734780913,
            "mae": 0.2842330608746658,
            "precision": 0.7306122448979592,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8351030559302132,
            "auditor_fn_violation": 0.02375955870822534,
            "auditor_fp_violation": 0.02320299784246187,
            "ave_precision_score": 0.8353429477531384,
            "fpr": 0.13172338090010977,
            "logloss": 0.9124038397358474,
            "mae": 0.2730779217615087,
            "precision": 0.7463002114164905,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.687407415312085,
            "auditor_fn_violation": 0.004131340380239299,
            "auditor_fp_violation": 0.019378082302530523,
            "ave_precision_score": 0.6836572003319143,
            "fpr": 0.11842105263157894,
            "logloss": 1.8609284109164037,
            "mae": 0.3232265074004539,
            "precision": 0.7372262773722628,
            "recall": 0.6338912133891214
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7022216234273664,
            "auditor_fn_violation": 0.01638470975657003,
            "auditor_fp_violation": 0.023944888148680878,
            "ave_precision_score": 0.6975351233999126,
            "fpr": 0.12403951701427003,
            "logloss": 1.7748125330829005,
            "mae": 0.32411965532870696,
            "precision": 0.7270531400966184,
            "recall": 0.6323529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7794450280443558,
            "auditor_fn_violation": 0.0018488952506789992,
            "auditor_fp_violation": 0.01994401325895384,
            "ave_precision_score": 0.7795783540284227,
            "fpr": 0.19078947368421054,
            "logloss": 1.139239144767529,
            "mae": 0.2857942572485446,
            "precision": 0.6952714535901926,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.815087349396844,
            "auditor_fn_violation": 0.01256353254803568,
            "auditor_fp_violation": 0.0241114349521178,
            "ave_precision_score": 0.8153558120359066,
            "fpr": 0.18111964873765093,
            "logloss": 1.063708136523486,
            "mae": 0.29005680296809777,
            "precision": 0.7021660649819494,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7915644551590238,
            "auditor_fn_violation": 0.006978088526756227,
            "auditor_fp_violation": 0.0200804430430916,
            "ave_precision_score": 0.7920754141176747,
            "fpr": 0.1425438596491228,
            "logloss": 1.0082086411728854,
            "mae": 0.28553411970021914,
            "precision": 0.7368421052631579,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8222166543907643,
            "auditor_fn_violation": 0.012379046020164382,
            "auditor_fp_violation": 0.018759226314394944,
            "ave_precision_score": 0.822486956558367,
            "fpr": 0.12843029637760703,
            "logloss": 0.9418823702998078,
            "mae": 0.281160262704026,
            "precision": 0.75,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 29756,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6801182247686004,
            "auditor_fn_violation": 0.000146810540996843,
            "auditor_fp_violation": 0.020055178268251275,
            "ave_precision_score": 0.6719384748628304,
            "fpr": 0.1875,
            "logloss": 2.0281382888185386,
            "mae": 0.3125854497312878,
            "precision": 0.6839186691312384,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.695598419763419,
            "auditor_fn_violation": 0.005018033558099423,
            "auditor_fp_violation": 0.025867746697452586,
            "ave_precision_score": 0.6867552043492393,
            "fpr": 0.18551042810098792,
            "logloss": 1.9117347682807273,
            "mae": 0.31386477595281437,
            "precision": 0.6887661141804788,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.720169454367886,
            "auditor_fn_violation": 0.002309972105997211,
            "auditor_fp_violation": 0.028185382811868394,
            "ave_precision_score": 0.6959914979194688,
            "fpr": 0.32894736842105265,
            "logloss": 3.3128819664374762,
            "mae": 0.3567187929505652,
            "precision": 0.5994659546061415,
            "recall": 0.9393305439330544
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.732974747622665,
            "auditor_fn_violation": 0.003233126400944572,
            "auditor_fp_violation": 0.016102047768651356,
            "ave_precision_score": 0.7122330549249397,
            "fpr": 0.33260153677277715,
            "logloss": 3.1483737404110568,
            "mae": 0.3599790314184411,
            "precision": 0.5976095617529881,
            "recall": 0.9453781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.685240227112935,
            "auditor_fn_violation": 9.175658812302685e-06,
            "auditor_fp_violation": 0.01891826340043658,
            "ave_precision_score": 0.6748512292179425,
            "fpr": 0.19517543859649122,
            "logloss": 2.1134178840830264,
            "mae": 0.3103745773558113,
            "precision": 0.6821428571428572,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6991430855717886,
            "auditor_fn_violation": 0.005294763349906376,
            "auditor_fp_violation": 0.02500725487969518,
            "ave_precision_score": 0.6893867638360536,
            "fpr": 0.1986827661909989,
            "logloss": 1.9837898723157708,
            "mae": 0.3130806509841652,
            "precision": 0.6762075134168157,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8127182909767319,
            "auditor_fn_violation": 0.011042905380606326,
            "auditor_fp_violation": 0.014587880992804596,
            "ave_precision_score": 0.8131958298590066,
            "fpr": 0.1425438596491228,
            "logloss": 0.9040270826433332,
            "mae": 0.27081877427617085,
            "precision": 0.7430830039525692,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.838053861651935,
            "auditor_fn_violation": 0.013721185510428101,
            "auditor_fp_violation": 0.02540343439696179,
            "ave_precision_score": 0.838272666519795,
            "fpr": 0.13611416026344675,
            "logloss": 0.8564644397799392,
            "mae": 0.2723686324082622,
            "precision": 0.7422037422037422,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7834059600576376,
            "auditor_fn_violation": 0.01419474418263233,
            "auditor_fp_violation": 0.002529003961516695,
            "ave_precision_score": 0.7839547611066688,
            "fpr": 0.023026315789473683,
            "logloss": 1.65292498187703,
            "mae": 0.39909797043734313,
            "precision": 0.8679245283018868,
            "recall": 0.28870292887029286
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.8224999191433762,
            "auditor_fn_violation": 0.017876744550729195,
            "auditor_fp_violation": 0.0024982020515538056,
            "ave_precision_score": 0.8227624314573883,
            "fpr": 0.010976948408342482,
            "logloss": 1.6205883852273861,
            "mae": 0.38459153771871196,
            "precision": 0.9315068493150684,
            "recall": 0.2857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8009988247913563,
            "auditor_fn_violation": 0.010262974381560597,
            "auditor_fp_violation": 0.021472532136793596,
            "ave_precision_score": 0.8015771048037693,
            "fpr": 0.23135964912280702,
            "logloss": 1.2325928909537398,
            "mae": 0.29777758901335255,
            "precision": 0.667192429022082,
            "recall": 0.8849372384937239
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8318349245423072,
            "auditor_fn_violation": 0.013919508527889755,
            "auditor_fp_violation": 0.03195932220497875,
            "ave_precision_score": 0.8320842138725519,
            "fpr": 0.21953896816684962,
            "logloss": 1.101840130552994,
            "mae": 0.2872530427350001,
            "precision": 0.6753246753246753,
            "recall": 0.8739495798319328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8066821696142962,
            "auditor_fn_violation": 0.015575680833883873,
            "auditor_fp_violation": 0.015451936292343761,
            "ave_precision_score": 0.8070796341128558,
            "fpr": 0.1162280701754386,
            "logloss": 1.0986208732655003,
            "mae": 0.27065044426627355,
            "precision": 0.7705627705627706,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8280784617096,
            "auditor_fn_violation": 0.018162698668929708,
            "auditor_fp_violation": 0.020919287886243487,
            "ave_precision_score": 0.8283205702224753,
            "fpr": 0.10976948408342481,
            "logloss": 1.1306216263785271,
            "mae": 0.27611999559897893,
            "precision": 0.7732426303854876,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.802186861105217,
            "auditor_fn_violation": 0.017227299420098364,
            "auditor_fp_violation": 0.02808432371250708,
            "ave_precision_score": 0.8028003726748862,
            "fpr": 0.1611842105263158,
            "logloss": 0.966121692710541,
            "mae": 0.2796710658644513,
            "precision": 0.7178502879078695,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.829395258962461,
            "auditor_fn_violation": 0.025424549622263835,
            "auditor_fp_violation": 0.0325977516181536,
            "ave_precision_score": 0.8296638076900151,
            "fpr": 0.15477497255762898,
            "logloss": 0.8988066731966173,
            "mae": 0.2733076585471277,
            "precision": 0.724609375,
            "recall": 0.7794117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7795313240490982,
            "auditor_fn_violation": 0.009060963077148943,
            "auditor_fp_violation": 0.012981041312959822,
            "ave_precision_score": 0.7810213592777436,
            "fpr": 0.07675438596491228,
            "logloss": 1.3611594748524691,
            "mae": 0.32200071573232947,
            "precision": 0.7852760736196319,
            "recall": 0.5355648535564853
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.807964878927073,
            "auditor_fn_violation": 0.016903578116208063,
            "auditor_fp_violation": 0.016235789898684027,
            "ave_precision_score": 0.8082895063349218,
            "fpr": 0.06805708013172337,
            "logloss": 1.3547659110608605,
            "mae": 0.31886904046679676,
            "precision": 0.8037974683544303,
            "recall": 0.5336134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7026399498323848,
            "auditor_fn_violation": 0.0015873889745283741,
            "auditor_fp_violation": 0.019150699328967576,
            "ave_precision_score": 0.6987951316923844,
            "fpr": 0.19736842105263158,
            "logloss": 1.6769497329136618,
            "mae": 0.3001107806369132,
            "precision": 0.6842105263157895,
            "recall": 0.8158995815899581
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7277191610645799,
            "auditor_fn_violation": 0.013592044940918193,
            "auditor_fp_violation": 0.029948143381657136,
            "ave_precision_score": 0.7234036376622524,
            "fpr": 0.2074643249176729,
            "logloss": 1.5185406716475909,
            "mae": 0.3045565752193403,
            "precision": 0.6707317073170732,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 29756,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7919210793352416,
            "auditor_fn_violation": 0.005413638699258612,
            "auditor_fp_violation": 0.01551257175196055,
            "ave_precision_score": 0.7924129285564799,
            "fpr": 0.15679824561403508,
            "logloss": 1.0683996770970141,
            "mae": 0.28049238704787627,
            "precision": 0.7244701348747592,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8273141549568885,
            "auditor_fn_violation": 0.014560599212242533,
            "auditor_fp_violation": 0.020947045686816313,
            "ave_precision_score": 0.8275645965659605,
            "fpr": 0.14709110867178923,
            "logloss": 0.9738162874194156,
            "mae": 0.2771623229439483,
            "precision": 0.7292929292929293,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8016805981482807,
            "auditor_fn_violation": 0.0027939881083461787,
            "auditor_fp_violation": 0.015078017624706933,
            "ave_precision_score": 0.8020106624245976,
            "fpr": 0.18640350877192982,
            "logloss": 1.115597161160061,
            "mae": 0.2795307099988469,
            "precision": 0.7001763668430335,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8301323357082181,
            "auditor_fn_violation": 0.014606720844210358,
            "auditor_fp_violation": 0.0261680356309222,
            "ave_precision_score": 0.8303672936543314,
            "fpr": 0.1756311745334797,
            "logloss": 1.0430471161688386,
            "mae": 0.2794659187029469,
            "precision": 0.7047970479704797,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7883779758020727,
            "auditor_fn_violation": 0.004363025765249949,
            "auditor_fp_violation": 0.01760449510873959,
            "ave_precision_score": 0.789629121148575,
            "fpr": 0.1513157894736842,
            "logloss": 0.9038505420211136,
            "mae": 0.2834218660766319,
            "precision": 0.7261904761904762,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8340419711113722,
            "auditor_fn_violation": 0.010183656338495883,
            "auditor_fp_violation": 0.01926391359753713,
            "ave_precision_score": 0.8342681051323568,
            "fpr": 0.13611416026344675,
            "logloss": 0.8404351344470729,
            "mae": 0.27921278142789197,
            "precision": 0.7416666666666667,
            "recall": 0.7478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 29756,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6859557773251979,
            "auditor_fn_violation": 0.005886185128092199,
            "auditor_fp_violation": 0.016778336971460917,
            "ave_precision_score": 0.6772340610692286,
            "fpr": 0.21600877192982457,
            "logloss": 1.9747041974642274,
            "mae": 0.3092288984609287,
            "precision": 0.6677908937605397,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6976672497219262,
            "auditor_fn_violation": 0.01178407696777943,
            "auditor_fp_violation": 0.02903213596275408,
            "ave_precision_score": 0.6882339345177582,
            "fpr": 0.2217343578485181,
            "logloss": 1.8991495686999513,
            "mae": 0.3162006721056387,
            "precision": 0.6633333333333333,
            "recall": 0.8361344537815126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7830739483360079,
            "auditor_fn_violation": 0.01611704470380974,
            "auditor_fp_violation": 0.022738297356293964,
            "ave_precision_score": 0.7837305425810275,
            "fpr": 0.12938596491228072,
            "logloss": 1.0581813254501176,
            "mae": 0.3024352231437843,
            "precision": 0.7366071428571429,
            "recall": 0.6903765690376569
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8116177192977898,
            "auditor_fn_violation": 0.011493510686382137,
            "auditor_fp_violation": 0.0236269351603013,
            "ave_precision_score": 0.8119240439515995,
            "fpr": 0.12184412733260154,
            "logloss": 1.013049385853296,
            "mae": 0.2948564207378625,
            "precision": 0.7477272727272727,
            "recall": 0.6911764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7954160462097288,
            "auditor_fn_violation": 0.006771636203479413,
            "auditor_fp_violation": 0.011581372786805733,
            "ave_precision_score": 0.7964876461198734,
            "fpr": 0.12938596491228072,
            "logloss": 0.8417946850826751,
            "mae": 0.28317275256185537,
            "precision": 0.7526205450733753,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8383511746423677,
            "auditor_fn_violation": 0.011329778892896348,
            "auditor_fp_violation": 0.016054102476752843,
            "ave_precision_score": 0.8385648139637936,
            "fpr": 0.12294182217343579,
            "logloss": 0.7981864352916889,
            "mae": 0.27994724963975576,
            "precision": 0.7527593818984547,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6859056888564022,
            "auditor_fn_violation": 0.013116604272186748,
            "auditor_fp_violation": 0.012839558573853996,
            "ave_precision_score": 0.6821269762170278,
            "fpr": 0.16885964912280702,
            "logloss": 1.757625405947276,
            "mae": 0.31183060324643763,
            "precision": 0.7003891050583657,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7196818562810362,
            "auditor_fn_violation": 0.008324954570192512,
            "auditor_fp_violation": 0.0233014118626746,
            "ave_precision_score": 0.7159717908935375,
            "fpr": 0.16575192096597147,
            "logloss": 1.551396627044274,
            "mae": 0.30941615343863665,
            "precision": 0.703921568627451,
            "recall": 0.7542016806722689
        }
    }
]