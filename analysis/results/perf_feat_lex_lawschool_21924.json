[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8481775507891278,
            "auditor_fn_violation": 0.011538839461178405,
            "auditor_fp_violation": 0.02071092219860816,
            "ave_precision_score": 0.8484315082988648,
            "fpr": 0.07894736842105263,
            "logloss": 0.6772441621186613,
            "mae": 0.3018693338601153,
            "precision": 0.8213399503722084,
            "recall": 0.6741344195519349
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8310139932824914,
            "auditor_fn_violation": 0.02121656831668615,
            "auditor_fp_violation": 0.011520895405363024,
            "ave_precision_score": 0.831297557796946,
            "fpr": 0.07244785949506037,
            "logloss": 0.7363581853733538,
            "mae": 0.30649384398026364,
            "precision": 0.8151260504201681,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.8614061324074014,
            "auditor_fn_violation": 0.005877728945581878,
            "auditor_fp_violation": 0.007451452264866449,
            "ave_precision_score": 0.8614456665044927,
            "fpr": 0.40021929824561403,
            "logloss": 2.0913294934087996,
            "mae": 0.4030055153784733,
            "precision": 0.5633971291866029,
            "recall": 0.9592668024439919
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.8384931373667606,
            "auditor_fn_violation": 0.004551995884237055,
            "auditor_fp_violation": 0.007818625529245742,
            "ave_precision_score": 0.8386021436249252,
            "fpr": 0.4138309549945115,
            "logloss": 2.0438903789933294,
            "mae": 0.4143254961883979,
            "precision": 0.5413625304136253,
            "recall": 0.9611231101511879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.8358782314349544,
            "auditor_fn_violation": 0.007525815557222997,
            "auditor_fp_violation": 0.021018252281535192,
            "ave_precision_score": 0.8359694455424742,
            "fpr": 0.3081140350877193,
            "logloss": 1.4392562429213882,
            "mae": 0.34215624156324914,
            "precision": 0.6212938005390836,
            "recall": 0.9389002036659878
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.8130293444445986,
            "auditor_fn_violation": 0.00669759811092171,
            "auditor_fp_violation": 0.02350733103340128,
            "ave_precision_score": 0.8131564863047295,
            "fpr": 0.3216245883644347,
            "logloss": 1.4117259182415738,
            "mae": 0.3597982675772913,
            "precision": 0.5902097902097903,
            "recall": 0.9114470842332614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8403082105399431,
            "auditor_fn_violation": 0.014613927895094145,
            "auditor_fp_violation": 0.021479247405925744,
            "ave_precision_score": 0.840525338869099,
            "fpr": 0.13925438596491227,
            "logloss": 0.9133662279916401,
            "mae": 0.2749614375707156,
            "precision": 0.7509803921568627,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8029259401943423,
            "auditor_fn_violation": 0.010514636326349656,
            "auditor_fp_violation": 0.016999568762741103,
            "ave_precision_score": 0.8036623970545647,
            "fpr": 0.12843029637760703,
            "logloss": 0.9649233640821051,
            "mae": 0.277296434004353,
            "precision": 0.7473002159827213,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8131328145652541,
            "auditor_fn_violation": 0.007514649658770144,
            "auditor_fp_violation": 0.02571415176897113,
            "ave_precision_score": 0.8136188668881124,
            "fpr": 0.17324561403508773,
            "logloss": 0.6525745128826779,
            "mae": 0.32986636332916786,
            "precision": 0.7198581560283688,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7926083212461649,
            "auditor_fn_violation": 0.008131950980694322,
            "auditor_fp_violation": 0.032808334640112916,
            "ave_precision_score": 0.7931631975486937,
            "fpr": 0.18551042810098792,
            "logloss": 0.7373155340221279,
            "mae": 0.3432022391434151,
            "precision": 0.687037037037037,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7368915718388069,
            "auditor_fn_violation": 0.013300818237038627,
            "auditor_fp_violation": 0.018390319623286248,
            "ave_precision_score": 0.7345281288851059,
            "fpr": 0.15570175438596492,
            "logloss": 1.5573335594483793,
            "mae": 0.29270893401549464,
            "precision": 0.7258687258687259,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7456397580067433,
            "auditor_fn_violation": 0.0064178400305363046,
            "auditor_fp_violation": 0.009158891328210761,
            "ave_precision_score": 0.7442177299410826,
            "fpr": 0.1350164654226125,
            "logloss": 1.2656695966684786,
            "mae": 0.28138983612210705,
            "precision": 0.7388535031847133,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8574415964167291,
            "auditor_fn_violation": 0.016400471647550652,
            "auditor_fp_violation": 0.024568175188565244,
            "ave_precision_score": 0.8576241502807598,
            "fpr": 0.2149122807017544,
            "logloss": 0.9572482290170172,
            "mae": 0.2831473343813895,
            "precision": 0.6908517350157729,
            "recall": 0.8920570264765784
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8225012488926522,
            "auditor_fn_violation": 0.004350475233111978,
            "auditor_fp_violation": 0.025320487690136447,
            "ave_precision_score": 0.8219717920254179,
            "fpr": 0.21844127332601537,
            "logloss": 0.9843121073636404,
            "mae": 0.29004334529485387,
            "precision": 0.6716171617161716,
            "recall": 0.8790496760259179
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8290843155960692,
            "auditor_fn_violation": 0.018756476221102658,
            "auditor_fp_violation": 0.018486685835729467,
            "ave_precision_score": 0.8293377380210369,
            "fpr": 0.12938596491228072,
            "logloss": 0.9465445177523913,
            "mae": 0.28014902065328173,
            "precision": 0.7581967213114754,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8006110192133422,
            "auditor_fn_violation": 0.014175199683256957,
            "auditor_fp_violation": 0.013689332758350322,
            "ave_precision_score": 0.8013368999629729,
            "fpr": 0.11086717892425905,
            "logloss": 0.9735675408159685,
            "mae": 0.27968291215585445,
            "precision": 0.768348623853211,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8436457835241267,
            "auditor_fn_violation": 0.011855950977239432,
            "auditor_fp_violation": 0.021247447597616376,
            "ave_precision_score": 0.8438585712724469,
            "fpr": 0.1337719298245614,
            "logloss": 0.8730132009421618,
            "mae": 0.2740140235901735,
            "precision": 0.758893280632411,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8064822524761963,
            "auditor_fn_violation": 0.009929041022492079,
            "auditor_fp_violation": 0.015691155715853854,
            "ave_precision_score": 0.8071526298372751,
            "fpr": 0.1251372118551043,
            "logloss": 0.9286959148698583,
            "mae": 0.27722866284852876,
            "precision": 0.7516339869281046,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.8786706139437903,
            "auditor_fn_violation": 0.01012077035766606,
            "auditor_fp_violation": 0.03661655623619619,
            "ave_precision_score": 0.8783955888902458,
            "fpr": 0.3256578947368421,
            "logloss": 1.3670610562354102,
            "mae": 0.3388961422616583,
            "precision": 0.6081794195250659,
            "recall": 0.9389002036659878
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.858882481030572,
            "auditor_fn_violation": 0.010856036017667436,
            "auditor_fp_violation": 0.03463129214364121,
            "ave_precision_score": 0.8584828044364119,
            "fpr": 0.31394072447859495,
            "logloss": 1.3368584558147938,
            "mae": 0.34324545445969545,
            "precision": 0.6016713091922006,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8589033647257304,
            "auditor_fn_violation": 0.017086057812555833,
            "auditor_fp_violation": 0.01972381964412219,
            "ave_precision_score": 0.859119710264131,
            "fpr": 0.13048245614035087,
            "logloss": 0.7425463860605207,
            "mae": 0.2693745332777675,
            "precision": 0.7643564356435644,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8328012207494472,
            "auditor_fn_violation": 0.015972289725054704,
            "auditor_fp_violation": 0.014372941822173437,
            "ave_precision_score": 0.8331996086733455,
            "fpr": 0.11964873765093303,
            "logloss": 0.7941665175776436,
            "mae": 0.27084694127006215,
            "precision": 0.7640692640692641,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8779436200894237,
            "auditor_fn_violation": 0.026146067817200847,
            "auditor_fp_violation": 0.012717735550277122,
            "ave_precision_score": 0.8782881434828791,
            "fpr": 0.0800438596491228,
            "logloss": 0.6085526802564133,
            "mae": 0.3038636110243061,
            "precision": 0.835214446952596,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8421188761878865,
            "auditor_fn_violation": 0.027643891671981283,
            "auditor_fp_violation": 0.01619834953740003,
            "ave_precision_score": 0.8424336602291946,
            "fpr": 0.09330406147091108,
            "logloss": 0.7141518760598907,
            "mae": 0.3152833348457036,
            "precision": 0.7936893203883495,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7931140187171388,
            "auditor_fn_violation": 0.025228230964376323,
            "auditor_fp_violation": 0.025935533608367714,
            "ave_precision_score": 0.7825158843225178,
            "fpr": 0.1206140350877193,
            "logloss": 2.787301219506433,
            "mae": 0.28547067677398386,
            "precision": 0.7629310344827587,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7703036014525856,
            "auditor_fn_violation": 0.019770361290965006,
            "auditor_fp_violation": 0.020895405363023367,
            "ave_precision_score": 0.7603656622248237,
            "fpr": 0.10647639956092206,
            "logloss": 2.857634055957967,
            "mae": 0.2851891859965618,
            "precision": 0.7651331719128329,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8408663714243187,
            "auditor_fn_violation": 0.017300443062850612,
            "auditor_fp_violation": 0.020677063799641626,
            "ave_precision_score": 0.8410840453786519,
            "fpr": 0.13815789473684212,
            "logloss": 0.8977746387620763,
            "mae": 0.2725389156496463,
            "precision": 0.7514792899408284,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8058538206877239,
            "auditor_fn_violation": 0.012328322186475355,
            "auditor_fp_violation": 0.012118747059745966,
            "ave_precision_score": 0.8065661608574284,
            "fpr": 0.12184412733260154,
            "logloss": 0.9414375621895624,
            "mae": 0.2750934779099602,
            "precision": 0.7549668874172185,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8491774424847985,
            "auditor_fn_violation": 0.01661262371815486,
            "auditor_fp_violation": 0.025292224028003508,
            "ave_precision_score": 0.8493866579756897,
            "fpr": 0.1425438596491228,
            "logloss": 0.7554566001082175,
            "mae": 0.2784841325507779,
            "precision": 0.75,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8155642636792384,
            "auditor_fn_violation": 0.00909213761252558,
            "auditor_fp_violation": 0.011035753489101465,
            "ave_precision_score": 0.8160862713482072,
            "fpr": 0.12952799121844127,
            "logloss": 0.824617259902815,
            "mae": 0.28420847261253224,
            "precision": 0.7456896551724138,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8378611041665381,
            "auditor_fn_violation": 0.01622851681137671,
            "auditor_fp_violation": 0.02294036754594324,
            "ave_precision_score": 0.8380889063938076,
            "fpr": 0.14583333333333334,
            "logloss": 0.776890113299962,
            "mae": 0.27703527445656506,
            "precision": 0.7427466150870407,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8085819030815383,
            "auditor_fn_violation": 0.006647810655937865,
            "auditor_fp_violation": 0.02066018503998746,
            "ave_precision_score": 0.809191675944454,
            "fpr": 0.13172338090010977,
            "logloss": 0.7903123524467969,
            "mae": 0.27915337633967124,
            "precision": 0.7452229299363057,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.740304160895106,
            "auditor_fn_violation": 0.016784578554328796,
            "auditor_fp_violation": 0.01617910572154854,
            "ave_precision_score": 0.7379036772779723,
            "fpr": 0.16557017543859648,
            "logloss": 1.5643330662538741,
            "mae": 0.28791894565443027,
            "precision": 0.7264492753623188,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7502057573288945,
            "auditor_fn_violation": 0.008198334254006111,
            "auditor_fp_violation": 0.009624431550885996,
            "ave_precision_score": 0.7486631095452596,
            "fpr": 0.14928649835345773,
            "logloss": 1.3092438367752628,
            "mae": 0.28195251490009193,
            "precision": 0.7246963562753036,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 21924,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7781002881359527,
            "auditor_fn_violation": 0.007490084682173867,
            "auditor_fp_violation": 0.015574863524607243,
            "ave_precision_score": 0.7276134932376325,
            "fpr": 0.18859649122807018,
            "logloss": 3.2447128982138556,
            "mae": 0.2985755587615261,
            "precision": 0.7138103161397671,
            "recall": 0.8737270875763747
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7849191960457518,
            "auditor_fn_violation": 0.00372694663021909,
            "auditor_fp_violation": 0.010134075584130472,
            "ave_precision_score": 0.7483787509317983,
            "fpr": 0.16794731064763996,
            "logloss": 2.436335709522975,
            "mae": 0.29257175948194936,
            "precision": 0.7208029197080292,
            "recall": 0.8531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 21924,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.753729985742307,
            "auditor_fn_violation": 0.018825704791510335,
            "auditor_fp_violation": 0.0043338750677167975,
            "ave_precision_score": 0.7543859776714532,
            "fpr": 0.043859649122807015,
            "logloss": 1.330158960502534,
            "mae": 0.3766130501295696,
            "precision": 0.8373983739837398,
            "recall": 0.4195519348268839
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7124303693849626,
            "auditor_fn_violation": 0.02314405407391779,
            "auditor_fp_violation": 0.011285675082327112,
            "ave_precision_score": 0.7132988382958215,
            "fpr": 0.04610318331503842,
            "logloss": 1.458873584253367,
            "mae": 0.37983714707932337,
            "precision": 0.7951219512195122,
            "recall": 0.35205183585313177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8425784901427464,
            "auditor_fn_violation": 0.008253832136349018,
            "auditor_fp_violation": 0.01337146309955411,
            "ave_precision_score": 0.8427282486610266,
            "fpr": 0.13706140350877194,
            "logloss": 0.9823158298972985,
            "mae": 0.27713784244946466,
            "precision": 0.7514910536779325,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8178363962682667,
            "auditor_fn_violation": 0.004853091445329819,
            "auditor_fp_violation": 0.01757781872353771,
            "ave_precision_score": 0.8180720535861828,
            "fpr": 0.12403951701427003,
            "logloss": 1.0765637233057048,
            "mae": 0.27733047486477724,
            "precision": 0.7569892473118279,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 21924,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.799657998750209,
            "auditor_fn_violation": 0.01273805695501483,
            "auditor_fp_violation": 0.019057069633704214,
            "ave_precision_score": 0.7697282929459197,
            "fpr": 0.14692982456140352,
            "logloss": 2.2438377962570724,
            "mae": 0.2810332715177394,
            "precision": 0.7554744525547445,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.7973970351347741,
            "auditor_fn_violation": 0.012759813463001996,
            "auditor_fp_violation": 0.011231770424964718,
            "ave_precision_score": 0.7755727586618419,
            "fpr": 0.14928649835345773,
            "logloss": 1.8464402496883763,
            "mae": 0.27664517761800034,
            "precision": 0.7429111531190926,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.842232091306008,
            "auditor_fn_violation": 0.01625531496766356,
            "auditor_fp_violation": 0.021711047214235113,
            "ave_precision_score": 0.8424316726425636,
            "fpr": 0.14035087719298245,
            "logloss": 0.9043266148198922,
            "mae": 0.2737342898241481,
            "precision": 0.75,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8052662022127035,
            "auditor_fn_violation": 0.00941694148551541,
            "auditor_fp_violation": 0.01606848831739063,
            "ave_precision_score": 0.8059843717877441,
            "fpr": 0.1251372118551043,
            "logloss": 0.9490132314245591,
            "mae": 0.2757167081217279,
            "precision": 0.7521739130434782,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8764846609524903,
            "auditor_fn_violation": 0.02645201343480902,
            "auditor_fp_violation": 0.013358440638413141,
            "ave_precision_score": 0.8769652899473526,
            "fpr": 0.06798245614035088,
            "logloss": 0.6221484229739911,
            "mae": 0.3068261987753335,
            "precision": 0.8509615384615384,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.842011618744603,
            "auditor_fn_violation": 0.03129023004175034,
            "auditor_fp_violation": 0.017445507291830017,
            "ave_precision_score": 0.8423228102173965,
            "fpr": 0.0801317233809001,
            "logloss": 0.726858179275995,
            "mae": 0.31724521345264683,
            "precision": 0.8137755102040817,
            "recall": 0.6889848812095032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7989285272406192,
            "auditor_fn_violation": 0.010321756529817419,
            "auditor_fp_violation": 0.02072654915197733,
            "ave_precision_score": 0.7797261165745397,
            "fpr": 0.16228070175438597,
            "logloss": 1.7573853151144687,
            "mae": 0.27796930890173444,
            "precision": 0.728440366972477,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7905968087525062,
            "auditor_fn_violation": 0.0061831277427553365,
            "auditor_fp_violation": 0.01946693194291987,
            "ave_precision_score": 0.7746547462021922,
            "fpr": 0.15697036223929747,
            "logloss": 1.6041549034733287,
            "mae": 0.28002722638510114,
            "precision": 0.7190569744597249,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8701526668001278,
            "auditor_fn_violation": 0.008307428448922715,
            "auditor_fp_violation": 0.012642205275659457,
            "ave_precision_score": 0.8703602234338429,
            "fpr": 0.06140350877192982,
            "logloss": 0.5963621399924504,
            "mae": 0.3172427428571884,
            "precision": 0.8592964824120602,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8278591445279782,
            "auditor_fn_violation": 0.008520767295806243,
            "auditor_fp_violation": 0.0008061196487376498,
            "ave_precision_score": 0.8282864357684242,
            "fpr": 0.06915477497255763,
            "logloss": 0.6818449585797143,
            "mae": 0.328340839927851,
            "precision": 0.8283378746594006,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.8421904666239743,
            "auditor_fn_violation": 0.005833065351770466,
            "auditor_fp_violation": 0.008308330207942673,
            "ave_precision_score": 0.8422711228607586,
            "fpr": 0.4024122807017544,
            "logloss": 2.315999026929826,
            "mae": 0.4103768963296256,
            "precision": 0.5625744934445769,
            "recall": 0.9613034623217923
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.814927726209784,
            "auditor_fn_violation": 0.004551995884237055,
            "auditor_fp_violation": 0.008614944331190219,
            "ave_precision_score": 0.8150591177168178,
            "fpr": 0.41712403951701427,
            "logloss": 2.3094735296150177,
            "mae": 0.42420269559663215,
            "precision": 0.5393939393939394,
            "recall": 0.9611231101511879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7604781216549168,
            "auditor_fn_violation": 0.027242559045271023,
            "auditor_fp_violation": 0.01978372296537068,
            "ave_precision_score": 0.755681511987012,
            "fpr": 0.12938596491228072,
            "logloss": 1.520395237505036,
            "mae": 0.2984210704346267,
            "precision": 0.75,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7251968465675138,
            "auditor_fn_violation": 0.025204306377772996,
            "auditor_fp_violation": 0.01983936412106006,
            "ave_precision_score": 0.7242186363385075,
            "fpr": 0.11306256860592755,
            "logloss": 1.7268338724691736,
            "mae": 0.29809893823458194,
            "precision": 0.7547619047619047,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8679774801586744,
            "auditor_fn_violation": 0.011317754671811914,
            "auditor_fp_violation": 0.01678595241071801,
            "ave_precision_score": 0.8681730532478831,
            "fpr": 0.12828947368421054,
            "logloss": 0.622364228652186,
            "mae": 0.2719013561304807,
            "precision": 0.7754318618042226,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8337635738989714,
            "auditor_fn_violation": 0.005301178540184403,
            "auditor_fp_violation": 0.015218264858083743,
            "ave_precision_score": 0.8343708609304068,
            "fpr": 0.12843029637760703,
            "logloss": 0.6944976146912971,
            "mae": 0.27948086968127944,
            "precision": 0.7536842105263157,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8297471600417663,
            "auditor_fn_violation": 0.006054150141136961,
            "auditor_fp_violation": 0.015762386965037296,
            "ave_precision_score": 0.8299449948320441,
            "fpr": 0.1425438596491228,
            "logloss": 0.9913301709628014,
            "mae": 0.282082282314194,
            "precision": 0.7455968688845401,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8064696185173186,
            "auditor_fn_violation": 0.003127126339223272,
            "auditor_fp_violation": 0.022884977262035443,
            "ave_precision_score": 0.8067672624468855,
            "fpr": 0.13611416026344675,
            "logloss": 1.061861544956753,
            "mae": 0.2809805028858775,
            "precision": 0.7411273486430062,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8452735965946239,
            "auditor_fn_violation": 0.007684371315253512,
            "auditor_fp_violation": 0.015085218985706549,
            "ave_precision_score": 0.8454334340969494,
            "fpr": 0.13706140350877194,
            "logloss": 0.8226171172632214,
            "mae": 0.2769659626552908,
            "precision": 0.7539370078740157,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8187933627100215,
            "auditor_fn_violation": 0.004222450348867813,
            "auditor_fp_violation": 0.015833267994354718,
            "ave_precision_score": 0.8190687153493224,
            "fpr": 0.12952799121844127,
            "logloss": 0.910328702468071,
            "mae": 0.2770122005683017,
            "precision": 0.7510548523206751,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8576150888383507,
            "auditor_fn_violation": 0.01761755457891164,
            "auditor_fp_violation": 0.016283285410676335,
            "ave_precision_score": 0.8578256063237015,
            "fpr": 0.12390350877192982,
            "logloss": 0.7764018004701371,
            "mae": 0.2706034321242589,
            "precision": 0.7721774193548387,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8312502084925489,
            "auditor_fn_violation": 0.01353270443084641,
            "auditor_fp_violation": 0.012422573310334013,
            "ave_precision_score": 0.8316418958400864,
            "fpr": 0.1207464324917673,
            "logloss": 0.8291219343394824,
            "mae": 0.27175665016983924,
            "precision": 0.7613882863340564,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8334253814554765,
            "auditor_fn_violation": 0.018593454103691006,
            "auditor_fp_violation": 0.02466714589323666,
            "ave_precision_score": 0.8336730807658774,
            "fpr": 0.1600877192982456,
            "logloss": 0.955243980983957,
            "mae": 0.27329650224195823,
            "precision": 0.7330895795246801,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.798652429048121,
            "auditor_fn_violation": 0.0024609227749156624,
            "auditor_fp_violation": 0.01866081229418222,
            "ave_precision_score": 0.7994062047423255,
            "fpr": 0.16245883644346873,
            "logloss": 1.00986396279432,
            "mae": 0.2800778816494727,
            "precision": 0.7120622568093385,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7083538468094477,
            "auditor_fn_violation": 0.01829197484546397,
            "auditor_fp_violation": 0.0335771138058924,
            "ave_precision_score": 0.6971098347718566,
            "fpr": 0.18969298245614036,
            "logloss": 2.1398805945201653,
            "mae": 0.2891410393654859,
            "precision": 0.7037671232876712,
            "recall": 0.8370672097759674
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6904670383906117,
            "auditor_fn_violation": 0.010263328220240737,
            "auditor_fp_violation": 0.03399423710208562,
            "ave_precision_score": 0.6795856275239467,
            "fpr": 0.18111964873765093,
            "logloss": 1.9567633964530549,
            "mae": 0.30063910319097525,
            "precision": 0.6880907372400756,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8565590115006704,
            "auditor_fn_violation": 0.014957837567442027,
            "auditor_fp_violation": 0.020229091136392055,
            "ave_precision_score": 0.8567369933724958,
            "fpr": 0.14035087719298245,
            "logloss": 0.7749704605068469,
            "mae": 0.27551539757439053,
            "precision": 0.7485265225933202,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.82997913737621,
            "auditor_fn_violation": 0.008783929557863694,
            "auditor_fp_violation": 0.025555708013172338,
            "ave_precision_score": 0.8305546765346963,
            "fpr": 0.13062568605927552,
            "logloss": 0.8063071485745876,
            "mae": 0.27798601862510164,
            "precision": 0.7457264957264957,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7963408424049929,
            "auditor_fn_violation": 0.011297656054596776,
            "auditor_fp_violation": 0.0157597824728091,
            "ave_precision_score": 0.7658184581297651,
            "fpr": 0.1524122807017544,
            "logloss": 2.2733645278166907,
            "mae": 0.28486273692984115,
            "precision": 0.7481884057971014,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.7946058066533903,
            "auditor_fn_violation": 0.001811315028936001,
            "auditor_fp_violation": 0.016524227693272706,
            "ave_precision_score": 0.7728096145109404,
            "fpr": 0.150384193194292,
            "logloss": 1.859466844140256,
            "mae": 0.2814372888112974,
            "precision": 0.7410207939508506,
            "recall": 0.8466522678185745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 15.38199784853469,
            "mae": 0.5383771929817107,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 14.6057574952527,
            "mae": 0.5082327113056004,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.848293193307669,
            "auditor_fn_violation": 0.013785418229892453,
            "auditor_fp_violation": 0.01980195441096804,
            "ave_precision_score": 0.8484967555633701,
            "fpr": 0.15021929824561403,
            "logloss": 0.9033203665013413,
            "mae": 0.26722074438160154,
            "precision": 0.7458256029684601,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8142472176242797,
            "auditor_fn_violation": 0.005602274101277169,
            "auditor_fp_violation": 0.016896659871412895,
            "ave_precision_score": 0.8148179717380757,
            "fpr": 0.14270032930845225,
            "logloss": 0.9329683304425219,
            "mae": 0.26987004263217024,
            "precision": 0.7368421052631579,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8348035829037579,
            "auditor_fn_violation": 0.0211861757244435,
            "auditor_fp_violation": 0.025096887110888862,
            "ave_precision_score": 0.8349258236666313,
            "fpr": 0.14802631578947367,
            "logloss": 1.3657673814451767,
            "mae": 0.2726804456096613,
            "precision": 0.7403846153846154,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8060742554418037,
            "auditor_fn_violation": 0.018373941720227698,
            "auditor_fp_violation": 0.026138858397365537,
            "ave_precision_score": 0.8063685749797047,
            "fpr": 0.13062568605927552,
            "logloss": 1.4879556710040922,
            "mae": 0.27407399807271166,
            "precision": 0.741304347826087,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7993421052631579,
            "auc_prc": 0.8962522587627177,
            "auditor_fn_violation": 0.012769321470682823,
            "auditor_fp_violation": 0.00955588198524816,
            "ave_precision_score": 0.8963892730155899,
            "fpr": 0.08333333333333333,
            "logloss": 0.4400653199865099,
            "mae": 0.2833765745573992,
            "precision": 0.8347826086956521,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8556618132004982,
            "auditor_fn_violation": 0.008833717012847537,
            "auditor_fp_violation": 0.011094558569860438,
            "ave_precision_score": 0.8559714136241587,
            "fpr": 0.09659714599341383,
            "logloss": 0.48959503535148985,
            "mae": 0.3014806080931587,
            "precision": 0.7967667436489607,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8133082162079144,
            "auditor_fn_violation": 0.01001357773251867,
            "auditor_fp_violation": 0.015850939700795933,
            "ave_precision_score": 0.8132242917438184,
            "fpr": 0.12390350877192982,
            "logloss": 1.1409104663697718,
            "mae": 0.2954977455499371,
            "precision": 0.7543478260869565,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7304414756557875,
            "auditor_fn_violation": 0.008470979840822401,
            "auditor_fp_violation": 0.01166545789556218,
            "ave_precision_score": 0.7317577739015105,
            "fpr": 0.12843029637760703,
            "logloss": 1.5710082747114593,
            "mae": 0.30185742311567265,
            "precision": 0.7291666666666666,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7640716785260399,
            "auditor_fn_violation": 0.005381963054275201,
            "auditor_fp_violation": 0.013754323457098809,
            "ave_precision_score": 0.7642590668899982,
            "fpr": 0.16666666666666666,
            "logloss": 1.1873559241345164,
            "mae": 0.297076150542891,
            "precision": 0.7179962894248608,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7442945892229254,
            "auditor_fn_violation": 0.008321617475870865,
            "auditor_fp_violation": 0.010878939940410849,
            "ave_precision_score": 0.7444744910116387,
            "fpr": 0.1602634467618002,
            "logloss": 1.2466070747580995,
            "mae": 0.29956887183817255,
            "precision": 0.7085828343313373,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.8437200932114406,
            "auditor_fn_violation": 0.007603976846392969,
            "auditor_fp_violation": 0.011256615410259628,
            "ave_precision_score": 0.8437927415429785,
            "fpr": 0.33771929824561403,
            "logloss": 1.5078697754864125,
            "mae": 0.35499667741694046,
            "precision": 0.6025806451612903,
            "recall": 0.9511201629327902
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.8215968847462031,
            "auditor_fn_violation": 0.00624476935368771,
            "auditor_fp_violation": 0.012858710992629765,
            "ave_precision_score": 0.8217146108277882,
            "fpr": 0.3512623490669594,
            "logloss": 1.4840025862225734,
            "mae": 0.3723439876514819,
            "precision": 0.5739014647137151,
            "recall": 0.9308855291576674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8377311814156057,
            "auditor_fn_violation": 0.009075642262479014,
            "auditor_fp_violation": 0.02160426303287911,
            "ave_precision_score": 0.8379688177670279,
            "fpr": 0.1524122807017544,
            "logloss": 0.9148946618008598,
            "mae": 0.27504137250111715,
            "precision": 0.7372400756143668,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.80425037947467,
            "auditor_fn_violation": 0.006780577202561446,
            "auditor_fp_violation": 0.019209659714599342,
            "ave_precision_score": 0.8048180150320405,
            "fpr": 0.141602634467618,
            "logloss": 0.960321801313327,
            "mae": 0.27605113330221737,
            "precision": 0.735655737704918,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7374887847513756,
            "auditor_fn_violation": 0.011275324257691075,
            "auditor_fp_violation": 0.024977080468391887,
            "ave_precision_score": 0.7351237434459914,
            "fpr": 0.17434210526315788,
            "logloss": 1.5663818697735543,
            "mae": 0.29106448216530006,
            "precision": 0.7087912087912088,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7444084399327257,
            "auditor_fn_violation": 0.0073898808183160995,
            "auditor_fp_violation": 0.013490865610788771,
            "ave_precision_score": 0.7429897285852224,
            "fpr": 0.14709110867178923,
            "logloss": 1.2694990038907032,
            "mae": 0.2827946252572543,
            "precision": 0.7248459958932238,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7847949619638708,
            "auditor_fn_violation": 0.016954300210812165,
            "auditor_fp_violation": 0.025451098053923416,
            "ave_precision_score": 0.7530295263883163,
            "fpr": 0.17543859649122806,
            "logloss": 2.369699956696657,
            "mae": 0.2955354071340989,
            "precision": 0.7212543554006968,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7828490572044641,
            "auditor_fn_violation": 0.0037767340852029345,
            "auditor_fp_violation": 0.029120766034185355,
            "ave_precision_score": 0.7605001722571161,
            "fpr": 0.17014270032930845,
            "logloss": 1.8991826616951453,
            "mae": 0.2974575326300173,
            "precision": 0.714548802946593,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8466905890872246,
            "auditor_fn_violation": 0.01497123664558545,
            "auditor_fp_violation": 0.018413760053340004,
            "ave_precision_score": 0.846896411105958,
            "fpr": 0.12280701754385964,
            "logloss": 0.8492991031762842,
            "mae": 0.2731812607455153,
            "precision": 0.7709611451942741,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8102300142645349,
            "auditor_fn_violation": 0.010844181861718906,
            "auditor_fp_violation": 0.014338638858397364,
            "ave_precision_score": 0.8109373488970797,
            "fpr": 0.1163556531284303,
            "logloss": 0.8989085716898843,
            "mae": 0.2743147924431736,
            "precision": 0.7633928571428571,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7996252974346335,
            "auditor_fn_violation": 0.01198994175867367,
            "auditor_fp_violation": 0.017694920198358128,
            "ave_precision_score": 0.7596493498187283,
            "fpr": 0.16776315789473684,
            "logloss": 2.715627669888749,
            "mae": 0.2837550626039669,
            "precision": 0.7357512953367875,
            "recall": 0.8676171079429735
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7971452461832929,
            "auditor_fn_violation": 0.010263328220240736,
            "auditor_fp_violation": 0.014466049866708493,
            "ave_precision_score": 0.7670895228418462,
            "fpr": 0.15806805708013172,
            "logloss": 2.2706954364344196,
            "mae": 0.2864801591803661,
            "precision": 0.7298311444652908,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8399519239673429,
            "auditor_fn_violation": 0.014129327902240326,
            "auditor_fp_violation": 0.020432241530191284,
            "ave_precision_score": 0.8401730121825727,
            "fpr": 0.13486842105263158,
            "logloss": 0.898809277704903,
            "mae": 0.27424388007635037,
            "precision": 0.7535070140280561,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.808560966700407,
            "auditor_fn_violation": 0.011842301792585467,
            "auditor_fp_violation": 0.013231143170769954,
            "ave_precision_score": 0.8092860805233949,
            "fpr": 0.1207464324917673,
            "logloss": 0.9311147302428447,
            "mae": 0.27456545853917586,
            "precision": 0.7566371681415929,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8349502215654384,
            "auditor_fn_violation": 0.002318040518812309,
            "auditor_fp_violation": 0.015569654540150857,
            "ave_precision_score": 0.8352569441521631,
            "fpr": 0.14035087719298245,
            "logloss": 0.8127425524127422,
            "mae": 0.2818013533909689,
            "precision": 0.747534516765286,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8061914558591692,
            "auditor_fn_violation": 0.0038194090466176535,
            "auditor_fp_violation": 0.015774462913595737,
            "ave_precision_score": 0.8067168703097375,
            "fpr": 0.12952799121844127,
            "logloss": 0.8470565727718052,
            "mae": 0.2828468855680982,
            "precision": 0.7478632478632479,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7289560337866878,
            "auditor_fn_violation": 0.0121172330010362,
            "auditor_fp_violation": 0.02143757553027462,
            "ave_precision_score": 0.7207234392553146,
            "fpr": 0.16228070175438597,
            "logloss": 1.6951090844310772,
            "mae": 0.2944879532307657,
            "precision": 0.720754716981132,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7350745809485634,
            "auditor_fn_violation": 0.00936952486172128,
            "auditor_fp_violation": 0.012486278814489571,
            "ave_precision_score": 0.7282786062247903,
            "fpr": 0.15367727771679474,
            "logloss": 1.5847083995828546,
            "mae": 0.2987030069235351,
            "precision": 0.7101449275362319,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8652976763673178,
            "auditor_fn_violation": 0.010824221960195808,
            "auditor_fp_violation": 0.011436325374005085,
            "ave_precision_score": 0.8652074706175896,
            "fpr": 0.09100877192982457,
            "logloss": 1.4052120948301239,
            "mae": 0.28149839239746943,
            "precision": 0.8113636363636364,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8403308037291349,
            "auditor_fn_violation": 0.006685743954973176,
            "auditor_fp_violation": 0.018111964873765096,
            "ave_precision_score": 0.8402258544529853,
            "fpr": 0.09110867178924259,
            "logloss": 1.7649744746044271,
            "mae": 0.28561383541914975,
            "precision": 0.8,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7744175712527271,
            "auditor_fn_violation": 0.008142173151820491,
            "auditor_fp_violation": 0.018864337208817777,
            "ave_precision_score": 0.724475900333511,
            "fpr": 0.1875,
            "logloss": 3.3435894123172196,
            "mae": 0.2991284340227969,
            "precision": 0.7154742096505824,
            "recall": 0.8757637474541752
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7826483793221106,
            "auditor_fn_violation": 0.006718935591629068,
            "auditor_fp_violation": 0.020836600282264396,
            "ave_precision_score": 0.7462550057562266,
            "fpr": 0.1668496158068057,
            "logloss": 2.602593722261181,
            "mae": 0.2946329734744169,
            "precision": 0.7200736648250461,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8228221691357603,
            "auditor_fn_violation": 0.011067638546468004,
            "auditor_fp_violation": 0.025388590240446724,
            "ave_precision_score": 0.8225397464289371,
            "fpr": 0.15350877192982457,
            "logloss": 0.9248614418687665,
            "mae": 0.2762085326200356,
            "precision": 0.7373358348968105,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7948598657241466,
            "auditor_fn_violation": 0.006903860424426199,
            "auditor_fp_violation": 0.01325319507605457,
            "ave_precision_score": 0.7943688003790788,
            "fpr": 0.15477497255762898,
            "logloss": 0.9922288586043403,
            "mae": 0.28413931442183743,
            "precision": 0.718562874251497,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8359414503714371,
            "auditor_fn_violation": 0.00785855933111802,
            "auditor_fp_violation": 0.016236404550568823,
            "ave_precision_score": 0.836123980377601,
            "fpr": 0.14035087719298245,
            "logloss": 0.9065002148387915,
            "mae": 0.278677082780472,
            "precision": 0.747534516765286,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8086446029011856,
            "auditor_fn_violation": 0.003127126339223272,
            "auditor_fp_violation": 0.01641396816684962,
            "ave_precision_score": 0.8089602100491202,
            "fpr": 0.13062568605927552,
            "logloss": 0.9971009313706539,
            "mae": 0.27881272137782076,
            "precision": 0.7489451476793249,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7621651536210097,
            "auditor_fn_violation": 0.01387251223782471,
            "auditor_fp_violation": 0.015879589115306084,
            "ave_precision_score": 0.7317022708351715,
            "fpr": 0.15679824561403508,
            "logloss": 2.5109467097242577,
            "mae": 0.28880446813656907,
            "precision": 0.7296786389413988,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.766831775902269,
            "auditor_fn_violation": 0.00777869713342801,
            "auditor_fp_violation": 0.008556139250431244,
            "ave_precision_score": 0.7440558184906947,
            "fpr": 0.1350164654226125,
            "logloss": 2.054246064784418,
            "mae": 0.28157027240071125,
            "precision": 0.7399577167019028,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7281126811799954,
            "auditor_fn_violation": 0.009332457926894636,
            "auditor_fp_violation": 0.020148351877318,
            "ave_precision_score": 0.7258901731757039,
            "fpr": 0.16557017543859648,
            "logloss": 1.628707761690054,
            "mae": 0.2989901314697009,
            "precision": 0.7145557655954632,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7372131911035458,
            "auditor_fn_violation": 0.005886773844041979,
            "auditor_fp_violation": 0.009742041712403953,
            "ave_precision_score": 0.7358729429861878,
            "fpr": 0.13830954994511527,
            "logloss": 1.3211689264914477,
            "mae": 0.28643702366656154,
            "precision": 0.7341772151898734,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8500180952337406,
            "auditor_fn_violation": 0.01409136384750063,
            "auditor_fp_violation": 0.02466193690878026,
            "ave_precision_score": 0.8502225339952867,
            "fpr": 0.1962719298245614,
            "logloss": 0.9097422854113938,
            "mae": 0.2813503869024323,
            "precision": 0.7051070840197694,
            "recall": 0.8716904276985743
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8221524569160722,
            "auditor_fn_violation": 0.007525018196129381,
            "auditor_fp_violation": 0.02055237572526267,
            "ave_precision_score": 0.8226367715177061,
            "fpr": 0.19538968166849616,
            "logloss": 0.9286825677045574,
            "mae": 0.2850052158124267,
            "precision": 0.6882661996497373,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.726145205362402,
            "auditor_fn_violation": 0.011391449601600748,
            "auditor_fp_violation": 0.01975246905863233,
            "ave_precision_score": 0.7238447037533176,
            "fpr": 0.16337719298245615,
            "logloss": 1.6178713876067812,
            "mae": 0.3007036997327207,
            "precision": 0.7151051625239006,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7362195768836064,
            "auditor_fn_violation": 0.0084045965675106,
            "auditor_fp_violation": 0.01397600752705034,
            "ave_precision_score": 0.7347979341294913,
            "fpr": 0.13721185510428102,
            "logloss": 1.311936072059129,
            "mae": 0.2894300711548059,
            "precision": 0.7340425531914894,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8776709457137242,
            "auditor_fn_violation": 0.02651900882552614,
            "auditor_fp_violation": 0.010993561695211906,
            "ave_precision_score": 0.878067094928017,
            "fpr": 0.08223684210526316,
            "logloss": 0.6080130781033468,
            "mae": 0.30479189480875474,
            "precision": 0.8318385650224215,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8421719014076585,
            "auditor_fn_violation": 0.02612418887937922,
            "auditor_fp_violation": 0.017357299670691547,
            "ave_precision_score": 0.8424837678541504,
            "fpr": 0.09220636663007684,
            "logloss": 0.7140738381446434,
            "mae": 0.31632382814638504,
            "precision": 0.7966101694915254,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7583229310311687,
            "auditor_fn_violation": 0.029201057633901465,
            "auditor_fp_violation": 0.024151456432054012,
            "ave_precision_score": 0.7588140940395762,
            "fpr": 0.08223684210526316,
            "logloss": 2.0590698539326566,
            "mae": 0.360348507086016,
            "precision": 0.7781065088757396,
            "recall": 0.5356415478615071
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7677289528508562,
            "auditor_fn_violation": 0.027624925022463626,
            "auditor_fp_violation": 0.012848910145836601,
            "ave_precision_score": 0.7680671485085543,
            "fpr": 0.07354555433589462,
            "logloss": 2.0367350497818864,
            "mae": 0.3491233810614993,
            "precision": 0.7859424920127795,
            "recall": 0.531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 21924,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7393761274955651,
            "auditor_fn_violation": 0.009493246864615713,
            "auditor_fp_violation": 0.004401591865649877,
            "ave_precision_score": 0.7401381220428622,
            "fpr": 0.08223684210526316,
            "logloss": 1.2094344635667047,
            "mae": 0.33637078650920865,
            "precision": 0.7857142857142857,
            "recall": 0.560081466395112
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7021842089341097,
            "auditor_fn_violation": 0.013461579495155213,
            "auditor_fp_violation": 0.004393229575035283,
            "ave_precision_score": 0.703302399355145,
            "fpr": 0.07793633369923161,
            "logloss": 1.3120525689009959,
            "mae": 0.33975418869551394,
            "precision": 0.7717041800643086,
            "recall": 0.5183585313174947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.761692988672179,
            "auditor_fn_violation": 0.01387251223782471,
            "auditor_fp_violation": 0.015879589115306084,
            "ave_precision_score": 0.7312121375071511,
            "fpr": 0.15679824561403508,
            "logloss": 2.518834486850983,
            "mae": 0.2892881168870238,
            "precision": 0.7296786389413988,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7669723933344386,
            "auditor_fn_violation": 0.006704710604490831,
            "auditor_fp_violation": 0.009406362709738126,
            "ave_precision_score": 0.7442045918700463,
            "fpr": 0.13721185510428102,
            "logloss": 2.0553022672593273,
            "mae": 0.28198711663230236,
            "precision": 0.7362869198312236,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8545454073738976,
            "auditor_fn_violation": 0.015833244006145716,
            "auditor_fp_violation": 0.02144538900695921,
            "ave_precision_score": 0.8546769030210755,
            "fpr": 0.16228070175438597,
            "logloss": 0.9452525757795027,
            "mae": 0.2668580855347064,
            "precision": 0.7342908438061041,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8271086165875203,
            "auditor_fn_violation": 0.01001439094532152,
            "auditor_fp_violation": 0.023303963462443157,
            "ave_precision_score": 0.827342968719047,
            "fpr": 0.17014270032930845,
            "logloss": 1.01235889838325,
            "mae": 0.27103087248076563,
            "precision": 0.7064393939393939,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7268625385432885,
            "auditor_fn_violation": 0.012615232072033444,
            "auditor_fp_violation": 0.021763137058799023,
            "ave_precision_score": 0.7245073271138011,
            "fpr": 0.16666666666666666,
            "logloss": 1.5907688401009457,
            "mae": 0.30222191613492744,
            "precision": 0.7148217636022514,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.739112345564664,
            "auditor_fn_violation": 0.005142332850474047,
            "auditor_fp_violation": 0.009119687941038113,
            "ave_precision_score": 0.7377055938977918,
            "fpr": 0.14818880351262348,
            "logloss": 1.284166004027994,
            "mae": 0.28851185589203676,
            "precision": 0.7222222222222222,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8373034121096626,
            "auditor_fn_violation": 0.006826830314074388,
            "auditor_fp_violation": 0.015738946534983544,
            "ave_precision_score": 0.8374628166253759,
            "fpr": 0.13815789473684212,
            "logloss": 1.0263823694989558,
            "mae": 0.27870890161308903,
            "precision": 0.75,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8097466774547004,
            "auditor_fn_violation": 0.003127126339223272,
            "auditor_fp_violation": 0.01641396816684962,
            "ave_precision_score": 0.810028343418985,
            "fpr": 0.13062568605927552,
            "logloss": 1.1220613703971094,
            "mae": 0.2786186964191602,
            "precision": 0.7489451476793249,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7384030777279154,
            "auditor_fn_violation": 0.01199217493836424,
            "auditor_fp_violation": 0.020291598949868744,
            "ave_precision_score": 0.7360283506422003,
            "fpr": 0.15899122807017543,
            "logloss": 1.5544479077716984,
            "mae": 0.29155998806411015,
            "precision": 0.7248576850094877,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.746252506465859,
            "auditor_fn_violation": 0.007551097339216162,
            "auditor_fp_violation": 0.00937450995766035,
            "ave_precision_score": 0.7448632218892859,
            "fpr": 0.13391877058177826,
            "logloss": 1.2630624377106514,
            "mae": 0.2805981610754045,
            "precision": 0.7398720682302772,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8338345223459765,
            "auditor_fn_violation": 0.025976346160717485,
            "auditor_fp_violation": 0.024755698628995293,
            "ave_precision_score": 0.8334620452472367,
            "fpr": 0.12171052631578948,
            "logloss": 1.835681014958742,
            "mae": 0.2845559793607554,
            "precision": 0.7607758620689655,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7939265003034254,
            "auditor_fn_violation": 0.0164915017556005,
            "auditor_fp_violation": 0.023384820448486755,
            "ave_precision_score": 0.7940979393473141,
            "fpr": 0.10098792535675083,
            "logloss": 1.907696766723387,
            "mae": 0.2825323155250575,
            "precision": 0.775609756097561,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7287833891956312,
            "auditor_fn_violation": 0.010272626576624864,
            "auditor_fp_violation": 0.02368264783097888,
            "ave_precision_score": 0.7283407202744083,
            "fpr": 0.20285087719298245,
            "logloss": 1.489024312865778,
            "mae": 0.2937655257545606,
            "precision": 0.6906354515050167,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7225862278273437,
            "auditor_fn_violation": 0.002551014360124519,
            "auditor_fp_violation": 0.02761388583973656,
            "ave_precision_score": 0.7216066365354142,
            "fpr": 0.19099890230515917,
            "logloss": 1.486950168819639,
            "mae": 0.29969050026885125,
            "precision": 0.6807339449541284,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8221980176747831,
            "auditor_fn_violation": 0.011022974952656594,
            "auditor_fp_violation": 0.025404217193815894,
            "ave_precision_score": 0.8219480505891683,
            "fpr": 0.15350877192982457,
            "logloss": 0.9177492446004702,
            "mae": 0.27701745227049523,
            "precision": 0.7368421052631579,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7945811831203031,
            "auditor_fn_violation": 0.005310661864943231,
            "auditor_fp_violation": 0.014020111337619571,
            "ave_precision_score": 0.7940925709130041,
            "fpr": 0.15148188803512624,
            "logloss": 0.9843574193814326,
            "mae": 0.2847637060227581,
            "precision": 0.7234468937875751,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7545108442982651,
            "auditor_fn_violation": 0.030011701861578602,
            "auditor_fp_violation": 0.02445097303829645,
            "ave_precision_score": 0.7549977256314421,
            "fpr": 0.08442982456140351,
            "logloss": 2.1791123348833774,
            "mae": 0.3588492042774015,
            "precision": 0.7774566473988439,
            "recall": 0.5478615071283096
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7721882359538943,
            "auditor_fn_violation": 0.03048888909962944,
            "auditor_fp_violation": 0.010501607338874081,
            "ave_precision_score": 0.7723991564882917,
            "fpr": 0.07135016465422613,
            "logloss": 2.110369940868571,
            "mae": 0.34666692118032266,
            "precision": 0.7943037974683544,
            "recall": 0.5421166306695464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.856496048663271,
            "auditor_fn_violation": 0.01658135920248687,
            "auditor_fp_violation": 0.009915301912739092,
            "ave_precision_score": 0.8567072912177076,
            "fpr": 0.06798245614035088,
            "logloss": 1.048697715074977,
            "mae": 0.2890143638065863,
            "precision": 0.8368421052631579,
            "recall": 0.6476578411405295
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8316862731479789,
            "auditor_fn_violation": 0.010403207260433443,
            "auditor_fp_violation": 0.010976948408342485,
            "ave_precision_score": 0.8320746266307102,
            "fpr": 0.07025246981339188,
            "logloss": 1.0711140363184248,
            "mae": 0.2897407320650896,
            "precision": 0.8160919540229885,
            "recall": 0.6133909287257019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8210525056362076,
            "auditor_fn_violation": 0.006773234001500703,
            "auditor_fp_violation": 0.01750218777347168,
            "ave_precision_score": 0.822256944232709,
            "fpr": 0.14473684210526316,
            "logloss": 0.9514467172027425,
            "mae": 0.28044364335259514,
            "precision": 0.7426900584795322,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7975935160850384,
            "auditor_fn_violation": 0.002100556434080226,
            "auditor_fp_violation": 0.017798337776383885,
            "ave_precision_score": 0.7989315475908789,
            "fpr": 0.13611416026344675,
            "logloss": 1.0340330616145303,
            "mae": 0.28129825351606796,
            "precision": 0.7405857740585774,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8626290674863146,
            "auditor_fn_violation": 0.01399310394111552,
            "auditor_fp_violation": 0.021828249364503907,
            "ave_precision_score": 0.8628142354278723,
            "fpr": 0.13596491228070176,
            "logloss": 0.7097705083137394,
            "mae": 0.2702836270417324,
            "precision": 0.7610789980732178,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8272980768042537,
            "auditor_fn_violation": 0.013852766641456828,
            "auditor_fp_violation": 0.015465736239611104,
            "ave_precision_score": 0.8277464060805615,
            "fpr": 0.13172338090010977,
            "logloss": 0.7761374577019308,
            "mae": 0.27743966577017926,
            "precision": 0.75,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8324253095676925,
            "auditor_fn_violation": 0.006902758423553797,
            "auditor_fp_violation": 0.01686408717756387,
            "ave_precision_score": 0.8325943092795769,
            "fpr": 0.13596491228070176,
            "logloss": 1.1235855912247001,
            "mae": 0.28003939472303113,
            "precision": 0.751004016064257,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8109639296696847,
            "auditor_fn_violation": 0.009177487535355019,
            "auditor_fp_violation": 0.018793123725889923,
            "ave_precision_score": 0.8111908748129938,
            "fpr": 0.132821075740944,
            "logloss": 1.2128121528924507,
            "mae": 0.278499506758152,
            "precision": 0.740343347639485,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7672602669576816,
            "auditor_fn_violation": 0.027416747061135522,
            "auditor_fp_violation": 0.02445097303829645,
            "ave_precision_score": 0.7676770216088542,
            "fpr": 0.08442982456140351,
            "logloss": 1.9550349731728374,
            "mae": 0.35330774539402804,
            "precision": 0.7818696883852692,
            "recall": 0.5621181262729125
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7781693989894882,
            "auditor_fn_violation": 0.028924140514422957,
            "auditor_fp_violation": 0.00953622392974753,
            "ave_precision_score": 0.7783819039316349,
            "fpr": 0.07464324917672886,
            "logloss": 1.9529120992654874,
            "mae": 0.34254688841745334,
            "precision": 0.7920489296636085,
            "recall": 0.5593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8005680699368215,
            "auditor_fn_violation": 0.01032845606888913,
            "auditor_fp_violation": 0.015085218985706549,
            "ave_precision_score": 0.7706863279690954,
            "fpr": 0.13706140350877194,
            "logloss": 2.216081526060896,
            "mae": 0.2770409033643696,
            "precision": 0.7632575757575758,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.7975826673675004,
            "auditor_fn_violation": 0.00719310182957043,
            "auditor_fp_violation": 0.0133781558726674,
            "ave_precision_score": 0.7755496552238119,
            "fpr": 0.13611416026344675,
            "logloss": 1.798436227018445,
            "mae": 0.2740864588227976,
            "precision": 0.753968253968254,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8318709846573185,
            "auditor_fn_violation": 0.011625933469110663,
            "auditor_fp_violation": 0.022510626328291036,
            "ave_precision_score": 0.8320995956898007,
            "fpr": 0.14802631578947367,
            "logloss": 0.8630938275112698,
            "mae": 0.27604361683825207,
            "precision": 0.7413793103448276,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8056221524215624,
            "auditor_fn_violation": 0.006735531409957019,
            "auditor_fp_violation": 0.016715344205739384,
            "ave_precision_score": 0.8060389583775567,
            "fpr": 0.150384193194292,
            "logloss": 0.885095276348906,
            "mae": 0.27949287934405465,
            "precision": 0.7192622950819673,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8548004249073302,
            "auditor_fn_violation": 0.01679351127309108,
            "auditor_fp_violation": 0.020421823561278505,
            "ave_precision_score": 0.8550100470536157,
            "fpr": 0.1425438596491228,
            "logloss": 1.0980433524245694,
            "mae": 0.2706563975069469,
            "precision": 0.7519083969465649,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8256955540919205,
            "auditor_fn_violation": 0.009568674681656642,
            "auditor_fp_violation": 0.0198565156029481,
            "ave_precision_score": 0.8261203733551234,
            "fpr": 0.12733260153677278,
            "logloss": 1.0972644131289637,
            "mae": 0.27384832229066497,
            "precision": 0.7542372881355932,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8340786354881058,
            "auditor_fn_violation": 0.006532050594919073,
            "auditor_fp_violation": 0.0173849856232029,
            "ave_precision_score": 0.8342599157085473,
            "fpr": 0.14364035087719298,
            "logloss": 1.0236698820968615,
            "mae": 0.2792342626949001,
            "precision": 0.7431372549019608,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8056454475006296,
            "auditor_fn_violation": 0.004186887881022211,
            "auditor_fp_violation": 0.017048572996706913,
            "ave_precision_score": 0.8059444724367588,
            "fpr": 0.13830954994511527,
            "logloss": 1.110747421125943,
            "mae": 0.28217045875405106,
            "precision": 0.7358490566037735,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8621408554997223,
            "auditor_fn_violation": 0.013613463393718515,
            "auditor_fp_violation": 0.023807663457932244,
            "ave_precision_score": 0.8623279998814563,
            "fpr": 0.13925438596491227,
            "logloss": 0.6972878696448168,
            "mae": 0.271069700236529,
            "precision": 0.7562380038387716,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8285479554253395,
            "auditor_fn_violation": 0.014388574490330572,
            "auditor_fp_violation": 0.017974753018660826,
            "ave_precision_score": 0.828984095908651,
            "fpr": 0.13391877058177826,
            "logloss": 0.7600700056783727,
            "mae": 0.2777442939279676,
            "precision": 0.7474120082815735,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8337972319566204,
            "auditor_fn_violation": 0.024158537892592993,
            "auditor_fp_violation": 0.02484164687252573,
            "ave_precision_score": 0.8339844499885671,
            "fpr": 0.12390350877192982,
            "logloss": 1.0412875352385422,
            "mae": 0.2836294552805852,
            "precision": 0.7590618336886994,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8105262749230563,
            "auditor_fn_violation": 0.023473599609287025,
            "auditor_fp_violation": 0.023382370236788456,
            "ave_precision_score": 0.81079840315689,
            "fpr": 0.10867178924259056,
            "logloss": 1.1638860022689064,
            "mae": 0.28202780407528827,
            "precision": 0.7620192307692307,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7308872204996627,
            "auditor_fn_violation": 0.01364026155000536,
            "auditor_fp_violation": 0.019833208317706384,
            "ave_precision_score": 0.7285346419733554,
            "fpr": 0.1611842105263158,
            "logloss": 1.5808753959671116,
            "mae": 0.29771434380974166,
            "precision": 0.72,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.74164539804243,
            "auditor_fn_violation": 0.004753516535362137,
            "auditor_fp_violation": 0.010663321310961274,
            "ave_precision_score": 0.7402326858243676,
            "fpr": 0.14050493962678376,
            "logloss": 1.2804876822256424,
            "mae": 0.2863474158776893,
            "precision": 0.7322175732217573,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8542226814060335,
            "auditor_fn_violation": 0.01727141172687319,
            "auditor_fp_violation": 0.027487810976372047,
            "ave_precision_score": 0.8544654468769101,
            "fpr": 0.17324561403508773,
            "logloss": 0.7681405775954739,
            "mae": 0.2711982569225715,
            "precision": 0.7228070175438597,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.832011734227945,
            "auditor_fn_violation": 0.009857916086800879,
            "auditor_fp_violation": 0.022149913752548225,
            "ave_precision_score": 0.8323818022238463,
            "fpr": 0.1668496158068057,
            "logloss": 0.8085960415589585,
            "mae": 0.2763917767651756,
            "precision": 0.7137476459510358,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8445461738365689,
            "auditor_fn_violation": 0.007603976846392969,
            "auditor_fp_violation": 0.01431949827061716,
            "ave_precision_score": 0.8446187741018367,
            "fpr": 0.3399122807017544,
            "logloss": 1.4923798862809716,
            "mae": 0.3553110550748208,
            "precision": 0.601029601029601,
            "recall": 0.9511201629327902
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.8224911967656611,
            "auditor_fn_violation": 0.00624476935368771,
            "auditor_fp_violation": 0.012858710992629765,
            "ave_precision_score": 0.8226069898695709,
            "fpr": 0.3512623490669594,
            "logloss": 1.464516681904413,
            "mae": 0.3723795499019281,
            "precision": 0.5739014647137151,
            "recall": 0.9308855291576674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.824361112542237,
            "auditor_fn_violation": 0.011943044985171692,
            "auditor_fp_violation": 0.016140038338125603,
            "ave_precision_score": 0.8245629156849199,
            "fpr": 0.14035087719298245,
            "logloss": 1.102144906798929,
            "mae": 0.2842848077064438,
            "precision": 0.744,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8009710281197308,
            "auditor_fn_violation": 0.008210188409954652,
            "auditor_fp_violation": 0.015230515916575194,
            "ave_precision_score": 0.8012493467034125,
            "fpr": 0.13172338090010977,
            "logloss": 1.1933913947338162,
            "mae": 0.28269487192758413,
            "precision": 0.7419354838709677,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7434982851567671,
            "auditor_fn_violation": 0.010801890163290102,
            "auditor_fp_violation": 0.007469683710463808,
            "ave_precision_score": 0.7443818587113118,
            "fpr": 0.08333333333333333,
            "logloss": 1.126128554481337,
            "mae": 0.3283886053959406,
            "precision": 0.7923497267759563,
            "recall": 0.5906313645621182
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.706236732736195,
            "auditor_fn_violation": 0.016477276768462255,
            "auditor_fp_violation": 0.006174533479692648,
            "ave_precision_score": 0.7073532412491745,
            "fpr": 0.0845225027442371,
            "logloss": 1.2361721415324287,
            "mae": 0.33204933457103797,
            "precision": 0.7673716012084593,
            "recall": 0.5485961123110151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8558641942689273,
            "auditor_fn_violation": 0.013691624682888485,
            "auditor_fp_violation": 0.01642913697545527,
            "ave_precision_score": 0.8560775408220616,
            "fpr": 0.13157894736842105,
            "logloss": 0.7034750073973928,
            "mae": 0.2721017344168939,
            "precision": 0.7660818713450293,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8209652220328384,
            "auditor_fn_violation": 0.002230952149514103,
            "auditor_fp_violation": 0.010994099890230521,
            "ave_precision_score": 0.8215371342533974,
            "fpr": 0.12843029637760703,
            "logloss": 0.7858532569203395,
            "mae": 0.27922993903737453,
            "precision": 0.7489270386266095,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.84298013221905,
            "auditor_fn_violation": 0.011855950977239432,
            "auditor_fp_violation": 0.0199321790223778,
            "ave_precision_score": 0.8431943264149357,
            "fpr": 0.12938596491228072,
            "logloss": 0.8810235629636318,
            "mae": 0.27421781558868824,
            "precision": 0.7649402390438247,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8055908177699083,
            "auditor_fn_violation": 0.010270440713809859,
            "auditor_fp_violation": 0.009874353144111656,
            "ave_precision_score": 0.8062637687569952,
            "fpr": 0.12403951701427003,
            "logloss": 0.9378598927222772,
            "mae": 0.27767089387975874,
            "precision": 0.7516483516483516,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7386390713502984,
            "auditor_fn_violation": 0.01199217493836424,
            "auditor_fp_violation": 0.020291598949868744,
            "ave_precision_score": 0.7362759806516467,
            "fpr": 0.15899122807017543,
            "logloss": 1.5549295984622533,
            "mae": 0.2915219356861201,
            "precision": 0.7248576850094877,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7464240671843285,
            "auditor_fn_violation": 0.008082163525710482,
            "auditor_fp_violation": 0.00937450995766035,
            "ave_precision_score": 0.7450015319711478,
            "fpr": 0.13391877058177826,
            "logloss": 1.2621207216999653,
            "mae": 0.2803469512926871,
            "precision": 0.7404255319148936,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7363097386773292,
            "auditor_fn_violation": 0.010491478186300788,
            "auditor_fp_violation": 0.019244593074134266,
            "ave_precision_score": 0.7339806552467243,
            "fpr": 0.16228070175438597,
            "logloss": 1.56063289626156,
            "mae": 0.292332659212701,
            "precision": 0.7212806026365348,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.745865648918519,
            "auditor_fn_violation": 0.006948906217030625,
            "auditor_fp_violation": 0.010396248235847578,
            "ave_precision_score": 0.7445982003837339,
            "fpr": 0.132821075740944,
            "logloss": 1.2680669687869586,
            "mae": 0.2820731283099513,
            "precision": 0.7430997876857749,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8202855084555317,
            "auditor_fn_violation": 0.007603976846392972,
            "auditor_fp_violation": 0.013647539275742804,
            "ave_precision_score": 0.8215728990311143,
            "fpr": 0.14583333333333334,
            "logloss": 0.9525161980148702,
            "mae": 0.28304539583984334,
            "precision": 0.7417475728155339,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7830874520945501,
            "auditor_fn_violation": 0.006858814631821774,
            "auditor_fp_violation": 0.015054100674298267,
            "ave_precision_score": 0.7844524093376184,
            "fpr": 0.14050493962678376,
            "logloss": 1.0582246743148533,
            "mae": 0.28298812754294156,
            "precision": 0.732776617954071,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8447066109837761,
            "auditor_fn_violation": 0.013517436667023975,
            "auditor_fp_violation": 0.01776784598074759,
            "ave_precision_score": 0.8449119796473769,
            "fpr": 0.14692982456140352,
            "logloss": 0.8671193164831259,
            "mae": 0.2762196208430208,
            "precision": 0.7408123791102514,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7981627864598876,
            "auditor_fn_violation": 0.005609386594846291,
            "auditor_fp_violation": 0.013956405833464013,
            "ave_precision_score": 0.7988929377787093,
            "fpr": 0.14050493962678376,
            "logloss": 0.9252296336516341,
            "mae": 0.28401333051306943,
            "precision": 0.7322175732217573,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.82903300093856,
            "auditor_fn_violation": 0.009555775895951697,
            "auditor_fp_violation": 0.02158082260282536,
            "ave_precision_score": 0.8293025202861304,
            "fpr": 0.14802631578947367,
            "logloss": 0.9375844718488668,
            "mae": 0.2788053563789413,
            "precision": 0.7388781431334622,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.795447322318307,
            "auditor_fn_violation": 0.011439260490335314,
            "auditor_fp_violation": 0.013299749098322095,
            "ave_precision_score": 0.7960295417495962,
            "fpr": 0.14489571899012074,
            "logloss": 1.0032929290476134,
            "mae": 0.28474314840298615,
            "precision": 0.7272727272727273,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7525132382315661,
            "auditor_fn_violation": 0.012827384142637652,
            "auditor_fp_violation": 0.019406071592282373,
            "ave_precision_score": 0.7338630691289169,
            "fpr": 0.15789473684210525,
            "logloss": 2.001452515555286,
            "mae": 0.2888696363474674,
            "precision": 0.7298311444652908,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7620054299092338,
            "auditor_fn_violation": 0.004753516535362137,
            "auditor_fp_violation": 0.011040653912498043,
            "ave_precision_score": 0.7470060168297796,
            "fpr": 0.13721185510428102,
            "logloss": 1.7536031053613723,
            "mae": 0.2804781368030284,
            "precision": 0.7368421052631579,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8413619674258224,
            "auditor_fn_violation": 0.007644174080823244,
            "auditor_fp_violation": 0.016379651623119565,
            "ave_precision_score": 0.8415938871167539,
            "fpr": 0.13486842105263158,
            "logloss": 0.9182830819526142,
            "mae": 0.2787285371449383,
            "precision": 0.7544910179640718,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8103355734596245,
            "auditor_fn_violation": 0.005851211376196381,
            "auditor_fp_violation": 0.013946604986670857,
            "ave_precision_score": 0.8108433018160465,
            "fpr": 0.12733260153677278,
            "logloss": 0.9994717081810126,
            "mae": 0.2781550192951988,
            "precision": 0.7510729613733905,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 21924,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7991868355818936,
            "auditor_fn_violation": 0.01273805695501483,
            "auditor_fp_violation": 0.019057069633704214,
            "ave_precision_score": 0.7685956655579526,
            "fpr": 0.14692982456140352,
            "logloss": 2.2723272640661416,
            "mae": 0.2804420960711197,
            "precision": 0.7554744525547445,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.7977334807534509,
            "auditor_fn_violation": 0.012759813463001996,
            "auditor_fp_violation": 0.010408499294339043,
            "ave_precision_score": 0.7758990633080887,
            "fpr": 0.14928649835345773,
            "logloss": 1.85613567349966,
            "mae": 0.2760305408256499,
            "precision": 0.7429111531190926,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8364817885293884,
            "auditor_fn_violation": 0.021480955443598813,
            "auditor_fp_violation": 0.023594095095220237,
            "ave_precision_score": 0.8366758947227452,
            "fpr": 0.1206140350877193,
            "logloss": 1.0115087316103812,
            "mae": 0.28480822504993597,
            "precision": 0.7669491525423728,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8140137262209732,
            "auditor_fn_violation": 0.015455448525698625,
            "auditor_fp_violation": 0.018508899168888194,
            "ave_precision_score": 0.8142418724930287,
            "fpr": 0.1119648737650933,
            "logloss": 1.1498380246190605,
            "mae": 0.28439606244395643,
            "precision": 0.7611241217798594,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8257540002989012,
            "auditor_fn_violation": 0.00796575195626541,
            "auditor_fp_violation": 0.021463620452556578,
            "ave_precision_score": 0.8260329560850628,
            "fpr": 0.15679824561403508,
            "logloss": 0.9332448092904171,
            "mae": 0.28268603963066163,
            "precision": 0.7270992366412213,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7944869310119269,
            "auditor_fn_violation": 0.00168803180707124,
            "auditor_fp_violation": 0.018717167163242912,
            "ave_precision_score": 0.7950852789052962,
            "fpr": 0.1394072447859495,
            "logloss": 0.9843234246621058,
            "mae": 0.2838943969444483,
            "precision": 0.7348643006263048,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7398339303029898,
            "auditor_fn_violation": 0.012726891056561974,
            "auditor_fp_violation": 0.021815226903362926,
            "ave_precision_score": 0.7374549074112959,
            "fpr": 0.15679824561403508,
            "logloss": 1.5531825363213214,
            "mae": 0.29224755201472413,
            "precision": 0.7239382239382239,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.746325088231181,
            "auditor_fn_violation": 0.008684354647896011,
            "auditor_fp_violation": 0.009173592598400506,
            "ave_precision_score": 0.7443128551871635,
            "fpr": 0.13172338090010977,
            "logloss": 1.2552713131667603,
            "mae": 0.2823110091341398,
            "precision": 0.7419354838709677,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8357949769871285,
            "auditor_fn_violation": 0.006156876406903206,
            "auditor_fp_violation": 0.013829853731716461,
            "ave_precision_score": 0.835884463986707,
            "fpr": 0.3256578947368421,
            "logloss": 1.5034872664662966,
            "mae": 0.3509476870239462,
            "precision": 0.610236220472441,
            "recall": 0.9470468431771895
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.8126202614432845,
            "auditor_fn_violation": 0.008938033585194634,
            "auditor_fp_violation": 0.01914105378704719,
            "ave_precision_score": 0.8127541704409518,
            "fpr": 0.3380900109769484,
            "logloss": 1.474255197720181,
            "mae": 0.36839872982801475,
            "precision": 0.5815217391304348,
            "recall": 0.9244060475161987
        }
    }
]