[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.698309256770974,
            "mae": 0.5007272303888672,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.7020766999899404,
            "mae": 0.5025657602513268,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 871,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5097026438856656,
            "auditor_fn_violation": 0.007939539709488776,
            "auditor_fp_violation": 0.008928921857215746,
            "ave_precision_score": 0.5226136280202749,
            "fpr": 0.015350877192982455,
            "logloss": 0.6998998280755444,
            "mae": 0.500236385714328,
            "precision": 0.48148148148148145,
            "recall": 0.02795698924731183
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.6113886626111398,
            "auditor_fn_violation": 0.00884890196844296,
            "auditor_fp_violation": 0.0059462805832869465,
            "ave_precision_score": 0.5495301507058011,
            "fpr": 0.009879253567508232,
            "logloss": 0.7023394322751056,
            "mae": 0.5015040445013705,
            "precision": 0.6666666666666666,
            "recall": 0.03680981595092025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 871,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6690139837344942,
            "auditor_fn_violation": 0.014348707790982837,
            "auditor_fp_violation": 0.04466178028965031,
            "ave_precision_score": 0.6597622893054552,
            "fpr": 0.17434210526315788,
            "logloss": 2.0697274067813685,
            "mae": 0.30790404547828143,
            "precision": 0.6906614785992218,
            "recall": 0.7634408602150538
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7152057111966117,
            "auditor_fn_violation": 0.011724458391978073,
            "auditor_fp_violation": 0.027333121771294506,
            "ave_precision_score": 0.703117849735384,
            "fpr": 0.15367727771679474,
            "logloss": 1.8746980548664927,
            "mae": 0.3003719026988609,
            "precision": 0.7265625,
            "recall": 0.7607361963190185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.47644440667713017,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.4769200334166108,
            "fpr": 0.03179824561403509,
            "logloss": 0.6968889530753164,
            "mae": 0.5007705669196552,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5139679398368475,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5156018908331302,
            "fpr": 0.03402854006586169,
            "logloss": 0.698540596071672,
            "mae": 0.5015430263643338,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6968417638486136,
            "mae": 0.5004967121701491,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.6993819283287844,
            "mae": 0.5017049801336554,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 871,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7776484546066934,
            "auditor_fn_violation": 0.0073335219769854795,
            "auditor_fp_violation": 0.011011519290396017,
            "ave_precision_score": 0.7780575513852821,
            "fpr": 0.18530701754385964,
            "logloss": 0.6993165944671663,
            "mae": 0.3584991460482247,
            "precision": 0.692167577413479,
            "recall": 0.8172043010752689
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8033788913741322,
            "auditor_fn_violation": 0.019132214986565026,
            "auditor_fp_violation": 0.010737640528350184,
            "ave_precision_score": 0.8036488734897219,
            "fpr": 0.16465422612513722,
            "logloss": 0.6638433904211968,
            "mae": 0.3574287071701397,
            "precision": 0.7109826589595376,
            "recall": 0.754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 871,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8025871155452731,
            "auditor_fn_violation": 0.025660252782493887,
            "auditor_fp_violation": 0.006130048275050042,
            "ave_precision_score": 0.6651347998338951,
            "fpr": 0.017543859649122806,
            "logloss": 0.6000084889500942,
            "mae": 0.424030599821555,
            "precision": 0.9148936170212766,
            "recall": 0.36989247311827955
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8239144685078857,
            "auditor_fn_violation": 0.03162438633470939,
            "auditor_fp_violation": 0.001976891182545092,
            "ave_precision_score": 0.6911110585548399,
            "fpr": 0.013172338090010977,
            "logloss": 0.5930788771319317,
            "mae": 0.42181975830399504,
            "precision": 0.9365079365079365,
            "recall": 0.3619631901840491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 871,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7941668664739931,
            "auditor_fn_violation": 0.005956423316355407,
            "auditor_fp_violation": 0.013982102908277408,
            "ave_precision_score": 0.7944126921815235,
            "fpr": 0.21600877192982457,
            "logloss": 0.8856074585737673,
            "mae": 0.37310982832129586,
            "precision": 0.6738410596026491,
            "recall": 0.875268817204301
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7896416153580061,
            "auditor_fn_violation": 0.008328114232096239,
            "auditor_fp_violation": 0.022682225147096315,
            "ave_precision_score": 0.790046185379929,
            "fpr": 0.17892425905598244,
            "logloss": 0.8704593710278552,
            "mae": 0.35840930290004946,
            "precision": 0.7140350877192982,
            "recall": 0.8323108384458078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5192055339072422,
            "auditor_fn_violation": 0.006734578381437477,
            "auditor_fp_violation": 0.006130048275050042,
            "ave_precision_score": 0.509336177946643,
            "fpr": 0.029605263157894735,
            "logloss": 0.6986527755751153,
            "mae": 0.5006788906298185,
            "precision": 0.5,
            "recall": 0.05806451612903226
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0.5320708437821278,
            "auditor_fn_violation": 0.005288689253589962,
            "auditor_fp_violation": 0.004252917215080558,
            "ave_precision_score": 0.5342658766784095,
            "fpr": 0.031833150384193196,
            "logloss": 0.7030838331449255,
            "mae": 0.5027532035773201,
            "precision": 0.5,
            "recall": 0.05930470347648262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.69695520392392,
            "mae": 0.500515208236481,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.699593788844814,
            "mae": 0.501773404368454,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5143458717631044,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5099762538429772,
            "fpr": 0.03179824561403509,
            "logloss": 0.6993352082581201,
            "mae": 0.5008770441146273,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5403602799298219,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5347017978899616,
            "fpr": 0.03402854006586169,
            "logloss": 0.7035247475946348,
            "mae": 0.5029186642392407,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 871,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.830874831649332,
            "auditor_fn_violation": 0.00484578381437465,
            "auditor_fp_violation": 0.004253502884728603,
            "ave_precision_score": 0.8191547990689931,
            "fpr": 0.07894736842105263,
            "logloss": 0.517088553759235,
            "mae": 0.3377190803692333,
            "precision": 0.8153846153846154,
            "recall": 0.6838709677419355
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8648954182110128,
            "auditor_fn_violation": 0.01041575472693438,
            "auditor_fp_violation": 0.005335005020263134,
            "ave_precision_score": 0.8538859013744167,
            "fpr": 0.04939626783754116,
            "logloss": 0.5755309617386352,
            "mae": 0.33290349530581553,
            "precision": 0.8767123287671232,
            "recall": 0.65439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7523465266158172,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6675607898790461,
            "fpr": 0.08442982456140351,
            "logloss": 0.668659235630834,
            "mae": 0.4089133233289447,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7713049014898183,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.6882826461051441,
            "fpr": 0.07903402854006586,
            "logloss": 0.6599525820678528,
            "mae": 0.4037404553361572,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7319241918244748,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6811567312030824,
            "fpr": 0.08442982456140351,
            "logloss": 0.6725514271999377,
            "mae": 0.41166749681558523,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7452134092218754,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.6998941803207409,
            "fpr": 0.07903402854006586,
            "logloss": 0.6609242356983895,
            "mae": 0.4058958875622629,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 871,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7788872608874081,
            "auditor_fn_violation": 0.0065082059988681405,
            "auditor_fp_violation": 0.008722869814356937,
            "ave_precision_score": 0.744351492535804,
            "fpr": 0.26206140350877194,
            "logloss": 2.419413846860083,
            "mae": 0.38056899992781773,
            "precision": 0.6323076923076923,
            "recall": 0.8838709677419355
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7838053131510577,
            "auditor_fn_violation": 0.007805081721023889,
            "auditor_fp_violation": 0.01655386248120653,
            "ave_precision_score": 0.7490178787512144,
            "fpr": 0.20636663007683864,
            "logloss": 2.4587647555508707,
            "mae": 0.3721320660852313,
            "precision": 0.6877076411960132,
            "recall": 0.8466257668711656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 871,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8025871155452731,
            "auditor_fn_violation": 0.025660252782493887,
            "auditor_fp_violation": 0.006130048275050042,
            "ave_precision_score": 0.6651347998338951,
            "fpr": 0.017543859649122806,
            "logloss": 0.6000084833009733,
            "mae": 0.4240305964557225,
            "precision": 0.9148936170212766,
            "recall": 0.36989247311827955
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8239144685078857,
            "auditor_fn_violation": 0.03162438633470939,
            "auditor_fp_violation": 0.001976891182545092,
            "ave_precision_score": 0.6911110585548399,
            "fpr": 0.013172338090010977,
            "logloss": 0.5930788686007124,
            "mae": 0.42181975388762455,
            "precision": 0.9365079365079365,
            "recall": 0.3619631901840491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 871,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.4010267225927137,
            "auditor_fn_violation": 0.0024287870213167305,
            "auditor_fp_violation": 0.00152331331684917,
            "ave_precision_score": 0.5133541635829201,
            "fpr": 0.003289473684210526,
            "logloss": 17.28762200924387,
            "mae": 0.511493489618021,
            "precision": 0.625,
            "recall": 0.010752688172043012
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.3686692686961778,
            "auditor_fn_violation": 0.0010393306979678163,
            "auditor_fp_violation": 0.0016725539873374917,
            "ave_precision_score": 0.5383204396342355,
            "fpr": 0.005488474204171241,
            "logloss": 18.330837954885197,
            "mae": 0.5417860025206722,
            "precision": 0.4444444444444444,
            "recall": 0.0081799591002045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7644896779114687,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6421163357200856,
            "fpr": 0.08442982456140351,
            "logloss": 0.6877473042112213,
            "mae": 0.415947132792912,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7806912952296265,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.6652108859074415,
            "fpr": 0.07903402854006586,
            "logloss": 0.6702895581959921,
            "mae": 0.4086823555693014,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 871,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7573431217794662,
            "auditor_fn_violation": 0.01265563101301641,
            "auditor_fp_violation": 0.021341104438949737,
            "ave_precision_score": 0.7578063715950227,
            "fpr": 0.15789473684210525,
            "logloss": 0.8448514681730972,
            "mae": 0.38051916510193495,
            "precision": 0.7159763313609467,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7442599884098163,
            "auditor_fn_violation": 0.01630828838171946,
            "auditor_fp_violation": 0.012012215106570048,
            "ave_precision_score": 0.7458850400192516,
            "fpr": 0.14928649835345773,
            "logloss": 0.8884084116504054,
            "mae": 0.374348624935527,
            "precision": 0.7296222664015904,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 871,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.5245109214515112,
            "auditor_fn_violation": 0.005897472175061311,
            "auditor_fp_violation": 0.006130048275050042,
            "ave_precision_score": 0.5103678914863756,
            "fpr": 0.029605263157894735,
            "logloss": 0.6976681059910583,
            "mae": 0.5003345948235508,
            "precision": 0.509090909090909,
            "recall": 0.060215053763440864
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0.532868674832269,
            "auditor_fn_violation": 0.0063347542757346675,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5339658491813811,
            "fpr": 0.03402854006586169,
            "logloss": 0.7024626791373949,
            "mae": 0.502723712919834,
            "precision": 0.5,
            "recall": 0.06339468302658487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 871,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6722116068770743,
            "auditor_fn_violation": 0.013117807960762121,
            "auditor_fp_violation": 0.041593076651359945,
            "ave_precision_score": 0.6630582956634304,
            "fpr": 0.19078947368421054,
            "logloss": 2.023668524476036,
            "mae": 0.3046734582498848,
            "precision": 0.6836363636363636,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7217736965561691,
            "auditor_fn_violation": 0.01327335295266444,
            "auditor_fp_violation": 0.024154488843570687,
            "ave_precision_score": 0.7103363918007797,
            "fpr": 0.1712403951701427,
            "logloss": 1.7833375405501009,
            "mae": 0.294679029607342,
            "precision": 0.7132352941176471,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 871,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7189437031875795,
            "auditor_fn_violation": 0.009210526315789478,
            "auditor_fp_violation": 0.011372110365398959,
            "ave_precision_score": 0.7197021772062275,
            "fpr": 0.19298245614035087,
            "logloss": 0.8894254213405879,
            "mae": 0.3719622354378532,
            "precision": 0.6788321167883211,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7371565057118735,
            "auditor_fn_violation": 0.014604504364964455,
            "auditor_fp_violation": 0.018135375427242608,
            "ave_precision_score": 0.7378949912710953,
            "fpr": 0.1734357848518112,
            "logloss": 0.8431624701977566,
            "mae": 0.3679241254091525,
            "precision": 0.7024482109227872,
            "recall": 0.7627811860940695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 871,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7750488977309279,
            "auditor_fn_violation": 0.005161761931711019,
            "auditor_fp_violation": 0.0024431885081832097,
            "ave_precision_score": 0.7753756470691279,
            "fpr": 0.039473684210526314,
            "logloss": 0.6079584193373908,
            "mae": 0.4249159587514505,
            "precision": 0.8625954198473282,
            "recall": 0.4860215053763441
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8088231546847432,
            "auditor_fn_violation": 0.0070441030890344945,
            "auditor_fp_violation": 0.0029289203572970693,
            "ave_precision_score": 0.8090322412284887,
            "fpr": 0.026344676180021953,
            "logloss": 0.5844648307386492,
            "mae": 0.42106971756425304,
            "precision": 0.9043824701195219,
            "recall": 0.46421267893660534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 871,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8085444043500188,
            "auditor_fn_violation": 0.005708828522920207,
            "auditor_fp_violation": 0.009419521959260572,
            "ave_precision_score": 0.8090868829161985,
            "fpr": 0.1074561403508772,
            "logloss": 0.5873630722028904,
            "mae": 0.4072555052279903,
            "precision": 0.7694117647058824,
            "recall": 0.7032258064516129
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8383988941147158,
            "auditor_fn_violation": 0.004588319539192656,
            "auditor_fp_violation": 0.008984450190145718,
            "ave_precision_score": 0.8385984294877243,
            "fpr": 0.09440175631174534,
            "logloss": 0.5610862415827319,
            "mae": 0.40163568862837573,
            "precision": 0.7957244655581948,
            "recall": 0.6850715746421268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 871,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7895030917128648,
            "auditor_fn_violation": 0.025660252782493887,
            "auditor_fp_violation": 0.006130048275050042,
            "ave_precision_score": 0.7898558624291617,
            "fpr": 0.017543859649122806,
            "logloss": 0.6033580509416645,
            "mae": 0.4214534508227779,
            "precision": 0.9148936170212766,
            "recall": 0.36989247311827955
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.8097305064143108,
            "auditor_fn_violation": 0.030504243746618826,
            "auditor_fp_violation": 0.001976891182545092,
            "ave_precision_score": 0.80993724408259,
            "fpr": 0.013172338090010977,
            "logloss": 0.5844773040813188,
            "mae": 0.41969366527022434,
            "precision": 0.9368421052631579,
            "recall": 0.36400817995910023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 871,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6608051808649044,
            "auditor_fn_violation": 0.03201754385964913,
            "auditor_fp_violation": 0.044279112210055344,
            "ave_precision_score": 0.6526402026395413,
            "fpr": 0.16228070175438597,
            "logloss": 2.012838089865162,
            "mae": 0.3161936898396517,
            "precision": 0.6973415132924335,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7070392727641444,
            "auditor_fn_violation": 0.02664323121853107,
            "auditor_fp_violation": 0.03540195920320881,
            "ave_precision_score": 0.6965979550129954,
            "fpr": 0.15367727771679474,
            "logloss": 1.7367390589335645,
            "mae": 0.30808905267341524,
            "precision": 0.7194388777555111,
            "recall": 0.7341513292433538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 871,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6729361163175467,
            "auditor_fn_violation": 0.014636389360498022,
            "auditor_fp_violation": 0.03920876015542211,
            "ave_precision_score": 0.6637662104470144,
            "fpr": 0.19298245614035087,
            "logloss": 2.0013955648143282,
            "mae": 0.30333200488267115,
            "precision": 0.6840215439856373,
            "recall": 0.8193548387096774
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7217606532283847,
            "auditor_fn_violation": 0.016128706403668865,
            "auditor_fp_violation": 0.024133679462701788,
            "ave_precision_score": 0.7104897729342413,
            "fpr": 0.17233809001097694,
            "logloss": 1.7620484095631272,
            "mae": 0.29332925846486685,
            "precision": 0.7135036496350365,
            "recall": 0.7995910020449898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 871,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6376198742898251,
            "auditor_fn_violation": 0.016409639690624415,
            "auditor_fp_violation": 0.045711664508026224,
            "ave_precision_score": 0.6288548913322818,
            "fpr": 0.18969298245614036,
            "logloss": 2.0095804817077068,
            "mae": 0.33680416098288474,
            "precision": 0.674812030075188,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6901562852559986,
            "auditor_fn_violation": 0.019565456508612078,
            "auditor_fp_violation": 0.030001924867730373,
            "ave_precision_score": 0.6801287137997254,
            "fpr": 0.1668496158068057,
            "logloss": 1.6366048309793622,
            "mae": 0.3209613094442276,
            "precision": 0.7054263565891473,
            "recall": 0.7443762781186094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 871,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.778660140150139,
            "auditor_fn_violation": 0.0019453876627051501,
            "auditor_fp_violation": 0.002399034498999196,
            "ave_precision_score": 0.6600598973795524,
            "fpr": 0.48135964912280704,
            "logloss": 0.6662513467355065,
            "mae": 0.418565540656186,
            "precision": 0.5116796440489433,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7809222708803407,
            "auditor_fn_violation": 0.001185241055133912,
            "auditor_fp_violation": 0.0010508737338792435,
            "ave_precision_score": 0.666728544204596,
            "fpr": 0.4610318331503842,
            "logloss": 0.6641128172501056,
            "mae": 0.41719444032296393,
            "precision": 0.5369349503858876,
            "recall": 0.9959100204498977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 871,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7849229628652836,
            "auditor_fn_violation": 0.018956328994529335,
            "auditor_fp_violation": 0.021503002472624523,
            "ave_precision_score": 0.7853412204105389,
            "fpr": 0.20723684210526316,
            "logloss": 0.7307130834472446,
            "mae": 0.3720939011035258,
            "precision": 0.671304347826087,
            "recall": 0.8301075268817204
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.797076911247065,
            "auditor_fn_violation": 0.027597260476924842,
            "auditor_fp_violation": 0.017755604226385262,
            "ave_precision_score": 0.797379421749844,
            "fpr": 0.21295279912184412,
            "logloss": 0.7111635273899503,
            "mae": 0.37741417948945816,
            "precision": 0.662608695652174,
            "recall": 0.7791411042944786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 871,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7788951514291852,
            "auditor_fn_violation": 0.005234861346915676,
            "auditor_fp_violation": 0.022018132579771584,
            "ave_precision_score": 0.7443502551339779,
            "fpr": 0.27850877192982454,
            "logloss": 2.419459834977062,
            "mae": 0.3807071212090944,
            "precision": 0.6203288490284006,
            "recall": 0.8924731182795699
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7838748363141295,
            "auditor_fn_violation": 0.005966611220730948,
            "auditor_fp_violation": 0.020908225428022956,
            "ave_precision_score": 0.7490882157045355,
            "fpr": 0.21734357848518113,
            "logloss": 2.4587239590103804,
            "mae": 0.37223142984146346,
            "precision": 0.6780487804878049,
            "recall": 0.852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 871,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7792786458900408,
            "auditor_fn_violation": 0.0019453876627051501,
            "auditor_fp_violation": 0.002399034498999196,
            "ave_precision_score": 0.661296908859356,
            "fpr": 0.48135964912280704,
            "logloss": 0.6699582416061494,
            "mae": 0.41911429490305874,
            "precision": 0.5116796440489433,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.781521741759506,
            "auditor_fn_violation": 0.001185241055133912,
            "auditor_fp_violation": 0.0010508737338792435,
            "ave_precision_score": 0.6684152238161039,
            "fpr": 0.4610318331503842,
            "logloss": 0.6671682633450953,
            "mae": 0.4174106442313294,
            "precision": 0.5369349503858876,
            "recall": 0.9959100204498977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 871,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6651250783148326,
            "auditor_fn_violation": 0.016775136766647804,
            "auditor_fp_violation": 0.042147454766670596,
            "ave_precision_score": 0.6568751825917802,
            "fpr": 0.18201754385964913,
            "logloss": 1.8952202235318558,
            "mae": 0.3115497763955669,
            "precision": 0.6885553470919324,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7092184276858489,
            "auditor_fn_violation": 0.015466497859607306,
            "auditor_fp_violation": 0.02861289869473159,
            "ave_precision_score": 0.6989281187526637,
            "fpr": 0.16794731064763996,
            "logloss": 1.6161048883341378,
            "mae": 0.30566600610967753,
            "precision": 0.7124060150375939,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 871,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.4010267225927137,
            "auditor_fn_violation": 0.0034521788341822387,
            "auditor_fp_violation": 0.002011460418383767,
            "ave_precision_score": 0.5133541635829201,
            "fpr": 0.0043859649122807015,
            "logloss": 17.288629953221882,
            "mae": 0.5122079898178447,
            "precision": 0.6,
            "recall": 0.012903225806451613
        },
        "train": {
            "accuracy": 0.4610318331503842,
            "auc_prc": 0.3686692686961778,
            "auditor_fn_violation": 0.0010393306979678163,
            "auditor_fp_violation": 0.002398281145140229,
            "ave_precision_score": 0.5383204396342355,
            "fpr": 0.006586169045005488,
            "logloss": 18.332418308597187,
            "mae": 0.5426543552007294,
            "precision": 0.4,
            "recall": 0.0081799591002045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6963368381286802,
            "mae": 0.5004144459962845,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.6984389502914148,
            "mae": 0.5014022034557146,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6971793092063611,
            "mae": 0.5005504781086194,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.7000055756369961,
            "mae": 0.5019039441018676,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 871,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6630838308651594,
            "auditor_fn_violation": 0.017673552159969814,
            "auditor_fp_violation": 0.04597168256210997,
            "ave_precision_score": 0.6548358470058346,
            "fpr": 0.17763157894736842,
            "logloss": 1.822874062072416,
            "mae": 0.31975880296726755,
            "precision": 0.6908396946564885,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7057708710039046,
            "auditor_fn_violation": 0.015390175518935803,
            "auditor_fp_violation": 0.03536294161407963,
            "ave_precision_score": 0.69665648167641,
            "fpr": 0.15477497255762898,
            "logloss": 1.4771057526624558,
            "mae": 0.3139323383540302,
            "precision": 0.724609375,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 871,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6584144022519254,
            "auditor_fn_violation": 0.01193406904357669,
            "auditor_fp_violation": 0.04258408885749048,
            "ave_precision_score": 0.6492140027242935,
            "fpr": 0.18530701754385964,
            "logloss": 2.0914989542970135,
            "mae": 0.31756103244339096,
            "precision": 0.6817325800376648,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7030283750377023,
            "auditor_fn_violation": 0.013688636276906436,
            "auditor_fp_violation": 0.02382153874966835,
            "ave_precision_score": 0.6914555186310286,
            "fpr": 0.1712403951701427,
            "logloss": 1.8893151957127114,
            "mae": 0.31023674676706936,
            "precision": 0.7039848197343453,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 871,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.6974629226317908,
            "auditor_fn_violation": 0.006802961705338619,
            "auditor_fp_violation": 0.01397229090623651,
            "ave_precision_score": 0.7017772662824434,
            "fpr": 0.18859649122807018,
            "logloss": 0.9150921233139236,
            "mae": 0.347589623166673,
            "precision": 0.6966490299823633,
            "recall": 0.8494623655913979
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.760070874321678,
            "auditor_fn_violation": 0.010209235452176202,
            "auditor_fp_violation": 0.014956742499518786,
            "ave_precision_score": 0.7624169539604224,
            "fpr": 0.1690450054884742,
            "logloss": 0.738453522322136,
            "mae": 0.33247527313284764,
            "precision": 0.7264653641207816,
            "recall": 0.83640081799591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.4706752208917272,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.4877388295920663,
            "fpr": 0.03179824561403509,
            "logloss": 0.697266326170431,
            "mae": 0.5005376749067453,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5056803950139276,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5134841059179333,
            "fpr": 0.03402854006586169,
            "logloss": 0.7002472613145788,
            "mae": 0.5019633578940097,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 871,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8284160978481174,
            "auditor_fn_violation": 0.00484578381437465,
            "auditor_fp_violation": 0.004253502884728603,
            "ave_precision_score": 0.8282413098168477,
            "fpr": 0.07894736842105263,
            "logloss": 0.517801600505888,
            "mae": 0.33994356638408807,
            "precision": 0.8153846153846154,
            "recall": 0.6838709677419355
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8638781676252548,
            "auditor_fn_violation": 0.01041575472693438,
            "auditor_fp_violation": 0.006981547281514508,
            "ave_precision_score": 0.8635217283297041,
            "fpr": 0.050493962678375415,
            "logloss": 0.5813586788839903,
            "mae": 0.3349053138370178,
            "precision": 0.8743169398907104,
            "recall": 0.65439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6971793092063611,
            "mae": 0.5005504781086194,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.7000055756369961,
            "mae": 0.5019039441018676,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 871,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6585194768425331,
            "auditor_fn_violation": 0.033738917185436715,
            "auditor_fp_violation": 0.04334451901565996,
            "ave_precision_score": 0.6497280478615706,
            "fpr": 0.17434210526315788,
            "logloss": 2.091860169669458,
            "mae": 0.31797323977597214,
            "precision": 0.6832669322709163,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7054645207964871,
            "auditor_fn_violation": 0.027828472273664983,
            "auditor_fp_violation": 0.03600283007579817,
            "ave_precision_score": 0.6947733689688028,
            "fpr": 0.15697036223929747,
            "logloss": 1.7997425840615817,
            "mae": 0.30785457949923667,
            "precision": 0.718503937007874,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.4786556464267925,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.47620850313352925,
            "fpr": 0.03179824561403509,
            "logloss": 0.6971937108484785,
            "mae": 0.5005887296508279,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5140935224912783,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.513255700320634,
            "fpr": 0.03402854006586169,
            "logloss": 0.7001555912874425,
            "mae": 0.5020198759210882,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6818094049063134,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6737040063295616,
            "fpr": 0.08442982456140351,
            "logloss": 0.6712601794301646,
            "mae": 0.41821619998990445,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7158328625492216,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.7101262879588693,
            "fpr": 0.07903402854006586,
            "logloss": 0.654100284243976,
            "mae": 0.41053985685731653,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6818471336367415,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6737794637904182,
            "fpr": 0.08442982456140351,
            "logloss": 0.6597686018888849,
            "mae": 0.42266120944629637,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7158424534035011,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.7101356444106077,
            "fpr": 0.07903402854006586,
            "logloss": 0.6438799519590889,
            "mae": 0.41524197274060465,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 871,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.784633242591854,
            "auditor_fn_violation": 0.01935483870967742,
            "auditor_fp_violation": 0.021090898386906868,
            "ave_precision_score": 0.785054499311363,
            "fpr": 0.20833333333333334,
            "logloss": 0.742774452198967,
            "mae": 0.3729109675051612,
            "precision": 0.6707105719237435,
            "recall": 0.832258064516129
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7975198558910634,
            "auditor_fn_violation": 0.028048460196776957,
            "auditor_fp_violation": 0.019095208119820423,
            "ave_precision_score": 0.7978173280645029,
            "fpr": 0.21405049396267836,
            "logloss": 0.7202037839619307,
            "mae": 0.37781109331271784,
            "precision": 0.6620450606585788,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 871,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8148676554617216,
            "auditor_fn_violation": 0.005022637238256938,
            "auditor_fp_violation": 0.008185662702617846,
            "ave_precision_score": 0.8151029476965765,
            "fpr": 0.11732456140350878,
            "logloss": 0.5929535321378968,
            "mae": 0.33859483543129865,
            "precision": 0.7658643326039387,
            "recall": 0.7526881720430108
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8355389309473881,
            "auditor_fn_violation": 0.009908435638941455,
            "auditor_fp_violation": 0.005540497656343483,
            "ave_precision_score": 0.8352050238806521,
            "fpr": 0.09549945115257959,
            "logloss": 0.7879882226014795,
            "mae": 0.33742511425367683,
            "precision": 0.8031674208144797,
            "recall": 0.7259713701431493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 871,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6526609855541206,
            "auditor_fn_violation": 0.013490379173740807,
            "auditor_fp_violation": 0.04369039208760155,
            "ave_precision_score": 0.64379191501828,
            "fpr": 0.23903508771929824,
            "logloss": 2.1424835879186075,
            "mae": 0.3542983711172782,
            "precision": 0.6378737541528239,
            "recall": 0.8258064516129032
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6973578780594902,
            "auditor_fn_violation": 0.013165603765834083,
            "auditor_fp_violation": 0.029866663892082552,
            "ave_precision_score": 0.6857845143378674,
            "fpr": 0.21075740944017562,
            "logloss": 1.8686303017201482,
            "mae": 0.3425227522756799,
            "precision": 0.673469387755102,
            "recall": 0.8098159509202454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 871,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.780805137198819,
            "auditor_fn_violation": 0.0009620826259196373,
            "auditor_fp_violation": 0.011629675418972493,
            "ave_precision_score": 0.7196725913825455,
            "fpr": 0.37609649122807015,
            "logloss": 3.3810725703302076,
            "mae": 0.38393579024756164,
            "precision": 0.5658227848101266,
            "recall": 0.9612903225806452
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7943292694443445,
            "auditor_fn_violation": 0.009003791424511593,
            "auditor_fp_violation": 0.009494280021433666,
            "ave_precision_score": 0.7378965837204929,
            "fpr": 0.3512623490669594,
            "logloss": 3.1907550092493104,
            "mae": 0.37541415989726096,
            "precision": 0.5907928388746803,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 871,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.719017741421798,
            "auditor_fn_violation": 0.006246462931522358,
            "auditor_fp_violation": 0.011372110365398959,
            "ave_precision_score": 0.7197858339272698,
            "fpr": 0.19298245614035087,
            "logloss": 0.9068956603838227,
            "mae": 0.3706205606873131,
            "precision": 0.6764705882352942,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7378703268138416,
            "auditor_fn_violation": 0.014604504364964455,
            "auditor_fp_violation": 0.016301548738171173,
            "ave_precision_score": 0.7386060822560131,
            "fpr": 0.17233809001097694,
            "logloss": 0.8602811578357464,
            "mae": 0.3663227251566268,
            "precision": 0.7037735849056603,
            "recall": 0.7627811860940695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 871,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.652500572776837,
            "auditor_fn_violation": 0.0019666100735710244,
            "auditor_fp_violation": 0.002690941559715855,
            "ave_precision_score": 0.6592241445920547,
            "fpr": 0.4451754385964912,
            "logloss": 0.7279706042210877,
            "mae": 0.42652983970025127,
            "precision": 0.5217903415783275,
            "recall": 0.9526881720430107
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6987569624823471,
            "auditor_fn_violation": 0.005360522044810193,
            "auditor_fp_violation": 0.005592521108515731,
            "ave_precision_score": 0.7007100109981458,
            "fpr": 0.4226125137211855,
            "logloss": 0.6999276718033335,
            "mae": 0.4151151023240827,
            "precision": 0.5502336448598131,
            "recall": 0.9631901840490797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.682267283452659,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6728141070487226,
            "fpr": 0.08442982456140351,
            "logloss": 0.6598332076792081,
            "mae": 0.42270118481757346,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7162922535235711,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.710081669096951,
            "fpr": 0.07903402854006586,
            "logloss": 0.6440314256966823,
            "mae": 0.4153436017350491,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 871,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.756521026014271,
            "auditor_fn_violation": 0.010116015846066783,
            "auditor_fp_violation": 0.021341104438949737,
            "ave_precision_score": 0.7568714188777457,
            "fpr": 0.15789473684210525,
            "logloss": 0.8522082343470491,
            "mae": 0.3809237210161723,
            "precision": 0.7142857142857143,
            "recall": 0.7741935483870968
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7428585204660364,
            "auditor_fn_violation": 0.014209424013253149,
            "auditor_fp_violation": 0.012012215106570048,
            "ave_precision_score": 0.7445898470542546,
            "fpr": 0.14928649835345773,
            "logloss": 0.8909987368421591,
            "mae": 0.3745160809259056,
            "precision": 0.7290836653386454,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 871,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8134009902625231,
            "auditor_fn_violation": 0.004843425768722888,
            "auditor_fp_violation": 0.011695906432748551,
            "ave_precision_score": 0.8107272560500189,
            "fpr": 0.15570175438596492,
            "logloss": 0.6076401429681361,
            "mae": 0.40516368600360136,
            "precision": 0.7263969171483622,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8352947886778425,
            "auditor_fn_violation": 0.0044424091820265375,
            "auditor_fp_violation": 0.014231015341716054,
            "ave_precision_score": 0.8353892150600515,
            "fpr": 0.12403951701427003,
            "logloss": 0.570399805937764,
            "mae": 0.39726948237576154,
            "precision": 0.7717171717171717,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 871,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7793411980855346,
            "auditor_fn_violation": 0.003478117336351636,
            "auditor_fp_violation": 0.005796440205659565,
            "ave_precision_score": 0.7284982238540992,
            "fpr": 0.18530701754385964,
            "logloss": 3.059104944054377,
            "mae": 0.37773291988853824,
            "precision": 0.6987522281639929,
            "recall": 0.843010752688172
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.786196959494858,
            "auditor_fn_violation": 0.005136044572246953,
            "auditor_fp_violation": 0.008209300752779357,
            "ave_precision_score": 0.7355979252579218,
            "fpr": 0.1668496158068057,
            "logloss": 3.0360046305474864,
            "mae": 0.36990738687086056,
            "precision": 0.7231329690346083,
            "recall": 0.8118609406952966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 871,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7750472754939507,
            "auditor_fn_violation": 0.005161761931711019,
            "auditor_fp_violation": 0.0024431885081832097,
            "ave_precision_score": 0.7753740250240232,
            "fpr": 0.039473684210526314,
            "logloss": 0.6079590845491976,
            "mae": 0.42491570562777814,
            "precision": 0.8625954198473282,
            "recall": 0.4860215053763441
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8088188640267244,
            "auditor_fn_violation": 0.0070441030890344945,
            "auditor_fp_violation": 0.0029289203572970693,
            "ave_precision_score": 0.8090279540108662,
            "fpr": 0.026344676180021953,
            "logloss": 0.5844644347955744,
            "mae": 0.42106953933916813,
            "precision": 0.9043824701195219,
            "recall": 0.46421267893660534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 871,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.757804227967228,
            "auditor_fn_violation": 0.00636672325976232,
            "auditor_fp_violation": 0.00797470465873857,
            "ave_precision_score": 0.7574627025047633,
            "fpr": 0.26206140350877194,
            "logloss": 0.6232887707429863,
            "mae": 0.43046062617775116,
            "precision": 0.5678119349005425,
            "recall": 0.6752688172043011
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7933589881194889,
            "auditor_fn_violation": 0.0026690371487769365,
            "auditor_fp_violation": 0.01427003293084523,
            "ave_precision_score": 0.7935312847261613,
            "fpr": 0.23161361141602635,
            "logloss": 0.5874777691483137,
            "mae": 0.4223914292654274,
            "precision": 0.5996204933586338,
            "recall": 0.6462167689161554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.69515197069629,
            "mae": 0.49953936027330265,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.697910645981431,
            "mae": 0.5009359118051246,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 871,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6560982219299918,
            "auditor_fn_violation": 0.033738917185436715,
            "auditor_fp_violation": 0.04579997252639428,
            "ave_precision_score": 0.6472396701996813,
            "fpr": 0.17653508771929824,
            "logloss": 2.1301381643462616,
            "mae": 0.31935616735243383,
            "precision": 0.6805555555555556,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7023460761554329,
            "auditor_fn_violation": 0.027828472273664983,
            "auditor_fp_violation": 0.03710052491663242,
            "ave_precision_score": 0.6905664883908645,
            "fpr": 0.15697036223929747,
            "logloss": 1.8773897461787494,
            "mae": 0.3096331122881326,
            "precision": 0.718503937007874,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 871,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7909997787397438,
            "auditor_fn_violation": 0.005956423316355407,
            "auditor_fp_violation": 0.013982102908277408,
            "ave_precision_score": 0.7913859452787664,
            "fpr": 0.21600877192982457,
            "logloss": 0.909654275532977,
            "mae": 0.3751484223625116,
            "precision": 0.6738410596026491,
            "recall": 0.875268817204301
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7870340198986817,
            "auditor_fn_violation": 0.008328114232096239,
            "auditor_fp_violation": 0.022682225147096315,
            "ave_precision_score": 0.7874923211229075,
            "fpr": 0.17892425905598244,
            "logloss": 0.8955322848397298,
            "mae": 0.35996995023916895,
            "precision": 0.7140350877192982,
            "recall": 0.8323108384458078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 871,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4756558454510191,
            "auditor_fn_violation": 0.001379456706281837,
            "auditor_fp_violation": 0.0025511205306330705,
            "ave_precision_score": 0.5173306157727077,
            "fpr": 0.0043859649122807015,
            "logloss": 0.69546845733802,
            "mae": 0.4997019212562264,
            "precision": 0.42857142857142855,
            "recall": 0.0064516129032258064
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.607890825738342,
            "auditor_fn_violation": 0.0010101486265345874,
            "auditor_fp_violation": 0.00043179465302958575,
            "ave_precision_score": 0.5491970942479552,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6972704219150372,
            "mae": 0.5006703076195115,
            "precision": 0.6666666666666666,
            "recall": 0.00408997955010225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 871,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7156726334752406,
            "auditor_fn_violation": 0.01594038860592341,
            "auditor_fp_violation": 0.008825895835786331,
            "ave_precision_score": 0.7083433905569968,
            "fpr": 0.08114035087719298,
            "logloss": 0.6440343207195199,
            "mae": 0.4141001448754156,
            "precision": 0.7777777777777778,
            "recall": 0.556989247311828
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7138577240537959,
            "auditor_fn_violation": 0.005454802583286765,
            "auditor_fp_violation": 0.003449154879019465,
            "ave_precision_score": 0.7067620025996825,
            "fpr": 0.08122941822173436,
            "logloss": 0.6459013438103363,
            "mae": 0.4148168241938435,
            "precision": 0.7791044776119403,
            "recall": 0.5337423312883436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 871,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5354841788864823,
            "auditor_fn_violation": 0.007939539709488776,
            "auditor_fp_violation": 0.008928921857215746,
            "ave_precision_score": 0.5378495001830711,
            "fpr": 0.015350877192982455,
            "logloss": 0.702695437353928,
            "mae": 0.5009263952573141,
            "precision": 0.48148148148148145,
            "recall": 0.02795698924731183
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.5882752631265258,
            "auditor_fn_violation": 0.00884890196844296,
            "auditor_fp_violation": 0.0059462805832869465,
            "ave_precision_score": 0.5898442287471195,
            "fpr": 0.009879253567508232,
            "logloss": 0.6985685761089672,
            "mae": 0.4991612233524134,
            "precision": 0.6666666666666666,
            "recall": 0.03680981595092025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 871,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7759742571637164,
            "auditor_fn_violation": 0.00550132050556499,
            "auditor_fp_violation": 0.014421189999607526,
            "ave_precision_score": 0.776387637886346,
            "fpr": 0.18530701754385964,
            "logloss": 0.6981160410848214,
            "mae": 0.35838103129348736,
            "precision": 0.6932849364791288,
            "recall": 0.821505376344086
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8011600762547972,
            "auditor_fn_violation": 0.020773145311002317,
            "auditor_fp_violation": 0.012329558164820703,
            "ave_precision_score": 0.8014332175598351,
            "fpr": 0.1668496158068057,
            "logloss": 0.6766880176435826,
            "mae": 0.3579476937548381,
            "precision": 0.7126654064272212,
            "recall": 0.7709611451942741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 871,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6373859195733235,
            "auditor_fn_violation": 0.015751744953782315,
            "auditor_fp_violation": 0.04319979198555673,
            "ave_precision_score": 0.6287312544166068,
            "fpr": 0.18530701754385964,
            "logloss": 1.9651840108549674,
            "mae": 0.33837631517371625,
            "precision": 0.6793168880455408,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6900745107967303,
            "auditor_fn_violation": 0.017064777464257577,
            "auditor_fp_violation": 0.02979903340425864,
            "ave_precision_score": 0.6827745595179591,
            "fpr": 0.15916575192096596,
            "logloss": 1.5101054926823863,
            "mae": 0.32508742554720005,
            "precision": 0.7134387351778656,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 871,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.783636527856607,
            "auditor_fn_violation": 0.01935483870967742,
            "auditor_fp_violation": 0.021090898386906868,
            "ave_precision_score": 0.7840610343253509,
            "fpr": 0.20833333333333334,
            "logloss": 0.7545793125627979,
            "mae": 0.37181867969532806,
            "precision": 0.6707105719237435,
            "recall": 0.832258064516129
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7974072746880377,
            "auditor_fn_violation": 0.027597260476924842,
            "auditor_fp_violation": 0.019095208119820423,
            "ave_precision_score": 0.7977024827717918,
            "fpr": 0.21405049396267836,
            "logloss": 0.730114307082095,
            "mae": 0.3770800572293519,
            "precision": 0.6614583333333334,
            "recall": 0.7791411042944786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 871,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6685819998814659,
            "auditor_fn_violation": 0.013511601584606679,
            "auditor_fp_violation": 0.04305997095647396,
            "ave_precision_score": 0.6594168210282796,
            "fpr": 0.18969298245614036,
            "logloss": 2.0119064071398434,
            "mae": 0.30858036328886707,
            "precision": 0.6813996316758748,
            "recall": 0.7956989247311828
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7161794921669913,
            "auditor_fn_violation": 0.013322737996628357,
            "auditor_fp_violation": 0.027114623272171096,
            "ave_precision_score": 0.7047212286013766,
            "fpr": 0.17014270032930845,
            "logloss": 1.7867498952989997,
            "mae": 0.2997825466440713,
            "precision": 0.7118959107806692,
            "recall": 0.7832310838445807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 871,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6626261555800196,
            "auditor_fn_violation": 0.012646198830409357,
            "auditor_fp_violation": 0.03649083559009381,
            "ave_precision_score": 0.6524865956347474,
            "fpr": 0.24561403508771928,
            "logloss": 2.22849940943999,
            "mae": 0.3221715823405524,
            "precision": 0.6427432216905901,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7067603530877004,
            "auditor_fn_violation": 0.011392231732584478,
            "auditor_fp_violation": 0.024700735091379187,
            "ave_precision_score": 0.6946901710785429,
            "fpr": 0.2261251372118551,
            "logloss": 1.986767491770249,
            "mae": 0.31041962825185343,
            "precision": 0.6698717948717948,
            "recall": 0.8548057259713702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 871,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6573275466920618,
            "auditor_fn_violation": 0.034267119411431804,
            "auditor_fp_violation": 0.04334451901565996,
            "ave_precision_score": 0.6485450940940214,
            "fpr": 0.17434210526315788,
            "logloss": 2.0965823359570797,
            "mae": 0.3189786654118082,
            "precision": 0.6826347305389222,
            "recall": 0.7354838709677419
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7046055926459455,
            "auditor_fn_violation": 0.02895085963648118,
            "auditor_fp_violation": 0.03480889184844528,
            "ave_precision_score": 0.6939153829999787,
            "fpr": 0.15916575192096596,
            "logloss": 1.8034655967958162,
            "mae": 0.308937254177299,
            "precision": 0.7162426614481409,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 871,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.6982281497550272,
            "auditor_fn_violation": 0.006802961705338619,
            "auditor_fp_violation": 0.01397229090623651,
            "ave_precision_score": 0.7031016383649199,
            "fpr": 0.18859649122807018,
            "logloss": 0.9161231472000223,
            "mae": 0.34724071192179334,
            "precision": 0.6966490299823633,
            "recall": 0.8494623655913979
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7588785411514345,
            "auditor_fn_violation": 0.010209235452176202,
            "auditor_fp_violation": 0.014956742499518786,
            "ave_precision_score": 0.7617974847700062,
            "fpr": 0.1690450054884742,
            "logloss": 0.7387934777273809,
            "mae": 0.3322843015275724,
            "precision": 0.7264653641207816,
            "recall": 0.83640081799591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6818503878053243,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6737811052779308,
            "fpr": 0.08442982456140351,
            "logloss": 0.6780457598573781,
            "mae": 0.41553159669172346,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7160048283131988,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.7102924895188283,
            "fpr": 0.07903402854006586,
            "logloss": 0.6600411277796262,
            "mae": 0.4077045378386647,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 871,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8115127319228643,
            "auditor_fn_violation": 0.010752688172043013,
            "auditor_fp_violation": 0.012755602653165353,
            "ave_precision_score": 0.808838393331369,
            "fpr": 0.16666666666666666,
            "logloss": 0.6150424164069558,
            "mae": 0.4077884207169215,
            "precision": 0.7142857142857143,
            "recall": 0.8172043010752689
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8361750628194614,
            "auditor_fn_violation": 0.011639156952404039,
            "auditor_fp_violation": 0.014210205960847154,
            "ave_precision_score": 0.8362722732119665,
            "fpr": 0.12843029637760703,
            "logloss": 0.570071643587797,
            "mae": 0.3981998578188317,
            "precision": 0.7673956262425448,
            "recall": 0.7893660531697342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 871,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6675973324122114,
            "auditor_fn_violation": 0.014348707790982837,
            "auditor_fp_violation": 0.04435515522587229,
            "ave_precision_score": 0.6583895640193703,
            "fpr": 0.17214912280701755,
            "logloss": 2.0958386594798943,
            "mae": 0.30916572255682817,
            "precision": 0.693359375,
            "recall": 0.7634408602150538
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7139899655755481,
            "auditor_fn_violation": 0.0101329131115047,
            "auditor_fp_violation": 0.028103068863443645,
            "ave_precision_score": 0.701925756411472,
            "fpr": 0.15148188803512624,
            "logloss": 1.8995502966698536,
            "mae": 0.3017912013155111,
            "precision": 0.7272727272727273,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 871,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.8072574759115857,
            "auditor_fn_violation": 0.006345500848896438,
            "auditor_fp_violation": 0.00806301267710664,
            "ave_precision_score": 0.8068057697882074,
            "fpr": 0.34649122807017546,
            "logloss": 0.5997293090830879,
            "mae": 0.39684319686095576,
            "precision": 0.56353591160221,
            "recall": 0.8774193548387097
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.839561802051844,
            "auditor_fn_violation": 0.004038349731412706,
            "auditor_fp_violation": 0.016566868344249596,
            "ave_precision_score": 0.839716748592334,
            "fpr": 0.3260153677277717,
            "logloss": 0.5692124968711212,
            "mae": 0.38974366296986457,
            "precision": 0.5903448275862069,
            "recall": 0.8752556237218814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 871,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6728033860623008,
            "auditor_fn_violation": 0.013117807960762121,
            "auditor_fp_violation": 0.041963479728403794,
            "ave_precision_score": 0.6636480494372792,
            "fpr": 0.18969298245614036,
            "logloss": 2.01710645813654,
            "mae": 0.30444930071322457,
            "precision": 0.6848816029143898,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7225163910819932,
            "auditor_fn_violation": 0.01327335295266444,
            "auditor_fp_violation": 0.023889169237492267,
            "ave_precision_score": 0.7110538456970259,
            "fpr": 0.17014270032930845,
            "logloss": 1.7767980198306657,
            "mae": 0.29441596635460276,
            "precision": 0.714548802946593,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 871,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6614031445768946,
            "auditor_fn_violation": 0.033588002263723826,
            "auditor_fp_violation": 0.04404362416107384,
            "ave_precision_score": 0.6532378114900159,
            "fpr": 0.1600877192982456,
            "logloss": 2.014120259401491,
            "mae": 0.31684281158080463,
            "precision": 0.6983471074380165,
            "recall": 0.7268817204301076
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7070381875153576,
            "auditor_fn_violation": 0.025339017102938646,
            "auditor_fp_violation": 0.03732682693358166,
            "ave_precision_score": 0.696582167910062,
            "fpr": 0.15148188803512624,
            "logloss": 1.7417722457152758,
            "mae": 0.3093420149589398,
            "precision": 0.7234468937875751,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 871,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8025871155452731,
            "auditor_fn_violation": 0.025660252782493887,
            "auditor_fp_violation": 0.006130048275050042,
            "ave_precision_score": 0.6651347998338951,
            "fpr": 0.017543859649122806,
            "logloss": 0.6003271865119821,
            "mae": 0.4237781338916536,
            "precision": 0.9148936170212766,
            "recall": 0.36989247311827955
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8239144685078857,
            "auditor_fn_violation": 0.03162438633470939,
            "auditor_fp_violation": 0.001976891182545092,
            "ave_precision_score": 0.6911110585548399,
            "fpr": 0.013172338090010977,
            "logloss": 0.5926692928634714,
            "mae": 0.4212928517720571,
            "precision": 0.9365079365079365,
            "recall": 0.3619631901840491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 871,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8105007087760421,
            "auditor_fn_violation": 0.01006178079607622,
            "auditor_fp_violation": 0.013111287727147853,
            "ave_precision_score": 0.8109129626115262,
            "fpr": 0.14364035087719298,
            "logloss": 0.5778657251982586,
            "mae": 0.3998503561147995,
            "precision": 0.7242105263157895,
            "recall": 0.7397849462365591
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8377467142886291,
            "auditor_fn_violation": 0.013185806738364777,
            "auditor_fp_violation": 0.010222608351845013,
            "ave_precision_score": 0.8380489917407581,
            "fpr": 0.13172338090010977,
            "logloss": 0.5596047833854096,
            "mae": 0.3925222250357941,
            "precision": 0.7515527950310559,
            "recall": 0.7423312883435583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 871,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6413966511083234,
            "auditor_fn_violation": 0.016119600075457464,
            "auditor_fp_violation": 0.04373699909729581,
            "ave_precision_score": 0.6332047084865365,
            "fpr": 0.19517543859649122,
            "logloss": 1.9443525747792607,
            "mae": 0.3344547173466006,
            "precision": 0.6685288640595903,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6881437049125951,
            "auditor_fn_violation": 0.017280275837918285,
            "auditor_fp_violation": 0.03384645798325886,
            "ave_precision_score": 0.6778547200139963,
            "fpr": 0.17892425905598244,
            "logloss": 1.652068237555953,
            "mae": 0.3202638792167653,
            "precision": 0.6964618249534451,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 871,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6583824073130348,
            "auditor_fn_violation": 0.01193406904357669,
            "auditor_fp_violation": 0.04258408885749048,
            "ave_precision_score": 0.6491744925859357,
            "fpr": 0.18530701754385964,
            "logloss": 2.091772021899698,
            "mae": 0.31756958248420997,
            "precision": 0.6817325800376648,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7030578155547327,
            "auditor_fn_violation": 0.013688636276906436,
            "auditor_fp_violation": 0.02382153874966835,
            "ave_precision_score": 0.6914968228835356,
            "fpr": 0.1712403951701427,
            "logloss": 1.889619967804961,
            "mae": 0.3102277746911066,
            "precision": 0.7039848197343453,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 871,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.8012006716850529,
            "auditor_fn_violation": 0.011651103565365027,
            "auditor_fp_violation": 0.0049305310255504525,
            "ave_precision_score": 0.800762462930535,
            "fpr": 0.3256578947368421,
            "logloss": 0.5954644511015079,
            "mae": 0.4002422685224334,
            "precision": 0.5683139534883721,
            "recall": 0.8408602150537634
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.832681538401522,
            "auditor_fn_violation": 0.005095638627185569,
            "auditor_fp_violation": 0.017308202537704005,
            "ave_precision_score": 0.8328284910537447,
            "fpr": 0.3029637760702525,
            "logloss": 0.5707672680095712,
            "mae": 0.39379196645105186,
            "precision": 0.597667638483965,
            "recall": 0.8384458077709611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 871,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7816326304020895,
            "auditor_fn_violation": 0.00432229767968308,
            "auditor_fp_violation": 0.026438439499195426,
            "ave_precision_score": 0.7179681170719253,
            "fpr": 0.30043859649122806,
            "logloss": 3.5278288411437804,
            "mae": 0.3798230281916627,
            "precision": 0.6068866571018652,
            "recall": 0.9096774193548387
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7951172386983105,
            "auditor_fn_violation": 0.012575228012992759,
            "auditor_fp_violation": 0.030501350008583877,
            "ave_precision_score": 0.7380268324511987,
            "fpr": 0.2601536772777168,
            "logloss": 3.2517451064097815,
            "mae": 0.3720924824181817,
            "precision": 0.6446776611694153,
            "recall": 0.8793456032719836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 871,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7764978485587718,
            "auditor_fn_violation": 0.00788530465949821,
            "auditor_fp_violation": 0.022599493700694685,
            "ave_precision_score": 0.725714897022178,
            "fpr": 0.17434210526315788,
            "logloss": 3.049246956741978,
            "mae": 0.38812695479576004,
            "precision": 0.708256880733945,
            "recall": 0.8301075268817204
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7829937348829541,
            "auditor_fn_violation": 0.01235524008988078,
            "auditor_fp_violation": 0.01711571576466672,
            "ave_precision_score": 0.7324195694234801,
            "fpr": 0.15148188803512624,
            "logloss": 3.035118391925656,
            "mae": 0.3795493448932137,
            "precision": 0.7376425855513308,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 871,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7521243562715071,
            "auditor_fn_violation": 0.01459630258441804,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6638613356646632,
            "fpr": 0.08442982456140351,
            "logloss": 0.6626415668787548,
            "mae": 0.41139597354228036,
            "precision": 0.7608695652173914,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7725291634854166,
            "auditor_fn_violation": 0.009082358539908728,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.686313647510097,
            "fpr": 0.07903402854006586,
            "logloss": 0.6526720727280302,
            "mae": 0.4060330515242827,
            "precision": 0.7811550151975684,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 871,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6608988248390851,
            "auditor_fn_violation": 0.033479532163742706,
            "auditor_fp_violation": 0.040499038423799996,
            "ave_precision_score": 0.6528418712706031,
            "fpr": 0.1524122807017544,
            "logloss": 1.9871033774367592,
            "mae": 0.31866529619575845,
            "precision": 0.7042553191489361,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7070369762432986,
            "auditor_fn_violation": 0.02882964180129704,
            "auditor_fp_violation": 0.03418461042237842,
            "ave_precision_score": 0.6972901325430612,
            "fpr": 0.14050493962678376,
            "logloss": 1.693937014829534,
            "mae": 0.3117222283673726,
            "precision": 0.7293868921775899,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 871,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.646036059393747,
            "auditor_fn_violation": 0.029914167138275806,
            "auditor_fp_violation": 0.049479473291730455,
            "ave_precision_score": 0.6306406016853066,
            "fpr": 0.15899122807017543,
            "logloss": 2.7337208993360282,
            "mae": 0.3336343307296217,
            "precision": 0.6840958605664488,
            "recall": 0.6752688172043011
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.681441554144494,
            "auditor_fn_violation": 0.025341261877664268,
            "auditor_fp_violation": 0.04119216942997904,
            "ave_precision_score": 0.6641631580536551,
            "fpr": 0.13391877058177826,
            "logloss": 2.4942191466499484,
            "mae": 0.3282610087973376,
            "precision": 0.7258426966292135,
            "recall": 0.6605316973415133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 871,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7824139479396659,
            "auditor_fn_violation": 0.019227504244482177,
            "auditor_fp_violation": 0.010319773146512817,
            "ave_precision_score": 0.6668932870315017,
            "fpr": 0.08991228070175439,
            "logloss": 0.6560119258878782,
            "mae": 0.41213125611344975,
            "precision": 0.7690140845070422,
            "recall": 0.5870967741935483
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7857995852865287,
            "auditor_fn_violation": 0.01041575472693439,
            "auditor_fp_violation": 0.0051295123841827925,
            "ave_precision_score": 0.6740830357026069,
            "fpr": 0.08562019758507135,
            "logloss": 0.6483954281286899,
            "mae": 0.4094228273427316,
            "precision": 0.780281690140845,
            "recall": 0.5664621676891616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 871,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6682399753251544,
            "auditor_fn_violation": 0.01434634974533107,
            "auditor_fp_violation": 0.04553995447231054,
            "ave_precision_score": 0.6595737425513378,
            "fpr": 0.16885964912280702,
            "logloss": 1.944016729176269,
            "mae": 0.30989736009684915,
            "precision": 0.6980392156862745,
            "recall": 0.7655913978494624
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7160098581916108,
            "auditor_fn_violation": 0.014110653925325322,
            "auditor_fp_violation": 0.028116074726486702,
            "ave_precision_score": 0.7052455371650829,
            "fpr": 0.14818880351262348,
            "logloss": 1.6893527888776219,
            "mae": 0.30123299121099006,
            "precision": 0.7347740667976425,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 871,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.670895564533903,
            "auditor_fn_violation": 0.002091586493114507,
            "auditor_fp_violation": 0.0017882373719533735,
            "ave_precision_score": 0.6586184461424514,
            "fpr": 0.003289473684210526,
            "logloss": 1.0344868443894593,
            "mae": 0.4968825894195521,
            "precision": 0.85,
            "recall": 0.03655913978494624
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.6922833438399538,
            "auditor_fn_violation": 0.001358088709007628,
            "auditor_fp_violation": 0.0010560760790964568,
            "ave_precision_score": 0.6804324629365588,
            "fpr": 0.0043907793633369925,
            "logloss": 1.0662444623677685,
            "mae": 0.5095025878052026,
            "precision": 0.8461538461538461,
            "recall": 0.044989775051124746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 871,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.719091657515784,
            "auditor_fn_violation": 0.009352009054895307,
            "auditor_fp_violation": 0.011124357313866332,
            "ave_precision_score": 0.7198402665371295,
            "fpr": 0.19517543859649122,
            "logloss": 0.8902729762456606,
            "mae": 0.3729527989635244,
            "precision": 0.6787003610108303,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7369765774958346,
            "auditor_fn_violation": 0.015706688755249974,
            "auditor_fp_violation": 0.018135375427242608,
            "ave_precision_score": 0.7377216222039136,
            "fpr": 0.1734357848518112,
            "logloss": 0.8428337208210771,
            "mae": 0.36867626302116,
            "precision": 0.704119850187266,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6980918165389702,
            "mae": 0.5007018641029534,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.7017240611657598,
            "mae": 0.5024722632016623,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 871,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7942342855676279,
            "auditor_fn_violation": 0.005956423316355407,
            "auditor_fp_violation": 0.013982102908277408,
            "ave_precision_score": 0.7946153217617952,
            "fpr": 0.21600877192982457,
            "logloss": 0.8855705105539307,
            "mae": 0.3731195172948534,
            "precision": 0.6738410596026491,
            "recall": 0.875268817204301
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7895548827098462,
            "auditor_fn_violation": 0.008328114232096239,
            "auditor_fp_violation": 0.022682225147096315,
            "ave_precision_score": 0.7900345547570935,
            "fpr": 0.17892425905598244,
            "logloss": 0.8704450701944856,
            "mae": 0.3584195155114688,
            "precision": 0.7140350877192982,
            "recall": 0.8323108384458078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 871,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7713556739095675,
            "auditor_fn_violation": 0.0020137709866063034,
            "auditor_fp_violation": 0.013349228776639587,
            "ave_precision_score": 0.7720480541086653,
            "fpr": 0.23903508771929824,
            "logloss": 0.9101976380955019,
            "mae": 0.375860248022435,
            "precision": 0.653968253968254,
            "recall": 0.886021505376344
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.761537503861375,
            "auditor_fn_violation": 0.006532294451590316,
            "auditor_fp_violation": 0.014207604788238536,
            "ave_precision_score": 0.7642476822209652,
            "fpr": 0.19978046103183314,
            "logloss": 0.9115851252304276,
            "mae": 0.36593135697388884,
            "precision": 0.6946308724832215,
            "recall": 0.8466257668711656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 871,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7184725705328274,
            "auditor_fn_violation": 0.010564044519901906,
            "auditor_fp_violation": 0.011372110365398959,
            "ave_precision_score": 0.7192226421206444,
            "fpr": 0.19298245614035087,
            "logloss": 0.8905547250376648,
            "mae": 0.3723321995930746,
            "precision": 0.6811594202898551,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7370121505444903,
            "auditor_fn_violation": 0.015199369667257047,
            "auditor_fp_violation": 0.018135375427242608,
            "ave_precision_score": 0.7377428087565571,
            "fpr": 0.1734357848518112,
            "logloss": 0.8441150069252451,
            "mae": 0.36825246099509407,
            "precision": 0.704119850187266,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6978576983824998,
            "mae": 0.5006695740709179,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.7013177776451196,
            "mae": 0.5023517939706796,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.520217883418223,
            "auditor_fn_violation": 0.007359460479154896,
            "auditor_fp_violation": 0.006949350445464895,
            "ave_precision_score": 0.5092529711375211,
            "fpr": 0.03179824561403509,
            "logloss": 0.6980918165389702,
            "mae": 0.5007018641029534,
            "precision": 0.5,
            "recall": 0.06236559139784946
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5375113614996977,
            "auditor_fn_violation": 0.006857786786807012,
            "auditor_fp_violation": 0.002210996717320168,
            "ave_precision_score": 0.5348857411446221,
            "fpr": 0.03402854006586169,
            "logloss": 0.7017240611657598,
            "mae": 0.5024722632016623,
            "precision": 0.5079365079365079,
            "recall": 0.065439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 871,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7584162710576109,
            "auditor_fn_violation": 0.01265563101301641,
            "auditor_fp_violation": 0.021341104438949737,
            "ave_precision_score": 0.7587145223183285,
            "fpr": 0.15789473684210525,
            "logloss": 0.8435751087062987,
            "mae": 0.3802429417703758,
            "precision": 0.7159763313609467,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7438666780733415,
            "auditor_fn_violation": 0.01630828838171946,
            "auditor_fp_violation": 0.012012215106570048,
            "ave_precision_score": 0.7456310315347051,
            "fpr": 0.14928649835345773,
            "logloss": 0.8870590367389991,
            "mae": 0.3740959074082411,
            "precision": 0.7296222664015904,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 871,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7723664585804112,
            "auditor_fn_violation": 0.015232974910394263,
            "auditor_fp_violation": 0.007562600573020919,
            "ave_precision_score": 0.6549057748235572,
            "fpr": 0.08442982456140351,
            "logloss": 0.6866555427294379,
            "mae": 0.4070333942378822,
            "precision": 0.7748538011695907,
            "recall": 0.5698924731182796
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.781305871092674,
            "auditor_fn_violation": 0.007515505781417308,
            "auditor_fp_violation": 0.004721128284630713,
            "ave_precision_score": 0.6693512958475152,
            "fpr": 0.08232711306256861,
            "logloss": 0.6776237232937782,
            "mae": 0.4036747790652232,
            "precision": 0.7807017543859649,
            "recall": 0.5460122699386503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 871,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.641066369780892,
            "auditor_fn_violation": 0.016419071873231467,
            "auditor_fp_violation": 0.04452686526158797,
            "ave_precision_score": 0.6328746946444286,
            "fpr": 0.19298245614035087,
            "logloss": 1.9445076591153518,
            "mae": 0.3344176364521365,
            "precision": 0.6691729323308271,
            "recall": 0.7655913978494624
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6881473724985954,
            "auditor_fn_violation": 0.017280275837918285,
            "auditor_fp_violation": 0.03558404128581165,
            "ave_precision_score": 0.6778372286786083,
            "fpr": 0.1778265642151482,
            "logloss": 1.6516468276075493,
            "mae": 0.32028444140031326,
            "precision": 0.6977611940298507,
            "recall": 0.7648261758691206
        }
    }
]