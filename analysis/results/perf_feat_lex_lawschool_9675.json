[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7699735141079354,
            "auditor_fn_violation": 0.012281159579533383,
            "auditor_fp_violation": 0.02739708682792432,
            "ave_precision_score": 0.7346383121827851,
            "fpr": 0.18530701754385964,
            "logloss": 2.803337449301447,
            "mae": 0.2896758575536344,
            "precision": 0.7050610820244329,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7718177592333841,
            "auditor_fn_violation": 0.016721936564792886,
            "auditor_fp_violation": 0.01839897682756121,
            "ave_precision_score": 0.7335943077132534,
            "fpr": 0.18660812294182216,
            "logloss": 3.029710964853012,
            "mae": 0.29954777941300686,
            "precision": 0.6996466431095406,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7705232404675546,
            "auditor_fn_violation": 0.019773468117056735,
            "auditor_fp_violation": 0.02166646408168228,
            "ave_precision_score": 0.73780848578183,
            "fpr": 0.20833333333333334,
            "logloss": 2.3887310088947755,
            "mae": 0.3255041875178451,
            "precision": 0.6801346801346801,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.792335122518526,
            "auditor_fn_violation": 0.012885781963140564,
            "auditor_fp_violation": 0.026568746915880324,
            "ave_precision_score": 0.7553133213989541,
            "fpr": 0.1877058177826564,
            "logloss": 2.400656834495035,
            "mae": 0.30098702662534405,
            "precision": 0.7026086956521739,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7695441443545538,
            "auditor_fn_violation": 0.014675585100538405,
            "auditor_fp_violation": 0.019101231716705164,
            "ave_precision_score": 0.742743335639662,
            "fpr": 0.23464912280701755,
            "logloss": 2.330522569280957,
            "mae": 0.3229618267082973,
            "precision": 0.662992125984252,
            "recall": 0.8789144050104384
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7754172298163156,
            "auditor_fn_violation": 0.0043792246808018985,
            "auditor_fp_violation": 0.009388312067593827,
            "ave_precision_score": 0.7467266158411086,
            "fpr": 0.24478594950603733,
            "logloss": 2.386567267856144,
            "mae": 0.3356162124112403,
            "precision": 0.6471518987341772,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6567179540677279,
            "auditor_fn_violation": 0.05858101673808739,
            "auditor_fp_violation": 0.022058972488959116,
            "ave_precision_score": 0.6579130510253114,
            "fpr": 0.11074561403508772,
            "logloss": 2.0345236437085528,
            "mae": 0.37591282907444656,
            "precision": 0.727027027027027,
            "recall": 0.5615866388308977
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.6371558429861853,
            "auditor_fn_violation": 0.055871511930209714,
            "auditor_fp_violation": 0.01387727973091371,
            "ave_precision_score": 0.6374267482122262,
            "fpr": 0.10537870472008781,
            "logloss": 1.9749851752302925,
            "mae": 0.38257829428561346,
            "precision": 0.7257142857142858,
            "recall": 0.5347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7660330152062058,
            "auditor_fn_violation": 0.03189438889499323,
            "auditor_fp_violation": 0.019551983306997284,
            "ave_precision_score": 0.7324797924059276,
            "fpr": 0.1600877192982456,
            "logloss": 2.909581959577453,
            "mae": 0.30608303936484876,
            "precision": 0.7125984251968503,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7693273529500626,
            "auditor_fn_violation": 0.024632272228320533,
            "auditor_fp_violation": 0.023353709503620382,
            "ave_precision_score": 0.731616096342054,
            "fpr": 0.1712403951701427,
            "logloss": 3.120928437972479,
            "mae": 0.3160375766629256,
            "precision": 0.693516699410609,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7722835839770583,
            "auditor_fn_violation": 0.013217412006006665,
            "auditor_fp_violation": 0.020293950812365784,
            "ave_precision_score": 0.7368900761221059,
            "fpr": 0.18311403508771928,
            "logloss": 2.6615313744672946,
            "mae": 0.294126871167169,
            "precision": 0.7090592334494773,
            "recall": 0.8496868475991649
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7727749735874185,
            "auditor_fn_violation": 0.005983014616673409,
            "auditor_fp_violation": 0.020997190304031264,
            "ave_precision_score": 0.7330589944948436,
            "fpr": 0.18880351262349068,
            "logloss": 2.845033314792857,
            "mae": 0.30982988297414893,
            "precision": 0.6950354609929078,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.791023789295127,
            "auditor_fn_violation": 0.01663507673149471,
            "auditor_fp_violation": 0.016644888780843567,
            "ave_precision_score": 0.7581799149349777,
            "fpr": 0.12609649122807018,
            "logloss": 2.538391247125816,
            "mae": 0.2728510708864547,
            "precision": 0.7573839662447257,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7942900250402865,
            "auditor_fn_violation": 0.010341440868912128,
            "auditor_fp_violation": 0.016203587145892713,
            "ave_precision_score": 0.7572660445669581,
            "fpr": 0.12733260153677278,
            "logloss": 2.656706342983648,
            "mae": 0.28081664218520813,
            "precision": 0.7510729613733905,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6912039842664757,
            "auditor_fn_violation": 0.03450170310954841,
            "auditor_fp_violation": 0.02409495158218873,
            "ave_precision_score": 0.6920285508672316,
            "fpr": 0.15899122807017543,
            "logloss": 0.7376535995991516,
            "mae": 0.37586998348451106,
            "precision": 0.7151277013752456,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6458465898709386,
            "auditor_fn_violation": 0.03762897914379803,
            "auditor_fp_violation": 0.02304403871136668,
            "ave_precision_score": 0.6479095536964681,
            "fpr": 0.16575192096597147,
            "logloss": 0.7793376754010699,
            "mae": 0.3854185658681864,
            "precision": 0.705078125,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 9675,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.5506214201815598,
            "auditor_fn_violation": 0.004086089440720799,
            "auditor_fp_violation": 0.008941594748997209,
            "ave_precision_score": 0.5457274793145327,
            "fpr": 0.09868421052631579,
            "logloss": 5.737983457111445,
            "mae": 0.5411688481705047,
            "precision": 0.4230769230769231,
            "recall": 0.13778705636743216
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0.5443311372312365,
            "auditor_fn_violation": 0.007783234155641591,
            "auditor_fp_violation": 0.008308240767782159,
            "ave_precision_score": 0.5378528085000646,
            "fpr": 0.10098792535675083,
            "logloss": 6.381429414903471,
            "mae": 0.5461618926236652,
            "precision": 0.39072847682119205,
            "recall": 0.12421052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7618670367481217,
            "auditor_fn_violation": 0.02874226275500861,
            "auditor_fp_violation": 0.021322069608200645,
            "ave_precision_score": 0.7269406815246895,
            "fpr": 0.17543859649122806,
            "logloss": 2.7264385903323465,
            "mae": 0.31771744253681367,
            "precision": 0.6958174904942965,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7701389595146927,
            "auditor_fn_violation": 0.026964007163903174,
            "auditor_fp_violation": 0.02546853442632857,
            "ave_precision_score": 0.7310969209986347,
            "fpr": 0.1734357848518112,
            "logloss": 2.841473913542345,
            "mae": 0.3177995064885907,
            "precision": 0.6937984496124031,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6814651585002699,
            "auditor_fn_violation": 0.037463831813353846,
            "auditor_fp_violation": 0.0367387869211134,
            "ave_precision_score": 0.6796225977075423,
            "fpr": 0.17214912280701755,
            "logloss": 1.1088067746272443,
            "mae": 0.3557037099705085,
            "precision": 0.6957364341085271,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7028697752311688,
            "auditor_fn_violation": 0.03486509908140274,
            "auditor_fp_violation": 0.03636491807571073,
            "ave_precision_score": 0.7031219627471956,
            "fpr": 0.145993413830955,
            "logloss": 1.0170048602925084,
            "mae": 0.3442485246829828,
            "precision": 0.7240663900414938,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7566479923317405,
            "auditor_fn_violation": 0.035593616086144385,
            "auditor_fp_violation": 0.02581945626190187,
            "ave_precision_score": 0.7233262067550168,
            "fpr": 0.17324561403508773,
            "logloss": 2.8406485924326828,
            "mae": 0.31754997544751057,
            "precision": 0.6973180076628352,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7676131377577018,
            "auditor_fn_violation": 0.031243861574903227,
            "auditor_fp_violation": 0.026571264564597838,
            "ave_precision_score": 0.7307206067126338,
            "fpr": 0.17453347969264543,
            "logloss": 2.9415966542643432,
            "mae": 0.31863053610126674,
            "precision": 0.6936416184971098,
            "recall": 0.7578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8179527314707178,
            "auditor_fn_violation": 0.023081254807164053,
            "auditor_fp_violation": 0.020876382642518537,
            "ave_precision_score": 0.8183203973771966,
            "fpr": 0.12171052631578948,
            "logloss": 0.9073314385213558,
            "mae": 0.2751924153854285,
            "precision": 0.7628205128205128,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.816080060298825,
            "auditor_fn_violation": 0.013655323819978044,
            "auditor_fp_violation": 0.019949848437547206,
            "ave_precision_score": 0.8163549981725599,
            "fpr": 0.1141602634467618,
            "logloss": 0.914820987486381,
            "mae": 0.2795534705270958,
            "precision": 0.7729257641921398,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 9675,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7567957290419692,
            "auditor_fn_violation": 0.023255228363183538,
            "auditor_fp_violation": 0.028171974393257974,
            "ave_precision_score": 0.7214261542254621,
            "fpr": 0.19846491228070176,
            "logloss": 2.677146943099981,
            "mae": 0.3349651341609825,
            "precision": 0.6841186736474695,
            "recall": 0.8183716075156576
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7609807624986034,
            "auditor_fn_violation": 0.01322317869316541,
            "auditor_fp_violation": 0.025513852103243743,
            "ave_precision_score": 0.7219679969834062,
            "fpr": 0.20965971459934138,
            "logloss": 2.8039481368883137,
            "mae": 0.3437978488532965,
            "precision": 0.6649122807017543,
            "recall": 0.7978947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6844809135422463,
            "auditor_fn_violation": 0.026592773687873134,
            "auditor_fp_violation": 0.03024593817106276,
            "ave_precision_score": 0.6836775252617435,
            "fpr": 0.16447368421052633,
            "logloss": 1.4376145271887075,
            "mae": 0.342444229385998,
            "precision": 0.7087378640776699,
            "recall": 0.7620041753653445
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.6460936991073485,
            "auditor_fn_violation": 0.032193656479288235,
            "auditor_fp_violation": 0.024189568877833613,
            "ave_precision_score": 0.6445888971377568,
            "fpr": 0.17014270032930845,
            "logloss": 1.5859298811043268,
            "mae": 0.34543564607479227,
            "precision": 0.6978557504873294,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8033654562880898,
            "auditor_fn_violation": 0.011962971102076706,
            "auditor_fp_violation": 0.01160305498156477,
            "ave_precision_score": 0.7985375431105062,
            "fpr": 0.12828947368421054,
            "logloss": 2.1005100961511585,
            "mae": 0.3208314307719337,
            "precision": 0.7536842105263157,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7968133579202232,
            "auditor_fn_violation": 0.002812409729042697,
            "auditor_fp_violation": 0.018011258925064704,
            "ave_precision_score": 0.7909980114717134,
            "fpr": 0.13391877058177826,
            "logloss": 2.233487089204784,
            "mae": 0.33018795820756136,
            "precision": 0.7436974789915967,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.603329052533319,
            "auditor_fn_violation": 0.014428359520931768,
            "auditor_fp_violation": 0.017065252623475552,
            "ave_precision_score": 0.5226304552520216,
            "fpr": 0.31469298245614036,
            "logloss": 7.243954622492005,
            "mae": 0.40978201812959636,
            "precision": 0.5894134477825465,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.645574167406597,
            "auditor_fn_violation": 0.004432376220463343,
            "auditor_fp_violation": 0.008927582352289555,
            "ave_precision_score": 0.5564473906363947,
            "fpr": 0.30954994511525796,
            "logloss": 6.8979125355117,
            "mae": 0.40161556079925376,
            "precision": 0.5930735930735931,
            "recall": 0.8652631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7743328556836679,
            "auditor_fn_violation": 0.019800937625901915,
            "auditor_fp_violation": 0.022524917953081328,
            "ave_precision_score": 0.7395446195599048,
            "fpr": 0.16337719298245615,
            "logloss": 2.734653938937609,
            "mae": 0.2951734129129218,
            "precision": 0.7178030303030303,
            "recall": 0.791231732776618
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7824097071413488,
            "auditor_fn_violation": 0.014974868565486162,
            "auditor_fp_violation": 0.022006767439752665,
            "ave_precision_score": 0.7439987849121492,
            "fpr": 0.16136114160263446,
            "logloss": 2.801164104985928,
            "mae": 0.29873883904755333,
            "precision": 0.7156673114119922,
            "recall": 0.7789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7696404573880685,
            "auditor_fn_violation": 0.011692854265099075,
            "auditor_fp_violation": 0.02739708682792432,
            "ave_precision_score": 0.7343002848495996,
            "fpr": 0.18530701754385964,
            "logloss": 2.806930134706798,
            "mae": 0.28987334781424373,
            "precision": 0.7060869565217391,
            "recall": 0.8475991649269311
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7716239694196939,
            "auditor_fn_violation": 0.016065630596799354,
            "auditor_fp_violation": 0.01839897682756121,
            "ave_precision_score": 0.7334020710151894,
            "fpr": 0.18660812294182216,
            "logloss": 3.034026331138025,
            "mae": 0.29942152163589714,
            "precision": 0.7001763668430335,
            "recall": 0.8357894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7958167022306903,
            "auditor_fn_violation": 0.01215983591546718,
            "auditor_fp_violation": 0.0005976257039828209,
            "ave_precision_score": 0.7920452007180409,
            "fpr": 0.013157894736842105,
            "logloss": 3.8740442694744637,
            "mae": 0.39284587012195227,
            "precision": 0.916083916083916,
            "recall": 0.27348643006263046
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7992511131809962,
            "auditor_fn_violation": 0.0075683170604887605,
            "auditor_fp_violation": 0.003653108289106638,
            "ave_precision_score": 0.7954477625837881,
            "fpr": 0.01646542261251372,
            "logloss": 3.753069402816713,
            "mae": 0.36485454983305304,
            "precision": 0.9117647058823529,
            "recall": 0.3263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7022143706871742,
            "auditor_fn_violation": 0.01796276965901183,
            "auditor_fp_violation": 0.00865291114622584,
            "ave_precision_score": 0.7030137651251865,
            "fpr": 0.13706140350877194,
            "logloss": 0.9322505771029279,
            "mae": 0.34110989647441575,
            "precision": 0.742798353909465,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.655421585583545,
            "auditor_fn_violation": 0.01751689872320758,
            "auditor_fp_violation": 0.019768577729886504,
            "ave_precision_score": 0.6572821289099524,
            "fpr": 0.145993413830955,
            "logloss": 1.0273941309340917,
            "mae": 0.3486603219685698,
            "precision": 0.7274590163934426,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7004366557880368,
            "auditor_fn_violation": 0.024756894846720147,
            "auditor_fp_violation": 0.02021798144321543,
            "ave_precision_score": 0.6999199495184967,
            "fpr": 0.13048245614035087,
            "logloss": 1.3293426401642556,
            "mae": 0.3302026624142377,
            "precision": 0.75,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.6540316127537715,
            "auditor_fn_violation": 0.026756022878271425,
            "auditor_fp_violation": 0.016661799212479483,
            "ave_precision_score": 0.652216438141845,
            "fpr": 0.1394072447859495,
            "logloss": 1.5231248536005426,
            "mae": 0.34177407148959765,
            "precision": 0.7315010570824524,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.786489562489855,
            "auditor_fn_violation": 0.019638409698567925,
            "auditor_fp_violation": 0.013768182002349989,
            "ave_precision_score": 0.7311208974727632,
            "fpr": 0.15021929824561403,
            "logloss": 4.9406588139096,
            "mae": 0.2767350918780775,
            "precision": 0.7334630350194552,
            "recall": 0.7870563674321504
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7841886505736011,
            "auditor_fn_violation": 0.01070425790051419,
            "auditor_fp_violation": 0.025065710631527013,
            "ave_precision_score": 0.7282360133444192,
            "fpr": 0.15148188803512624,
            "logloss": 5.238331034291451,
            "mae": 0.29025101795650754,
            "precision": 0.7223340040241448,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7834827689880418,
            "auditor_fn_violation": 0.017866626378053696,
            "auditor_fp_violation": 0.023008589603338597,
            "ave_precision_score": 0.7506775267788981,
            "fpr": 0.15899122807017543,
            "logloss": 2.410622334268859,
            "mae": 0.28191459246130146,
            "precision": 0.7269303201506592,
            "recall": 0.8058455114822547
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7853542379408046,
            "auditor_fn_violation": 0.01282107574094402,
            "auditor_fp_violation": 0.02246246185762193,
            "ave_precision_score": 0.7483344225657339,
            "fpr": 0.16794731064763996,
            "logloss": 2.5501709968829607,
            "mae": 0.2960928570280795,
            "precision": 0.7096774193548387,
            "recall": 0.7873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7555295564549235,
            "auditor_fn_violation": 0.033389188001318536,
            "auditor_fp_violation": 0.024966067015112843,
            "ave_precision_score": 0.7221972275727063,
            "fpr": 0.17214912280701755,
            "logloss": 2.90685582540775,
            "mae": 0.31563216055771665,
            "precision": 0.6992337164750958,
            "recall": 0.7620041753653445
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7641862880462555,
            "auditor_fn_violation": 0.027689641227107285,
            "auditor_fp_violation": 0.024310416016274088,
            "ave_precision_score": 0.727381589673379,
            "fpr": 0.18221734357848518,
            "logloss": 3.027895219519949,
            "mae": 0.320993213919404,
            "precision": 0.6867924528301886,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7484454629683904,
            "auditor_fn_violation": 0.0231567959564883,
            "auditor_fp_violation": 0.021101758437664604,
            "ave_precision_score": 0.7465579121273286,
            "fpr": 0.1425438596491228,
            "logloss": 1.1565750073342347,
            "mae": 0.2853965955834569,
            "precision": 0.7420634920634921,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7509926402399304,
            "auditor_fn_violation": 0.009125888266219887,
            "auditor_fp_violation": 0.017865235299449143,
            "ave_precision_score": 0.7512305302886557,
            "fpr": 0.1437980241492865,
            "logloss": 1.180682248274328,
            "mae": 0.2915023722800319,
            "precision": 0.7321063394683026,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8397865587414224,
            "auditor_fn_violation": 0.008391934952203058,
            "auditor_fp_violation": 0.007827377334791942,
            "ave_precision_score": 0.8001576848430796,
            "fpr": 0.12938596491228072,
            "logloss": 2.8543884742713543,
            "mae": 0.21920857103665395,
            "precision": 0.7722007722007722,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8381338757115531,
            "auditor_fn_violation": 0.009738286440580049,
            "auditor_fp_violation": 0.009677841670107453,
            "ave_precision_score": 0.7955297178846013,
            "fpr": 0.12733260153677278,
            "logloss": 3.001269532540028,
            "mae": 0.22812355374940835,
            "precision": 0.7693836978131213,
            "recall": 0.8147368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.5332617124588894,
            "auditor_fn_violation": 0.06183157528476724,
            "auditor_fp_violation": 0.08460202179814434,
            "ave_precision_score": 0.5349171503117878,
            "fpr": 0.29605263157894735,
            "logloss": 2.0280304809917498,
            "mae": 0.40565503848057,
            "precision": 0.5921450151057401,
            "recall": 0.8183716075156576
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.5602647516097976,
            "auditor_fn_violation": 0.06212028424519036,
            "auditor_fp_violation": 0.08284826634709312,
            "ave_precision_score": 0.5620473144531987,
            "fpr": 0.27552140504939626,
            "logloss": 1.715473058990214,
            "mae": 0.38770199422181884,
            "precision": 0.6041009463722398,
            "recall": 0.8063157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6741104992782903,
            "auditor_fn_violation": 0.06272662344797277,
            "auditor_fp_violation": 0.028412544062234108,
            "ave_precision_score": 0.6751263670881031,
            "fpr": 0.13048245614035087,
            "logloss": 1.6501070719145232,
            "mae": 0.35071527404582337,
            "precision": 0.7238979118329466,
            "recall": 0.651356993736952
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.646956782496768,
            "auditor_fn_violation": 0.05311456467733549,
            "auditor_fp_violation": 0.024222298311161242,
            "ave_precision_score": 0.6478058166511698,
            "fpr": 0.13721185510428102,
            "logloss": 1.595855944607622,
            "mae": 0.35595479693440163,
            "precision": 0.7139588100686499,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7979284179689506,
            "auditor_fn_violation": 0.010296487565468998,
            "auditor_fp_violation": 0.012469105789878858,
            "ave_precision_score": 0.7931520477196109,
            "fpr": 0.14144736842105263,
            "logloss": 1.9916638470190402,
            "mae": 0.3288063535669715,
            "precision": 0.735655737704918,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.79515812064651,
            "auditor_fn_violation": 0.0045340574267722054,
            "auditor_fp_violation": 0.013285632282298917,
            "ave_precision_score": 0.7903257172506227,
            "fpr": 0.150384193194292,
            "logloss": 2.1597575294025746,
            "mae": 0.33456252215406646,
            "precision": 0.7232323232323232,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 9675,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.78163178759193,
            "auditor_fn_violation": 0.014716789363806174,
            "auditor_fp_violation": 0.024771078967626925,
            "ave_precision_score": 0.7670796080874853,
            "fpr": 0.18201754385964913,
            "logloss": 1.6060969877757754,
            "mae": 0.28641870386294005,
            "precision": 0.7123050259965338,
            "recall": 0.8580375782881002
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7864405278683393,
            "auditor_fn_violation": 0.011496909122421862,
            "auditor_fp_violation": 0.028056677307928577,
            "ave_precision_score": 0.7688440531703236,
            "fpr": 0.19319429198682767,
            "logloss": 1.707570439780497,
            "mae": 0.3010033958545006,
            "precision": 0.6890459363957597,
            "recall": 0.8210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7556168988563006,
            "auditor_fn_violation": 0.04556733692268249,
            "auditor_fp_violation": 0.035860074551274275,
            "ave_precision_score": 0.7563969666666766,
            "fpr": 0.20065789473684212,
            "logloss": 0.8478073499088563,
            "mae": 0.35436629311114304,
            "precision": 0.6720430107526881,
            "recall": 0.7828810020876826
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8006243298995881,
            "auditor_fn_violation": 0.03886533017505345,
            "auditor_fp_violation": 0.04743501948660107,
            "ave_precision_score": 0.8010751084497363,
            "fpr": 0.17233809001097694,
            "logloss": 0.7255246718678849,
            "mae": 0.32297143494105723,
            "precision": 0.7026515151515151,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7661407050451634,
            "auditor_fn_violation": 0.03248727246090174,
            "auditor_fp_violation": 0.019914103966613996,
            "ave_precision_score": 0.7326114396520782,
            "fpr": 0.15350877192982457,
            "logloss": 2.902283944940125,
            "mae": 0.3061919581842476,
            "precision": 0.7194388777555111,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7695301295596583,
            "auditor_fn_violation": 0.024935004910740084,
            "auditor_fp_violation": 0.021400014098832815,
            "ave_precision_score": 0.7318117695545923,
            "fpr": 0.16465422612513722,
            "logloss": 3.134173408006721,
            "mae": 0.3169970689252281,
            "precision": 0.6981891348088531,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7549085593483135,
            "auditor_fn_violation": 0.035197597333626346,
            "auditor_fp_violation": 0.02581945626190187,
            "ave_precision_score": 0.7215769091926403,
            "fpr": 0.17324561403508773,
            "logloss": 2.92688366743477,
            "mae": 0.3161733530266341,
            "precision": 0.6984732824427481,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7640500552956049,
            "auditor_fn_violation": 0.02893523600439078,
            "auditor_fp_violation": 0.024990181170001718,
            "ave_precision_score": 0.7272360597688452,
            "fpr": 0.18221734357848518,
            "logloss": 3.043462200445546,
            "mae": 0.3210369084563378,
            "precision": 0.6850094876660342,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7717638218444485,
            "auditor_fn_violation": 0.015018953961103178,
            "auditor_fp_violation": 0.03048144321542887,
            "ave_precision_score": 0.7564866333430287,
            "fpr": 0.19407894736842105,
            "logloss": 1.7531075515211052,
            "mae": 0.29542322156726586,
            "precision": 0.6994906621392191,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7763962686651525,
            "auditor_fn_violation": 0.014270032930845224,
            "auditor_fp_violation": 0.030385502371625087,
            "ave_precision_score": 0.7581484361929144,
            "fpr": 0.20965971459934138,
            "logloss": 1.8618503771582149,
            "mae": 0.30945666139345196,
            "precision": 0.676818950930626,
            "recall": 0.8421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 9675,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7051787295808465,
            "auditor_fn_violation": 0.01844806431527671,
            "auditor_fp_violation": 0.010574936185729921,
            "ave_precision_score": 0.70595210994944,
            "fpr": 0.13157894736842105,
            "logloss": 0.9352984683670141,
            "mae": 0.34061154583264797,
            "precision": 0.7525773195876289,
            "recall": 0.7620041753653445
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.6548147067121672,
            "auditor_fn_violation": 0.020075105436478138,
            "auditor_fp_violation": 0.018429188612171323,
            "ave_precision_score": 0.6567770837554683,
            "fpr": 0.145993413830955,
            "logloss": 1.0341301281123125,
            "mae": 0.3521876176700362,
            "precision": 0.7223382045929019,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7540882658971169,
            "auditor_fn_violation": 0.03591409368933818,
            "auditor_fp_violation": 0.02581945626190187,
            "ave_precision_score": 0.7208181561108937,
            "fpr": 0.17324561403508773,
            "logloss": 2.8960036679599575,
            "mae": 0.3190339133953463,
            "precision": 0.6967370441458733,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7624958880426126,
            "auditor_fn_violation": 0.030712346178288753,
            "auditor_fp_violation": 0.02244735596531688,
            "ave_precision_score": 0.7258006982848825,
            "fpr": 0.18441273326015367,
            "logloss": 3.0121432447454395,
            "mae": 0.323812569811998,
            "precision": 0.6818181818181818,
            "recall": 0.7578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7631698808791844,
            "auditor_fn_violation": 0.017816265611837533,
            "auditor_fp_violation": 0.020582634415137153,
            "ave_precision_score": 0.7283554683385118,
            "fpr": 0.1787280701754386,
            "logloss": 2.7885892421043375,
            "mae": 0.30207174835991896,
            "precision": 0.7036363636363636,
            "recall": 0.8079331941544885
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7658597170930752,
            "auditor_fn_violation": 0.016026344676180023,
            "auditor_fp_violation": 0.018826977109537856,
            "ave_precision_score": 0.7275763674826884,
            "fpr": 0.18660812294182216,
            "logloss": 3.0181253747204586,
            "mae": 0.31074377924935154,
            "precision": 0.6909090909090909,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.757781629192993,
            "auditor_fn_violation": 0.03302292788338278,
            "auditor_fp_violation": 0.03894696325108385,
            "ave_precision_score": 0.7519057522666975,
            "fpr": 0.18969298245614036,
            "logloss": 3.659161169234479,
            "mae": 0.3318334070472489,
            "precision": 0.6766355140186916,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7698797239379208,
            "auditor_fn_violation": 0.03439135709746375,
            "auditor_fp_violation": 0.045015559069074215,
            "ave_precision_score": 0.7646430731451983,
            "fpr": 0.18880351262349068,
            "logloss": 3.4607911878996003,
            "mae": 0.32911464881719615,
            "precision": 0.6785046728971963,
            "recall": 0.7642105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 9675,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.671216653218242,
            "auditor_fn_violation": 0.025976998864593637,
            "auditor_fp_violation": 0.03370001215509907,
            "ave_precision_score": 0.6638814384316138,
            "fpr": 0.18421052631578946,
            "logloss": 1.7293474694033633,
            "mae": 0.35282590334263364,
            "precision": 0.6865671641791045,
            "recall": 0.7682672233820459
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6386861894124476,
            "auditor_fn_violation": 0.031877058177826566,
            "auditor_fp_violation": 0.02821780682584921,
            "ave_precision_score": 0.632012178800771,
            "fpr": 0.18660812294182216,
            "logloss": 1.926375488516951,
            "mae": 0.3525276644472003,
            "precision": 0.67984934086629,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7467773891232576,
            "auditor_fn_violation": 0.033105336409918334,
            "auditor_fp_violation": 0.02658168226571047,
            "ave_precision_score": 0.7481469865985073,
            "fpr": 0.1425438596491228,
            "logloss": 0.8384977277041786,
            "mae": 0.3432798079962653,
            "precision": 0.7330595482546202,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7732704046632135,
            "auditor_fn_violation": 0.028433762782367554,
            "auditor_fp_violation": 0.026656864620993172,
            "ave_precision_score": 0.7746672633705818,
            "fpr": 0.13830954994511527,
            "logloss": 0.726902723176716,
            "mae": 0.3297905815698668,
            "precision": 0.7402061855670103,
            "recall": 0.7557894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7031965037038518,
            "auditor_fn_violation": 0.009872999304105777,
            "auditor_fp_violation": 0.00823254730359386,
            "ave_precision_score": 0.703993014503409,
            "fpr": 0.15570175438596492,
            "logloss": 0.8404849545086016,
            "mae": 0.32543701722221285,
            "precision": 0.7325800376647834,
            "recall": 0.8121085594989561
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.6571408088724453,
            "auditor_fn_violation": 0.0050031775376971534,
            "auditor_fp_violation": 0.00197383659452764,
            "ave_precision_score": 0.6591799183959105,
            "fpr": 0.1778265642151482,
            "logloss": 0.922023200459427,
            "mae": 0.3409677443843903,
            "precision": 0.7075812274368231,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 9675,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7696701685681713,
            "auditor_fn_violation": 0.012281159579533383,
            "auditor_fp_violation": 0.027440136137109522,
            "ave_precision_score": 0.7343409441330374,
            "fpr": 0.18640350877192982,
            "logloss": 2.76754617947506,
            "mae": 0.29018129131225323,
            "precision": 0.7038327526132404,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7720572524997054,
            "auditor_fn_violation": 0.015806805708013176,
            "auditor_fp_violation": 0.01890754186849818,
            "ave_precision_score": 0.7338408515009578,
            "fpr": 0.1877058177826564,
            "logloss": 2.9799451370357906,
            "mae": 0.3007643750926446,
            "precision": 0.6984126984126984,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7412035673970401,
            "auditor_fn_violation": 0.012482602644398053,
            "auditor_fp_violation": 0.02584984400956202,
            "ave_precision_score": 0.7422440463290558,
            "fpr": 0.18201754385964913,
            "logloss": 0.9369728574092784,
            "mae": 0.28987182520202454,
            "precision": 0.7051509769094139,
            "recall": 0.8288100208768268
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7104585422719336,
            "auditor_fn_violation": 0.009509503726385118,
            "auditor_fp_violation": 0.024698133918770578,
            "ave_precision_score": 0.7124974410223385,
            "fpr": 0.20087815587266739,
            "logloss": 1.0930224049506507,
            "mae": 0.3105143888841267,
            "precision": 0.6778169014084507,
            "recall": 0.8105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.768769633880373,
            "auditor_fn_violation": 0.016158938578178225,
            "auditor_fp_violation": 0.023018718852558653,
            "ave_precision_score": 0.7334187733568598,
            "fpr": 0.18311403508771928,
            "logloss": 2.68627439913712,
            "mae": 0.29991115181745054,
            "precision": 0.708041958041958,
            "recall": 0.8455114822546973
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7721675526838737,
            "auditor_fn_violation": 0.012310358772892719,
            "auditor_fp_violation": 0.02360043907793634,
            "ave_precision_score": 0.7331405508101826,
            "fpr": 0.18990120746432493,
            "logloss": 2.8378336589552577,
            "mae": 0.3095824360612523,
            "precision": 0.6916221033868093,
            "recall": 0.8168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7865234790025288,
            "auditor_fn_violation": 0.012761875984324069,
            "auditor_fp_violation": 0.02070671771808274,
            "ave_precision_score": 0.73110099746221,
            "fpr": 0.1513157894736842,
            "logloss": 4.948145151414322,
            "mae": 0.27829999836484026,
            "precision": 0.735632183908046,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7753370186705734,
            "auditor_fn_violation": 0.005479230458143164,
            "auditor_fp_violation": 0.02153093183214333,
            "ave_precision_score": 0.7169673608811946,
            "fpr": 0.16355653128430298,
            "logloss": 5.351263876244508,
            "mae": 0.3002424375733621,
            "precision": 0.7117988394584139,
            "recall": 0.7747368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6830091469939312,
            "auditor_fn_violation": 0.023884737940885623,
            "auditor_fp_violation": 0.030666302013694753,
            "ave_precision_score": 0.6814769819411485,
            "fpr": 0.17105263157894737,
            "logloss": 1.463794097451972,
            "mae": 0.34299068864720855,
            "precision": 0.7028571428571428,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6444441254530816,
            "auditor_fn_violation": 0.03003755271823907,
            "auditor_fp_violation": 0.023650792052286533,
            "ave_precision_score": 0.6424904870660443,
            "fpr": 0.1734357848518112,
            "logloss": 1.6311198971200154,
            "mae": 0.34483610001493475,
            "precision": 0.6961538461538461,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.5910623654078175,
            "auditor_fn_violation": 0.05553647950774641,
            "auditor_fp_violation": 0.07551608524776145,
            "ave_precision_score": 0.5924673724691982,
            "fpr": 0.2850877192982456,
            "logloss": 1.9560115755027525,
            "mae": 0.38617572429124547,
            "precision": 0.6048632218844985,
            "recall": 0.8308977035490606
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.5895017465195977,
            "auditor_fn_violation": 0.052204055693569826,
            "auditor_fp_violation": 0.07152891771316931,
            "ave_precision_score": 0.5917571618347761,
            "fpr": 0.27991218441273324,
            "logloss": 1.7562013231824263,
            "mae": 0.3769353437116774,
            "precision": 0.6076923076923076,
            "recall": 0.8315789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7242516074415998,
            "auditor_fn_violation": 0.024731714463612057,
            "auditor_fp_violation": 0.031142376727036993,
            "ave_precision_score": 0.6888821677148572,
            "fpr": 0.25548245614035087,
            "logloss": 2.805367172836304,
            "mae": 0.39704597295628996,
            "precision": 0.6077441077441077,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7345474462982569,
            "auditor_fn_violation": 0.015658905771563928,
            "auditor_fp_violation": 0.026958982467094345,
            "ave_precision_score": 0.6955418692153419,
            "fpr": 0.270032930845225,
            "logloss": 2.8999079279346507,
            "mae": 0.39776141591128045,
            "precision": 0.5920398009950248,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6913433915767151,
            "auditor_fn_violation": 0.015781232831556972,
            "auditor_fp_violation": 0.021912098375268432,
            "ave_precision_score": 0.6891905934494305,
            "fpr": 0.4024122807017544,
            "logloss": 2.468762229303474,
            "mae": 0.4289350224398162,
            "precision": 0.5446650124069479,
            "recall": 0.9164926931106472
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6659826172768052,
            "auditor_fn_violation": 0.007568317060488763,
            "auditor_fp_violation": 0.01808678838659,
            "ave_precision_score": 0.6620241580599212,
            "fpr": 0.3995609220636663,
            "logloss": 2.5274022564289744,
            "mae": 0.4157205710218626,
            "precision": 0.5528255528255528,
            "recall": 0.9473684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6559620730867708,
            "auditor_fn_violation": 0.059375343368860564,
            "auditor_fp_violation": 0.020068575017219727,
            "ave_precision_score": 0.6562554295425287,
            "fpr": 0.1074561403508772,
            "logloss": 2.0870848410051472,
            "mae": 0.3796175790950308,
            "precision": 0.7292817679558011,
            "recall": 0.5511482254697286
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.6312681431892313,
            "auditor_fn_violation": 0.057646311167600675,
            "auditor_fp_violation": 0.014491586017986086,
            "ave_precision_score": 0.6302976397118358,
            "fpr": 0.10537870472008781,
            "logloss": 2.096611397775334,
            "mae": 0.3873783655529732,
            "precision": 0.7249283667621776,
            "recall": 0.5326315789473685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7170080779271154,
            "auditor_fn_violation": 0.011223583488993882,
            "auditor_fp_violation": 0.0219906000567238,
            "ave_precision_score": 0.718136166702281,
            "fpr": 0.17105263157894737,
            "logloss": 1.021087498846345,
            "mae": 0.2920997752841647,
            "precision": 0.7121771217712177,
            "recall": 0.8058455114822547
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.6713579671275485,
            "auditor_fn_violation": 0.008945635218672369,
            "auditor_fp_violation": 0.021279166960392358,
            "ave_precision_score": 0.6733070375774599,
            "fpr": 0.1800219538968167,
            "logloss": 1.204294062817154,
            "mae": 0.30993305119739806,
            "precision": 0.6962962962962963,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 9675,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6011798656905497,
            "auditor_fn_violation": 0.01566677654470205,
            "auditor_fp_violation": 0.021337263482030713,
            "ave_precision_score": 0.5208583561225026,
            "fpr": 0.3355263157894737,
            "logloss": 7.299415866194642,
            "mae": 0.4151847639522217,
            "precision": 0.5819672131147541,
            "recall": 0.8893528183716075
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6454647715304503,
            "auditor_fn_violation": 0.011954474550811717,
            "auditor_fp_violation": 0.013466902989959622,
            "ave_precision_score": 0.556630636021956,
            "fpr": 0.32821075740944017,
            "logloss": 6.956753781084261,
            "mae": 0.4062908961173228,
            "precision": 0.5852981969486823,
            "recall": 0.888421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 9675,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8212357173870319,
            "auditor_fn_violation": 0.02093863311723987,
            "auditor_fp_violation": 0.025581418905230743,
            "ave_precision_score": 0.8215761262396919,
            "fpr": 0.13267543859649122,
            "logloss": 0.9084163942143302,
            "mae": 0.26972722694926565,
            "precision": 0.7515400410677618,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8020341298060343,
            "auditor_fn_violation": 0.014057426772199432,
            "auditor_fp_violation": 0.023122085821609486,
            "ave_precision_score": 0.8033734508997659,
            "fpr": 0.14050493962678376,
            "logloss": 1.0430836640622574,
            "mae": 0.28704442102194294,
            "precision": 0.7360824742268042,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8000325481393953,
            "auditor_fn_violation": 0.0305735633446874,
            "auditor_fp_violation": 0.03231990194886755,
            "ave_precision_score": 0.8007919503888257,
            "fpr": 0.15460526315789475,
            "logloss": 0.8081110322532933,
            "mae": 0.27845602279036996,
            "precision": 0.7339622641509433,
            "recall": 0.8121085594989561
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8016193159259821,
            "auditor_fn_violation": 0.024211681784042986,
            "auditor_fp_violation": 0.033172539501908384,
            "ave_precision_score": 0.8030362019677286,
            "fpr": 0.1668496158068057,
            "logloss": 0.8246196978499213,
            "mae": 0.2879096800801681,
            "precision": 0.7137476459510358,
            "recall": 0.7978947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.5928746693396829,
            "auditor_fn_violation": 0.05553647950774641,
            "auditor_fp_violation": 0.07432843077671084,
            "ave_precision_score": 0.5938013860856288,
            "fpr": 0.28728070175438597,
            "logloss": 1.9310525635078024,
            "mae": 0.38535759271315156,
            "precision": 0.603030303030303,
            "recall": 0.8308977035490606
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.5919458298048015,
            "auditor_fn_violation": 0.052566872725171875,
            "auditor_fp_violation": 0.06639543197816697,
            "ave_precision_score": 0.5943498269244831,
            "fpr": 0.2810098792535675,
            "logloss": 1.7109113434457015,
            "mae": 0.3759850341248467,
            "precision": 0.6073619631901841,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 9675,
        "test": {
            "accuracy": 0.33114035087719296,
            "auc_prc": 0.5504616333049341,
            "auditor_fn_violation": 0.01612689081785884,
            "auditor_fp_violation": 0.003345184554920803,
            "ave_precision_score": 0.4273446163212674,
            "fpr": 0.3826754385964912,
            "logloss": 21.52410060467767,
            "mae": 0.6692551389597642,
            "precision": 0.3844797178130511,
            "recall": 0.4551148225469729
        },
        "train": {
            "accuracy": 0.3578485181119649,
            "auc_prc": 0.5748195354515394,
            "auditor_fn_violation": 0.013112253740828469,
            "auditor_fp_violation": 0.014066103384726946,
            "ave_precision_score": 0.4383872198202864,
            "fpr": 0.38529088913282106,
            "logloss": 20.894074128417707,
            "mae": 0.6424918477326992,
            "precision": 0.40709459459459457,
            "recall": 0.5073684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 9675,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6985893975558981,
            "auditor_fn_violation": 0.008456030472841812,
            "auditor_fp_violation": 0.0154445727482679,
            "ave_precision_score": 0.6993857745820895,
            "fpr": 0.11074561403508772,
            "logloss": 1.1060498775504188,
            "mae": 0.3413706843159417,
            "precision": 0.7554479418886199,
            "recall": 0.651356993736952
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6508694951392444,
            "auditor_fn_violation": 0.0005546247616846722,
            "auditor_fp_violation": 0.013469420638677133,
            "ave_precision_score": 0.652845499014447,
            "fpr": 0.1207464324917673,
            "logloss": 1.2428183356642344,
            "mae": 0.35305228357904994,
            "precision": 0.7355769230769231,
            "recall": 0.6442105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7767099738415987,
            "auditor_fn_violation": 0.010481906750173976,
            "auditor_fp_violation": 0.02142589441270613,
            "ave_precision_score": 0.7439702970122446,
            "fpr": 0.18092105263157895,
            "logloss": 2.3951915933866497,
            "mae": 0.29441644307601655,
            "precision": 0.7048300536672629,
            "recall": 0.8225469728601252
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7779000609057893,
            "auditor_fn_violation": 0.004004852966664742,
            "auditor_fp_violation": 0.016314363689463138,
            "ave_precision_score": 0.7416444595642256,
            "fpr": 0.1778265642151482,
            "logloss": 2.5628035334225294,
            "mae": 0.307750044764828,
            "precision": 0.7049180327868853,
            "recall": 0.8147368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7729444013327742,
            "auditor_fn_violation": 0.020611288136834785,
            "auditor_fp_violation": 0.01966340504841781,
            "ave_precision_score": 0.7738023553974468,
            "fpr": 0.15570175438596492,
            "logloss": 1.0916775521387847,
            "mae": 0.28541865593147836,
            "precision": 0.723196881091618,
            "recall": 0.7745302713987474
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7851544961338237,
            "auditor_fn_violation": 0.011855104281009879,
            "auditor_fp_violation": 0.02357022729332622,
            "ave_precision_score": 0.7855219046292266,
            "fpr": 0.150384193194292,
            "logloss": 1.1602126757814497,
            "mae": 0.29732809210924604,
            "precision": 0.7254509018036072,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7255608446726161,
            "auditor_fn_violation": 0.013785115188807096,
            "auditor_fp_violation": 0.009078339613467854,
            "ave_precision_score": 0.7233628710703854,
            "fpr": 0.1513157894736842,
            "logloss": 1.3765088008214552,
            "mae": 0.2923997750573025,
            "precision": 0.7288801571709234,
            "recall": 0.7745302713987474
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7291366719320529,
            "auditor_fn_violation": 0.0004968513490091877,
            "auditor_fp_violation": 0.006289086496339343,
            "ave_precision_score": 0.7293491847574577,
            "fpr": 0.13830954994511527,
            "logloss": 1.3655370688904385,
            "mae": 0.29532166982009933,
            "precision": 0.738045738045738,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7567366132279909,
            "auditor_fn_violation": 0.04287074680438047,
            "auditor_fp_violation": 0.02504456869656821,
            "ave_precision_score": 0.7208482135997561,
            "fpr": 0.1513157894736842,
            "logloss": 2.902799434755602,
            "mae": 0.3136377722163595,
            "precision": 0.7154639175257732,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7655511745334892,
            "auditor_fn_violation": 0.03519556300190653,
            "auditor_fp_violation": 0.025992205359570593,
            "ave_precision_score": 0.7268640598608864,
            "fpr": 0.15477497255762898,
            "logloss": 2.9885615161126378,
            "mae": 0.3136395329698527,
            "precision": 0.7110655737704918,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7234579448902949,
            "auditor_fn_violation": 0.005017763615719889,
            "auditor_fp_violation": 0.02034712937077104,
            "ave_precision_score": 0.7245010527436172,
            "fpr": 0.21162280701754385,
            "logloss": 1.354982862876675,
            "mae": 0.3210141368610111,
            "precision": 0.6815181518151815,
            "recall": 0.8622129436325678
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7060276949550822,
            "auditor_fn_violation": 0.009289964758218269,
            "auditor_fp_violation": 0.023545050806151113,
            "ave_precision_score": 0.7068861024344002,
            "fpr": 0.21734357848518113,
            "logloss": 1.4767136105013914,
            "mae": 0.3271367064929717,
            "precision": 0.6716417910447762,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7748374914176049,
            "auditor_fn_violation": 0.01381487382338937,
            "auditor_fp_violation": 0.02621196466917873,
            "ave_precision_score": 0.7610627146358588,
            "fpr": 0.18969298245614036,
            "logloss": 1.6531969770297408,
            "mae": 0.29341445336189953,
            "precision": 0.7042735042735043,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7799517682475828,
            "auditor_fn_violation": 0.010064128488069791,
            "auditor_fp_violation": 0.025760581677559694,
            "ave_precision_score": 0.7631017936377424,
            "fpr": 0.1964873765093304,
            "logloss": 1.7661214480925622,
            "mae": 0.3066574547729702,
            "precision": 0.6865148861646234,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6453772815462037,
            "auditor_fn_violation": 0.021806211771600192,
            "auditor_fp_violation": 0.037197135448320574,
            "ave_precision_score": 0.6468958779178267,
            "fpr": 0.26973684210526316,
            "logloss": 1.4910577109462773,
            "mae": 0.4079595685344238,
            "precision": 0.5913621262458472,
            "recall": 0.7432150313152401
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6510579622991198,
            "auditor_fn_violation": 0.016003235311109826,
            "auditor_fp_violation": 0.02904359560519241,
            "ave_precision_score": 0.6529011636810838,
            "fpr": 0.27661909989023054,
            "logloss": 1.543436233822528,
            "mae": 0.40671792585110345,
            "precision": 0.5813953488372093,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7718616583656909,
            "auditor_fn_violation": 0.013070907958832366,
            "auditor_fp_violation": 0.024991390138162956,
            "ave_precision_score": 0.7364223009513033,
            "fpr": 0.18530701754385964,
            "logloss": 2.652584282612766,
            "mae": 0.29406223537363174,
            "precision": 0.7091222030981067,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7729373509608352,
            "auditor_fn_violation": 0.012509099312496393,
            "auditor_fp_violation": 0.026032487739050748,
            "ave_precision_score": 0.7346192336764724,
            "fpr": 0.19758507135016465,
            "logloss": 2.810363735009541,
            "mae": 0.30837136567408663,
            "precision": 0.6875,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7509448824815874,
            "auditor_fn_violation": 0.009985166465223606,
            "auditor_fp_violation": 0.022345123779425474,
            "ave_precision_score": 0.7517540676510182,
            "fpr": 0.18311403508771928,
            "logloss": 0.9364261713573152,
            "mae": 0.28680083756305697,
            "precision": 0.7054673721340388,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7139247069305439,
            "auditor_fn_violation": 0.007704662314402912,
            "auditor_fp_violation": 0.021797802596199362,
            "ave_precision_score": 0.7158386629612921,
            "fpr": 0.1964873765093304,
            "logloss": 1.0993773851565767,
            "mae": 0.306737564139942,
            "precision": 0.6837455830388692,
            "recall": 0.8147368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7699378752708502,
            "auditor_fn_violation": 0.013640900267369888,
            "auditor_fp_violation": 0.02461154329241117,
            "ave_precision_score": 0.7344123715367872,
            "fpr": 0.18859649122807018,
            "logloss": 2.763800462519916,
            "mae": 0.29891811772865384,
            "precision": 0.7049742710120068,
            "recall": 0.8580375782881002
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7703969674618167,
            "auditor_fn_violation": 0.013687676931076321,
            "auditor_fp_violation": 0.02822787742071925,
            "ave_precision_score": 0.7313410516481954,
            "fpr": 0.19758507135016465,
            "logloss": 2.947406167437626,
            "mae": 0.31040720960966045,
            "precision": 0.6853146853146853,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6545889080656031,
            "auditor_fn_violation": 0.058777881551477854,
            "auditor_fp_violation": 0.02333779020299016,
            "ave_precision_score": 0.6548656279882067,
            "fpr": 0.11074561403508772,
            "logloss": 2.0643858149286007,
            "mae": 0.3804917874747392,
            "precision": 0.7240437158469946,
            "recall": 0.5532359081419624
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6294415796378672,
            "auditor_fn_violation": 0.05695303021549483,
            "auditor_fp_violation": 0.017039446520105944,
            "ave_precision_score": 0.628537517537179,
            "fpr": 0.10537870472008781,
            "logloss": 2.0770215824249196,
            "mae": 0.3883356628133569,
            "precision": 0.7264957264957265,
            "recall": 0.5368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.5645036734516098,
            "auditor_fn_violation": 0.01791927627000696,
            "auditor_fp_violation": 0.020562375916697084,
            "ave_precision_score": 0.5458075899513342,
            "fpr": 0.3530701754385965,
            "logloss": 3.522313859134447,
            "mae": 0.4136940248039414,
            "precision": 0.575197889182058,
            "recall": 0.9102296450939458
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.599750442234763,
            "auditor_fn_violation": 0.011993760471431051,
            "auditor_fp_violation": 0.03084371443821186,
            "ave_precision_score": 0.5823964738409462,
            "fpr": 0.33040614709110866,
            "logloss": 3.1662085271004874,
            "mae": 0.39567808638281426,
            "precision": 0.5926928281461434,
            "recall": 0.9221052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8035118200399393,
            "auditor_fn_violation": 0.018896732959748017,
            "auditor_fp_violation": 0.021724707264697544,
            "ave_precision_score": 0.7657363096103169,
            "fpr": 0.13048245614035087,
            "logloss": 2.5523890860694207,
            "mae": 0.2632961576743393,
            "precision": 0.7634194831013916,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8080699022701363,
            "auditor_fn_violation": 0.016264371136403034,
            "auditor_fp_violation": 0.020574225319489624,
            "ave_precision_score": 0.7687882525694615,
            "fpr": 0.12843029637760703,
            "logloss": 2.5418169141234777,
            "mae": 0.26922356315941137,
            "precision": 0.7626774847870182,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 9675,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.5559549889666938,
            "auditor_fn_violation": 0.0045210233307695115,
            "auditor_fp_violation": 0.01042552975973421,
            "ave_precision_score": 0.5514287897469,
            "fpr": 0.09649122807017543,
            "logloss": 5.513653377532035,
            "mae": 0.5427730090748298,
            "precision": 0.41333333333333333,
            "recall": 0.12943632567849686
        },
        "train": {
            "accuracy": 0.4456641053787047,
            "auc_prc": 0.5507559653947147,
            "auditor_fn_violation": 0.007783234155641591,
            "auditor_fp_violation": 0.01293567911056506,
            "ave_precision_score": 0.5441177167445892,
            "fpr": 0.09769484083424808,
            "logloss": 6.195407833669039,
            "mae": 0.5456487604444672,
            "precision": 0.39864864864864863,
            "recall": 0.12421052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7929942747937184,
            "auditor_fn_violation": 0.023658114492912875,
            "auditor_fp_violation": 0.018951825290709455,
            "ave_precision_score": 0.7603008080380578,
            "fpr": 0.12280701754385964,
            "logloss": 2.441480949049861,
            "mae": 0.2697713619848475,
            "precision": 0.7690721649484537,
            "recall": 0.778705636743215
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.802955318022988,
            "auditor_fn_violation": 0.01499335605754233,
            "auditor_fp_violation": 0.01646542261251372,
            "ave_precision_score": 0.7666515636498695,
            "fpr": 0.11964873765093303,
            "logloss": 2.5728763291913395,
            "mae": 0.27134422054337143,
            "precision": 0.7655913978494624,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8709503133777132,
            "auditor_fn_violation": 0.014501611544518917,
            "auditor_fp_violation": 0.01098010615453183,
            "ave_precision_score": 0.8712151374132022,
            "fpr": 0.15570175438596492,
            "logloss": 0.5228284496785668,
            "mae": 0.30621949828003525,
            "precision": 0.7422867513611615,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8645409594507096,
            "auditor_fn_violation": 0.014630539025940262,
            "auditor_fp_violation": 0.021475543560358117,
            "ave_precision_score": 0.864892387655164,
            "fpr": 0.15697036223929747,
            "logloss": 0.5119901867385618,
            "mae": 0.3018065521391451,
            "precision": 0.7404718693284936,
            "recall": 0.8589473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7686236554132364,
            "auditor_fn_violation": 0.01642447716368165,
            "auditor_fp_violation": 0.027057756979052713,
            "ave_precision_score": 0.7331954549011512,
            "fpr": 0.1787280701754386,
            "logloss": 2.7193086635027175,
            "mae": 0.29409290363639434,
            "precision": 0.7120141342756183,
            "recall": 0.8413361169102297
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7709620109042292,
            "auditor_fn_violation": 0.014394823502224282,
            "auditor_fp_violation": 0.027729382974652314,
            "ave_precision_score": 0.7326439912060669,
            "fpr": 0.18990120746432493,
            "logloss": 2.878176974728416,
            "mae": 0.3073618761797665,
            "precision": 0.6932624113475178,
            "recall": 0.8231578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6712428305178421,
            "auditor_fn_violation": 0.019473592645496834,
            "auditor_fp_violation": 0.010952250719176696,
            "ave_precision_score": 0.6691261443099532,
            "fpr": 0.14144736842105263,
            "logloss": 1.0469834039392307,
            "mae": 0.35763603896249835,
            "precision": 0.7323651452282157,
            "recall": 0.7369519832985386
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6571065518805451,
            "auditor_fn_violation": 0.023063146340054314,
            "auditor_fp_violation": 0.019871801327304404,
            "ave_precision_score": 0.6554593372611535,
            "fpr": 0.141602634467618,
            "logloss": 0.9495235828685239,
            "mae": 0.36295752619617055,
            "precision": 0.7225806451612903,
            "recall": 0.7073684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6682606136573912,
            "auditor_fn_violation": 0.02790215360949346,
            "auditor_fp_violation": 0.02519397512256392,
            "ave_precision_score": 0.6701156882631519,
            "fpr": 0.23574561403508773,
            "logloss": 0.971581177923396,
            "mae": 0.3757206558054577,
            "precision": 0.6498371335504886,
            "recall": 0.8329853862212944
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6768741193138699,
            "auditor_fn_violation": 0.02114737997573517,
            "auditor_fp_violation": 0.029214795717983064,
            "ave_precision_score": 0.6786087834026426,
            "fpr": 0.22941822173435786,
            "logloss": 0.906185320027391,
            "mae": 0.35940313452684824,
            "precision": 0.6522462562396006,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7008754800067484,
            "auditor_fn_violation": 0.022266326044756993,
            "auditor_fp_violation": 0.006485251813135609,
            "ave_precision_score": 0.701632952714986,
            "fpr": 0.14035087719298245,
            "logloss": 0.9493597884837376,
            "mae": 0.34257278984245076,
            "precision": 0.7403651115618661,
            "recall": 0.7620041753653445
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6518355909162533,
            "auditor_fn_violation": 0.02019296319833613,
            "auditor_fp_violation": 0.014632574346166634,
            "ave_precision_score": 0.6540075949436618,
            "fpr": 0.15367727771679474,
            "logloss": 1.0522920267037126,
            "mae": 0.3525159560794647,
            "precision": 0.717741935483871,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8068644231387769,
            "auditor_fn_violation": 0.06136230450866206,
            "auditor_fp_violation": 0.02710080628823792,
            "ave_precision_score": 0.8071348203903366,
            "fpr": 0.08991228070175439,
            "logloss": 1.146337448286819,
            "mae": 0.32540898182800815,
            "precision": 0.7897435897435897,
            "recall": 0.6430062630480167
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.818146008338906,
            "auditor_fn_violation": 0.05440406724825236,
            "auditor_fp_violation": 0.0245722514828951,
            "ave_precision_score": 0.818371550317701,
            "fpr": 0.09001097694840834,
            "logloss": 1.0432845055864923,
            "mae": 0.31605274085576135,
            "precision": 0.783641160949868,
            "recall": 0.6252631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7033181050342602,
            "auditor_fn_violation": 0.020904296231183384,
            "auditor_fp_violation": 0.02547252947611523,
            "ave_precision_score": 0.7040801445197358,
            "fpr": 0.12828947368421054,
            "logloss": 1.3678716204072918,
            "mae": 0.32154746375941984,
            "precision": 0.7494646680942184,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.6587613792228516,
            "auditor_fn_violation": 0.02577387486278814,
            "auditor_fp_violation": 0.010317324444354932,
            "ave_precision_score": 0.6597213958995314,
            "fpr": 0.12952799121844127,
            "logloss": 1.5367142064690724,
            "mae": 0.3302609980822957,
            "precision": 0.7440347071583514,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8092201205034075,
            "auditor_fn_violation": 0.020615866388308975,
            "auditor_fp_violation": 0.02391262509622788,
            "ave_precision_score": 0.8097232975080221,
            "fpr": 0.19078947368421054,
            "logloss": 0.8806077712327671,
            "mae": 0.27539761692254855,
            "precision": 0.7030716723549488,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8255267259385849,
            "auditor_fn_violation": 0.014935582644866835,
            "auditor_fp_violation": 0.02354505080615112,
            "ave_precision_score": 0.8259050300656526,
            "fpr": 0.20636663007683864,
            "logloss": 0.9081199379196956,
            "mae": 0.29348719059594824,
            "precision": 0.6835016835016835,
            "recall": 0.8547368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7533188496542651,
            "auditor_fn_violation": 0.03596903270702853,
            "auditor_fp_violation": 0.02541681860540497,
            "ave_precision_score": 0.7200300547062798,
            "fpr": 0.17105263157894737,
            "logloss": 2.9521161482727747,
            "mae": 0.3190900750381081,
            "precision": 0.6982591876208898,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7623324044578815,
            "auditor_fn_violation": 0.03143566930498585,
            "auditor_fp_violation": 0.023764086244574472,
            "ave_precision_score": 0.7256345719843323,
            "fpr": 0.17892425905598244,
            "logloss": 3.0573214641786426,
            "mae": 0.32384368105003114,
            "precision": 0.6859344894026975,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7389478085979696,
            "auditor_fn_violation": 0.01477401750723364,
            "auditor_fp_violation": 0.030192759612657515,
            "ave_precision_score": 0.739719806259917,
            "fpr": 0.23355263157894737,
            "logloss": 1.1411269574378973,
            "mae": 0.29869736402542063,
            "precision": 0.6677067082683308,
            "recall": 0.8935281837160751
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7121505521164878,
            "auditor_fn_violation": 0.010919174995666995,
            "auditor_fp_violation": 0.027210747338845317,
            "ave_precision_score": 0.7129910549851839,
            "fpr": 0.24698133918770582,
            "logloss": 1.2841264889883326,
            "mae": 0.3202657748592402,
            "precision": 0.6511627906976745,
            "recall": 0.8842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5997622745763702,
            "auditor_fn_violation": 0.024081602754276087,
            "auditor_fp_violation": 0.02803522952878735,
            "ave_precision_score": 0.5773212386843096,
            "fpr": 0.3717105263157895,
            "logloss": 3.5317955267636556,
            "mae": 0.42136149387102995,
            "precision": 0.560880829015544,
            "recall": 0.9039665970772442
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6653146542596894,
            "auditor_fn_violation": 0.018755560690970015,
            "auditor_fp_violation": 0.03675263597820724,
            "ave_precision_score": 0.6369973479169821,
            "fpr": 0.34577387486278816,
            "logloss": 3.267278902249938,
            "mae": 0.3874014880826761,
            "precision": 0.5844327176781002,
            "recall": 0.9326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7923924931718838,
            "auditor_fn_violation": 0.008027963960004396,
            "auditor_fp_violation": 0.0235986183704064,
            "ave_precision_score": 0.718756331457465,
            "fpr": 0.2905701754385965,
            "logloss": 4.973280380716304,
            "mae": 0.32186373447484945,
            "precision": 0.6354883081155434,
            "recall": 0.964509394572025
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7831337300410407,
            "auditor_fn_violation": 0.007995840314287366,
            "auditor_fp_violation": 0.026354746774892007,
            "ave_precision_score": 0.7087225363373861,
            "fpr": 0.3106476399560922,
            "logloss": 5.305695166994001,
            "mae": 0.350007140594186,
            "precision": 0.6112637362637363,
            "recall": 0.9368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7196403947501566,
            "auditor_fn_violation": 0.008923012123209912,
            "auditor_fp_violation": 0.020088833515659828,
            "ave_precision_score": 0.7204889759371087,
            "fpr": 0.18969298245614036,
            "logloss": 1.2353472058683819,
            "mae": 0.30139488163900247,
            "precision": 0.6996527777777778,
            "recall": 0.8413361169102297
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6837474858289991,
            "auditor_fn_violation": 0.008018949679357562,
            "auditor_fp_violation": 0.016948811166275595,
            "ave_precision_score": 0.6846145416371913,
            "fpr": 0.19319429198682767,
            "logloss": 1.3883455867313998,
            "mae": 0.3151275231819297,
            "precision": 0.6901408450704225,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7707617403860395,
            "auditor_fn_violation": 0.012663443577628834,
            "auditor_fp_violation": 0.025713099145091383,
            "ave_precision_score": 0.7352657753674113,
            "fpr": 0.19517543859649122,
            "logloss": 2.7005712431390085,
            "mae": 0.29867121471724795,
            "precision": 0.7008403361344537,
            "recall": 0.8705636743215032
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7718204945230427,
            "auditor_fn_violation": 0.01002715350395748,
            "auditor_fp_violation": 0.02822787742071925,
            "ave_precision_score": 0.7328102145557479,
            "fpr": 0.19758507135016465,
            "logloss": 2.8703306472602446,
            "mae": 0.31020476219078685,
            "precision": 0.6858638743455497,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.7953668310487559,
            "auditor_fn_violation": 0.02344522579936271,
            "auditor_fp_violation": 0.0215474454033467,
            "ave_precision_score": 0.7700424718367609,
            "fpr": 0.12719298245614036,
            "logloss": 1.94390036219452,
            "mae": 0.26242021171805635,
            "precision": 0.7693836978131213,
            "recall": 0.8079331941544885
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8046833745123918,
            "auditor_fn_violation": 0.016049454041250216,
            "auditor_fp_violation": 0.01964773059144604,
            "ave_precision_score": 0.778156339213919,
            "fpr": 0.13611416026344675,
            "logloss": 1.9624898028514823,
            "mae": 0.2669963557076518,
            "precision": 0.7534791252485089,
            "recall": 0.7978947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 9675,
        "test": {
            "accuracy": 0.2993421052631579,
            "auc_prc": 0.3837367884423504,
            "auditor_fn_violation": 0.016683148371973787,
            "auditor_fp_violation": 0.02222104047647991,
            "ave_precision_score": 0.3848115830699883,
            "fpr": 0.3530701754385965,
            "logloss": 3.081226134827103,
            "mae": 0.6803644041650804,
            "precision": 0.3347107438016529,
            "recall": 0.33820459290187893
        },
        "train": {
            "accuracy": 0.2996706915477497,
            "auc_prc": 0.37978170152332347,
            "auditor_fn_violation": 0.016453867929978636,
            "auditor_fp_violation": 0.026697147000473317,
            "ave_precision_score": 0.3809259104208028,
            "fpr": 0.3600439077936334,
            "logloss": 3.110122149168544,
            "mae": 0.6810113962609663,
            "precision": 0.33468559837728196,
            "recall": 0.3473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7707446068032137,
            "auditor_fn_violation": 0.013661502399003772,
            "auditor_fp_violation": 0.02482425752603218,
            "ave_precision_score": 0.7352145995541166,
            "fpr": 0.19188596491228072,
            "logloss": 2.706590686352626,
            "mae": 0.29888126889911065,
            "precision": 0.7018739352640545,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7713393650035842,
            "auditor_fn_violation": 0.01086371251949853,
            "auditor_fp_violation": 0.02580589935447487,
            "ave_precision_score": 0.7323001275161606,
            "fpr": 0.19538968166849616,
            "logloss": 2.8785604051582765,
            "mae": 0.3102737530437637,
            "precision": 0.6877192982456141,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6830989143827368,
            "auditor_fn_violation": 0.023628355858330594,
            "auditor_fp_violation": 0.029795186580770634,
            "ave_precision_score": 0.6813854569752308,
            "fpr": 0.16885964912280702,
            "logloss": 1.4663934653997182,
            "mae": 0.342582732942611,
            "precision": 0.7061068702290076,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6448879558462371,
            "auditor_fn_violation": 0.03003755271823907,
            "auditor_fp_violation": 0.022553097211452287,
            "ave_precision_score": 0.6427843455623227,
            "fpr": 0.1734357848518112,
            "logloss": 1.6379526254394325,
            "mae": 0.3444545029915706,
            "precision": 0.6961538461538461,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 9675,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6218774497491948,
            "auditor_fn_violation": 0.06347745668974106,
            "auditor_fp_violation": 0.04637676755398891,
            "ave_precision_score": 0.6225310444320531,
            "fpr": 0.17543859649122806,
            "logloss": 3.1190622314887553,
            "mae": 0.3250033795632355,
            "precision": 0.6850393700787402,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6238151488903048,
            "auditor_fn_violation": 0.05754925183430586,
            "auditor_fp_violation": 0.05694417869263537,
            "ave_precision_score": 0.6256352004159957,
            "fpr": 0.16575192096597147,
            "logloss": 3.1893904957225345,
            "mae": 0.329675856170507,
            "precision": 0.688659793814433,
            "recall": 0.7031578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7577889821621369,
            "auditor_fn_violation": 0.02108055891293997,
            "auditor_fp_violation": 0.02340109801061546,
            "ave_precision_score": 0.7224015201774715,
            "fpr": 0.20394736842105263,
            "logloss": 2.6818772594781533,
            "mae": 0.33256510130873607,
            "precision": 0.6831345826235093,
            "recall": 0.837160751565762
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7624379417263263,
            "auditor_fn_violation": 0.014214570454676759,
            "auditor_fp_violation": 0.021649261321866283,
            "ave_precision_score": 0.7234246386845957,
            "fpr": 0.21624588364434688,
            "logloss": 2.8039446840059106,
            "mae": 0.3408605039701957,
            "precision": 0.6626712328767124,
            "recall": 0.8147368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7470942198656001,
            "auditor_fn_violation": 0.007723510236970297,
            "auditor_fp_violation": 0.027804789109031242,
            "ave_precision_score": 0.7479007554556626,
            "fpr": 0.18201754385964913,
            "logloss": 0.9348001545307953,
            "mae": 0.28258857180004343,
            "precision": 0.7087719298245614,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7050439270890554,
            "auditor_fn_violation": 0.008536599456929922,
            "auditor_fp_violation": 0.027739453569522354,
            "ave_precision_score": 0.7069922477166013,
            "fpr": 0.19978046103183314,
            "logloss": 1.1033555837832898,
            "mae": 0.30412396357386595,
            "precision": 0.6834782608695652,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7716669224669063,
            "auditor_fn_violation": 0.014725945866754568,
            "auditor_fp_violation": 0.02947611523033913,
            "ave_precision_score": 0.7362841132934094,
            "fpr": 0.19736842105263158,
            "logloss": 2.67680919596553,
            "mae": 0.29609809192758,
            "precision": 0.697986577181208,
            "recall": 0.8684759916492694
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7737074426258881,
            "auditor_fn_violation": 0.014050493962678375,
            "auditor_fp_violation": 0.028026465523318465,
            "ave_precision_score": 0.7346856685291523,
            "fpr": 0.20636663007683864,
            "logloss": 2.8284728778962025,
            "mae": 0.3085448832991434,
            "precision": 0.6813559322033899,
            "recall": 0.8463157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7864849142537131,
            "auditor_fn_violation": 0.05878017067721497,
            "auditor_fp_violation": 0.024489992301770593,
            "ave_precision_score": 0.7869284722744028,
            "fpr": 0.09868421052631579,
            "logloss": 1.703032670736515,
            "mae": 0.33240012544936753,
            "precision": 0.7794117647058824,
            "recall": 0.6638830897703549
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7782535931785364,
            "auditor_fn_violation": 0.0484742041712404,
            "auditor_fp_violation": 0.027721830028499782,
            "ave_precision_score": 0.7794350800428531,
            "fpr": 0.0889132821075741,
            "logloss": 1.471135080110844,
            "mae": 0.32204056414148563,
            "precision": 0.7944162436548223,
            "recall": 0.6589473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8499579902539657,
            "auditor_fn_violation": 0.005665586199318758,
            "auditor_fp_violation": 0.017675539888983436,
            "ave_precision_score": 0.8498637372844129,
            "fpr": 0.17543859649122806,
            "logloss": 0.9665340426147975,
            "mae": 0.24722337583113044,
            "precision": 0.7283531409168081,
            "recall": 0.8956158663883089
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8490104753096498,
            "auditor_fn_violation": 0.01234040094748397,
            "auditor_fp_violation": 0.024149286498353458,
            "ave_precision_score": 0.8474396150026704,
            "fpr": 0.1778265642151482,
            "logloss": 1.0571916802635084,
            "mae": 0.26065356746005974,
            "precision": 0.7211703958691911,
            "recall": 0.8821052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7585423397717429,
            "auditor_fn_violation": 0.028048657656667766,
            "auditor_fp_violation": 0.02417598557594912,
            "ave_precision_score": 0.7258235622581031,
            "fpr": 0.16337719298245615,
            "logloss": 2.710868177096126,
            "mae": 0.3173912196560325,
            "precision": 0.7095516569200779,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.76828408086907,
            "auditor_fn_violation": 0.024842567450459308,
            "auditor_fp_violation": 0.024335592503449178,
            "ave_precision_score": 0.731319300085087,
            "fpr": 0.1690450054884742,
            "logloss": 2.8248378740402726,
            "mae": 0.31847370662404095,
            "precision": 0.6980392156862745,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.5978069566541815,
            "auditor_fn_violation": 0.01945756876533715,
            "auditor_fp_violation": 0.018047789797820186,
            "ave_precision_score": 0.517798673390723,
            "fpr": 0.3333333333333333,
            "logloss": 7.224903572729218,
            "mae": 0.42316883024277435,
            "precision": 0.5760111576011158,
            "recall": 0.8622129436325678
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6443983866807379,
            "auditor_fn_violation": 0.010674215725922932,
            "auditor_fp_violation": 0.022618556078107536,
            "ave_precision_score": 0.5558003666381012,
            "fpr": 0.3205268935236004,
            "logloss": 6.831989972514761,
            "mae": 0.4062179618524842,
            "precision": 0.5858156028368794,
            "recall": 0.8694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6828311393468296,
            "auditor_fn_violation": 0.030266820495916197,
            "auditor_fp_violation": 0.03287701065597018,
            "ave_precision_score": 0.6817286023700958,
            "fpr": 0.1600877192982456,
            "logloss": 1.4496294395863167,
            "mae": 0.3417156931241624,
            "precision": 0.7091633466135459,
            "recall": 0.7432150313152401
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6442994149393715,
            "auditor_fn_violation": 0.03051360563868508,
            "auditor_fp_violation": 0.021855708516702082,
            "ave_precision_score": 0.642640094194318,
            "fpr": 0.16575192096597147,
            "logloss": 1.6171959311508912,
            "mae": 0.34446560411259547,
            "precision": 0.6992031872509961,
            "recall": 0.7389473684210527
        }
    }
]