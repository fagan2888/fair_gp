[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8167670110852349,
            "auditor_fn_violation": 0.022577340986210385,
            "auditor_fp_violation": 0.0272475496252368,
            "ave_precision_score": 0.8173805647434493,
            "fpr": 0.12609649122807018,
            "logloss": 0.9207731379283307,
            "mae": 0.2728361139825865,
            "precision": 0.7584033613445378,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8358464076091853,
            "auditor_fn_violation": 0.015954103220843067,
            "auditor_fp_violation": 0.020462221209050176,
            "ave_precision_score": 0.8360837058788111,
            "fpr": 0.145993413830955,
            "logloss": 0.8666671811211936,
            "mae": 0.2697149501854196,
            "precision": 0.7313131313131314,
            "recall": 0.7735042735042735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6011719245074469,
            "auditor_fn_violation": 0.03808389285972133,
            "auditor_fp_violation": 0.020740672102792193,
            "ave_precision_score": 0.5719526138893134,
            "fpr": 0.3048245614035088,
            "logloss": 0.8241206675104419,
            "mae": 0.4995873315553916,
            "precision": 0.5479674796747968,
            "recall": 0.6934156378600823
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5750260843794105,
            "auditor_fn_violation": 0.027414224999296355,
            "auditor_fp_violation": 0.0283517480108927,
            "ave_precision_score": 0.5492345531606819,
            "fpr": 0.3238199780461032,
            "logloss": 0.8145720364762006,
            "mae": 0.4951330493280969,
            "precision": 0.5249597423510467,
            "recall": 0.6965811965811965
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7055411635199751,
            "auditor_fn_violation": 0.02600444011262725,
            "auditor_fp_violation": 0.01844988056996953,
            "ave_precision_score": 0.6808975763911026,
            "fpr": 0.10964912280701754,
            "logloss": 0.9398971816117824,
            "mae": 0.4286359794086661,
            "precision": 0.6865203761755486,
            "recall": 0.4506172839506173
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6524389641613797,
            "auditor_fn_violation": 0.014255959920065306,
            "auditor_fp_violation": 0.008573417944213322,
            "ave_precision_score": 0.6290028679249084,
            "fpr": 0.141602634467618,
            "logloss": 0.8749913753505428,
            "mae": 0.43623406879155197,
            "precision": 0.6271676300578035,
            "recall": 0.4636752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8621603983844188,
            "auditor_fn_violation": 0.01646090534979424,
            "auditor_fp_violation": 0.009639341899349315,
            "ave_precision_score": 0.8599836379554158,
            "fpr": 0.08662280701754387,
            "logloss": 0.4979054820899757,
            "mae": 0.3027222238709791,
            "precision": 0.8179723502304147,
            "recall": 0.7304526748971193
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8601193551890965,
            "auditor_fn_violation": 0.019129912653513104,
            "auditor_fp_violation": 0.013345788742061543,
            "ave_precision_score": 0.8580779403174053,
            "fpr": 0.10098792535675083,
            "logloss": 0.486419698174398,
            "mae": 0.30367377696663106,
            "precision": 0.7904328018223234,
            "recall": 0.7414529914529915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7555485465358469,
            "auditor_fn_violation": 0.01774691358024692,
            "auditor_fp_violation": 0.022642801251956186,
            "ave_precision_score": 0.6958182340120838,
            "fpr": 0.15899122807017543,
            "logloss": 0.6496929267235608,
            "mae": 0.4275625750030342,
            "precision": 0.7064777327935222,
            "recall": 0.7181069958847737
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.722055262475788,
            "auditor_fn_violation": 0.004118701154925088,
            "auditor_fp_violation": 0.019914612721861975,
            "ave_precision_score": 0.6705587632863254,
            "fpr": 0.17672886937431395,
            "logloss": 0.6399371884461992,
            "mae": 0.4292566582446041,
            "precision": 0.6861598440545809,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 12498,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5781387776113511,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.027690264393377812,
            "ave_precision_score": 0.5346052437765461,
            "fpr": 0.08552631578947369,
            "logloss": 0.6941385002584272,
            "mae": 0.4991142486401817,
            "precision": 0.5357142857142857,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5658069825870269,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.030898994729578046,
            "ave_precision_score": 0.5158489159605759,
            "fpr": 0.0867178924259056,
            "logloss": 0.6951724505323391,
            "mae": 0.4996899238467609,
            "precision": 0.5269461077844312,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6127694542578375,
            "auditor_fn_violation": 0.056643022164464665,
            "auditor_fp_violation": 0.054896631249485225,
            "ave_precision_score": 0.613946005483618,
            "fpr": 0.2850877192982456,
            "logloss": 1.0585576227505178,
            "mae": 0.4331311267359976,
            "precision": 0.5918367346938775,
            "recall": 0.7757201646090535
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6155764788060323,
            "auditor_fn_violation": 0.05507238218544476,
            "auditor_fp_violation": 0.057097476788585955,
            "ave_precision_score": 0.6172521630786911,
            "fpr": 0.29527991218441274,
            "logloss": 1.1580131521268622,
            "mae": 0.4371001091941741,
            "precision": 0.5668276972624798,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 12498,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8127994608292268,
            "auditor_fn_violation": 0.016533102303082813,
            "auditor_fp_violation": 0.018038052878675565,
            "ave_precision_score": 0.8131044784564069,
            "fpr": 0.15460526315789475,
            "logloss": 0.5689500312503794,
            "mae": 0.35339295658182857,
            "precision": 0.718,
            "recall": 0.7386831275720165
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8243534143942112,
            "auditor_fn_violation": 0.004665203073545558,
            "auditor_fp_violation": 0.019699038340027706,
            "ave_precision_score": 0.8246174192552667,
            "fpr": 0.15697036223929747,
            "logloss": 0.5331351937184221,
            "mae": 0.34279868649252365,
            "precision": 0.720703125,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6913039400678119,
            "auditor_fn_violation": 0.0058840516930185535,
            "auditor_fp_violation": 0.010733259204348903,
            "ave_precision_score": 0.6437589071499972,
            "fpr": 0.05263157894736842,
            "logloss": 0.7036380726109979,
            "mae": 0.43925400454706204,
            "precision": 0.7913043478260869,
            "recall": 0.37448559670781895
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6373139574692623,
            "auditor_fn_violation": 0.009752596470488912,
            "auditor_fp_violation": 0.007275015920291992,
            "ave_precision_score": 0.5961834924149898,
            "fpr": 0.06476399560922064,
            "logloss": 0.727155147957101,
            "mae": 0.4518202828523487,
            "precision": 0.7216981132075472,
            "recall": 0.3269230769230769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6759846107261585,
            "auditor_fn_violation": 0.018721572449642628,
            "auditor_fp_violation": 0.014135985503665275,
            "ave_precision_score": 0.6467350561960968,
            "fpr": 0.25548245614035087,
            "logloss": 0.6816225622262005,
            "mae": 0.4561813154662224,
            "precision": 0.6199021207177814,
            "recall": 0.7818930041152263
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6872813419727113,
            "auditor_fn_violation": 0.01927298826310901,
            "auditor_fp_violation": 0.016856925512856412,
            "ave_precision_score": 0.6347524861745852,
            "fpr": 0.2722283205268935,
            "logloss": 0.6553296218823026,
            "mae": 0.45655307140702006,
            "precision": 0.5967479674796748,
            "recall": 0.7841880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 12498,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23313649732458,
            "mae": 0.5327826037537307,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.743489818633183,
            "mae": 0.5139070447681535,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7298156364954315,
            "auditor_fn_violation": 0.028240289509782697,
            "auditor_fp_violation": 0.024658183016226014,
            "ave_precision_score": 0.6662178208162827,
            "fpr": 0.1425438596491228,
            "logloss": 0.6352717289025664,
            "mae": 0.42298303911331714,
            "precision": 0.70917225950783,
            "recall": 0.6522633744855967
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7340501596171385,
            "auditor_fn_violation": 0.007172544494169082,
            "auditor_fp_violation": 0.02711777051487587,
            "ave_precision_score": 0.6638358228080337,
            "fpr": 0.15477497255762898,
            "logloss": 0.6231963908216367,
            "mae": 0.4178331031757443,
            "precision": 0.6954643628509719,
            "recall": 0.688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6187667965008381,
            "auditor_fn_violation": 0.008974983755685513,
            "auditor_fp_violation": 0.005883988139362485,
            "ave_precision_score": 0.5210108830992797,
            "fpr": 0.3881578947368421,
            "logloss": 8.149342484146064,
            "mae": 0.4615419399025932,
            "precision": 0.553030303030303,
            "recall": 0.9012345679012346
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6332659322353619,
            "auditor_fn_violation": 0.005024064848433676,
            "auditor_fp_violation": 0.0062714800048566275,
            "ave_precision_score": 0.5346277389031111,
            "fpr": 0.40285400658616904,
            "logloss": 7.605477018593605,
            "mae": 0.46768257964880877,
            "precision": 0.5300896286811779,
            "recall": 0.8846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7651166612217797,
            "auditor_fn_violation": 0.002538174139051332,
            "auditor_fp_violation": 0.0023422699942344124,
            "ave_precision_score": 0.5350168725243533,
            "fpr": 0.4583333333333333,
            "logloss": 1.3599738311731804,
            "mae": 0.4679311452997162,
            "precision": 0.5350389321468298,
            "recall": 0.9897119341563786
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7594235033259423,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0022647699424887245,
            "ave_precision_score": 0.5188470066518847,
            "fpr": 0.47639956092206365,
            "logloss": 1.3947845218432018,
            "mae": 0.4790470954378337,
            "precision": 0.5188470066518847,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6983396541092898,
            "auditor_fn_violation": 0.016932441700960223,
            "auditor_fp_violation": 0.01365208796639486,
            "ave_precision_score": 0.6889966541292842,
            "fpr": 0.20394736842105263,
            "logloss": 0.6700852826967,
            "mae": 0.4100035993472199,
            "precision": 0.6483931947069943,
            "recall": 0.7057613168724279
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6581824881698869,
            "auditor_fn_violation": 0.012581271637254076,
            "auditor_fp_violation": 0.015850911730963185,
            "ave_precision_score": 0.6556998882761055,
            "fpr": 0.23819978046103182,
            "logloss": 0.6887848273773833,
            "mae": 0.4155313498499005,
            "precision": 0.6131907308377896,
            "recall": 0.7350427350427351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5536821968416872,
            "auditor_fn_violation": 0.014890621615767815,
            "auditor_fp_violation": 0.009711411745325754,
            "ave_precision_score": 0.5549360563200849,
            "fpr": 0.44627192982456143,
            "logloss": 0.6917575088829359,
            "mae": 0.49869756590117487,
            "precision": 0.5283893395133256,
            "recall": 0.9382716049382716
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5527609076686064,
            "auditor_fn_violation": 0.007346111627121507,
            "auditor_fp_violation": 0.009876775701050387,
            "ave_precision_score": 0.5538832603475954,
            "fpr": 0.4632272228320527,
            "logloss": 0.6925028560854855,
            "mae": 0.4990481538646962,
            "precision": 0.5160550458715596,
            "recall": 0.9615384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8429165403719632,
            "auditor_fn_violation": 0.010233918128654975,
            "auditor_fp_violation": 0.010496458281854875,
            "ave_precision_score": 0.8119995192230349,
            "fpr": 0.10307017543859649,
            "logloss": 0.5134888257808727,
            "mae": 0.32870270537310525,
            "precision": 0.7929515418502202,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8396829200277653,
            "auditor_fn_violation": 0.01042810098792536,
            "auditor_fp_violation": 0.005929534433671235,
            "ave_precision_score": 0.8073012274425397,
            "fpr": 0.1163556531284303,
            "logloss": 0.5228460274295164,
            "mae": 0.33806090016412815,
            "precision": 0.7695652173913043,
            "recall": 0.7564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6826266390228342,
            "auditor_fn_violation": 0.004083640170384811,
            "auditor_fp_violation": 0.014262107734124046,
            "ave_precision_score": 0.6832459609156298,
            "fpr": 0.3826754385964912,
            "logloss": 0.8442479914503701,
            "mae": 0.4322230254831977,
            "precision": 0.5738705738705738,
            "recall": 0.9670781893004116
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6900433618815266,
            "auditor_fn_violation": 0.008837850769793692,
            "auditor_fp_violation": 0.021725933102561375,
            "ave_precision_score": 0.6894659850630411,
            "fpr": 0.40065861690450055,
            "logloss": 0.8695355718002301,
            "mae": 0.44394546403149887,
            "precision": 0.5510455104551045,
            "recall": 0.9572649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8372087022657313,
            "auditor_fn_violation": 0.01293453541260559,
            "auditor_fp_violation": 0.011932707355242567,
            "ave_precision_score": 0.8238092967846032,
            "fpr": 0.03837719298245614,
            "logloss": 0.5320428843358971,
            "mae": 0.3335525515946772,
            "precision": 0.8841059602649006,
            "recall": 0.5493827160493827
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8423410279169012,
            "auditor_fn_violation": 0.006013866606621826,
            "auditor_fp_violation": 0.008122446248881865,
            "ave_precision_score": 0.8216703125969718,
            "fpr": 0.042810098792535674,
            "logloss": 0.5265235189062799,
            "mae": 0.33345409329371317,
            "precision": 0.8704318936877077,
            "recall": 0.5598290598290598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8284766941644691,
            "auditor_fn_violation": 0.0039257093350660716,
            "auditor_fp_violation": 0.01320422535211268,
            "ave_precision_score": 0.8248027432767316,
            "fpr": 0.08114035087719298,
            "logloss": 0.5155666085494066,
            "mae": 0.34608528391343724,
            "precision": 0.8262910798122066,
            "recall": 0.7242798353909465
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8015064104703115,
            "auditor_fn_violation": 0.01080807227898337,
            "auditor_fp_violation": 0.0069454596813959294,
            "ave_precision_score": 0.7979929344195787,
            "fpr": 0.09549945115257959,
            "logloss": 0.538610774029557,
            "mae": 0.35790731060256287,
            "precision": 0.7928571428571428,
            "recall": 0.7115384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 12498,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8153392975522167,
            "auditor_fn_violation": 0.04778535845787308,
            "auditor_fp_violation": 0.05882443785520138,
            "ave_precision_score": 0.8159438773487061,
            "fpr": 0.19407894736842105,
            "logloss": 0.7063668204753913,
            "mae": 0.34370654234542797,
            "precision": 0.6775956284153005,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8317776659689375,
            "auditor_fn_violation": 0.03485181119648738,
            "auditor_fp_violation": 0.06401567993894537,
            "ave_precision_score": 0.8319648555954411,
            "fpr": 0.22283205268935236,
            "logloss": 0.6486753418291585,
            "mae": 0.3451607979311632,
            "precision": 0.65,
            "recall": 0.8055555555555556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7711017654953143,
            "auditor_fn_violation": 0.015420817991480765,
            "auditor_fp_violation": 0.022279878099003378,
            "ave_precision_score": 0.7711605820655018,
            "fpr": 0.12938596491228072,
            "logloss": 1.0096721389699794,
            "mae": 0.30764185340552946,
            "precision": 0.7473233404710921,
            "recall": 0.7181069958847737
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7863284778220956,
            "auditor_fn_violation": 0.012975315939092015,
            "auditor_fp_violation": 0.015843478131589584,
            "ave_precision_score": 0.786685251088499,
            "fpr": 0.15697036223929747,
            "logloss": 0.9259955581599575,
            "mae": 0.31047065693226833,
            "precision": 0.718503937007874,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7747441412971641,
            "auditor_fn_violation": 0.004027236300628114,
            "auditor_fp_violation": 0.02003541718145129,
            "ave_precision_score": 0.7452871039125887,
            "fpr": 0.36622807017543857,
            "logloss": 3.140226384153364,
            "mae": 0.3672098907663256,
            "precision": 0.5850931677018634,
            "recall": 0.9691358024691358
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7824471662884461,
            "auditor_fn_violation": 0.006595551052192106,
            "auditor_fp_violation": 0.022870707406095064,
            "ave_precision_score": 0.7535834008285784,
            "fpr": 0.38638858397365533,
            "logloss": 3.36098397623077,
            "mae": 0.38404652017902885,
            "precision": 0.5616438356164384,
            "recall": 0.9636752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7845794459887184,
            "auditor_fn_violation": 0.015323803335499247,
            "auditor_fp_violation": 0.022027633638085825,
            "ave_precision_score": 0.690134999079522,
            "fpr": 0.12938596491228072,
            "logloss": 0.6020029673209362,
            "mae": 0.40969795549059645,
            "precision": 0.7203791469194313,
            "recall": 0.6255144032921811
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7710280110543913,
            "auditor_fn_violation": 0.014288796945218469,
            "auditor_fp_violation": 0.011195000656634617,
            "ave_precision_score": 0.6653766178287737,
            "fpr": 0.15587266739846323,
            "logloss": 0.6152779082783394,
            "mae": 0.41337785175485225,
            "precision": 0.690631808278867,
            "recall": 0.6773504273504274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 12498,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7990431737621113,
            "auditor_fn_violation": 0.016212728322864772,
            "auditor_fp_violation": 0.017567024956758104,
            "ave_precision_score": 0.7995120509899971,
            "fpr": 0.4067982456140351,
            "logloss": 2.7692004521565665,
            "mae": 0.4280525956531627,
            "precision": 0.5492102065613609,
            "recall": 0.9300411522633745
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7852488741186869,
            "auditor_fn_violation": 0.006246071284490604,
            "auditor_fp_violation": 0.020177266566395687,
            "ave_precision_score": 0.7866341938994365,
            "fpr": 0.407244785949506,
            "logloss": 2.570172405320155,
            "mae": 0.4214353356285493,
            "precision": 0.5442260442260443,
            "recall": 0.9465811965811965
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 12498,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7705441959952328,
            "auditor_fn_violation": 0.003948270882968738,
            "auditor_fp_violation": 0.013621200889547817,
            "ave_precision_score": 0.7713190623868162,
            "fpr": 0.14802631578947367,
            "logloss": 0.5448387849888814,
            "mae": 0.3762907961285428,
            "precision": 0.735812133072407,
            "recall": 0.7736625514403292
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7493689886378073,
            "auditor_fn_violation": 0.009091164963832367,
            "auditor_fp_violation": 0.020766998783367574,
            "ave_precision_score": 0.7403020705042813,
            "fpr": 0.19209659714599342,
            "logloss": 0.5822004829364423,
            "mae": 0.3938264509194769,
            "precision": 0.6679316888045541,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8542974160283295,
            "auditor_fn_violation": 0.006524799653454632,
            "auditor_fp_violation": 0.009863273206490407,
            "ave_precision_score": 0.8516607902139177,
            "fpr": 0.07017543859649122,
            "logloss": 0.48648992895998444,
            "mae": 0.3181047849316281,
            "precision": 0.843520782396088,
            "recall": 0.7098765432098766
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8538597145672202,
            "auditor_fn_violation": 0.011497649807199757,
            "auditor_fp_violation": 0.00986190850230318,
            "ave_precision_score": 0.8523745093248545,
            "fpr": 0.0867178924259056,
            "logloss": 0.4955714452457003,
            "mae": 0.32637416734130137,
            "precision": 0.8073170731707318,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6039431924400205,
            "auditor_fn_violation": 0.002770558082448933,
            "auditor_fp_violation": 0.014053619965406472,
            "ave_precision_score": 0.5981539292507627,
            "fpr": 0.10964912280701754,
            "logloss": 2.5547435549725317,
            "mae": 0.49333549272124566,
            "precision": 0.5780590717299579,
            "recall": 0.28189300411522633
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5441438468848023,
            "auditor_fn_violation": 0.002157861652922035,
            "auditor_fp_violation": 0.012401721621614922,
            "ave_precision_score": 0.5419211666405274,
            "fpr": 0.1163556531284303,
            "logloss": 2.5014350294647563,
            "mae": 0.49902523542716154,
            "precision": 0.5391304347826087,
            "recall": 0.26495726495726496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 12498,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6401835727911048,
            "auditor_fn_violation": 0.007287379972565158,
            "auditor_fp_violation": 0.04035396590066717,
            "ave_precision_score": 0.6105998718385313,
            "fpr": 0.19736842105263158,
            "logloss": 3.1261613539259265,
            "mae": 0.3965724406247191,
            "precision": 0.6885813148788927,
            "recall": 0.8189300411522634
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6180718512204966,
            "auditor_fn_violation": 0.013191102104384215,
            "auditor_fp_violation": 0.031226073102016246,
            "ave_precision_score": 0.5944184606171601,
            "fpr": 0.20965971459934138,
            "logloss": 3.0156867479810705,
            "mae": 0.4023061982947928,
            "precision": 0.6684027777777778,
            "recall": 0.8226495726495726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6312336862943345,
            "auditor_fn_violation": 0.0912524366471735,
            "auditor_fp_violation": 0.05661086401449634,
            "ave_precision_score": 0.6166595760006324,
            "fpr": 0.12280701754385964,
            "logloss": 0.7075669147822974,
            "mae": 0.4754178116725821,
            "precision": 0.6455696202531646,
            "recall": 0.41975308641975306
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5853014327075974,
            "auditor_fn_violation": 0.09244560781333558,
            "auditor_fp_violation": 0.0679703548056981,
            "ave_precision_score": 0.5813701257147363,
            "fpr": 0.15697036223929747,
            "logloss": 0.7034854211444079,
            "mae": 0.4767202839093553,
            "precision": 0.6038781163434903,
            "recall": 0.4658119658119658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6925382222848626,
            "auditor_fn_violation": 0.008711013645224175,
            "auditor_fp_violation": 0.010903138127007666,
            "ave_precision_score": 0.6934389078059278,
            "fpr": 0.15350877192982457,
            "logloss": 0.7403271835634491,
            "mae": 0.40571586234778934,
            "precision": 0.6796338672768879,
            "recall": 0.6111111111111112
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6686472337471252,
            "auditor_fn_violation": 0.010688451687353993,
            "auditor_fp_violation": 0.001786541716120748,
            "ave_precision_score": 0.6694643081014082,
            "fpr": 0.17453347969264543,
            "logloss": 0.7461294665325974,
            "mae": 0.41614357105230876,
            "precision": 0.6336405529953917,
            "recall": 0.5876068376068376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7389156349227601,
            "auditor_fn_violation": 0.003025503573749188,
            "auditor_fp_violation": 0.004447739065974805,
            "ave_precision_score": 0.5377360472438593,
            "fpr": 0.3980263157894737,
            "logloss": 0.7153438123801722,
            "mae": 0.49699834377436974,
            "precision": 0.5381679389312977,
            "recall": 0.8703703703703703
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.7094550827958269,
            "auditor_fn_violation": 6.567405030632364e-05,
            "auditor_fp_violation": 0.010379782591996987,
            "ave_precision_score": 0.5111628637424753,
            "fpr": 0.40175631174533477,
            "logloss": 0.6905926895529526,
            "mae": 0.49608132169103,
            "precision": 0.5093833780160858,
            "recall": 0.811965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5279181652804938,
            "auditor_fn_violation": 0.006829380550140783,
            "auditor_fp_violation": 0.03500535375998682,
            "ave_precision_score": 0.522995914544243,
            "fpr": 0.18201754385964913,
            "logloss": 0.8845759196550871,
            "mae": 0.5194904636121926,
            "precision": 0.5160349854227405,
            "recall": 0.36419753086419754
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5085302025383083,
            "auditor_fn_violation": 0.015095649563267567,
            "auditor_fp_violation": 0.033495798777420704,
            "ave_precision_score": 0.5025577016029028,
            "fpr": 0.1712403951701427,
            "logloss": 0.8785127001481055,
            "mae": 0.515407470342193,
            "precision": 0.4657534246575342,
            "recall": 0.2905982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6856143127390684,
            "auditor_fn_violation": 0.03172604866074652,
            "auditor_fp_violation": 0.05497899678774401,
            "ave_precision_score": 0.6865048288944399,
            "fpr": 0.2730263157894737,
            "logloss": 0.6510899274156786,
            "mae": 0.43855789936660267,
            "precision": 0.6300148588410104,
            "recall": 0.8724279835390947
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6774375107237076,
            "auditor_fn_violation": 0.03372362483229663,
            "auditor_fp_violation": 0.05443377034638097,
            "ave_precision_score": 0.6785399189119142,
            "fpr": 0.29637760702524696,
            "logloss": 0.6563601283916429,
            "mae": 0.4430682386903442,
            "precision": 0.5988112927191679,
            "recall": 0.8611111111111112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8226728362838018,
            "auditor_fn_violation": 0.013888888888888893,
            "auditor_fp_violation": 0.015000823655382588,
            "ave_precision_score": 0.8229283605207938,
            "fpr": 0.07346491228070176,
            "logloss": 0.6939051286610123,
            "mae": 0.34126303507808303,
            "precision": 0.8159340659340659,
            "recall": 0.6111111111111112
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7765474537428294,
            "auditor_fn_violation": 0.011811947047951443,
            "auditor_fp_violation": 0.01271888852822166,
            "ave_precision_score": 0.7769268066205506,
            "fpr": 0.09769484083424808,
            "logloss": 0.7454184239121969,
            "mae": 0.3575698780424101,
            "precision": 0.7574931880108992,
            "recall": 0.594017094017094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6476292760513679,
            "auditor_fn_violation": 0.014660493827160493,
            "auditor_fp_violation": 0.017291615188205257,
            "ave_precision_score": 0.6396463495349505,
            "fpr": 0.33771929824561403,
            "logloss": 0.6785203931123983,
            "mae": 0.4535481802263428,
            "precision": 0.5904255319148937,
            "recall": 0.9135802469135802
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6263012096272841,
            "auditor_fn_violation": 0.020560668749472263,
            "auditor_fp_violation": 0.02456804592973267,
            "ave_precision_score": 0.6189601642584828,
            "fpr": 0.36443468715697036,
            "logloss": 0.6749444976328217,
            "mae": 0.4569348793938903,
            "precision": 0.5620052770448549,
            "recall": 0.9102564102564102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6839026884847758,
            "auditor_fn_violation": 0.016122482131254067,
            "auditor_fp_violation": 0.027252697471377988,
            "ave_precision_score": 0.6852621090293152,
            "fpr": 0.17543859649122806,
            "logloss": 0.7482443989221363,
            "mae": 0.3585704611840284,
            "precision": 0.6928982725527831,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6909100312216289,
            "auditor_fn_violation": 0.007083415425896218,
            "auditor_fp_violation": 0.023737960666347847,
            "ave_precision_score": 0.6925361866543109,
            "fpr": 0.19099890230515917,
            "logloss": 0.7215079855002701,
            "mae": 0.3519213885035924,
            "precision": 0.6753731343283582,
            "recall": 0.7735042735042735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7656362076347893,
            "auditor_fn_violation": 0.029821854017760455,
            "auditor_fp_violation": 0.020128078411992427,
            "ave_precision_score": 0.7664316601826233,
            "fpr": 0.15350877192982457,
            "logloss": 1.1941050716047759,
            "mae": 0.39943682231831334,
            "precision": 0.7244094488188977,
            "recall": 0.757201646090535
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7850229192428656,
            "auditor_fn_violation": 0.023905354311501405,
            "auditor_fp_violation": 0.020115319904949042,
            "ave_precision_score": 0.7855591965041916,
            "fpr": 0.17892425905598244,
            "logloss": 1.0790515494429502,
            "mae": 0.39662379167627854,
            "precision": 0.6907020872865275,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7506123784317426,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7487436221822241,
            "fpr": 0.46710526315789475,
            "logloss": 4.322722738655865,
            "mae": 0.4650628357602839,
            "precision": 0.5328947368421053,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.7192337833077749,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7155460486331597,
            "fpr": 0.4862788144895719,
            "logloss": 4.598763868801652,
            "mae": 0.48487965839492764,
            "precision": 0.5137211855104281,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.7453895555874906,
            "auditor_fn_violation": 0.0039257093350660716,
            "auditor_fp_violation": 0.01320422535211268,
            "ave_precision_score": 0.7580040795706233,
            "fpr": 0.08114035087719298,
            "logloss": 0.542833617190623,
            "mae": 0.3688619939871786,
            "precision": 0.8262910798122066,
            "recall": 0.7242798353909465
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.6472905410981434,
            "auditor_fn_violation": 0.01080807227898337,
            "auditor_fp_violation": 0.0069454596813959294,
            "ave_precision_score": 0.7067344082302977,
            "fpr": 0.09549945115257959,
            "logloss": 0.5632463190584632,
            "mae": 0.37785443114004336,
            "precision": 0.7928571428571428,
            "recall": 0.7115384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.812360757493046,
            "auditor_fn_violation": 0.005624593892137757,
            "auditor_fp_violation": 0.019757433489827857,
            "ave_precision_score": 0.8084922979086167,
            "fpr": 0.17653508771929824,
            "logloss": 0.5116584693244335,
            "mae": 0.33560074924638394,
            "precision": 0.7243150684931506,
            "recall": 0.8703703703703703
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8208613047316133,
            "auditor_fn_violation": 0.0019491119930197885,
            "auditor_fp_violation": 0.008253773171148717,
            "ave_precision_score": 0.8151635149807712,
            "fpr": 0.21405049396267836,
            "logloss": 0.5280141284585685,
            "mae": 0.34503793196280363,
            "precision": 0.6782178217821783,
            "recall": 0.8782051282051282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7664473684210527,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5328947368421053,
            "fpr": 0.46710526315789475,
            "logloss": 0.6920799440450753,
            "mae": 0.49937667266318675,
            "precision": 0.5328947368421053,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.7568605927552141,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5137211855104281,
            "fpr": 0.4862788144895719,
            "logloss": 0.6928066760763218,
            "mae": 0.49973999518332707,
            "precision": 0.5137211855104281,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7465703191536373,
            "auditor_fn_violation": 0.013157894736842106,
            "auditor_fp_violation": 0.024344164401614368,
            "ave_precision_score": 0.7393295690703687,
            "fpr": 0.16885964912280702,
            "logloss": 0.636792500727696,
            "mae": 0.4071243869438759,
            "precision": 0.7015503875968992,
            "recall": 0.7448559670781894
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7490079978246708,
            "auditor_fn_violation": 0.013510090348729213,
            "auditor_fp_violation": 0.013202072487505354,
            "ave_precision_score": 0.7153255334403714,
            "fpr": 0.19978046103183314,
            "logloss": 0.605788932057918,
            "mae": 0.4126111036969979,
            "precision": 0.6642066420664207,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8066427946311738,
            "auditor_fn_violation": 0.014890621615767813,
            "auditor_fp_violation": 0.02424120747879088,
            "ave_precision_score": 0.8074386304589666,
            "fpr": 0.14912280701754385,
            "logloss": 0.8208648704340524,
            "mae": 0.28871686410383524,
            "precision": 0.7322834645669292,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8250933387123159,
            "auditor_fn_violation": 0.012459305543828047,
            "auditor_fp_violation": 0.022987167129614718,
            "ave_precision_score": 0.8253300881312878,
            "fpr": 0.18111964873765093,
            "logloss": 0.8151030660527538,
            "mae": 0.2966919646362712,
            "precision": 0.6915887850467289,
            "recall": 0.7905982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5396938457822378,
            "auditor_fn_violation": 0.005049274420619475,
            "auditor_fp_violation": 0.008571163825055598,
            "ave_precision_score": 0.512889061693861,
            "fpr": 0.05921052631578947,
            "logloss": 0.737158793436875,
            "mae": 0.5081915488239916,
            "precision": 0.5909090909090909,
            "recall": 0.16049382716049382
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.4702687419879319,
            "auditor_fn_violation": 0.01043982849690864,
            "auditor_fp_violation": 0.006469709321485831,
            "ave_precision_score": 0.4718365671758792,
            "fpr": 0.07903402854006586,
            "logloss": 0.7315617799436093,
            "mae": 0.510506872330004,
            "precision": 0.48201438848920863,
            "recall": 0.14316239316239315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6475119404507378,
            "auditor_fn_violation": 0.02202007075301423,
            "auditor_fp_violation": 0.013456469813030232,
            "ave_precision_score": 0.6151952174664965,
            "fpr": 0.18859649122807018,
            "logloss": 6.711977105010056,
            "mae": 0.35847150736943145,
            "precision": 0.6600790513833992,
            "recall": 0.6872427983539094
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6564552579311532,
            "auditor_fn_violation": 0.00823271130625687,
            "auditor_fp_violation": 0.02294256553337314,
            "ave_precision_score": 0.6206678203068796,
            "fpr": 0.2074643249176729,
            "logloss": 6.084816125259893,
            "mae": 0.3450044727082858,
            "precision": 0.6413662239089184,
            "recall": 0.7222222222222222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6698261883884831,
            "auditor_fn_violation": 0.055738304093567254,
            "auditor_fp_violation": 0.0627625401531999,
            "ave_precision_score": 0.6705262447536485,
            "fpr": 0.17763157894736842,
            "logloss": 3.422913695401386,
            "mae": 0.4240577121783421,
            "precision": 0.6326530612244898,
            "recall": 0.5740740740740741
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6901310598435693,
            "auditor_fn_violation": 0.047958475236192045,
            "auditor_fp_violation": 0.060103128801976345,
            "ave_precision_score": 0.6903800592135392,
            "fpr": 0.1964873765093304,
            "logloss": 2.972332416831018,
            "mae": 0.4128343408146885,
            "precision": 0.6125541125541125,
            "recall": 0.6047008547008547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8680760529217841,
            "auditor_fn_violation": 0.008984008374846595,
            "auditor_fp_violation": 0.00810785767234989,
            "ave_precision_score": 0.8684345895033272,
            "fpr": 0.046052631578947366,
            "logloss": 0.5108595584541078,
            "mae": 0.34860019261638325,
            "precision": 0.8768328445747801,
            "recall": 0.6152263374485597
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8485356595661107,
            "auditor_fn_violation": 0.007866813025978782,
            "auditor_fp_violation": 0.0007805279342275126,
            "ave_precision_score": 0.8488111941223853,
            "fpr": 0.04610318331503842,
            "logloss": 0.5168203372380281,
            "mae": 0.3529356644375395,
            "precision": 0.8719512195121951,
            "recall": 0.6111111111111112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8576319974780666,
            "auditor_fn_violation": 0.012296043606959788,
            "auditor_fp_violation": 0.008288032287291,
            "ave_precision_score": 0.8474644654171108,
            "fpr": 0.0800438596491228,
            "logloss": 0.5035314992796626,
            "mae": 0.3138476296559307,
            "precision": 0.8261904761904761,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8546783196063349,
            "auditor_fn_violation": 0.002899040220664813,
            "auditor_fp_violation": 0.01641090955044069,
            "ave_precision_score": 0.8441598977523819,
            "fpr": 0.09330406147091108,
            "logloss": 0.48787360544281694,
            "mae": 0.3113778219632416,
            "precision": 0.8,
            "recall": 0.7264957264957265
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7903244574385357,
            "auditor_fn_violation": 0.004519078044906506,
            "auditor_fp_violation": 0.03314698130302281,
            "ave_precision_score": 0.6201517276448271,
            "fpr": 0.28728070175438597,
            "logloss": 0.6340251729209357,
            "mae": 0.45189497443406207,
            "precision": 0.6251788268955651,
            "recall": 0.8991769547325102
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7700519760947657,
            "auditor_fn_violation": 0.012055879234803496,
            "auditor_fp_violation": 0.03656091958579984,
            "ave_precision_score": 0.5920180450851961,
            "fpr": 0.3040614709110867,
            "logloss": 0.6482005335614639,
            "mae": 0.4584537685800724,
            "precision": 0.5967976710334789,
            "recall": 0.8760683760683761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6551685582500756,
            "auditor_fn_violation": 0.017049761750054144,
            "auditor_fp_violation": 0.03982888559426736,
            "ave_precision_score": 0.6444319499180728,
            "fpr": 0.17105263157894737,
            "logloss": 4.61661916769709,
            "mae": 0.3793565269821302,
            "precision": 0.6770186335403726,
            "recall": 0.6728395061728395
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6316761844847159,
            "auditor_fn_violation": 0.01039995496636551,
            "auditor_fp_violation": 0.029300770864255046,
            "ave_precision_score": 0.6192348317902451,
            "fpr": 0.18331503841931943,
            "logloss": 4.582828179007104,
            "mae": 0.3885101239908985,
            "precision": 0.6520833333333333,
            "recall": 0.6688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7577869105620494,
            "auditor_fn_violation": 0.01614955598873728,
            "auditor_fp_violation": 0.01654775142080554,
            "ave_precision_score": 0.5454451150681296,
            "fpr": 0.4133771929824561,
            "logloss": 0.6938791920357247,
            "mae": 0.4900066761724782,
            "precision": 0.54632972322503,
            "recall": 0.934156378600823
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7568047192456062,
            "auditor_fn_violation": 0.006246071284490604,
            "auditor_fp_violation": 0.019964170051019265,
            "ave_precision_score": 0.5382042103454239,
            "fpr": 0.4149286498353458,
            "logloss": 0.6932703009976563,
            "mae": 0.48976082950994027,
            "precision": 0.5395858708891595,
            "recall": 0.9465811965811965
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8613262392465402,
            "auditor_fn_violation": 0.00600362789690276,
            "auditor_fp_violation": 0.011716497817313237,
            "ave_precision_score": 0.8612980715361498,
            "fpr": 0.08771929824561403,
            "logloss": 0.49001155322248235,
            "mae": 0.3285351840977296,
            "precision": 0.8177676537585421,
            "recall": 0.7386831275720165
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8315032078408096,
            "auditor_fn_violation": 0.004777787159784964,
            "auditor_fp_violation": 0.013687734313246921,
            "ave_precision_score": 0.8313883309896384,
            "fpr": 0.11086717892425905,
            "logloss": 0.513732211374051,
            "mae": 0.33853961359586826,
            "precision": 0.773542600896861,
            "recall": 0.7371794871794872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7759034426181384,
            "auditor_fn_violation": 0.03897733015666741,
            "auditor_fp_violation": 0.031188225846305904,
            "ave_precision_score": 0.7427472204009367,
            "fpr": 0.08223684210526316,
            "logloss": 0.6626394796710157,
            "mae": 0.4069727986614197,
            "precision": 0.7634069400630915,
            "recall": 0.49794238683127573
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7479548439192114,
            "auditor_fn_violation": 0.03752099224108006,
            "auditor_fp_violation": 0.03749507524041499,
            "ave_precision_score": 0.7240269525702084,
            "fpr": 0.10098792535675083,
            "logloss": 0.6348754273396865,
            "mae": 0.4021636683332328,
            "precision": 0.7363896848137536,
            "recall": 0.5491452991452992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8664240666891556,
            "auditor_fn_violation": 0.008243989603638736,
            "auditor_fp_violation": 0.008169631826043983,
            "ave_precision_score": 0.8664383191326233,
            "fpr": 0.029605263157894735,
            "logloss": 0.5397193132023844,
            "mae": 0.3474329637216502,
            "precision": 0.9045936395759717,
            "recall": 0.5267489711934157
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8362692453839712,
            "auditor_fn_violation": 0.008406278439209287,
            "auditor_fp_violation": 0.00627148000485662,
            "ave_precision_score": 0.8362525113807505,
            "fpr": 0.04500548847420417,
            "logloss": 0.5509002418375156,
            "mae": 0.3545016643440946,
            "precision": 0.8581314878892734,
            "recall": 0.5299145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.755433688921288,
            "auditor_fn_violation": 0.01538471951483648,
            "auditor_fp_violation": 0.02521929824561404,
            "ave_precision_score": 0.6698363005817741,
            "fpr": 0.15570175438596492,
            "logloss": 0.6244660090883299,
            "mae": 0.42018601003413397,
            "precision": 0.7072164948453609,
            "recall": 0.7057613168724279
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.760200679216039,
            "auditor_fn_violation": 0.0049724638089072805,
            "auditor_fp_violation": 0.018420459247769302,
            "ave_precision_score": 0.6664285153193155,
            "fpr": 0.1800219538968167,
            "logloss": 0.6238594580361185,
            "mae": 0.41955469394129274,
            "precision": 0.6771653543307087,
            "recall": 0.7350427350427351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6188961394933434,
            "auditor_fn_violation": 0.05603837268067288,
            "auditor_fp_violation": 0.07545712873733632,
            "ave_precision_score": 0.6197003829104002,
            "fpr": 0.25,
            "logloss": 0.6868069524329513,
            "mae": 0.4883540553743379,
            "precision": 0.5538160469667319,
            "recall": 0.5823045267489712
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5768327476014719,
            "auditor_fn_violation": 0.056238096578381976,
            "auditor_fp_violation": 0.07288396399164464,
            "ave_precision_score": 0.5777294212060831,
            "fpr": 0.2601536772777168,
            "logloss": 0.6952186366618224,
            "mae": 0.49262790249417304,
            "precision": 0.5316205533596838,
            "recall": 0.5747863247863247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7476907745171558,
            "auditor_fn_violation": 0.032360028156811785,
            "auditor_fp_violation": 0.0456819866567828,
            "ave_precision_score": 0.7256030413583114,
            "fpr": 0.09210526315789473,
            "logloss": 0.58413468659919,
            "mae": 0.393672611237618,
            "precision": 0.7862595419847328,
            "recall": 0.6358024691358025
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6986879341199483,
            "auditor_fn_violation": 0.027733213243641343,
            "auditor_fp_violation": 0.04258461294486995,
            "ave_precision_score": 0.6858904600077531,
            "fpr": 0.1163556531284303,
            "logloss": 0.5926052770756746,
            "mae": 0.3995420449586129,
            "precision": 0.7476190476190476,
            "recall": 0.6709401709401709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.716650170649169,
            "auditor_fn_violation": 0.016618836185112992,
            "auditor_fp_violation": 0.025162671938061116,
            "ave_precision_score": 0.6892852300319736,
            "fpr": 0.13706140350877194,
            "logloss": 0.6397898788070538,
            "mae": 0.423143365644424,
            "precision": 0.7184684684684685,
            "recall": 0.6563786008230452
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7170166807753097,
            "auditor_fn_violation": 0.007901995552928592,
            "auditor_fp_violation": 0.017971965418895716,
            "ave_precision_score": 0.6861350442511276,
            "fpr": 0.15916575192096596,
            "logloss": 0.6145583028720027,
            "mae": 0.41919346538711744,
            "precision": 0.6927966101694916,
            "recall": 0.6987179487179487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6512118356415664,
            "auditor_fn_violation": 0.004697314273337677,
            "auditor_fp_violation": 0.004895601680256983,
            "ave_precision_score": 0.6491200803640631,
            "fpr": 0.03618421052631579,
            "logloss": 1.9784331693524224,
            "mae": 0.46175772238156243,
            "precision": 0.7441860465116279,
            "recall": 0.19753086419753085
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6426473394784531,
            "auditor_fn_violation": 0.011117678516141753,
            "auditor_fp_violation": 0.007277493786749859,
            "ave_precision_score": 0.6426132161552459,
            "fpr": 0.030735455543358946,
            "logloss": 1.809911728961078,
            "mae": 0.45012312146521877,
            "precision": 0.7894736842105263,
            "recall": 0.22435897435897437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7667516289021801,
            "auditor_fn_violation": 0.017500992708107718,
            "auditor_fp_violation": 0.022704575405650275,
            "ave_precision_score": 0.7648591512699339,
            "fpr": 0.09320175438596491,
            "logloss": 0.9721405913944935,
            "mae": 0.36788911560974386,
            "precision": 0.7571428571428571,
            "recall": 0.5452674897119342
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7793589250935655,
            "auditor_fn_violation": 0.009020799909932738,
            "auditor_fp_violation": 0.015114985392977235,
            "ave_precision_score": 0.7787960022994951,
            "fpr": 0.1141602634467618,
            "logloss": 0.6977150969869419,
            "mae": 0.3528760630869126,
            "precision": 0.7312661498708011,
            "recall": 0.6047008547008547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 12498,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8178707432232666,
            "auditor_fn_violation": 0.004043029384159996,
            "auditor_fp_violation": 0.010136109051972658,
            "ave_precision_score": 0.7638546251046807,
            "fpr": 0.07675438596491228,
            "logloss": 0.5848401270982587,
            "mae": 0.3576893507556075,
            "precision": 0.8214285714285714,
            "recall": 0.6625514403292181
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8089329388332022,
            "auditor_fn_violation": 0.010747089232270355,
            "auditor_fp_violation": 0.01156172489239865,
            "ave_precision_score": 0.7520847792341544,
            "fpr": 0.08562019758507135,
            "logloss": 0.5868595207633888,
            "mae": 0.3642181223708192,
            "precision": 0.7941952506596306,
            "recall": 0.6431623931623932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.83594929780506,
            "auditor_fn_violation": 0.03585481192693669,
            "auditor_fp_violation": 0.020735524256651015,
            "ave_precision_score": 0.8174205257690523,
            "fpr": 0.1074561403508772,
            "logloss": 0.5385231801583016,
            "mae": 0.38143034479499127,
            "precision": 0.7836644591611479,
            "recall": 0.7304526748971193
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8083168030912988,
            "auditor_fn_violation": 0.02546276750447991,
            "auditor_fp_violation": 0.02388663265381976,
            "ave_precision_score": 0.7987390863998717,
            "fpr": 0.13391877058177826,
            "logloss": 0.5605484053942394,
            "mae": 0.3902803168649469,
            "precision": 0.7426160337552743,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6092887662808273,
            "auditor_fn_violation": 0.01439652371669919,
            "auditor_fp_violation": 0.0040256156823984856,
            "ave_precision_score": 0.6639543695503463,
            "fpr": 0.015350877192982455,
            "logloss": 2.1415153487829617,
            "mae": 0.5287260936921373,
            "precision": 0.6410256410256411,
            "recall": 0.051440329218107
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5555692511681418,
            "auditor_fn_violation": 0.00540169063769503,
            "auditor_fp_violation": 0.008702267000022301,
            "ave_precision_score": 0.6222662515050119,
            "fpr": 0.025246981339187707,
            "logloss": 2.1218029055665926,
            "mae": 0.5268702759631346,
            "precision": 0.4523809523809524,
            "recall": 0.0405982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8145184123513414,
            "auditor_fn_violation": 0.01767020431737781,
            "auditor_fp_violation": 0.019278683798698633,
            "ave_precision_score": 0.8149396696381526,
            "fpr": 0.1337719298245614,
            "logloss": 1.0468163808825992,
            "mae": 0.2994682703612943,
            "precision": 0.7415254237288136,
            "recall": 0.720164609053498
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8185511330833765,
            "auditor_fn_violation": 0.011110642010751782,
            "auditor_fp_violation": 0.019114261855971537,
            "ave_precision_score": 0.8187937453960482,
            "fpr": 0.16465422612513722,
            "logloss": 0.9730203855556249,
            "mae": 0.2997870208613947,
            "precision": 0.7029702970297029,
            "recall": 0.7585470085470085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7399779699406752,
            "auditor_fn_violation": 0.00788977330156668,
            "auditor_fp_violation": 0.011253191664607531,
            "ave_precision_score": 0.7405051726609876,
            "fpr": 0.32346491228070173,
            "logloss": 0.9830693389599706,
            "mae": 0.4245841417281905,
            "precision": 0.5761494252873564,
            "recall": 0.8251028806584362
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7594596321034854,
            "auditor_fn_violation": 0.007149089476202541,
            "auditor_fp_violation": 0.00230937153873029,
            "ave_precision_score": 0.7597894386440166,
            "fpr": 0.34357848518111966,
            "logloss": 0.985671706525432,
            "mae": 0.42302160722364057,
            "precision": 0.5560283687943263,
            "recall": 0.8376068376068376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.5794661966382063,
            "auditor_fn_violation": 0.02675799581257671,
            "auditor_fp_violation": 0.038480149905279655,
            "ave_precision_score": 0.5817746142960506,
            "fpr": 0.27521929824561403,
            "logloss": 2.9682818932565884,
            "mae": 0.425726846336082,
            "precision": 0.6034755134281201,
            "recall": 0.7860082304526749
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.5974103127245538,
            "auditor_fn_violation": 0.02333305187311774,
            "auditor_fp_violation": 0.03980940251206102,
            "ave_precision_score": 0.6003508283160318,
            "fpr": 0.29527991218441274,
            "logloss": 2.50496320702226,
            "mae": 0.4191321719514669,
            "precision": 0.5861538461538461,
            "recall": 0.8141025641025641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8517403413622028,
            "auditor_fn_violation": 0.029429283084253847,
            "auditor_fp_violation": 0.029970760233918134,
            "ave_precision_score": 0.8522087621832842,
            "fpr": 0.15570175438596492,
            "logloss": 0.5111068205924325,
            "mae": 0.32785107005028086,
            "precision": 0.7305502846299811,
            "recall": 0.7921810699588477
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8407335870233428,
            "auditor_fn_violation": 0.02551905954759961,
            "auditor_fp_violation": 0.023539731349718637,
            "ave_precision_score": 0.8409779803219402,
            "fpr": 0.1690450054884742,
            "logloss": 0.5284698443527552,
            "mae": 0.33658755284403863,
            "precision": 0.7158671586715867,
            "recall": 0.8290598290598291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 12498,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.8189015454520983,
            "auditor_fn_violation": 0.024799653454624232,
            "auditor_fp_violation": 0.004761757680586443,
            "ave_precision_score": 0.8154540476044967,
            "fpr": 0.03179824561403509,
            "logloss": 0.7216367305468362,
            "mae": 0.4093334618792461,
            "precision": 0.867579908675799,
            "recall": 0.39094650205761317
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7729954612603297,
            "auditor_fn_violation": 0.025816938275774727,
            "auditor_fp_violation": 0.0042693639069016015,
            "ave_precision_score": 0.7758267636892535,
            "fpr": 0.042810098792535674,
            "logloss": 0.6922931658505354,
            "mae": 0.4014795168980743,
            "precision": 0.8414634146341463,
            "recall": 0.4423076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7781809600558641,
            "auditor_fn_violation": 0.02842980651216519,
            "auditor_fp_violation": 0.023376369327073553,
            "ave_precision_score": 0.6600112160408069,
            "fpr": 0.14583333333333334,
            "logloss": 0.6391117679792211,
            "mae": 0.4241016504371114,
            "precision": 0.7057522123893806,
            "recall": 0.6563786008230452
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7749595442433874,
            "auditor_fn_violation": 0.011052004465835421,
            "auditor_fp_violation": 0.024342560082066936,
            "ave_precision_score": 0.6493741254024339,
            "fpr": 0.1602634467618002,
            "logloss": 0.62607699583209,
            "mae": 0.41843142634427377,
            "precision": 0.6919831223628692,
            "recall": 0.7008547008547008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6655165209978524,
            "auditor_fn_violation": 0.004503284961374628,
            "auditor_fp_violation": 0.0024864096861872994,
            "ave_precision_score": 0.6460105162506156,
            "fpr": 0.01644736842105263,
            "logloss": 0.7980194339893921,
            "mae": 0.4621732066173041,
            "precision": 0.6341463414634146,
            "recall": 0.053497942386831275
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6256455981264123,
            "auditor_fn_violation": 0.004878643737041117,
            "auditor_fp_violation": 0.0025100787218173674,
            "ave_precision_score": 0.6095317047093384,
            "fpr": 0.018660812294182216,
            "logloss": 0.7741011229200111,
            "mae": 0.4568906227120584,
            "precision": 0.6046511627906976,
            "recall": 0.05555555555555555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.745728728142393,
            "auditor_fn_violation": 0.005195924481986865,
            "auditor_fp_violation": 0.0031427600691870477,
            "ave_precision_score": 0.746280612509457,
            "fpr": 0.19407894736842105,
            "logloss": 0.6818677063597411,
            "mae": 0.4396254660422799,
            "precision": 0.647410358565737,
            "recall": 0.668724279835391
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7749429696319299,
            "auditor_fn_violation": 0.010721288712507162,
            "auditor_fp_violation": 0.008964920844556015,
            "ave_precision_score": 0.7752030698726606,
            "fpr": 0.2074643249176729,
            "logloss": 0.6385617697376929,
            "mae": 0.424213569462054,
            "precision": 0.6351351351351351,
            "recall": 0.7029914529914529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6209820041588382,
            "auditor_fn_violation": 0.1321317052920367,
            "auditor_fp_violation": 0.11059632649699366,
            "ave_precision_score": 0.5865716073409379,
            "fpr": 0.17982456140350878,
            "logloss": 0.6828188389520289,
            "mae": 0.4921922156946701,
            "precision": 0.6177156177156177,
            "recall": 0.5452674897119342
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5827423820589271,
            "auditor_fn_violation": 0.12782984791766352,
            "auditor_fp_violation": 0.11926466834996396,
            "ave_precision_score": 0.5507082067741232,
            "fpr": 0.20965971459934138,
            "logloss": 0.6864114423122455,
            "mae": 0.4937979195565476,
            "precision": 0.5668934240362812,
            "recall": 0.5341880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7003043458173928,
            "auditor_fn_violation": 0.008562107429066509,
            "auditor_fp_violation": 0.017394572111028753,
            "ave_precision_score": 0.6966457754698967,
            "fpr": 0.17982456140350878,
            "logloss": 7.870275929024063,
            "mae": 0.453065991138781,
            "precision": 0.5848101265822785,
            "recall": 0.47530864197530864
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6385062816532692,
            "auditor_fn_violation": 0.007017741375589908,
            "auditor_fp_violation": 0.019813020197089505,
            "ave_precision_score": 0.6381065804114872,
            "fpr": 0.21075740944017562,
            "logloss": 8.13064125486468,
            "mae": 0.4763580921872012,
            "precision": 0.5339805825242718,
            "recall": 0.4700854700854701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7066747790970754,
            "auditor_fn_violation": 0.04937369143022164,
            "auditor_fp_violation": 0.04023041759327898,
            "ave_precision_score": 0.706484881447365,
            "fpr": 0.22697368421052633,
            "logloss": 0.6364961258514188,
            "mae": 0.4440613103572998,
            "precision": 0.6316725978647687,
            "recall": 0.7304526748971193
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6756273362252367,
            "auditor_fn_violation": 0.036223929747530186,
            "auditor_fp_violation": 0.04565221161970698,
            "ave_precision_score": 0.6803790473832518,
            "fpr": 0.20965971459934138,
            "logloss": 0.6385578800274514,
            "mae": 0.4451091274062967,
            "precision": 0.6508226691042047,
            "recall": 0.7606837606837606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7776726061106061,
            "auditor_fn_violation": 0.018148509132914593,
            "auditor_fp_violation": 0.02191438102297999,
            "ave_precision_score": 0.77799448653662,
            "fpr": 0.1337719298245614,
            "logloss": 1.041010698234741,
            "mae": 0.2965740229042477,
            "precision": 0.7415254237288136,
            "recall": 0.720164609053498
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7953045445000494,
            "auditor_fn_violation": 0.0044329983956767766,
            "auditor_fp_violation": 0.011182611324345296,
            "ave_precision_score": 0.7956631743590432,
            "fpr": 0.1602634467618002,
            "logloss": 0.9970503048470477,
            "mae": 0.2966964916932778,
            "precision": 0.708,
            "recall": 0.7564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7973819441093951,
            "auditor_fn_violation": 0.013672298029023172,
            "auditor_fp_violation": 0.0083086236718557,
            "ave_precision_score": 0.7419377325850539,
            "fpr": 0.08223684210526316,
            "logloss": 0.6615610229176909,
            "mae": 0.41144909028356014,
            "precision": 0.8096446700507615,
            "recall": 0.6563786008230452
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7454415124142982,
            "auditor_fn_violation": 0.005582294276037416,
            "auditor_fp_violation": 0.0039249404692583536,
            "ave_precision_score": 0.6949679558293249,
            "fpr": 0.10537870472008781,
            "logloss": 0.6797865389089558,
            "mae": 0.42047895603986,
            "precision": 0.7623762376237624,
            "recall": 0.6581196581196581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7703435525603826,
            "auditor_fn_violation": 0.052536820446177177,
            "auditor_fp_violation": 0.01635470719051149,
            "ave_precision_score": 0.7489831126926657,
            "fpr": 0.06469298245614036,
            "logloss": 0.6914158866215913,
            "mae": 0.3950199713775267,
            "precision": 0.7649402390438247,
            "recall": 0.3950617283950617
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7689457466700423,
            "auditor_fn_violation": 0.050409524613695855,
            "auditor_fp_violation": 0.019842754594583883,
            "ave_precision_score": 0.7428228978749911,
            "fpr": 0.08232711306256861,
            "logloss": 0.6497912473038264,
            "mae": 0.38005136047887617,
            "precision": 0.7422680412371134,
            "recall": 0.46153846153846156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5170421142060496,
            "auditor_fn_violation": 0.004038517074579473,
            "auditor_fp_violation": 0.006864652829256239,
            "ave_precision_score": 0.5425551074654316,
            "fpr": 0.01864035087719298,
            "logloss": 9.51144044059579,
            "mae": 0.5252359451351561,
            "precision": 0.7017543859649122,
            "recall": 0.0823045267489712
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.48416788267486177,
            "auditor_fn_violation": 0.008213947291883633,
            "auditor_fp_violation": 0.005134139300696529,
            "ave_precision_score": 0.5128892881262441,
            "fpr": 0.029637760702524697,
            "logloss": 9.633939598267672,
            "mae": 0.517294179337096,
            "precision": 0.6625,
            "recall": 0.11324786324786325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7901066613436164,
            "auditor_fn_violation": 0.005563677712800521,
            "auditor_fp_violation": 0.011456531587183941,
            "ave_precision_score": 0.623658617081842,
            "fpr": 0.26864035087719296,
            "logloss": 0.6317670782767888,
            "mae": 0.4489225138370928,
            "precision": 0.6359583952451708,
            "recall": 0.8806584362139918
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7761165208118588,
            "auditor_fn_violation": 0.00474260463283515,
            "auditor_fp_violation": 0.016899049242640133,
            "ave_precision_score": 0.5952533981418969,
            "fpr": 0.29857299670691545,
            "logloss": 0.639656029500879,
            "mae": 0.45370513292358683,
            "precision": 0.6052249637155298,
            "recall": 0.8910256410256411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7250904581414562,
            "auditor_fn_violation": 0.013300032488628988,
            "auditor_fp_violation": 0.02620768470471955,
            "ave_precision_score": 0.7036521763385655,
            "fpr": 0.15460526315789475,
            "logloss": 0.6088180908221894,
            "mae": 0.4150031214547262,
            "precision": 0.70625,
            "recall": 0.6975308641975309
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.728786188035408,
            "auditor_fn_violation": 0.008138891234390686,
            "auditor_fp_violation": 0.016510024208755296,
            "ave_precision_score": 0.6992792786525293,
            "fpr": 0.1800219538968167,
            "logloss": 0.59970996088302,
            "mae": 0.41064146920040856,
            "precision": 0.6752475247524753,
            "recall": 0.7286324786324786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8443502274647782,
            "auditor_fn_violation": 0.010376055880441847,
            "auditor_fp_violation": 0.012980294044971582,
            "ave_precision_score": 0.7894032239263622,
            "fpr": 0.08442982456140351,
            "logloss": 0.5218708809807224,
            "mae": 0.3295842322210471,
            "precision": 0.8225806451612904,
            "recall": 0.7345679012345679
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8331977622357803,
            "auditor_fn_violation": 0.005286761049658963,
            "auditor_fp_violation": 0.002324238737477482,
            "ave_precision_score": 0.7739479110271876,
            "fpr": 0.09879253567508232,
            "logloss": 0.5315845880360407,
            "mae": 0.3389728461708117,
            "precision": 0.792147806004619,
            "recall": 0.7329059829059829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8275009706918919,
            "auditor_fn_violation": 0.006240524149880874,
            "auditor_fp_violation": 0.00929186228482003,
            "ave_precision_score": 0.8143355695480852,
            "fpr": 0.06798245614035088,
            "logloss": 0.5142390889609,
            "mae": 0.3389957879849693,
            "precision": 0.8442211055276382,
            "recall": 0.691358024691358
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7772900174420063,
            "auditor_fn_violation": 0.0036238002758310133,
            "auditor_fp_violation": 0.007844925205600971,
            "ave_precision_score": 0.7762374005703252,
            "fpr": 0.0845225027442371,
            "logloss": 0.5260937914591599,
            "mae": 0.3467153243221645,
            "precision": 0.8065326633165829,
            "recall": 0.6858974358974359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.782054149195377,
            "auditor_fn_violation": 0.014493538372680673,
            "auditor_fp_violation": 0.01757474672596986,
            "ave_precision_score": 0.7310573448648563,
            "fpr": 0.12938596491228072,
            "logloss": 5.00684283819575,
            "mae": 0.29297618692474303,
            "precision": 0.74235807860262,
            "recall": 0.6995884773662552
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7811995211224708,
            "auditor_fn_violation": 0.003553435221931378,
            "auditor_fp_violation": 0.010057659952474523,
            "ave_precision_score": 0.728840742673929,
            "fpr": 0.15806805708013172,
            "logloss": 4.609091953146654,
            "mae": 0.28742352110169017,
            "precision": 0.710261569416499,
            "recall": 0.7542735042735043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6043479910716547,
            "auditor_fn_violation": 0.023306078983466906,
            "auditor_fp_violation": 0.019829503335804303,
            "ave_precision_score": 0.5914997742812655,
            "fpr": 0.17982456140350878,
            "logloss": 0.6728639429479695,
            "mae": 0.4712253959620731,
            "precision": 0.6583333333333333,
            "recall": 0.6502057613168725
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.5754643023777748,
            "auditor_fn_violation": 0.022324486100556363,
            "auditor_fp_violation": 0.013675344980957606,
            "ave_precision_score": 0.5661435217664356,
            "fpr": 0.17892425905598244,
            "logloss": 0.6833640457095241,
            "mae": 0.4765432475034544,
            "precision": 0.6401766004415012,
            "recall": 0.6196581196581197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5960678941858112,
            "auditor_fn_violation": 0.0014665006136741186,
            "auditor_fp_violation": 0.00297545506959888,
            "ave_precision_score": 0.5972244977676986,
            "fpr": 0.007675438596491228,
            "logloss": 1.334067913801019,
            "mae": 0.4952958892246708,
            "precision": 0.8409090909090909,
            "recall": 0.07613168724279835
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5343996064445844,
            "auditor_fn_violation": 0.004888025744227739,
            "auditor_fp_violation": 0.003565649832867908,
            "ave_precision_score": 0.5364831585152255,
            "fpr": 0.01756311745334797,
            "logloss": 1.3953950756825342,
            "mae": 0.5005461340142602,
            "precision": 0.6862745098039216,
            "recall": 0.07478632478632478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6245777096482873,
            "auditor_fn_violation": 0.02861706735975745,
            "auditor_fp_violation": 0.024122807017543862,
            "ave_precision_score": 0.6264512704690937,
            "fpr": 0.07785087719298246,
            "logloss": 1.039668335636204,
            "mae": 0.4753150823546639,
            "precision": 0.6358974358974359,
            "recall": 0.2551440329218107
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5545738948270394,
            "auditor_fn_violation": 0.02596939589255726,
            "auditor_fp_violation": 0.034650484546785834,
            "ave_precision_score": 0.5561177440665785,
            "fpr": 0.10647639956092206,
            "logloss": 0.9491565920865165,
            "mae": 0.4789550862210237,
            "precision": 0.5446009389671361,
            "recall": 0.24786324786324787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7167056008543299,
            "auditor_fn_violation": 0.0019854162154357086,
            "auditor_fp_violation": 0.0023422699942344124,
            "ave_precision_score": 0.7184225910157263,
            "fpr": 0.4583333333333333,
            "logloss": 1.023486633759802,
            "mae": 0.4130496053319228,
            "precision": 0.5355555555555556,
            "recall": 0.9917695473251029
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6636769752378329,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0022647699424887245,
            "ave_precision_score": 0.6651962657684585,
            "fpr": 0.47639956092206365,
            "logloss": 1.112665953440578,
            "mae": 0.42891908256678496,
            "precision": 0.5188470066518847,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8442705034315721,
            "auditor_fn_violation": 0.014085174355642193,
            "auditor_fp_violation": 0.019705955028416114,
            "ave_precision_score": 0.8415534101480712,
            "fpr": 0.09539473684210527,
            "logloss": 0.5360012365881976,
            "mae": 0.3315162510094532,
            "precision": 0.8040540540540541,
            "recall": 0.7345679012345679
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8396778667282851,
            "auditor_fn_violation": 0.00453385497293291,
            "auditor_fp_violation": 0.024092295569822564,
            "ave_precision_score": 0.836666877339512,
            "fpr": 0.11964873765093303,
            "logloss": 0.5031877465991691,
            "mae": 0.3356717672868679,
            "precision": 0.7670940170940171,
            "recall": 0.7670940170940171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6027563012584048,
            "auditor_fn_violation": 0.03666251534185258,
            "auditor_fp_violation": 0.06950107075199738,
            "ave_precision_score": 0.6210444216542034,
            "fpr": 0.2324561403508772,
            "logloss": 0.6452029037220604,
            "mae": 0.45138252689911607,
            "precision": 0.6466666666666666,
            "recall": 0.7983539094650206
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.5780286294332854,
            "auditor_fn_violation": 0.02964714270971132,
            "auditor_fp_violation": 0.07158556196772331,
            "ave_precision_score": 0.5858210356120455,
            "fpr": 0.27552140504939626,
            "logloss": 0.6573491032347265,
            "mae": 0.45916035282297796,
            "precision": 0.6022187004754358,
            "recall": 0.811965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 12498,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5617200882324168,
            "auditor_fn_violation": 0.010085011912497298,
            "auditor_fp_violation": 0.0052533769870686114,
            "ave_precision_score": 0.5548851051757309,
            "fpr": 0.027412280701754384,
            "logloss": 2.446959232910931,
            "mae": 0.5250518952975175,
            "precision": 0.6376811594202898,
            "recall": 0.09053497942386832
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5184977684600353,
            "auditor_fn_violation": 0.0064595119479861724,
            "auditor_fp_violation": 0.0027405203023988223,
            "ave_precision_score": 0.5307509315668855,
            "fpr": 0.03732162458836443,
            "logloss": 2.201950794608788,
            "mae": 0.511834155879344,
            "precision": 0.5952380952380952,
            "recall": 0.10683760683760683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7873200487286826,
            "auditor_fn_violation": 0.021798967583567978,
            "auditor_fp_violation": 0.02597088378222552,
            "ave_precision_score": 0.7369753025632032,
            "fpr": 0.13706140350877194,
            "logloss": 5.869451008795718,
            "mae": 0.3021346543848787,
            "precision": 0.7300215982721382,
            "recall": 0.6954732510288066
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7793333143415914,
            "auditor_fn_violation": 0.012159081313856289,
            "auditor_fp_violation": 0.023948579315266387,
            "ave_precision_score": 0.723634650996934,
            "fpr": 0.16245883644346873,
            "logloss": 5.815627082544444,
            "mae": 0.3098105029814878,
            "precision": 0.6942148760330579,
            "recall": 0.717948717948718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.754424354414428,
            "auditor_fn_violation": 0.008013861815031406,
            "auditor_fp_violation": 0.008880034593526072,
            "ave_precision_score": 0.7559252416759361,
            "fpr": 0.08552631578947369,
            "logloss": 0.5992923580131809,
            "mae": 0.41433939198848974,
            "precision": 0.7880434782608695,
            "recall": 0.5967078189300411
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7519327414946431,
            "auditor_fn_violation": 0.006499385478529288,
            "auditor_fp_violation": 0.011792166472980106,
            "ave_precision_score": 0.7525521291152333,
            "fpr": 0.10318331503841932,
            "logloss": 0.5996830509725435,
            "mae": 0.41239589936908594,
            "precision": 0.7532808398950132,
            "recall": 0.6132478632478633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8344649151806407,
            "auditor_fn_violation": 0.024718431882174572,
            "auditor_fp_violation": 0.008030639980232273,
            "ave_precision_score": 0.8344322112876339,
            "fpr": 0.07894736842105263,
            "logloss": 0.5004568797387706,
            "mae": 0.3197468380023023,
            "precision": 0.8285714285714286,
            "recall": 0.7160493827160493
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8326810036459639,
            "auditor_fn_violation": 0.007536097272650517,
            "auditor_fp_violation": 0.018185061934272117,
            "ave_precision_score": 0.83072874031286,
            "fpr": 0.10208562019758508,
            "logloss": 0.5139876570410763,
            "mae": 0.32633493422774923,
            "precision": 0.7876712328767124,
            "recall": 0.7371794871794872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7466740312399847,
            "auditor_fn_violation": 0.0018004115226337456,
            "auditor_fp_violation": 0.016648134420558437,
            "ave_precision_score": 0.7475687516271519,
            "fpr": 0.3574561403508772,
            "logloss": 0.817796366095861,
            "mae": 0.3786004809907785,
            "precision": 0.5862944162436549,
            "recall": 0.9506172839506173
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7309324830616186,
            "auditor_fn_violation": 0.006159287718014394,
            "auditor_fp_violation": 0.006772009029345392,
            "ave_precision_score": 0.7317778708965849,
            "fpr": 0.38309549945115257,
            "logloss": 0.8890239169301603,
            "mae": 0.39462715257306785,
            "precision": 0.5610062893081761,
            "recall": 0.9529914529914529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8354665346047748,
            "auditor_fn_violation": 0.003551187639881602,
            "auditor_fp_violation": 0.012295630508195371,
            "ave_precision_score": 0.7694397124607988,
            "fpr": 0.0800438596491228,
            "logloss": 0.5645530017988932,
            "mae": 0.3505804228389503,
            "precision": 0.8274231678486997,
            "recall": 0.720164609053498
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8236796227079282,
            "auditor_fn_violation": 0.01080807227898337,
            "auditor_fp_violation": 0.006209533343409988,
            "ave_precision_score": 0.7497497808938112,
            "fpr": 0.09440175631174534,
            "logloss": 0.5390797286504159,
            "mae": 0.35646492850060857,
            "precision": 0.7947494033412887,
            "recall": 0.7115384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8634759403087505,
            "auditor_fn_violation": 0.02202007075301423,
            "auditor_fp_violation": 0.015276233423935423,
            "ave_precision_score": 0.8638197921809305,
            "fpr": 0.10416666666666667,
            "logloss": 0.5044766708435393,
            "mae": 0.3146191723485173,
            "precision": 0.7948164146868251,
            "recall": 0.757201646090535
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8433969898531376,
            "auditor_fn_violation": 0.012440541529454814,
            "auditor_fp_violation": 0.003922462602800482,
            "ave_precision_score": 0.8437131186778799,
            "fpr": 0.1163556531284303,
            "logloss": 0.49796696147124664,
            "mae": 0.323986046713622,
            "precision": 0.771551724137931,
            "recall": 0.7649572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7072775512825696,
            "auditor_fn_violation": 0.008368078117103472,
            "auditor_fp_violation": 0.014480891195123963,
            "ave_precision_score": 0.6734076807939475,
            "fpr": 0.047149122807017545,
            "logloss": 0.657172618973871,
            "mae": 0.4347933887079227,
            "precision": 0.6791044776119403,
            "recall": 0.18724279835390947
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6647381693669722,
            "auditor_fn_violation": 0.007927796072691794,
            "auditor_fp_violation": 0.006055905623022352,
            "ave_precision_score": 0.6211070412090309,
            "fpr": 0.05817782656421515,
            "logloss": 0.6781798450488619,
            "mae": 0.44649905736765666,
            "precision": 0.6418918918918919,
            "recall": 0.202991452991453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6345721885828507,
            "auditor_fn_violation": 0.003867049310519103,
            "auditor_fp_violation": 0.013798801581418343,
            "ave_precision_score": 0.6356644197711501,
            "fpr": 0.08223684210526316,
            "logloss": 0.6908778306441797,
            "mae": 0.4889652435177643,
            "precision": 0.6543778801843319,
            "recall": 0.29218106995884774
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6170835757265581,
            "auditor_fn_violation": 0.0009147457006952035,
            "auditor_fp_violation": 0.006692717302693691,
            "ave_precision_score": 0.6182464715358627,
            "fpr": 0.08122941822173436,
            "logloss": 0.6784882324575264,
            "mae": 0.4863692766625913,
            "precision": 0.6636363636363637,
            "recall": 0.31196581196581197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 12498,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.405532157814246,
            "mae": 0.5328947368421053,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.743301155673105,
            "mae": 0.5137211855104281,
            "precision": 0,
            "recall": 0
        }
    }
]