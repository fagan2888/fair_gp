[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 5740,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.4133084892376582,
            "auditor_fn_violation": 0.10941946756007062,
            "auditor_fp_violation": 0.0937874097007224,
            "ave_precision_score": 0.5494022357950576,
            "fpr": 0.2807017543859649,
            "logloss": 0.6915538767682258,
            "mae": 0.4990780448312299,
            "precision": 0.5608919382504288,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.5056905358541088,
            "auditor_fn_violation": 0.10247815775308683,
            "auditor_fp_violation": 0.09503960601655442,
            "ave_precision_score": 0.5565964558957647,
            "fpr": 0.2524698133918771,
            "logloss": 0.6896878649559175,
            "mae": 0.4981468918556439,
            "precision": 0.5818181818181818,
            "recall": 0.6852248394004282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6904713135558422,
            "mae": 0.49830087306990956,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6878802914518222,
            "mae": 0.4970040755790099,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6904643126228024,
            "mae": 0.49829454804983053,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.687861649916624,
            "mae": 0.49699188914440334,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6906598290968304,
            "mae": 0.4984646895736979,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6883745327882521,
            "mae": 0.49732176401743383,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867815358596818,
            "mae": 0.4944184583922227,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6831296336960342,
            "mae": 0.4925652715560503,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5790401524663912,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5505015901697503,
            "fpr": 0.020833333333333332,
            "logloss": 0.7060159396531427,
            "mae": 0.49502544134463133,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5313926854830759,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5251196827087788,
            "fpr": 0.027442371020856202,
            "logloss": 0.7013790601265281,
            "mae": 0.49446901154390543,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867500617657984,
            "mae": 0.4943681781163864,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6830227207608229,
            "mae": 0.4924771770033433,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867755589889597,
            "mae": 0.4944090494199803,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6831095653040513,
            "mae": 0.4925487998353663,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6868365397585487,
            "mae": 0.49450229020103026,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.683309649133168,
            "mae": 0.49271174483451047,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.396952017763938,
            "auditor_fn_violation": 0.09138927915270724,
            "auditor_fp_violation": 0.09847523219814244,
            "ave_precision_score": 0.5530298274714888,
            "fpr": 0.30372807017543857,
            "logloss": 0.6902429414413345,
            "mae": 0.49788305320237813,
            "precision": 0.5624012638230648,
            "recall": 0.731006160164271
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.5017853123987783,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.1042414533084127,
            "ave_precision_score": 0.554522596328265,
            "fpr": 0.2854006586169045,
            "logloss": 0.6866220974450655,
            "mae": 0.4961960716776215,
            "precision": 0.5723684210526315,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7114568161851725,
            "auditor_fn_violation": 0.002575741201051911,
            "auditor_fp_violation": 0.0033281733746130093,
            "ave_precision_score": 0.561894388091408,
            "fpr": 0.4550438596491228,
            "logloss": 0.7072123999045298,
            "mae": 0.48469963258034304,
            "precision": 0.5378619153674833,
            "recall": 0.9917864476386037
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7168078483398999,
            "auditor_fn_violation": 0.0011470558508075226,
            "auditor_fp_violation": 0.007268519892010563,
            "ave_precision_score": 0.5621804235138469,
            "fpr": 0.4676180021953897,
            "logloss": 0.7084704926859913,
            "mae": 0.4856469609276785,
            "precision": 0.5218855218855218,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7109343543754072,
            "auditor_fn_violation": 0.08107505673835513,
            "auditor_fp_violation": 0.09022703818369454,
            "ave_precision_score": 0.5574201711822536,
            "fpr": 0.2817982456140351,
            "logloss": 0.6859898728630522,
            "mae": 0.49453389132599623,
            "precision": 0.5658783783783784,
            "recall": 0.6878850102669405
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7161384086759301,
            "auditor_fn_violation": 0.08347886996194502,
            "auditor_fp_violation": 0.09267115633745711,
            "ave_precision_score": 0.5574892896518002,
            "fpr": 0.2678375411635565,
            "logloss": 0.6848126350752886,
            "mae": 0.49415435923982115,
            "precision": 0.5749128919860628,
            "recall": 0.7066381156316917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.690465713624097,
            "mae": 0.49829581396229433,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6878653727294628,
            "mae": 0.496994324134812,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6904675855197865,
            "mae": 0.49829750521141186,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6878703541608653,
            "mae": 0.4969975811589824,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6903267296675566,
            "mae": 0.49816624003282767,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6874901334752507,
            "mae": 0.4967457485251317,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6903105520096069,
            "mae": 0.4981506253478297,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6874457919725078,
            "mae": 0.49671594289864457,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6868360027479166,
            "mae": 0.4945014945574497,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6833079278926169,
            "mae": 0.4927103558369185,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6892618250476132,
            "auditor_fn_violation": 0.019748099715407627,
            "auditor_fp_violation": 0.00919246646026832,
            "ave_precision_score": 0.6895201485766358,
            "fpr": 0.03508771929824561,
            "logloss": 0.6532509222170197,
            "mae": 0.43749494774686315,
            "precision": 0.84,
            "recall": 0.34496919917864477
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6565194181283505,
            "auditor_fn_violation": 0.027146204961016558,
            "auditor_fp_violation": 0.009730916426854957,
            "ave_precision_score": 0.6557516018286778,
            "fpr": 0.02854006586169045,
            "logloss": 0.6318729108073339,
            "mae": 0.44308323841339087,
            "precision": 0.844311377245509,
            "recall": 0.3019271948608137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6826247589593597,
            "auditor_fn_violation": 0.027664451168990245,
            "auditor_fp_violation": 0.012665118679050569,
            "ave_precision_score": 0.6828994132555576,
            "fpr": 0.04057017543859649,
            "logloss": 0.6716463985901421,
            "mae": 0.44091573457249944,
            "precision": 0.827906976744186,
            "recall": 0.3655030800821355
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6414229251418279,
            "auditor_fn_violation": 0.03532132842230459,
            "auditor_fp_violation": 0.01709091088893504,
            "ave_precision_score": 0.640849547843648,
            "fpr": 0.038419319429198684,
            "logloss": 0.6470959716905219,
            "mae": 0.4468036264213851,
            "precision": 0.8128342245989305,
            "recall": 0.32548179871520344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867798464719975,
            "mae": 0.4944158053646485,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6831239739171802,
            "mae": 0.4925606286093903,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6868380591115186,
            "mae": 0.49450453831569147,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6833145117716605,
            "mae": 0.4927156679127795,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5790401524663912,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5505015901697503,
            "fpr": 0.020833333333333332,
            "logloss": 0.7015744928951821,
            "mae": 0.49421489692963005,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5313926854830759,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5251196827087788,
            "fpr": 0.027442371020856202,
            "logloss": 0.698306288615564,
            "mae": 0.4941530741595803,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5790401524663912,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5505015901697503,
            "fpr": 0.020833333333333332,
            "logloss": 0.7015744928951821,
            "mae": 0.49421489692963005,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5313926854830759,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5251196827087788,
            "fpr": 0.027442371020856202,
            "logloss": 0.698306288615564,
            "mae": 0.4941530741595803,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 5740,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.41226221259975016,
            "auditor_fn_violation": 0.10514833027126337,
            "auditor_fp_violation": 0.09415376676986585,
            "ave_precision_score": 0.5555156058766809,
            "fpr": 0.2817982456140351,
            "logloss": 0.689542887384963,
            "mae": 0.49766866274570165,
            "precision": 0.5687919463087249,
            "recall": 0.6960985626283368
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.5168025976895445,
            "auditor_fn_violation": 0.10004301459440529,
            "auditor_fp_violation": 0.0958851277182781,
            "ave_precision_score": 0.5605553330358648,
            "fpr": 0.25466520307354557,
            "logloss": 0.6857473323261715,
            "mae": 0.4957670255366848,
            "precision": 0.5857142857142857,
            "recall": 0.702355460385439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5790401524663912,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5505015901697503,
            "fpr": 0.020833333333333332,
            "logloss": 0.7009023488567938,
            "mae": 0.49365166262641813,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5313926854830759,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5251196827087788,
            "fpr": 0.027442371020856202,
            "logloss": 0.6977197484671216,
            "mae": 0.493718108401504,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867263625406218,
            "mae": 0.49432905397394244,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6829400727017441,
            "mae": 0.49240849746961624,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7845925146278216,
            "auditor_fn_violation": 0.003739778089988844,
            "auditor_fp_violation": 0.004187306501547988,
            "ave_precision_score": 0.7819509727071225,
            "fpr": 0.02412280701754386,
            "logloss": 0.6261203258603475,
            "mae": 0.4172507334092865,
            "precision": 0.8921568627450981,
            "recall": 0.3737166324435318
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7792720449112621,
            "auditor_fn_violation": 0.012032333812056794,
            "auditor_fp_violation": 0.00383204280020965,
            "ave_precision_score": 0.7756437107191378,
            "fpr": 0.015367727771679473,
            "logloss": 0.6166374582171851,
            "mae": 0.4246518898791173,
            "precision": 0.9181286549707602,
            "recall": 0.3361884368308351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6880053410156847,
            "mae": 0.49624781696158543,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6830199127386014,
            "mae": 0.4936980881884645,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8027028833147806,
            "auditor_fn_violation": 0.007571868583162219,
            "auditor_fp_violation": 0.02466202270381838,
            "ave_precision_score": 0.7418645751257861,
            "fpr": 0.28618421052631576,
            "logloss": 6.385496495519752,
            "mae": 0.3272108513070961,
            "precision": 0.6329113924050633,
            "recall": 0.9240246406570842
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7890433659734775,
            "auditor_fn_violation": 0.006290002985165844,
            "auditor_fp_violation": 0.022487910523036777,
            "ave_precision_score": 0.7166150989880412,
            "fpr": 0.2996706915477497,
            "logloss": 6.791977755887586,
            "mae": 0.3417709948884988,
            "precision": 0.61,
            "recall": 0.9143468950749465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.801147883726951,
            "auditor_fn_violation": 0.008076209517633923,
            "auditor_fp_violation": 0.025193498452012388,
            "ave_precision_score": 0.744215425454692,
            "fpr": 0.2850877192982456,
            "logloss": 6.064133100057517,
            "mae": 0.3260043944898414,
            "precision": 0.6332863187588152,
            "recall": 0.9219712525667351
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.786707925733811,
            "auditor_fn_violation": 0.005180555522909385,
            "auditor_fp_violation": 0.023822944788916257,
            "ave_precision_score": 0.7204845462000914,
            "fpr": 0.29857299670691545,
            "logloss": 6.411735174480115,
            "mae": 0.3385993174271129,
            "precision": 0.6103151862464183,
            "recall": 0.9122055674518201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7180807563977788,
            "auditor_fn_violation": 0.09473278936561115,
            "auditor_fp_violation": 0.09771671826625387,
            "ave_precision_score": 0.5560456524443227,
            "fpr": 0.30153508771929827,
            "logloss": 0.6872974586595959,
            "mae": 0.49461121099037036,
            "precision": 0.5627980922098569,
            "recall": 0.7268993839835729
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7232995923859247,
            "auditor_fn_violation": 0.08899319993324512,
            "auditor_fp_violation": 0.10020668308264356,
            "ave_precision_score": 0.5599018518897088,
            "fpr": 0.2810098792535675,
            "logloss": 0.6837542732904828,
            "mae": 0.4928919694557148,
            "precision": 0.5733333333333334,
            "recall": 0.7366167023554604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7120532613783292,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.0014963880288957907,
            "ave_precision_score": 0.5591286293734347,
            "fpr": 0.4605263157894737,
            "logloss": 0.7023638887088947,
            "mae": 0.4865009840577841,
            "precision": 0.5364238410596026,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7166616993769253,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0033326410933436266,
            "ave_precision_score": 0.5585061657388551,
            "fpr": 0.4796926454445664,
            "logloss": 0.7046719399046525,
            "mae": 0.4879789932106512,
            "precision": 0.5165929203539823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.8280675494201198,
            "auditor_fn_violation": 0.0017426780503620447,
            "auditor_fp_violation": 0.012200722394220839,
            "ave_precision_score": 0.8260022867267465,
            "fpr": 0.4144736842105263,
            "logloss": 3.0649398832069306,
            "mae": 0.41401335954666146,
            "precision": 0.5614849187935035,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.8198897740621662,
            "auditor_fn_violation": 5.4062058542157794e-05,
            "auditor_fp_violation": 0.016326974614570656,
            "ave_precision_score": 0.8168991159480276,
            "fpr": 0.429198682766191,
            "logloss": 3.1628083110614766,
            "mae": 0.4287292896078812,
            "precision": 0.5432242990654206,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7813829786571556,
            "auditor_fn_violation": 0.007036006340286033,
            "auditor_fp_violation": 0.004907120743034057,
            "ave_precision_score": 0.7787232190486718,
            "fpr": 0.023026315789473683,
            "logloss": 0.630259553406938,
            "mae": 0.4188033791019278,
            "precision": 0.8917525773195877,
            "recall": 0.35523613963039014
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7776982944871322,
            "auditor_fn_violation": 0.002738360791374537,
            "auditor_fp_violation": 0.00383204280020965,
            "ave_precision_score": 0.774060966868555,
            "fpr": 0.015367727771679473,
            "logloss": 0.6231890959538154,
            "mae": 0.42575875862520335,
            "precision": 0.9146341463414634,
            "recall": 0.32119914346895073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7939720709405189,
            "auditor_fn_violation": 0.009102903562808462,
            "auditor_fp_violation": 0.02416924664602685,
            "ave_precision_score": 0.7442436985581926,
            "fpr": 0.2719298245614035,
            "logloss": 5.328326331822766,
            "mae": 0.32314593327244756,
            "precision": 0.6405797101449275,
            "recall": 0.9075975359342916
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7820527836286442,
            "auditor_fn_violation": 0.005420308999922433,
            "auditor_fp_violation": 0.02113062568605928,
            "ave_precision_score": 0.7246860448192248,
            "fpr": 0.27332601536772777,
            "logloss": 5.639989032136187,
            "mae": 0.3251213295631288,
            "precision": 0.6294642857142857,
            "recall": 0.9057815845824411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.79284290872803,
            "auditor_fn_violation": 0.0056130444180265875,
            "auditor_fp_violation": 0.017827657378740973,
            "ave_precision_score": 0.7902972507407615,
            "fpr": 0.07236842105263158,
            "logloss": 0.7412041314636739,
            "mae": 0.3641038927347476,
            "precision": 0.8230563002680965,
            "recall": 0.6303901437371663
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7916337895184775,
            "auditor_fn_violation": 0.010163667005925673,
            "auditor_fp_violation": 0.0215978876791171,
            "ave_precision_score": 0.7904155691407773,
            "fpr": 0.07903402854006586,
            "logloss": 0.6710572409270007,
            "mae": 0.3642781588552134,
            "precision": 0.8016528925619835,
            "recall": 0.6231263383297645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867056843527274,
            "mae": 0.49429393546623096,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6828662991045076,
            "mae": 0.49234675317511994,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7914657118941024,
            "auditor_fn_violation": 0.007173349184048419,
            "auditor_fp_violation": 0.019860681114551085,
            "ave_precision_score": 0.7884126060827286,
            "fpr": 0.07785087719298246,
            "logloss": 0.7543486958416759,
            "mae": 0.36080029186102336,
            "precision": 0.8141361256544503,
            "recall": 0.6386036960985626
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7859927535137374,
            "auditor_fn_violation": 0.009655953760486285,
            "auditor_fp_violation": 0.024282789924941407,
            "ave_precision_score": 0.7839333645104098,
            "fpr": 0.08562019758507135,
            "logloss": 0.7158750899315849,
            "mae": 0.3623598549140623,
            "precision": 0.7914438502673797,
            "recall": 0.6338329764453962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7483033520502888,
            "auditor_fn_violation": 0.011721423682409303,
            "auditor_fp_violation": 0.004200206398348815,
            "ave_precision_score": 0.7440485438312774,
            "fpr": 0.017543859649122806,
            "logloss": 0.6647869897673208,
            "mae": 0.42704527099728556,
            "precision": 0.901840490797546,
            "recall": 0.30184804928131415
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.734465809761704,
            "auditor_fn_violation": 0.0024398442072504373,
            "auditor_fp_violation": 0.0032634170943720894,
            "ave_precision_score": 0.7298806168209055,
            "fpr": 0.013172338090010977,
            "logloss": 0.6728338536079185,
            "mae": 0.4316956827825112,
            "precision": 0.9136690647482014,
            "recall": 0.27194860813704497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7909210828898274,
            "auditor_fn_violation": 0.016001567059332106,
            "auditor_fp_violation": 0.020307017543859655,
            "ave_precision_score": 0.7560256440030418,
            "fpr": 0.14912280701754385,
            "logloss": 3.6501720867461205,
            "mae": 0.29026247661323434,
            "precision": 0.7333333333333333,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7814614496247115,
            "auditor_fn_violation": 0.006285301936596957,
            "auditor_fp_violation": 0.015758348908733115,
            "ave_precision_score": 0.7427400229745609,
            "fpr": 0.1602634467618002,
            "logloss": 3.8075843226678985,
            "mae": 0.2876251672199333,
            "precision": 0.7091633466135459,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7958917955941618,
            "auditor_fn_violation": 0.002897708851183407,
            "auditor_fp_violation": 0.015366357069143449,
            "ave_precision_score": 0.794235026918763,
            "fpr": 0.06798245614035088,
            "logloss": 0.7105958790994682,
            "mae": 0.3668926732671302,
            "precision": 0.8292011019283747,
            "recall": 0.6180698151950719
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.804498476903658,
            "auditor_fn_violation": 0.007869555304310634,
            "auditor_fp_violation": 0.015152638917732225,
            "ave_precision_score": 0.8029883510812299,
            "fpr": 0.06695938529088913,
            "logloss": 0.6504691983758657,
            "mae": 0.3658973379785444,
            "precision": 0.8231884057971014,
            "recall": 0.6081370449678801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.686754002260355,
            "mae": 0.4943745765638979,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6830362764519827,
            "mae": 0.4924883956312479,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 5740,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5582311204665524,
            "auditor_fn_violation": 0.0009951727367700698,
            "auditor_fp_violation": 0.008464912280701755,
            "ave_precision_score": 0.5566038801879318,
            "fpr": 0.12171052631578948,
            "logloss": 0.7020486779262071,
            "mae": 0.491931488606752,
            "precision": 0.5888888888888889,
            "recall": 0.3264887063655031
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5388304426460675,
            "auditor_fn_violation": 0.010196574345907853,
            "auditor_fp_violation": 0.008029983880697386,
            "ave_precision_score": 0.5397578968234438,
            "fpr": 0.1163556531284303,
            "logloss": 0.6961286474467202,
            "mae": 0.4915379628980722,
            "precision": 0.5776892430278885,
            "recall": 0.31049250535331907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8011746746953956,
            "auditor_fn_violation": 0.008076209517633923,
            "auditor_fp_violation": 0.025193498452012388,
            "ave_precision_score": 0.7442024908044284,
            "fpr": 0.2850877192982456,
            "logloss": 6.069415267158599,
            "mae": 0.3260335788963498,
            "precision": 0.6332863187588152,
            "recall": 0.9219712525667351
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7860537092975499,
            "auditor_fn_violation": 0.005180555522909385,
            "auditor_fp_violation": 0.023822944788916257,
            "ave_precision_score": 0.7192036211282995,
            "fpr": 0.29857299670691545,
            "logloss": 6.436651334155771,
            "mae": 0.33870963428395073,
            "precision": 0.6103151862464183,
            "recall": 0.9122055674518201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5084914670231987,
            "auditor_fn_violation": 0.0005606289851939911,
            "auditor_fp_violation": 0.006215170278637788,
            "ave_precision_score": 0.5141516628287803,
            "fpr": 0.4517543859649123,
            "logloss": 0.692227446286489,
            "mae": 0.49949659812345837,
            "precision": 0.5412026726057907,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.469495706299751,
            "auditor_fn_violation": 0.0013280462207095295,
            "auditor_fp_violation": 0.002588483104399694,
            "ave_precision_score": 0.4753974630171249,
            "fpr": 0.4796926454445664,
            "logloss": 0.6929070235931098,
            "mae": 0.49983633817485346,
            "precision": 0.5144444444444445,
            "recall": 0.9914346895074947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867980644607392,
            "mae": 0.49444415933338176,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6831845919230122,
            "mae": 0.4926102319088254,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6901198842390476,
            "auditor_fn_violation": 0.010264688929716497,
            "auditor_fp_violation": 0.0014886480908152739,
            "ave_precision_score": 0.6854400146599255,
            "fpr": 0.01206140350877193,
            "logloss": 0.7228887234943994,
            "mae": 0.4359305254860995,
            "precision": 0.9285714285714286,
            "recall": 0.2936344969199179
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6778294649548504,
            "auditor_fn_violation": 0.0024398442072504373,
            "auditor_fp_violation": 0.0005265968493191324,
            "ave_precision_score": 0.6734421141255726,
            "fpr": 0.009879253567508232,
            "logloss": 0.748106634314695,
            "mae": 0.43951053946916463,
            "precision": 0.9338235294117647,
            "recall": 0.27194860813704497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7102709703465583,
            "auditor_fn_violation": 0.08107505673835513,
            "auditor_fp_violation": 0.09060371517027863,
            "ave_precision_score": 0.5563917313813819,
            "fpr": 0.28289473684210525,
            "logloss": 0.6886888434040577,
            "mae": 0.49702134957177596,
            "precision": 0.5649241146711635,
            "recall": 0.6878850102669405
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7155562301566442,
            "auditor_fn_violation": 0.08347886996194502,
            "auditor_fp_violation": 0.09309144490264139,
            "ave_precision_score": 0.5566145983787447,
            "fpr": 0.2689352360043908,
            "logloss": 0.6876535136350787,
            "mae": 0.49652511758155277,
            "precision": 0.5739130434782609,
            "recall": 0.7066381156316917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5375895872834562,
            "auditor_fn_violation": 0.07151284268165278,
            "auditor_fp_violation": 0.0704153766769866,
            "ave_precision_score": 0.5400104015885154,
            "fpr": 0.3059210526315789,
            "logloss": 0.6937874631352529,
            "mae": 0.4980459721072724,
            "precision": 0.5463414634146342,
            "recall": 0.6899383983572895
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5641509659126444,
            "auditor_fn_violation": 0.06722969558359992,
            "auditor_fp_violation": 0.07183720493270439,
            "ave_precision_score": 0.5671639063323803,
            "fpr": 0.3040614709110867,
            "logloss": 0.6848590108209127,
            "mae": 0.4936404034871563,
            "precision": 0.5546623794212219,
            "recall": 0.7387580299785867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.8303760068586208,
            "auditor_fn_violation": 0.0017426780503620447,
            "auditor_fp_violation": 0.012515479876161001,
            "ave_precision_score": 0.8279930979234242,
            "fpr": 0.41885964912280704,
            "logloss": 3.104939665870039,
            "mae": 0.41562432724803494,
            "precision": 0.558891454965358,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.8228694285834102,
            "auditor_fn_violation": 5.4062058542157794e-05,
            "auditor_fp_violation": 0.016900544891763337,
            "ave_precision_score": 0.8196188958041634,
            "fpr": 0.433589462129528,
            "logloss": 3.2038637871874487,
            "mae": 0.43061659127710966,
            "precision": 0.5406976744186046,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.5380232989879734,
            "auditor_fn_violation": 0.002695071868583183,
            "auditor_fp_violation": 0.005993292053663572,
            "ave_precision_score": 0.5442902851563132,
            "fpr": 0.03179824561403509,
            "logloss": 0.7036776880277154,
            "mae": 0.4949455141955823,
            "precision": 0.5,
            "recall": 0.059548254620123205
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5342976603290929,
            "auditor_fn_violation": 0.0017769963590378959,
            "auditor_fp_violation": 0.0058296496276737785,
            "ave_precision_score": 0.5396585864849683,
            "fpr": 0.03732162458836443,
            "logloss": 0.698306350732072,
            "mae": 0.49410640930043354,
            "precision": 0.46875,
            "recall": 0.06423982869379015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7061531676660301,
            "auditor_fn_violation": 0.07242696062538276,
            "auditor_fp_violation": 0.08213364293085655,
            "ave_precision_score": 0.5597574973597719,
            "fpr": 0.26644736842105265,
            "logloss": 0.6864668665204895,
            "mae": 0.493895186111331,
            "precision": 0.5691489361702128,
            "recall": 0.6591375770020534
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7126782265261677,
            "auditor_fn_violation": 0.08045374520786863,
            "auditor_fp_violation": 0.08694534270824063,
            "ave_precision_score": 0.5591431230620135,
            "fpr": 0.25905598243688255,
            "logloss": 0.6831121331685679,
            "mae": 0.4921755606531443,
            "precision": 0.5763016157989228,
            "recall": 0.6873661670235546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.706951234290575,
            "auditor_fn_violation": 0.0096004899311935,
            "auditor_fp_violation": 0.006865325077399382,
            "ave_precision_score": 0.7071579263066319,
            "fpr": 0.03070175438596491,
            "logloss": 0.637306535896484,
            "mae": 0.43272709833723666,
            "precision": 0.8461538461538461,
            "recall": 0.3162217659137577
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6810614631049176,
            "auditor_fn_violation": 0.019326010666679223,
            "auditor_fp_violation": 0.004010047368993583,
            "ave_precision_score": 0.6802418179061765,
            "fpr": 0.018660812294182216,
            "logloss": 0.622614086417691,
            "mae": 0.43788663255421534,
            "precision": 0.8851351351351351,
            "recall": 0.28051391862955033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5803599583155765,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5532782137467004,
            "fpr": 0.020833333333333332,
            "logloss": 0.7021010748069734,
            "mae": 0.49127741991501434,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5326648940683326,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5275101413755148,
            "fpr": 0.027442371020856202,
            "logloss": 0.6954682620561277,
            "mae": 0.4917027245303279,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8412874041666442,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.0021904024767801914,
            "ave_precision_score": 0.7849034266601352,
            "fpr": 0.4583333333333333,
            "logloss": 7.020260468333851,
            "mae": 0.4585285195390749,
            "precision": 0.5376106194690266,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.8320517761109986,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003550202232968432,
            "ave_precision_score": 0.7643698935688518,
            "fpr": 0.47859495060373214,
            "logloss": 7.470401033181519,
            "mae": 0.4774040687618307,
            "precision": 0.5171650055370985,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8460804760261059,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.0021904024767801914,
            "ave_precision_score": 0.786336757829046,
            "fpr": 0.4583333333333333,
            "logloss": 7.191057429246531,
            "mae": 0.4590311098346129,
            "precision": 0.5376106194690266,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.8370961002573178,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003550202232968432,
            "ave_precision_score": 0.7667642979776561,
            "fpr": 0.47859495060373214,
            "logloss": 7.607285040138592,
            "mae": 0.4775420123400703,
            "precision": 0.5171650055370985,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7114568161851725,
            "auditor_fn_violation": 0.002575741201051911,
            "auditor_fp_violation": 0.0033281733746130093,
            "ave_precision_score": 0.561894388091408,
            "fpr": 0.4550438596491228,
            "logloss": 0.7072015483582054,
            "mae": 0.48473231543443707,
            "precision": 0.5378619153674833,
            "recall": 0.9917864476386037
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7168078483398999,
            "auditor_fn_violation": 0.0011470558508075226,
            "auditor_fp_violation": 0.007268519892010563,
            "ave_precision_score": 0.5621804235138469,
            "fpr": 0.4676180021953897,
            "logloss": 0.7085154198817938,
            "mae": 0.4857045041415615,
            "precision": 0.5218855218855218,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7096226120807623,
            "auditor_fn_violation": 0.08025775424186751,
            "auditor_fp_violation": 0.0851264189886481,
            "ave_precision_score": 0.5590935642336138,
            "fpr": 0.27521929824561403,
            "logloss": 0.6867856517874081,
            "mae": 0.49442490278498125,
            "precision": 0.5679862306368331,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7156299168202478,
            "auditor_fn_violation": 0.0821343700712444,
            "auditor_fp_violation": 0.08710604127728168,
            "ave_precision_score": 0.5602002832780029,
            "fpr": 0.2623490669593853,
            "logloss": 0.6831433922531052,
            "mae": 0.4925765486763285,
            "precision": 0.5769911504424778,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5585983050869475,
            "auditor_fn_violation": 0.003838845059260089,
            "auditor_fp_violation": 0.0023168214654282777,
            "ave_precision_score": 0.5641422004924371,
            "fpr": 0.02850877192982456,
            "logloss": 0.6853606137252165,
            "mae": 0.4838137518994412,
            "precision": 0.559322033898305,
            "recall": 0.06776180698151951
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5419171400363932,
            "auditor_fn_violation": 0.0014949334449048854,
            "auditor_fp_violation": 0.005577476488563207,
            "ave_precision_score": 0.5475229439680847,
            "fpr": 0.03732162458836443,
            "logloss": 0.687783794766226,
            "mae": 0.4881683894965704,
            "precision": 0.48484848484848486,
            "recall": 0.06852248394004283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7595188352334955,
            "auditor_fn_violation": 0.0007610144457653558,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.7233888439283928,
            "fpr": 0.020833333333333332,
            "logloss": 0.6369937437517984,
            "mae": 0.43637448367548703,
            "precision": 0.8841463414634146,
            "recall": 0.29774127310061604
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7709875267152105,
            "auditor_fn_violation": 0.009362138224931083,
            "auditor_fp_violation": 0.003233749666241434,
            "ave_precision_score": 0.7243840459620067,
            "fpr": 0.013172338090010977,
            "logloss": 0.6231150008407331,
            "mae": 0.4404867388747062,
            "precision": 0.9076923076923077,
            "recall": 0.25267665952890794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7805912991318598,
            "auditor_fn_violation": 0.007488562268093231,
            "auditor_fp_violation": 0.004907120743034057,
            "ave_precision_score": 0.7779111095695546,
            "fpr": 0.023026315789473683,
            "logloss": 0.6319994948671204,
            "mae": 0.41940192495403034,
            "precision": 0.890625,
            "recall": 0.351129363449692
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7766655739779456,
            "auditor_fn_violation": 0.0014972839691893317,
            "auditor_fp_violation": 0.00383204280020965,
            "ave_precision_score": 0.7730277618505085,
            "fpr": 0.015367727771679473,
            "logloss": 0.6259047777184586,
            "mae": 0.4261680925999464,
            "precision": 0.9130434782608695,
            "recall": 0.3147751605995717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7366747648091648,
            "auditor_fn_violation": 0.004370204258078461,
            "auditor_fp_violation": 0.00686274509803922,
            "ave_precision_score": 0.730307592528111,
            "fpr": 0.044956140350877194,
            "logloss": 0.6356813499124534,
            "mae": 0.4346344998000935,
            "precision": 0.831275720164609,
            "recall": 0.41478439425051333
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7347542203798452,
            "auditor_fn_violation": 0.0058245991768464105,
            "auditor_fp_violation": 0.00601259876781282,
            "ave_precision_score": 0.7238657579327356,
            "fpr": 0.043907793633369926,
            "logloss": 0.6192738645344187,
            "mae": 0.4368463739478625,
            "precision": 0.8198198198198198,
            "recall": 0.3897216274089936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5623591470923778,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5378989929900196,
            "fpr": 0.020833333333333332,
            "logloss": 0.7018219723129718,
            "mae": 0.4941064123913907,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5249809053678944,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5164184185867913,
            "fpr": 0.027442371020856202,
            "logloss": 0.6991523184075814,
            "mae": 0.49452040506410283,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7905321991744579,
            "auditor_fn_violation": 0.016001567059332106,
            "auditor_fp_violation": 0.020307017543859655,
            "ave_precision_score": 0.755677168252151,
            "fpr": 0.14912280701754385,
            "logloss": 3.6473535139184765,
            "mae": 0.2902886094782928,
            "precision": 0.7333333333333333,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7814882078210115,
            "auditor_fn_violation": 0.006285301936596957,
            "auditor_fp_violation": 0.015758348908733115,
            "ave_precision_score": 0.7427653140392496,
            "fpr": 0.1602634467618002,
            "logloss": 3.8044985164472394,
            "mae": 0.2876429280474948,
            "precision": 0.7091633466135459,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8451395823745234,
            "auditor_fn_violation": 0.01888351525631327,
            "auditor_fp_violation": 0.01711816305469557,
            "ave_precision_score": 0.8455441873446725,
            "fpr": 0.15679824561403508,
            "logloss": 0.709306137885456,
            "mae": 0.2736186559025337,
            "precision": 0.7332089552238806,
            "recall": 0.8069815195071869
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.846338676190838,
            "auditor_fn_violation": 0.010600864522831823,
            "auditor_fp_violation": 0.027106140168708773,
            "ave_precision_score": 0.8465559677377599,
            "fpr": 0.17233809001097694,
            "logloss": 0.692559607646982,
            "mae": 0.26883994384409676,
            "precision": 0.7160940325497287,
            "recall": 0.8479657387580299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7120532613783292,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.0014963880288957907,
            "ave_precision_score": 0.5591286293734347,
            "fpr": 0.4605263157894737,
            "logloss": 0.7024201416938273,
            "mae": 0.4863700675533006,
            "precision": 0.5364238410596026,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7166616993769253,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0033326410933436266,
            "ave_precision_score": 0.5585061657388551,
            "fpr": 0.4796926454445664,
            "logloss": 0.704513669006886,
            "mae": 0.48775416638796204,
            "precision": 0.5165929203539823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7600209159434912,
            "auditor_fn_violation": 0.0007610144457653558,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.7283526252602331,
            "fpr": 0.020833333333333332,
            "logloss": 0.6411585174785019,
            "mae": 0.4389149434309541,
            "precision": 0.8841463414634146,
            "recall": 0.29774127310061604
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.796742243270622,
            "auditor_fn_violation": 0.009362138224931083,
            "auditor_fp_violation": 0.003233749666241434,
            "ave_precision_score": 0.758887414463373,
            "fpr": 0.013172338090010977,
            "logloss": 0.6193757854237412,
            "mae": 0.43976695846437025,
            "precision": 0.9076923076923077,
            "recall": 0.25267665952890794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.8436438771070625,
            "auditor_fn_violation": 0.0017426780503620447,
            "auditor_fp_violation": 0.011924664602683181,
            "ave_precision_score": 0.8409198887647322,
            "fpr": 0.4199561403508772,
            "logloss": 3.4848857735426066,
            "mae": 0.4199567835832357,
            "precision": 0.558246828143022,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.8561698090762349,
            "auditor_fn_violation": 0.0009214055195011249,
            "auditor_fp_violation": 0.012964666093096402,
            "ave_precision_score": 0.8544830207430685,
            "fpr": 0.43468715697036225,
            "logloss": 3.453726367369574,
            "mae": 0.43242447107422993,
            "precision": 0.5400696864111498,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8395016036674798,
            "auditor_fn_violation": 0.014806008861990709,
            "auditor_fp_violation": 0.024824561403508773,
            "ave_precision_score": 0.8398507064319751,
            "fpr": 0.16776315789473684,
            "logloss": 0.7219138238973296,
            "mae": 0.27612926552575706,
            "precision": 0.7248201438848921,
            "recall": 0.8275154004106776
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8398840137739665,
            "auditor_fn_violation": 0.007773183808648524,
            "auditor_fp_violation": 0.023852612217046917,
            "ave_precision_score": 0.8401139222522208,
            "fpr": 0.17672886937431395,
            "logloss": 0.722648152859393,
            "mae": 0.2716582830414215,
            "precision": 0.7099099099099099,
            "recall": 0.8436830835117773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.8408546627616055,
            "auditor_fn_violation": 0.0011617853669080298,
            "auditor_fp_violation": 0.012048503611971106,
            "ave_precision_score": 0.8365403889467597,
            "fpr": 0.4276315789473684,
            "logloss": 3.4487243203859483,
            "mae": 0.42766832769227503,
            "precision": 0.5542857142857143,
            "recall": 0.9958932238193019
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.8459730293097569,
            "auditor_fn_violation": 0.0005006616725860704,
            "auditor_fp_violation": 0.012047448106723637,
            "ave_precision_score": 0.8433537868329533,
            "fpr": 0.442371020856202,
            "logloss": 3.4891859639092666,
            "mae": 0.44109683112079134,
            "precision": 0.5362485615650172,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7937420119272296,
            "auditor_fn_violation": 0.009102903562808462,
            "auditor_fp_violation": 0.02344169246646028,
            "ave_precision_score": 0.7447371742042597,
            "fpr": 0.2730263157894737,
            "logloss": 5.295848260439363,
            "mae": 0.32322661872384817,
            "precision": 0.6396526772793053,
            "recall": 0.9075975359342916
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7820556276543924,
            "auditor_fn_violation": 0.005420308999922433,
            "auditor_fp_violation": 0.02113062568605928,
            "ave_precision_score": 0.7247020852129414,
            "fpr": 0.27332601536772777,
            "logloss": 5.626067431243827,
            "mae": 0.3249824830205797,
            "precision": 0.6294642857142857,
            "recall": 0.9057815845824411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7908763448024174,
            "auditor_fn_violation": 0.01414180986346771,
            "auditor_fp_violation": 0.019899380804953563,
            "ave_precision_score": 0.7551198980259,
            "fpr": 0.14692982456140352,
            "logloss": 3.7564660448281164,
            "mae": 0.2900552363643434,
            "precision": 0.7362204724409449,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7821743155207781,
            "auditor_fn_violation": 0.00509828717295393,
            "auditor_fp_violation": 0.01913549114427271,
            "ave_precision_score": 0.7432758630131374,
            "fpr": 0.15697036223929747,
            "logloss": 3.8861263257587977,
            "mae": 0.2874261207563715,
            "precision": 0.7128514056224899,
            "recall": 0.7601713062098501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7692180261568917,
            "auditor_fn_violation": 0.004345437515760654,
            "auditor_fp_violation": 0.026914344685242536,
            "ave_precision_score": 0.7653876901864138,
            "fpr": 0.36403508771929827,
            "logloss": 2.535279949488219,
            "mae": 0.3732709841897402,
            "precision": 0.5891089108910891,
            "recall": 0.9774127310061602
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7709872594795402,
            "auditor_fn_violation": 0.003046279472636372,
            "auditor_fp_violation": 0.025479376192877847,
            "ave_precision_score": 0.7668640935098593,
            "fpr": 0.38309549945115257,
            "logloss": 2.652621167907842,
            "mae": 0.39115885560087105,
            "precision": 0.5669975186104218,
            "recall": 0.9785867237687366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.844729792564715,
            "auditor_fn_violation": 0.0017426780503620447,
            "auditor_fp_violation": 0.01162280701754385,
            "ave_precision_score": 0.8418951791269373,
            "fpr": 0.42214912280701755,
            "logloss": 3.508886722345453,
            "mae": 0.42107091006790637,
            "precision": 0.5569620253164557,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.8568032455605479,
            "auditor_fn_violation": 0.0005006616725860704,
            "auditor_fp_violation": 0.01241829095835682,
            "ave_precision_score": 0.8550942006222663,
            "fpr": 0.43578485181119647,
            "logloss": 3.4799569604062777,
            "mae": 0.433643530987846,
            "precision": 0.5399768250289687,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.684594615435135,
            "auditor_fn_violation": 0.010264688929716497,
            "auditor_fp_violation": 0.002631578947368421,
            "ave_precision_score": 0.682976462965193,
            "fpr": 0.010964912280701754,
            "logloss": 0.7310796748511988,
            "mae": 0.4370992945274325,
            "precision": 0.934640522875817,
            "recall": 0.2936344969199179
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6720087113154772,
            "auditor_fn_violation": 0.0024398442072504373,
            "auditor_fp_violation": 0.0005265968493191324,
            "ave_precision_score": 0.6701517881260337,
            "fpr": 0.009879253567508232,
            "logloss": 0.7577754350635453,
            "mae": 0.44019575380930165,
            "precision": 0.9338235294117647,
            "recall": 0.27194860813704497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8018453950674578,
            "auditor_fn_violation": 0.007571868583162219,
            "auditor_fp_violation": 0.02466202270381838,
            "ave_precision_score": 0.741754446704527,
            "fpr": 0.28618421052631576,
            "logloss": 6.350236757553918,
            "mae": 0.3271940898967388,
            "precision": 0.6329113924050633,
            "recall": 0.9240246406570842
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7868580670673934,
            "auditor_fn_violation": 0.006290002985165844,
            "auditor_fp_violation": 0.022487910523036777,
            "ave_precision_score": 0.7148381115473713,
            "fpr": 0.2996706915477497,
            "logloss": 6.778904431316856,
            "mae": 0.3419477110460423,
            "precision": 0.61,
            "recall": 0.9143468950749465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8018897684245608,
            "auditor_fn_violation": 0.008076209517633923,
            "auditor_fp_violation": 0.025193498452012388,
            "ave_precision_score": 0.7441901421987396,
            "fpr": 0.2850877192982456,
            "logloss": 6.115081419621019,
            "mae": 0.3257860008688308,
            "precision": 0.6332863187588152,
            "recall": 0.9219712525667351
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7872391244963204,
            "auditor_fn_violation": 0.005154699755780528,
            "auditor_fp_violation": 0.02474016277528902,
            "ave_precision_score": 0.7201176411173429,
            "fpr": 0.29747530186608123,
            "logloss": 6.4614502241870575,
            "mae": 0.33806582202779717,
            "precision": 0.610632183908046,
            "recall": 0.9100642398286938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7827485043622635,
            "auditor_fn_violation": 0.018568302172268455,
            "auditor_fp_violation": 0.03114035087719299,
            "ave_precision_score": 0.7834738255135157,
            "fpr": 0.13048245614035087,
            "logloss": 0.9750254264678615,
            "mae": 0.29167986296570686,
            "precision": 0.7515657620041754,
            "recall": 0.7392197125256673
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7791705712279325,
            "auditor_fn_violation": 0.014664921010631429,
            "auditor_fp_violation": 0.026878689886373756,
            "ave_precision_score": 0.7796874474285627,
            "fpr": 0.14709110867178923,
            "logloss": 0.9905228349751226,
            "mae": 0.2880956552883344,
            "precision": 0.7237113402061855,
            "recall": 0.7516059957173448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5790401524663912,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5505015901697503,
            "fpr": 0.020833333333333332,
            "logloss": 0.7015744928951821,
            "mae": 0.49421489692963005,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5313926854830759,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5251196827087788,
            "fpr": 0.027442371020856202,
            "logloss": 0.698306288615564,
            "mae": 0.4941530741595803,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 5740,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.8421897779539018,
            "auditor_fn_violation": 0.0011617853669080298,
            "auditor_fp_violation": 0.011578947368421062,
            "ave_precision_score": 0.8377138853722504,
            "fpr": 0.42872807017543857,
            "logloss": 3.4909234010175836,
            "mae": 0.4290072930591428,
            "precision": 0.5536529680365296,
            "recall": 0.9958932238193019
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.8464268143261267,
            "auditor_fn_violation": 0.0005006616725860704,
            "auditor_fp_violation": 0.011862026680907037,
            "ave_precision_score": 0.8436885874129035,
            "fpr": 0.4456641053787047,
            "logloss": 3.5348680462371904,
            "mae": 0.44238314188488137,
            "precision": 0.5344036697247706,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.8435129280723481,
            "auditor_fn_violation": 0.0017426780503620447,
            "auditor_fp_violation": 0.014971620227038204,
            "ave_precision_score": 0.8411530055222056,
            "fpr": 0.42105263157894735,
            "logloss": 3.4512918523387404,
            "mae": 0.421599110650457,
            "precision": 0.5576036866359447,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.8542252526304812,
            "auditor_fn_violation": 0.0005006616725860704,
            "auditor_fp_violation": 0.014371396643624966,
            "ave_precision_score": 0.8524308305792674,
            "fpr": 0.433589462129528,
            "logloss": 3.440092780944509,
            "mae": 0.4324688088098879,
            "precision": 0.5412311265969802,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7180807563977788,
            "auditor_fn_violation": 0.09473278936561115,
            "auditor_fp_violation": 0.09771671826625387,
            "ave_precision_score": 0.5560456524443227,
            "fpr": 0.30153508771929827,
            "logloss": 0.6872986460730307,
            "mae": 0.4946132564688461,
            "precision": 0.5627980922098569,
            "recall": 0.7268993839835729
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7232995923859247,
            "auditor_fn_violation": 0.08899319993324512,
            "auditor_fp_violation": 0.10020668308264356,
            "ave_precision_score": 0.5599018518897088,
            "fpr": 0.2810098792535675,
            "logloss": 0.6837585453590008,
            "mae": 0.49289550157069634,
            "precision": 0.5733333333333334,
            "recall": 0.7366167023554604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.39409051018908803,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5504707316791536,
            "fpr": 0.3092105263157895,
            "logloss": 0.6904747632760337,
            "mae": 0.498303983327851,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.49957974409226924,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.550939272810427,
            "fpr": 0.2897914379802415,
            "logloss": 0.6878894711882183,
            "mae": 0.497010071014599,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 5740,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.8285371062005523,
            "auditor_fn_violation": 0.0017426780503620447,
            "auditor_fp_violation": 0.012827657378740987,
            "ave_precision_score": 0.8264790467577138,
            "fpr": 0.4155701754385965,
            "logloss": 3.065164701033439,
            "mae": 0.41431270212536814,
            "precision": 0.5608342989571263,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.8198051014849967,
            "auditor_fn_violation": 5.4062058542157794e-05,
            "auditor_fp_violation": 0.016326974614570656,
            "ave_precision_score": 0.8168209460712907,
            "fpr": 0.429198682766191,
            "logloss": 3.1635412108869314,
            "mae": 0.4289800636260589,
            "precision": 0.5432242990654206,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7935693702706835,
            "auditor_fn_violation": 0.0032286825894304637,
            "auditor_fp_violation": 0.017092363261093917,
            "ave_precision_score": 0.7919605925639396,
            "fpr": 0.0712719298245614,
            "logloss": 0.7162760635540542,
            "mae": 0.3665848958824932,
            "precision": 0.8243243243243243,
            "recall": 0.6262833675564682
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.794874920790725,
            "auditor_fn_violation": 0.007157346446124807,
            "auditor_fp_violation": 0.01924674399976266,
            "ave_precision_score": 0.7935648294884434,
            "fpr": 0.07574094401756312,
            "logloss": 0.6599644734680548,
            "mae": 0.3665509428241532,
            "precision": 0.8083333333333333,
            "recall": 0.6231263383297645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.8260135919760732,
            "auditor_fn_violation": 0.003622698944486473,
            "auditor_fp_violation": 0.015307017543859654,
            "ave_precision_score": 0.8255415481733768,
            "fpr": 0.39144736842105265,
            "logloss": 2.6755299090069107,
            "mae": 0.39824471896911645,
            "precision": 0.5729665071770335,
            "recall": 0.9835728952772074
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.8180480438588519,
            "auditor_fn_violation": 0.0027947733742011154,
            "auditor_fp_violation": 0.019291245141958645,
            "ave_precision_score": 0.8172271083819934,
            "fpr": 0.40504939626783754,
            "logloss": 2.7511676492090094,
            "mae": 0.4086214172535967,
            "precision": 0.555421686746988,
            "recall": 0.987152034261242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7904452230902537,
            "auditor_fn_violation": 0.013387549983789044,
            "auditor_fp_violation": 0.021576367389060894,
            "ave_precision_score": 0.7548034600525795,
            "fpr": 0.14473684210526316,
            "logloss": 3.7348191270344024,
            "mae": 0.29026800750822745,
            "precision": 0.7365269461077845,
            "recall": 0.757700205338809
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7807801828158487,
            "auditor_fn_violation": 0.006014991643886177,
            "auditor_fp_violation": 0.018255357443063263,
            "ave_precision_score": 0.7420405857939427,
            "fpr": 0.1525795828759605,
            "logloss": 3.871299278064253,
            "mae": 0.2884133706918599,
            "precision": 0.7191919191919192,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8396879737377886,
            "auditor_fn_violation": 0.014099030944918767,
            "auditor_fp_violation": 0.023090815273477814,
            "ave_precision_score": 0.8400369145684662,
            "fpr": 0.16557017543859648,
            "logloss": 0.7168647602451005,
            "mae": 0.2760570317591207,
            "precision": 0.7264492753623188,
            "recall": 0.8234086242299795
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8403893980754834,
            "auditor_fn_violation": 0.006816520424880769,
            "auditor_fp_violation": 0.025652436190306663,
            "ave_precision_score": 0.840617835067308,
            "fpr": 0.1756311745334797,
            "logloss": 0.7169383377444987,
            "mae": 0.2715978979014793,
            "precision": 0.7106690777576854,
            "recall": 0.841541755888651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.8328388564563388,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.005250257997936023,
            "ave_precision_score": 0.8080554434915135,
            "fpr": 0.4440789473684211,
            "logloss": 5.17996876798055,
            "mae": 0.4422818150730007,
            "precision": 0.5454545454545454,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.8340219107578747,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.006588641330683037,
            "ave_precision_score": 0.8063649336840821,
            "fpr": 0.4665203073545554,
            "logloss": 5.359564799091827,
            "mae": 0.4597424045087305,
            "precision": 0.523542600896861,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8437718256699563,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.003978328173374612,
            "ave_precision_score": 0.8402484284206932,
            "fpr": 0.4517543859649123,
            "logloss": 4.066689381769335,
            "mae": 0.44990856725327233,
            "precision": 0.5412026726057907,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8418456240818699,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.005775259342767589,
            "ave_precision_score": 0.8383548912052063,
            "fpr": 0.47200878155872666,
            "logloss": 4.217193647208108,
            "mae": 0.47040408361538705,
            "precision": 0.5206243032329989,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7906616282302741,
            "auditor_fn_violation": 0.016785096725386365,
            "auditor_fp_violation": 0.019200206398348813,
            "ave_precision_score": 0.754951447528207,
            "fpr": 0.14364035087719298,
            "logloss": 3.7508661117274507,
            "mae": 0.2897093922272169,
            "precision": 0.7364185110663984,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7820582264960698,
            "auditor_fn_violation": 0.00509828717295393,
            "auditor_fp_violation": 0.01963983742249385,
            "ave_precision_score": 0.7432227667926853,
            "fpr": 0.15367727771679474,
            "logloss": 3.8746163871627983,
            "mae": 0.2872220083977135,
            "precision": 0.7171717171717171,
            "recall": 0.7601713062098501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8433182533446087,
            "auditor_fn_violation": 0.01927753161136929,
            "auditor_fp_violation": 0.014739422084623324,
            "ave_precision_score": 0.8437236391684643,
            "fpr": 0.15789473684210525,
            "logloss": 0.7283712486535524,
            "mae": 0.2741516531937646,
            "precision": 0.7323420074349443,
            "recall": 0.8090349075975359
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8437584400612759,
            "auditor_fn_violation": 0.01014721333593458,
            "auditor_fp_violation": 0.02651773617745078,
            "ave_precision_score": 0.8439805145771954,
            "fpr": 0.17233809001097694,
            "logloss": 0.7137717273573123,
            "mae": 0.26932465827252405,
            "precision": 0.7155797101449275,
            "recall": 0.8458244111349036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 5740,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.514807370826067,
            "auditor_fn_violation": 0.002634280773803091,
            "auditor_fp_violation": 0.005350877192982454,
            "ave_precision_score": 0.5204490729325726,
            "fpr": 0.4473684210526316,
            "logloss": 0.6901293375204681,
            "mae": 0.49744864344074013,
            "precision": 0.5400225479143179,
            "recall": 0.9835728952772074
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.478796613367361,
            "auditor_fn_violation": 0.0014996344934737693,
            "auditor_fp_violation": 0.005466223633073273,
            "ave_precision_score": 0.4846900717863153,
            "fpr": 0.4643249176728869,
            "logloss": 0.6900786686929645,
            "mae": 0.4973869988476013,
            "precision": 0.5214932126696833,
            "recall": 0.987152034261242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8045073516579682,
            "auditor_fn_violation": 0.007571868583162219,
            "auditor_fp_violation": 0.025227038183694536,
            "ave_precision_score": 0.7431817213334856,
            "fpr": 0.28728070175438597,
            "logloss": 6.421350270630708,
            "mae": 0.32743425387700054,
            "precision": 0.6320224719101124,
            "recall": 0.9240246406570842
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7897505851325176,
            "auditor_fn_violation": 0.006290002985165844,
            "auditor_fp_violation": 0.022487910523036777,
            "ave_precision_score": 0.717175278381915,
            "fpr": 0.2996706915477497,
            "logloss": 6.825490931592779,
            "mae": 0.34200849593387744,
            "precision": 0.61,
            "recall": 0.9143468950749465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7913413124447464,
            "auditor_fn_violation": 0.022132461544003747,
            "auditor_fp_violation": 0.030701754385964918,
            "ave_precision_score": 0.7919356549555907,
            "fpr": 0.13157894736842105,
            "logloss": 0.9341493562355041,
            "mae": 0.28909690890188433,
            "precision": 0.7505197505197505,
            "recall": 0.7412731006160165
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.787252907511691,
            "auditor_fn_violation": 0.010828865378422663,
            "auditor_fp_violation": 0.024735218203933897,
            "ave_precision_score": 0.7877162411136228,
            "fpr": 0.14818880351262348,
            "logloss": 0.951092227750456,
            "mae": 0.2859995822484923,
            "precision": 0.725050916496945,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7886885958343542,
            "auditor_fn_violation": 0.011149537087070864,
            "auditor_fp_violation": 0.021341589267285865,
            "ave_precision_score": 0.7516620967369418,
            "fpr": 0.14692982456140352,
            "logloss": 3.8078102588945275,
            "mae": 0.2910801030634389,
            "precision": 0.7346534653465346,
            "recall": 0.7618069815195072
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7815097365391566,
            "auditor_fn_violation": 0.004381377266199228,
            "auditor_fp_violation": 0.020856201975850718,
            "ave_precision_score": 0.7426395162333502,
            "fpr": 0.15587266739846323,
            "logloss": 3.8964040753698925,
            "mae": 0.2885724445408409,
            "precision": 0.7137096774193549,
            "recall": 0.7580299785867237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5790401524663912,
            "auditor_fn_violation": 0.0028369177564033445,
            "auditor_fp_violation": 0.0032559339525283803,
            "ave_precision_score": 0.5505015901697503,
            "fpr": 0.020833333333333332,
            "logloss": 0.7011539946977317,
            "mae": 0.4941306263371779,
            "precision": 0.5869565217391305,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5313926854830759,
            "auditor_fn_violation": 0.0030744857640496747,
            "auditor_fp_violation": 0.0053104696353873096,
            "ave_precision_score": 0.5251196827087788,
            "fpr": 0.027442371020856202,
            "logloss": 0.6980310900947377,
            "mae": 0.49412286522032534,
            "precision": 0.5098039215686274,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7937405771066763,
            "auditor_fn_violation": 0.008702132641665767,
            "auditor_fp_violation": 0.02344169246646028,
            "ave_precision_score": 0.7447360441885728,
            "fpr": 0.2730263157894737,
            "logloss": 5.2942892768267145,
            "mae": 0.3232209741386924,
            "precision": 0.6391304347826087,
            "recall": 0.9055441478439425
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7820573325692963,
            "auditor_fn_violation": 0.005420308999922433,
            "auditor_fp_violation": 0.02113062568605928,
            "ave_precision_score": 0.7247016794950336,
            "fpr": 0.27332601536772777,
            "logloss": 5.624608762865085,
            "mae": 0.32494356712269096,
            "precision": 0.6294642857142857,
            "recall": 0.9057815845824411
        }
    }
]