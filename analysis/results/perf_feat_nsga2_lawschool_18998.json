[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.659985946774416,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.039242843951985226,
            "ave_precision_score": 0.6607109396096823,
            "fpr": 0.19736842105263158,
            "logloss": 0.6525097185834322,
            "mae": 0.46038268108264,
            "precision": 0.6078431372549019,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6736414138473426,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030918847659624236,
            "ave_precision_score": 0.6741210405102085,
            "fpr": 0.1800219538968167,
            "logloss": 0.6729039917963954,
            "mae": 0.4674941453792392,
            "precision": 0.6272727272727273,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6763855661881978,
            "auditor_fn_violation": 0.00364054324407512,
            "auditor_fp_violation": 0.00519390581717452,
            "ave_precision_score": 0.561618609921934,
            "fpr": 0.07017543859649122,
            "logloss": 0.6718672228532726,
            "mae": 0.4740523461644587,
            "precision": 0.69377990430622,
            "recall": 0.31798245614035087
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7415708123684609,
            "auditor_fn_violation": 0.00988586618703133,
            "auditor_fp_violation": 0.007391499642518267,
            "ave_precision_score": 0.6270597630435731,
            "fpr": 0.052689352360043906,
            "logloss": 0.6534304563917109,
            "mae": 0.4651330220712396,
            "precision": 0.7808219178082192,
            "recall": 0.3433734939759036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 18998,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.636312749742582,
            "auditor_fn_violation": 0.061422745460141585,
            "auditor_fp_violation": 0.039704524469067415,
            "ave_precision_score": 0.6375784009061707,
            "fpr": 0.12280701754385964,
            "logloss": 0.6569017883425793,
            "mae": 0.47079006438715415,
            "precision": 0.6744186046511628,
            "recall": 0.5087719298245614
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6455584392585686,
            "auditor_fn_violation": 0.06578233901577774,
            "auditor_fp_violation": 0.037954194496641794,
            "ave_precision_score": 0.6465106780246077,
            "fpr": 0.1251372118551043,
            "logloss": 0.6678346151524908,
            "mae": 0.4758951927971761,
            "precision": 0.680672268907563,
            "recall": 0.4879518072289157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6598075127560151,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.039242843951985226,
            "ave_precision_score": 0.6605337325163028,
            "fpr": 0.19736842105263158,
            "logloss": 0.6524759927842887,
            "mae": 0.4603623937194546,
            "precision": 0.6078431372549019,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.673621290809093,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030522827002761516,
            "ave_precision_score": 0.674101004374843,
            "fpr": 0.17892425905598244,
            "logloss": 0.6728346565031894,
            "mae": 0.46746339397065334,
            "precision": 0.6287015945330297,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7198951485142814,
            "auditor_fn_violation": 0.06286790166204986,
            "auditor_fp_violation": 0.03627558479532164,
            "ave_precision_score": 0.6060539569748371,
            "fpr": 0.10416666666666667,
            "logloss": 0.6515140011406397,
            "mae": 0.4673116504819247,
            "precision": 0.703125,
            "recall": 0.4934210526315789
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7248693683887646,
            "auditor_fn_violation": 0.06456561702352773,
            "auditor_fp_violation": 0.03557541269870803,
            "ave_precision_score": 0.6208293502645074,
            "fpr": 0.11306256860592755,
            "logloss": 0.6628368364091112,
            "mae": 0.4724208801886645,
            "precision": 0.6943620178041543,
            "recall": 0.46987951807228917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6772809854651161,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.032534048938134816,
            "ave_precision_score": 0.677865493918044,
            "fpr": 0.17653508771929824,
            "logloss": 0.6489922014378542,
            "mae": 0.4587888181180971,
            "precision": 0.631578947368421,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6761021182436432,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.676669766378343,
            "fpr": 0.16355653128430298,
            "logloss": 0.675047829076818,
            "mae": 0.46839618733567806,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7114017295644579,
            "auditor_fn_violation": 0.08411963296398893,
            "auditor_fp_violation": 0.102791243459526,
            "ave_precision_score": 0.7129129591065015,
            "fpr": 0.2949561403508772,
            "logloss": 0.684385318758915,
            "mae": 0.49209102942493926,
            "precision": 0.5501672240802675,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7506646972736832,
            "auditor_fn_violation": 0.09199035439232231,
            "auditor_fp_violation": 0.09630212389333488,
            "ave_precision_score": 0.7518959839015831,
            "fpr": 0.27552140504939626,
            "logloss": 0.6808834918362414,
            "mae": 0.4905320960459934,
            "precision": 0.5925324675324676,
            "recall": 0.7329317269076305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7309965291263912,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6718297526488568,
            "fpr": 0.13267543859649122,
            "logloss": 0.6286551235744436,
            "mae": 0.4213368810647935,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7906134014014613,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7185251858571127,
            "fpr": 0.11745334796926454,
            "logloss": 0.601389129865439,
            "mae": 0.41135708171502167,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.661255179539983,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.03964200523237921,
            "ave_precision_score": 0.6619689877998591,
            "fpr": 0.1962719298245614,
            "logloss": 0.6521678677694286,
            "mae": 0.4602448323275894,
            "precision": 0.6091703056768559,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6743418650152668,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030522827002761516,
            "ave_precision_score": 0.6748190954832023,
            "fpr": 0.17892425905598244,
            "logloss": 0.6726740590660465,
            "mae": 0.46740751740912184,
            "precision": 0.6287015945330297,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6772488234559977,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.032534048938134816,
            "ave_precision_score": 0.6778335418252389,
            "fpr": 0.17653508771929824,
            "logloss": 0.648994748221435,
            "mae": 0.4587901116414159,
            "precision": 0.631578947368421,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6760330467886297,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.6766015749611358,
            "fpr": 0.16355653128430298,
            "logloss": 0.6750556077246646,
            "mae": 0.46839929389655915,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6600626255319625,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.039242843951985226,
            "ave_precision_score": 0.6607784172175318,
            "fpr": 0.19736842105263158,
            "logloss": 0.6525589181601927,
            "mae": 0.4604123348468228,
            "precision": 0.6078431372549019,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6735421715574589,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030918847659624236,
            "ave_precision_score": 0.674022988593934,
            "fpr": 0.1800219538968167,
            "logloss": 0.6730060266171224,
            "mae": 0.4675393959039129,
            "precision": 0.6272727272727273,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8192601121619244,
            "auditor_fn_violation": 0.008971510464758388,
            "auditor_fp_violation": 0.02035722530009235,
            "ave_precision_score": 0.8195353787519124,
            "fpr": 0.26644736842105265,
            "logloss": 0.6369224447225195,
            "mae": 0.35439181151984583,
            "precision": 0.6340361445783133,
            "recall": 0.9232456140350878
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8325947332318919,
            "auditor_fn_violation": 0.011528000035267306,
            "auditor_fp_violation": 0.029164662199695407,
            "ave_precision_score": 0.8328774469338216,
            "fpr": 0.2513721185510428,
            "logloss": 0.6222378723502137,
            "mae": 0.33834885196109993,
            "precision": 0.6676342525399129,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7114017295644579,
            "auditor_fn_violation": 0.08411963296398893,
            "auditor_fp_violation": 0.102791243459526,
            "ave_precision_score": 0.7129129591065015,
            "fpr": 0.2949561403508772,
            "logloss": 0.6843853185159321,
            "mae": 0.49209102939226124,
            "precision": 0.5501672240802675,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7506646972736832,
            "auditor_fn_violation": 0.09199035439232231,
            "auditor_fp_violation": 0.09630212389333488,
            "ave_precision_score": 0.7518959839015831,
            "fpr": 0.27552140504939626,
            "logloss": 0.6808834914362824,
            "mae": 0.49053209594785185,
            "precision": 0.5925324675324676,
            "recall": 0.7329317269076305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 18998,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6774489250896223,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.031884810710988,
            "ave_precision_score": 0.6780325902569634,
            "fpr": 0.17763157894736842,
            "logloss": 0.6489433523741582,
            "mae": 0.4587638965611787,
            "precision": 0.6301369863013698,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6762662433958193,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.6768330935816659,
            "fpr": 0.16355653128430298,
            "logloss": 0.6748999354757717,
            "mae": 0.4683370030312324,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7271376755129716,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6646666340484944,
            "fpr": 0.13267543859649122,
            "logloss": 0.6359777052340703,
            "mae": 0.42628458148816173,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7905347520052425,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7152568003945424,
            "fpr": 0.11745334796926454,
            "logloss": 0.6033497376930647,
            "mae": 0.4142666694623317,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6612114646244289,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.03964200523237921,
            "ave_precision_score": 0.6619253469254751,
            "fpr": 0.1962719298245614,
            "logloss": 0.6521558868740465,
            "mae": 0.4602377421484051,
            "precision": 0.6091703056768559,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6743000865179071,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030522827002761516,
            "ave_precision_score": 0.6747773987882303,
            "fpr": 0.17892425905598244,
            "logloss": 0.6726499019331956,
            "mae": 0.4673968771253799,
            "precision": 0.6287015945330297,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6611788928461166,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.03964200523237921,
            "ave_precision_score": 0.6618928522191834,
            "fpr": 0.1962719298245614,
            "logloss": 0.6521330548209989,
            "mae": 0.4602242233885223,
            "precision": 0.6091703056768559,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6742140693090893,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030522827002761516,
            "ave_precision_score": 0.6746953897732575,
            "fpr": 0.17892425905598244,
            "logloss": 0.6726039536867827,
            "mae": 0.4673766247952678,
            "precision": 0.6287015945330297,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6772498316189648,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.032534048938134816,
            "ave_precision_score": 0.6778345330193267,
            "fpr": 0.17653508771929824,
            "logloss": 0.6489974757480099,
            "mae": 0.45879149811930564,
            "precision": 0.631578947368421,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6760346668487254,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.6766031915052917,
            "fpr": 0.16355653128430298,
            "logloss": 0.6750639318483337,
            "mae": 0.46840261967503083,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6974718335925683,
            "auditor_fn_violation": 0.08740910664819947,
            "auditor_fp_violation": 0.10070406278855035,
            "ave_precision_score": 0.6990159179723443,
            "fpr": 0.29605263157894735,
            "logloss": 0.6816870966765551,
            "mae": 0.4876895780805825,
            "precision": 0.5492487479131887,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7442729852698423,
            "auditor_fn_violation": 0.09448110774602252,
            "auditor_fp_violation": 0.09010400193491971,
            "ave_precision_score": 0.7457177199659779,
            "fpr": 0.27552140504939626,
            "logloss": 0.6778909402990423,
            "mae": 0.48710844764725175,
            "precision": 0.5951612903225807,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7060966342853972,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.10910087719298246,
            "ave_precision_score": 0.5431354589146111,
            "fpr": 0.3125,
            "logloss": 0.6852988603213491,
            "mae": 0.4934712341872224,
            "precision": 0.5403225806451613,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7362286920836807,
            "auditor_fn_violation": 0.09442820678983772,
            "auditor_fp_violation": 0.10018259475923805,
            "ave_precision_score": 0.5873481851964582,
            "fpr": 0.2864983534577388,
            "logloss": 0.6814527717620609,
            "mae": 0.49157782090351426,
            "precision": 0.5876777251184834,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 18998,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7079775456267544,
            "auditor_fn_violation": 0.062103243305632515,
            "auditor_fp_violation": 0.04250346260387812,
            "ave_precision_score": 0.6035222072697932,
            "fpr": 0.12171052631578948,
            "logloss": 0.6582869984059769,
            "mae": 0.47157162937678787,
            "precision": 0.6754385964912281,
            "recall": 0.506578947368421
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7145588579948327,
            "auditor_fn_violation": 0.06612178681796341,
            "auditor_fp_violation": 0.038764840807669516,
            "ave_precision_score": 0.620180238984455,
            "fpr": 0.12403951701427003,
            "logloss": 0.6672272869683349,
            "mae": 0.475726599914444,
            "precision": 0.6807909604519774,
            "recall": 0.4839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 18998,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.636312749742582,
            "auditor_fn_violation": 0.061422745460141585,
            "auditor_fp_violation": 0.039704524469067415,
            "ave_precision_score": 0.6375784009061707,
            "fpr": 0.12280701754385964,
            "logloss": 0.6569017883734419,
            "mae": 0.47079006379895044,
            "precision": 0.6744186046511628,
            "recall": 0.5087719298245614
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6455584392585686,
            "auditor_fn_violation": 0.06578233901577774,
            "auditor_fp_violation": 0.037954194496641794,
            "ave_precision_score": 0.6465106780246077,
            "fpr": 0.1251372118551043,
            "logloss": 0.6678346169814787,
            "mae": 0.47589519292803156,
            "precision": 0.680672268907563,
            "recall": 0.4879518072289157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7178023795344812,
            "auditor_fn_violation": 0.06347385734072021,
            "auditor_fp_violation": 0.04103185595567867,
            "ave_precision_score": 0.6007377198970525,
            "fpr": 0.11403508771929824,
            "logloss": 0.6559584289350109,
            "mae": 0.47009064904169034,
            "precision": 0.6876876876876877,
            "recall": 0.5021929824561403
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7242149555605611,
            "auditor_fn_violation": 0.06574266329863912,
            "auditor_fp_violation": 0.03827047945078048,
            "ave_precision_score": 0.615997028261903,
            "fpr": 0.12294182217343579,
            "logloss": 0.6646826323288708,
            "mae": 0.4740150432489837,
            "precision": 0.6818181818181818,
            "recall": 0.4819277108433735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7312274858239417,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6753122678153298,
            "fpr": 0.13267543859649122,
            "logloss": 0.6273778438505989,
            "mae": 0.41907913824379966,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7908033477119586,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7211018872079455,
            "fpr": 0.11745334796926454,
            "logloss": 0.6021050107187293,
            "mae": 0.41048502033876927,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7198951485142814,
            "auditor_fn_violation": 0.06286790166204986,
            "auditor_fp_violation": 0.03627558479532164,
            "ave_precision_score": 0.6060539569748371,
            "fpr": 0.10416666666666667,
            "logloss": 0.6515238689918845,
            "mae": 0.46732399142102193,
            "precision": 0.703125,
            "recall": 0.4934210526315789
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7248693683887646,
            "auditor_fn_violation": 0.06456561702352773,
            "auditor_fp_violation": 0.03557541269870803,
            "ave_precision_score": 0.6208293502645074,
            "fpr": 0.11306256860592755,
            "logloss": 0.6628372647832014,
            "mae": 0.47242886675307044,
            "precision": 0.6943620178041543,
            "recall": 0.46987951807228917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7186146385543775,
            "auditor_fn_violation": 0.01283568020929518,
            "auditor_fp_violation": 0.006194213604185906,
            "ave_precision_score": 0.7201729154242861,
            "fpr": 0.06798245614035088,
            "logloss": 0.6733556524636545,
            "mae": 0.4745238808947697,
            "precision": 0.6884422110552764,
            "recall": 0.30043859649122806
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7851901396074953,
            "auditor_fn_violation": 0.011023236745004163,
            "auditor_fp_violation": 0.0072479753776149985,
            "ave_precision_score": 0.7864133539991703,
            "fpr": 0.050493962678375415,
            "logloss": 0.656372287213409,
            "mae": 0.4666078460334292,
            "precision": 0.7777777777777778,
            "recall": 0.3232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6974718335925683,
            "auditor_fn_violation": 0.08740910664819947,
            "auditor_fp_violation": 0.10070406278855035,
            "ave_precision_score": 0.6990159179723443,
            "fpr": 0.29605263157894735,
            "logloss": 0.6816870964444592,
            "mae": 0.48768957812143,
            "precision": 0.5492487479131887,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7442729852698423,
            "auditor_fn_violation": 0.09448110774602252,
            "auditor_fp_violation": 0.09010400193491971,
            "ave_precision_score": 0.7457177199659779,
            "fpr": 0.27552140504939626,
            "logloss": 0.6778909401294554,
            "mae": 0.4871084476145379,
            "precision": 0.5951612903225807,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8192545197652419,
            "auditor_fn_violation": 0.008971510464758388,
            "auditor_fp_violation": 0.02035722530009235,
            "ave_precision_score": 0.8195297985810133,
            "fpr": 0.26644736842105265,
            "logloss": 0.6369210048988233,
            "mae": 0.35439678786621953,
            "precision": 0.6340361445783133,
            "recall": 0.9232456140350878
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8325879831222839,
            "auditor_fn_violation": 0.011528000035267306,
            "auditor_fp_violation": 0.029164662199695407,
            "ave_precision_score": 0.8328706999651865,
            "fpr": 0.2513721185510428,
            "logloss": 0.6222318015409211,
            "mae": 0.33835271077248247,
            "precision": 0.6676342525399129,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7710578768612587,
            "auditor_fn_violation": 0.044744536780547864,
            "auditor_fp_violation": 0.0835257002154509,
            "ave_precision_score": 0.7714235393596212,
            "fpr": 0.24561403508771928,
            "logloss": 0.7037507307870419,
            "mae": 0.35819154115337404,
            "precision": 0.6190476190476191,
            "recall": 0.7982456140350878
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.813115978001522,
            "auditor_fn_violation": 0.05624694166347058,
            "auditor_fp_violation": 0.07524658266067409,
            "ave_precision_score": 0.8134058183142556,
            "fpr": 0.20856201975850713,
            "logloss": 0.6614013643451122,
            "mae": 0.33342037125291124,
            "precision": 0.6774193548387096,
            "recall": 0.8012048192771084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8129916845852353,
            "auditor_fn_violation": 0.013835987996306556,
            "auditor_fp_violation": 0.020970394736842122,
            "ave_precision_score": 0.8132824633767721,
            "fpr": 0.2708333333333333,
            "logloss": 0.7640366146876179,
            "mae": 0.34306730225880966,
            "precision": 0.6329866270430906,
            "recall": 0.9342105263157895
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8256053812891317,
            "auditor_fn_violation": 0.008715432531443006,
            "auditor_fp_violation": 0.022716701706078257,
            "ave_precision_score": 0.825951928822879,
            "fpr": 0.26125137211855104,
            "logloss": 0.7476641205265139,
            "mae": 0.32744644236511805,
            "precision": 0.66,
            "recall": 0.927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7198951485142814,
            "auditor_fn_violation": 0.06286790166204986,
            "auditor_fp_violation": 0.03627558479532164,
            "ave_precision_score": 0.6060539569748371,
            "fpr": 0.10416666666666667,
            "logloss": 0.6515238689918845,
            "mae": 0.46732399142102193,
            "precision": 0.703125,
            "recall": 0.4934210526315789
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7248693683887646,
            "auditor_fn_violation": 0.06456561702352773,
            "auditor_fp_violation": 0.03557541269870803,
            "ave_precision_score": 0.6208293502645074,
            "fpr": 0.11306256860592755,
            "logloss": 0.6628372647832014,
            "mae": 0.47242886675307044,
            "precision": 0.6943620178041543,
            "recall": 0.46987951807228917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7186146385543775,
            "auditor_fn_violation": 0.01283568020929518,
            "auditor_fp_violation": 0.006194213604185906,
            "ave_precision_score": 0.7201729154242861,
            "fpr": 0.06798245614035088,
            "logloss": 0.6733556525147847,
            "mae": 0.47452388086209174,
            "precision": 0.6884422110552764,
            "recall": 0.30043859649122806
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7851901396074953,
            "auditor_fn_violation": 0.011023236745004163,
            "auditor_fp_violation": 0.0072479753776149985,
            "ave_precision_score": 0.7864133539991703,
            "fpr": 0.050493962678375415,
            "logloss": 0.6563722873009961,
            "mae": 0.4666078460661431,
            "precision": 0.7777777777777778,
            "recall": 0.3232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8226332045054114,
            "auditor_fn_violation": 0.011974838411819023,
            "auditor_fp_violation": 0.01704851492767006,
            "ave_precision_score": 0.8229226903429209,
            "fpr": 0.18201754385964913,
            "logloss": 0.5316474046940506,
            "mae": 0.3487576277296239,
            "precision": 0.6902985074626866,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8539793511661684,
            "auditor_fn_violation": 0.006980722009883665,
            "auditor_fp_violation": 0.024367230752465833,
            "ave_precision_score": 0.8541621658813408,
            "fpr": 0.16575192096597147,
            "logloss": 0.527300667644306,
            "mae": 0.3453726563291401,
            "precision": 0.7303571428571428,
            "recall": 0.821285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 18998,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7079775456267544,
            "auditor_fn_violation": 0.062103243305632515,
            "auditor_fp_violation": 0.04250346260387812,
            "ave_precision_score": 0.6035222072697932,
            "fpr": 0.12171052631578948,
            "logloss": 0.6582869984059769,
            "mae": 0.47157162937678787,
            "precision": 0.6754385964912281,
            "recall": 0.506578947368421
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7145588579948327,
            "auditor_fn_violation": 0.06612178681796341,
            "auditor_fp_violation": 0.038764840807669516,
            "ave_precision_score": 0.620180238984455,
            "fpr": 0.12403951701427003,
            "logloss": 0.6672272869683349,
            "mae": 0.475726599914444,
            "precision": 0.6807909604519774,
            "recall": 0.4839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8219688894988063,
            "auditor_fn_violation": 0.011801708217913204,
            "auditor_fp_violation": 0.019106840566328095,
            "ave_precision_score": 0.822338636798444,
            "fpr": 0.21162280701754385,
            "logloss": 0.5546401131371403,
            "mae": 0.34041949330279303,
            "precision": 0.6723259762308998,
            "recall": 0.868421052631579
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8593658498548395,
            "auditor_fn_violation": 0.012180445161546299,
            "auditor_fp_violation": 0.02680182754230644,
            "ave_precision_score": 0.8595431997922627,
            "fpr": 0.1964873765093304,
            "logloss": 0.539331117869329,
            "mae": 0.3351918051144256,
            "precision": 0.7036423841059603,
            "recall": 0.8534136546184738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8250086534227274,
            "auditor_fn_violation": 0.011926746691289628,
            "auditor_fp_violation": 0.015043090181594346,
            "ave_precision_score": 0.8254245606259127,
            "fpr": 0.22807017543859648,
            "logloss": 0.5707553663823034,
            "mae": 0.34162368643385715,
            "precision": 0.6612377850162866,
            "recall": 0.8903508771929824
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8550256495024717,
            "auditor_fn_violation": 0.00993215452369302,
            "auditor_fp_violation": 0.020757861275824407,
            "ave_precision_score": 0.8552307625819517,
            "fpr": 0.20856201975850713,
            "logloss": 0.5522074564185157,
            "mae": 0.3324252399215726,
            "precision": 0.6945337620578779,
            "recall": 0.8674698795180723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8267660949010371,
            "auditor_fn_violation": 0.013629193598030163,
            "auditor_fp_violation": 0.012306671283471852,
            "ave_precision_score": 0.8270297517209785,
            "fpr": 0.2565789473684211,
            "logloss": 0.6246817427724968,
            "mae": 0.34804253139102176,
            "precision": 0.6432926829268293,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8350998093495415,
            "auditor_fn_violation": 0.007172487976053503,
            "auditor_fp_violation": 0.023700108706341375,
            "ave_precision_score": 0.8354363604969408,
            "fpr": 0.24478594950603733,
            "logloss": 0.609843010076166,
            "mae": 0.33242319728775493,
            "precision": 0.6720588235294118,
            "recall": 0.9176706827309237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7312274858239417,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6753122678153298,
            "fpr": 0.13267543859649122,
            "logloss": 0.6277220390528694,
            "mae": 0.4193123898289183,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7908033477119586,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7211018872079455,
            "fpr": 0.11745334796926454,
            "logloss": 0.6020968906062864,
            "mae": 0.41057325907779446,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8312767216238204,
            "auditor_fn_violation": 0.009190327793167127,
            "auditor_fp_violation": 0.010214681440443222,
            "ave_precision_score": 0.8315878186618786,
            "fpr": 0.18421052631578946,
            "logloss": 0.5322802564717849,
            "mae": 0.3385363522678223,
            "precision": 0.6945454545454546,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8625810799009496,
            "auditor_fn_violation": 0.00958388989547653,
            "auditor_fp_violation": 0.02584765696637546,
            "ave_precision_score": 0.862742092424642,
            "fpr": 0.16355653128430298,
            "logloss": 0.5221706998058868,
            "mae": 0.3356069610187623,
            "precision": 0.7372134038800705,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7526679957816791,
            "auditor_fn_violation": 0.010118497999384435,
            "auditor_fp_violation": 0.018928901200369348,
            "ave_precision_score": 0.7356752022752574,
            "fpr": 0.15570175438596492,
            "logloss": 0.6279130298623784,
            "mae": 0.4236885204976588,
            "precision": 0.6899563318777293,
            "recall": 0.6929824561403509
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7994290599060571,
            "auditor_fn_violation": 0.010143758348432154,
            "auditor_fp_violation": 0.02338913946571763,
            "ave_precision_score": 0.7830602859114276,
            "fpr": 0.1350164654226125,
            "logloss": 0.5939090481856466,
            "mae": 0.4096682864158495,
            "precision": 0.740506329113924,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8250132785798742,
            "auditor_fn_violation": 0.01448041705140043,
            "auditor_fp_violation": 0.019126077254539853,
            "ave_precision_score": 0.8252795436212772,
            "fpr": 0.29714912280701755,
            "logloss": 0.6582676681796683,
            "mae": 0.35831311634734575,
            "precision": 0.6117478510028653,
            "recall": 0.9364035087719298
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8370345442350617,
            "auditor_fn_violation": 0.009013000409982411,
            "auditor_fp_violation": 0.028476277299511223,
            "ave_precision_score": 0.8373048994896359,
            "fpr": 0.27552140504939626,
            "logloss": 0.6374966247280388,
            "mae": 0.3402576727025856,
            "precision": 0.6523545706371191,
            "recall": 0.9457831325301205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8267660949010371,
            "auditor_fn_violation": 0.013629193598030163,
            "auditor_fp_violation": 0.012306671283471852,
            "ave_precision_score": 0.8270297517209785,
            "fpr": 0.2565789473684211,
            "logloss": 0.6246808657142011,
            "mae": 0.34804285421399217,
            "precision": 0.6432926829268293,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8350998093495415,
            "auditor_fn_violation": 0.007172487976053503,
            "auditor_fp_violation": 0.023700108706341375,
            "ave_precision_score": 0.8354363604969408,
            "fpr": 0.24478594950603733,
            "logloss": 0.6098417537394265,
            "mae": 0.3324234583977058,
            "precision": 0.6720588235294118,
            "recall": 0.9176706827309237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 18998,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.819258218436123,
            "auditor_fn_violation": 0.008971510464758388,
            "auditor_fp_violation": 0.019813788858110193,
            "ave_precision_score": 0.819533525701171,
            "fpr": 0.2675438596491228,
            "logloss": 0.6370975402453692,
            "mae": 0.3543535725287679,
            "precision": 0.6330827067669172,
            "recall": 0.9232456140350878
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8325156828842046,
            "auditor_fn_violation": 0.011528000035267306,
            "auditor_fp_violation": 0.029164662199695407,
            "ave_precision_score": 0.8327985473113475,
            "fpr": 0.2513721185510428,
            "logloss": 0.62248550387001,
            "mae": 0.3383294117576379,
            "precision": 0.6676342525399129,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6612726899026304,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.03964200523237921,
            "ave_precision_score": 0.6619905244498152,
            "fpr": 0.1962719298245614,
            "logloss": 0.6521751032076739,
            "mae": 0.4602491163052292,
            "precision": 0.6091703056768559,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.674359447464088,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030522827002761516,
            "ave_precision_score": 0.6748366274865314,
            "fpr": 0.17892425905598244,
            "logloss": 0.6726886576880835,
            "mae": 0.46741395004903313,
            "precision": 0.6287015945330297,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8173702875484856,
            "auditor_fn_violation": 0.0115564404432133,
            "auditor_fp_violation": 0.02145371652816252,
            "ave_precision_score": 0.8176501711878459,
            "fpr": 0.24342105263157895,
            "logloss": 0.6146800049825686,
            "mae": 0.34972757321571535,
            "precision": 0.6487341772151899,
            "recall": 0.8991228070175439
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8315590711004928,
            "auditor_fn_violation": 0.012125339998853813,
            "auditor_fp_violation": 0.030047070643174755,
            "ave_precision_score": 0.831845093865927,
            "fpr": 0.21514818880351264,
            "logloss": 0.6036418158548131,
            "mae": 0.3354812558387435,
            "precision": 0.6932707355242567,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.8153469595828708,
            "auditor_fn_violation": 0.006098030163127115,
            "auditor_fp_violation": 0.040512465373961234,
            "ave_precision_score": 0.815632846029802,
            "fpr": 0.33771929824561403,
            "logloss": 0.7656569925719314,
            "mae": 0.3714361512066844,
            "precision": 0.5860215053763441,
            "recall": 0.956140350877193
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8366610500080118,
            "auditor_fn_violation": 0.005600888736063906,
            "auditor_fp_violation": 0.02859056514008234,
            "ave_precision_score": 0.8369260733856836,
            "fpr": 0.31613611416026344,
            "logloss": 0.71814735477605,
            "mae": 0.34565399218443066,
            "precision": 0.6235294117647059,
            "recall": 0.9578313253012049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6772979233146557,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.032534048938134816,
            "ave_precision_score": 0.6778824264578658,
            "fpr": 0.17653508771929824,
            "logloss": 0.6489862688691069,
            "mae": 0.4587857979921657,
            "precision": 0.631578947368421,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.676117575979811,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.6766852070217759,
            "fpr": 0.16355653128430298,
            "logloss": 0.6750297451569991,
            "mae": 0.46838895799479685,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.75597949470068,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.011368882733148662,
            "ave_precision_score": 0.7400626665572353,
            "fpr": 0.14144736842105263,
            "logloss": 0.6312561305860053,
            "mae": 0.42430074258070244,
            "precision": 0.7006960556844548,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7956940479258491,
            "auditor_fn_violation": 0.007485485300146809,
            "auditor_fp_violation": 0.014291295784904977,
            "ave_precision_score": 0.7795311588409758,
            "fpr": 0.11964873765093303,
            "logloss": 0.6000621874887,
            "mae": 0.41280373526914976,
            "precision": 0.7494252873563219,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8229800676431726,
            "auditor_fn_violation": 0.004371537396121885,
            "auditor_fp_violation": 0.01041666666666667,
            "ave_precision_score": 0.8233291580420714,
            "fpr": 0.125,
            "logloss": 0.5211440505033338,
            "mae": 0.336219689659918,
            "precision": 0.7432432432432432,
            "recall": 0.7236842105263158
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.858210443037179,
            "auditor_fn_violation": 0.009786676894184868,
            "auditor_fp_violation": 0.017557801739833036,
            "ave_precision_score": 0.8583829974386428,
            "fpr": 0.12403951701427003,
            "logloss": 0.5252099568015437,
            "mae": 0.3365942770643174,
            "precision": 0.7665289256198347,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7303514703510424,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6736661974994446,
            "fpr": 0.13267543859649122,
            "logloss": 0.6297583637782584,
            "mae": 0.42201007495781306,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7906391600099996,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7204084156359867,
            "fpr": 0.11745334796926454,
            "logloss": 0.6016981336640936,
            "mae": 0.4119322064090377,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8250860628499324,
            "auditor_fn_violation": 0.01448041705140043,
            "auditor_fp_violation": 0.019126077254539853,
            "ave_precision_score": 0.8253521910815255,
            "fpr": 0.29714912280701755,
            "logloss": 0.6583485731794984,
            "mae": 0.35832144153723594,
            "precision": 0.6117478510028653,
            "recall": 0.9364035087719298
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8370393125696096,
            "auditor_fn_violation": 0.009013000409982411,
            "auditor_fp_violation": 0.028476277299511223,
            "ave_precision_score": 0.8373096556550768,
            "fpr": 0.27552140504939626,
            "logloss": 0.6375725958468131,
            "mae": 0.3402626623598353,
            "precision": 0.6523545706371191,
            "recall": 0.9457831325301205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6531840026101358,
            "auditor_fn_violation": 0.006636657433056327,
            "auditor_fp_violation": 0.025363573407202224,
            "ave_precision_score": 0.6469321295459854,
            "fpr": 0.23574561403508773,
            "logloss": 1.6104192193719435,
            "mae": 0.3680677924023353,
            "precision": 0.650974025974026,
            "recall": 0.8793859649122807
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7004599135054724,
            "auditor_fn_violation": 0.005530354127817528,
            "auditor_fp_violation": 0.03537075772838299,
            "ave_precision_score": 0.6949773820897535,
            "fpr": 0.2327113062568606,
            "logloss": 1.4138007047637837,
            "mae": 0.35793232365943795,
            "precision": 0.6702954898911353,
            "recall": 0.8654618473895582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7271376755129716,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6646666340484944,
            "fpr": 0.13267543859649122,
            "logloss": 0.6325952564862338,
            "mae": 0.4252790483858502,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7905347520052425,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7152568003945424,
            "fpr": 0.11745334796926454,
            "logloss": 0.6016811653845705,
            "mae": 0.41404757234058315,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8192545197652419,
            "auditor_fn_violation": 0.008971510464758388,
            "auditor_fp_violation": 0.02035722530009235,
            "ave_precision_score": 0.8195297985810133,
            "fpr": 0.26644736842105265,
            "logloss": 0.6369223122557828,
            "mae": 0.354395799832761,
            "precision": 0.6340361445783133,
            "recall": 0.9232456140350878
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8325879831222839,
            "auditor_fn_violation": 0.011528000035267306,
            "auditor_fp_violation": 0.029164662199695407,
            "ave_precision_score": 0.8328706999651865,
            "fpr": 0.2513721185510428,
            "logloss": 0.622234156595189,
            "mae": 0.3383519862932791,
            "precision": 0.6676342525399129,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8352813003138164,
            "auditor_fn_violation": 0.006194213604185906,
            "auditor_fp_violation": 0.032990920283164055,
            "ave_precision_score": 0.8355141790676126,
            "fpr": 0.27521929824561403,
            "logloss": 0.6953008504811261,
            "mae": 0.34084856653545786,
            "precision": 0.6281481481481481,
            "recall": 0.9298245614035088
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.862008370163704,
            "auditor_fn_violation": 0.0013776290673120574,
            "auditor_fp_violation": 0.02853209229141805,
            "ave_precision_score": 0.8622574086592274,
            "fpr": 0.26344676180021953,
            "logloss": 0.6430482834973096,
            "mae": 0.32081998843286164,
            "precision": 0.6605374823196606,
            "recall": 0.9377510040160643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.826763328974653,
            "auditor_fn_violation": 0.013629193598030163,
            "auditor_fp_violation": 0.012306671283471852,
            "ave_precision_score": 0.8270269872184979,
            "fpr": 0.2565789473684211,
            "logloss": 0.6246708484508146,
            "mae": 0.3480460555351743,
            "precision": 0.6432926829268293,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8351173142307537,
            "auditor_fn_violation": 0.007172487976053503,
            "auditor_fp_violation": 0.023700108706341375,
            "ave_precision_score": 0.8354537622356468,
            "fpr": 0.24478594950603733,
            "logloss": 0.6098282617855256,
            "mae": 0.33242606529093444,
            "precision": 0.6720588235294118,
            "recall": 0.9176706827309237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7953981913786763,
            "auditor_fn_violation": 0.0013273314866112653,
            "auditor_fp_violation": 0.01638484918436443,
            "ave_precision_score": 0.7967542510720302,
            "fpr": 0.4199561403508772,
            "logloss": 1.279269903496325,
            "mae": 0.41129146238848124,
            "precision": 0.5374396135265701,
            "recall": 0.9758771929824561
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7991118717657538,
            "auditor_fn_violation": 0.0027155824174855295,
            "auditor_fp_violation": 0.015925877690747738,
            "ave_precision_score": 0.7996649683630048,
            "fpr": 0.38748627881448955,
            "logloss": 1.142248216921855,
            "mae": 0.37664848802047296,
            "precision": 0.5832349468713105,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7507462712623866,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.011368882733148662,
            "ave_precision_score": 0.733951501103083,
            "fpr": 0.14144736842105263,
            "logloss": 0.6365888541220758,
            "mae": 0.4289784481454837,
            "precision": 0.7006960556844548,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7957575914206337,
            "auditor_fn_violation": 0.007485485300146809,
            "auditor_fp_violation": 0.014291295784904977,
            "ave_precision_score": 0.7785343153364376,
            "fpr": 0.11964873765093303,
            "logloss": 0.6013617403308092,
            "mae": 0.4157071053944978,
            "precision": 0.7494252873563219,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8267645240633815,
            "auditor_fn_violation": 0.013629193598030163,
            "auditor_fp_violation": 0.012306671283471852,
            "ave_precision_score": 0.8270281909249503,
            "fpr": 0.2565789473684211,
            "logloss": 0.6246998056184874,
            "mae": 0.34802787635262095,
            "precision": 0.6432926829268293,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8351124782697708,
            "auditor_fn_violation": 0.007172487976053503,
            "auditor_fp_violation": 0.023700108706341375,
            "ave_precision_score": 0.8354515762754512,
            "fpr": 0.24478594950603733,
            "logloss": 0.6098753987426042,
            "mae": 0.33241166303222797,
            "precision": 0.6720588235294118,
            "recall": 0.9176706827309237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6600092013967979,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.039242843951985226,
            "ave_precision_score": 0.6607294859212767,
            "fpr": 0.19736842105263158,
            "logloss": 0.6525277461242798,
            "mae": 0.460393539315351,
            "precision": 0.6078431372549019,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6733303960320173,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030918847659624236,
            "ave_precision_score": 0.6738100825235852,
            "fpr": 0.1800219538968167,
            "logloss": 0.674590812756222,
            "mae": 0.4679051968591077,
            "precision": 0.6272727272727273,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6598095237025285,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.039242843951985226,
            "ave_precision_score": 0.660535698738849,
            "fpr": 0.19736842105263158,
            "logloss": 0.6524826616172931,
            "mae": 0.4603664061430384,
            "precision": 0.6078431372549019,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.673619609477976,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030522827002761516,
            "ave_precision_score": 0.6740993062903275,
            "fpr": 0.17892425905598244,
            "logloss": 0.6728483521375119,
            "mae": 0.4674694686964498,
            "precision": 0.6287015945330297,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7312274858239417,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6753122678153298,
            "fpr": 0.13267543859649122,
            "logloss": 0.6275750859093727,
            "mae": 0.4192681428404492,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7908033477119586,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7211018872079455,
            "fpr": 0.11745334796926454,
            "logloss": 0.6020170254870478,
            "mae": 0.41056097505775685,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7114017295644579,
            "auditor_fn_violation": 0.08411963296398893,
            "auditor_fp_violation": 0.1033875807940905,
            "ave_precision_score": 0.7129129591065015,
            "fpr": 0.29605263157894735,
            "logloss": 0.684390968038451,
            "mae": 0.4920956268253034,
            "precision": 0.5492487479131887,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7506646972736832,
            "auditor_fn_violation": 0.09199035439232231,
            "auditor_fp_violation": 0.09630212389333488,
            "ave_precision_score": 0.7518959839015831,
            "fpr": 0.27552140504939626,
            "logloss": 0.6808697611330301,
            "mae": 0.49052462240212835,
            "precision": 0.5925324675324676,
            "recall": 0.7329317269076305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6600184633398427,
            "auditor_fn_violation": 0.024606128808864276,
            "auditor_fp_violation": 0.039242843951985226,
            "ave_precision_score": 0.660738726818416,
            "fpr": 0.19736842105263158,
            "logloss": 0.6525359179148253,
            "mae": 0.46039846313610805,
            "precision": 0.6078431372549019,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6736525787432053,
            "auditor_fn_violation": 0.04698927433113355,
            "auditor_fp_violation": 0.030918847659624236,
            "ave_precision_score": 0.6741321710296233,
            "fpr": 0.1800219538968167,
            "logloss": 0.6729582016134578,
            "mae": 0.4675181853849723,
            "precision": 0.6272727272727273,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7557867302160076,
            "auditor_fn_violation": 0.014153393351800552,
            "auditor_fp_violation": 0.013319002000615573,
            "ave_precision_score": 0.7395199437538069,
            "fpr": 0.1524122807017544,
            "logloss": 0.6200473042323492,
            "mae": 0.420069933166368,
            "precision": 0.6958424507658644,
            "recall": 0.6973684210526315
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.809414824931359,
            "auditor_fn_violation": 0.010130533109385961,
            "auditor_fp_violation": 0.02148877188412808,
            "ave_precision_score": 0.7924744855116492,
            "fpr": 0.13062568605927552,
            "logloss": 0.5850035369183543,
            "mae": 0.40697845281331785,
            "precision": 0.7451820128479657,
            "recall": 0.6987951807228916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8215523146964441,
            "auditor_fn_violation": 0.008911395814096645,
            "auditor_fp_violation": 0.017851646660510936,
            "ave_precision_score": 0.8219159903838361,
            "fpr": 0.2225877192982456,
            "logloss": 0.5718688134906579,
            "mae": 0.3467218170859077,
            "precision": 0.6666666666666666,
            "recall": 0.8903508771929824
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8582768432882153,
            "auditor_fn_violation": 0.012458175181516408,
            "auditor_fp_violation": 0.024436335028160006,
            "ave_precision_score": 0.858454308029502,
            "fpr": 0.21624588364434688,
            "logloss": 0.5531594545255138,
            "mae": 0.3400729049240154,
            "precision": 0.6853035143769968,
            "recall": 0.8614457831325302
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8223395669145478,
            "auditor_fn_violation": 0.010993767313019391,
            "auditor_fp_violation": 0.019688750384733767,
            "ave_precision_score": 0.822700374850002,
            "fpr": 0.21271929824561403,
            "logloss": 0.5559943306194546,
            "mae": 0.3413187050495684,
            "precision": 0.6711864406779661,
            "recall": 0.868421052631579
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8591218232755102,
            "auditor_fn_violation": 0.006559718566913099,
            "auditor_fp_violation": 0.02562705485550563,
            "ave_precision_score": 0.8592965438299269,
            "fpr": 0.19758507135016465,
            "logloss": 0.541095656613591,
            "mae": 0.3359245155925766,
            "precision": 0.7024793388429752,
            "recall": 0.8534136546184738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6773514306301616,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.032534048938134816,
            "ave_precision_score": 0.6779359038605198,
            "fpr": 0.17653508771929824,
            "logloss": 0.6489778318090215,
            "mae": 0.45878149912561894,
            "precision": 0.631578947368421,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6761557265378729,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.6767222861824922,
            "fpr": 0.16355653128430298,
            "logloss": 0.6750041521087368,
            "mae": 0.46837872222605703,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8352813003138164,
            "auditor_fn_violation": 0.006194213604185906,
            "auditor_fp_violation": 0.032990920283164055,
            "ave_precision_score": 0.8355141790676126,
            "fpr": 0.27521929824561403,
            "logloss": 0.6953007063308116,
            "mae": 0.34084855096931443,
            "precision": 0.6281481481481481,
            "recall": 0.9298245614035088
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.862008370163704,
            "auditor_fn_violation": 0.0013776290673120574,
            "auditor_fp_violation": 0.02853209229141805,
            "ave_precision_score": 0.8622574086592274,
            "fpr": 0.26344676180021953,
            "logloss": 0.6430481289637746,
            "mae": 0.3208199700076133,
            "precision": 0.6605374823196606,
            "recall": 0.9377510040160643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.825027974801847,
            "auditor_fn_violation": 0.011926746691289628,
            "auditor_fp_violation": 0.01454293628808864,
            "ave_precision_score": 0.8254358063448826,
            "fpr": 0.2236842105263158,
            "logloss": 0.5662609011081918,
            "mae": 0.3403793704755428,
            "precision": 0.6655737704918033,
            "recall": 0.8903508771929824
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8552168053626252,
            "auditor_fn_violation": 0.010531698693787226,
            "auditor_fp_violation": 0.017898007404788936,
            "ave_precision_score": 0.8554163322939159,
            "fpr": 0.2074643249176729,
            "logloss": 0.5492858002671099,
            "mae": 0.33169012273319065,
            "precision": 0.6951612903225807,
            "recall": 0.8654618473895582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5401148180158429,
            "auditor_fn_violation": 0.01283568020929518,
            "auditor_fp_violation": 0.005578639581409665,
            "ave_precision_score": 0.541620296989726,
            "fpr": 0.07675438596491228,
            "logloss": 0.6836061314814291,
            "mae": 0.47978168314224795,
            "precision": 0.6618357487922706,
            "recall": 0.30043859649122806
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5886631978133124,
            "auditor_fn_violation": 0.011479507492097921,
            "auditor_fp_violation": 0.004566197909329876,
            "ave_precision_score": 0.5904352602533869,
            "fpr": 0.054884742041712405,
            "logloss": 0.6632160692923089,
            "mae": 0.47017977495486596,
            "precision": 0.7641509433962265,
            "recall": 0.3253012048192771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8126574311411727,
            "auditor_fn_violation": 0.013835987996306556,
            "auditor_fp_violation": 0.020970394736842122,
            "ave_precision_score": 0.8129487773659536,
            "fpr": 0.2708333333333333,
            "logloss": 0.7667307635643825,
            "mae": 0.3429920382168946,
            "precision": 0.6329866270430906,
            "recall": 0.9342105263157895
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8251357888612242,
            "auditor_fn_violation": 0.008715432531443006,
            "auditor_fp_violation": 0.022729990989865594,
            "ave_precision_score": 0.8254901025803989,
            "fpr": 0.2601536772777168,
            "logloss": 0.7506602801742118,
            "mae": 0.32739047789141257,
            "precision": 0.6609442060085837,
            "recall": 0.927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.8148331213119591,
            "auditor_fn_violation": 0.006098030163127115,
            "auditor_fp_violation": 0.04263090566328101,
            "ave_precision_score": 0.8151196578473923,
            "fpr": 0.3300438596491228,
            "logloss": 0.7599625778670291,
            "mae": 0.3703940208822547,
            "precision": 0.5915875169606513,
            "recall": 0.956140350877193
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8361349544389497,
            "auditor_fn_violation": 0.006546493327866902,
            "auditor_fp_violation": 0.028447040875179075,
            "ave_precision_score": 0.8364006133420607,
            "fpr": 0.31284302963776073,
            "logloss": 0.7130783990997662,
            "mae": 0.34482153600963206,
            "precision": 0.6245059288537549,
            "recall": 0.9518072289156626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8222345439041133,
            "auditor_fn_violation": 0.007059864573714992,
            "auditor_fp_violation": 0.014023545706371196,
            "ave_precision_score": 0.8226691828023749,
            "fpr": 0.18859649122807018,
            "logloss": 0.5308458223529489,
            "mae": 0.32696895897745554,
            "precision": 0.6934046345811051,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8618896423950047,
            "auditor_fn_violation": 0.012228937704715679,
            "auditor_fp_violation": 0.021079461943478026,
            "ave_precision_score": 0.8620654237812423,
            "fpr": 0.1690450054884742,
            "logloss": 0.5207524704668154,
            "mae": 0.3229599151174653,
            "precision": 0.7307692307692307,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8246354622916185,
            "auditor_fn_violation": 0.011926746691289628,
            "auditor_fp_violation": 0.015144082794706071,
            "ave_precision_score": 0.8250551316159112,
            "fpr": 0.23135964912280702,
            "logloss": 0.5731525532230413,
            "mae": 0.3424139119978615,
            "precision": 0.6580226904376013,
            "recall": 0.8903508771929824
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8561581387777626,
            "auditor_fn_violation": 0.009332610353598813,
            "auditor_fp_violation": 0.02233397033300288,
            "ave_precision_score": 0.8563528098247477,
            "fpr": 0.21075740944017562,
            "logloss": 0.5532989551094868,
            "mae": 0.3324049323093734,
            "precision": 0.6928,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7526679957816791,
            "auditor_fn_violation": 0.010118497999384435,
            "auditor_fp_violation": 0.018928901200369348,
            "ave_precision_score": 0.7356752022752574,
            "fpr": 0.15570175438596492,
            "logloss": 0.6279131316134076,
            "mae": 0.4236885691878566,
            "precision": 0.6899563318777293,
            "recall": 0.6929824561403509
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7994290599060571,
            "auditor_fn_violation": 0.010143758348432154,
            "auditor_fp_violation": 0.02338913946571763,
            "ave_precision_score": 0.7830602859114276,
            "fpr": 0.1350164654226125,
            "logloss": 0.5939090360394188,
            "mae": 0.409668276137565,
            "precision": 0.740506329113924,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7750473462802165,
            "auditor_fn_violation": 0.04465316251154201,
            "auditor_fp_violation": 0.08021698984302862,
            "ave_precision_score": 0.7754080978812794,
            "fpr": 0.23355263157894737,
            "logloss": 0.6711615847474389,
            "mae": 0.3556379116476468,
            "precision": 0.6302083333333334,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8078485904633399,
            "auditor_fn_violation": 0.058662751995909,
            "auditor_fp_violation": 0.06987771201058891,
            "ave_precision_score": 0.8081571713440154,
            "fpr": 0.20197585071350166,
            "logloss": 0.6523266440476625,
            "mae": 0.33595030525460634,
            "precision": 0.6816608996539792,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8218410643313179,
            "auditor_fn_violation": 0.013771064173591877,
            "auditor_fp_violation": 0.020898257156048015,
            "ave_precision_score": 0.8221526039987976,
            "fpr": 0.2532894736842105,
            "logloss": 0.6259517751077006,
            "mae": 0.3590416439488651,
            "precision": 0.6401869158878505,
            "recall": 0.9013157894736842
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8351043869784212,
            "auditor_fn_violation": 0.012484625659608799,
            "auditor_fp_violation": 0.03297337093314692,
            "ave_precision_score": 0.835391997962668,
            "fpr": 0.24039517014270034,
            "logloss": 0.6121101762141001,
            "mae": 0.34545175093418456,
            "precision": 0.6755555555555556,
            "recall": 0.9156626506024096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6763855661881978,
            "auditor_fn_violation": 0.00364054324407512,
            "auditor_fp_violation": 0.00519390581717452,
            "ave_precision_score": 0.561618609921934,
            "fpr": 0.07017543859649122,
            "logloss": 0.6718672228532726,
            "mae": 0.4740523461644587,
            "precision": 0.69377990430622,
            "recall": 0.31798245614035087
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7415708123684609,
            "auditor_fn_violation": 0.00988586618703133,
            "auditor_fp_violation": 0.007391499642518267,
            "ave_precision_score": 0.6270597630435731,
            "fpr": 0.052689352360043906,
            "logloss": 0.6534304563917109,
            "mae": 0.4651330220712396,
            "precision": 0.7808219178082192,
            "recall": 0.3433734939759036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7279495841026365,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6662197288212806,
            "fpr": 0.13267543859649122,
            "logloss": 0.6336287426494039,
            "mae": 0.42461665695239054,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7906744848933972,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7159308258595884,
            "fpr": 0.11745334796926454,
            "logloss": 0.6030309724987718,
            "mae": 0.41372712663120287,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7557867302160076,
            "auditor_fn_violation": 0.014153393351800552,
            "auditor_fp_violation": 0.013319002000615573,
            "ave_precision_score": 0.7395199437538069,
            "fpr": 0.1524122807017544,
            "logloss": 0.628616816303889,
            "mae": 0.4288080909795928,
            "precision": 0.6958424507658644,
            "recall": 0.6973684210526315
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.809414824931359,
            "auditor_fn_violation": 0.010130533109385961,
            "auditor_fp_violation": 0.02148877188412808,
            "ave_precision_score": 0.7924744855116492,
            "fpr": 0.13062568605927552,
            "logloss": 0.5886095239048187,
            "mae": 0.41456858930305773,
            "precision": 0.7451820128479657,
            "recall": 0.6987951807228916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.824007097188395,
            "auditor_fn_violation": 0.013533010156971378,
            "auditor_fp_violation": 0.013872056786703606,
            "ave_precision_score": 0.824347543272945,
            "fpr": 0.23355263157894737,
            "logloss": 0.5741241948144483,
            "mae": 0.3487355345644817,
            "precision": 0.6547811993517018,
            "recall": 0.8859649122807017
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8561471974343163,
            "auditor_fn_violation": 0.009689691807846096,
            "auditor_fp_violation": 0.0195485364511765,
            "ave_precision_score": 0.8563542669591359,
            "fpr": 0.21185510428100987,
            "logloss": 0.5488765547928606,
            "mae": 0.3379298272896326,
            "precision": 0.6921850079744817,
            "recall": 0.8714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7186146385543775,
            "auditor_fn_violation": 0.01283568020929518,
            "auditor_fp_violation": 0.006194213604185906,
            "ave_precision_score": 0.7201729154242861,
            "fpr": 0.06798245614035088,
            "logloss": 0.6733556526389853,
            "mae": 0.4745238809274477,
            "precision": 0.6884422110552764,
            "recall": 0.30043859649122806
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7851901396074953,
            "auditor_fn_violation": 0.011023236745004163,
            "auditor_fp_violation": 0.0072479753776149985,
            "ave_precision_score": 0.7864133539991703,
            "fpr": 0.050493962678375415,
            "logloss": 0.6563722873761908,
            "mae": 0.4666078460988569,
            "precision": 0.7777777777777778,
            "recall": 0.3232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7709764924478492,
            "auditor_fn_violation": 0.044744536780547864,
            "auditor_fp_violation": 0.0835257002154509,
            "ave_precision_score": 0.7713421914769225,
            "fpr": 0.24561403508771928,
            "logloss": 0.7036781759900381,
            "mae": 0.35818914751162245,
            "precision": 0.6190476190476191,
            "recall": 0.7982456140350878
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8131570208666206,
            "auditor_fn_violation": 0.05580610036193071,
            "auditor_fp_violation": 0.07524658266067409,
            "ave_precision_score": 0.8134468149324446,
            "fpr": 0.20856201975850713,
            "logloss": 0.661230751435418,
            "mae": 0.3333889293050623,
            "precision": 0.6768707482993197,
            "recall": 0.7991967871485943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8189905125275048,
            "auditor_fn_violation": 0.018457602339181284,
            "auditor_fp_violation": 0.02126134964604494,
            "ave_precision_score": 0.8192643867494294,
            "fpr": 0.25219298245614036,
            "logloss": 0.6380135193076008,
            "mae": 0.352792674171995,
            "precision": 0.6450617283950617,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8312536606044238,
            "auditor_fn_violation": 0.014860760274908635,
            "auditor_fp_violation": 0.03282187309797127,
            "ave_precision_score": 0.8316004942132463,
            "fpr": 0.23929747530186607,
            "logloss": 0.6156677525936443,
            "mae": 0.33468323001050176,
            "precision": 0.6755952380952381,
            "recall": 0.9116465863453815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8354178672426198,
            "auditor_fn_violation": 0.00469615650969529,
            "auditor_fp_violation": 0.030547860880270852,
            "ave_precision_score": 0.8356508507307441,
            "fpr": 0.2719298245614035,
            "logloss": 0.6925261505172715,
            "mae": 0.3401301254201439,
            "precision": 0.6304023845007451,
            "recall": 0.9276315789473685
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8617032792762165,
            "auditor_fn_violation": 0.0019220680747137867,
            "auditor_fp_violation": 0.02912213649157593,
            "ave_precision_score": 0.8619534338758464,
            "fpr": 0.2623490669593853,
            "logloss": 0.6413647356587034,
            "mae": 0.320331227127506,
            "precision": 0.6609929078014184,
            "recall": 0.9357429718875502
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7117125188615336,
            "auditor_fn_violation": 0.01283568020929518,
            "auditor_fp_violation": 0.005578639581409665,
            "ave_precision_score": 0.7132897116737644,
            "fpr": 0.07675438596491228,
            "logloss": 0.6806788336197277,
            "mae": 0.4781497869509877,
            "precision": 0.6618357487922706,
            "recall": 0.30043859649122806
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7827734131678603,
            "auditor_fn_violation": 0.011479507492097921,
            "auditor_fp_violation": 0.004566197909329876,
            "ave_precision_score": 0.7839928500118993,
            "fpr": 0.054884742041712405,
            "logloss": 0.6593210465159884,
            "mae": 0.4681335675206064,
            "precision": 0.7641509433962265,
            "recall": 0.3253012048192771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8267748073433329,
            "auditor_fn_violation": 0.013629193598030163,
            "auditor_fp_violation": 0.012306671283471852,
            "ave_precision_score": 0.8270384504919965,
            "fpr": 0.2565789473684211,
            "logloss": 0.6247002030689935,
            "mae": 0.3480246354786431,
            "precision": 0.6432926829268293,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8351125327647808,
            "auditor_fn_violation": 0.007172487976053503,
            "auditor_fp_violation": 0.023700108706341375,
            "ave_precision_score": 0.8354490150099811,
            "fpr": 0.24478594950603733,
            "logloss": 0.6098786222055456,
            "mae": 0.33240916480391214,
            "precision": 0.6720588235294118,
            "recall": 0.9176706827309237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6772534322559913,
            "auditor_fn_violation": 0.0261426592797784,
            "auditor_fp_violation": 0.032534048938134816,
            "ave_precision_score": 0.6778381318266777,
            "fpr": 0.17653508771929824,
            "logloss": 0.6489990492294111,
            "mae": 0.45879229880959255,
            "precision": 0.631578947368421,
            "recall": 0.6052631578947368
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6760267453936672,
            "auditor_fn_violation": 0.04896424336203211,
            "auditor_fp_violation": 0.031043766927225224,
            "ave_precision_score": 0.6765940449542114,
            "fpr": 0.16355653128430298,
            "logloss": 0.6750687308835588,
            "mae": 0.4684045373735097,
            "precision": 0.6485849056603774,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.828933894448926,
            "auditor_fn_violation": 0.01578129809172053,
            "auditor_fp_violation": 0.01696675900277009,
            "ave_precision_score": 0.8294113570957072,
            "fpr": 0.22807017543859648,
            "logloss": 0.5818120074189624,
            "mae": 0.33424220282426287,
            "precision": 0.6617886178861788,
            "recall": 0.8925438596491229
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8615433275505029,
            "auditor_fn_violation": 0.0035487724773958654,
            "auditor_fp_violation": 0.014977022828331694,
            "ave_precision_score": 0.8617153110509146,
            "fpr": 0.2074643249176729,
            "logloss": 0.5583845952674173,
            "mae": 0.3282290964555591,
            "precision": 0.6980830670926518,
            "recall": 0.8775100401606426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7309965291263912,
            "auditor_fn_violation": 0.006492382271468152,
            "auditor_fp_violation": 0.009231205755617118,
            "ave_precision_score": 0.6718297526488568,
            "fpr": 0.13267543859649122,
            "logloss": 0.6276716290723433,
            "mae": 0.4217349630208653,
            "precision": 0.7139479905437353,
            "recall": 0.6622807017543859
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7906134014014613,
            "auditor_fn_violation": 0.00943400385295298,
            "auditor_fp_violation": 0.020165159218909056,
            "ave_precision_score": 0.7185251858571127,
            "fpr": 0.11745334796926454,
            "logloss": 0.6008217317028076,
            "mae": 0.4119391539159643,
            "precision": 0.7523148148148148,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7562575427125485,
            "auditor_fn_violation": 0.014153393351800552,
            "auditor_fp_violation": 0.013319002000615573,
            "ave_precision_score": 0.739000180886393,
            "fpr": 0.1524122807017544,
            "logloss": 0.6203424402507534,
            "mae": 0.42025845514185595,
            "precision": 0.6958424507658644,
            "recall": 0.6973684210526315
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8094179583184277,
            "auditor_fn_violation": 0.010130533109385961,
            "auditor_fp_violation": 0.02148877188412808,
            "ave_precision_score": 0.7920898230041832,
            "fpr": 0.13062568605927552,
            "logloss": 0.5852264949985306,
            "mae": 0.4070375961497933,
            "precision": 0.7451820128479657,
            "recall": 0.6987951807228916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7526679957816791,
            "auditor_fn_violation": 0.010118497999384435,
            "auditor_fp_violation": 0.018928901200369348,
            "ave_precision_score": 0.7356752022752574,
            "fpr": 0.15570175438596492,
            "logloss": 0.6349752205892757,
            "mae": 0.4269230776188666,
            "precision": 0.6899563318777293,
            "recall": 0.6929824561403509
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7994290599060571,
            "auditor_fn_violation": 0.010143758348432154,
            "auditor_fp_violation": 0.02338913946571763,
            "ave_precision_score": 0.7830602859114276,
            "fpr": 0.1350164654226125,
            "logloss": 0.5967570372187138,
            "mae": 0.41149942319877,
            "precision": 0.740506329113924,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7114017295644579,
            "auditor_fn_violation": 0.08411963296398893,
            "auditor_fp_violation": 0.102791243459526,
            "ave_precision_score": 0.7129129591065015,
            "fpr": 0.2949561403508772,
            "logloss": 0.6843853186715522,
            "mae": 0.49209102945761724,
            "precision": 0.5501672240802675,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7506646972736832,
            "auditor_fn_violation": 0.09199035439232231,
            "auditor_fp_violation": 0.09630212389333488,
            "ave_precision_score": 0.7518959839015831,
            "fpr": 0.27552140504939626,
            "logloss": 0.6808834917433458,
            "mae": 0.4905320960459934,
            "precision": 0.5925324675324676,
            "recall": 0.7329317269076305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6507922261340693,
            "auditor_fn_violation": 0.006636657433056327,
            "auditor_fp_violation": 0.02532269544475223,
            "ave_precision_score": 0.6445306625248746,
            "fpr": 0.24232456140350878,
            "logloss": 1.6237187870674712,
            "mae": 0.3700140257888849,
            "precision": 0.6446945337620579,
            "recall": 0.8793859649122807
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6991367241008127,
            "auditor_fn_violation": 0.0037449468565811037,
            "auditor_fp_violation": 0.0350305520634271,
            "ave_precision_score": 0.693253486949277,
            "fpr": 0.2349066959385291,
            "logloss": 1.425513855824378,
            "mae": 0.35914917326298196,
            "precision": 0.6692426584234931,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6516806882191581,
            "auditor_fn_violation": 0.011388119421360417,
            "auditor_fp_violation": 0.02618834641428133,
            "ave_precision_score": 0.6457573799470508,
            "fpr": 0.21820175438596492,
            "logloss": 1.5138931965887168,
            "mae": 0.36995543441183765,
            "precision": 0.6632825719120136,
            "recall": 0.8596491228070176
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.702633046708639,
            "auditor_fn_violation": 0.008536891804319364,
            "auditor_fp_violation": 0.03903062648341631,
            "ave_precision_score": 0.6970213054718615,
            "fpr": 0.21185510428100987,
            "logloss": 1.375071576761119,
            "mae": 0.3598301908528815,
            "precision": 0.6836065573770492,
            "recall": 0.8373493975903614
        }
    }
]