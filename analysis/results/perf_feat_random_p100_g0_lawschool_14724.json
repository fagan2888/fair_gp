[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8604950593537242,
            "auditor_fn_violation": 0.014899774895487196,
            "auditor_fp_violation": 0.022086094095095217,
            "ave_precision_score": 0.8607324524025457,
            "fpr": 0.11074561403508772,
            "logloss": 0.6725322019715245,
            "mae": 0.25843476499434986,
            "precision": 0.7926078028747433,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8211081369984287,
            "auditor_fn_violation": 0.009962232659147972,
            "auditor_fp_violation": 0.026971930374784386,
            "ave_precision_score": 0.8218931189787602,
            "fpr": 0.14489571899012074,
            "logloss": 0.741577969851518,
            "mae": 0.27756988276421096,
            "precision": 0.7278350515463917,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7675876400078206,
            "auditor_fn_violation": 0.00437703219351842,
            "auditor_fp_violation": 0.004878213943409604,
            "ave_precision_score": 0.5426262514337515,
            "fpr": 0.44627192982456143,
            "logloss": 0.6966453543864356,
            "mae": 0.4901160876217641,
            "precision": 0.5426966292134832,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7537285780633871,
            "auditor_fn_violation": 0.0020863314469419837,
            "auditor_fp_violation": 0.0021218833307197938,
            "ave_precision_score": 0.5116756815209971,
            "fpr": 0.4807903402854007,
            "logloss": 0.7092336418529651,
            "mae": 0.49647160301355053,
            "precision": 0.5117056856187291,
            "recall": 0.9913606911447084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8079257130162515,
            "auditor_fn_violation": 0.004289938185586166,
            "auditor_fp_violation": 0.006125765720715095,
            "ave_precision_score": 0.8036304318192071,
            "fpr": 0.12938596491228072,
            "logloss": 0.5513073247024582,
            "mae": 0.3231397516077809,
            "precision": 0.7601626016260162,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7847842618677442,
            "auditor_fn_violation": 0.003184026287776234,
            "auditor_fp_violation": 0.007921534420573945,
            "ave_precision_score": 0.7864348713742646,
            "fpr": 0.12623490669593854,
            "logloss": 0.5267021502555017,
            "mae": 0.3098000853427744,
            "precision": 0.7604166666666666,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7925298819800723,
            "auditor_fn_violation": 0.021364830099689144,
            "auditor_fp_violation": 0.028472309038629833,
            "ave_precision_score": 0.7770816908212966,
            "fpr": 0.26206140350877194,
            "logloss": 2.051899684220311,
            "mae": 0.33467167874329323,
            "precision": 0.6526162790697675,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7571885942556831,
            "auditor_fn_violation": 0.022864295993532378,
            "auditor_fp_violation": 0.042915457895562184,
            "ave_precision_score": 0.7397252158488741,
            "fpr": 0.28210757409440174,
            "logloss": 2.1450380158627778,
            "mae": 0.35844589539266813,
            "precision": 0.6146926536731634,
            "recall": 0.8855291576673866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7929512851423445,
            "auditor_fn_violation": 0.007974684675027691,
            "auditor_fp_violation": 0.01462161936908781,
            "ave_precision_score": 0.7932484675545481,
            "fpr": 0.23793859649122806,
            "logloss": 0.6061326108994305,
            "mae": 0.4030232760859163,
            "precision": 0.6303236797274276,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7736531320822271,
            "auditor_fn_violation": 0.010870261004805676,
            "auditor_fp_violation": 0.0182687784224557,
            "ave_precision_score": 0.7743691681940698,
            "fpr": 0.23710208562019758,
            "logloss": 0.6056578953381276,
            "mae": 0.4000216981582139,
            "precision": 0.6236933797909407,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 14724,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8642617086386328,
            "auditor_fn_violation": 0.010370886483009968,
            "auditor_fp_violation": 0.005794995207734304,
            "ave_precision_score": 0.8604458912894147,
            "fpr": 0.08771929824561403,
            "logloss": 0.5015001408769171,
            "mae": 0.3109761263864736,
            "precision": 0.8135198135198135,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8492617714119111,
            "auditor_fn_violation": 0.00814143430545315,
            "auditor_fp_violation": 0.009497020542574881,
            "ave_precision_score": 0.842492275270712,
            "fpr": 0.08122941822173436,
            "logloss": 0.4829829961781736,
            "mae": 0.30014042087046494,
            "precision": 0.8238095238095238,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.768030794329835,
            "auditor_fn_violation": 0.005944724336299005,
            "auditor_fp_violation": 0.0019689961245155647,
            "ave_precision_score": 0.5890147454824806,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6607452084510498,
            "mae": 0.4733214333914874,
            "precision": 0.9393939393939394,
            "recall": 0.12627291242362526
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7586928268828828,
            "auditor_fn_violation": 0.005761119790987525,
            "auditor_fp_violation": 0.0012251058491453662,
            "ave_precision_score": 0.5680780689607853,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6571137121244794,
            "mae": 0.4712397763352232,
            "precision": 0.9411764705882353,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8344467592395937,
            "auditor_fn_violation": 0.0034033658484296284,
            "auditor_fp_violation": 0.011902529482852022,
            "ave_precision_score": 0.8362249671852677,
            "fpr": 0.11074561403508772,
            "logloss": 0.5048172907055147,
            "mae": 0.32853729728601155,
            "precision": 0.7873684210526316,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8363211425741837,
            "auditor_fn_violation": 0.00633249010770686,
            "auditor_fp_violation": 0.013961306256860602,
            "ave_precision_score": 0.8356848839540594,
            "fpr": 0.11306256860592755,
            "logloss": 0.4914233203017897,
            "mae": 0.31963981708468775,
            "precision": 0.7765726681127982,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8308854714273632,
            "auditor_fn_violation": 0.021143745310322648,
            "auditor_fp_violation": 0.020708317706379965,
            "ave_precision_score": 0.8309129435878863,
            "fpr": 0.125,
            "logloss": 0.5158680576669546,
            "mae": 0.317550225698046,
            "precision": 0.7729083665338645,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.824849974245551,
            "auditor_fn_violation": 0.010189832453359826,
            "auditor_fp_violation": 0.024421259996863728,
            "ave_precision_score": 0.8260854566810618,
            "fpr": 0.12403951701427003,
            "logloss": 0.4900237568890862,
            "mae": 0.3059732835089663,
            "precision": 0.769857433808554,
            "recall": 0.816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.820787073598081,
            "auditor_fn_violation": 0.013039536213241864,
            "auditor_fp_violation": 0.0093709630370463,
            "ave_precision_score": 0.8213765373245897,
            "fpr": 0.12280701754385964,
            "logloss": 0.7524903534729007,
            "mae": 0.284530279504364,
            "precision": 0.7666666666666667,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7982263330087187,
            "auditor_fn_violation": 0.010012020114131815,
            "auditor_fp_violation": 0.011045554335894627,
            "ave_precision_score": 0.798574161377012,
            "fpr": 0.15367727771679474,
            "logloss": 0.7962847026480101,
            "mae": 0.29966584263261076,
            "precision": 0.7125256673511293,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7501732903651298,
            "auditor_fn_violation": 0.01086441919462608,
            "auditor_fp_violation": 0.026513730883027053,
            "ave_precision_score": 0.7431314367526496,
            "fpr": 0.1600877192982456,
            "logloss": 0.6104673683191245,
            "mae": 0.3942075579901013,
            "precision": 0.7085828343313373,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6956110708632699,
            "auditor_fn_violation": 0.010007278451752397,
            "auditor_fp_violation": 0.016122392974753024,
            "ave_precision_score": 0.6829986991231856,
            "fpr": 0.2074643249176729,
            "logloss": 0.6461184714815981,
            "mae": 0.4049199694066291,
            "precision": 0.6365384615384615,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8161841484299757,
            "auditor_fn_violation": 0.019701111230214036,
            "auditor_fp_violation": 0.008821415176897118,
            "ave_precision_score": 0.8168538941546993,
            "fpr": 0.10526315789473684,
            "logloss": 0.5618408423369171,
            "mae": 0.33931090321822777,
            "precision": 0.7793103448275862,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7904842795299809,
            "auditor_fn_violation": 0.00891432527329757,
            "auditor_fp_violation": 0.016347812450995765,
            "ave_precision_score": 0.7912371769565407,
            "fpr": 0.11086717892425905,
            "logloss": 0.5392266506319366,
            "mae": 0.3296990170171018,
            "precision": 0.764018691588785,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.5297872662366562,
            "auditor_fn_violation": 0.033426233608461094,
            "auditor_fp_violation": 0.029779764137183817,
            "ave_precision_score": 0.5169677917457338,
            "fpr": 0.06907894736842106,
            "logloss": 1.0677706669018452,
            "mae": 0.5312257626123539,
            "precision": 0.4424778761061947,
            "recall": 0.10183299389002037
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5263081198857094,
            "auditor_fn_violation": 0.04070954235845547,
            "auditor_fp_violation": 0.033215069782029163,
            "ave_precision_score": 0.4993318809758419,
            "fpr": 0.07354555433589462,
            "logloss": 1.0049648123476007,
            "mae": 0.5094025016542009,
            "precision": 0.4846153846153846,
            "recall": 0.13606911447084233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8328440173651339,
            "auditor_fn_violation": 0.010730428413191847,
            "auditor_fp_violation": 0.013670979705796558,
            "ave_precision_score": 0.8321623537930148,
            "fpr": 0.07017543859649122,
            "logloss": 0.520244729236646,
            "mae": 0.3251365775307804,
            "precision": 0.8383838383838383,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8372562892572306,
            "auditor_fn_violation": 0.006835106319924708,
            "auditor_fp_violation": 0.009073133918770583,
            "ave_precision_score": 0.8303541905840985,
            "fpr": 0.06915477497255763,
            "logloss": 0.49604186933810235,
            "mae": 0.31305744625734316,
            "precision": 0.8388746803069054,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8093494069886553,
            "auditor_fn_violation": 0.009294493872154933,
            "auditor_fp_violation": 0.005440784264699756,
            "ave_precision_score": 0.7792089973418337,
            "fpr": 0.041666666666666664,
            "logloss": 0.5662732410259069,
            "mae": 0.3690079066890149,
            "precision": 0.8527131782945736,
            "recall": 0.4480651731160896
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7821345291918858,
            "auditor_fn_violation": 0.0014580611816696928,
            "auditor_fp_violation": 0.007772071506978205,
            "ave_precision_score": 0.754444610823964,
            "fpr": 0.048298572996706916,
            "logloss": 0.5535695015488318,
            "mae": 0.3668159165628381,
            "precision": 0.8166666666666667,
            "recall": 0.42332613390928725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 14724,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5595910820411574,
            "auditor_fn_violation": 0.0006118912352163505,
            "auditor_fp_violation": 0.004078634829353682,
            "ave_precision_score": 0.5409057974938133,
            "fpr": 0.4550438596491228,
            "logloss": 0.6891504712905063,
            "mae": 0.496113386495333,
            "precision": 0.5414364640883977,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6080892338204559,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017004469186137825,
            "ave_precision_score": 0.5286854258471421,
            "fpr": 0.48518111964873767,
            "logloss": 0.6871480530339414,
            "mae": 0.49523901381620855,
            "precision": 0.5116022099447514,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8597770317856129,
            "auditor_fn_violation": 0.008854557473112513,
            "auditor_fp_violation": 5.208984456390329e-05,
            "ave_precision_score": 0.8599902851988072,
            "fpr": 0.06469298245614036,
            "logloss": 0.5261281502544697,
            "mae": 0.3389004963560422,
            "precision": 0.8418230563002681,
            "recall": 0.639511201629328
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8403963723491461,
            "auditor_fn_violation": 0.0069062312556159074,
            "auditor_fp_violation": 0.006963501646542262,
            "ave_precision_score": 0.8408039865179575,
            "fpr": 0.06476399560922064,
            "logloss": 0.5072296817649175,
            "mae": 0.3274961027759408,
            "precision": 0.8409703504043127,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6715661107906536,
            "auditor_fn_violation": 0.07210043948976311,
            "auditor_fp_violation": 0.06346626661666041,
            "ave_precision_score": 0.6036153593807032,
            "fpr": 0.2412280701754386,
            "logloss": 0.7448746377009346,
            "mae": 0.45905505068469465,
            "precision": 0.6021699819168174,
            "recall": 0.6782077393075356
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6406082661524144,
            "auditor_fn_violation": 0.0669854644339759,
            "auditor_fp_violation": 0.06288223302493336,
            "ave_precision_score": 0.5681647382820475,
            "fpr": 0.25466520307354557,
            "logloss": 0.7479043617630362,
            "mae": 0.4635736641323789,
            "precision": 0.5774134790528234,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8637056848335164,
            "auditor_fn_violation": 0.005484689320041451,
            "auditor_fp_violation": 0.001276201191815648,
            "ave_precision_score": 0.8642455859717344,
            "fpr": 0.08662280701754387,
            "logloss": 0.49296942252608233,
            "mae": 0.32073943208077954,
            "precision": 0.8154205607476636,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8493430127904906,
            "auditor_fn_violation": 0.0026885225691275134,
            "auditor_fp_violation": 0.01528687078563588,
            "ave_precision_score": 0.8497872315549879,
            "fpr": 0.07793633369923161,
            "logloss": 0.4808367874015778,
            "mae": 0.31069787180472397,
            "precision": 0.8255528255528255,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7139346248001094,
            "auditor_fn_violation": 0.025681566441562165,
            "auditor_fp_violation": 0.03248843605450682,
            "ave_precision_score": 0.6990807406052848,
            "fpr": 0.1787280701754386,
            "logloss": 0.6540514384308954,
            "mae": 0.42620552688624647,
            "precision": 0.6759443339960238,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6379016116600895,
            "auditor_fn_violation": 0.028677574070693445,
            "auditor_fp_violation": 0.03142641524227694,
            "ave_precision_score": 0.6268580379425035,
            "fpr": 0.21405049396267836,
            "logloss": 0.6753729478527414,
            "mae": 0.4391434466411103,
            "precision": 0.629277566539924,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 14724,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8668781153038669,
            "auditor_fn_violation": 0.008711633972916001,
            "auditor_fp_violation": 0.0067768887777638915,
            "ave_precision_score": 0.8671383328271155,
            "fpr": 0.10197368421052631,
            "logloss": 0.48712540059652654,
            "mae": 0.3211912469787262,
            "precision": 0.7956043956043956,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.848752339090165,
            "auditor_fn_violation": 0.004741662379413599,
            "auditor_fp_violation": 0.010638819193978365,
            "ave_precision_score": 0.849077261508226,
            "fpr": 0.09769484083424808,
            "logloss": 0.47932300301446695,
            "mae": 0.31156280638423106,
            "precision": 0.7981859410430839,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8190505610673307,
            "auditor_fn_violation": 0.009879586951084447,
            "auditor_fp_violation": 0.0002057548860274246,
            "ave_precision_score": 0.8140788198895195,
            "fpr": 0.06469298245614036,
            "logloss": 0.5361406590581723,
            "mae": 0.3494420663977699,
            "precision": 0.8422459893048129,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8090019722752395,
            "auditor_fn_violation": 0.0012802488424416717,
            "auditor_fp_violation": 0.005331660655480633,
            "ave_precision_score": 0.804390127649033,
            "fpr": 0.07025246981339188,
            "logloss": 0.5086666940270407,
            "mae": 0.3338372493909036,
            "precision": 0.8315789473684211,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5979431073562219,
            "auditor_fn_violation": 0.02375209918890914,
            "auditor_fp_violation": 0.04924573905071467,
            "ave_precision_score": 0.5990454338412949,
            "fpr": 0.27960526315789475,
            "logloss": 1.8294406645618977,
            "mae": 0.4617361303687106,
            "precision": 0.5764119601328903,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.5423577857299202,
            "auditor_fn_violation": 0.026420542778092575,
            "auditor_fp_violation": 0.04801434843970521,
            "ave_precision_score": 0.5434634932804983,
            "fpr": 0.29088913282107576,
            "logloss": 1.8321947904801816,
            "mae": 0.47398621722026174,
            "precision": 0.5399305555555556,
            "recall": 0.67170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8553960336573999,
            "auditor_fn_violation": 0.022521617179404735,
            "auditor_fp_violation": 0.007209234487644289,
            "ave_precision_score": 0.846987710502855,
            "fpr": 0.023026315789473683,
            "logloss": 0.6823348238833438,
            "mae": 0.3638845605912553,
            "precision": 0.9135802469135802,
            "recall": 0.45213849287169044
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.820572129793652,
            "auditor_fn_violation": 0.014601949297404179,
            "auditor_fp_violation": 0.008458130782499608,
            "ave_precision_score": 0.8082335931824697,
            "fpr": 0.029637760702524697,
            "logloss": 0.642232726439492,
            "mae": 0.35270777230511874,
            "precision": 0.8888888888888888,
            "recall": 0.46652267818574517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7407878604556262,
            "auditor_fn_violation": 0.04001411369564441,
            "auditor_fp_violation": 0.006336729591198902,
            "ave_precision_score": 0.7240988213345572,
            "fpr": 0.11074561403508772,
            "logloss": 4.033729915895034,
            "mae": 0.33847631225613034,
            "precision": 0.768348623853211,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7539924832936831,
            "auditor_fn_violation": 0.028163103702527073,
            "auditor_fp_violation": 0.010354594636976635,
            "ave_precision_score": 0.7346823544235995,
            "fpr": 0.10318331503841932,
            "logloss": 3.5576586006221462,
            "mae": 0.309297271497898,
            "precision": 0.7761904761904762,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6334408388095002,
            "auditor_fn_violation": 0.001136688462500448,
            "auditor_fp_violation": 0.0028180605909072206,
            "ave_precision_score": 0.6349244760296048,
            "fpr": 0.43859649122807015,
            "logloss": 1.507927327315753,
            "mae": 0.4512834769363205,
            "precision": 0.5391705069124424,
            "recall": 0.9531568228105907
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6626695633118644,
            "auditor_fn_violation": 0.003430592731505739,
            "auditor_fp_violation": 0.0019013642778736234,
            "ave_precision_score": 0.6644069533148239,
            "fpr": 0.4665203073545554,
            "logloss": 1.546516423125255,
            "mae": 0.47214062686940056,
            "precision": 0.5114942528735632,
            "recall": 0.9611231101511879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8034656631972712,
            "auditor_fn_violation": 0.04042725193839998,
            "auditor_fp_violation": 0.031410176272034004,
            "ave_precision_score": 0.7717488959193473,
            "fpr": 0.08114035087719298,
            "logloss": 0.5836744214167022,
            "mae": 0.36990271678721337,
            "precision": 0.7972602739726027,
            "recall": 0.5926680244399185
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8048186573532499,
            "auditor_fn_violation": 0.026588871792561763,
            "auditor_fp_violation": 0.021601066332131096,
            "ave_precision_score": 0.7716907004834181,
            "fpr": 0.08781558726673985,
            "logloss": 0.5469481771318899,
            "mae": 0.35246795983872614,
            "precision": 0.7855227882037533,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8290259608798393,
            "auditor_fn_violation": 0.00790098974523886,
            "auditor_fp_violation": 0.016077530524648918,
            "ave_precision_score": 0.8250434718223709,
            "fpr": 0.08662280701754387,
            "logloss": 0.558068505177685,
            "mae": 0.33372909369829457,
            "precision": 0.8068459657701712,
            "recall": 0.6720977596741344
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8232008069446077,
            "auditor_fn_violation": 0.011150019085191086,
            "auditor_fp_violation": 0.012405421828445978,
            "ave_precision_score": 0.8205494525110227,
            "fpr": 0.09769484083424808,
            "logloss": 0.5154173519635064,
            "mae": 0.32349381613433686,
            "precision": 0.7855421686746988,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8722217994093564,
            "auditor_fn_violation": 0.013845714081537864,
            "auditor_fp_violation": 0.014147601783556282,
            "ave_precision_score": 0.8724217933856605,
            "fpr": 0.12719298245614036,
            "logloss": 0.7223647781334029,
            "mae": 0.24303135596026754,
            "precision": 0.7738791423001949,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.840440662989828,
            "auditor_fn_violation": 0.0020649939662346285,
            "auditor_fp_violation": 0.009450466520307352,
            "ave_precision_score": 0.840892961099682,
            "fpr": 0.145993413830955,
            "logloss": 0.7870964529768129,
            "mae": 0.25848481225290726,
            "precision": 0.7392156862745098,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6319514620034663,
            "auditor_fn_violation": 0.01441964126201451,
            "auditor_fp_violation": 0.019291473934241785,
            "ave_precision_score": 0.5643919523826395,
            "fpr": 0.2949561403508772,
            "logloss": 6.527951440812974,
            "mae": 0.3959128416861809,
            "precision": 0.6026587887740029,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6024655167173144,
            "auditor_fn_violation": 0.01803017119772021,
            "auditor_fp_violation": 0.016671240395170137,
            "ave_precision_score": 0.5315372912979129,
            "fpr": 0.3227222832052689,
            "logloss": 6.835844244454109,
            "mae": 0.4186810876451926,
            "precision": 0.5670103092783505,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8561889914062806,
            "auditor_fn_violation": 0.019564887269089226,
            "auditor_fp_violation": 0.007141517689711215,
            "ave_precision_score": 0.8563772135659589,
            "fpr": 0.03728070175438596,
            "logloss": 0.541612233929107,
            "mae": 0.36370165689374534,
            "precision": 0.8877887788778878,
            "recall": 0.5478615071283096
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8354439716146305,
            "auditor_fn_violation": 0.009326849900306553,
            "auditor_fp_violation": 0.008472832052689352,
            "ave_precision_score": 0.8358381048287418,
            "fpr": 0.04610318331503842,
            "logloss": 0.5424157513906068,
            "mae": 0.36023583937064224,
            "precision": 0.8581081081081081,
            "recall": 0.5485961123110151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8272549092603594,
            "auditor_fn_violation": 0.002608353878586487,
            "auditor_fp_violation": 0.02336489977913906,
            "ave_precision_score": 0.8275954926631266,
            "fpr": 0.24890350877192982,
            "logloss": 0.779146246116696,
            "mae": 0.3419402625101308,
            "precision": 0.6642011834319527,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8051823145379366,
            "auditor_fn_violation": 0.0051612994999917046,
            "auditor_fp_violation": 0.024619727144425278,
            "ave_precision_score": 0.8057492575669403,
            "fpr": 0.2283205268935236,
            "logloss": 0.7486517107504269,
            "mae": 0.3302897308696507,
            "precision": 0.6719242902208202,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8348979210165729,
            "auditor_fn_violation": 0.012802819166041379,
            "auditor_fp_violation": 0.02906092428220194,
            "ave_precision_score": 0.8352679431969965,
            "fpr": 0.19736842105263158,
            "logloss": 0.5749790421378694,
            "mae": 0.32298101749875696,
            "precision": 0.7077922077922078,
            "recall": 0.8879837067209776
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.820534208277778,
            "auditor_fn_violation": 0.00667388979902464,
            "auditor_fp_violation": 0.022492943390308932,
            "ave_precision_score": 0.8208893141402618,
            "fpr": 0.21844127332601537,
            "logloss": 0.5967298978418111,
            "mae": 0.33177309024477897,
            "precision": 0.67430441898527,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 14724,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6567068446482968,
            "auditor_fn_violation": 0.003975059849215698,
            "auditor_fp_violation": 0.011464974788515237,
            "ave_precision_score": 0.6570662869078854,
            "fpr": 0.06359649122807018,
            "logloss": 0.7621045810899556,
            "mae": 0.47232265326831685,
            "precision": 0.6547619047619048,
            "recall": 0.2240325865580448
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5636709592289758,
            "auditor_fn_violation": 0.012003518313485529,
            "auditor_fp_violation": 0.017737082483926612,
            "ave_precision_score": 0.5629243719595409,
            "fpr": 0.10208562019758508,
            "logloss": 0.7849236677524642,
            "mae": 0.4817104213978404,
            "precision": 0.5255102040816326,
            "recall": 0.2224622030237581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7795913950204283,
            "auditor_fn_violation": 0.003485993496980741,
            "auditor_fp_violation": 0.005589240321706884,
            "ave_precision_score": 0.780896251990796,
            "fpr": 0.3717105263157895,
            "logloss": 0.7611075591233014,
            "mae": 0.41068505683276607,
            "precision": 0.5799256505576208,
            "recall": 0.9531568228105907
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7636820018167074,
            "auditor_fn_violation": 0.0021716813697714296,
            "auditor_fp_violation": 0.018660812294182223,
            "ave_precision_score": 0.7651803298366264,
            "fpr": 0.38638858397365533,
            "logloss": 0.7062649818068335,
            "mae": 0.41633142522330735,
            "precision": 0.5566750629722922,
            "recall": 0.9546436285097192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 14724,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7702481477193338,
            "auditor_fn_violation": 0.0006118912352163505,
            "auditor_fp_violation": 0.004078634829353682,
            "ave_precision_score": 0.541430233393681,
            "fpr": 0.4550438596491228,
            "logloss": 0.7223601597964934,
            "mae": 0.4851045966671224,
            "precision": 0.5414364640883977,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7558011049723756,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017004469186137825,
            "ave_precision_score": 0.5116022099447514,
            "fpr": 0.48518111964873767,
            "logloss": 0.7426098736736122,
            "mae": 0.4948488730368839,
            "precision": 0.5116022099447514,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8437990556307701,
            "auditor_fn_violation": 0.011523207203344417,
            "auditor_fp_violation": 0.013655352752427392,
            "ave_precision_score": 0.8426705909340523,
            "fpr": 0.07894736842105263,
            "logloss": 0.5049779622214965,
            "mae": 0.3314123485204682,
            "precision": 0.8265060240963855,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8328819992500858,
            "auditor_fn_violation": 0.004310171102886969,
            "auditor_fp_violation": 0.007362886153363651,
            "ave_precision_score": 0.8316436429070098,
            "fpr": 0.07793633369923161,
            "logloss": 0.4873440764586102,
            "mae": 0.32375848348917996,
            "precision": 0.8259803921568627,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7963326128800624,
            "auditor_fn_violation": 0.011572337156536968,
            "auditor_fp_violation": 0.027886298287285928,
            "ave_precision_score": 0.7968659422819031,
            "fpr": 0.31469298245614036,
            "logloss": 0.6166512329148325,
            "mae": 0.3879567265935373,
            "precision": 0.6152815013404825,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7762424240230178,
            "auditor_fn_violation": 0.005649690725071305,
            "auditor_fp_violation": 0.027305159165751918,
            "ave_precision_score": 0.7775213393496533,
            "fpr": 0.3380900109769484,
            "logloss": 0.6277806317493437,
            "mae": 0.3911491015641802,
            "precision": 0.585464333781965,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7111504457350444,
            "auditor_fn_violation": 0.01782300711044414,
            "auditor_fp_violation": 0.019544109680376717,
            "ave_precision_score": 0.6990306942759795,
            "fpr": 0.11293859649122807,
            "logloss": 4.779581024798224,
            "mae": 0.3483795139253845,
            "precision": 0.75,
            "recall": 0.6293279022403259
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7035911405213557,
            "auditor_fn_violation": 0.005260874409959387,
            "auditor_fp_violation": 0.009918456954680884,
            "ave_precision_score": 0.693299688664619,
            "fpr": 0.11855104281009879,
            "logloss": 4.389237654128059,
            "mae": 0.34481113814169995,
            "precision": 0.7320099255583127,
            "recall": 0.6371490280777538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.862647517885923,
            "auditor_fn_violation": 0.0023649372923142896,
            "auditor_fp_violation": 0.004398987373421685,
            "ave_precision_score": 0.8628571125035438,
            "fpr": 0.33114035087719296,
            "logloss": 0.6974585837193448,
            "mae": 0.3603992522265272,
            "precision": 0.6113256113256114,
            "recall": 0.9674134419551935
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.8471714134343276,
            "auditor_fn_violation": 0.0041963712057810345,
            "auditor_fp_violation": 0.018254077152265978,
            "ave_precision_score": 0.8475575496668832,
            "fpr": 0.3402854006586169,
            "logloss": 0.6963376441395207,
            "mae": 0.36056209100833575,
            "precision": 0.5888594164456233,
            "recall": 0.958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 14724,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6084924172392534,
            "auditor_fn_violation": 0.018160217243720314,
            "auditor_fp_violation": 0.01621296412051508,
            "ave_precision_score": 0.5881475636394248,
            "fpr": 0.20723684210526316,
            "logloss": 0.783099767855465,
            "mae": 0.49096044060659777,
            "precision": 0.5298507462686567,
            "recall": 0.43380855397148677
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5889952348903288,
            "auditor_fn_violation": 0.004710841573947436,
            "auditor_fp_violation": 0.0039791437980241555,
            "ave_precision_score": 0.5697298992513217,
            "fpr": 0.18441273326015367,
            "logloss": 0.7486036950221109,
            "mae": 0.47672773718130573,
            "precision": 0.5384615384615384,
            "recall": 0.42332613390928725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8200652001272255,
            "auditor_fn_violation": 0.02413620609568728,
            "auditor_fp_violation": 0.004862586990040427,
            "ave_precision_score": 0.8168197954630001,
            "fpr": 0.12390350877192982,
            "logloss": 0.5556662669589262,
            "mae": 0.3474630635476371,
            "precision": 0.7590618336886994,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8232412660761468,
            "auditor_fn_violation": 0.011481935451750037,
            "auditor_fp_violation": 0.009820448486749254,
            "ave_precision_score": 0.8179693487645481,
            "fpr": 0.1141602634467618,
            "logloss": 0.5071103512871472,
            "mae": 0.3252798354040533,
            "precision": 0.767337807606264,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8713048087395655,
            "auditor_fn_violation": 0.008660270840032874,
            "auditor_fp_violation": 0.011100345876567904,
            "ave_precision_score": 0.8715268274900532,
            "fpr": 0.2324561403508772,
            "logloss": 0.5680606347913371,
            "mae": 0.3139538395110305,
            "precision": 0.6792738275340393,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8601291654359536,
            "auditor_fn_violation": 0.004701358249188583,
            "auditor_fp_violation": 0.01951838638858398,
            "ave_precision_score": 0.8603536454498597,
            "fpr": 0.23819978046103182,
            "logloss": 0.5894078992315498,
            "mae": 0.32071951522188247,
            "precision": 0.6630434782608695,
            "recall": 0.9222462203023758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 14724,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.599865026155194,
            "auditor_fn_violation": 0.015947136170364813,
            "auditor_fp_violation": 0.018593470017085473,
            "ave_precision_score": 0.532448229410854,
            "fpr": 0.38706140350877194,
            "logloss": 0.6894404315640238,
            "mae": 0.4965958990679498,
            "precision": 0.5609452736318408,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5939065304723914,
            "auditor_fn_violation": 0.01622122699997392,
            "auditor_fp_violation": 0.021338893680413987,
            "ave_precision_score": 0.5311567928010534,
            "fpr": 0.40504939626783754,
            "logloss": 0.687957573377084,
            "mae": 0.4958965267687545,
            "precision": 0.5358490566037736,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7294080344028346,
            "auditor_fn_violation": 0.010571872655161326,
            "auditor_fp_violation": 0.0006042421969412847,
            "ave_precision_score": 0.6760817473451022,
            "fpr": 0.017543859649122806,
            "logloss": 0.8770340824842859,
            "mae": 0.44778415813976735,
            "precision": 0.8857142857142857,
            "recall": 0.2525458248472505
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6861958037589301,
            "auditor_fn_violation": 0.006176015249186212,
            "auditor_fp_violation": 0.0016955464952171874,
            "ave_precision_score": 0.6293640284658125,
            "fpr": 0.013172338090010977,
            "logloss": 0.8608546408381379,
            "mae": 0.44889414606515715,
            "precision": 0.8857142857142857,
            "recall": 0.20086393088552915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7383778881290214,
            "auditor_fn_violation": 0.021536784935863078,
            "auditor_fp_violation": 0.034124057173813394,
            "ave_precision_score": 0.5991422899091158,
            "fpr": 0.21271929824561403,
            "logloss": 0.7395120264551855,
            "mae": 0.4739001452792109,
            "precision": 0.6290630975143403,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7341350547111567,
            "auditor_fn_violation": 0.01231172636814741,
            "auditor_fp_violation": 0.014475850713501645,
            "ave_precision_score": 0.5855872356801199,
            "fpr": 0.21514818880351264,
            "logloss": 0.7064231978039469,
            "mae": 0.4590992122790423,
            "precision": 0.6201550387596899,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6976070051100706,
            "auditor_fn_violation": 0.022619877085789834,
            "auditor_fp_violation": 0.02735498187273409,
            "ave_precision_score": 0.6955233060831238,
            "fpr": 0.27631578947368424,
            "logloss": 1.1269411940907856,
            "mae": 0.3778857399570233,
            "precision": 0.6299559471365639,
            "recall": 0.8737270875763747
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6335167916495978,
            "auditor_fn_violation": 0.014632770102870367,
            "auditor_fp_violation": 0.03779206523443626,
            "ave_precision_score": 0.6287313542352957,
            "fpr": 0.31613611416026344,
            "logloss": 1.5070952480535205,
            "mae": 0.4010080121737282,
            "precision": 0.5844155844155844,
            "recall": 0.8747300215982722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8502760387515467,
            "auditor_fn_violation": 0.011737592453639189,
            "auditor_fp_violation": 0.008141642705338167,
            "ave_precision_score": 0.8066343417422006,
            "fpr": 0.06907894736842106,
            "logloss": 0.5121369415339594,
            "mae": 0.331175249364031,
            "precision": 0.8363636363636363,
            "recall": 0.6558044806517311
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8291089745813817,
            "auditor_fn_violation": 0.010905823472651278,
            "auditor_fp_violation": 0.009840050180335583,
            "ave_precision_score": 0.7839725144742397,
            "fpr": 0.07903402854006586,
            "logloss": 0.5265011973799728,
            "mae": 0.339116035141746,
            "precision": 0.8085106382978723,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8200654772937701,
            "auditor_fn_violation": 0.007295798049094239,
            "auditor_fp_violation": 0.005521523523773806,
            "ave_precision_score": 0.8031247872261409,
            "fpr": 0.03289473684210526,
            "logloss": 0.5722871787328815,
            "mae": 0.3947214527513113,
            "precision": 0.8770491803278688,
            "recall": 0.43584521384928715
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7642999170633349,
            "auditor_fn_violation": 0.005467136723463886,
            "auditor_fp_violation": 0.005868257017406305,
            "ave_precision_score": 0.7465508045560614,
            "fpr": 0.05159165751920966,
            "logloss": 0.5869592292102638,
            "mae": 0.4022111770023237,
            "precision": 0.7965367965367965,
            "recall": 0.39740820734341253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6914545135994823,
            "mae": 0.4989757811029752,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930639007772993,
            "mae": 0.4997802836049663,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7702750666226381,
            "auditor_fn_violation": 0.00039973916461214204,
            "auditor_fp_violation": 0.010712276534566832,
            "ave_precision_score": 0.5551916489946082,
            "fpr": 0.4166666666666667,
            "logloss": 0.682372218648228,
            "mae": 0.4909381279558466,
            "precision": 0.5555555555555556,
            "recall": 0.9674134419551935
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7549907514605229,
            "auditor_fn_violation": 0.0029753931430820334,
            "auditor_fp_violation": 0.00529245726830799,
            "ave_precision_score": 0.5254836993453067,
            "fpr": 0.4434687156970362,
            "logloss": 0.6853324725924963,
            "mae": 0.4923139635543007,
            "precision": 0.5258215962441315,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.4994109443044564,
            "auditor_fn_violation": 0.006958587915818058,
            "auditor_fp_violation": 0.013527732633245831,
            "ave_precision_score": 0.5020373869926682,
            "fpr": 0.41776315789473684,
            "logloss": 0.6940588901313334,
            "mae": 0.48745364139036257,
            "precision": 0.5528169014084507,
            "recall": 0.9592668024439919
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5078394276457329,
            "auditor_fn_violation": 0.0033144220032101063,
            "auditor_fp_violation": 0.012643092363180203,
            "ave_precision_score": 0.5068836914315049,
            "fpr": 0.4522502744237102,
            "logloss": 0.7044795073008138,
            "mae": 0.49220415889914226,
            "precision": 0.5203725261932479,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7767049928840821,
            "auditor_fn_violation": 0.07850966520170079,
            "auditor_fp_violation": 0.04759709547026712,
            "ave_precision_score": 0.6716486784788824,
            "fpr": 0.14364035087719298,
            "logloss": 0.6383224418073231,
            "mae": 0.41063736165105774,
            "precision": 0.7158351409978309,
            "recall": 0.6720977596741344
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7434350447127076,
            "auditor_fn_violation": 0.0736712083889491,
            "auditor_fp_violation": 0.05179747530186608,
            "ave_precision_score": 0.6236686797233376,
            "fpr": 0.1734357848518112,
            "logloss": 0.6665510791593251,
            "mae": 0.4231387973322434,
            "precision": 0.6609442060085837,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7859152642005798,
            "auditor_fn_violation": 0.0037718404973737804,
            "auditor_fp_violation": 4.4276367879318385e-05,
            "ave_precision_score": 0.7270008275237477,
            "fpr": 0.01425438596491228,
            "logloss": 0.7019203417834706,
            "mae": 0.4501845954443541,
            "precision": 0.934010152284264,
            "recall": 0.37474541751527496
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7242471101368353,
            "auditor_fn_violation": 0.0054552825675153495,
            "auditor_fp_violation": 0.0021610867178924256,
            "ave_precision_score": 0.6742644516609728,
            "fpr": 0.02305159165751921,
            "logloss": 0.6972154918237861,
            "mae": 0.4472914604811585,
            "precision": 0.8864864864864865,
            "recall": 0.3542116630669546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.6532778479586507,
            "auditor_fn_violation": 0.0048192017722514,
            "auditor_fp_violation": 0.002229445347335084,
            "ave_precision_score": 0.6549406074572528,
            "fpr": 0.02412280701754386,
            "logloss": 2.3984827318041484,
            "mae": 0.5131538313039049,
            "precision": 0.6140350877192983,
            "recall": 0.07128309572301425
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6423691750391927,
            "auditor_fn_violation": 0.0037530257733058643,
            "auditor_fp_violation": 0.002817743453034343,
            "ave_precision_score": 0.6439536871422926,
            "fpr": 0.02854006586169045,
            "logloss": 2.325226245102454,
            "mae": 0.47805302114540776,
            "precision": 0.6119402985074627,
            "recall": 0.08855291576673865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8558066088422743,
            "auditor_fn_violation": 0.010118537177975489,
            "auditor_fp_violation": 0.013751718964870615,
            "ave_precision_score": 0.8484100943000238,
            "fpr": 0.09868421052631579,
            "logloss": 0.5005389314051031,
            "mae": 0.31797005089914854,
            "precision": 0.8030634573304157,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8519489571081239,
            "auditor_fn_violation": 0.005938932130215536,
            "auditor_fp_violation": 0.012986122000940882,
            "ave_precision_score": 0.842155130024569,
            "fpr": 0.09549945115257959,
            "logloss": 0.48016092021450446,
            "mae": 0.3085215582781186,
            "precision": 0.8036117381489842,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7613615824183677,
            "auditor_fn_violation": 0.021742237467395585,
            "auditor_fp_violation": 0.013756927949326994,
            "ave_precision_score": 0.6234117498430393,
            "fpr": 0.1962719298245614,
            "logloss": 0.6575402825203076,
            "mae": 0.46356786382302906,
            "precision": 0.659047619047619,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7308083542918402,
            "auditor_fn_violation": 0.01597228972505471,
            "auditor_fp_violation": 0.006696428571428568,
            "ave_precision_score": 0.5751372269422119,
            "fpr": 0.24039517014270034,
            "logloss": 0.6818385526625161,
            "mae": 0.47430150457847,
            "precision": 0.6018181818181818,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.852099665200148,
            "auditor_fn_violation": 0.010125236717047202,
            "auditor_fp_violation": 0.012358315622786184,
            "ave_precision_score": 0.8523356984743158,
            "fpr": 0.12280701754385964,
            "logloss": 0.8820435269889007,
            "mae": 0.2625878676015451,
            "precision": 0.776,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8227500825989013,
            "auditor_fn_violation": 0.0022475479678420464,
            "auditor_fp_violation": 0.015424082640740163,
            "ave_precision_score": 0.8230559230067924,
            "fpr": 0.1525795828759605,
            "logloss": 1.0428647299796072,
            "mae": 0.2817176781741002,
            "precision": 0.7242063492063492,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.5535484754518579,
            "auditor_fn_violation": 0.02835468253117519,
            "auditor_fp_violation": 0.0588745468183523,
            "ave_precision_score": 0.5757285465081203,
            "fpr": 0.28289473684210525,
            "logloss": 0.699263913502733,
            "mae": 0.4964398553823693,
            "precision": 0.5924170616113744,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5350714656938023,
            "auditor_fn_violation": 0.026764313300600057,
            "auditor_fp_violation": 0.06129939626783755,
            "ave_precision_score": 0.5358869204143288,
            "fpr": 0.3150384193194292,
            "logloss": 0.7015726339612033,
            "mae": 0.496696792076762,
            "precision": 0.5529595015576324,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.8483763556182038,
            "auditor_fn_violation": 0.00265525065208847,
            "auditor_fp_violation": 0.01467370921365172,
            "ave_precision_score": 0.8485881027963311,
            "fpr": 0.3574561403508772,
            "logloss": 0.6876096593869507,
            "mae": 0.3710040173833345,
            "precision": 0.5914786967418546,
            "recall": 0.9613034623217923
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8378714354458163,
            "auditor_fn_violation": 0.00486731643246806,
            "auditor_fp_violation": 0.015825917359259842,
            "ave_precision_score": 0.83836881361103,
            "fpr": 0.3721185510428101,
            "logloss": 0.6813152032054448,
            "mae": 0.3735416612358371,
            "precision": 0.5664961636828645,
            "recall": 0.9568034557235421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5634009937708571,
            "auditor_fn_violation": 0.000788312430771439,
            "auditor_fp_violation": 0.013105804892278207,
            "ave_precision_score": 0.5450870967020177,
            "fpr": 0.17324561403508773,
            "logloss": 0.7384219369309889,
            "mae": 0.48813167089770504,
            "precision": 0.5406976744186046,
            "recall": 0.3788187372708758
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6026753076039533,
            "auditor_fn_violation": 0.009322108237927142,
            "auditor_fp_violation": 0.008154304531911563,
            "ave_precision_score": 0.5619111563198774,
            "fpr": 0.14050493962678376,
            "logloss": 0.708102009536923,
            "mae": 0.48265286823149367,
            "precision": 0.5910543130990416,
            "recall": 0.39956803455723544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8830822189524701,
            "auditor_fn_violation": 0.005728105906313652,
            "auditor_fp_violation": 0.0014428886944201388,
            "ave_precision_score": 0.8814768148163935,
            "fpr": 0.07236842105263158,
            "logloss": 0.47345775466397266,
            "mae": 0.309124098821102,
            "precision": 0.8401937046004843,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8365421542318874,
            "auditor_fn_violation": 0.005360449319927082,
            "auditor_fp_violation": 0.00823761172965344,
            "ave_precision_score": 0.8338537488960438,
            "fpr": 0.08122941822173436,
            "logloss": 0.48621397659298166,
            "mae": 0.31006696076427803,
            "precision": 0.8208232445520581,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7467424238775653,
            "auditor_fn_violation": 0.009774627505627617,
            "auditor_fp_violation": 0.0040057090469642065,
            "ave_precision_score": 0.7061593401251915,
            "fpr": 0.049342105263157895,
            "logloss": 9.596087548024686,
            "mae": 0.43155297474812176,
            "precision": 0.7761194029850746,
            "recall": 0.31771894093686354
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7339670948164544,
            "auditor_fn_violation": 0.010846552692908623,
            "auditor_fp_violation": 0.006267641524227693,
            "ave_precision_score": 0.6896830069596875,
            "fpr": 0.04939626783754116,
            "logloss": 8.732920132032097,
            "mae": 0.4045288103087317,
            "precision": 0.7704081632653061,
            "recall": 0.326133909287257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 14724,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7980701686030257,
            "auditor_fn_violation": 0.01372512237824705,
            "auditor_fp_violation": 0.005896570404633919,
            "ave_precision_score": 0.7960829990820197,
            "fpr": 0.13486842105263158,
            "logloss": 0.552508148170511,
            "mae": 0.3440797572170196,
            "precision": 0.7554671968190855,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8090893240775141,
            "auditor_fn_violation": 0.008065567707382535,
            "auditor_fp_violation": 0.013691782970048612,
            "ave_precision_score": 0.8047354821681285,
            "fpr": 0.12184412733260154,
            "logloss": 0.5032895711066065,
            "mae": 0.323200019506986,
            "precision": 0.7672955974842768,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 14724,
        "test": {
            "accuracy": 0.3519736842105263,
            "auc_prc": 0.5247473670327437,
            "auditor_fn_violation": 0.018216046735984568,
            "auditor_fp_violation": 0.020755198566487488,
            "ave_precision_score": 0.4778135222868967,
            "fpr": 0.3026315789473684,
            "logloss": 0.786227271541524,
            "mae": 0.5234529410505242,
            "precision": 0.3893805309734513,
            "recall": 0.35845213849287166
        },
        "train": {
            "accuracy": 0.38419319429198684,
            "auc_prc": 0.5135740622374934,
            "auditor_fn_violation": 0.01963048225077231,
            "auditor_fp_violation": 0.023473028069625222,
            "ave_precision_score": 0.46095392637650473,
            "fpr": 0.28210757409440174,
            "logloss": 0.7726387241958655,
            "mae": 0.5190651933003205,
            "precision": 0.38221153846153844,
            "recall": 0.3434125269978402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5197218254074423,
            "auditor_fn_violation": 0.006241737235144888,
            "auditor_fp_violation": 0.00830051673125809,
            "ave_precision_score": 0.5246123035479157,
            "fpr": 0.2883771929824561,
            "logloss": 0.6927234821347249,
            "mae": 0.49951998811019094,
            "precision": 0.5328596802841918,
            "recall": 0.6109979633401222
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5276256360513694,
            "auditor_fn_violation": 0.005004824641471057,
            "auditor_fp_violation": 0.004748510271287448,
            "ave_precision_score": 0.5302669534675923,
            "fpr": 0.30954994511525796,
            "logloss": 0.6926675466055585,
            "mae": 0.4994940314151584,
            "precision": 0.5095652173913043,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6222907225302224,
            "auditor_fn_violation": 0.04679181405652625,
            "auditor_fp_violation": 0.028995811976497067,
            "ave_precision_score": 0.6253014603567542,
            "fpr": 0.26535087719298245,
            "logloss": 0.6818993067741657,
            "mae": 0.4603747665522653,
            "precision": 0.6052202283849919,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5962403370866239,
            "auditor_fn_violation": 0.05080928322660641,
            "auditor_fp_violation": 0.03699329622079347,
            "ave_precision_score": 0.607809721838862,
            "fpr": 0.2864983534577388,
            "logloss": 0.6751218488567587,
            "mae": 0.4584706614343971,
            "precision": 0.5606060606060606,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7605044711202039,
            "auditor_fn_violation": 0.04438667952978169,
            "auditor_fp_violation": 0.0431746676667917,
            "ave_precision_score": 0.7663552386172459,
            "fpr": 0.2565789473684211,
            "logloss": 0.644805129243316,
            "mae": 0.3823951217917758,
            "precision": 0.6454545454545455,
            "recall": 0.8676171079429735
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7487656200301176,
            "auditor_fn_violation": 0.04213678273465895,
            "auditor_fp_violation": 0.05406147091108673,
            "ave_precision_score": 0.7373946452990071,
            "fpr": 0.27661909989023054,
            "logloss": 0.6813048226630877,
            "mae": 0.39714153308899813,
            "precision": 0.6050156739811913,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 14724,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7702505614553234,
            "auditor_fn_violation": 0.0006118912352163505,
            "auditor_fp_violation": 0.004078634829353682,
            "ave_precision_score": 0.5414362779980254,
            "fpr": 0.4550438596491228,
            "logloss": 15.726058392235572,
            "mae": 0.45614315484847257,
            "precision": 0.5414364640883977,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7560840707964602,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017004469186137825,
            "ave_precision_score": 0.5121681415929203,
            "fpr": 0.48518111964873767,
            "logloss": 16.738302225579233,
            "mae": 0.48518636027162587,
            "precision": 0.5116022099447514,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8190216221884322,
            "auditor_fn_violation": 0.006237270875763747,
            "auditor_fp_violation": 0.011001375171896494,
            "ave_precision_score": 0.823046799373531,
            "fpr": 0.07894736842105263,
            "logloss": 0.5550682013159849,
            "mae": 0.3542593140236772,
            "precision": 0.813953488372093,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7981880099962677,
            "auditor_fn_violation": 0.009350558212203623,
            "auditor_fp_violation": 0.004944527207150697,
            "ave_precision_score": 0.7949407625996044,
            "fpr": 0.08122941822173436,
            "logloss": 0.5452743769044697,
            "mae": 0.34522982785717454,
            "precision": 0.8107416879795396,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.742673105722262,
            "auditor_fn_violation": 0.00677770036088184,
            "auditor_fp_violation": 0.007076405384006352,
            "ave_precision_score": 0.5364134052679876,
            "fpr": 0.41885964912280704,
            "logloss": 16.142326401027084,
            "mae": 0.47247652016069386,
            "precision": 0.5358444714459295,
            "recall": 0.8981670061099797
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7348871956621892,
            "auditor_fn_violation": 0.0068611854630114795,
            "auditor_fp_violation": 0.004841618315822488,
            "ave_precision_score": 0.5089278798032947,
            "fpr": 0.4522502744237102,
            "logloss": 16.800729952723472,
            "mae": 0.48816067086733084,
            "precision": 0.5106888361045131,
            "recall": 0.9287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8484816682060148,
            "auditor_fn_violation": 0.007695537213706367,
            "auditor_fp_violation": 0.007680647580947622,
            "ave_precision_score": 0.7764095662578714,
            "fpr": 0.09429824561403509,
            "logloss": 0.541014501563299,
            "mae": 0.3501464684020009,
            "precision": 0.8027522935779816,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8315120442185941,
            "auditor_fn_violation": 0.006967872866548291,
            "auditor_fp_violation": 0.011457189901207468,
            "ave_precision_score": 0.75645420685742,
            "fpr": 0.09220636663007684,
            "logloss": 0.5229964960739323,
            "mae": 0.3414832971229511,
            "precision": 0.8028169014084507,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 14724,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7876987320905431,
            "auditor_fn_violation": 0.003921463536642012,
            "auditor_fp_violation": 0.007422802850356295,
            "ave_precision_score": 0.7881078971586779,
            "fpr": 0.0537280701754386,
            "logloss": 0.8238256118234845,
            "mae": 0.3871450458182218,
            "precision": 0.8143939393939394,
            "recall": 0.4378818737270876
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7723500957934515,
            "auditor_fn_violation": 0.00924387080866681,
            "auditor_fp_violation": 0.008901619099890234,
            "ave_precision_score": 0.7727970797891479,
            "fpr": 0.05598243688254665,
            "logloss": 0.77467616991958,
            "mae": 0.37104926799376986,
            "precision": 0.8097014925373134,
            "recall": 0.468682505399568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7795717053880121,
            "auditor_fn_violation": 0.00814440633151107,
            "auditor_fp_violation": 0.009503792140684256,
            "ave_precision_score": 0.7603691685584214,
            "fpr": 0.09320175438596491,
            "logloss": 0.5762800596334765,
            "mae": 0.3638101197664806,
            "precision": 0.805045871559633,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.7790979303712635,
            "auditor_fn_violation": 0.004876799757226884,
            "auditor_fp_violation": 0.00859534263760389,
            "ave_precision_score": 0.7626451280653777,
            "fpr": 0.09001097694840834,
            "logloss": 0.5272993977331143,
            "mae": 0.34325595289207056,
            "precision": 0.8079625292740047,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8060410115921601,
            "auditor_fn_violation": 0.0076933040340157926,
            "auditor_fp_violation": 0.017713151643955496,
            "ave_precision_score": 0.8047344132338654,
            "fpr": 0.11513157894736842,
            "logloss": 0.9118993483049477,
            "mae": 0.2800379646209781,
            "precision": 0.7737068965517241,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7729259947332231,
            "auditor_fn_violation": 0.007726538847254462,
            "auditor_fp_violation": 0.007056609691077312,
            "ave_precision_score": 0.7724120206018708,
            "fpr": 0.15477497255762898,
            "logloss": 0.9745982352430811,
            "mae": 0.3057425803391969,
            "precision": 0.7080745341614907,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8510077688573572,
            "auditor_fn_violation": 0.007559313252581558,
            "auditor_fp_violation": 0.00568300204192191,
            "ave_precision_score": 0.845830309690121,
            "fpr": 0.1118421052631579,
            "logloss": 0.5304970374166019,
            "mae": 0.324391618704938,
            "precision": 0.7825159914712153,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.836919373337324,
            "auditor_fn_violation": 0.008736512934069558,
            "auditor_fp_violation": 0.009041281166692805,
            "ave_precision_score": 0.830362160480343,
            "fpr": 0.10318331503841932,
            "logloss": 0.49462164371318673,
            "mae": 0.3062180789488109,
            "precision": 0.7887640449438202,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7375247323754591,
            "auditor_fn_violation": 0.09366848894129418,
            "auditor_fp_violation": 0.10493499187398425,
            "ave_precision_score": 0.5775853187913834,
            "fpr": 0.27960526315789475,
            "logloss": 0.6835414796722372,
            "mae": 0.4935687938214917,
            "precision": 0.5906902086677368,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7031954119223229,
            "auditor_fn_violation": 0.09436856467508944,
            "auditor_fp_violation": 0.10233554179081074,
            "ave_precision_score": 0.5300974987392258,
            "fpr": 0.3194291986827662,
            "logloss": 0.6890896828072931,
            "mae": 0.49635649993443204,
            "precision": 0.5380952380952381,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.823926850111192,
            "auditor_fn_violation": 0.015862275342123127,
            "auditor_fp_violation": 0.014275221902737844,
            "ave_precision_score": 0.8214629742377186,
            "fpr": 0.12390350877192982,
            "logloss": 0.9749602525355838,
            "mae": 0.264798980057605,
            "precision": 0.7775590551181102,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7950499810119428,
            "auditor_fn_violation": 0.001147482295818094,
            "auditor_fp_violation": 0.015426532852438453,
            "ave_precision_score": 0.7907850140280596,
            "fpr": 0.15697036223929747,
            "logloss": 1.1198622765978279,
            "mae": 0.281921203096318,
            "precision": 0.7212475633528265,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8672886884690298,
            "auditor_fn_violation": 0.013115464322721265,
            "auditor_fp_violation": 0.017720965120640083,
            "ave_precision_score": 0.8673541527089181,
            "fpr": 0.1337719298245614,
            "logloss": 0.5058456552273825,
            "mae": 0.3350787245704739,
            "precision": 0.7607843137254902,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8244901620363833,
            "auditor_fn_violation": 0.013243463025702182,
            "auditor_fp_violation": 0.016524227693272706,
            "ave_precision_score": 0.8248706887960173,
            "fpr": 0.1734357848518112,
            "logloss": 0.5553105902332505,
            "mae": 0.3492681326675315,
            "precision": 0.694980694980695,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.695635759397796,
            "auditor_fn_violation": 0.01911601815128454,
            "auditor_fp_violation": 0.009889256990457139,
            "ave_precision_score": 0.6972865762803513,
            "fpr": 0.10964912280701754,
            "logloss": 0.6652147726512224,
            "mae": 0.44479033081351144,
            "precision": 0.6996996996996997,
            "recall": 0.4745417515274949
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6343296202674711,
            "auditor_fn_violation": 0.010405578091623164,
            "auditor_fp_violation": 0.014360690763681986,
            "ave_precision_score": 0.6357551401607535,
            "fpr": 0.13721185510428102,
            "logloss": 0.6865552219974271,
            "mae": 0.45697528143483906,
            "precision": 0.6118012422360248,
            "recall": 0.42548596112311016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7548928142317748,
            "auditor_fn_violation": 0.0955220280844678,
            "auditor_fp_violation": 0.10125223986331625,
            "ave_precision_score": 0.6830548746771326,
            "fpr": 0.1787280701754386,
            "logloss": 0.6283705323309438,
            "mae": 0.44243220310492787,
            "precision": 0.6561181434599156,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7327567973927703,
            "auditor_fn_violation": 0.09146192563650891,
            "auditor_fp_violation": 0.10865218754900424,
            "ave_precision_score": 0.6514358839397629,
            "fpr": 0.19099890230515917,
            "logloss": 0.6256412112463746,
            "mae": 0.444116346956702,
            "precision": 0.6336842105263157,
            "recall": 0.6501079913606912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8589807329213475,
            "auditor_fn_violation": 0.00977239432593705,
            "auditor_fp_violation": 0.0002057548860274246,
            "ave_precision_score": 0.8434835862125379,
            "fpr": 0.06469298245614036,
            "logloss": 0.5125585082714975,
            "mae": 0.3446607038035597,
            "precision": 0.8418230563002681,
            "recall": 0.639511201629328
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.830757818073191,
            "auditor_fn_violation": 0.0029611681559438023,
            "auditor_fp_violation": 0.005331660655480633,
            "ave_precision_score": 0.8114364098517549,
            "fpr": 0.07025246981339188,
            "logloss": 0.5091333173278313,
            "mae": 0.34008183309033463,
            "precision": 0.830238726790451,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8386781106746343,
            "auditor_fn_violation": 0.005810733554864762,
            "auditor_fp_violation": 0.010339834145934909,
            "ave_precision_score": 0.8263523462443431,
            "fpr": 0.0800438596491228,
            "logloss": 0.5291755183348351,
            "mae": 0.3379896200838115,
            "precision": 0.8245192307692307,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8177450689302579,
            "auditor_fn_violation": 0.009085025118956461,
            "auditor_fp_violation": 0.005067037792065236,
            "ave_precision_score": 0.8008268917713081,
            "fpr": 0.08122941822173436,
            "logloss": 0.533543367565499,
            "mae": 0.34335441800278055,
            "precision": 0.8102564102564103,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.820218941510421,
            "auditor_fn_violation": 0.0005404294851180905,
            "auditor_fp_violation": 0.0025654248447722922,
            "ave_precision_score": 0.8179397482982459,
            "fpr": 0.45394736842105265,
            "logloss": 3.473561648390359,
            "mae": 0.45299589438968474,
            "precision": 0.5420353982300885,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7895301037209213,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002109632272228316,
            "ave_precision_score": 0.7836402072254125,
            "fpr": 0.4818880351262349,
            "logloss": 3.7577077443679414,
            "mae": 0.4788059860301275,
            "precision": 0.5133037694013304,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7156800332399262,
            "auditor_fn_violation": 0.014203022832029162,
            "auditor_fp_violation": 0.00576374130099596,
            "ave_precision_score": 0.7238439271565147,
            "fpr": 0.08333333333333333,
            "logloss": 0.6606645637645079,
            "mae": 0.3912947668138434,
            "precision": 0.7710843373493976,
            "recall": 0.5213849287169042
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7420503101084128,
            "auditor_fn_violation": 0.03244956649351696,
            "auditor_fp_violation": 0.00919319429198683,
            "ave_precision_score": 0.7404171926953378,
            "fpr": 0.08342480790340286,
            "logloss": 0.6141352763456448,
            "mae": 0.37684454619434676,
            "precision": 0.7724550898203593,
            "recall": 0.5572354211663066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8094029583570993,
            "auditor_fn_violation": 0.0064918533604888,
            "auditor_fp_violation": 0.00960276284535567,
            "ave_precision_score": 0.7598856643222105,
            "fpr": 0.19298245614035087,
            "logloss": 2.8913204266617036,
            "mae": 0.3056650917258179,
            "precision": 0.7147487844408428,
            "recall": 0.8981670061099797
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.779502127434836,
            "auditor_fn_violation": 0.009720407877797878,
            "auditor_fp_violation": 0.017925748784694998,
            "ave_precision_score": 0.7257763290130749,
            "fpr": 0.21624588364434688,
            "logloss": 3.123557434505549,
            "mae": 0.3258940458673939,
            "precision": 0.6749174917491749,
            "recall": 0.8833693304535637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7684221404906424,
            "auditor_fn_violation": 0.064902901347054,
            "auditor_fp_violation": 0.01335844063841314,
            "ave_precision_score": 0.7420574432365401,
            "fpr": 0.16337719298245615,
            "logloss": 4.5879105496084245,
            "mae": 0.3414074439636206,
            "precision": 0.7145593869731801,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7215026050666964,
            "auditor_fn_violation": 0.05881083849186687,
            "auditor_fp_violation": 0.025391543829386864,
            "ave_precision_score": 0.6944337756624197,
            "fpr": 0.2030735455543359,
            "logloss": 4.942215586909542,
            "mae": 0.36746833769181714,
            "precision": 0.6482889733840305,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8709351372904315,
            "auditor_fn_violation": 0.014602761996641303,
            "auditor_fp_violation": 0.009740800933450016,
            "ave_precision_score": 0.8655530806366291,
            "fpr": 0.09649122807017543,
            "logloss": 0.494907040713173,
            "mae": 0.3102968729748554,
            "precision": 0.8074398249452954,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.841919911168043,
            "auditor_fn_violation": 0.012385222135028323,
            "auditor_fp_violation": 0.012216755527677592,
            "ave_precision_score": 0.828594453267147,
            "fpr": 0.09440175631174534,
            "logloss": 0.48867314445696625,
            "mae": 0.30973043088503716,
            "precision": 0.8022988505747126,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7994029607495801,
            "auditor_fn_violation": 0.007695537213706367,
            "auditor_fp_violation": 0.006990457140475897,
            "ave_precision_score": 0.7993873564407313,
            "fpr": 0.09649122807017543,
            "logloss": 0.5423910706157807,
            "mae": 0.35974387522264006,
            "precision": 0.7990867579908676,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8015437054856185,
            "auditor_fn_violation": 0.007707572197736812,
            "auditor_fp_violation": 0.011457189901207468,
            "ave_precision_score": 0.8018539392522419,
            "fpr": 0.09220636663007684,
            "logloss": 0.5266394651549084,
            "mae": 0.34825775421477045,
            "precision": 0.8032786885245902,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.8023451865955836,
            "auditor_fn_violation": 0.006058616500518096,
            "auditor_fp_violation": 0.006555506938367296,
            "ave_precision_score": 0.7804535986455503,
            "fpr": 0.13267543859649122,
            "logloss": 0.6760324038168769,
            "mae": 0.39609806815835263,
            "precision": 0.7019704433497537,
            "recall": 0.5804480651731161
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7803122000073615,
            "auditor_fn_violation": 0.010099740868150965,
            "auditor_fp_violation": 0.010325192096597147,
            "ave_precision_score": 0.7508256811348485,
            "fpr": 0.13721185510428102,
            "logloss": 0.6462279666697816,
            "mae": 0.39665199638524273,
            "precision": 0.6890547263681592,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8486352970734555,
            "auditor_fn_violation": 0.008101975917390224,
            "auditor_fp_violation": 0.008954244280535073,
            "ave_precision_score": 0.8472085857897639,
            "fpr": 0.09429824561403509,
            "logloss": 0.5106272914428879,
            "mae": 0.3193897974857113,
            "precision": 0.8041002277904328,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8303607822626711,
            "auditor_fn_violation": 0.005927077974266998,
            "auditor_fp_violation": 0.009021679473106475,
            "ave_precision_score": 0.8337818973892205,
            "fpr": 0.0845225027442371,
            "logloss": 0.49049234683435156,
            "mae": 0.31007714405999354,
            "precision": 0.8183962264150944,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8263470521260661,
            "auditor_fn_violation": 0.007592810947940121,
            "auditor_fp_violation": 0.0066518731508105194,
            "ave_precision_score": 0.8266737503972548,
            "fpr": 0.08442982456140351,
            "logloss": 0.5853032796734983,
            "mae": 0.35542413488994434,
            "precision": 0.8135593220338984,
            "recall": 0.6843177189409368
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8056143956081243,
            "auditor_fn_violation": 0.011621814491942727,
            "auditor_fp_violation": 0.012280461031833154,
            "ave_precision_score": 0.8061174774877746,
            "fpr": 0.0845225027442371,
            "logloss": 0.6019946754249434,
            "mae": 0.3450679099463278,
            "precision": 0.8117359413202934,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8324050338594027,
            "auditor_fn_violation": 0.007065780540965455,
            "auditor_fp_violation": 0.0030368379380755935,
            "ave_precision_score": 0.7280674216495719,
            "fpr": 0.09868421052631579,
            "logloss": 0.5602106821226838,
            "mae": 0.3595481158087128,
            "precision": 0.7949886104783599,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.837274886905224,
            "auditor_fn_violation": 0.006967872866548291,
            "auditor_fp_violation": 0.0073163321310961305,
            "ave_precision_score": 0.7304335974189404,
            "fpr": 0.09549945115257959,
            "logloss": 0.5310890672260536,
            "mae": 0.3464381476919423,
            "precision": 0.7972027972027972,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7792653837677148,
            "auditor_fn_violation": 0.0033051059420445205,
            "auditor_fp_violation": 0.012655227736800443,
            "ave_precision_score": 0.7795837589800155,
            "fpr": 0.41118421052631576,
            "logloss": 0.8888459060642048,
            "mae": 0.41219020702888537,
            "precision": 0.5608899297423887,
            "recall": 0.9755600814663951
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7679865822404852,
            "auditor_fn_violation": 0.0033831761077116025,
            "auditor_fp_violation": 0.023088344832993574,
            "ave_precision_score": 0.768521812788093,
            "fpr": 0.41602634467618005,
            "logloss": 0.8901022597791903,
            "mae": 0.41064312080907167,
            "precision": 0.5450180072028812,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7455314932273486,
            "auditor_fn_violation": 0.008825526137135106,
            "auditor_fp_violation": 0.014564320540067505,
            "ave_precision_score": 0.7172841042159466,
            "fpr": 0.09320175438596491,
            "logloss": 0.588023551662375,
            "mae": 0.3936046024849802,
            "precision": 0.7911547911547911,
            "recall": 0.6558044806517311
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.6830708407614974,
            "auditor_fn_violation": 0.006047990364942046,
            "auditor_fp_violation": 0.010371746118864671,
            "ave_precision_score": 0.7019377919525731,
            "fpr": 0.10647639956092206,
            "logloss": 0.5804461732026515,
            "mae": 0.388561743862608,
            "precision": 0.7657004830917874,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 14724,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8429668837914055,
            "auditor_fn_violation": 0.027861149819559086,
            "auditor_fp_violation": 0.01905967412593241,
            "ave_precision_score": 0.8423769596236382,
            "fpr": 0.10855263157894737,
            "logloss": 2.840831275417916,
            "mae": 0.3121687452751108,
            "precision": 0.7824175824175824,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8101959488026533,
            "auditor_fn_violation": 0.02347359960928703,
            "auditor_fp_violation": 0.024698133918770585,
            "ave_precision_score": 0.8099935516990124,
            "fpr": 0.12294182217343579,
            "logloss": 2.7501615047189194,
            "mae": 0.31116662426011105,
            "precision": 0.7471783295711061,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8412226384980855,
            "auditor_fn_violation": 0.017465698359952837,
            "auditor_fp_violation": 0.008800579239071555,
            "ave_precision_score": 0.8384358103205641,
            "fpr": 0.08662280701754387,
            "logloss": 0.5415067960243508,
            "mae": 0.33641920860023483,
            "precision": 0.8167053364269141,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8268144464278319,
            "auditor_fn_violation": 0.011403698022489707,
            "auditor_fp_violation": 0.008438529088913281,
            "ave_precision_score": 0.8262588108670967,
            "fpr": 0.07683863885839737,
            "logloss": 0.5115686524524231,
            "mae": 0.3241227463738324,
            "precision": 0.8258706467661692,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8278297026511432,
            "auditor_fn_violation": 0.016116857826848182,
            "auditor_fp_violation": 0.02236477476351211,
            "ave_precision_score": 0.8243453325717324,
            "fpr": 0.14144736842105263,
            "logloss": 0.5287279275337955,
            "mae": 0.35602996287573324,
            "precision": 0.7528735632183908,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8085854773967065,
            "auditor_fn_violation": 0.011688197765254522,
            "auditor_fp_violation": 0.020777795201505418,
            "ave_precision_score": 0.8027976169448918,
            "fpr": 0.1756311745334797,
            "logloss": 0.545688747625046,
            "mae": 0.36536360390557937,
            "precision": 0.6981132075471698,
            "recall": 0.7991360691144709
        }
    }
]