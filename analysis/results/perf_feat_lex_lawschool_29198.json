[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8039194646805615,
            "auditor_fn_violation": 0.013819530168705347,
            "auditor_fp_violation": 0.02198180270088313,
            "ave_precision_score": 0.7916671088445276,
            "fpr": 0.2236842105263158,
            "logloss": 1.431435088517359,
            "mae": 0.30296074214192215,
            "precision": 0.6714975845410628,
            "recall": 0.8891257995735607
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8103292240116095,
            "auditor_fn_violation": 0.00976608915092738,
            "auditor_fp_violation": 0.015336806790247529,
            "ave_precision_score": 0.7998006171156746,
            "fpr": 0.21405049396267836,
            "logloss": 1.3759550441909236,
            "mae": 0.2876488430367165,
            "precision": 0.6953125,
            "recall": 0.9175257731958762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.5865058658966288,
            "auditor_fn_violation": 0.0029200800508734524,
            "auditor_fp_violation": 0.01724931685873826,
            "ave_precision_score": 0.5728365609069176,
            "fpr": 0.32894736842105265,
            "logloss": 2.7744384608184376,
            "mae": 0.4061857413988579,
            "precision": 0.5827538247566064,
            "recall": 0.8933901918976546
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6292031790828074,
            "auditor_fn_violation": 0.005653694252379283,
            "auditor_fp_violation": 0.011688130981277361,
            "ave_precision_score": 0.6186291215842238,
            "fpr": 0.3029637760702525,
            "logloss": 2.2765132727288986,
            "mae": 0.37922716319669336,
            "precision": 0.6155988857938719,
            "recall": 0.911340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8031182769752656,
            "auditor_fn_violation": 0.013026970411102382,
            "auditor_fp_violation": 0.021546176389053893,
            "ave_precision_score": 0.7909663467767944,
            "fpr": 0.2225877192982456,
            "logloss": 1.4267262908785772,
            "mae": 0.30410818403191847,
            "precision": 0.6704545454545454,
            "recall": 0.8805970149253731
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8097279471285146,
            "auditor_fn_violation": 0.010626138716941846,
            "auditor_fp_violation": 0.01286312827569148,
            "ave_precision_score": 0.7992160972554713,
            "fpr": 0.21514818880351264,
            "logloss": 1.3724221606209093,
            "mae": 0.2888230440831872,
            "precision": 0.6951788491446346,
            "recall": 0.9216494845360824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8423017927356151,
            "auditor_fn_violation": 0.008222515243332212,
            "auditor_fp_violation": 0.013311354005781954,
            "ave_precision_score": 0.842622420694029,
            "fpr": 0.15789473684210525,
            "logloss": 0.5399784624355337,
            "mae": 0.3239589152688952,
            "precision": 0.7323420074349443,
            "recall": 0.8400852878464818
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.874448318456224,
            "auditor_fn_violation": 0.0022881845032647987,
            "auditor_fp_violation": 0.014141195508212101,
            "ave_precision_score": 0.8746455823237798,
            "fpr": 0.14270032930845225,
            "logloss": 0.4807760793021931,
            "mae": 0.3083377312222541,
            "precision": 0.7560975609756098,
            "recall": 0.8309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8069757859702549,
            "auditor_fn_violation": 0.012800190775446078,
            "auditor_fp_violation": 0.030058215516217193,
            "ave_precision_score": 0.8034321865662089,
            "fpr": 0.2982456140350877,
            "logloss": 1.3723663450093382,
            "mae": 0.33948431118135075,
            "precision": 0.6190476190476191,
            "recall": 0.9424307036247335
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8157356292378637,
            "auditor_fn_violation": 0.007600122217569907,
            "auditor_fp_violation": 0.0371180614606041,
            "ave_precision_score": 0.8131389661822269,
            "fpr": 0.28210757409440174,
            "logloss": 1.320242993302691,
            "mae": 0.32141230710861085,
            "precision": 0.6430555555555556,
            "recall": 0.954639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8379465659131846,
            "auditor_fn_violation": 0.019961283806531258,
            "auditor_fp_violation": 0.030818086412419326,
            "ave_precision_score": 0.8383391840800394,
            "fpr": 0.1513157894736842,
            "logloss": 0.7020511512164149,
            "mae": 0.2675315835791466,
            "precision": 0.7283464566929134,
            "recall": 0.7889125799573561
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8396741799854501,
            "auditor_fn_violation": 0.01695202960381138,
            "auditor_fp_violation": 0.019366841370211763,
            "ave_precision_score": 0.8400210132996899,
            "fpr": 0.13721185510428102,
            "logloss": 0.7051289182492977,
            "mae": 0.26301035422489516,
            "precision": 0.7572815533980582,
            "recall": 0.8041237113402062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8460124181810054,
            "auditor_fn_violation": 0.02617785134477986,
            "auditor_fp_violation": 0.009744663577680094,
            "ave_precision_score": 0.8464018871942154,
            "fpr": 0.07346491228070176,
            "logloss": 0.5214059376865477,
            "mae": 0.31747779402867493,
            "precision": 0.8203753351206434,
            "recall": 0.652452025586354
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8691546762919583,
            "auditor_fn_violation": 0.017800762728167753,
            "auditor_fp_violation": 0.008766098235958013,
            "ave_precision_score": 0.8693679784866515,
            "fpr": 0.05598243688254665,
            "logloss": 0.49554373024499043,
            "mae": 0.3090873285755231,
            "precision": 0.8636363636363636,
            "recall": 0.6659793814432989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8276911457295683,
            "auditor_fn_violation": 0.018128343246175137,
            "auditor_fp_violation": 0.02789988515306325,
            "ave_precision_score": 0.8280970903603166,
            "fpr": 0.15899122807017543,
            "logloss": 0.7001132334870834,
            "mae": 0.27485830988988186,
            "precision": 0.7195357833655706,
            "recall": 0.7931769722814499
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8370658659525072,
            "auditor_fn_violation": 0.0006721966344902548,
            "auditor_fp_violation": 0.012986812201419272,
            "ave_precision_score": 0.8373613598223754,
            "fpr": 0.132821075740944,
            "logloss": 0.6726655749577749,
            "mae": 0.26308910401987756,
            "precision": 0.766859344894027,
            "recall": 0.8206185567010309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 29198,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6196256738827202,
            "auditor_fn_violation": 0.010020386787865189,
            "auditor_fp_violation": 0.009504574076274207,
            "ave_precision_score": 0.6279717550892238,
            "fpr": 0.046052631578947366,
            "logloss": 6.870723001636497,
            "mae": 0.44134471481503146,
            "precision": 0.7543859649122807,
            "recall": 0.27505330490405117
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6530853487451898,
            "auditor_fn_violation": 0.01327871264159698,
            "auditor_fp_violation": 0.0037723597346979807,
            "ave_precision_score": 0.6616837804242182,
            "fpr": 0.04939626783754116,
            "logloss": 6.916854309771531,
            "mae": 0.43886111199375555,
            "precision": 0.7715736040609137,
            "recall": 0.3134020618556701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8495503128798745,
            "auditor_fn_violation": 0.014584034713649796,
            "auditor_fp_violation": 0.021466971605084952,
            "ave_precision_score": 0.8498859213030656,
            "fpr": 0.20942982456140352,
            "logloss": 0.5578407600488052,
            "mae": 0.3415355549541824,
            "precision": 0.6832504145936982,
            "recall": 0.8784648187633263
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8739239149824269,
            "auditor_fn_violation": 0.017524641551710483,
            "auditor_fp_violation": 0.02259550718139795,
            "ave_precision_score": 0.8741225981309365,
            "fpr": 0.18111964873765093,
            "logloss": 0.5128197434972971,
            "mae": 0.32634204637104336,
            "precision": 0.7231543624161074,
            "recall": 0.8886597938144329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7868595621502729,
            "auditor_fn_violation": 0.006660775072008382,
            "auditor_fp_violation": 0.01574442596332819,
            "ave_precision_score": 0.7369703045584726,
            "fpr": 0.19736842105263158,
            "logloss": 2.904588789133702,
            "mae": 0.30809314751757866,
            "precision": 0.6847635726795096,
            "recall": 0.8336886993603412
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.7973792975228287,
            "auditor_fn_violation": 0.009279482159629728,
            "auditor_fp_violation": 0.010010667738594029,
            "ave_precision_score": 0.7466618960398984,
            "fpr": 0.15916575192096596,
            "logloss": 2.959135607046016,
            "mae": 0.2902649893853752,
            "precision": 0.740608228980322,
            "recall": 0.8536082474226804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8302453346992011,
            "auditor_fn_violation": 0.016328133767253953,
            "auditor_fp_violation": 0.023444616054809714,
            "ave_precision_score": 0.8305702218257915,
            "fpr": 0.13596491228070176,
            "logloss": 0.7788622911340385,
            "mae": 0.2737464068476138,
            "precision": 0.7356076759061834,
            "recall": 0.7356076759061834
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8331953992239132,
            "auditor_fn_violation": 0.00781966118573676,
            "auditor_fp_violation": 0.016743711445401283,
            "ave_precision_score": 0.8335273452545402,
            "fpr": 0.12294182217343579,
            "logloss": 0.7714145596685689,
            "mae": 0.2670154155019285,
            "precision": 0.7700205338809035,
            "recall": 0.7731958762886598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8116209697558742,
            "auditor_fn_violation": 0.0209478921183556,
            "auditor_fp_violation": 0.01917993346798147,
            "ave_precision_score": 0.8120281561622762,
            "fpr": 0.09210526315789473,
            "logloss": 1.2222413022422671,
            "mae": 0.29187190611888786,
            "precision": 0.7777777777777778,
            "recall": 0.6268656716417911
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8120830137917577,
            "auditor_fn_violation": 0.0242737673565924,
            "auditor_fp_violation": 0.014115428023685473,
            "ave_precision_score": 0.8125456236775649,
            "fpr": 0.09220636663007684,
            "logloss": 1.3041046612268739,
            "mae": 0.2955599059154853,
            "precision": 0.7894736842105263,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8413806908874751,
            "auditor_fn_violation": 0.015507518796992486,
            "auditor_fp_violation": 0.030011187675735622,
            "ave_precision_score": 0.841700146641497,
            "fpr": 0.12609649122807018,
            "logloss": 0.5309921469136644,
            "mae": 0.29516065694597754,
            "precision": 0.7553191489361702,
            "recall": 0.7569296375266524
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8602839291712948,
            "auditor_fn_violation": 0.006203673316962214,
            "auditor_fp_violation": 0.011675247239014034,
            "ave_precision_score": 0.8605447748453688,
            "fpr": 0.09989023051591657,
            "logloss": 0.49457966802857484,
            "mae": 0.2800938290452869,
            "precision": 0.8104166666666667,
            "recall": 0.8020618556701031
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7981348062388094,
            "auditor_fn_violation": 0.012077769049489396,
            "auditor_fp_violation": 0.031159657043285414,
            "ave_precision_score": 0.784554349293292,
            "fpr": 0.21052631578947367,
            "logloss": 1.505279415250433,
            "mae": 0.30009125562317324,
            "precision": 0.6862745098039216,
            "recall": 0.8955223880597015
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7986615669907451,
            "auditor_fn_violation": 0.004965654599567713,
            "auditor_fp_violation": 0.01627989672392203,
            "ave_precision_score": 0.7826519135693839,
            "fpr": 0.2030735455543359,
            "logloss": 1.5964362745363039,
            "mae": 0.2866839818691203,
            "precision": 0.7072784810126582,
            "recall": 0.9216494845360824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8474643545460532,
            "auditor_fn_violation": 0.01895363408521304,
            "auditor_fp_violation": 0.024912379707734356,
            "ave_precision_score": 0.8487942565778308,
            "fpr": 0.13267543859649122,
            "logloss": 0.5296374954479979,
            "mae": 0.27610075695882413,
            "precision": 0.7589641434262948,
            "recall": 0.8123667377398721
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8733322964350225,
            "auditor_fn_violation": 0.015048604116921481,
            "auditor_fp_violation": 0.016542725066093597,
            "ave_precision_score": 0.8735459057761787,
            "fpr": 0.11306256860592755,
            "logloss": 0.4889195559183585,
            "mae": 0.2647591082677466,
            "precision": 0.7960396039603961,
            "recall": 0.8288659793814434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 29198,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8027962294139965,
            "auditor_fn_violation": 0.009821662364867392,
            "auditor_fp_violation": 0.020147716922102096,
            "ave_precision_score": 0.8031363022603905,
            "fpr": 0.17543859649122806,
            "logloss": 0.6023497879418136,
            "mae": 0.34394558006353465,
            "precision": 0.6928982725527831,
            "recall": 0.7697228144989339
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8381264030564358,
            "auditor_fn_violation": 0.0014756639922142894,
            "auditor_fp_violation": 0.009523662281040799,
            "ave_precision_score": 0.8384130311491135,
            "fpr": 0.15806805708013172,
            "logloss": 0.5450659254848988,
            "mae": 0.32311424592252896,
            "precision": 0.7348066298342542,
            "recall": 0.822680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 29198,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8528395026316928,
            "auditor_fn_violation": 0.022628866943478106,
            "auditor_fp_violation": 0.03425606906657163,
            "ave_precision_score": 0.8530486076446498,
            "fpr": 0.14583333333333334,
            "logloss": 0.6061638963024183,
            "mae": 0.28300490458333305,
            "precision": 0.7407407407407407,
            "recall": 0.8102345415778252
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8471031911851269,
            "auditor_fn_violation": 0.027080244887797485,
            "auditor_fp_violation": 0.02015274964827385,
            "ave_precision_score": 0.8475774217352029,
            "fpr": 0.141602634467618,
            "logloss": 0.6181971181308722,
            "mae": 0.2784049223627313,
            "precision": 0.75,
            "recall": 0.797938144329897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.809518284021035,
            "auditor_fn_violation": 0.024328545243706288,
            "auditor_fp_violation": 0.02152637519306166,
            "ave_precision_score": 0.8098951583831059,
            "fpr": 0.10635964912280702,
            "logloss": 1.052016564588874,
            "mae": 0.28875366677299746,
            "precision": 0.7668269230769231,
            "recall": 0.6801705756929638
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8055420919072138,
            "auditor_fn_violation": 0.028893138841422708,
            "auditor_fp_violation": 0.012677602387099769,
            "ave_precision_score": 0.8061673725033989,
            "fpr": 0.10976948408342481,
            "logloss": 1.1167486190101292,
            "mae": 0.29380512098867284,
            "precision": 0.7663551401869159,
            "recall": 0.6762886597938145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.80370314082677,
            "auditor_fn_violation": 0.014006564919762095,
            "auditor_fp_violation": 0.02198180270088313,
            "ave_precision_score": 0.791503314936788,
            "fpr": 0.2236842105263158,
            "logloss": 1.4340731154466901,
            "mae": 0.30410428519519034,
            "precision": 0.6720257234726688,
            "recall": 0.8912579957356077
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.81025093357629,
            "auditor_fn_violation": 0.010164427897291977,
            "auditor_fp_violation": 0.01277551882830095,
            "ave_precision_score": 0.7997539794865074,
            "fpr": 0.21624588364434688,
            "logloss": 1.3776559980613048,
            "mae": 0.2887663824410436,
            "precision": 0.6945736434108527,
            "recall": 0.9237113402061856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 29198,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8491864013376418,
            "auditor_fn_violation": 0.01464014513896682,
            "auditor_fp_violation": 0.02180854223595106,
            "ave_precision_score": 0.8494682460071838,
            "fpr": 0.12609649122807018,
            "logloss": 0.6212316006646342,
            "mae": 0.26622346731719615,
            "precision": 0.7589098532494759,
            "recall": 0.7718550106609808
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8431499470410511,
            "auditor_fn_violation": 0.020380911426211148,
            "auditor_fp_violation": 0.01881541720134198,
            "ave_precision_score": 0.843548478265582,
            "fpr": 0.1141602634467618,
            "logloss": 0.6413151146829706,
            "mae": 0.26104233687280165,
            "precision": 0.7846790890269151,
            "recall": 0.7814432989690722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6811109458087875,
            "auditor_fn_violation": 0.08494183219242137,
            "auditor_fp_violation": 0.08915488495505129,
            "ave_precision_score": 0.682865211070139,
            "fpr": 0.24232456140350878,
            "logloss": 2.0892304219635727,
            "mae": 0.3803001531134791,
            "precision": 0.6060606060606061,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6936355123389046,
            "auditor_fn_violation": 0.08368961263820206,
            "auditor_fp_violation": 0.08293522569739699,
            "ave_precision_score": 0.6953248985895624,
            "fpr": 0.22941822173435786,
            "logloss": 2.1140286636471695,
            "mae": 0.3702552584307633,
            "precision": 0.6267857142857143,
            "recall": 0.7237113402061855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7920776672648091,
            "auditor_fn_violation": 0.015823139939400738,
            "auditor_fp_violation": 0.018863114332105663,
            "ave_precision_score": 0.7800199910283766,
            "fpr": 0.12938596491228072,
            "logloss": 1.3891130736838142,
            "mae": 0.280841184390106,
            "precision": 0.7445887445887446,
            "recall": 0.7334754797441365
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.796353225227499,
            "auditor_fn_violation": 0.010589926103635976,
            "auditor_fp_violation": 0.013868060172229872,
            "ave_precision_score": 0.7853297974340873,
            "fpr": 0.11855104281009879,
            "logloss": 1.3847296302148506,
            "mae": 0.2765891716580158,
            "precision": 0.773109243697479,
            "recall": 0.7587628865979381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8247646692576608,
            "auditor_fn_violation": 0.01008351101634684,
            "auditor_fp_violation": 0.01609342204269139,
            "ave_precision_score": 0.8262622475948046,
            "fpr": 0.26644736842105265,
            "logloss": 0.8127357317049034,
            "mae": 0.3342787677196484,
            "precision": 0.6415929203539823,
            "recall": 0.9275053304904051
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8493531919326451,
            "auditor_fn_violation": 0.006554483008362852,
            "auditor_fp_violation": 0.018954561617785748,
            "ave_precision_score": 0.850571375618134,
            "fpr": 0.2667398463227223,
            "logloss": 0.7805820455394725,
            "mae": 0.3203794439205681,
            "precision": 0.6523605150214592,
            "recall": 0.9402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8460095570572255,
            "auditor_fn_violation": 0.01857255077993492,
            "auditor_fp_violation": 0.016650330679973072,
            "ave_precision_score": 0.8473538909089979,
            "fpr": 0.09758771929824561,
            "logloss": 0.5312193034832372,
            "mae": 0.2807415996089778,
            "precision": 0.7977272727272727,
            "recall": 0.7484008528784648
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8718543296073951,
            "auditor_fn_violation": 0.015677798273111002,
            "auditor_fp_violation": 0.012584839442803914,
            "ave_precision_score": 0.8720770267763769,
            "fpr": 0.0889132821075741,
            "logloss": 0.48937910928711525,
            "mae": 0.27087600061313866,
            "precision": 0.8239130434782609,
            "recall": 0.7814432989690722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8465537676607705,
            "auditor_fn_violation": 0.018116653574234094,
            "auditor_fp_violation": 0.01533355114648925,
            "ave_precision_score": 0.8478867554857221,
            "fpr": 0.09758771929824561,
            "logloss": 0.5294232466469717,
            "mae": 0.28130562426750466,
            "precision": 0.7972665148063781,
            "recall": 0.746268656716418
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8720259864058031,
            "auditor_fn_violation": 0.018656285717518987,
            "auditor_fp_violation": 0.012028261777028804,
            "ave_precision_score": 0.8722473389207941,
            "fpr": 0.08562019758507135,
            "logloss": 0.48941526703923627,
            "mae": 0.27147056957528143,
            "precision": 0.8281938325991189,
            "recall": 0.7752577319587629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8036052498652493,
            "auditor_fn_violation": 0.013199977555829877,
            "auditor_fp_violation": 0.01803888954892876,
            "ave_precision_score": 0.7913588617046172,
            "fpr": 0.23355263157894737,
            "logloss": 1.4329653404624387,
            "mae": 0.30289263578902037,
            "precision": 0.6629746835443038,
            "recall": 0.8933901918976546
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8092607295045282,
            "auditor_fn_violation": 0.009947152217456743,
            "auditor_fp_violation": 0.012054029261555427,
            "ave_precision_score": 0.7994666272668798,
            "fpr": 0.21953896816684962,
            "logloss": 1.3634817884149764,
            "mae": 0.2902310785004934,
            "precision": 0.689922480620155,
            "recall": 0.9175257731958762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7947003610031087,
            "auditor_fn_violation": 0.01597744360902256,
            "auditor_fp_violation": 0.012185160983723417,
            "ave_precision_score": 0.7951399102828345,
            "fpr": 0.21162280701754385,
            "logloss": 0.700206046713126,
            "mae": 0.3364265496071923,
            "precision": 0.6756302521008404,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8070879496584795,
            "auditor_fn_violation": 0.010979211696674098,
            "auditor_fp_violation": 0.009415438846028986,
            "ave_precision_score": 0.8074262635849496,
            "fpr": 0.20087815587266739,
            "logloss": 0.6463954066040336,
            "mae": 0.32156077069537364,
            "precision": 0.7024390243902439,
            "recall": 0.8907216494845361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7969192243490388,
            "auditor_fn_violation": 0.011811244529233537,
            "auditor_fp_violation": 0.018575996990218214,
            "ave_precision_score": 0.7724584749087688,
            "fpr": 0.13596491228070176,
            "logloss": 1.8495018615015821,
            "mae": 0.27875191991037673,
            "precision": 0.7464212678936605,
            "recall": 0.7782515991471215
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.7991388733432995,
            "auditor_fn_violation": 0.0168750778005364,
            "auditor_fp_violation": 0.008482655906165126,
            "ave_precision_score": 0.7713178749821967,
            "fpr": 0.12733260153677278,
            "logloss": 2.008428346700999,
            "mae": 0.2717649746214869,
            "precision": 0.7721021611001965,
            "recall": 0.8103092783505155
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8257557727440965,
            "auditor_fn_violation": 0.0113272921108742,
            "auditor_fp_violation": 0.020328402835531275,
            "ave_precision_score": 0.8261192439044909,
            "fpr": 0.14912280701754385,
            "logloss": 0.5809039739531225,
            "mae": 0.30489952149710325,
            "precision": 0.7235772357723578,
            "recall": 0.7590618336886994
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8405811523177663,
            "auditor_fn_violation": 0.010931682641710141,
            "auditor_fp_violation": 0.015777430775652825,
            "ave_precision_score": 0.840908618162438,
            "fpr": 0.145993413830955,
            "logloss": 0.5499437960888445,
            "mae": 0.2984549952117608,
            "precision": 0.745697896749522,
            "recall": 0.8041237113402062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.5864130721071946,
            "auditor_fn_violation": 0.003684584595817905,
            "auditor_fp_violation": 0.02492475545522951,
            "ave_precision_score": 0.5762838102718879,
            "fpr": 0.29276315789473684,
            "logloss": 2.5528536772341353,
            "mae": 0.39688664784249306,
            "precision": 0.5972850678733032,
            "recall": 0.8443496801705757
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6345791252194075,
            "auditor_fn_violation": 0.004352303461699503,
            "auditor_fp_violation": 0.0057873770246801085,
            "ave_precision_score": 0.6261118362934923,
            "fpr": 0.2678375411635565,
            "logloss": 2.019334359977798,
            "mae": 0.3753747682029826,
            "precision": 0.6358208955223881,
            "recall": 0.8783505154639175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8038389256040075,
            "auditor_fn_violation": 0.013819530168705347,
            "auditor_fp_violation": 0.02264266761712408,
            "ave_precision_score": 0.7916365852122118,
            "fpr": 0.2225877192982456,
            "logloss": 1.4284745476274785,
            "mae": 0.302744604461236,
            "precision": 0.6725806451612903,
            "recall": 0.8891257995735607
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8104189963558995,
            "auditor_fn_violation": 0.010164427897291977,
            "auditor_fp_violation": 0.014728694155419157,
            "ave_precision_score": 0.7999051320103554,
            "fpr": 0.21514818880351264,
            "logloss": 1.3747683701904692,
            "mae": 0.28768652782010995,
            "precision": 0.6956521739130435,
            "recall": 0.9237113402061856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8464834320354699,
            "auditor_fn_violation": 0.019605917779523436,
            "auditor_fp_violation": 0.03074630707694745,
            "ave_precision_score": 0.8468175108740552,
            "fpr": 0.17543859649122806,
            "logloss": 0.684754306617425,
            "mae": 0.2766522042125126,
            "precision": 0.7101449275362319,
            "recall": 0.835820895522388
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8532961701276722,
            "auditor_fn_violation": 0.013432616248146935,
            "auditor_fp_violation": 0.022123962214560696,
            "ave_precision_score": 0.8536792316997469,
            "fpr": 0.1668496158068057,
            "logloss": 0.6480358333407622,
            "mae": 0.26424727146974125,
            "precision": 0.7323943661971831,
            "recall": 0.8577319587628865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8532730753551736,
            "auditor_fn_violation": 0.021602513747054207,
            "auditor_fp_violation": 0.03727575145538791,
            "ave_precision_score": 0.8535521523635623,
            "fpr": 0.14802631578947367,
            "logloss": 0.6285896628774372,
            "mae": 0.27878187870654975,
            "precision": 0.733201581027668,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8542022443201824,
            "auditor_fn_violation": 0.024137970056695376,
            "auditor_fp_violation": 0.02138185866019388,
            "ave_precision_score": 0.8545808888492772,
            "fpr": 0.141602634467618,
            "logloss": 0.6320245481567869,
            "mae": 0.27062535124157727,
            "precision": 0.7519230769230769,
            "recall": 0.8061855670103093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8381204958068571,
            "auditor_fn_violation": 0.019479669322560133,
            "auditor_fp_violation": 0.03138489564769713,
            "ave_precision_score": 0.8385124716166841,
            "fpr": 0.16337719298245615,
            "logloss": 0.7159990211696649,
            "mae": 0.26916584454828985,
            "precision": 0.7204502814258912,
            "recall": 0.8187633262260128
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8393935625529334,
            "auditor_fn_violation": 0.018063304174635333,
            "auditor_fp_violation": 0.020967002159315202,
            "ave_precision_score": 0.8397428815893037,
            "fpr": 0.1525795828759605,
            "logloss": 0.7182027745366448,
            "mae": 0.2632443707413856,
            "precision": 0.7435424354243543,
            "recall": 0.8309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8143551077044473,
            "auditor_fn_violation": 0.013709647252459512,
            "auditor_fp_violation": 0.021947150607896725,
            "ave_precision_score": 0.8147435072597893,
            "fpr": 0.15679824561403508,
            "logloss": 0.7977454286642834,
            "mae": 0.2799559247002057,
            "precision": 0.717391304347826,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8195085964972539,
            "auditor_fn_violation": 0.005488474204171249,
            "auditor_fp_violation": 0.018799956710626006,
            "ave_precision_score": 0.819937821768613,
            "fpr": 0.1394072447859495,
            "logloss": 0.7967209466762051,
            "mae": 0.274951452555212,
            "precision": 0.7533980582524272,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7913170714376019,
            "auditor_fn_violation": 0.015320484045935737,
            "auditor_fp_violation": 0.031360144152706826,
            "ave_precision_score": 0.7812109983562123,
            "fpr": 0.19956140350877194,
            "logloss": 1.3493865877165294,
            "mae": 0.28557070368668447,
            "precision": 0.6845753899480069,
            "recall": 0.8422174840085288
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.800903554701932,
            "auditor_fn_violation": 0.0074167958627089315,
            "auditor_fp_violation": 0.01860412382822364,
            "ave_precision_score": 0.7922876193112066,
            "fpr": 0.18221734357848518,
            "logloss": 1.3114567522828027,
            "mae": 0.27065850518292184,
            "precision": 0.7186440677966102,
            "recall": 0.8742268041237113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7583347259666111,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.5176990317374373,
            "fpr": 0.4780701754385965,
            "logloss": 16.52262822478697,
            "mae": 0.47916864716707336,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7676600441501104,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.5353200883002207,
            "fpr": 0.4621295279912184,
            "logloss": 15.961759497345765,
            "mae": 0.46213107423052163,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7929725139002021,
            "auditor_fn_violation": 0.016559589271686683,
            "auditor_fp_violation": 0.023422339709318445,
            "ave_precision_score": 0.7836493636839321,
            "fpr": 0.1524122807017544,
            "logloss": 1.2272142276147586,
            "mae": 0.2808746049701943,
            "precision": 0.7214428857715431,
            "recall": 0.767590618336887
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8037308861764861,
            "auditor_fn_violation": 0.014285875949166553,
            "auditor_fp_violation": 0.015522332678839231,
            "ave_precision_score": 0.7961010775218169,
            "fpr": 0.13172338090010977,
            "logloss": 1.18735363404015,
            "mae": 0.26708460996337907,
            "precision": 0.7619047619047619,
            "recall": 0.7917525773195876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6780533909562567,
            "auditor_fn_violation": 0.027159783787827782,
            "auditor_fp_violation": 0.021162528216704283,
            "ave_precision_score": 0.6739188865642504,
            "fpr": 0.18859649122807018,
            "logloss": 2.371783213002826,
            "mae": 0.314216251850525,
            "precision": 0.6785046728971963,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6890809298851224,
            "auditor_fn_violation": 0.017026718118754745,
            "auditor_fp_violation": 0.02360816932329432,
            "ave_precision_score": 0.680585815953469,
            "fpr": 0.18111964873765093,
            "logloss": 2.490848427226736,
            "mae": 0.2999695163477582,
            "precision": 0.7043010752688172,
            "recall": 0.8103092783505155
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7510963427717399,
            "auditor_fn_violation": 0.02055278120674822,
            "auditor_fp_violation": 0.030375034652093,
            "ave_precision_score": 0.7226657210163908,
            "fpr": 0.19736842105263158,
            "logloss": 2.4668957562386873,
            "mae": 0.3004327038321677,
            "precision": 0.6880415944540728,
            "recall": 0.8464818763326226
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.768473978089715,
            "auditor_fn_violation": 0.018977672660608597,
            "auditor_fp_violation": 0.021345784181856602,
            "ave_precision_score": 0.7445700066045795,
            "fpr": 0.1800219538968167,
            "logloss": 2.112720445078468,
            "mae": 0.2816636677730752,
            "precision": 0.7191780821917808,
            "recall": 0.865979381443299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7988856689993288,
            "auditor_fn_violation": 0.013641847155201435,
            "auditor_fp_violation": 0.025231673993109185,
            "ave_precision_score": 0.7860696117273818,
            "fpr": 0.16557017543859648,
            "logloss": 1.3986090550240557,
            "mae": 0.2839859751514731,
            "precision": 0.7156308851224106,
            "recall": 0.8102345415778252
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8007685100173945,
            "auditor_fn_violation": 0.011454502246313671,
            "auditor_fp_violation": 0.01655818555680958,
            "ave_precision_score": 0.7869286057931679,
            "fpr": 0.14489571899012074,
            "logloss": 1.4632359820363354,
            "mae": 0.27003640252033617,
            "precision": 0.753731343283582,
            "recall": 0.8329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.852624019744515,
            "auditor_fn_violation": 0.023395709422810763,
            "auditor_fp_violation": 0.0349367351788048,
            "ave_precision_score": 0.8529666863816534,
            "fpr": 0.14802631578947367,
            "logloss": 0.6255603632162461,
            "mae": 0.2764940980782889,
            "precision": 0.7326732673267327,
            "recall": 0.7889125799573561
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8539009424034412,
            "auditor_fn_violation": 0.025022915794357628,
            "auditor_fp_violation": 0.02028416381935963,
            "ave_precision_score": 0.8542914434867337,
            "fpr": 0.14050493962678376,
            "logloss": 0.6181373005136702,
            "mae": 0.26912036945281165,
            "precision": 0.7533718689788054,
            "recall": 0.8061855670103093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8553751439203482,
            "auditor_fn_violation": 0.026428010324318258,
            "auditor_fp_violation": 0.03180567106253218,
            "ave_precision_score": 0.8556867182659077,
            "fpr": 0.1513157894736842,
            "logloss": 0.5863526257257816,
            "mae": 0.2799255286196325,
            "precision": 0.735632183908046,
            "recall": 0.8187633262260128
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8522381648008429,
            "auditor_fn_violation": 0.02522208516753992,
            "auditor_fp_violation": 0.023865844168560586,
            "ave_precision_score": 0.8526238008316712,
            "fpr": 0.150384193194292,
            "logloss": 0.5820166852433856,
            "mae": 0.2737923064869548,
            "precision": 0.7415094339622641,
            "recall": 0.8103092783505155
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8251956160875942,
            "auditor_fn_violation": 0.0067005199566079416,
            "auditor_fp_violation": 0.01551176191041939,
            "ave_precision_score": 0.8255133218064048,
            "fpr": 0.09210526315789473,
            "logloss": 0.585541045717013,
            "mae": 0.33330290723126,
            "precision": 0.7868020304568528,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8520628279297268,
            "auditor_fn_violation": 0.008428485746941735,
            "auditor_fp_violation": 0.004259365192251201,
            "ave_precision_score": 0.8523133209649737,
            "fpr": 0.06915477497255763,
            "logloss": 0.5497933372698199,
            "mae": 0.31881979816089273,
            "precision": 0.8421052631578947,
            "recall": 0.6927835051546392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7922789871498488,
            "auditor_fn_violation": 0.014413365503310514,
            "auditor_fp_violation": 0.01469991287473764,
            "ave_precision_score": 0.780670353504388,
            "fpr": 0.13157894736842105,
            "logloss": 1.3352481241674647,
            "mae": 0.284083930736951,
            "precision": 0.7452229299363057,
            "recall": 0.7484008528784648
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.797170155185887,
            "auditor_fn_violation": 0.011599352699537163,
            "auditor_fp_violation": 0.0034038847059672333,
            "ave_precision_score": 0.7876983423163278,
            "fpr": 0.12623490669593854,
            "logloss": 1.2728277553771883,
            "mae": 0.2825565679874134,
            "precision": 0.7672064777327935,
            "recall": 0.7814432989690722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8533099662765133,
            "auditor_fn_violation": 0.006059925934238582,
            "auditor_fp_violation": 0.014776642509207571,
            "ave_precision_score": 0.8536174360688256,
            "fpr": 0.29605263157894735,
            "logloss": 0.6147042121430512,
            "mae": 0.35657970011399137,
            "precision": 0.6191819464033851,
            "recall": 0.9360341151385928
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8766702925156651,
            "auditor_fn_violation": 0.0003870223047065092,
            "auditor_fp_violation": 0.01787232726766749,
            "ave_precision_score": 0.8768578946542778,
            "fpr": 0.2722283205268935,
            "logloss": 0.5577926622160192,
            "mae": 0.34470662578830225,
            "precision": 0.64822695035461,
            "recall": 0.9422680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8167981958111219,
            "auditor_fn_violation": 0.028221206000074814,
            "auditor_fp_violation": 0.031382420498198095,
            "ave_precision_score": 0.8171774474241309,
            "fpr": 0.14364035087719298,
            "logloss": 0.8635126538679542,
            "mae": 0.28167993523600804,
            "precision": 0.7259414225941423,
            "recall": 0.7398720682302772
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8121185117713186,
            "auditor_fn_violation": 0.023753211040320486,
            "auditor_fp_violation": 0.019240580696031295,
            "ave_precision_score": 0.8129237063996269,
            "fpr": 0.1350164654226125,
            "logloss": 0.9177900958963836,
            "mae": 0.2812340974494786,
            "precision": 0.7479508196721312,
            "recall": 0.7525773195876289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8223435925646299,
            "auditor_fn_violation": 0.009167040736168782,
            "auditor_fp_violation": 0.024600510870856598,
            "ave_precision_score": 0.8227064693444259,
            "fpr": 0.2642543859649123,
            "logloss": 0.7334881222314792,
            "mae": 0.3347392483771265,
            "precision": 0.6381381381381381,
            "recall": 0.906183368869936
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8430490712465659,
            "auditor_fn_violation": 0.003428881822399765,
            "auditor_fp_violation": 0.01669732997325336,
            "ave_precision_score": 0.8433404269863047,
            "fpr": 0.26344676180021953,
            "logloss": 0.7101591031149063,
            "mae": 0.32653263092490065,
            "precision": 0.6516690856313497,
            "recall": 0.9257731958762887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8312380123730563,
            "auditor_fn_violation": 0.01824757789997382,
            "auditor_fp_violation": 0.016843392340897396,
            "ave_precision_score": 0.8315551517085749,
            "fpr": 0.09429824561403509,
            "logloss": 0.9535494702391748,
            "mae": 0.27807286505046763,
            "precision": 0.7855361596009975,
            "recall": 0.6716417910447762
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8269193261547776,
            "auditor_fn_violation": 0.018042934579650775,
            "auditor_fp_violation": 0.011345423437073232,
            "ave_precision_score": 0.8272489052185602,
            "fpr": 0.09769484083424808,
            "logloss": 1.0107318197117243,
            "mae": 0.27904893355822136,
            "precision": 0.7920560747663551,
            "recall": 0.6989690721649484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8028372428334425,
            "auditor_fn_violation": 0.010473946059177794,
            "auditor_fp_violation": 0.020796206090847886,
            "ave_precision_score": 0.7906080624230466,
            "fpr": 0.22807017543859648,
            "logloss": 1.4463225880246868,
            "mae": 0.3031562157666783,
            "precision": 0.6687898089171974,
            "recall": 0.8955223880597015
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8084029370038559,
            "auditor_fn_violation": 0.010110108977333169,
            "auditor_fp_violation": 0.010863571476425337,
            "ave_precision_score": 0.7979085389938197,
            "fpr": 0.2217343578485181,
            "logloss": 1.3927552916683397,
            "mae": 0.28881534546802007,
            "precision": 0.6887519260400616,
            "recall": 0.9216494845360824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 29198,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8301616781846948,
            "auditor_fn_violation": 0.019472655519395508,
            "auditor_fp_violation": 0.023952021702110818,
            "ave_precision_score": 0.830469819697527,
            "fpr": 0.13157894736842105,
            "logloss": 0.9197126350676733,
            "mae": 0.2763266840569666,
            "precision": 0.7413793103448276,
            "recall": 0.7334754797441365
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8243750570054462,
            "auditor_fn_violation": 0.014910543528692836,
            "auditor_fp_violation": 0.016047989363182386,
            "ave_precision_score": 0.8248153605431181,
            "fpr": 0.11855104281009879,
            "logloss": 0.981916338028981,
            "mae": 0.27274549605864684,
            "precision": 0.7711864406779662,
            "recall": 0.7505154639175258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7540775064081751,
            "auditor_fn_violation": 0.0059009463958403455,
            "auditor_fp_violation": 0.0028984000633638296,
            "ave_precision_score": 0.7548687005139224,
            "fpr": 0.1611842105263158,
            "logloss": 0.7066967029869797,
            "mae": 0.35614670112874847,
            "precision": 0.6872340425531915,
            "recall": 0.6886993603411514
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8231696381767696,
            "auditor_fn_violation": 0.014315298697477573,
            "auditor_fp_violation": 0.005710074571100222,
            "ave_precision_score": 0.8234715223185385,
            "fpr": 0.1394072447859495,
            "logloss": 0.6252439018002746,
            "mae": 0.3313240757092305,
            "precision": 0.7348643006263048,
            "recall": 0.7257731958762886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8426006983425719,
            "auditor_fn_violation": 0.017515804436464295,
            "auditor_fp_violation": 0.017494356659142223,
            "ave_precision_score": 0.8429265966407877,
            "fpr": 0.23684210526315788,
            "logloss": 0.6407690022127865,
            "mae": 0.3291897334480123,
            "precision": 0.6619718309859155,
            "recall": 0.9019189765458422
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8658264126775166,
            "auditor_fn_violation": 0.012810211956952259,
            "auditor_fp_violation": 0.02064490860273239,
            "ave_precision_score": 0.8661038454492476,
            "fpr": 0.23600439077936333,
            "logloss": 0.5877562534161964,
            "mae": 0.3186644363554698,
            "precision": 0.6717557251908397,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8451146664147744,
            "auditor_fn_violation": 0.02263821868103094,
            "auditor_fp_violation": 0.027211793592332983,
            "ave_precision_score": 0.8454169601183665,
            "fpr": 0.16228070175438597,
            "logloss": 0.8132286814024343,
            "mae": 0.29523788142589036,
            "precision": 0.7218045112781954,
            "recall": 0.8187633262260128
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8573298306549881,
            "auditor_fn_violation": 0.018450326479341837,
            "auditor_fp_violation": 0.013569157351721012,
            "ave_precision_score": 0.8575571566627884,
            "fpr": 0.14709110867178923,
            "logloss": 0.7182583607554864,
            "mae": 0.28303644090364144,
            "precision": 0.7495327102803738,
            "recall": 0.8268041237113402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 29198,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8441129620188731,
            "auditor_fn_violation": 0.01906585493584708,
            "auditor_fp_violation": 0.01400192071601125,
            "ave_precision_score": 0.8443320424547099,
            "fpr": 0.05921052631578947,
            "logloss": 0.9727866758115041,
            "mae": 0.30920691988756116,
            "precision": 0.847887323943662,
            "recall": 0.6417910447761194
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8553861314304005,
            "auditor_fn_violation": 0.02107800423234918,
            "auditor_fp_violation": 0.012584839442803916,
            "ave_precision_score": 0.8556611700060763,
            "fpr": 0.05598243688254665,
            "logloss": 1.0300945143149027,
            "mae": 0.3042004231866525,
            "precision": 0.8632707774798928,
            "recall": 0.6639175257731958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8463953813250005,
            "auditor_fn_violation": 0.01206607937754835,
            "auditor_fp_violation": 0.017925032671973387,
            "ave_precision_score": 0.8467154907081054,
            "fpr": 0.14802631578947367,
            "logloss": 0.5065016888119914,
            "mae": 0.3162832178383261,
            "precision": 0.7418738049713193,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8689453077988214,
            "auditor_fn_violation": 0.0028856926228116877,
            "auditor_fp_violation": 0.007938961982653328,
            "ave_precision_score": 0.8692519863555913,
            "fpr": 0.12184412733260154,
            "logloss": 0.46779584975555416,
            "mae": 0.3001695070944141,
            "precision": 0.7877629063097514,
            "recall": 0.8494845360824742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8081003255623167,
            "auditor_fn_violation": 0.008757902218232149,
            "auditor_fp_violation": 0.01883093738861828,
            "ave_precision_score": 0.8095395355445203,
            "fpr": 0.2675438596491228,
            "logloss": 0.777117498957396,
            "mae": 0.33197977514455007,
            "precision": 0.6347305389221557,
            "recall": 0.9040511727078892
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8265507562281115,
            "auditor_fn_violation": 0.003711792863851891,
            "auditor_fp_violation": 0.016944697824708962,
            "ave_precision_score": 0.8278636997047503,
            "fpr": 0.265642151481888,
            "logloss": 0.7542007759433257,
            "mae": 0.3251296187116909,
            "precision": 0.6502890173410405,
            "recall": 0.9278350515463918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8434274619399477,
            "auditor_fn_violation": 0.021906445217521414,
            "auditor_fp_violation": 0.030659676844481405,
            "ave_precision_score": 0.8437772032821764,
            "fpr": 0.15789473684210525,
            "logloss": 0.7246958182346767,
            "mae": 0.2677252334780501,
            "precision": 0.7230769230769231,
            "recall": 0.8017057569296375
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.845260108342692,
            "auditor_fn_violation": 0.01622777733769394,
            "auditor_fp_violation": 0.01924831094138929,
            "ave_precision_score": 0.8455759197538368,
            "fpr": 0.14489571899012074,
            "logloss": 0.7209751200106308,
            "mae": 0.2593646448952366,
            "precision": 0.7518796992481203,
            "recall": 0.8247422680412371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8063118169220371,
            "auditor_fn_violation": 0.01579274679235402,
            "auditor_fp_violation": 0.02982802661280741,
            "ave_precision_score": 0.8037470918237157,
            "fpr": 0.20285087719298245,
            "logloss": 1.0540546890787226,
            "mae": 0.29440556744855295,
            "precision": 0.6906354515050167,
            "recall": 0.8805970149253731
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8137155113915288,
            "auditor_fn_violation": 0.01603539782950649,
            "auditor_fp_violation": 0.025298516308240957,
            "ave_precision_score": 0.8112900446194082,
            "fpr": 0.19978046103183314,
            "logloss": 1.037074053734106,
            "mae": 0.27909083736571244,
            "precision": 0.7050243111831442,
            "recall": 0.8969072164948454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7940861282359326,
            "auditor_fn_violation": 0.0035302809261960875,
            "auditor_fp_violation": 0.01271731812601483,
            "ave_precision_score": 0.7731602195726524,
            "fpr": 0.43969298245614036,
            "logloss": 2.899830004654763,
            "mae": 0.41655675606733367,
            "precision": 0.5342624854819977,
            "recall": 0.9808102345415778
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.8080483245536658,
            "auditor_fn_violation": 0.0014982968755304586,
            "auditor_fp_violation": 0.0040815695490174775,
            "ave_precision_score": 0.7898281776870748,
            "fpr": 0.43468715697036225,
            "logloss": 2.580582346758371,
            "mae": 0.4030465505422736,
            "precision": 0.5494880546075085,
            "recall": 0.9958762886597938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.832503435984112,
            "auditor_fn_violation": 0.015956402199528676,
            "auditor_fp_violation": 0.016081046295196234,
            "ave_precision_score": 0.8327972227608267,
            "fpr": 0.08881578947368421,
            "logloss": 0.961657180919998,
            "mae": 0.2783972073527268,
            "precision": 0.7928388746803069,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8269005423190247,
            "auditor_fn_violation": 0.018420903731030818,
            "auditor_fp_violation": 0.00845946517009117,
            "ave_precision_score": 0.8272326043201902,
            "fpr": 0.09330406147091108,
            "logloss": 1.017671571221936,
            "mae": 0.2799436011552138,
            "precision": 0.7966507177033493,
            "recall": 0.6865979381443299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8454774827784262,
            "auditor_fn_violation": 0.012255452062993303,
            "auditor_fp_violation": 0.011900518791334995,
            "ave_precision_score": 0.8458025110271771,
            "fpr": 0.1524122807017544,
            "logloss": 0.5020453359910947,
            "mae": 0.31943352475942094,
            "precision": 0.7362428842504743,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8667980790879533,
            "auditor_fn_violation": 0.0013624995756334397,
            "auditor_fp_violation": 0.007536989224037971,
            "ave_precision_score": 0.8671137462292555,
            "fpr": 0.12403951701427003,
            "logloss": 0.46876685640564864,
            "mae": 0.3039008908251834,
            "precision": 0.781431334622824,
            "recall": 0.8329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7993462890520886,
            "auditor_fn_violation": 0.0038365503310515093,
            "auditor_fp_violation": 0.025365332066056786,
            "ave_precision_score": 0.7832015302858746,
            "fpr": 0.3508771929824561,
            "logloss": 1.996998994637966,
            "mae": 0.3631407544075556,
            "precision": 0.5881595881595881,
            "recall": 0.9744136460554371
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8045664569445604,
            "auditor_fn_violation": 0.0031097581676417666,
            "auditor_fp_violation": 0.020382080260560806,
            "ave_precision_score": 0.7874939648033035,
            "fpr": 0.3534577387486279,
            "logloss": 2.041825236569969,
            "mae": 0.3561100450601127,
            "precision": 0.5969962453066333,
            "recall": 0.9835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7999365327471379,
            "auditor_fn_violation": 0.003864605543710021,
            "auditor_fp_violation": 0.0238431151241535,
            "ave_precision_score": 0.7845367550349112,
            "fpr": 0.3508771929824561,
            "logloss": 1.9492835543494278,
            "mae": 0.35963672553062725,
            "precision": 0.5881595881595881,
            "recall": 0.9744136460554371
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.8029524890389552,
            "auditor_fn_violation": 0.0031097581676417666,
            "auditor_fp_violation": 0.01714568420401663,
            "ave_precision_score": 0.7859843861392083,
            "fpr": 0.35236004390779363,
            "logloss": 2.0187882578473357,
            "mae": 0.3533250756057423,
            "precision": 0.5977443609022557,
            "recall": 0.9835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7969911774976354,
            "auditor_fn_violation": 0.01974853177720421,
            "auditor_fp_violation": 0.02838996475387114,
            "ave_precision_score": 0.7811422395464707,
            "fpr": 0.17982456140350878,
            "logloss": 1.5405045285887067,
            "mae": 0.28883579980033747,
            "precision": 0.7107583774250441,
            "recall": 0.8592750533049041
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8020171315169756,
            "auditor_fn_violation": 0.01772833750155601,
            "auditor_fp_violation": 0.019101436279587523,
            "ave_precision_score": 0.7873686867916074,
            "fpr": 0.17014270032930845,
            "logloss": 1.5122504993581272,
            "mae": 0.27355410263611213,
            "precision": 0.7309027777777778,
            "recall": 0.8680412371134021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7946100033886003,
            "auditor_fn_violation": 0.011752796169528306,
            "auditor_fp_violation": 0.012925230683933312,
            "ave_precision_score": 0.7823654100098406,
            "fpr": 0.12938596491228072,
            "logloss": 1.3579956700555886,
            "mae": 0.2815659972253305,
            "precision": 0.7521008403361344,
            "recall": 0.7633262260127932
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7984766355565067,
            "auditor_fn_violation": 0.010886416875077807,
            "auditor_fp_violation": 0.006276959230685985,
            "ave_precision_score": 0.7872744869096124,
            "fpr": 0.13172338090010977,
            "logloss": 1.3269883779834426,
            "mae": 0.2780735641693798,
            "precision": 0.7585513078470825,
            "recall": 0.777319587628866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 29198,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8454792272356988,
            "auditor_fn_violation": 0.01908455841095276,
            "auditor_fp_violation": 0.027417231000752443,
            "ave_precision_score": 0.8462027613575431,
            "fpr": 0.1600877192982456,
            "logloss": 0.6950007641594556,
            "mae": 0.27343252337070434,
            "precision": 0.7170542635658915,
            "recall": 0.7889125799573561
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8576489005136245,
            "auditor_fn_violation": 0.0035986284472710422,
            "auditor_fp_violation": 0.015908844946738616,
            "ave_precision_score": 0.8578493986434211,
            "fpr": 0.1437980241492865,
            "logloss": 0.6449924549962657,
            "mae": 0.2568312443038354,
            "precision": 0.7551401869158878,
            "recall": 0.8329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7963007472918824,
            "auditor_fn_violation": 0.004909662215239592,
            "auditor_fp_violation": 0.0278627579105778,
            "ave_precision_score": 0.7771706559644878,
            "fpr": 0.3267543859649123,
            "logloss": 1.9921196325174322,
            "mae": 0.35412737798546196,
            "precision": 0.6021361815754339,
            "recall": 0.9616204690831557
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.801903577539883,
            "auditor_fn_violation": 0.005592585467425623,
            "auditor_fp_violation": 0.02455898950232682,
            "ave_precision_score": 0.7839439325415902,
            "fpr": 0.3260153677277717,
            "logloss": 1.9931784184801702,
            "mae": 0.3448945513898844,
            "precision": 0.6122715404699739,
            "recall": 0.9670103092783505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8016440118673193,
            "auditor_fn_violation": 0.01196554819885535,
            "auditor_fp_violation": 0.025355431468060675,
            "ave_precision_score": 0.7889637864035428,
            "fpr": 0.18530701754385964,
            "logloss": 1.3985085325289872,
            "mae": 0.2827816611191752,
            "precision": 0.7008849557522124,
            "recall": 0.8443496801705757
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8061454446559865,
            "auditor_fn_violation": 0.005807597858929239,
            "auditor_fp_violation": 0.015986147400318486,
            "ave_precision_score": 0.7938408602626781,
            "fpr": 0.17453347969264543,
            "logloss": 1.4032415067498938,
            "mae": 0.2687662076932016,
            "precision": 0.7295918367346939,
            "recall": 0.8845360824742268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7996914950746302,
            "auditor_fn_violation": 0.011067781393782967,
            "auditor_fp_violation": 0.025159894657637336,
            "ave_precision_score": 0.7882476022837512,
            "fpr": 0.20175438596491227,
            "logloss": 1.3692626005623387,
            "mae": 0.2949231003158407,
            "precision": 0.6870748299319728,
            "recall": 0.8614072494669509
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8059532888485927,
            "auditor_fn_violation": 0.009727613249289894,
            "auditor_fp_violation": 0.018336141989146744,
            "ave_precision_score": 0.7954726757048731,
            "fpr": 0.1942919868276619,
            "logloss": 1.337455169905499,
            "mae": 0.28187978297752764,
            "precision": 0.7103109656301145,
            "recall": 0.8948453608247423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7987124442749972,
            "auditor_fn_violation": 0.01564311899150862,
            "auditor_fp_violation": 0.024464377648409974,
            "ave_precision_score": 0.7851949503404971,
            "fpr": 0.1600877192982456,
            "logloss": 1.3894288813878939,
            "mae": 0.28282664238589894,
            "precision": 0.7186897880539499,
            "recall": 0.7953091684434968
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8029373143193763,
            "auditor_fn_violation": 0.011228173413151972,
            "auditor_fp_violation": 0.0166045670289575,
            "ave_precision_score": 0.7905822224164026,
            "fpr": 0.1394072447859495,
            "logloss": 1.3996755314908897,
            "mae": 0.2686535419518502,
            "precision": 0.7603773584905661,
            "recall": 0.8309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.5848248389821722,
            "auditor_fn_violation": 0.02884075861295029,
            "auditor_fp_violation": 0.028211753989940996,
            "ave_precision_score": 0.586360343918835,
            "fpr": 0.28399122807017546,
            "logloss": 1.5748691460536353,
            "mae": 0.39015774190522584,
            "precision": 0.5996908809891809,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6452496605208572,
            "auditor_fn_violation": 0.031561555784399155,
            "auditor_fp_violation": 0.03557458913745924,
            "ave_precision_score": 0.646201120933192,
            "fpr": 0.2513721185510428,
            "logloss": 1.3543432985909978,
            "mae": 0.365747879612319,
            "precision": 0.6393700787401575,
            "recall": 0.8371134020618557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.795375290514297,
            "auditor_fn_violation": 0.011946844723749678,
            "auditor_fp_violation": 0.021593204229535472,
            "ave_precision_score": 0.7827747756690988,
            "fpr": 0.15679824561403508,
            "logloss": 1.4203199782519136,
            "mae": 0.2875972065807255,
            "precision": 0.72552783109405,
            "recall": 0.8059701492537313
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7962742143660382,
            "auditor_fn_violation": 0.00908031278644743,
            "auditor_fp_violation": 0.013837139190797924,
            "ave_precision_score": 0.7841277315340562,
            "fpr": 0.15916575192096596,
            "logloss": 1.4234601192405345,
            "mae": 0.28175728358699015,
            "precision": 0.7358834244080146,
            "recall": 0.8329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8495018553722907,
            "auditor_fn_violation": 0.016232278457337372,
            "auditor_fp_violation": 0.019840798384222418,
            "ave_precision_score": 0.8498230405443776,
            "fpr": 0.24561403508771928,
            "logloss": 0.5863604995367978,
            "mae": 0.34862502541921603,
            "precision": 0.6569678407350689,
            "recall": 0.9147121535181236
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8726204601519316,
            "auditor_fn_violation": 0.015175348263492029,
            "auditor_fp_violation": 0.025216060357755758,
            "ave_precision_score": 0.8728263067267701,
            "fpr": 0.21734357848518113,
            "logloss": 0.5388000702450845,
            "mae": 0.33399382442258574,
            "precision": 0.6876971608832808,
            "recall": 0.8989690721649485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7934235045096729,
            "auditor_fn_violation": 0.010490311599895266,
            "auditor_fp_violation": 0.012865827095956604,
            "ave_precision_score": 0.7812750756698094,
            "fpr": 0.13267543859649122,
            "logloss": 1.3607850309305478,
            "mae": 0.28298632373016697,
            "precision": 0.7484407484407485,
            "recall": 0.767590618336887
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7976325721605279,
            "auditor_fn_violation": 0.008815508051648244,
            "auditor_fp_violation": 0.015545523414913191,
            "ave_precision_score": 0.7864521598801623,
            "fpr": 0.1350164654226125,
            "logloss": 1.3291333676428903,
            "mae": 0.2795192989625046,
            "precision": 0.7549800796812749,
            "recall": 0.7814432989690722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8411597857237921,
            "auditor_fn_violation": 0.00523463509520069,
            "auditor_fp_violation": 0.026612807413567793,
            "ave_precision_score": 0.8414706675646159,
            "fpr": 0.2236842105263158,
            "logloss": 0.9042982479524193,
            "mae": 0.2900424682120661,
            "precision": 0.6746411483253588,
            "recall": 0.9019189765458422
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8281520487032143,
            "auditor_fn_violation": 0.0057080131723380905,
            "auditor_fp_violation": 0.011878810366774375,
            "ave_precision_score": 0.828563487513071,
            "fpr": 0.21295279912184412,
            "logloss": 0.9069299031971731,
            "mae": 0.2816492016873572,
            "precision": 0.6905901116427432,
            "recall": 0.8927835051546392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8091177531071951,
            "auditor_fn_violation": 0.02435893839075301,
            "auditor_fp_violation": 0.02152637519306166,
            "ave_precision_score": 0.8094946098072499,
            "fpr": 0.10635964912280702,
            "logloss": 1.0503993095612119,
            "mae": 0.28850984228598664,
            "precision": 0.7673860911270983,
            "recall": 0.6823027718550106
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8024415365381997,
            "auditor_fn_violation": 0.028162096710310412,
            "auditor_fp_violation": 0.015143550656297832,
            "ave_precision_score": 0.8037600656269928,
            "fpr": 0.11306256860592755,
            "logloss": 1.116417327523977,
            "mae": 0.29336038738813996,
            "precision": 0.7626728110599078,
            "recall": 0.6824742268041237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7489848075586447,
            "auditor_fn_violation": 0.01269498372797666,
            "auditor_fp_violation": 0.022758999643578474,
            "ave_precision_score": 0.7204534431142264,
            "fpr": 0.19956140350877194,
            "logloss": 2.455510576188544,
            "mae": 0.3029278491331663,
            "precision": 0.6823734729493892,
            "recall": 0.8336886993603412
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7669999102060535,
            "auditor_fn_violation": 0.005968291330474047,
            "auditor_fp_violation": 0.014764768633756437,
            "ave_precision_score": 0.7431287133253252,
            "fpr": 0.1778265642151482,
            "logloss": 2.0982617842804765,
            "mae": 0.2825004561211881,
            "precision": 0.7226027397260274,
            "recall": 0.8701030927835052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7894066976810425,
            "auditor_fn_violation": 0.014382972356263794,
            "auditor_fp_violation": 0.026048473327789007,
            "ave_precision_score": 0.777768679339411,
            "fpr": 0.17434210526315788,
            "logloss": 1.374358615742897,
            "mae": 0.2830948748676491,
            "precision": 0.7060998151571165,
            "recall": 0.814498933901919
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7955728956734407,
            "auditor_fn_violation": 0.0003327033847477034,
            "auditor_fp_violation": 0.014633354462670651,
            "ave_precision_score": 0.7854363884249831,
            "fpr": 0.16136114160263446,
            "logloss": 1.354066982389201,
            "mae": 0.274289513944758,
            "precision": 0.7346570397111913,
            "recall": 0.8391752577319588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8483356524721124,
            "auditor_fn_violation": 0.02018104963902293,
            "auditor_fp_violation": 0.031919527939487546,
            "ave_precision_score": 0.8487350940619858,
            "fpr": 0.16776315789473684,
            "logloss": 0.5923942702135409,
            "mae": 0.28500662090537116,
            "precision": 0.71875,
            "recall": 0.8336886993603412
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8544863528595488,
            "auditor_fn_violation": 0.014949019430330328,
            "auditor_fp_violation": 0.023399452698628653,
            "ave_precision_score": 0.8547642553311178,
            "fpr": 0.16136114160263446,
            "logloss": 0.5730131962475575,
            "mae": 0.27875449850039774,
            "precision": 0.7384341637010676,
            "recall": 0.8556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8297695621239491,
            "auditor_fn_violation": 0.011523678599483797,
            "auditor_fp_violation": 0.016439942972555546,
            "ave_precision_score": 0.830117496665705,
            "fpr": 0.06907894736842106,
            "logloss": 1.0192973721389316,
            "mae": 0.28460860601498,
            "precision": 0.8240223463687151,
            "recall": 0.6289978678038379
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.826142313724161,
            "auditor_fn_violation": 0.022967849989249386,
            "auditor_fp_violation": 0.011368614173147187,
            "ave_precision_score": 0.8264920388444348,
            "fpr": 0.0801317233809001,
            "logloss": 1.0788096515349224,
            "mae": 0.2928198134873642,
            "precision": 0.8073878627968337,
            "recall": 0.6309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.801526075055476,
            "auditor_fn_violation": 0.015327497849100365,
            "auditor_fp_violation": 0.02600887093580452,
            "ave_precision_score": 0.787876604673117,
            "fpr": 0.19407894736842105,
            "logloss": 1.4580222898255644,
            "mae": 0.2898407505594212,
            "precision": 0.6958762886597938,
            "recall": 0.8635394456289979
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8054801311662432,
            "auditor_fn_violation": 0.009648398157683298,
            "auditor_fp_violation": 0.015707858567430937,
            "ave_precision_score": 0.7908648911022671,
            "fpr": 0.1800219538968167,
            "logloss": 1.497295253737142,
            "mae": 0.2714255799115474,
            "precision": 0.7225042301184433,
            "recall": 0.8804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7551498948498666,
            "auditor_fn_violation": 0.024162551902143423,
            "auditor_fp_violation": 0.0188581640331076,
            "ave_precision_score": 0.7555862543192886,
            "fpr": 0.08223684210526316,
            "logloss": 3.0057589508264697,
            "mae": 0.35707125201874607,
            "precision": 0.7761194029850746,
            "recall": 0.5543710021321961
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7939025658575993,
            "auditor_fn_violation": 0.02713682709608791,
            "auditor_fp_violation": 0.009245373448153248,
            "ave_precision_score": 0.7941175361934129,
            "fpr": 0.07354555433589462,
            "logloss": 2.8425370772570417,
            "mae": 0.3380738933262293,
            "precision": 0.8107344632768362,
            "recall": 0.5917525773195876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8451136565144898,
            "auditor_fn_violation": 0.023540661354879738,
            "auditor_fp_violation": 0.019298740643934897,
            "ave_precision_score": 0.8465019642997178,
            "fpr": 0.09868421052631579,
            "logloss": 0.5323713671948282,
            "mae": 0.2816016622237058,
            "precision": 0.7968397291196389,
            "recall": 0.7526652452025586
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8690982973624468,
            "auditor_fn_violation": 0.015766066518044068,
            "auditor_fp_violation": 0.013466087413614507,
            "ave_precision_score": 0.8693229727995313,
            "fpr": 0.09001097694840834,
            "logloss": 0.49383916209320544,
            "mae": 0.27304427638657497,
            "precision": 0.8193832599118943,
            "recall": 0.7670103092783506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7889924585697905,
            "auditor_fn_violation": 0.016409961470841283,
            "auditor_fp_violation": 0.022009029345372466,
            "ave_precision_score": 0.7552947149078255,
            "fpr": 0.13157894736842105,
            "logloss": 3.583540578793512,
            "mae": 0.28031429966935273,
            "precision": 0.744136460554371,
            "recall": 0.744136460554371
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7896020475539626,
            "auditor_fn_violation": 0.01204974707752895,
            "auditor_fp_violation": 0.013721185510428105,
            "ave_precision_score": 0.7535876450950364,
            "fpr": 0.12403951701427003,
            "logloss": 3.7294445896103094,
            "mae": 0.27589322228973184,
            "precision": 0.7674897119341564,
            "recall": 0.7690721649484537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.5857934311503039,
            "auditor_fn_violation": 0.003534956794972511,
            "auditor_fp_violation": 0.024872777315749883,
            "ave_precision_score": 0.575688617297476,
            "fpr": 0.28728070175438597,
            "logloss": 2.536211172210308,
            "mae": 0.39539437930054727,
            "precision": 0.601823708206687,
            "recall": 0.8443496801705757
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6319096725913542,
            "auditor_fn_violation": 0.0036122081772607434,
            "auditor_fp_violation": 0.007567910205469923,
            "ave_precision_score": 0.6238876314187349,
            "fpr": 0.2667398463227223,
            "logloss": 2.0055662837071186,
            "mae": 0.3746455959274521,
            "precision": 0.6345864661654136,
            "recall": 0.8701030927835052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 29198,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.5848086137898474,
            "auditor_fn_violation": 0.001262484569633039,
            "auditor_fp_violation": 0.023263930141380555,
            "ave_precision_score": 0.5725685477027058,
            "fpr": 0.3026315789473684,
            "logloss": 2.6644867511914203,
            "mae": 0.4000290879084887,
            "precision": 0.593519882179676,
            "recall": 0.8592750533049041
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6294803574742938,
            "auditor_fn_violation": 0.0033111908291556815,
            "auditor_fp_violation": 0.006400643156413792,
            "ave_precision_score": 0.6192318029758994,
            "fpr": 0.270032930845225,
            "logloss": 2.173732159721638,
            "mae": 0.37787232239702984,
            "precision": 0.6355555555555555,
            "recall": 0.8845360824742268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.5877046659105197,
            "auditor_fn_violation": 0.004273744061646658,
            "auditor_fp_violation": 0.023588174725753443,
            "ave_precision_score": 0.5790609411852848,
            "fpr": 0.2905701754385965,
            "logloss": 2.3778473818617547,
            "mae": 0.3940493882516484,
            "precision": 0.5978755690440061,
            "recall": 0.8400852878464818
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6353570885860103,
            "auditor_fn_violation": 0.004653320809804567,
            "auditor_fp_violation": 0.008188906582561597,
            "ave_precision_score": 0.6284604916703473,
            "fpr": 0.2645444566410538,
            "logloss": 1.8879238242071061,
            "mae": 0.3734845744266936,
            "precision": 0.6365007541478129,
            "recall": 0.8701030927835052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.812375043196433,
            "auditor_fn_violation": 0.019323027718550115,
            "auditor_fp_violation": 0.020392756722506043,
            "ave_precision_score": 0.8127799393107603,
            "fpr": 0.09539473684210527,
            "logloss": 1.2241080565852007,
            "mae": 0.291534148368131,
            "precision": 0.7722513089005235,
            "recall": 0.6289978678038379
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8120604649465537,
            "auditor_fn_violation": 0.024653999796304053,
            "auditor_fp_violation": 0.007931231737295341,
            "ave_precision_score": 0.8125242877561403,
            "fpr": 0.09001097694840834,
            "logloss": 1.302138480963169,
            "mae": 0.2956670999639335,
            "precision": 0.7939698492462312,
            "recall": 0.6515463917525773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7938158873553068,
            "auditor_fn_violation": 0.007048872180451128,
            "auditor_fp_violation": 0.023758960041186484,
            "ave_precision_score": 0.7439223512375867,
            "fpr": 0.18640350877192982,
            "logloss": 2.8729627387314847,
            "mae": 0.29662304283569063,
            "precision": 0.7027972027972028,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8026006384756473,
            "auditor_fn_violation": 0.00791019271900144,
            "auditor_fp_violation": 0.014233958452507953,
            "ave_precision_score": 0.7518842343089235,
            "fpr": 0.15916575192096596,
            "logloss": 2.938765359605134,
            "mae": 0.2808751276213498,
            "precision": 0.7456140350877193,
            "recall": 0.8762886597938144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8018326282989454,
            "auditor_fn_violation": 0.019704111023828234,
            "auditor_fp_violation": 0.02038533127400895,
            "ave_precision_score": 0.8023187907119149,
            "fpr": 0.10526315789473684,
            "logloss": 1.102701182472839,
            "mae": 0.29640728412821743,
            "precision": 0.7641277641277642,
            "recall": 0.6631130063965884
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7984003005020388,
            "auditor_fn_violation": 0.024866748899476047,
            "auditor_fp_violation": 0.01631854795071196,
            "ave_precision_score": 0.7988460336268981,
            "fpr": 0.10647639956092206,
            "logloss": 1.1843958245251665,
            "mae": 0.30017098647117685,
            "precision": 0.7668269230769231,
            "recall": 0.6577319587628866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8370549553390263,
            "auditor_fn_violation": 0.024520255863539446,
            "auditor_fp_violation": 0.027399904954259237,
            "ave_precision_score": 0.8373372643849826,
            "fpr": 0.13267543859649122,
            "logloss": 0.8072886990047861,
            "mae": 0.268234287049754,
            "precision": 0.7479166666666667,
            "recall": 0.7654584221748401
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8334928551673669,
            "auditor_fn_violation": 0.026967080471216633,
            "auditor_fp_violation": 0.016522111078472297,
            "ave_precision_score": 0.8339409096016095,
            "fpr": 0.1163556531284303,
            "logloss": 0.8187012788435755,
            "mae": 0.26229430353494415,
            "precision": 0.7777777777777778,
            "recall": 0.7649484536082474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8394617354992092,
            "auditor_fn_violation": 0.024302827965435984,
            "auditor_fp_violation": 0.027437032196744687,
            "ave_precision_score": 0.8397569668516442,
            "fpr": 0.13706140350877194,
            "logloss": 0.7626835283940654,
            "mae": 0.2671493839634913,
            "precision": 0.7443762781186094,
            "recall": 0.7761194029850746
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8364859136639303,
            "auditor_fn_violation": 0.025586474588930264,
            "auditor_fp_violation": 0.018212458063418938,
            "ave_precision_score": 0.8368713837040219,
            "fpr": 0.11855104281009879,
            "logloss": 0.7648757808516908,
            "mae": 0.26092290814856645,
            "precision": 0.7786885245901639,
            "recall": 0.7835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.8045082969294686,
            "auditor_fn_violation": 0.007495417648599109,
            "auditor_fp_violation": 0.0230362163874698,
            "ave_precision_score": 0.8049019966851897,
            "fpr": 0.37719298245614036,
            "logloss": 0.8992542488724939,
            "mae": 0.3850777086310526,
            "precision": 0.5656565656565656,
            "recall": 0.9552238805970149
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.8174039130255893,
            "auditor_fn_violation": 0.005062975997827243,
            "auditor_fp_violation": 0.010523440680673879,
            "ave_precision_score": 0.81771106300059,
            "fpr": 0.39626783754116357,
            "logloss": 0.8689765581427935,
            "mae": 0.38165443619492806,
            "precision": 0.5640096618357487,
            "recall": 0.9628865979381444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7975833488643432,
            "auditor_fn_violation": 0.016218250851008118,
            "auditor_fp_violation": 0.01689289533087799,
            "ave_precision_score": 0.7867405329466299,
            "fpr": 0.13157894736842105,
            "logloss": 1.259699160147388,
            "mae": 0.2760746154293045,
            "precision": 0.7520661157024794,
            "recall": 0.7761194029850746
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8025502065752927,
            "auditor_fn_violation": 0.019090837077189445,
            "auditor_fp_violation": 0.011214009265987446,
            "ave_precision_score": 0.793879968013085,
            "fpr": 0.13611416026344675,
            "logloss": 1.2000515220215058,
            "mae": 0.2749762014732548,
            "precision": 0.7587548638132295,
            "recall": 0.8041237113402062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8128909996150913,
            "auditor_fn_violation": 0.0128796805446452,
            "auditor_fp_violation": 0.03069680408696685,
            "ave_precision_score": 0.8144419045904169,
            "fpr": 0.23464912280701755,
            "logloss": 0.7887683770041636,
            "mae": 0.3151430965711673,
            "precision": 0.6661466458658346,
            "recall": 0.9104477611940298
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8373579078396556,
            "auditor_fn_violation": 0.006357576923512173,
            "auditor_fp_violation": 0.016326278196069945,
            "ave_precision_score": 0.8386273643355444,
            "fpr": 0.24588364434687157,
            "logloss": 0.7257032399792999,
            "mae": 0.30816566714971977,
            "precision": 0.6656716417910448,
            "recall": 0.9195876288659793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8074212348797134,
            "auditor_fn_violation": 0.017083286574645574,
            "auditor_fp_violation": 0.018818561641123128,
            "ave_precision_score": 0.8078136006339908,
            "fpr": 0.08662280701754387,
            "logloss": 1.2268964912007807,
            "mae": 0.2937251524120238,
            "precision": 0.791005291005291,
            "recall": 0.6375266524520256
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8057654966248239,
            "auditor_fn_violation": 0.02440051150316295,
            "auditor_fp_violation": 0.013651613302206215,
            "ave_precision_score": 0.8063857455394465,
            "fpr": 0.08781558726673985,
            "logloss": 1.335054798906526,
            "mae": 0.2989143407057626,
            "precision": 0.7938144329896907,
            "recall": 0.6350515463917525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8418914832256097,
            "auditor_fn_violation": 0.020349380914974003,
            "auditor_fp_violation": 0.029622589204387952,
            "ave_precision_score": 0.842244966893338,
            "fpr": 0.15021929824561403,
            "logloss": 0.7318469165987771,
            "mae": 0.26769541390183965,
            "precision": 0.7313725490196078,
            "recall": 0.7953091684434968
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8451663193430387,
            "auditor_fn_violation": 0.016318308870958614,
            "auditor_fp_violation": 0.019629669712383342,
            "ave_precision_score": 0.8454568208143466,
            "fpr": 0.14050493962678376,
            "logloss": 0.7257752127165762,
            "mae": 0.2592031903834853,
            "precision": 0.7552581261950286,
            "recall": 0.8144329896907216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7937902939022624,
            "auditor_fn_violation": 0.007336438110200875,
            "auditor_fp_violation": 0.021630331472020915,
            "ave_precision_score": 0.7439015686521674,
            "fpr": 0.18092105263157895,
            "logloss": 2.861186686665327,
            "mae": 0.29316967317208764,
            "precision": 0.7058823529411765,
            "recall": 0.8443496801705757
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8026354663703352,
            "auditor_fn_violation": 0.007063722882976678,
            "auditor_fp_violation": 0.011193395278366141,
            "ave_precision_score": 0.751916112967993,
            "fpr": 0.15148188803512624,
            "logloss": 2.93098506415261,
            "mae": 0.2783235929414127,
            "precision": 0.7522441651705566,
            "recall": 0.8639175257731959
        }
    }
]