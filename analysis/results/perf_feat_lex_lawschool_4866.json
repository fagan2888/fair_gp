[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8536398332593382,
            "auditor_fn_violation": 0.016689079914214394,
            "auditor_fp_violation": 0.00911441739943079,
            "ave_precision_score": 0.853999993947933,
            "fpr": 0.17763157894736842,
            "logloss": 0.6024966509371048,
            "mae": 0.289955972937286,
            "precision": 0.7286432160804021,
            "recall": 0.8717434869739479
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8357086817389946,
            "auditor_fn_violation": 0.00949083846998227,
            "auditor_fp_violation": 0.018121593775877673,
            "ave_precision_score": 0.8359707387493545,
            "fpr": 0.2283205268935236,
            "logloss": 0.6315268787037578,
            "mae": 0.3137722933601279,
            "precision": 0.6623376623376623,
            "recall": 0.8967032967032967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8521348467542345,
            "auditor_fn_violation": 0.020712477586752463,
            "auditor_fp_violation": 0.016521706809396377,
            "ave_precision_score": 0.8523754285543126,
            "fpr": 0.09210526315789473,
            "logloss": 0.5618371461974728,
            "mae": 0.328096977065638,
            "precision": 0.8046511627906977,
            "recall": 0.6933867735470942
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8379953145144061,
            "auditor_fn_violation": 0.02213483552671259,
            "auditor_fp_violation": 0.010928803897779577,
            "ave_precision_score": 0.8382310833355913,
            "fpr": 0.10098792535675083,
            "logloss": 0.5149371378529515,
            "mae": 0.3211601361569475,
            "precision": 0.7766990291262136,
            "recall": 0.7032967032967034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.851531281519213,
            "auditor_fn_violation": 0.020712477586752463,
            "auditor_fp_violation": 0.016521706809396377,
            "ave_precision_score": 0.8517787423800901,
            "fpr": 0.09210526315789473,
            "logloss": 0.5623206589772203,
            "mae": 0.32777812196326794,
            "precision": 0.8046511627906977,
            "recall": 0.6933867735470942
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8380906277177964,
            "auditor_fn_violation": 0.022279586494734684,
            "auditor_fp_violation": 0.00901987405396037,
            "ave_precision_score": 0.83832645923464,
            "fpr": 0.10208562019758508,
            "logloss": 0.5152031997249247,
            "mae": 0.32084742781647885,
            "precision": 0.7753623188405797,
            "recall": 0.7054945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8427551173713599,
            "auditor_fn_violation": 0.02654651408079317,
            "auditor_fp_violation": 0.013314536340852131,
            "ave_precision_score": 0.8429860895634258,
            "fpr": 0.06469298245614036,
            "logloss": 0.5953802563143431,
            "mae": 0.35582823233868877,
            "precision": 0.8356545961002786,
            "recall": 0.6012024048096193
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8272604399917265,
            "auditor_fn_violation": 0.0258042725660728,
            "auditor_fp_violation": 0.010168120630885673,
            "ave_precision_score": 0.8275310285755918,
            "fpr": 0.07903402854006586,
            "logloss": 0.5374205081211326,
            "mae": 0.3396057602642748,
            "precision": 0.8032786885245902,
            "recall": 0.6461538461538462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8628842991015355,
            "auditor_fn_violation": 0.01675060647611012,
            "auditor_fp_violation": 0.01371012276453847,
            "ave_precision_score": 0.8630976980508529,
            "fpr": 0.08991228070175439,
            "logloss": 0.5479137228258308,
            "mae": 0.3105979666352939,
            "precision": 0.8119266055045872,
            "recall": 0.7094188376753507
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8505330666106987,
            "auditor_fn_violation": 0.011618677699907118,
            "auditor_fp_violation": 0.018598224430450446,
            "ave_precision_score": 0.8507614035649944,
            "fpr": 0.11086717892425905,
            "logloss": 0.49045530656885983,
            "mae": 0.30330468713975245,
            "precision": 0.7672811059907834,
            "recall": 0.7318681318681318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8772567459713231,
            "auditor_fn_violation": 0.0221473649052491,
            "auditor_fp_violation": 0.01267735015504864,
            "ave_precision_score": 0.8774587363670403,
            "fpr": 0.04824561403508772,
            "logloss": 0.5372860929575972,
            "mae": 0.3194683888276606,
            "precision": 0.8839050131926122,
            "recall": 0.6713426853707415
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8605605430938938,
            "auditor_fn_violation": 0.019722319393010945,
            "auditor_fp_violation": 0.009003023475263348,
            "ave_precision_score": 0.860762918425283,
            "fpr": 0.07135016465422613,
            "logloss": 0.4998611819283674,
            "mae": 0.30879188209831404,
            "precision": 0.8284960422163589,
            "recall": 0.6901098901098901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8337975873287438,
            "auditor_fn_violation": 0.019923619168160888,
            "auditor_fp_violation": 0.012539293148124549,
            "ave_precision_score": 0.8340955842390574,
            "fpr": 0.07456140350877193,
            "logloss": 0.6310964740168498,
            "mae": 0.334564194076608,
            "precision": 0.8210526315789474,
            "recall": 0.625250501002004
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.81682840503912,
            "auditor_fn_violation": 0.019645118876732495,
            "auditor_fp_violation": 0.009101719721917307,
            "ave_precision_score": 0.8172913928496855,
            "fpr": 0.0845225027442371,
            "logloss": 0.5606272605617685,
            "mae": 0.323223352195395,
            "precision": 0.7946666666666666,
            "recall": 0.654945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8500464297778795,
            "auditor_fn_violation": 0.011142899834757239,
            "auditor_fp_violation": 0.01469776135253388,
            "ave_precision_score": 0.8503245085241862,
            "fpr": 0.15679824561403508,
            "logloss": 0.5706268900586146,
            "mae": 0.289010432755739,
            "precision": 0.7473498233215548,
            "recall": 0.8476953907815631
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8294757884783337,
            "auditor_fn_violation": 0.005350960784550249,
            "auditor_fp_violation": 0.019611666377799614,
            "ave_precision_score": 0.8297979102483293,
            "fpr": 0.18331503841931943,
            "logloss": 0.5763223630272506,
            "mae": 0.3057288973160041,
            "precision": 0.6996402877697842,
            "recall": 0.8549450549450549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8649490469205987,
            "auditor_fn_violation": 0.00841815209366101,
            "auditor_fp_violation": 0.008331209379380658,
            "ave_precision_score": 0.8654355102725357,
            "fpr": 0.08223684210526316,
            "logloss": 0.5496382861629268,
            "mae": 0.29649485106998136,
            "precision": 0.8283752860411899,
            "recall": 0.7254509018036072
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8436003598376192,
            "auditor_fn_violation": 0.01624829616048058,
            "auditor_fp_violation": 0.01434706414774587,
            "ave_precision_score": 0.8443530613917241,
            "fpr": 0.10098792535675083,
            "logloss": 0.5046401378270634,
            "mae": 0.29230774239386237,
            "precision": 0.7870370370370371,
            "recall": 0.7472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8839037079217733,
            "auditor_fn_violation": 0.012597563548148939,
            "auditor_fp_violation": 0.011018011129518716,
            "ave_precision_score": 0.8841078039962561,
            "fpr": 0.08223684210526316,
            "logloss": 0.49584559583948806,
            "mae": 0.27942105291208064,
            "precision": 0.8325892857142857,
            "recall": 0.7474949899799599
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8664321692321669,
            "auditor_fn_violation": 0.016093895127923665,
            "auditor_fp_violation": 0.009619273210468546,
            "ave_precision_score": 0.8666724184594836,
            "fpr": 0.09220636663007684,
            "logloss": 0.46084389599573644,
            "mae": 0.2791801211284882,
            "precision": 0.8023529411764706,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8553670173013939,
            "auditor_fn_violation": 0.019211668951938973,
            "auditor_fp_violation": 0.021651055605114485,
            "ave_precision_score": 0.8557520760664328,
            "fpr": 0.10635964912280702,
            "logloss": 0.5405362785323891,
            "mae": 0.31694767815803826,
            "precision": 0.7922912205567452,
            "recall": 0.7414829659318637
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.84279505500199,
            "auditor_fn_violation": 0.024057610885272796,
            "auditor_fp_violation": 0.01497775723611994,
            "ave_precision_score": 0.8430240189525585,
            "fpr": 0.12843029637760703,
            "logloss": 0.5134727913357426,
            "mae": 0.3180797438904092,
            "precision": 0.7445414847161572,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7948939665021004,
            "auditor_fn_violation": 0.015153113244031922,
            "auditor_fp_violation": 0.012456989932458268,
            "ave_precision_score": 0.7951676468352047,
            "fpr": 0.10197368421052631,
            "logloss": 0.7283721377897721,
            "mae": 0.3733697098939222,
            "precision": 0.7627551020408163,
            "recall": 0.5991983967935872
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.757051927942371,
            "auditor_fn_violation": 0.01946900519897227,
            "auditor_fp_violation": 0.00995387755888074,
            "ave_precision_score": 0.7574543746241417,
            "fpr": 0.13062568605927552,
            "logloss": 0.6764370770601181,
            "mae": 0.36324230995863416,
            "precision": 0.7039800995024875,
            "recall": 0.621978021978022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7975956271049436,
            "auditor_fn_violation": 0.014375241711493165,
            "auditor_fp_violation": 0.013726052419183553,
            "ave_precision_score": 0.7607044790997267,
            "fpr": 0.13706140350877194,
            "logloss": 4.634062043363185,
            "mae": 0.3022950637170446,
            "precision": 0.7395833333333334,
            "recall": 0.7114228456913828
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.759436359206501,
            "auditor_fn_violation": 0.014651210479970091,
            "auditor_fp_violation": 0.01792420128256977,
            "ave_precision_score": 0.7184096468537922,
            "fpr": 0.16465422612513722,
            "logloss": 4.526736608146078,
            "mae": 0.3214994228877297,
            "precision": 0.6781115879828327,
            "recall": 0.6945054945054945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8699753577267682,
            "auditor_fn_violation": 0.009773933832577436,
            "auditor_fp_violation": 0.012048128796567692,
            "ave_precision_score": 0.870181504104238,
            "fpr": 0.08333333333333333,
            "logloss": 0.5473794569580882,
            "mae": 0.29732909300442417,
            "precision": 0.8186157517899761,
            "recall": 0.687374749498998
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.852587230666896,
            "auditor_fn_violation": 0.009645239502539173,
            "auditor_fp_violation": 0.010668823540739884,
            "ave_precision_score": 0.8528529059955817,
            "fpr": 0.09330406147091108,
            "logloss": 0.4865610783557898,
            "mae": 0.2907753761241935,
            "precision": 0.7931873479318735,
            "recall": 0.7164835164835165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8671448292469042,
            "auditor_fn_violation": 0.016631948106739795,
            "auditor_fp_violation": 0.014827853532135426,
            "ave_precision_score": 0.8669352847986079,
            "fpr": 0.07236842105263158,
            "logloss": 0.5330098367549168,
            "mae": 0.32082726223381,
            "precision": 0.8345864661654135,
            "recall": 0.6673346693386774
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8299272975253174,
            "auditor_fn_violation": 0.007816552273193333,
            "auditor_fp_violation": 0.011400620101296052,
            "ave_precision_score": 0.8297680155365001,
            "fpr": 0.09659714599341383,
            "logloss": 0.5146201462695671,
            "mae": 0.32366822182628174,
            "precision": 0.7821782178217822,
            "recall": 0.6945054945054945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8534205454105588,
            "auditor_fn_violation": 0.021145360897233074,
            "auditor_fp_violation": 0.014153498152160063,
            "ave_precision_score": 0.8537946604522294,
            "fpr": 0.08991228070175439,
            "logloss": 0.5580300888430176,
            "mae": 0.31737960288247496,
            "precision": 0.8097447795823666,
            "recall": 0.6993987975951904
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8442566905003657,
            "auditor_fn_violation": 0.013367751896840814,
            "auditor_fp_violation": 0.011708744968898649,
            "ave_precision_score": 0.8444949705952988,
            "fpr": 0.10428100987925357,
            "logloss": 0.49989536563017706,
            "mae": 0.31095397102050526,
            "precision": 0.7748815165876777,
            "recall": 0.7186813186813187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8691650161010345,
            "auditor_fn_violation": 0.01636826284147242,
            "auditor_fp_violation": 0.01400482137547258,
            "ave_precision_score": 0.8695082827877079,
            "fpr": 0.08771929824561403,
            "logloss": 0.4926980094919254,
            "mae": 0.3135994554918797,
            "precision": 0.8253275109170306,
            "recall": 0.7575150300601202
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8570943182211382,
            "auditor_fn_violation": 0.018337535132266197,
            "auditor_fp_violation": 0.008312149748685658,
            "ave_precision_score": 0.8573050420285446,
            "fpr": 0.11745334796926454,
            "logloss": 0.4767511447910149,
            "mae": 0.3158729183468426,
            "precision": 0.7713675213675214,
            "recall": 0.7934065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8534443597030926,
            "auditor_fn_violation": 0.026278434061104663,
            "auditor_fp_violation": 0.009483454398708634,
            "ave_precision_score": 0.8536650344407553,
            "fpr": 0.039473684210526314,
            "logloss": 0.6729645115728077,
            "mae": 0.3471045089203184,
            "precision": 0.883495145631068,
            "recall": 0.5470941883767535
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8372900677388215,
            "auditor_fn_violation": 0.017876744550729195,
            "auditor_fp_violation": 0.010326997515743256,
            "ave_precision_score": 0.8375406101965782,
            "fpr": 0.05159165751920966,
            "logloss": 0.5859333881099174,
            "mae": 0.3289371858261225,
            "precision": 0.8493589743589743,
            "recall": 0.5824175824175825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8774408598588136,
            "auditor_fn_violation": 0.012133916956720458,
            "auditor_fp_violation": 0.017581028843294686,
            "ave_precision_score": 0.8772754826027565,
            "fpr": 0.14144736842105263,
            "logloss": 0.4923481809597031,
            "mae": 0.26680141052827566,
            "precision": 0.7688172043010753,
            "recall": 0.8597194388777555
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8530932194881743,
            "auditor_fn_violation": 0.00755358801461985,
            "auditor_fp_violation": 0.010871030485104098,
            "ave_precision_score": 0.8529504846638487,
            "fpr": 0.18221734357848518,
            "logloss": 0.5149537842976775,
            "mae": 0.2832708864063372,
            "precision": 0.7030411449016101,
            "recall": 0.8637362637362638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8678032415352194,
            "auditor_fn_violation": 0.0050517702070808305,
            "auditor_fp_violation": 0.011129518712034324,
            "ave_precision_score": 0.8679976046649676,
            "fpr": 0.08552631578947369,
            "logloss": 0.5088019212508054,
            "mae": 0.32331253300735463,
            "precision": 0.8251121076233184,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8481610173285774,
            "auditor_fn_violation": 0.01462467280249937,
            "auditor_fp_violation": 0.011525795828759613,
            "ave_precision_score": 0.8484322536390608,
            "fpr": 0.10647639956092206,
            "logloss": 0.483383223455675,
            "mae": 0.317450335804418,
            "precision": 0.7863436123348018,
            "recall": 0.7846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8498283323979542,
            "auditor_fn_violation": 0.007330450374433077,
            "auditor_fp_violation": 0.012348137292383501,
            "ave_precision_score": 0.8501649216518747,
            "fpr": 0.10197368421052631,
            "logloss": 0.548620583620887,
            "mae": 0.3205704238081811,
            "precision": 0.7987012987012987,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8303057006473841,
            "auditor_fn_violation": 0.009987816793524805,
            "auditor_fp_violation": 0.004759084869143221,
            "ave_precision_score": 0.8306480903675266,
            "fpr": 0.10867178924259056,
            "logloss": 0.5129560768732201,
            "mae": 0.3194515561869876,
            "precision": 0.7744874715261959,
            "recall": 0.7472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8669463023715114,
            "auditor_fn_violation": 0.009024628203775979,
            "auditor_fp_violation": 0.011012701244637015,
            "ave_precision_score": 0.8680959105829259,
            "fpr": 0.08223684210526316,
            "logloss": 0.50429699175169,
            "mae": 0.3183635127284664,
            "precision": 0.8344370860927153,
            "recall": 0.7575150300601202
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.85313353887215,
            "auditor_fn_violation": 0.014528172157151305,
            "auditor_fp_violation": 0.009590386504130802,
            "ave_precision_score": 0.8533665671972341,
            "fpr": 0.10757409440175632,
            "logloss": 0.48290265672429217,
            "mae": 0.3125397518080885,
            "precision": 0.7850877192982456,
            "recall": 0.7868131868131868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8685763161047731,
            "auditor_fn_violation": 0.011476901170762575,
            "auditor_fp_violation": 0.011280850431162653,
            "ave_precision_score": 0.8687840487360146,
            "fpr": 0.08442982456140351,
            "logloss": 0.5067847573923142,
            "mae": 0.323247941762307,
            "precision": 0.8253968253968254,
            "recall": 0.7294589178356713
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8357644132318751,
            "auditor_fn_violation": 0.012566796540451862,
            "auditor_fp_violation": 0.005827893003639726,
            "ave_precision_score": 0.8364172161374426,
            "fpr": 0.10647639956092206,
            "logloss": 0.4843877245433632,
            "mae": 0.3180691010516002,
            "precision": 0.7868131868131868,
            "recall": 0.7868131868131868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8464012625851226,
            "auditor_fn_violation": 0.015201455542664286,
            "auditor_fp_violation": 0.019142134998513232,
            "ave_precision_score": 0.8468537687301267,
            "fpr": 0.10964912280701754,
            "logloss": 0.5500647602780782,
            "mae": 0.32614581627166717,
            "precision": 0.788135593220339,
            "recall": 0.7454909819639278
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8368611059780446,
            "auditor_fn_violation": 0.018571549197235263,
            "auditor_fp_violation": 0.015208850886821884,
            "ave_precision_score": 0.8370989185196898,
            "fpr": 0.1350164654226125,
            "logloss": 0.5258579381006204,
            "mae": 0.3270416883783697,
            "precision": 0.739406779661017,
            "recall": 0.7670329670329671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.856246171557772,
            "auditor_fn_violation": 0.012665682241676336,
            "auditor_fp_violation": 0.01199768489019158,
            "ave_precision_score": 0.856553710867686,
            "fpr": 0.09868421052631579,
            "logloss": 0.5034016227250947,
            "mae": 0.33269764293442694,
            "precision": 0.8089171974522293,
            "recall": 0.7635270541082164
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8445449303226245,
            "auditor_fn_violation": 0.01724225280756565,
            "auditor_fp_violation": 0.008078648872455567,
            "ave_precision_score": 0.8447876583549759,
            "fpr": 0.11086717892425905,
            "logloss": 0.49020083518667623,
            "mae": 0.325802735624473,
            "precision": 0.778021978021978,
            "recall": 0.778021978021978
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7982456140350878,
            "auc_prc": 0.8895520304634476,
            "auditor_fn_violation": 0.016627553352318677,
            "auditor_fp_violation": 0.016842954844738967,
            "ave_precision_score": 0.8897996745863843,
            "fpr": 0.08114035087719298,
            "logloss": 0.48625898376053095,
            "mae": 0.2762170063291338,
            "precision": 0.8401727861771058,
            "recall": 0.779559118236473
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8629509794543833,
            "auditor_fn_violation": 0.020909277330792148,
            "auditor_fp_violation": 0.021766133225489634,
            "ave_precision_score": 0.8632023879052649,
            "fpr": 0.1119648737650933,
            "logloss": 0.46789467125689915,
            "mae": 0.287485190568735,
            "precision": 0.777292576419214,
            "recall": 0.7824175824175824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.842165882156676,
            "auditor_fn_violation": 0.014790546004289279,
            "auditor_fp_violation": 0.019776666241875872,
            "ave_precision_score": 0.8425904085005174,
            "fpr": 0.10197368421052631,
            "logloss": 0.5557552074608256,
            "mae": 0.3226922795682249,
            "precision": 0.7947019867549668,
            "recall": 0.7214428857715431
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8389624262355022,
            "auditor_fn_violation": 0.013666903897419817,
            "auditor_fp_violation": 0.013114564677335488,
            "ave_precision_score": 0.8392068293224719,
            "fpr": 0.1119648737650933,
            "logloss": 0.5137146610599046,
            "mae": 0.3174183181687396,
            "precision": 0.7692307692307693,
            "recall": 0.7472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8583082383825854,
            "auditor_fn_violation": 0.011298913616707108,
            "auditor_fp_violation": 0.011944586041374626,
            "ave_precision_score": 0.8576194385383131,
            "fpr": 0.08114035087719298,
            "logloss": 0.5427647952502629,
            "mae": 0.29830368431878906,
            "precision": 0.8275058275058275,
            "recall": 0.7114228456913828
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8363012761884132,
            "auditor_fn_violation": 0.010098792535675088,
            "auditor_fp_violation": 0.012334623606216422,
            "ave_precision_score": 0.8354148060555857,
            "fpr": 0.12184412733260154,
            "logloss": 0.4943187418031144,
            "mae": 0.30050875421396983,
            "precision": 0.7555066079295154,
            "recall": 0.7538461538461538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 4866,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8519689152233715,
            "auditor_fn_violation": 0.010808898498751888,
            "auditor_fp_violation": 0.014716345949619817,
            "ave_precision_score": 0.8523184604271318,
            "fpr": 0.10855263157894737,
            "logloss": 0.5523675317107086,
            "mae": 0.3126819485433659,
            "precision": 0.7861771058315334,
            "recall": 0.7294589178356713
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8331890139181414,
            "auditor_fn_violation": 0.01566205473999108,
            "auditor_fp_violation": 0.010745854757640545,
            "ave_precision_score": 0.8334668412539392,
            "fpr": 0.11855104281009879,
            "logloss": 0.5248709409410922,
            "mae": 0.31374369467977686,
            "precision": 0.7583892617449665,
            "recall": 0.7450549450549451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8743496524633194,
            "auditor_fn_violation": 0.013874239707485154,
            "auditor_fp_violation": 0.014087124591138868,
            "ave_precision_score": 0.8745588402654305,
            "fpr": 0.0668859649122807,
            "logloss": 0.5166207687424521,
            "mae": 0.3041833171308482,
            "precision": 0.8530120481927711,
            "recall": 0.7094188376753507
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8575773880929154,
            "auditor_fn_violation": 0.01802149551875128,
            "auditor_fp_violation": 0.01427003293084523,
            "ave_precision_score": 0.8578432447710944,
            "fpr": 0.09220636663007684,
            "logloss": 0.47582009440319434,
            "mae": 0.29713623883429113,
            "precision": 0.8023529411764706,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.858080875283724,
            "auditor_fn_violation": 0.022338536722567942,
            "auditor_fp_violation": 0.014663247100802856,
            "ave_precision_score": 0.8582953483009369,
            "fpr": 0.08442982456140351,
            "logloss": 0.5595200534426701,
            "mae": 0.3199417938873618,
            "precision": 0.8157894736842105,
            "recall": 0.6833667334669339
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8511761309322254,
            "auditor_fn_violation": 0.01945694261830376,
            "auditor_fp_violation": 0.017418683921659253,
            "ave_precision_score": 0.8513910169047885,
            "fpr": 0.10318331503841932,
            "logloss": 0.4930160563673304,
            "mae": 0.3102081769720946,
            "precision": 0.7761904761904762,
            "recall": 0.7164835164835165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8653910108112591,
            "auditor_fn_violation": 0.016904422880849423,
            "auditor_fp_violation": 0.013290641858884502,
            "ave_precision_score": 0.8655775934481029,
            "fpr": 0.07346491228070176,
            "logloss": 0.5684483588600332,
            "mae": 0.3158498311540027,
            "precision": 0.8416075650118203,
            "recall": 0.7134268537074149
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8384288772191271,
            "auditor_fn_violation": 0.016110782740859583,
            "auditor_fp_violation": 0.011985575904635355,
            "ave_precision_score": 0.8386950209013974,
            "fpr": 0.09989023051591657,
            "logloss": 0.5197317169653661,
            "mae": 0.3155939578472659,
            "precision": 0.7822966507177034,
            "recall": 0.7186813186813187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.879307339543079,
            "auditor_fn_violation": 0.022156154414091345,
            "auditor_fp_violation": 0.01756775413109044,
            "ave_precision_score": 0.8795669269431374,
            "fpr": 0.12171052631578948,
            "logloss": 0.4675830288669724,
            "mae": 0.30039700921808715,
            "precision": 0.7865384615384615,
            "recall": 0.8196392785571143
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8542626549979884,
            "auditor_fn_violation": 0.01703236390393361,
            "auditor_fp_violation": 0.02013403431740713,
            "ave_precision_score": 0.8549978803301814,
            "fpr": 0.15367727771679474,
            "logloss": 0.48061095346065336,
            "mae": 0.3104583939739823,
            "precision": 0.7318007662835249,
            "recall": 0.8395604395604396
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8796409863796959,
            "auditor_fn_violation": 0.01334467179973984,
            "auditor_fp_violation": 0.014827853532135428,
            "ave_precision_score": 0.8797497690683806,
            "fpr": 0.07785087719298246,
            "logloss": 0.4940296057158996,
            "mae": 0.27837728567892717,
            "precision": 0.8422222222222222,
            "recall": 0.7595190380761523
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8538841647717992,
            "auditor_fn_violation": 0.014318283253519262,
            "auditor_fp_violation": 0.013441947349163251,
            "ave_precision_score": 0.8541556453600494,
            "fpr": 0.10318331503841932,
            "logloss": 0.47015417593054293,
            "mae": 0.2822440302940101,
            "precision": 0.7892376681614349,
            "recall": 0.7736263736263737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8829122868438769,
            "auditor_fn_violation": 0.018330520690503813,
            "auditor_fp_violation": 0.013240197952508395,
            "ave_precision_score": 0.8831076035603875,
            "fpr": 0.1162280701754386,
            "logloss": 0.4798919018433672,
            "mae": 0.3028132856533487,
            "precision": 0.7888446215139442,
            "recall": 0.7935871743486974
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8626940991269266,
            "auditor_fn_violation": 0.020470199394458457,
            "auditor_fp_violation": 0.006932809521058412,
            "ave_precision_score": 0.8628669388936181,
            "fpr": 0.12843029637760703,
            "logloss": 0.4710619073529908,
            "mae": 0.3078634510906546,
            "precision": 0.7592592592592593,
            "recall": 0.810989010989011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8460714235424615,
            "auditor_fn_violation": 0.016278170375839406,
            "auditor_fp_violation": 0.019197888789771037,
            "ave_precision_score": 0.8464743694050625,
            "fpr": 0.12280701754385964,
            "logloss": 0.5631970990536227,
            "mae": 0.32230074222944066,
            "precision": 0.7700205338809035,
            "recall": 0.751503006012024
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8327669216946467,
            "auditor_fn_violation": 0.022610101205051813,
            "auditor_fp_violation": 0.018872648140659008,
            "ave_precision_score": 0.8330232494326829,
            "fpr": 0.14709110867178923,
            "logloss": 0.5361221950001415,
            "mae": 0.3247597006724127,
            "precision": 0.7248459958932238,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8649477991847254,
            "auditor_fn_violation": 0.020068646064057942,
            "auditor_fp_violation": 0.015780977868399815,
            "ave_precision_score": 0.8654480377975068,
            "fpr": 0.09758771929824561,
            "logloss": 0.4984820816706087,
            "mae": 0.2878720252451705,
            "precision": 0.8153526970954357,
            "recall": 0.7875751503006012
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8539383394694479,
            "auditor_fn_violation": 0.022380912172350158,
            "auditor_fp_violation": 0.02524698133918771,
            "ave_precision_score": 0.854193505136181,
            "fpr": 0.13391877058177826,
            "logloss": 0.4795704121230127,
            "mae": 0.2953077095979109,
            "precision": 0.7463617463617463,
            "recall": 0.789010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 4866,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8371860350743324,
            "auditor_fn_violation": 0.021474967478817292,
            "auditor_fp_violation": 0.016075676479333934,
            "ave_precision_score": 0.8379056342672819,
            "fpr": 0.10087719298245613,
            "logloss": 0.5720567743428729,
            "mae": 0.32655164865884634,
            "precision": 0.8004338394793926,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8360690172718415,
            "auditor_fn_violation": 0.012808048153822034,
            "auditor_fp_violation": 0.021130625686059275,
            "ave_precision_score": 0.8363085548536526,
            "fpr": 0.1251372118551043,
            "logloss": 0.5179732939863251,
            "mae": 0.32690852794527364,
            "precision": 0.7494505494505495,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8597572445941624,
            "auditor_fn_violation": 0.018194283303449004,
            "auditor_fp_violation": 0.019848349687778766,
            "ave_precision_score": 0.8600318608669448,
            "fpr": 0.11513157894736842,
            "logloss": 0.533638450696952,
            "mae": 0.3184645728380705,
            "precision": 0.7857142857142857,
            "recall": 0.7715430861723447
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8445747234180994,
            "auditor_fn_violation": 0.023309730883825288,
            "auditor_fp_violation": 0.021412271072852283,
            "ave_precision_score": 0.844796918553252,
            "fpr": 0.15697036223929747,
            "logloss": 0.5118534884291893,
            "mae": 0.32623280430814244,
            "precision": 0.7145708582834331,
            "recall": 0.7868131868131868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8534385850935851,
            "auditor_fn_violation": 0.01981594768484338,
            "auditor_fp_violation": 0.013511002081474873,
            "ave_precision_score": 0.8537813501626899,
            "fpr": 0.08771929824561403,
            "logloss": 0.5576424838607578,
            "mae": 0.31795032773994825,
            "precision": 0.813953488372093,
            "recall": 0.7014028056112225
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8436971295052598,
            "auditor_fn_violation": 0.013623478607013182,
            "auditor_fp_violation": 0.017100930151944076,
            "ave_precision_score": 0.8439390593198328,
            "fpr": 0.10098792535675083,
            "logloss": 0.49941598296605705,
            "mae": 0.31144851889130565,
            "precision": 0.780952380952381,
            "recall": 0.7208791208791209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8545031090279305,
            "auditor_fn_violation": 0.024694125092289847,
            "auditor_fp_violation": 0.015810182235249142,
            "ave_precision_score": 0.8547502354079679,
            "fpr": 0.10526315789473684,
            "logloss": 0.5635099510359365,
            "mae": 0.31942473999375226,
            "precision": 0.7939914163090128,
            "recall": 0.7414829659318637
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.835486645795783,
            "auditor_fn_violation": 0.02008178429693249,
            "auditor_fp_violation": 0.01850674986038092,
            "ave_precision_score": 0.8357229104051667,
            "fpr": 0.13611416026344675,
            "logloss": 0.5285811730111015,
            "mae": 0.32054489444688006,
            "precision": 0.7367303609341825,
            "recall": 0.7626373626373626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8475247626364835,
            "auditor_fn_violation": 0.014390623351967089,
            "auditor_fp_violation": 0.01475617008623253,
            "ave_precision_score": 0.8477403371593923,
            "fpr": 0.1074561403508772,
            "logloss": 0.5556851132118633,
            "mae": 0.3300896775607518,
            "precision": 0.7860262008733624,
            "recall": 0.7214428857715431
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8344032538333247,
            "auditor_fn_violation": 0.014402721318198818,
            "auditor_fp_violation": 0.0079582875960483,
            "ave_precision_score": 0.8346584454066772,
            "fpr": 0.1251372118551043,
            "logloss": 0.5176314288344829,
            "mae": 0.3257243837858371,
            "precision": 0.7516339869281046,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8580334091344133,
            "auditor_fn_violation": 0.031143427205287774,
            "auditor_fp_violation": 0.020535979779958375,
            "ave_precision_score": 0.8582125147640849,
            "fpr": 0.09978070175438597,
            "logloss": 0.5134657093399865,
            "mae": 0.31689499493541806,
            "precision": 0.8076109936575053,
            "recall": 0.7655310621242485
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.83566103921516,
            "auditor_fn_violation": 0.02823608882884404,
            "auditor_fp_violation": 0.020459009763706744,
            "ave_precision_score": 0.8359146159654086,
            "fpr": 0.12623490669593854,
            "logloss": 0.506757986888379,
            "mae": 0.32709146995962785,
            "precision": 0.7494553376906318,
            "recall": 0.756043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8548491610477957,
            "auditor_fn_violation": 0.020864096614281194,
            "auditor_fp_violation": 0.020071364852809994,
            "ave_precision_score": 0.8552315831672193,
            "fpr": 0.10526315789473684,
            "logloss": 0.5325430345375415,
            "mae": 0.3216877700120166,
            "precision": 0.7944325481798715,
            "recall": 0.7434869739478958
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8249853184048686,
            "auditor_fn_violation": 0.028421852571139078,
            "auditor_fp_violation": 0.02126061586457912,
            "ave_precision_score": 0.8252860492463734,
            "fpr": 0.12623490669593854,
            "logloss": 0.5196508356012891,
            "mae": 0.32744748028651804,
            "precision": 0.740990990990991,
            "recall": 0.7230769230769231
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8469444497463876,
            "auditor_fn_violation": 0.009582762015258595,
            "auditor_fp_violation": 0.02383872817637314,
            "ave_precision_score": 0.8472537499643316,
            "fpr": 0.12609649122807018,
            "logloss": 0.5554464438713569,
            "mae": 0.3217219266982539,
            "precision": 0.7718253968253969,
            "recall": 0.779559118236473
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.83090868882052,
            "auditor_fn_violation": 0.018154183906104876,
            "auditor_fp_violation": 0.017259807036801664,
            "ave_precision_score": 0.8311566471207998,
            "fpr": 0.15148188803512624,
            "logloss": 0.5416504814543027,
            "mae": 0.3286993489111288,
            "precision": 0.7206477732793523,
            "recall": 0.7824175824175824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8702571667124015,
            "auditor_fn_violation": 0.009283918714622237,
            "auditor_fp_violation": 0.009987893462469736,
            "ave_precision_score": 0.8706533678541322,
            "fpr": 0.0668859649122807,
            "logloss": 0.5570173737335401,
            "mae": 0.30075767492538336,
            "precision": 0.8486352357320099,
            "recall": 0.685370741482966
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8537685979112484,
            "auditor_fn_violation": 0.013526977961665129,
            "auditor_fp_violation": 0.014462610973096847,
            "ave_precision_score": 0.8540332809439537,
            "fpr": 0.0845225027442371,
            "logloss": 0.4935928395385415,
            "mae": 0.2940818407722893,
            "precision": 0.8075,
            "recall": 0.7098901098901099
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8619363981828276,
            "auditor_fn_violation": 0.021070650072073975,
            "auditor_fp_violation": 0.01689339875111508,
            "ave_precision_score": 0.8621886692342562,
            "fpr": 0.09978070175438597,
            "logloss": 0.5329403988561027,
            "mae": 0.30595820442919686,
            "precision": 0.8084210526315789,
            "recall": 0.7695390781563126
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8508424753029031,
            "auditor_fn_violation": 0.021994909590957894,
            "auditor_fp_violation": 0.02022310166194851,
            "ave_precision_score": 0.8510672174674363,
            "fpr": 0.13721185510428102,
            "logloss": 0.4981037204481235,
            "mae": 0.3088030731783409,
            "precision": 0.7412008281573499,
            "recall": 0.7868131868131868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8708575479419903,
            "auditor_fn_violation": 0.016185880532995824,
            "auditor_fp_violation": 0.01223928465230874,
            "ave_precision_score": 0.8710466581429599,
            "fpr": 0.07236842105263158,
            "logloss": 0.5555147719806491,
            "mae": 0.2945813742979609,
            "precision": 0.8465116279069768,
            "recall": 0.7294589178356713
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.854449536234985,
            "auditor_fn_violation": 0.016877962871376707,
            "auditor_fp_violation": 0.01282569761395806,
            "ave_precision_score": 0.8547248539529664,
            "fpr": 0.09659714599341383,
            "logloss": 0.49866634667346965,
            "mae": 0.29245218018108965,
            "precision": 0.7914691943127962,
            "recall": 0.734065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.858382342275218,
            "auditor_fn_violation": 0.019473156839995787,
            "auditor_fp_violation": 0.015122552143069543,
            "ave_precision_score": 0.8586102363035989,
            "fpr": 0.10526315789473684,
            "logloss": 0.5427242912957376,
            "mae": 0.30964264036996164,
            "precision": 0.7922077922077922,
            "recall": 0.7334669338677354
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8481886695325992,
            "auditor_fn_violation": 0.01151976453842535,
            "auditor_fp_violation": 0.01808307816742735,
            "ave_precision_score": 0.8484206771447685,
            "fpr": 0.13172338090010977,
            "logloss": 0.495340805629248,
            "mae": 0.30569470333830995,
            "precision": 0.7419354838709677,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.867919585830058,
            "auditor_fn_violation": 0.0050517702070808305,
            "auditor_fp_violation": 0.011129518712034324,
            "ave_precision_score": 0.868113272285727,
            "fpr": 0.08552631578947369,
            "logloss": 0.5086026516117642,
            "mae": 0.32333361603148086,
            "precision": 0.8251121076233184,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.848208047302518,
            "auditor_fn_violation": 0.01462467280249937,
            "auditor_fp_violation": 0.011525795828759613,
            "ave_precision_score": 0.848478958086984,
            "fpr": 0.10647639956092206,
            "logloss": 0.48337668755697066,
            "mae": 0.31750804260802484,
            "precision": 0.7863436123348018,
            "recall": 0.7846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8727368670642878,
            "auditor_fn_violation": 0.007673241219280668,
            "auditor_fp_violation": 0.012364066947028591,
            "ave_precision_score": 0.8729500277961032,
            "fpr": 0.09868421052631579,
            "logloss": 0.49077420434768204,
            "mae": 0.30757471178494916,
            "precision": 0.8097251585623678,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8544051369539514,
            "auditor_fn_violation": 0.016875550355242998,
            "auditor_fp_violation": 0.0032858628459183125,
            "ave_precision_score": 0.8546379273666567,
            "fpr": 0.10208562019758508,
            "logloss": 0.47632754208690903,
            "mae": 0.30832610895441137,
            "precision": 0.7919463087248322,
            "recall": 0.778021978021978
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8479760699162807,
            "auditor_fn_violation": 0.019468762085574663,
            "auditor_fp_violation": 0.017623507922348243,
            "ave_precision_score": 0.8492082881294023,
            "fpr": 0.1206140350877193,
            "logloss": 0.5087599224373583,
            "mae": 0.3161913242317193,
            "precision": 0.7855750487329435,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8430656756609994,
            "auditor_fn_violation": 0.019876720425567845,
            "auditor_fp_violation": 0.01253201609952433,
            "ave_precision_score": 0.8436427988196046,
            "fpr": 0.15916575192096596,
            "logloss": 0.4920342848463894,
            "mae": 0.3186904400053948,
            "precision": 0.7232824427480916,
            "recall": 0.832967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7712855139835989,
            "auditor_fn_violation": 0.04206878669619943,
            "auditor_fp_violation": 0.02878223100123189,
            "ave_precision_score": 0.7723020438475556,
            "fpr": 0.08771929824561403,
            "logloss": 1.2157592763751581,
            "mae": 0.36139113704996556,
            "precision": 0.7994987468671679,
            "recall": 0.6392785571142284
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7437982975910886,
            "auditor_fn_violation": 0.048754538545976535,
            "auditor_fp_violation": 0.03643335836847883,
            "ave_precision_score": 0.7445295636268414,
            "fpr": 0.12184412733260154,
            "logloss": 1.0434799569705517,
            "mae": 0.35258869953184246,
            "precision": 0.7350835322195705,
            "recall": 0.676923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8357094143423712,
            "auditor_fn_violation": 0.012619537320254547,
            "auditor_fp_violation": 0.018510258697591445,
            "ave_precision_score": 0.8363810647876414,
            "fpr": 0.11293859649122807,
            "logloss": 0.5096246904435661,
            "mae": 0.3166887570476862,
            "precision": 0.7948207171314741,
            "recall": 0.7995991983967936
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8486137535983366,
            "auditor_fn_violation": 0.01679111229056345,
            "auditor_fp_violation": 0.00970593332948178,
            "ave_precision_score": 0.848839408741229,
            "fpr": 0.13172338090010977,
            "logloss": 0.48983542576521394,
            "mae": 0.3175914743562504,
            "precision": 0.757085020242915,
            "recall": 0.8219780219780219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8531004994300424,
            "auditor_fn_violation": 0.01043094961853532,
            "auditor_fp_violation": 0.017177477592285804,
            "ave_precision_score": 0.8533818146815402,
            "fpr": 0.08662280701754387,
            "logloss": 0.5457769839289096,
            "mae": 0.3142808193811665,
            "precision": 0.8179723502304147,
            "recall": 0.7114228456913828
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8353875797012427,
            "auditor_fn_violation": 0.012894898734635288,
            "auditor_fp_violation": 0.013949871935601902,
            "ave_precision_score": 0.8358287354985763,
            "fpr": 0.11086717892425905,
            "logloss": 0.5066067878845533,
            "mae": 0.3107164805828114,
            "precision": 0.7730337078651686,
            "recall": 0.756043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8828103223065392,
            "auditor_fn_violation": 0.01503006012024048,
            "auditor_fp_violation": 0.009820632088696322,
            "ave_precision_score": 0.8830134853265921,
            "fpr": 0.08223684210526316,
            "logloss": 0.5054734329442989,
            "mae": 0.28041568760358804,
            "precision": 0.8306997742663657,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8650546040676321,
            "auditor_fn_violation": 0.01225075692693695,
            "auditor_fp_violation": 0.012510351069771027,
            "ave_precision_score": 0.8652901060137657,
            "fpr": 0.09330406147091108,
            "logloss": 0.4777316183282709,
            "mae": 0.2801029657455351,
            "precision": 0.8004694835680751,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8670464030664022,
            "auditor_fn_violation": 0.006954698871427066,
            "auditor_fp_violation": 0.012393271313877918,
            "ave_precision_score": 0.8672908916538719,
            "fpr": 0.08881578947368421,
            "logloss": 0.4945790806737222,
            "mae": 0.30308761808427925,
            "precision": 0.824295010845987,
            "recall": 0.7615230460921844
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8528859240246116,
            "auditor_fn_violation": 0.00658616904500549,
            "auditor_fp_violation": 0.013336029425924855,
            "ave_precision_score": 0.8531130058871501,
            "fpr": 0.10757409440175632,
            "logloss": 0.47348467234253866,
            "mae": 0.3006500864537427,
            "precision": 0.7860262008733624,
            "recall": 0.7912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8855400183569355,
            "auditor_fn_violation": 0.019409432900889496,
            "auditor_fp_violation": 0.014819888704812883,
            "ave_precision_score": 0.8857333141266708,
            "fpr": 0.08771929824561403,
            "logloss": 0.4669823827044558,
            "mae": 0.29230977450303425,
            "precision": 0.828693790149893,
            "recall": 0.7755511022044088
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8601739712173606,
            "auditor_fn_violation": 0.0231794550126054,
            "auditor_fp_violation": 0.020239952240645523,
            "ave_precision_score": 0.8604254762226812,
            "fpr": 0.12623490669593854,
            "logloss": 0.4690207712025023,
            "mae": 0.3021287081413519,
            "precision": 0.760914760914761,
            "recall": 0.8043956043956044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8446334731599761,
            "auditor_fn_violation": 0.023999753893752425,
            "auditor_fp_violation": 0.017445626778811434,
            "ave_precision_score": 0.845331415174522,
            "fpr": 0.10197368421052631,
            "logloss": 0.5605088324778327,
            "mae": 0.31841521223166064,
            "precision": 0.7978260869565217,
            "recall": 0.7354709418837675
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8437780186388388,
            "auditor_fn_violation": 0.019119190359585526,
            "auditor_fp_violation": 0.018660812294182216,
            "ave_precision_score": 0.8440080383792472,
            "fpr": 0.1251372118551043,
            "logloss": 0.5019495584582958,
            "mae": 0.3158873212795948,
            "precision": 0.7494505494505495,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 4866,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8688079808509515,
            "auditor_fn_violation": 0.01678356713426854,
            "auditor_fp_violation": 0.011742810415870183,
            "ave_precision_score": 0.8690894933665505,
            "fpr": 0.09539473684210527,
            "logloss": 0.5238838237290918,
            "mae": 0.3027206225571015,
            "precision": 0.8116883116883117,
            "recall": 0.751503006012024
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8512161036280774,
            "auditor_fn_violation": 0.015587266739846322,
            "auditor_fp_violation": 0.009679453848672174,
            "ave_precision_score": 0.8514386444292086,
            "fpr": 0.12403951701427003,
            "logloss": 0.48866212103336953,
            "mae": 0.3048877558823901,
            "precision": 0.7564655172413793,
            "recall": 0.7714285714285715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8812748138103785,
            "auditor_fn_violation": 0.01289201209436417,
            "auditor_fp_violation": 0.01540397604179942,
            "ave_precision_score": 0.8814526235042395,
            "fpr": 0.14802631578947367,
            "logloss": 0.4914305961477849,
            "mae": 0.2678220624914965,
            "precision": 0.7631578947368421,
            "recall": 0.8717434869739479
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8569022553057184,
            "auditor_fn_violation": 0.004928770461152459,
            "auditor_fp_violation": 0.013528607468176485,
            "ave_precision_score": 0.8570031265564813,
            "fpr": 0.18551042810098792,
            "logloss": 0.5144670410719093,
            "mae": 0.28319542162001754,
            "precision": 0.7040280210157618,
            "recall": 0.8835164835164835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 4866,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8712215246573748,
            "auditor_fn_violation": 0.009305892486727852,
            "auditor_fp_violation": 0.012226009940104497,
            "ave_precision_score": 0.8714287185432616,
            "fpr": 0.08552631578947369,
            "logloss": 0.540102619873039,
            "mae": 0.2922424809322253,
            "precision": 0.8173302107728337,
            "recall": 0.6993987975951904
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8558454677478363,
            "auditor_fn_violation": 0.009625939373469568,
            "auditor_fp_violation": 0.006066208330926112,
            "ave_precision_score": 0.8561096081034975,
            "fpr": 0.09659714599341383,
            "logloss": 0.4779272873441103,
            "mae": 0.28517841105643277,
            "precision": 0.7924528301886793,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8530111146485952,
            "auditor_fn_violation": 0.022369300003515807,
            "auditor_fp_violation": 0.01662259462214859,
            "ave_precision_score": 0.8533216344442792,
            "fpr": 0.09758771929824561,
            "logloss": 0.5507238301182915,
            "mae": 0.3206273497003406,
            "precision": 0.8030973451327433,
            "recall": 0.7274549098196392
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8419134782335849,
            "auditor_fn_violation": 0.018928601585023106,
            "auditor_fp_violation": 0.014775550291755738,
            "ave_precision_score": 0.8421381042550078,
            "fpr": 0.1119648737650933,
            "logloss": 0.5107089701496684,
            "mae": 0.31729558420954856,
            "precision": 0.7655172413793103,
            "recall": 0.7318681318681318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8587664489271312,
            "auditor_fn_violation": 0.020872886123123442,
            "auditor_fp_violation": 0.029005246166263123,
            "ave_precision_score": 0.8591290782155738,
            "fpr": 0.13706140350877194,
            "logloss": 0.5128020333605446,
            "mae": 0.3289468116492029,
            "precision": 0.7685185185185185,
            "recall": 0.8316633266533067
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8310269915431907,
            "auditor_fn_violation": 0.024279562369573352,
            "auditor_fp_violation": 0.024989408207676162,
            "ave_precision_score": 0.8313667079134665,
            "fpr": 0.17014270032930845,
            "logloss": 0.519192306080696,
            "mae": 0.33671762121475324,
            "precision": 0.7069943289224953,
            "recall": 0.8219780219780219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.864942843095405,
            "auditor_fn_violation": 0.01759659670217629,
            "auditor_fp_violation": 0.017134998513232236,
            "ave_precision_score": 0.8652184843835913,
            "fpr": 0.13815789473684212,
            "logloss": 0.499300077589283,
            "mae": 0.3021920543629166,
            "precision": 0.7713248638838476,
            "recall": 0.8517034068136272
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8493562853455693,
            "auditor_fn_violation": 0.017669268163230847,
            "auditor_fp_violation": 0.01345398347680398,
            "ave_precision_score": 0.8495651810342877,
            "fpr": 0.18990120746432493,
            "logloss": 0.5113338755906653,
            "mae": 0.31969119939118884,
            "precision": 0.6921708185053381,
            "recall": 0.8549450549450549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8374559306834831,
            "auditor_fn_violation": 0.023004342017368076,
            "auditor_fp_violation": 0.015425215581326203,
            "ave_precision_score": 0.8381814326941472,
            "fpr": 0.09978070175438597,
            "logloss": 0.5676213498702884,
            "mae": 0.3257174857426435,
            "precision": 0.8021739130434783,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8391044466309783,
            "auditor_fn_violation": 0.012607809314724796,
            "auditor_fp_violation": 0.018371945230804782,
            "ave_precision_score": 0.8393404710444382,
            "fpr": 0.13172338090010977,
            "logloss": 0.5119095719508877,
            "mae": 0.32530040479174166,
            "precision": 0.7379912663755459,
            "recall": 0.7428571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8686034283790005,
            "auditor_fn_violation": 0.02445461097633864,
            "auditor_fp_violation": 0.016880124038910836,
            "ave_precision_score": 0.8679631768063374,
            "fpr": 0.10416666666666667,
            "logloss": 0.4988096118418586,
            "mae": 0.3122717660560483,
            "precision": 0.8045267489711934,
            "recall": 0.7835671342685371
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8324262641128739,
            "auditor_fn_violation": 0.02604311166330925,
            "auditor_fp_violation": 0.01894967935755965,
            "ave_precision_score": 0.8315898653170155,
            "fpr": 0.11855104281009879,
            "logloss": 0.4989638353116008,
            "mae": 0.3213933564674745,
            "precision": 0.7631578947368421,
            "recall": 0.7648351648351648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8813637241998001,
            "auditor_fn_violation": 0.008668653095665014,
            "auditor_fp_violation": 0.014286245274202452,
            "ave_precision_score": 0.8814863498578119,
            "fpr": 0.08881578947368421,
            "logloss": 0.4826399247938744,
            "mae": 0.30409656619533626,
            "precision": 0.8269230769230769,
            "recall": 0.7755511022044088
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8576534439590597,
            "auditor_fn_violation": 0.008516181951966805,
            "auditor_fp_violation": 0.026243572707839852,
            "ave_precision_score": 0.8576025015472432,
            "fpr": 0.10208562019758508,
            "logloss": 0.4671445470878739,
            "mae": 0.30817598989833983,
            "precision": 0.7876712328767124,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8504685550291312,
            "auditor_fn_violation": 0.009828868262841468,
            "auditor_fp_violation": 0.011323329510216218,
            "ave_precision_score": 0.8508560566420422,
            "fpr": 0.08991228070175439,
            "logloss": 0.5902335793998091,
            "mae": 0.31281069633523495,
            "precision": 0.8132118451025057,
            "recall": 0.7154308617234469
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8393487286806898,
            "auditor_fn_violation": 0.006429355496314886,
            "auditor_fp_violation": 0.0043835576867525565,
            "ave_precision_score": 0.8395747220281193,
            "fpr": 0.10208562019758508,
            "logloss": 0.5356118902010517,
            "mae": 0.31035788136052755,
            "precision": 0.777511961722488,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8609749319294209,
            "auditor_fn_violation": 0.022808775445628104,
            "auditor_fp_violation": 0.010147190008920608,
            "ave_precision_score": 0.8612315892812441,
            "fpr": 0.06140350877192982,
            "logloss": 0.5833949606182703,
            "mae": 0.32052777854366005,
            "precision": 0.8478260869565217,
            "recall": 0.625250501002004
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8485371181768736,
            "auditor_fn_violation": 0.018916539004354593,
            "auditor_fp_violation": 0.011903730236678412,
            "ave_precision_score": 0.8487984074510799,
            "fpr": 0.06695938529088913,
            "logloss": 0.5142370584413835,
            "mae": 0.30728754097479266,
            "precision": 0.8291316526610645,
            "recall": 0.6505494505494506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8639216204330721,
            "auditor_fn_violation": 0.01971706571036811,
            "auditor_fp_violation": 0.016242937853107348,
            "ave_precision_score": 0.8641795382037178,
            "fpr": 0.09429824561403509,
            "logloss": 0.5323823518192883,
            "mae": 0.30333934208669744,
            "precision": 0.8162393162393162,
            "recall": 0.7655310621242485
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8520904739972845,
            "auditor_fn_violation": 0.022301299139938002,
            "auditor_fp_violation": 0.021756504323377054,
            "ave_precision_score": 0.8523092311574129,
            "fpr": 0.13391877058177826,
            "logloss": 0.495642626778862,
            "mae": 0.30563554894685147,
            "precision": 0.7447698744769874,
            "recall": 0.7824175824175824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8803969062994541,
            "auditor_fn_violation": 0.013043631121892914,
            "auditor_fp_violation": 0.016370375090268046,
            "ave_precision_score": 0.8804526374094939,
            "fpr": 0.08991228070175439,
            "logloss": 0.47541798883353537,
            "mae": 0.273438474238215,
            "precision": 0.8259023354564756,
            "recall": 0.779559118236473
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8583237884514068,
            "auditor_fn_violation": 0.01184545421647507,
            "auditor_fp_violation": 0.009686675525256615,
            "ave_precision_score": 0.8586386587235182,
            "fpr": 0.12294182217343579,
            "logloss": 0.46394983192030503,
            "mae": 0.2789646850843402,
            "precision": 0.7656903765690377,
            "recall": 0.8043956043956044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8446243800668432,
            "auditor_fn_violation": 0.02211220686988011,
            "auditor_fp_violation": 0.012356102119706046,
            "ave_precision_score": 0.8453173060396371,
            "fpr": 0.10635964912280702,
            "logloss": 0.5598988493843841,
            "mae": 0.323930033925934,
            "precision": 0.7949260042283298,
            "recall": 0.7535070140280561
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8372235822081525,
            "auditor_fn_violation": 0.015194026610052952,
            "auditor_fp_violation": 0.013509349663951318,
            "ave_precision_score": 0.8374421693584695,
            "fpr": 0.14270032930845225,
            "logloss": 0.5171768549789523,
            "mae": 0.3291920355985526,
            "precision": 0.7280334728033473,
            "recall": 0.7648351648351648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8735545409845051,
            "auditor_fn_violation": 0.02042901592659003,
            "auditor_fp_violation": 0.029414107302153703,
            "ave_precision_score": 0.8737288169559752,
            "fpr": 0.15570175438596492,
            "logloss": 0.5026867884924565,
            "mae": 0.3187717174819626,
            "precision": 0.7538994800693241,
            "recall": 0.8717434869739479
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8475162001798252,
            "auditor_fn_violation": 0.019522080553913707,
            "auditor_fp_violation": 0.024276869451345162,
            "ave_precision_score": 0.8477133095984608,
            "fpr": 0.18990120746432493,
            "logloss": 0.5288891792892785,
            "mae": 0.33748128118543474,
            "precision": 0.6894075403949731,
            "recall": 0.843956043956044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8652351193198535,
            "auditor_fn_violation": 0.02014775164363815,
            "auditor_fp_violation": 0.013638439318635577,
            "ave_precision_score": 0.8655530325658265,
            "fpr": 0.09429824561403509,
            "logloss": 0.5343947598398718,
            "mae": 0.30104019382614705,
            "precision": 0.810989010989011,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.850707574554534,
            "auditor_fn_violation": 0.017080614226607643,
            "auditor_fp_violation": 0.01399560922063666,
            "ave_precision_score": 0.8509292579497989,
            "fpr": 0.11525795828759605,
            "logloss": 0.4937984466425618,
            "mae": 0.3018192228312685,
            "precision": 0.7687224669603524,
            "recall": 0.7670329670329671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8751356042001117,
            "auditor_fn_violation": 0.015084994550504516,
            "auditor_fp_violation": 0.013911898390042908,
            "ave_precision_score": 0.8753150299928977,
            "fpr": 0.11074561403508772,
            "logloss": 0.4920824386947998,
            "mae": 0.3014776911015935,
            "precision": 0.795959595959596,
            "recall": 0.7895791583166333
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8473949804191674,
            "auditor_fn_violation": 0.012841823379693853,
            "auditor_fp_violation": 0.012488686040017719,
            "ave_precision_score": 0.8480909650760629,
            "fpr": 0.132821075740944,
            "logloss": 0.4750073525921836,
            "mae": 0.30242806071753925,
            "precision": 0.7565392354124748,
            "recall": 0.8263736263736263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8624163944321631,
            "auditor_fn_violation": 0.02181336356924376,
            "auditor_fp_violation": 0.01419066734633193,
            "ave_precision_score": 0.8627476253709052,
            "fpr": 0.07456140350877193,
            "logloss": 0.5630126288872994,
            "mae": 0.30654846682875614,
            "precision": 0.8341463414634146,
            "recall": 0.685370741482966
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8578796745752583,
            "auditor_fn_violation": 0.01664636132254135,
            "auditor_fp_violation": 0.014443353168871687,
            "ave_precision_score": 0.858080771758051,
            "fpr": 0.08122941822173436,
            "logloss": 0.49248270928270227,
            "mae": 0.297033780790113,
            "precision": 0.811704834605598,
            "recall": 0.701098901098901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8552799476051173,
            "auditor_fn_violation": 0.0234591990999543,
            "auditor_fp_violation": 0.009140966823839261,
            "ave_precision_score": 0.8556029282371327,
            "fpr": 0.03399122807017544,
            "logloss": 0.6629938190288434,
            "mae": 0.35214057702468016,
            "precision": 0.8876811594202898,
            "recall": 0.4909819639278557
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8344710038855963,
            "auditor_fn_violation": 0.01677663719376124,
            "auditor_fp_violation": 0.0027707165828952194,
            "ave_precision_score": 0.8347917909086434,
            "fpr": 0.04061470911086718,
            "logloss": 0.5945492507838134,
            "mae": 0.33253054867555315,
            "precision": 0.8644688644688645,
            "recall": 0.5186813186813187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8718681838141185,
            "auditor_fn_violation": 0.013702844285061353,
            "auditor_fp_violation": 0.014055265281848696,
            "ave_precision_score": 0.8720454187436413,
            "fpr": 0.1162280701754386,
            "logloss": 0.4981223541048865,
            "mae": 0.3119515370758324,
            "precision": 0.7867203219315896,
            "recall": 0.7835671342685371
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8428067997420139,
            "auditor_fn_violation": 0.01336533938070711,
            "auditor_fp_violation": 0.010909546093554413,
            "ave_precision_score": 0.8435045753096352,
            "fpr": 0.13611416026344675,
            "logloss": 0.48410083403409016,
            "mae": 0.31483747358980835,
            "precision": 0.7489878542510121,
            "recall": 0.8131868131868132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.857977702743757,
            "auditor_fn_violation": 0.022514326899412872,
            "auditor_fp_violation": 0.011373773416592329,
            "ave_precision_score": 0.8582362722324677,
            "fpr": 0.0537280701754386,
            "logloss": 0.556238550108165,
            "mae": 0.3314756124215037,
            "precision": 0.8664850136239782,
            "recall": 0.6372745490981964
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8432799066587175,
            "auditor_fn_violation": 0.02293337836696783,
            "auditor_fp_violation": 0.007582760413657636,
            "ave_precision_score": 0.8435276525935071,
            "fpr": 0.07244785949506037,
            "logloss": 0.5099816042461451,
            "mae": 0.3216947905972813,
            "precision": 0.8211382113821138,
            "recall": 0.6659340659340659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8834744352565406,
            "auditor_fn_violation": 0.010551805365116197,
            "auditor_fp_violation": 0.009815322203814621,
            "ave_precision_score": 0.8835076893903747,
            "fpr": 0.08991228070175439,
            "logloss": 0.47105269162524516,
            "mae": 0.28830933313522683,
            "precision": 0.826271186440678,
            "recall": 0.781563126252505
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.861691245848818,
            "auditor_fn_violation": 0.013124087767336944,
            "auditor_fp_violation": 0.01137414062048645,
            "ave_precision_score": 0.8616416436676416,
            "fpr": 0.10867178924259056,
            "logloss": 0.4616676848269726,
            "mae": 0.2912939230137802,
            "precision": 0.7824175824175824,
            "recall": 0.7824175824175824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8605378043647742,
            "auditor_fn_violation": 0.012902998980416972,
            "auditor_fp_violation": 0.011392358013678265,
            "ave_precision_score": 0.8603618392973938,
            "fpr": 0.07346491228070176,
            "logloss": 0.5493774516834896,
            "mae": 0.30163587938959446,
            "precision": 0.8353808353808354,
            "recall": 0.6813627254509018
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8460801700067679,
            "auditor_fn_violation": 0.01335810183230601,
            "auditor_fp_violation": 0.014221888420282316,
            "ave_precision_score": 0.846238956234757,
            "fpr": 0.09330406147091108,
            "logloss": 0.4957931700650801,
            "mae": 0.2941615630753193,
            "precision": 0.7980997624703088,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8676098820482214,
            "auditor_fn_violation": 0.013546830503111491,
            "auditor_fp_violation": 0.010980841935346845,
            "ave_precision_score": 0.8678154562828145,
            "fpr": 0.08114035087719298,
            "logloss": 0.5384383207691095,
            "mae": 0.3039184190956962,
            "precision": 0.8271028037383178,
            "recall": 0.7094188376753507
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8542884660327054,
            "auditor_fn_violation": 0.013744104413698268,
            "auditor_fp_violation": 0.00857453733125349,
            "ave_precision_score": 0.8545650125706654,
            "fpr": 0.09440175631174534,
            "logloss": 0.47716434111467987,
            "mae": 0.2968426953789571,
            "precision": 0.7917675544794189,
            "recall": 0.7186813186813187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8691618045256237,
            "auditor_fn_violation": 0.010408975846429707,
            "auditor_fp_violation": 0.00973036404570749,
            "ave_precision_score": 0.8693726027380968,
            "fpr": 0.08662280701754387,
            "logloss": 0.5314727469709529,
            "mae": 0.3017236485286144,
            "precision": 0.8188073394495413,
            "recall": 0.7154308617234469
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8552475801200055,
            "auditor_fn_violation": 0.009913028793380059,
            "auditor_fp_violation": 0.0085432433993876,
            "ave_precision_score": 0.8555201962870649,
            "fpr": 0.10208562019758508,
            "logloss": 0.4752573025392272,
            "mae": 0.2963450319340333,
            "precision": 0.7832167832167832,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8674595660759058,
            "auditor_fn_violation": 0.02391845093696164,
            "auditor_fp_violation": 0.018696104668450793,
            "ave_precision_score": 0.8678124514281385,
            "fpr": 0.1074561403508772,
            "logloss": 0.49853519369738786,
            "mae": 0.3116574290919775,
            "precision": 0.8008130081300813,
            "recall": 0.7895791583166333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8342587627274087,
            "auditor_fn_violation": 0.028339827022593217,
            "auditor_fp_violation": 0.021130625686059282,
            "ave_precision_score": 0.8345604548659654,
            "fpr": 0.12952799121844127,
            "logloss": 0.4982103643027988,
            "mae": 0.32050555190797303,
            "precision": 0.7489361702127659,
            "recall": 0.7736263736263737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 4866,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8648803040366911,
            "auditor_fn_violation": 0.014304925640755195,
            "auditor_fp_violation": 0.01197379040822395,
            "ave_precision_score": 0.8651281973246322,
            "fpr": 0.09539473684210527,
            "logloss": 0.5380894085723309,
            "mae": 0.30457306478912644,
            "precision": 0.8070953436807096,
            "recall": 0.7294589178356713
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8546864800683548,
            "auditor_fn_violation": 0.013662078865152411,
            "auditor_fp_violation": 0.0075683170604887735,
            "ave_precision_score": 0.8549035373308627,
            "fpr": 0.11855104281009879,
            "logloss": 0.4922937713230051,
            "mae": 0.30401421073605905,
            "precision": 0.7626373626373626,
            "recall": 0.7626373626373626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8545679721072206,
            "auditor_fn_violation": 0.008706008508244557,
            "auditor_fp_violation": 0.01157023915721507,
            "ave_precision_score": 0.8548541806320028,
            "fpr": 0.10087719298245613,
            "logloss": 0.5480442989105324,
            "mae": 0.31905379369524317,
            "precision": 0.7982456140350878,
            "recall": 0.7294589178356713
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8303373425141273,
            "auditor_fn_violation": 0.00831111808060217,
            "auditor_fp_violation": 0.005093689217555414,
            "ave_precision_score": 0.8306985972228826,
            "fpr": 0.10976948408342481,
            "logloss": 0.514528215613815,
            "mae": 0.31915535514550153,
            "precision": 0.771689497716895,
            "recall": 0.7428571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8489838982472829,
            "auditor_fn_violation": 0.021529901909081328,
            "auditor_fp_violation": 0.017963340554776774,
            "ave_precision_score": 0.8493522483440957,
            "fpr": 0.1118421052631579,
            "logloss": 0.5679576517696853,
            "mae": 0.3269182403507186,
            "precision": 0.7857142857142857,
            "recall": 0.749498997995992
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8178184737648908,
            "auditor_fn_violation": 0.026986405471586594,
            "auditor_fp_violation": 0.02030735455543359,
            "ave_precision_score": 0.81813016638966,
            "fpr": 0.12733260153677278,
            "logloss": 0.5474940955151101,
            "mae": 0.33284700607625883,
            "precision": 0.7381489841986456,
            "recall": 0.7186813186813187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8558604513800776,
            "auditor_fn_violation": 0.024461203107970328,
            "auditor_fp_violation": 0.016070366594452233,
            "ave_precision_score": 0.8561673584686698,
            "fpr": 0.09539473684210527,
            "logloss": 0.5210605077122707,
            "mae": 0.3166528024328791,
            "precision": 0.8066666666666666,
            "recall": 0.7274549098196392
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8377342289825485,
            "auditor_fn_violation": 0.024419488305328044,
            "auditor_fp_violation": 0.009705933329481773,
            "ave_precision_score": 0.8384866858312392,
            "fpr": 0.10537870472008781,
            "logloss": 0.48895929960343204,
            "mae": 0.3123276571880691,
            "precision": 0.7777777777777778,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8492542188360035,
            "auditor_fn_violation": 0.008503849804872912,
            "auditor_fp_violation": 0.011604753408946096,
            "ave_precision_score": 0.849537699004962,
            "fpr": 0.07017543859649122,
            "logloss": 0.6249236132573861,
            "mae": 0.31503250827671236,
            "precision": 0.8328981723237598,
            "recall": 0.6392785571142284
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8342833644443117,
            "auditor_fn_violation": 0.013654841316751307,
            "auditor_fp_violation": 0.008049762166117821,
            "ave_precision_score": 0.8346096536765045,
            "fpr": 0.08342480790340286,
            "logloss": 0.5457851401067605,
            "mae": 0.30226995014020985,
            "precision": 0.7962466487935657,
            "recall": 0.6527472527472528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8319465635701497,
            "auditor_fn_violation": 0.0126964455226242,
            "auditor_fp_violation": 0.01884478144513827,
            "ave_precision_score": 0.8321943606559714,
            "fpr": 0.09868421052631579,
            "logloss": 0.6286518567383823,
            "mae": 0.3538530210574033,
            "precision": 0.8021978021978022,
            "recall": 0.7314629258517034
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8227369481948197,
            "auditor_fn_violation": 0.013341214219370094,
            "auditor_fp_violation": 0.01119119148034741,
            "ave_precision_score": 0.8229865288298066,
            "fpr": 0.12623490669593854,
            "logloss": 0.5713999043501402,
            "mae": 0.3492548865440959,
            "precision": 0.75,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8503024322385127,
            "auditor_fn_violation": 0.00684922476532012,
            "auditor_fp_violation": 0.013752601843592033,
            "ave_precision_score": 0.8558852307406914,
            "fpr": 0.0712719298245614,
            "logloss": 0.5040039456929678,
            "mae": 0.3033109618190314,
            "precision": 0.8410757946210269,
            "recall": 0.6893787575150301
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8383089092151037,
            "auditor_fn_violation": 0.011519764538425358,
            "auditor_fp_violation": 0.013704334931731087,
            "ave_precision_score": 0.838920667444019,
            "fpr": 0.0867178924259056,
            "logloss": 0.4873607151297765,
            "mae": 0.29896368787590205,
            "precision": 0.8073170731707318,
            "recall": 0.7274725274725274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8689864781165841,
            "auditor_fn_violation": 0.014590584678128193,
            "auditor_fp_violation": 0.011461386517140312,
            "ave_precision_score": 0.8692421797182628,
            "fpr": 0.09758771929824561,
            "logloss": 0.5202565676498687,
            "mae": 0.3047575741436224,
            "precision": 0.8086021505376344,
            "recall": 0.7535070140280561
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.849132540751647,
            "auditor_fn_violation": 0.01654986067719328,
            "auditor_fp_violation": 0.00675948928303195,
            "ave_precision_score": 0.8493605848933122,
            "fpr": 0.13172338090010977,
            "logloss": 0.4940501885278502,
            "mae": 0.3084451219122693,
            "precision": 0.7446808510638298,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8514965562021188,
            "auditor_fn_violation": 0.016631948106739795,
            "auditor_fp_violation": 0.011402977783441655,
            "ave_precision_score": 0.8517187800758257,
            "fpr": 0.1206140350877193,
            "logloss": 0.601165048815807,
            "mae": 0.2842677025185191,
            "precision": 0.7745901639344263,
            "recall": 0.7575150300601202
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8156621396112479,
            "auditor_fn_violation": 0.011425676409210989,
            "auditor_fp_violation": 0.023783388218075373,
            "ave_precision_score": 0.8160046210758269,
            "fpr": 0.14050493962678376,
            "logloss": 0.6066769156470724,
            "mae": 0.2959068283294537,
            "precision": 0.7229437229437229,
            "recall": 0.734065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.8572169859338827,
            "auditor_fn_violation": 0.0032345392539464895,
            "auditor_fp_violation": 0.006536468289367499,
            "ave_precision_score": 0.8575560018157253,
            "fpr": 0.41776315789473684,
            "logloss": 1.8053245656387535,
            "mae": 0.4173383063123157,
            "precision": 0.5620689655172414,
            "recall": 0.9799599198396793
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.8556993431123601,
            "auditor_fn_violation": 0.001954138068298332,
            "auditor_fp_violation": 0.007914957536541686,
            "ave_precision_score": 0.8558987467671264,
            "fpr": 0.4676180021953897,
            "logloss": 2.0145820217363473,
            "mae": 0.45880461365349146,
            "precision": 0.5136986301369864,
            "recall": 0.989010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 4866,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8520514939603996,
            "auditor_fn_violation": 0.022824157086102026,
            "auditor_fp_violation": 0.013064971751412434,
            "ave_precision_score": 0.8523645826088013,
            "fpr": 0.08991228070175439,
            "logloss": 0.5570158571311028,
            "mae": 0.3217178408042201,
            "precision": 0.8140589569160998,
            "recall": 0.7194388777555111
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8410384079904214,
            "auditor_fn_violation": 0.018981676939964543,
            "auditor_fp_violation": 0.013280663238777511,
            "ave_precision_score": 0.8412625284791121,
            "fpr": 0.10647639956092206,
            "logloss": 0.513369259268,
            "mae": 0.3176407431866708,
            "precision": 0.7723004694835681,
            "recall": 0.7230769230769231
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8487232348622896,
            "auditor_fn_violation": 0.017844900326969733,
            "auditor_fp_violation": 0.01739518287243533,
            "ave_precision_score": 0.8489629916085073,
            "fpr": 0.09978070175438597,
            "logloss": 0.5503808335281568,
            "mae": 0.325586291626614,
            "precision": 0.7941176470588235,
            "recall": 0.7034068136272545
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8367114000196505,
            "auditor_fn_violation": 0.014347233447123681,
            "auditor_fp_violation": 0.013872840718701257,
            "ave_precision_score": 0.836959050102861,
            "fpr": 0.10867178924259056,
            "logloss": 0.5104945584346984,
            "mae": 0.3188942829908601,
            "precision": 0.7670588235294118,
            "recall": 0.7164835164835165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.8338813036028876,
            "auditor_fn_violation": 0.037867401469605884,
            "auditor_fp_violation": 0.004914298458009431,
            "ave_precision_score": 0.8361505391238235,
            "fpr": 0.02412280701754386,
            "logloss": 0.7785802091618856,
            "mae": 0.3913247175433003,
            "precision": 0.8981481481481481,
            "recall": 0.38877755511022044
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7908016043402964,
            "auditor_fn_violation": 0.03922992485012244,
            "auditor_fp_violation": 0.007293893350280202,
            "ave_precision_score": 0.7969599077832255,
            "fpr": 0.03293084522502744,
            "logloss": 0.694665010540008,
            "mae": 0.3669716452080225,
            "precision": 0.8744769874476988,
            "recall": 0.4593406593406593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8632923283278041,
            "auditor_fn_violation": 0.016886843863164937,
            "auditor_fp_violation": 0.008832993500700909,
            "ave_precision_score": 0.8635120039699421,
            "fpr": 0.06578947368421052,
            "logloss": 0.568879420624941,
            "mae": 0.3189672507309807,
            "precision": 0.8433420365535248,
            "recall": 0.6472945891783567
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8426883032380829,
            "auditor_fn_violation": 0.015058925706565673,
            "auditor_fp_violation": 0.012315365801991258,
            "ave_precision_score": 0.8431282594903216,
            "fpr": 0.0801317233809001,
            "logloss": 0.5038640654027032,
            "mae": 0.3086674736700768,
            "precision": 0.8089005235602095,
            "recall": 0.6791208791208792
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8657371583274085,
            "auditor_fn_violation": 0.018128361987132163,
            "auditor_fp_violation": 0.012794167622445951,
            "ave_precision_score": 0.8660509902434307,
            "fpr": 0.09758771929824561,
            "logloss": 0.5244540516569363,
            "mae": 0.30220058236291314,
            "precision": 0.8114406779661016,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8523406264730264,
            "auditor_fn_violation": 0.021266329718579998,
            "auditor_fp_violation": 0.014857395959712675,
            "ave_precision_score": 0.8525700487987559,
            "fpr": 0.12733260153677278,
            "logloss": 0.4923666901749777,
            "mae": 0.30482159574458867,
            "precision": 0.7531914893617021,
            "recall": 0.778021978021978
        }
    }
]