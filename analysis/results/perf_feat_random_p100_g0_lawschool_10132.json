[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8218479797575033,
            "auditor_fn_violation": 0.01571561439982493,
            "auditor_fp_violation": 0.02890055765864778,
            "ave_precision_score": 0.8223845345027707,
            "fpr": 0.13486842105263158,
            "logloss": 0.9207393765574242,
            "mae": 0.27575738128596194,
            "precision": 0.7458677685950413,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.84361795534279,
            "auditor_fn_violation": 0.020691431714330143,
            "auditor_fp_violation": 0.02339744071696015,
            "ave_precision_score": 0.8439205760820845,
            "fpr": 0.13172338090010977,
            "logloss": 0.7991008672871133,
            "mae": 0.25765703117293504,
            "precision": 0.7575757575757576,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7858037401719193,
            "auditor_fn_violation": 0.008493817704344021,
            "auditor_fp_violation": 0.009148451174339569,
            "ave_precision_score": 0.7765800015026486,
            "fpr": 0.14802631578947367,
            "logloss": 0.5653029372312292,
            "mae": 0.3500368971103933,
            "precision": 0.733201581027668,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8459355419384158,
            "auditor_fn_violation": 0.00391735494995394,
            "auditor_fp_violation": 0.007578605476444681,
            "ave_precision_score": 0.8372515708746219,
            "fpr": 0.13611416026344675,
            "logloss": 0.5097988009608083,
            "mae": 0.3245276492446841,
            "precision": 0.7554240631163708,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5331112818339558,
            "auditor_fn_violation": 0.004379126089652407,
            "auditor_fp_violation": 0.006594211747466117,
            "ave_precision_score": 0.5494906272714499,
            "fpr": 0.40021929824561403,
            "logloss": 0.7532099021700814,
            "mae": 0.48755779128783105,
            "precision": 0.5338441890166028,
            "recall": 0.8690228690228691
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5745799116479391,
            "auditor_fn_violation": 0.0059618986175543,
            "auditor_fp_violation": 0.003252986080828449,
            "ave_precision_score": 0.5402047948656382,
            "fpr": 0.38638858397365533,
            "logloss": 0.742377923714269,
            "mae": 0.48272295759093226,
            "precision": 0.5404699738903395,
            "recall": 0.8752642706131079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6541276458760872,
            "auditor_fn_violation": 0.015077324287850611,
            "auditor_fp_violation": 0.01269996336549029,
            "ave_precision_score": 0.6492277984499043,
            "fpr": 0.043859649122807015,
            "logloss": 9.544174082947322,
            "mae": 0.44559636932783003,
            "precision": 0.7674418604651163,
            "recall": 0.27442827442827444
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6510589271051239,
            "auditor_fn_violation": 0.014318767796928785,
            "auditor_fp_violation": 0.013658531695311994,
            "ave_precision_score": 0.6480483542628233,
            "fpr": 0.043907793633369926,
            "logloss": 9.466060706808733,
            "mae": 0.43767899440788993,
            "precision": 0.7647058823529411,
            "recall": 0.2748414376321353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 10132,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6771671354509828,
            "auditor_fn_violation": 0.03725106685633001,
            "auditor_fp_violation": 0.0711421826026784,
            "ave_precision_score": 0.6778829368119402,
            "fpr": 0.21271929824561403,
            "logloss": 0.8681832608447191,
            "mae": 0.41277771265850516,
            "precision": 0.6196078431372549,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6479033972865051,
            "auditor_fn_violation": 0.037521205468516124,
            "auditor_fp_violation": 0.0802269571798766,
            "ave_precision_score": 0.6490805188014042,
            "fpr": 0.24807903402854006,
            "logloss": 0.9682547526564249,
            "mae": 0.42128395042193056,
            "precision": 0.5971479500891266,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7505403941444957,
            "auditor_fn_violation": 0.01110396834081046,
            "auditor_fp_violation": 0.017910204746204257,
            "ave_precision_score": 0.6683380910237517,
            "fpr": 0.13706140350877194,
            "logloss": 0.6419689033901248,
            "mae": 0.45546780168814094,
            "precision": 0.7044917257683215,
            "recall": 0.6195426195426196
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7671761449649978,
            "auditor_fn_violation": 0.010672935672297481,
            "auditor_fp_violation": 0.019412658075575538,
            "ave_precision_score": 0.6830086887266068,
            "fpr": 0.14489571899012074,
            "logloss": 0.6182938026993062,
            "mae": 0.4429153700069853,
            "precision": 0.7098901098901099,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.750932260084233,
            "auditor_fn_violation": 0.010041671225881753,
            "auditor_fp_violation": 0.022743924777140087,
            "ave_precision_score": 0.74777310216424,
            "fpr": 0.24342105263157895,
            "logloss": 1.4174235598922496,
            "mae": 0.3354804707329721,
            "precision": 0.6481774960380349,
            "recall": 0.8503118503118503
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7566294300688621,
            "auditor_fn_violation": 0.008781558726673985,
            "auditor_fp_violation": 0.02876812574871311,
            "ave_precision_score": 0.7506444335664754,
            "fpr": 0.2645444566410538,
            "logloss": 1.5365956466740542,
            "mae": 0.33193576649061085,
            "precision": 0.6408345752608048,
            "recall": 0.9090909090909091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6568006664916739,
            "auditor_fn_violation": 0.0032917532917532927,
            "auditor_fp_violation": 0.008049415883095214,
            "ave_precision_score": 0.6586811393572138,
            "fpr": 0.4473684210526316,
            "logloss": 0.6885515660445405,
            "mae": 0.47202494864662486,
            "precision": 0.5374149659863946,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.689411603295786,
            "auditor_fn_violation": 0.0012392580232674175,
            "auditor_fp_violation": 0.00139342084818229,
            "ave_precision_score": 0.6904522676601972,
            "fpr": 0.45334796926454446,
            "logloss": 0.6778348717268414,
            "mae": 0.4689074728216743,
            "precision": 0.5328054298642534,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7720448907345641,
            "auditor_fn_violation": 0.011744538060327539,
            "auditor_fp_violation": 0.02133451377864615,
            "ave_precision_score": 0.7572492651505561,
            "fpr": 0.19078947368421054,
            "logloss": 2.3084072764051147,
            "mae": 0.27670416932065994,
            "precision": 0.7025641025641025,
            "recall": 0.8544698544698545
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7753805497884799,
            "auditor_fn_violation": 0.008212985289032566,
            "auditor_fp_violation": 0.026612834508718906,
            "ave_precision_score": 0.7537348485420922,
            "fpr": 0.21185510428100987,
            "logloss": 2.3816364849310028,
            "mae": 0.27317820777722057,
            "precision": 0.684640522875817,
            "recall": 0.8858350951374208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6372733013257492,
            "auditor_fn_violation": 0.02620636831163147,
            "auditor_fp_violation": 0.024964891928196363,
            "ave_precision_score": 0.564832281738121,
            "fpr": 0.36951754385964913,
            "logloss": 0.6875599425049328,
            "mae": 0.49595850421801996,
            "precision": 0.5427408412483039,
            "recall": 0.8316008316008316
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6237422300783801,
            "auditor_fn_violation": 0.026829704132948714,
            "auditor_fp_violation": 0.027166694234345323,
            "ave_precision_score": 0.5500192029040522,
            "fpr": 0.37980241492864986,
            "logloss": 0.6893079197616508,
            "mae": 0.49678473522974553,
            "precision": 0.5311653116531165,
            "recall": 0.828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.696426778132896,
            "auditor_fn_violation": 0.017860725097567205,
            "auditor_fp_violation": 0.008151178410062295,
            "ave_precision_score": 0.6913122086724658,
            "fpr": 0.3201754385964912,
            "logloss": 0.6597012129222345,
            "mae": 0.472191467227643,
            "precision": 0.5852272727272727,
            "recall": 0.8565488565488566
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7060679785041556,
            "auditor_fn_violation": 0.011543201138075158,
            "auditor_fp_violation": 0.0159892536176313,
            "ave_precision_score": 0.7002942699347282,
            "fpr": 0.31833150384193193,
            "logloss": 0.6485466566785234,
            "mae": 0.46674469525544493,
            "precision": 0.5944055944055944,
            "recall": 0.8985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7359800475805475,
            "auditor_fn_violation": 0.01040868804026699,
            "auditor_fp_violation": 0.023545304677005743,
            "ave_precision_score": 0.7213516577483285,
            "fpr": 0.14144736842105263,
            "logloss": 0.6160087367713125,
            "mae": 0.4130361522792986,
            "precision": 0.708803611738149,
            "recall": 0.6528066528066528
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7396087715419303,
            "auditor_fn_violation": 0.007760447246828178,
            "auditor_fp_violation": 0.019938950122550862,
            "ave_precision_score": 0.7278866440437729,
            "fpr": 0.14928649835345773,
            "logloss": 0.5863894290490949,
            "mae": 0.40022874015877197,
            "precision": 0.7154811715481172,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8154964208367238,
            "auditor_fn_violation": 0.00022568114673378326,
            "auditor_fp_violation": 0.0003129197704237385,
            "ave_precision_score": 0.7940810507924704,
            "fpr": 0.08881578947368421,
            "logloss": 0.5367411319834133,
            "mae": 0.3338578340312779,
            "precision": 0.8052884615384616,
            "recall": 0.6964656964656964
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8462961413573402,
            "auditor_fn_violation": 0.0017869450897301745,
            "auditor_fp_violation": 0.016315053456235056,
            "ave_precision_score": 0.8278045754129749,
            "fpr": 0.0889132821075741,
            "logloss": 0.4879830492258198,
            "mae": 0.31420455327861607,
            "precision": 0.812933025404157,
            "recall": 0.7441860465116279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 10132,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8256406190579688,
            "auditor_fn_violation": 0.0022932851880220345,
            "auditor_fp_violation": 0.0019207676965034386,
            "ave_precision_score": 0.8121171810414638,
            "fpr": 0.08771929824561403,
            "logloss": 0.5472427198668688,
            "mae": 0.3442133705096091,
            "precision": 0.8090692124105012,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.819221037674427,
            "auditor_fn_violation": 0.002694341882047699,
            "auditor_fp_violation": 0.018863810655158412,
            "ave_precision_score": 0.8081334028616736,
            "fpr": 0.09110867178924259,
            "logloss": 0.5325898889980042,
            "mae": 0.3371936419907195,
            "precision": 0.8087557603686636,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.686632850428057,
            "auditor_fn_violation": 0.0026329467118940846,
            "auditor_fp_violation": 0.05120435950665528,
            "ave_precision_score": 0.6872589556957093,
            "fpr": 0.20942982456140352,
            "logloss": 0.6359792293349146,
            "mae": 0.4589404430109681,
            "precision": 0.6570915619389587,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6796930760252676,
            "auditor_fn_violation": 0.006523509931469502,
            "auditor_fp_violation": 0.055473687903803845,
            "ave_precision_score": 0.6802166020834997,
            "fpr": 0.23819978046103182,
            "logloss": 0.6334679193560316,
            "mae": 0.45895456467907464,
            "precision": 0.629059829059829,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.6916454164606105,
            "mae": 0.4984444037341235,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6925773849050934,
            "mae": 0.4989098873148896,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7561445273854119,
            "auditor_fn_violation": 0.001009866141445089,
            "auditor_fp_violation": 0.014613098872471206,
            "ave_precision_score": 0.7501237670527432,
            "fpr": 0.39035087719298245,
            "logloss": 1.898820730123839,
            "mae": 0.3888667648364055,
            "precision": 0.5700483091787439,
            "recall": 0.9812889812889813
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7627555935664273,
            "auditor_fn_violation": 0.0019192254405283788,
            "auditor_fp_violation": 0.015061977153912857,
            "ave_precision_score": 0.7568659076442465,
            "fpr": 0.41931942919868276,
            "logloss": 2.0112261126165922,
            "mae": 0.4059494110243446,
            "precision": 0.5505882352941176,
            "recall": 0.9894291754756871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.4418677313571896,
            "auditor_fn_violation": 0.005851752562278884,
            "auditor_fp_violation": 0.011959640981804878,
            "ave_precision_score": 0.4415206625601742,
            "fpr": 0.34539473684210525,
            "logloss": 3.633167958831129,
            "mae": 0.484246425085554,
            "precision": 0.5374449339207048,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.43930644860946844,
            "auditor_fn_violation": 0.0028591121435682797,
            "auditor_fp_violation": 0.011956854076758457,
            "ave_precision_score": 0.440792405066867,
            "fpr": 0.33699231613611413,
            "logloss": 3.457973170412741,
            "mae": 0.4783932706635545,
            "precision": 0.5348484848484848,
            "recall": 0.7463002114164905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8123601922973331,
            "auditor_fn_violation": 0.04148201845570267,
            "auditor_fp_violation": 0.023563113119224984,
            "ave_precision_score": 0.812612788590955,
            "fpr": 0.09539473684210527,
            "logloss": 1.652450743667614,
            "mae": 0.3278211209003874,
            "precision": 0.795774647887324,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8606459803155626,
            "auditor_fn_violation": 0.04149425740827982,
            "auditor_fp_violation": 0.02040509450701472,
            "ave_precision_score": 0.8606509197407306,
            "fpr": 0.08562019758507135,
            "logloss": 1.8217583484034259,
            "mae": 0.30684311548300064,
            "precision": 0.8106796116504854,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7592830790051716,
            "auditor_fn_violation": 0.0010281030017872143,
            "auditor_fp_violation": 0.01612427239793219,
            "ave_precision_score": 0.7597609120311475,
            "fpr": 0.20285087719298245,
            "logloss": 0.6003739406137486,
            "mae": 0.3951455665509249,
            "precision": 0.6678635547576302,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8129990390861733,
            "auditor_fn_violation": 0.003283801690867782,
            "auditor_fp_violation": 0.014124676079775855,
            "ave_precision_score": 0.8132983654535957,
            "fpr": 0.18331503841931943,
            "logloss": 0.5477338338302793,
            "mae": 0.3743359787685083,
            "precision": 0.6946983546617916,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.6916435877919498,
            "mae": 0.49849074111695874,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6925477380743824,
            "mae": 0.49894235908788853,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.5684596845083486,
            "auditor_fn_violation": 0.02051418827734618,
            "auditor_fp_violation": 0.07150598363658567,
            "ave_precision_score": 0.5694710075652445,
            "fpr": 0.17324561403508773,
            "logloss": 0.7782721155869495,
            "mae": 0.46371779443794175,
            "precision": 0.6788617886178862,
            "recall": 0.6943866943866944
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.5710450163835498,
            "auditor_fn_violation": 0.02844027542161462,
            "auditor_fp_violation": 0.0732498283285466,
            "ave_precision_score": 0.572210845439785,
            "fpr": 0.1800219538968167,
            "logloss": 0.7413645278412757,
            "mae": 0.4608396838544883,
            "precision": 0.6771653543307087,
            "recall": 0.7272727272727273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 10132,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5973586330280173,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005825904668864737,
            "ave_precision_score": 0.6148484786461477,
            "fpr": 0.0010964912280701754,
            "logloss": 0.8329370438322921,
            "mae": 0.4721903130692928,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8165337745005286,
            "mae": 0.47681086408342394,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7880347554873286,
            "auditor_fn_violation": 0.01472626472626473,
            "auditor_fp_violation": 0.01429254691252493,
            "ave_precision_score": 0.7757633366046064,
            "fpr": 0.13706140350877194,
            "logloss": 0.5779424568928874,
            "mae": 0.3827177878028076,
            "precision": 0.7294372294372294,
            "recall": 0.7006237006237006
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8070094023032318,
            "auditor_fn_violation": 0.006781108509339694,
            "auditor_fp_violation": 0.008683818775092854,
            "ave_precision_score": 0.78797415241705,
            "fpr": 0.12184412733260154,
            "logloss": 0.5525899107787551,
            "mae": 0.37117468854402214,
            "precision": 0.750561797752809,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7840303068633971,
            "auditor_fn_violation": 0.009006729401466247,
            "auditor_fp_violation": 0.026407375747954577,
            "ave_precision_score": 0.6447181198494285,
            "fpr": 0.1875,
            "logloss": 0.7210028694385088,
            "mae": 0.4217186177096537,
            "precision": 0.6809701492537313,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7871923083743552,
            "auditor_fn_violation": 0.010605635142944006,
            "auditor_fp_violation": 0.020901312722734322,
            "ave_precision_score": 0.6381399021609726,
            "fpr": 0.21075740944017562,
            "logloss": 0.6849007959594668,
            "mae": 0.41760859465069095,
            "precision": 0.6660869565217391,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6954886238812856,
            "auditor_fn_violation": 0.004937629937629941,
            "auditor_fp_violation": 0.01843682582325886,
            "ave_precision_score": 0.5430902993556921,
            "fpr": 0.28399122807017546,
            "logloss": 1.7433520591098062,
            "mae": 0.4933991214895382,
            "precision": 0.5511265164644714,
            "recall": 0.6611226611226612
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6938631399987117,
            "auditor_fn_violation": 0.0026850590504127504,
            "auditor_fp_violation": 0.02636472540085912,
            "ave_precision_score": 0.5348321596614425,
            "fpr": 0.29747530186608123,
            "logloss": 1.6688964085144529,
            "mae": 0.49035869981200586,
            "precision": 0.5422297297297297,
            "recall": 0.678646934460888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6180500167850465,
            "auditor_fn_violation": 0.006278039172776023,
            "auditor_fp_violation": 0.013773558024992878,
            "ave_precision_score": 0.5881562632002032,
            "fpr": 0.10855263157894737,
            "logloss": 1.9761514836937915,
            "mae": 0.4809665533084307,
            "precision": 0.604,
            "recall": 0.31392931392931395
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.6024601486764163,
            "auditor_fn_violation": 0.013986906565978889,
            "auditor_fp_violation": 0.01890140294422808,
            "ave_precision_score": 0.5773076928347812,
            "fpr": 0.13172338090010977,
            "logloss": 2.0160696666321085,
            "mae": 0.49540938710715965,
            "precision": 0.5419847328244275,
            "recall": 0.30021141649048627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.5771410758828103,
            "auditor_fn_violation": 0.005341120472699422,
            "auditor_fp_violation": 0.016068303008100308,
            "ave_precision_score": 0.5793621102622672,
            "fpr": 0.3267543859649123,
            "logloss": 0.7066009813400861,
            "mae": 0.4586965214155023,
            "precision": 0.592896174863388,
            "recall": 0.9022869022869023
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6085694098887134,
            "auditor_fn_violation": 0.005801769771851206,
            "auditor_fp_violation": 0.022209524382358712,
            "ave_precision_score": 0.6100954071950978,
            "fpr": 0.3512623490669594,
            "logloss": 0.6733075377244137,
            "mae": 0.46022325659103785,
            "precision": 0.5800524934383202,
            "recall": 0.9344608879492601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7511132503526737,
            "auditor_fn_violation": 0.022841667578509684,
            "auditor_fp_violation": 0.026244555704807274,
            "ave_precision_score": 0.5380946106908987,
            "fpr": 0.42543859649122806,
            "logloss": 15.773134120381288,
            "mae": 0.46271908145986107,
            "precision": 0.5353293413173653,
            "recall": 0.9293139293139293
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7500163597562308,
            "auditor_fn_violation": 0.028484368871880685,
            "auditor_fp_violation": 0.042366509781513614,
            "ave_precision_score": 0.5401934573533217,
            "fpr": 0.407244785949506,
            "logloss": 15.355589852978143,
            "mae": 0.44895711106081565,
            "precision": 0.5397022332506204,
            "recall": 0.919661733615222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8442968147910139,
            "auditor_fn_violation": 0.006184575263522644,
            "auditor_fp_violation": 0.005642732120324011,
            "ave_precision_score": 0.8254344895608411,
            "fpr": 0.07785087719298246,
            "logloss": 0.5292929988013525,
            "mae": 0.3154973648202589,
            "precision": 0.8179487179487179,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8875838853789064,
            "auditor_fn_violation": 0.00829885148165597,
            "auditor_fp_violation": 0.011345352841225207,
            "ave_precision_score": 0.8723125360785084,
            "fpr": 0.06695938529088913,
            "logloss": 0.45377869083150235,
            "mae": 0.286445247608469,
            "precision": 0.8497536945812808,
            "recall": 0.7293868921775899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.725198036982174,
            "auditor_fn_violation": 0.00049923405186564,
            "auditor_fp_violation": 0.002671266332885579,
            "ave_precision_score": 0.7394355477906851,
            "fpr": 0.09210526315789473,
            "logloss": 0.5901872768889429,
            "mae": 0.3607021602066724,
            "precision": 0.7941176470588235,
            "recall": 0.6735966735966736
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7607622226626318,
            "auditor_fn_violation": 0.00876299306340406,
            "auditor_fp_violation": 0.01363848247447484,
            "ave_precision_score": 0.7538376419949807,
            "fpr": 0.08562019758507135,
            "logloss": 0.5547081686548657,
            "mae": 0.3428517159822874,
            "precision": 0.8120481927710843,
            "recall": 0.7124735729386892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6703108515772103,
            "auditor_fn_violation": 0.008306889885837259,
            "auditor_fp_violation": 0.006243131029429725,
            "ave_precision_score": 0.6709949256516243,
            "fpr": 0.0668859649122807,
            "logloss": 3.533326012968238,
            "mae": 0.44579528615969566,
            "precision": 0.698019801980198,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6810398010123726,
            "auditor_fn_violation": 0.008322058560743388,
            "auditor_fp_violation": 0.004749159185801143,
            "ave_precision_score": 0.6814306524727878,
            "fpr": 0.07135016465422613,
            "logloss": 3.7028428060077347,
            "mae": 0.43759529273571846,
            "precision": 0.7031963470319634,
            "recall": 0.32558139534883723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8264855003299076,
            "auditor_fn_violation": 0.0413680380785644,
            "auditor_fp_violation": 0.019456995156103715,
            "ave_precision_score": 0.826490211006949,
            "fpr": 0.07894736842105263,
            "logloss": 0.5456996790818743,
            "mae": 0.3867967540169494,
            "precision": 0.808,
            "recall": 0.6299376299376299
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.836599011017578,
            "auditor_fn_violation": 0.03587118214540164,
            "auditor_fp_violation": 0.021051681879012976,
            "ave_precision_score": 0.8367232903514492,
            "fpr": 0.06805708013172337,
            "logloss": 0.5400181736953622,
            "mae": 0.38785520977822147,
            "precision": 0.8315217391304348,
            "recall": 0.6469344608879493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.624102581377687,
            "auditor_fn_violation": 0.0021815844184265368,
            "auditor_fp_violation": 0.0038415353930068806,
            "ave_precision_score": 0.5874399509793293,
            "fpr": 0.05263157894736842,
            "logloss": 9.482058543666291,
            "mae": 0.47674701082163023,
            "precision": 0.6335877862595419,
            "recall": 0.17255717255717257
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6289521506923164,
            "auditor_fn_violation": 0.002759321703492442,
            "auditor_fp_violation": 0.00558370800314773,
            "ave_precision_score": 0.5966872328994257,
            "fpr": 0.04171240395170143,
            "logloss": 9.03121921167551,
            "mae": 0.4620191621050779,
            "precision": 0.6833333333333333,
            "recall": 0.1733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6240541977414991,
            "auditor_fn_violation": 0.0012583433636065215,
            "auditor_fp_violation": 0.004258761753571871,
            "ave_precision_score": 0.5823231560706809,
            "fpr": 0.46600877192982454,
            "logloss": 7.126373364650612,
            "mae": 0.4690240196344492,
            "precision": 0.5298672566371682,
            "recall": 0.9958419958419958
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6002668541575908,
            "auditor_fn_violation": 0.0007310229912532519,
            "auditor_fp_violation": 0.0021202051035291644,
            "ave_precision_score": 0.5639110179411899,
            "fpr": 0.47420417124039516,
            "logloss": 6.995517241524556,
            "mae": 0.4729075825100806,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.766679149721837,
            "auditor_fn_violation": 0.015072765072765079,
            "auditor_fp_violation": 0.035700838523222214,
            "ave_precision_score": 0.6097711165945994,
            "fpr": 0.25877192982456143,
            "logloss": 0.655195385780161,
            "mae": 0.4463211371350968,
            "precision": 0.6205787781350482,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7637436099292975,
            "auditor_fn_violation": 0.011236867694121418,
            "auditor_fp_violation": 0.03886290844022074,
            "ave_precision_score": 0.5955713766212548,
            "fpr": 0.2843029637760702,
            "logloss": 0.649452947781511,
            "mae": 0.4488215723394955,
            "precision": 0.6021505376344086,
            "recall": 0.828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.793047464303903,
            "auditor_fn_violation": 0.006916329284750338,
            "auditor_fp_violation": 0.021777180770952902,
            "ave_precision_score": 0.74625753430209,
            "fpr": 0.19517543859649122,
            "logloss": 2.811767946118511,
            "mae": 0.2988565777370496,
            "precision": 0.7033333333333334,
            "recall": 0.8773388773388774
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8059957708102145,
            "auditor_fn_violation": 0.004376855115884551,
            "auditor_fp_violation": 0.022590459578264655,
            "ave_precision_score": 0.7533923125230445,
            "fpr": 0.20197585071350166,
            "logloss": 2.982489588000163,
            "mae": 0.2949811907910152,
            "precision": 0.7017828200972447,
            "recall": 0.9154334038054969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8491377626347322,
            "auditor_fn_violation": 0.020612211401685097,
            "auditor_fp_violation": 0.013010339072739853,
            "ave_precision_score": 0.8310980656582244,
            "fpr": 0.09758771929824561,
            "logloss": 3.217829388687968,
            "mae": 0.24291116525460885,
            "precision": 0.7968036529680366,
            "recall": 0.7255717255717256
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8739319985631382,
            "auditor_fn_violation": 0.02546048646679183,
            "auditor_fp_violation": 0.014535685106937535,
            "ave_precision_score": 0.864880918493217,
            "fpr": 0.08781558726673985,
            "logloss": 2.9580815484113563,
            "mae": 0.21622895986487262,
            "precision": 0.816933638443936,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7368438999883982,
            "auditor_fn_violation": 0.049554108764635084,
            "auditor_fp_violation": 0.07149835144706314,
            "ave_precision_score": 0.6887648260419825,
            "fpr": 0.31469298245614036,
            "logloss": 2.8365432029047497,
            "mae": 0.41286487075124395,
            "precision": 0.5852601156069365,
            "recall": 0.841995841995842
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.756957989161573,
            "auditor_fn_violation": 0.040928004678547146,
            "auditor_fp_violation": 0.07536000882165718,
            "ave_precision_score": 0.7043393145692882,
            "fpr": 0.3172338090010977,
            "logloss": 2.9726722767224043,
            "mae": 0.39755694957452076,
            "precision": 0.5835734870317003,
            "recall": 0.8562367864693446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8225343322914299,
            "auditor_fn_violation": 0.011573567494620128,
            "auditor_fp_violation": 0.003526071559408965,
            "ave_precision_score": 0.8160198500072995,
            "fpr": 0.0756578947368421,
            "logloss": 0.5667723955901505,
            "mae": 0.32185506953734594,
            "precision": 0.8207792207792208,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8625936024136686,
            "auditor_fn_violation": 0.0015757606700347996,
            "auditor_fp_violation": 0.013104671969685578,
            "ave_precision_score": 0.8556965075717289,
            "fpr": 0.06915477497255763,
            "logloss": 0.4771709172530552,
            "mae": 0.2960786036905924,
            "precision": 0.8417085427135679,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8361089502348039,
            "auditor_fn_violation": 0.0009323594849910668,
            "auditor_fp_violation": 0.0032360483575528155,
            "ave_precision_score": 0.836481077379328,
            "fpr": 0.1524122807017544,
            "logloss": 0.5202299251478455,
            "mae": 0.3250063359494625,
            "precision": 0.7481884057971014,
            "recall": 0.8586278586278586
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8576113923863995,
            "auditor_fn_violation": 0.005249441289570972,
            "auditor_fp_violation": 0.017447834433534322,
            "ave_precision_score": 0.8578873356838701,
            "fpr": 0.17233809001097694,
            "logloss": 0.5060707341406596,
            "mae": 0.3295657205843683,
            "precision": 0.7221238938053097,
            "recall": 0.8625792811839323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7913399069577316,
            "auditor_fn_violation": 0.009800032826348618,
            "auditor_fp_violation": 0.001434851630235684,
            "ave_precision_score": 0.7825119241955186,
            "fpr": 0.08114035087719298,
            "logloss": 0.5490913038050694,
            "mae": 0.36092979134174813,
            "precision": 0.8163771712158809,
            "recall": 0.683991683991684
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.801397046674669,
            "auditor_fn_violation": 0.0013970661610617757,
            "auditor_fp_violation": 0.017771128119533457,
            "ave_precision_score": 0.7990100157901016,
            "fpr": 0.0867178924259056,
            "logloss": 0.5152271145567137,
            "mae": 0.3457417737377724,
            "precision": 0.8145539906103286,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6352563412670011,
            "auditor_fn_violation": 0.08114946930736405,
            "auditor_fp_violation": 0.09312543249073961,
            "ave_precision_score": 0.6346178128757213,
            "fpr": 0.27960526315789475,
            "logloss": 2.6667455385777186,
            "mae": 0.41257540305462304,
            "precision": 0.5853658536585366,
            "recall": 0.7484407484407485
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6636253904087298,
            "auditor_fn_violation": 0.0801363647967176,
            "auditor_fp_violation": 0.09298578009012125,
            "ave_precision_score": 0.6641985497278863,
            "fpr": 0.2557628979143798,
            "logloss": 2.6764156651999844,
            "mae": 0.3891804200743885,
            "precision": 0.6030664395229983,
            "recall": 0.7484143763213531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6611015664047278,
            "auditor_fn_violation": 0.008407192617718934,
            "auditor_fp_violation": 0.008751577319168003,
            "ave_precision_score": 0.6202237663818678,
            "fpr": 0.37609649122807015,
            "logloss": 0.7081496526966498,
            "mae": 0.4579094865452166,
            "precision": 0.5533854166666666,
            "recall": 0.8835758835758836
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6693194373355635,
            "auditor_fn_violation": 0.003293084522502746,
            "auditor_fp_violation": 0.004135151797663263,
            "ave_precision_score": 0.6242193133148388,
            "fpr": 0.38199780461031835,
            "logloss": 0.6712357021263606,
            "mae": 0.45081569589613135,
            "precision": 0.5526992287917738,
            "recall": 0.9090909090909091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7577252690480039,
            "auditor_fn_violation": 0.01247173286646972,
            "auditor_fp_violation": 0.0061642650710302446,
            "ave_precision_score": 0.7494885264908409,
            "fpr": 0.023026315789473683,
            "logloss": 0.8522608722130331,
            "mae": 0.4191955206834041,
            "precision": 0.8846153846153846,
            "recall": 0.33471933471933474
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7409662475321306,
            "auditor_fn_violation": 0.015697268294720623,
            "auditor_fp_violation": 0.007944503756722754,
            "ave_precision_score": 0.7358410966056868,
            "fpr": 0.018660812294182216,
            "logloss": 0.8197139325070266,
            "mae": 0.41497832811902696,
            "precision": 0.9022988505747126,
            "recall": 0.33192389006342493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8097849588947809,
            "auditor_fn_violation": 0.04079129737024475,
            "auditor_fp_violation": 0.03810243415964506,
            "ave_precision_score": 0.8098770399740414,
            "fpr": 0.15679824561403508,
            "logloss": 2.6614500050711154,
            "mae": 0.3267643516590944,
            "precision": 0.7201565557729941,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8371875709275809,
            "auditor_fn_violation": 0.05434633780688461,
            "auditor_fp_violation": 0.03902079605431335,
            "ave_precision_score": 0.8369172578696888,
            "fpr": 0.16465422612513722,
            "logloss": 2.8483183052551753,
            "mae": 0.3227430745326634,
            "precision": 0.7053045186640472,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5479485532753433,
            "auditor_fn_violation": 0.0005357077725498786,
            "auditor_fp_violation": 0.009336711849228645,
            "ave_precision_score": 0.5843668843303185,
            "fpr": 0.31030701754385964,
            "logloss": 0.7165301413700571,
            "mae": 0.47966244342949305,
            "precision": 0.5578125,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6389572984353071,
            "auditor_fn_violation": 0.007635129019756192,
            "auditor_fp_violation": 0.01208466785959532,
            "ave_precision_score": 0.6172720912519424,
            "fpr": 0.3238199780461032,
            "logloss": 0.700820139690221,
            "mae": 0.4723611734930168,
            "precision": 0.554380664652568,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.6916483659974899,
            "mae": 0.49858199765807704,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6924977464045851,
            "mae": 0.4990063087869554,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8339557279250551,
            "auditor_fn_violation": 0.010748349564139038,
            "auditor_fp_violation": 0.024512048683192907,
            "ave_precision_score": 0.8346945717652331,
            "fpr": 0.16447368421052633,
            "logloss": 0.7296667881239146,
            "mae": 0.2734816265295707,
            "precision": 0.7257769652650823,
            "recall": 0.8253638253638254
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8616210861698084,
            "auditor_fn_violation": 0.011157963625224239,
            "auditor_fp_violation": 0.02300648091063562,
            "ave_precision_score": 0.8618319940134646,
            "fpr": 0.1778265642151482,
            "logloss": 0.670963171508871,
            "mae": 0.2667624220109449,
            "precision": 0.7122557726465364,
            "recall": 0.8477801268498943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7554590097428278,
            "auditor_fn_violation": 0.013885089542984282,
            "auditor_fp_violation": 0.009667440061871625,
            "ave_precision_score": 0.727125627263155,
            "fpr": 0.23135964912280702,
            "logloss": 0.6004604796696196,
            "mae": 0.4272231900443633,
            "precision": 0.656910569105691,
            "recall": 0.83991683991684
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7770025991376657,
            "auditor_fn_violation": 0.01802725903509607,
            "auditor_fp_violation": 0.01708193615325626,
            "ave_precision_score": 0.7462089714808426,
            "fpr": 0.2239297475301866,
            "logloss": 0.5885588945948139,
            "mae": 0.42081830540158743,
            "precision": 0.6588628762541806,
            "recall": 0.8329809725158562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8405230698060631,
            "auditor_fn_violation": 0.00732437903490536,
            "auditor_fp_violation": 0.0025466072373509178,
            "ave_precision_score": 0.7857737444212185,
            "fpr": 0.09100877192982457,
            "logloss": 0.5277436377569358,
            "mae": 0.3444738413223572,
            "precision": 0.8056206088992974,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8593896445713409,
            "auditor_fn_violation": 0.005878353132839651,
            "auditor_fp_violation": 0.018292407861299494,
            "ave_precision_score": 0.8079015941349958,
            "fpr": 0.09549945115257959,
            "logloss": 0.49861508874118116,
            "mae": 0.33217972513742167,
            "precision": 0.8004587155963303,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7719937420262075,
            "auditor_fn_violation": 0.006718003428529746,
            "auditor_fp_violation": 0.0371356901534579,
            "ave_precision_score": 0.6232525093884103,
            "fpr": 0.27521929824561403,
            "logloss": 0.6420403774719383,
            "mae": 0.4548946996791321,
            "precision": 0.6231231231231231,
            "recall": 0.8627858627858628
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7872492608019481,
            "auditor_fn_violation": 0.009691276226900254,
            "auditor_fp_violation": 0.03782285510929333,
            "ave_precision_score": 0.6298268900522577,
            "fpr": 0.29747530186608123,
            "logloss": 0.6339043056142922,
            "mae": 0.4522864221872273,
            "precision": 0.6111908177905309,
            "recall": 0.9006342494714588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7602383022531553,
            "auditor_fn_violation": 0.017185961264908636,
            "auditor_fp_violation": 0.03113424512557497,
            "ave_precision_score": 0.7559753310371873,
            "fpr": 0.2719298245614035,
            "logloss": 1.6597440501769019,
            "mae": 0.3816541719570068,
            "precision": 0.6050955414012739,
            "recall": 0.7900207900207901
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7806308395961847,
            "auditor_fn_violation": 0.01531899290559593,
            "auditor_fp_violation": 0.04148183791207414,
            "ave_precision_score": 0.7766039473275786,
            "fpr": 0.2678375411635565,
            "logloss": 1.5840304757378174,
            "mae": 0.3541965446862509,
            "precision": 0.6181533646322379,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6878059110500858,
            "auditor_fn_violation": 0.0027811212021738338,
            "auditor_fp_violation": 0.006469552651931445,
            "ave_precision_score": 0.6265349670471289,
            "fpr": 0.45285087719298245,
            "logloss": 0.6487966164892376,
            "mae": 0.4561484760621138,
            "precision": 0.5354330708661418,
            "recall": 0.9896049896049897
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.6936501126198475,
            "auditor_fn_violation": 0.0021373719839499843,
            "auditor_fp_violation": 0.003869499621570958,
            "ave_precision_score": 0.6150631301270109,
            "fpr": 0.4632272228320527,
            "logloss": 0.651923123736919,
            "mae": 0.463628024713399,
            "precision": 0.5237020316027088,
            "recall": 0.9809725158562368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.685045057380912,
            "auditor_fn_violation": 0.02284622679359524,
            "auditor_fp_violation": 0.018391032686123663,
            "ave_precision_score": 0.6855258790579382,
            "fpr": 0.05592105263157895,
            "logloss": 1.9982373298541827,
            "mae": 0.45083775250978897,
            "precision": 0.734375,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6656411232546111,
            "auditor_fn_violation": 0.017658266477606346,
            "auditor_fp_violation": 0.015788761409259736,
            "ave_precision_score": 0.6661251302368839,
            "fpr": 0.05598243688254665,
            "logloss": 2.1267357076280877,
            "mae": 0.45642733056458595,
            "precision": 0.7150837988826816,
            "recall": 0.27061310782241016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6741354919304834,
            "auditor_fn_violation": 0.008972535288324772,
            "auditor_fp_violation": 0.012112284772255478,
            "ave_precision_score": 0.5470369955302044,
            "fpr": 0.2225877192982456,
            "logloss": 1.1174099769728372,
            "mae": 0.49372953987320917,
            "precision": 0.5634408602150538,
            "recall": 0.5446985446985447
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.643656311005855,
            "auditor_fn_violation": 0.0067161286878949554,
            "auditor_fp_violation": 0.020668240530502383,
            "ave_precision_score": 0.5191361788254126,
            "fpr": 0.2491767288693743,
            "logloss": 1.1566998173615188,
            "mae": 0.5079910402788355,
            "precision": 0.5190677966101694,
            "recall": 0.5179704016913319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6517153578439461,
            "auditor_fn_violation": 0.05389676113360325,
            "auditor_fp_violation": 0.026989966214841045,
            "ave_precision_score": 0.6522538726673963,
            "fpr": 0.0756578947368421,
            "logloss": 0.7890248677655854,
            "mae": 0.4742327863021792,
            "precision": 0.7051282051282052,
            "recall": 0.34303534303534305
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6916694625807773,
            "auditor_fn_violation": 0.05807803612413931,
            "auditor_fp_violation": 0.024179360329609195,
            "ave_precision_score": 0.6905149677249109,
            "fpr": 0.06805708013172337,
            "logloss": 0.655962888428412,
            "mae": 0.4674177360853277,
            "precision": 0.7350427350427351,
            "recall": 0.36363636363636365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.4048220452632345,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.40613530400462616,
            "fpr": 0.4725877192982456,
            "logloss": 0.9096043365620169,
            "mae": 0.508345523097536,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.3982047641584556,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.39924524503616393,
            "fpr": 0.4807903402854007,
            "logloss": 0.9008219074310259,
            "mae": 0.5109847386896152,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7978091729071728,
            "auditor_fn_violation": 0.01893214064266696,
            "auditor_fp_violation": 0.027857491757235314,
            "ave_precision_score": 0.787746224129608,
            "fpr": 0.18859649122807018,
            "logloss": 1.822817244422891,
            "mae": 0.2826784665582445,
            "precision": 0.7013888888888888,
            "recall": 0.83991683991684
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7995759391242235,
            "auditor_fn_violation": 0.020076444118513916,
            "auditor_fp_violation": 0.03342455728814239,
            "ave_precision_score": 0.785280676167147,
            "fpr": 0.1986827661909989,
            "logloss": 1.8345645660333039,
            "mae": 0.2734989424426569,
            "precision": 0.6937394247038917,
            "recall": 0.8668076109936576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7980563289389342,
            "auditor_fn_violation": 0.01009410219936536,
            "auditor_fp_violation": 0.003373427768958358,
            "ave_precision_score": 0.6657639513881332,
            "fpr": 0.02412280701754386,
            "logloss": 0.6079092041155606,
            "mae": 0.41817017074412943,
            "precision": 0.8910891089108911,
            "recall": 0.37422037422037424
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8095032342565955,
            "auditor_fn_violation": 0.010378205767887453,
            "auditor_fp_violation": 0.0035286628673393177,
            "ave_precision_score": 0.668764496050847,
            "fpr": 0.015367727771679473,
            "logloss": 0.5970006597330499,
            "mae": 0.41666837016981334,
            "precision": 0.9247311827956989,
            "recall": 0.36363636363636365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.691703962831452,
            "mae": 0.49879808410217885,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6924237267748762,
            "mae": 0.4991577353357091,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7414557156192991,
            "auditor_fn_violation": 0.008714939635992272,
            "auditor_fp_violation": 0.002773028859852648,
            "ave_precision_score": 0.7370671199422305,
            "fpr": 0.027412280701754384,
            "logloss": 0.9099521369380037,
            "mae": 0.4347982990571804,
            "precision": 0.84472049689441,
            "recall": 0.28274428274428276
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7207800531247871,
            "auditor_fn_violation": 0.013418333128337486,
            "auditor_fp_violation": 0.006541058298121891,
            "ave_precision_score": 0.721763287525569,
            "fpr": 0.030735455543358946,
            "logloss": 0.9133155288204033,
            "mae": 0.43387769070238236,
            "precision": 0.84,
            "recall": 0.3107822410147992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7897779096484092,
            "auditor_fn_violation": 0.013301510012036336,
            "auditor_fp_violation": 0.023191679895795174,
            "ave_precision_score": 0.7894961843564245,
            "fpr": 0.15789473684210525,
            "logloss": 0.5856444932320112,
            "mae": 0.3794950873247887,
            "precision": 0.7024793388429752,
            "recall": 0.7068607068607069
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7953835783866945,
            "auditor_fn_violation": 0.011782234052675429,
            "auditor_fp_violation": 0.022014044479196426,
            "ave_precision_score": 0.7947990247644006,
            "fpr": 0.150384193194292,
            "logloss": 0.5716296685141226,
            "mae": 0.3808638742755849,
            "precision": 0.7145833333333333,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 10132,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5255512706470608,
            "auditor_fn_violation": 0.02071479374110953,
            "auditor_fp_violation": 0.009535148776814429,
            "ave_precision_score": 0.5452809218247829,
            "fpr": 0.05921052631578947,
            "logloss": 0.8504406950639196,
            "mae": 0.5098733131757431,
            "precision": 0.5909090909090909,
            "recall": 0.16216216216216217
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5112349266544166,
            "auditor_fn_violation": 0.016685889863844085,
            "auditor_fp_violation": 0.01066117318015729,
            "ave_precision_score": 0.5398198570606267,
            "fpr": 0.054884742041712405,
            "logloss": 0.8544962141799517,
            "mae": 0.510912828212839,
            "precision": 0.5934959349593496,
            "recall": 0.1543340380549683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7701623071535707,
            "auditor_fn_violation": 0.0038844512528723118,
            "auditor_fp_violation": 0.009194244311474746,
            "ave_precision_score": 0.7707476841221166,
            "fpr": 0.10416666666666667,
            "logloss": 0.5469621676953174,
            "mae": 0.36769068428609325,
            "precision": 0.7865168539325843,
            "recall": 0.7276507276507277
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.814976119891507,
            "auditor_fn_violation": 0.005158933681130092,
            "auditor_fp_violation": 0.012661082958663524,
            "ave_precision_score": 0.8119708100469345,
            "fpr": 0.09879253567508232,
            "logloss": 0.5155322922666646,
            "mae": 0.3541895067554405,
            "precision": 0.8004434589800443,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7580964774456344,
            "auditor_fn_violation": 0.00047643797643797645,
            "auditor_fp_violation": 0.0017630357797044876,
            "ave_precision_score": 0.5699158995929816,
            "fpr": 0.4692982456140351,
            "logloss": 12.69504602081452,
            "mae": 0.466730447437026,
            "precision": 0.5286343612334802,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7631372212249237,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 3.508613646503558e-05,
            "ave_precision_score": 0.5666122086962241,
            "fpr": 0.47200878155872666,
            "logloss": 13.063039864232891,
            "mae": 0.4679657014088887,
            "precision": 0.5238095238095238,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8169671228391875,
            "auditor_fn_violation": 0.02604907539118066,
            "auditor_fp_violation": 0.016582203769283998,
            "ave_precision_score": 0.8175975399263256,
            "fpr": 0.08771929824561403,
            "logloss": 0.8658561617559141,
            "mae": 0.2942881542411361,
            "precision": 0.7959183673469388,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8273183760518225,
            "auditor_fn_violation": 0.02488959232124167,
            "auditor_fp_violation": 0.018555553884787156,
            "ave_precision_score": 0.8277390825864434,
            "fpr": 0.08122941822173436,
            "logloss": 0.7734270055256187,
            "mae": 0.2726297449267479,
            "precision": 0.8136020151133502,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8254817686243303,
            "auditor_fn_violation": 0.005689900426742543,
            "auditor_fp_violation": 0.003948386046322306,
            "ave_precision_score": 0.8258774676837464,
            "fpr": 0.0800438596491228,
            "logloss": 0.5506586576985852,
            "mae": 0.3308505743047327,
            "precision": 0.8093994778067886,
            "recall": 0.6444906444906445
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.866552030632547,
            "auditor_fn_violation": 0.013200186584915868,
            "auditor_fp_violation": 0.004957169851986629,
            "ave_precision_score": 0.8667313244124701,
            "fpr": 0.06366630076838639,
            "logloss": 0.4942158542994104,
            "mae": 0.3129154192876688,
            "precision": 0.8501291989664083,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7646984835378567,
            "auditor_fn_violation": 0.0006337308968887916,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5303805564237375,
            "fpr": 0.4725877192982456,
            "logloss": 16.11878497602977,
            "mae": 0.47324240670882556,
            "precision": 0.5268935236004391,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7613259668508288,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011929286398107497,
            "ave_precision_score": 0.5226519337016574,
            "fpr": 0.47859495060373214,
            "logloss": 16.39771540129555,
            "mae": 0.4786403462939035,
            "precision": 0.5203520352035204,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7680896094664131,
            "auditor_fn_violation": 0.0301158952474742,
            "auditor_fp_violation": 0.0023456262465909564,
            "ave_precision_score": 0.7687003206766351,
            "fpr": 0.04057017543859649,
            "logloss": 0.8303446806308017,
            "mae": 0.3916596516952553,
            "precision": 0.8438818565400844,
            "recall": 0.4158004158004158
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.8149166610577883,
            "auditor_fn_violation": 0.032174294446778044,
            "auditor_fp_violation": 0.004405816278964858,
            "ave_precision_score": 0.8151796983383199,
            "fpr": 0.03402854006586169,
            "logloss": 0.7622649479518105,
            "mae": 0.3705894748092167,
            "precision": 0.8702928870292888,
            "recall": 0.4397463002114165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6790986132577415,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5423107270352336,
            "fpr": 0.4725877192982456,
            "logloss": 0.6922610580149209,
            "mae": 0.49946460846746177,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6494768154632303,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5204720962250702,
            "fpr": 0.4807903402854007,
            "logloss": 0.6925922427017767,
            "mae": 0.499630332451097,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6511409726914037,
            "auditor_fn_violation": 0.0022773279352226723,
            "auditor_fp_violation": 0.010125371433223436,
            "ave_precision_score": 0.6058081493778491,
            "fpr": 0.32785087719298245,
            "logloss": 0.7016568347405581,
            "mae": 0.4628206587788698,
            "precision": 0.5589970501474927,
            "recall": 0.7879417879417879
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6842012379358259,
            "auditor_fn_violation": 0.007403058228882142,
            "auditor_fp_violation": 0.010385496393646406,
            "ave_precision_score": 0.6351742858697954,
            "fpr": 0.3512623490669594,
            "logloss": 0.6846835231291728,
            "mae": 0.45716443018319186,
            "precision": 0.5518207282913166,
            "recall": 0.8329809725158562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6432799194079182,
            "auditor_fn_violation": 0.012603950103950119,
            "auditor_fp_violation": 0.0008344527211299705,
            "ave_precision_score": 0.5578301470338864,
            "fpr": 0.1162280701754386,
            "logloss": 0.7194960419469392,
            "mae": 0.4864866459219341,
            "precision": 0.6015037593984962,
            "recall": 0.33264033264033266
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6675758942215867,
            "auditor_fn_violation": 0.021234477364975423,
            "auditor_fp_violation": 0.015292543193540141,
            "ave_precision_score": 0.5656066984089094,
            "fpr": 0.11525795828759605,
            "logloss": 0.7201941866618315,
            "mae": 0.4875003305784172,
            "precision": 0.6379310344827587,
            "recall": 0.39112050739957716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7547725228575118,
            "auditor_fn_violation": 0.012939052412736626,
            "auditor_fp_violation": 0.02870720885741035,
            "ave_precision_score": 0.7552357163406804,
            "fpr": 0.1699561403508772,
            "logloss": 1.5242272751769623,
            "mae": 0.3248580602229611,
            "precision": 0.6881287726358148,
            "recall": 0.7110187110187111
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7559098608940277,
            "auditor_fn_violation": 0.014395351157917216,
            "auditor_fp_violation": 0.018029261837811828,
            "ave_precision_score": 0.7562469647794977,
            "fpr": 0.17453347969264543,
            "logloss": 1.319657614335142,
            "mae": 0.31169696474317604,
            "precision": 0.6936416184971098,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7622043023358812,
            "auditor_fn_violation": 0.0009027245869351133,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5263779451026415,
            "fpr": 0.4725877192982456,
            "logloss": 0.6926610399364757,
            "mae": 0.4996348067203112,
            "precision": 0.5263736263736264,
            "recall": 0.9958419958419958
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7601760176017602,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.001443543900275193,
            "ave_precision_score": 0.5203520352035204,
            "fpr": 0.47859495060373214,
            "logloss": 0.6921925004757276,
            "mae": 0.4994036520613535,
            "precision": 0.5203520352035204,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7173011236885973,
            "auditor_fn_violation": 0.029817266659371924,
            "auditor_fp_violation": 0.03309571783286523,
            "ave_precision_score": 0.5855710142047947,
            "fpr": 0.4199561403508772,
            "logloss": 11.231759009068595,
            "mae": 0.4642960572072914,
            "precision": 0.5351941747572816,
            "recall": 0.9168399168399168
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.74279549046624,
            "auditor_fn_violation": 0.031482723489973385,
            "auditor_fp_violation": 0.045616989709737404,
            "ave_precision_score": 0.6178800341989449,
            "fpr": 0.4061470911086718,
            "logloss": 10.539612717559825,
            "mae": 0.45235201674242465,
            "precision": 0.5380774032459426,
            "recall": 0.9112050739957717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 10132,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8295777018848938,
            "auditor_fn_violation": 0.003396615238720505,
            "auditor_fp_violation": 0.0073803272682867295,
            "ave_precision_score": 0.8204841940406344,
            "fpr": 0.08442982456140351,
            "logloss": 0.5870283363234217,
            "mae": 0.31663293553718824,
            "precision": 0.8108108108108109,
            "recall": 0.6860706860706861
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8781893566982971,
            "auditor_fn_violation": 0.004694792099382,
            "auditor_fp_violation": 0.011370414367271651,
            "ave_precision_score": 0.870606900115207,
            "fpr": 0.07354555433589462,
            "logloss": 0.4582654370732165,
            "mae": 0.2821774013424557,
            "precision": 0.8365853658536585,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7897594417521955,
            "auditor_fn_violation": 0.012932213590108335,
            "auditor_fp_violation": 0.019456995156103715,
            "ave_precision_score": 0.7416164126231708,
            "fpr": 0.14692982456140352,
            "logloss": 2.8063973890618663,
            "mae": 0.30748656746653613,
            "precision": 0.7392996108949417,
            "recall": 0.7900207900207901
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8040618034494329,
            "auditor_fn_violation": 0.008983460314734407,
            "auditor_fp_violation": 0.011290217483923032,
            "ave_precision_score": 0.751427796673738,
            "fpr": 0.145993413830955,
            "logloss": 2.9204305013758733,
            "mae": 0.2930037454752053,
            "precision": 0.744721689059501,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6437466552798916,
            "auditor_fn_violation": 0.02377174745595799,
            "auditor_fp_violation": 0.006141368502462658,
            "ave_precision_score": 0.5799485915846547,
            "fpr": 0.08114035087719298,
            "logloss": 0.7518554559536396,
            "mae": 0.48792228859179376,
            "precision": 0.6558139534883721,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6280909387730769,
            "auditor_fn_violation": 0.023225644750674745,
            "auditor_fp_violation": 0.009733896716438858,
            "ave_precision_score": 0.5652566322741885,
            "fpr": 0.09110867178924259,
            "logloss": 0.7508885732983803,
            "mae": 0.4869936400887471,
            "precision": 0.6175115207373272,
            "recall": 0.2832980972515856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.6563699975394583,
            "auditor_fn_violation": 0.0007157967684283494,
            "auditor_fp_violation": 0.008504803191272853,
            "ave_precision_score": 0.6572701752091388,
            "fpr": 0.1513157894736842,
            "logloss": 0.7263923304190092,
            "mae": 0.35616470049053695,
            "precision": 0.7288801571709234,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.653297415161749,
            "auditor_fn_violation": 0.009201606858156013,
            "auditor_fp_violation": 0.006345578394959634,
            "ave_precision_score": 0.6595082116831261,
            "fpr": 0.15587266739846323,
            "logloss": 0.7026387230365785,
            "mae": 0.3502571088201586,
            "precision": 0.7269230769230769,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6552577617587483,
            "auditor_fn_violation": 0.007741547215231437,
            "auditor_fp_violation": 0.005278931086416748,
            "ave_precision_score": 0.5823761733343691,
            "fpr": 0.17543859649122806,
            "logloss": 0.6816452793347566,
            "mae": 0.4912779067495936,
            "precision": 0.559228650137741,
            "recall": 0.42203742203742206
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6683772835495715,
            "auditor_fn_violation": 0.005616113139151969,
            "auditor_fp_violation": 0.006661353623144827,
            "ave_precision_score": 0.5822510528118425,
            "fpr": 0.16465422612513722,
            "logloss": 0.6789275245194163,
            "mae": 0.48991597523150143,
            "precision": 0.5821727019498607,
            "recall": 0.4418604651162791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5663160097546229,
            "auditor_fn_violation": 0.04330342488237225,
            "auditor_fp_violation": 0.023128078316440752,
            "ave_precision_score": 0.5678029558245377,
            "fpr": 0.35526315789473684,
            "logloss": 0.688698523156671,
            "mae": 0.4956501461238715,
            "precision": 0.5561643835616439,
            "recall": 0.8440748440748441
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5335338555182559,
            "auditor_fn_violation": 0.04202802022729013,
            "auditor_fp_violation": 0.01439032825586817,
            "ave_precision_score": 0.5365639103045406,
            "fpr": 0.3787047200878156,
            "logloss": 0.6910590695173415,
            "mae": 0.49697481274081373,
            "precision": 0.5356662180349933,
            "recall": 0.8414376321353065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6953687001547144,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5208823162741377,
            "fpr": 0.4725877192982456,
            "logloss": 0.6926885221974916,
            "mae": 0.49974724395494713,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.697914191774256,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5173974951362958,
            "fpr": 0.4807903402854007,
            "logloss": 0.6928292379410835,
            "mae": 0.4998175215904328,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7432620038023396,
            "auditor_fn_violation": 0.013898767188240874,
            "auditor_fp_violation": 0.024277994871168645,
            "ave_precision_score": 0.7440355672020822,
            "fpr": 0.26206140350877194,
            "logloss": 0.9698108808689324,
            "mae": 0.39264612894284684,
            "precision": 0.6200317965023847,
            "recall": 0.8108108108108109
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.765815803678416,
            "auditor_fn_violation": 0.013685214537842624,
            "auditor_fp_violation": 0.030998601566846612,
            "ave_precision_score": 0.7675091161289644,
            "fpr": 0.29088913282107576,
            "logloss": 0.981431127933913,
            "mae": 0.3859708842286752,
            "precision": 0.6021021021021021,
            "recall": 0.8477801268498943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8310929046591069,
            "auditor_fn_violation": 7.294744136849705e-05,
            "auditor_fp_violation": 0.006996173728986041,
            "ave_precision_score": 0.7633245499095265,
            "fpr": 0.07346491228070176,
            "logloss": 0.5745535794310603,
            "mae": 0.35156870407068674,
            "precision": 0.825065274151436,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8367773978275297,
            "auditor_fn_violation": 0.002796453030032291,
            "auditor_fp_violation": 0.019026710574460308,
            "ave_precision_score": 0.7675377927679897,
            "fpr": 0.0801317233809001,
            "logloss": 0.5473877909765903,
            "mae": 0.34897205772534684,
            "precision": 0.8128205128205128,
            "recall": 0.6701902748414377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.807320939656226,
            "auditor_fn_violation": 0.004794014662435715,
            "auditor_fp_violation": 0.0036990678552529803,
            "ave_precision_score": 0.7278577060319282,
            "fpr": 0.08442982456140351,
            "logloss": 0.5546633672471583,
            "mae": 0.35747551321656557,
            "precision": 0.8126520681265207,
            "recall": 0.6943866943866944
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8439875585229913,
            "auditor_fn_violation": 0.0030633344395374442,
            "auditor_fp_violation": 0.0196081379787378,
            "ave_precision_score": 0.7373580758935171,
            "fpr": 0.0889132821075741,
            "logloss": 0.5305772586886683,
            "mae": 0.34645497951039106,
            "precision": 0.8116279069767441,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5365851783730706,
            "auditor_fn_violation": 0.0012560637560637563,
            "auditor_fp_violation": 0.008693063866161943,
            "ave_precision_score": 0.537702804088462,
            "fpr": 0.4473684210526316,
            "logloss": 0.6962629553039767,
            "mae": 0.4879794172307779,
            "precision": 0.5389830508474577,
            "recall": 0.9916839916839917
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.528890568767802,
            "auditor_fn_violation": 0.000587139100911342,
            "auditor_fp_violation": 0.007398162488910271,
            "ave_precision_score": 0.5308620918467113,
            "fpr": 0.45773874862788144,
            "logloss": 0.6904886730959492,
            "mae": 0.4887577301649641,
            "precision": 0.530933633295838,
            "recall": 0.9978858350951374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.6922785156267194,
            "mae": 0.49947348576888706,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6925936537898473,
            "mae": 0.49963103547185234,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8269710006427411,
            "auditor_fn_violation": 0.004463471568734725,
            "auditor_fp_violation": 0.009184068058778036,
            "ave_precision_score": 0.8146082552130307,
            "fpr": 0.08552631578947369,
            "logloss": 0.5348348268828392,
            "mae": 0.3190363756291111,
            "precision": 0.8142857142857143,
            "recall": 0.7110187110187111
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8767496911829338,
            "auditor_fn_violation": 0.012042153338454365,
            "auditor_fp_violation": 0.015472986181074542,
            "ave_precision_score": 0.8699003063165109,
            "fpr": 0.08562019758507135,
            "logloss": 0.4627151168774491,
            "mae": 0.29832293009784167,
            "precision": 0.8202764976958525,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7450467450745709,
            "auditor_fn_violation": 0.01112220520115257,
            "auditor_fp_violation": 0.023555480929702447,
            "ave_precision_score": 0.7392690849394202,
            "fpr": 0.13815789473684212,
            "logloss": 1.2813315610834395,
            "mae": 0.33641365602450424,
            "precision": 0.7083333333333334,
            "recall": 0.6361746361746362
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7453044158621625,
            "auditor_fn_violation": 0.013174658797919727,
            "auditor_fp_violation": 0.017081936153256247,
            "ave_precision_score": 0.7388784625193016,
            "fpr": 0.14489571899012074,
            "logloss": 1.1751526193453437,
            "mae": 0.3153833618799606,
            "precision": 0.7092511013215859,
            "recall": 0.6807610993657506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.8179495767119859,
            "auditor_fn_violation": 0.0024505781084728454,
            "auditor_fp_violation": 0.0026152969430537,
            "ave_precision_score": 0.6941030034415466,
            "fpr": 0.46271929824561403,
            "logloss": 10.467117327333382,
            "mae": 0.46819963786114177,
            "precision": 0.5300668151447662,
            "recall": 0.9896049896049897
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8249648103380514,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010976948408342613,
            "ave_precision_score": 0.6945145152025634,
            "fpr": 0.47200878155872666,
            "logloss": 10.807475038857175,
            "mae": 0.47200752919473515,
            "precision": 0.5238095238095238,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8300965713552108,
            "auditor_fn_violation": 0.0040485829959514275,
            "auditor_fp_violation": 0.0013330891032686113,
            "ave_precision_score": 0.7865908937957891,
            "fpr": 0.06798245614035088,
            "logloss": 0.5434129775185144,
            "mae": 0.3396873650092043,
            "precision": 0.8268156424581006,
            "recall": 0.6153846153846154
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8696124084915147,
            "auditor_fn_violation": 0.007542300703406572,
            "auditor_fp_violation": 0.012405455392989791,
            "ave_precision_score": 0.82910109356869,
            "fpr": 0.059275521405049394,
            "logloss": 0.4826720338049205,
            "mae": 0.3142496158177714,
            "precision": 0.8563829787234043,
            "recall": 0.6807610993657506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7661031196611454,
            "auditor_fn_violation": 0.009836506547032867,
            "auditor_fp_violation": 0.003220783978507754,
            "ave_precision_score": 0.7666590421754681,
            "fpr": 0.05263157894736842,
            "logloss": 0.7060407419408068,
            "mae": 0.37759029754715834,
            "precision": 0.840531561461794,
            "recall": 0.525987525987526
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8105078803114382,
            "auditor_fn_violation": 0.006920350983864119,
            "auditor_fp_violation": 0.00452611160398779,
            "ave_precision_score": 0.8113926291304041,
            "fpr": 0.03951701427003293,
            "logloss": 0.6056942917532279,
            "mae": 0.35585059865353114,
            "precision": 0.8795986622073578,
            "recall": 0.5560253699788583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6600036506689528,
            "auditor_fn_violation": 0.027580971659919042,
            "auditor_fp_violation": 0.029241462123987465,
            "ave_precision_score": 0.6407890325645684,
            "fpr": 0.18092105263157895,
            "logloss": 0.7259938788831718,
            "mae": 0.4441882369702251,
            "precision": 0.619815668202765,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6101187621886841,
            "auditor_fn_violation": 0.02693645669675078,
            "auditor_fp_violation": 0.016081981264003134,
            "ave_precision_score": 0.591488083223981,
            "fpr": 0.20087815587266739,
            "logloss": 0.7365208631692037,
            "mae": 0.4645904212727594,
            "precision": 0.5744186046511628,
            "recall": 0.5221987315010571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6959281777039038,
            "auditor_fn_violation": 0.039375661086187404,
            "auditor_fp_violation": 0.03425326657711565,
            "ave_precision_score": 0.6971559291760012,
            "fpr": 0.22149122807017543,
            "logloss": 0.6740078706262886,
            "mae": 0.4270112495486453,
            "precision": 0.6203007518796992,
            "recall": 0.6860706860706861
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7411715102192258,
            "auditor_fn_violation": 0.05011568728925072,
            "auditor_fp_violation": 0.037817842804084026,
            "ave_precision_score": 0.7421568483566168,
            "fpr": 0.2239297475301866,
            "logloss": 0.6582033895808681,
            "mae": 0.41951370023653056,
            "precision": 0.6243093922651933,
            "recall": 0.7167019027484144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.772762760016179,
            "auditor_fn_violation": 0.011860798045008577,
            "auditor_fp_violation": 0.013613282045019746,
            "ave_precision_score": 0.772668723250153,
            "fpr": 0.14035087719298245,
            "logloss": 1.1116168362970265,
            "mae": 0.31277093761335045,
            "precision": 0.7293868921775899,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7716854747065802,
            "auditor_fn_violation": 0.011104587343323206,
            "auditor_fp_violation": 0.01778867118776597,
            "ave_precision_score": 0.7700667872122147,
            "fpr": 0.16465422612513722,
            "logloss": 1.1702088181103072,
            "mae": 0.29898035441884113,
            "precision": 0.7076023391812866,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7338045947961086,
            "auditor_fn_violation": 0.013221723748039548,
            "auditor_fp_violation": 0.028473155045386087,
            "ave_precision_score": 0.7347202512091614,
            "fpr": 0.16337719298245615,
            "logloss": 0.6846544588257413,
            "mae": 0.3795506203743188,
            "precision": 0.6882845188284519,
            "recall": 0.683991683991684
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7477165713658571,
            "auditor_fn_violation": 0.011647632993968482,
            "auditor_fp_violation": 0.0199915793272484,
            "ave_precision_score": 0.7481926110638835,
            "fpr": 0.16794731064763996,
            "logloss": 0.6391055539326287,
            "mae": 0.36231164617870826,
            "precision": 0.6958250497017893,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7766193879842556,
            "auditor_fn_violation": 0.03235902906955539,
            "auditor_fp_violation": 0.016800993202263203,
            "ave_precision_score": 0.7773132389055247,
            "fpr": 0.16885964912280702,
            "logloss": 0.6756246996332063,
            "mae": 0.3509172831146356,
            "precision": 0.6844262295081968,
            "recall": 0.6943866943866944
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8225119921534263,
            "auditor_fn_violation": 0.022670995560485775,
            "auditor_fp_violation": 0.030813146274102924,
            "ave_precision_score": 0.8229880853189022,
            "fpr": 0.15697036223929747,
            "logloss": 0.5459653493892795,
            "mae": 0.3099184482949801,
            "precision": 0.7239382239382239,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8034118201779499,
            "auditor_fn_violation": 0.02517370609475874,
            "auditor_fp_violation": 0.015325436561240689,
            "ave_precision_score": 0.8048508042102556,
            "fpr": 0.08442982456140351,
            "logloss": 0.6418969801908072,
            "mae": 0.32530883319365483,
            "precision": 0.8025641025641026,
            "recall": 0.6507276507276507
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.838954290708128,
            "auditor_fn_violation": 0.030352538738416774,
            "auditor_fp_violation": 0.014392834408472804,
            "ave_precision_score": 0.84029968247023,
            "fpr": 0.05817782656421515,
            "logloss": 0.5801541070569253,
            "mae": 0.30799157251414777,
            "precision": 0.8590425531914894,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7555768469577031,
            "auditor_fn_violation": 0.018815880657985923,
            "auditor_fp_violation": 0.02480207188504905,
            "ave_precision_score": 0.7562850306408402,
            "fpr": 0.3651315789473684,
            "logloss": 1.1374715684077297,
            "mae": 0.4068631828696921,
            "precision": 0.5618421052631579,
            "recall": 0.8877338877338877
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7907709736686455,
            "auditor_fn_violation": 0.024952251434777667,
            "auditor_fp_violation": 0.042960467948814356,
            "ave_precision_score": 0.7910575164785238,
            "fpr": 0.3424807903402854,
            "logloss": 1.0828050133957268,
            "mae": 0.3926678924166587,
            "precision": 0.5684647302904564,
            "recall": 0.86892177589852
        }
    }
]