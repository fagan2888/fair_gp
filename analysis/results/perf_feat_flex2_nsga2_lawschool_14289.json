[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.607637267765854,
            "auditor_fn_violation": 0.05211348125915604,
            "auditor_fp_violation": 0.024794766012418226,
            "ave_precision_score": 0.5479138958696431,
            "fpr": 0.19846491228070176,
            "logloss": 0.6914845855639055,
            "mae": 0.4986472556923042,
            "precision": 0.5530864197530864,
            "recall": 0.45621181262729127
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6131463122415298,
            "auditor_fn_violation": 0.05291458132306606,
            "auditor_fp_violation": 0.031529324133605145,
            "ave_precision_score": 0.5283778664040661,
            "fpr": 0.19758507135016465,
            "logloss": 0.68941035447893,
            "mae": 0.49733297963566364,
            "precision": 0.5372750642673522,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.38871599261421796,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5359080844257522,
            "fpr": 0.4616228070175439,
            "logloss": 0.6938325744528819,
            "mae": 0.49875751647510025,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.451734709825764,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.505562790643387,
            "fpr": 0.49176728869374314,
            "logloss": 0.6973906175241524,
            "mae": 0.5002989865160669,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.817661657256113,
            "auditor_fn_violation": 0.022593078929502988,
            "auditor_fp_violation": 0.03819487852648249,
            "ave_precision_score": 0.8182254492829498,
            "fpr": 0.22916666666666666,
            "logloss": 0.5755419978580764,
            "mae": 0.39457950502094863,
            "precision": 0.6671974522292994,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8304582167288246,
            "auditor_fn_violation": 0.01543648187618097,
            "auditor_fp_violation": 0.03973998353457739,
            "ave_precision_score": 0.8307107467130035,
            "fpr": 0.2535675082327113,
            "logloss": 0.5691661356267306,
            "mae": 0.39283982932191386,
            "precision": 0.640746500777605,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.4341336411292998,
            "auditor_fn_violation": 0.0017441133383356594,
            "auditor_fp_violation": 0.005906988373546695,
            "ave_precision_score": 0.5344005380048901,
            "fpr": 0.020833333333333332,
            "logloss": 0.6942212957975383,
            "mae": 0.5004994869232178,
            "precision": 0.32142857142857145,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5005176522731841,
            "auditor_fn_violation": 0.004924216381021034,
            "auditor_fp_violation": 0.002195389681668497,
            "ave_precision_score": 0.5068895730469936,
            "fpr": 0.021953896816684963,
            "logloss": 0.6934496662036058,
            "mae": 0.5001016385468903,
            "precision": 0.47368421052631576,
            "recall": 0.038876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.38871599261421796,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5359080844257522,
            "fpr": 0.4616228070175439,
            "logloss": 0.6938240148781074,
            "mae": 0.49876272586876885,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.451734709825764,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.505562790643387,
            "fpr": 0.49176728869374314,
            "logloss": 0.6973691040274754,
            "mae": 0.5002988685499038,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.607637267765854,
            "auditor_fn_violation": 0.05211348125915604,
            "auditor_fp_violation": 0.024794766012418226,
            "ave_precision_score": 0.5479138958696431,
            "fpr": 0.19846491228070176,
            "logloss": 0.6914845855639055,
            "mae": 0.4986472556923042,
            "precision": 0.5530864197530864,
            "recall": 0.45621181262729127
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6131463122415298,
            "auditor_fn_violation": 0.05291458132306606,
            "auditor_fp_violation": 0.031529324133605145,
            "ave_precision_score": 0.5283778664040661,
            "fpr": 0.19758507135016465,
            "logloss": 0.68941035447893,
            "mae": 0.49733297963566364,
            "precision": 0.5372750642673522,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8176586584269799,
            "auditor_fn_violation": 0.022593078929502988,
            "auditor_fp_violation": 0.03819487852648249,
            "ave_precision_score": 0.8182224556627808,
            "fpr": 0.22916666666666666,
            "logloss": 0.5755380164650621,
            "mae": 0.3945770640449043,
            "precision": 0.6671974522292994,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8304561413993563,
            "auditor_fn_violation": 0.01543648187618097,
            "auditor_fp_violation": 0.03973998353457739,
            "ave_precision_score": 0.8307086720376812,
            "fpr": 0.2535675082327113,
            "logloss": 0.5691660894283973,
            "mae": 0.39283881980095686,
            "precision": 0.640746500777605,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6121681814750988,
            "auditor_fn_violation": 0.071622539035981,
            "auditor_fp_violation": 0.061669166979205735,
            "ave_precision_score": 0.6097955445017949,
            "fpr": 0.20065789473684212,
            "logloss": 0.6801377521719111,
            "mae": 0.4815873962483908,
            "precision": 0.6064516129032258,
            "recall": 0.5743380855397149
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.5912887635856408,
            "auditor_fn_violation": 0.06710400599346125,
            "auditor_fp_violation": 0.07523865061941352,
            "ave_precision_score": 0.5882974678839521,
            "fpr": 0.22063666300768386,
            "logloss": 0.6884539857958102,
            "mae": 0.4864355229520117,
            "precision": 0.5821205821205822,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6100810761036882,
            "auditor_fn_violation": 0.06185014471004394,
            "auditor_fp_violation": 0.051738238113097475,
            "ave_precision_score": 0.6082895030695847,
            "fpr": 0.17763157894736842,
            "logloss": 0.6701010630531365,
            "mae": 0.4751554261484559,
            "precision": 0.5919395465994962,
            "recall": 0.4786150712830957
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5916859872165801,
            "auditor_fn_violation": 0.06213711465102551,
            "auditor_fp_violation": 0.06447977105221891,
            "ave_precision_score": 0.5873861860678575,
            "fpr": 0.18880351262349068,
            "logloss": 0.6728790463530102,
            "mae": 0.47866837093943954,
            "precision": 0.5825242718446602,
            "recall": 0.5183585313174947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7880354792087401,
            "auditor_fn_violation": 0.014138260621002612,
            "auditor_fp_violation": 0.025055215235237738,
            "ave_precision_score": 0.788702782941785,
            "fpr": 0.1600877192982456,
            "logloss": 0.5826574057717956,
            "mae": 0.40317969477996884,
            "precision": 0.7159533073929961,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7951491547051832,
            "auditor_fn_violation": 0.01178777267522221,
            "auditor_fp_violation": 0.03495472008781559,
            "ave_precision_score": 0.795436745325647,
            "fpr": 0.18331503841931943,
            "logloss": 0.5877318235290017,
            "mae": 0.4062602385780421,
            "precision": 0.6854990583804144,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8176586584269799,
            "auditor_fn_violation": 0.022593078929502988,
            "auditor_fp_violation": 0.03819487852648249,
            "ave_precision_score": 0.8182224556627808,
            "fpr": 0.22916666666666666,
            "logloss": 0.5755349893494859,
            "mae": 0.3945749532186279,
            "precision": 0.6671974522292994,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8304475280931614,
            "auditor_fn_violation": 0.01543648187618097,
            "auditor_fp_violation": 0.03973998353457739,
            "ave_precision_score": 0.8306982757824972,
            "fpr": 0.2535675082327113,
            "logloss": 0.5691660860183417,
            "mae": 0.39283781610715535,
            "precision": 0.640746500777605,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6039544354588398,
            "auditor_fn_violation": 0.054194804730767855,
            "auditor_fp_violation": 0.051274638496478724,
            "ave_precision_score": 0.601291269229274,
            "fpr": 0.16228070175438597,
            "logloss": 0.6850615113229049,
            "mae": 0.491594205822861,
            "precision": 0.5865921787709497,
            "recall": 0.42769857433808556
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.587421770503043,
            "auditor_fn_violation": 0.05634517405457179,
            "auditor_fp_violation": 0.05623725889916889,
            "ave_precision_score": 0.5829452894239884,
            "fpr": 0.16575192096597147,
            "logloss": 0.6814994481369397,
            "mae": 0.48966738984037833,
            "precision": 0.5907859078590786,
            "recall": 0.4708423326133909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.783372754921859,
            "auditor_fn_violation": 0.016777879015257086,
            "auditor_fp_violation": 0.022862232779097394,
            "ave_precision_score": 0.7840431168131963,
            "fpr": 0.1600877192982456,
            "logloss": 0.583738325713894,
            "mae": 0.4040662240964083,
            "precision": 0.7125984251968503,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7900533585559465,
            "auditor_fn_violation": 0.012603338604481349,
            "auditor_fp_violation": 0.0325192096597146,
            "ave_precision_score": 0.7903464546449221,
            "fpr": 0.1800219538968167,
            "logloss": 0.5881455486450715,
            "mae": 0.40652623526449394,
            "precision": 0.6840077071290944,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 14289,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.5691100637307356,
            "auditor_fn_violation": 0.0023805695501482814,
            "auditor_fp_violation": 0.002747739300745928,
            "ave_precision_score": 0.5671267859864345,
            "fpr": 0.029605263157894735,
            "logloss": 0.695560314986199,
            "mae": 0.5006443829063261,
            "precision": 0.4489795918367347,
            "recall": 0.04480651731160896
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5700041622368367,
            "auditor_fn_violation": 0.004867316432468064,
            "auditor_fp_violation": 0.00555708013172338,
            "ave_precision_score": 0.5658881565356843,
            "fpr": 0.02305159165751921,
            "logloss": 0.6912387095360703,
            "mae": 0.49854272826442864,
            "precision": 0.5,
            "recall": 0.04535637149028078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5983981214610575,
            "auditor_fn_violation": 0.05456774573909315,
            "auditor_fp_violation": 0.051274638496478724,
            "ave_precision_score": 0.5958099316776543,
            "fpr": 0.16228070175438597,
            "logloss": 0.6869585631550164,
            "mae": 0.49247588014654947,
            "precision": 0.5877437325905293,
            "recall": 0.42973523421588594
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.5799830238695829,
            "auditor_fn_violation": 0.056684202914699874,
            "auditor_fp_violation": 0.05735455543358947,
            "ave_precision_score": 0.5752102764981386,
            "fpr": 0.1690450054884742,
            "logloss": 0.6834607557547855,
            "mae": 0.4906530724071645,
            "precision": 0.5871313672922251,
            "recall": 0.47300215982721383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7533961962141673,
            "auditor_fn_violation": 0.005781702218887341,
            "auditor_fp_violation": 0.03400685502354462,
            "ave_precision_score": 0.7511568323607289,
            "fpr": 0.27960526315789475,
            "logloss": 1.3118992019792999,
            "mae": 0.3232344490765483,
            "precision": 0.6423562412342216,
            "recall": 0.9327902240325866
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7241061788340606,
            "auditor_fn_violation": 0.002942201506426138,
            "auditor_fp_violation": 0.02508036694370394,
            "ave_precision_score": 0.7238112578872331,
            "fpr": 0.3029637760702525,
            "logloss": 1.389564097626206,
            "mae": 0.34248367605868935,
            "precision": 0.6129032258064516,
            "recall": 0.9438444924406048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8037033169619887,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.006107534275117726,
            "ave_precision_score": 0.7924084875004603,
            "fpr": 0.09100877192982457,
            "logloss": 0.5836523180200576,
            "mae": 0.3838000310862666,
            "precision": 0.7675070028011205,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.807991319488443,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.010864238670221108,
            "ave_precision_score": 0.7973090266102334,
            "fpr": 0.10208562019758508,
            "logloss": 0.5508097144841889,
            "mae": 0.3729458104422404,
            "precision": 0.7486486486486487,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8184751998518313,
            "auditor_fn_violation": 0.036204309143530934,
            "auditor_fp_violation": 0.008295307746801683,
            "ave_precision_score": 0.8189340697010646,
            "fpr": 0.06030701754385965,
            "logloss": 0.7608605504020202,
            "mae": 0.3253427573808836,
            "precision": 0.8372781065088757,
            "recall": 0.5763747454175153
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8039689151932381,
            "auditor_fn_violation": 0.03146804238097835,
            "auditor_fp_violation": 0.01796495217186765,
            "ave_precision_score": 0.8044504965019391,
            "fpr": 0.07244785949506037,
            "logloss": 0.7148488604216207,
            "mae": 0.31621861405249896,
            "precision": 0.8081395348837209,
            "recall": 0.6004319654427646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6068222445569672,
            "auditor_fn_violation": 0.05152838818022653,
            "auditor_fp_violation": 0.023380526732508244,
            "ave_precision_score": 0.5473905317426372,
            "fpr": 0.19846491228070176,
            "logloss": 0.6916257572573841,
            "mae": 0.49877933530431046,
            "precision": 0.551980198019802,
            "recall": 0.45417515274949083
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6110059454613241,
            "auditor_fn_violation": 0.05291458132306606,
            "auditor_fp_violation": 0.03111278814489572,
            "ave_precision_score": 0.5263528497683895,
            "fpr": 0.20087815587266739,
            "logloss": 0.6897735878742599,
            "mae": 0.49757778660918695,
            "precision": 0.5331632653061225,
            "recall": 0.4514038876889849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.612521546345402,
            "auditor_fn_violation": 0.06191044056168935,
            "auditor_fp_violation": 0.055582468641913574,
            "ave_precision_score": 0.6108003523233149,
            "fpr": 0.1787280701754386,
            "logloss": 0.6813945906973126,
            "mae": 0.48251917932117194,
            "precision": 0.5995085995085995,
            "recall": 0.4969450101832994
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5881538086409436,
            "auditor_fn_violation": 0.06288866813816256,
            "auditor_fp_violation": 0.06635418300141133,
            "ave_precision_score": 0.58520750863103,
            "fpr": 0.1942919868276619,
            "logloss": 0.6875606614616646,
            "mae": 0.4862951706649182,
            "precision": 0.5815602836879432,
            "recall": 0.531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7940424090552654,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7705548921021853,
            "fpr": 0.08333333333333333,
            "logloss": 0.5888487912351742,
            "mae": 0.40802426213039117,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8089286479630746,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.011658107260467308,
            "ave_precision_score": 0.7827638522165042,
            "fpr": 0.09879253567508232,
            "logloss": 0.5719398305052067,
            "mae": 0.4026389731631975,
            "precision": 0.7547683923705722,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 14289,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7327303784669765,
            "auditor_fn_violation": 0.0006654875477900454,
            "auditor_fp_violation": 0.022216318706505,
            "ave_precision_score": 0.7263765280897764,
            "fpr": 0.3881578947368421,
            "logloss": 1.9276309565824816,
            "mae": 0.39268945781881676,
            "precision": 0.5785714285714286,
            "recall": 0.9898167006109979
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6927784886064109,
            "auditor_fn_violation": 0.001977273212215471,
            "auditor_fp_violation": 0.010891190998902307,
            "ave_precision_score": 0.6901358509227034,
            "fpr": 0.4313940724478595,
            "logloss": 2.183416888723058,
            "mae": 0.42572249122511935,
            "precision": 0.5365566037735849,
            "recall": 0.9827213822894169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8259507653558161,
            "auditor_fn_violation": 0.010194465287454896,
            "auditor_fp_violation": 0.015616535400258367,
            "ave_precision_score": 0.8262182428431035,
            "fpr": 0.14802631578947367,
            "logloss": 1.1374538557214329,
            "mae": 0.2773932039286361,
            "precision": 0.7368421052631579,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8406659376242008,
            "auditor_fn_violation": 0.006074069508028826,
            "auditor_fp_violation": 0.019150854633840367,
            "ave_precision_score": 0.8408862320890681,
            "fpr": 0.14928649835345773,
            "logloss": 0.9937461141334406,
            "mae": 0.2594175880171682,
            "precision": 0.7359223300970874,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7908755819894655,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7737219934715243,
            "fpr": 0.08333333333333333,
            "logloss": 0.5841053892547481,
            "mae": 0.3834383500527525,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7976915147138062,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.012812156970362247,
            "ave_precision_score": 0.7799713762559293,
            "fpr": 0.09769484083424808,
            "logloss": 0.5512701355802574,
            "mae": 0.3730164526846223,
            "precision": 0.7568306010928961,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6832723821603588,
            "auditor_fn_violation": 0.018908332440061466,
            "auditor_fp_violation": 0.0003984873109138677,
            "ave_precision_score": 0.6592623239759132,
            "fpr": 0.09539473684210527,
            "logloss": 1.1734213528112152,
            "mae": 0.43622335092278947,
            "precision": 0.7030716723549488,
            "recall": 0.4195519348268839
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6933171338663838,
            "auditor_fn_violation": 0.024365032136616786,
            "auditor_fp_violation": 0.014074015994981967,
            "ave_precision_score": 0.6679794148327447,
            "fpr": 0.10208562019758508,
            "logloss": 1.1500350525528396,
            "mae": 0.4257392825397257,
            "precision": 0.7084639498432602,
            "recall": 0.48812095032397407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.795893810000154,
            "auditor_fn_violation": 0.01352860256547683,
            "auditor_fp_violation": 0.02221892319873317,
            "ave_precision_score": 0.7965652623519943,
            "fpr": 0.18530701754385964,
            "logloss": 0.5764690979834033,
            "mae": 0.4025014260285452,
            "precision": 0.70298769771529,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8013496729058277,
            "auditor_fn_violation": 0.00896411272828141,
            "auditor_fp_violation": 0.02778540065861692,
            "ave_precision_score": 0.8016309336292011,
            "fpr": 0.21514818880351264,
            "logloss": 0.5857254375702939,
            "mae": 0.4072438865556544,
            "precision": 0.666098807495741,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7550432327417741,
            "auditor_fn_violation": 0.00825829849573016,
            "auditor_fp_violation": 0.02129172396549569,
            "ave_precision_score": 0.7559466139908058,
            "fpr": 0.21710526315789475,
            "logloss": 1.0962757538761791,
            "mae": 0.30994008723692196,
            "precision": 0.6769983686786297,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7256269677964938,
            "auditor_fn_violation": 0.010889227654323331,
            "auditor_fp_violation": 0.019190058021013017,
            "ave_precision_score": 0.7262155206873712,
            "fpr": 0.23710208562019758,
            "logloss": 1.1425598391299059,
            "mae": 0.3174543233574353,
            "precision": 0.6459016393442623,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8176606696391483,
            "auditor_fn_violation": 0.022593078929502988,
            "auditor_fp_violation": 0.03819487852648249,
            "ave_precision_score": 0.8182160284865369,
            "fpr": 0.22916666666666666,
            "logloss": 0.5755469077512144,
            "mae": 0.3945819394981587,
            "precision": 0.6671974522292994,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8304567557877062,
            "auditor_fn_violation": 0.01543648187618097,
            "auditor_fp_violation": 0.03973998353457739,
            "ave_precision_score": 0.830709285942188,
            "fpr": 0.2535675082327113,
            "logloss": 0.569166265395626,
            "mae": 0.39284054217727205,
            "precision": 0.640746500777605,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6440286028225334,
            "auditor_fn_violation": 0.004021956622717709,
            "auditor_fp_violation": 0.0005026670000416719,
            "ave_precision_score": 0.5575922904082137,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6977137134362653,
            "mae": 0.4994335464087495,
            "precision": 0.9166666666666666,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.633371300202288,
            "auditor_fn_violation": 0.004639716638256212,
            "auditor_fp_violation": 0.0006223537713658461,
            "ave_precision_score": 0.5390796459510355,
            "fpr": 0.0010976948408342481,
            "logloss": 0.689322229989248,
            "mae": 0.4948951102768681,
            "precision": 0.9411764705882353,
            "recall": 0.03455723542116631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6087202507784536,
            "auditor_fn_violation": 0.042903848215242804,
            "auditor_fp_violation": 0.031253906738342295,
            "ave_precision_score": 0.5482636101953259,
            "fpr": 0.20065789473684212,
            "logloss": 0.6901738587753227,
            "mae": 0.4976738075676717,
            "precision": 0.5536585365853659,
            "recall": 0.4623217922606925
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.6101316045998627,
            "auditor_fn_violation": 0.04224347013819576,
            "auditor_fp_violation": 0.040639211227850094,
            "ave_precision_score": 0.5253987983525933,
            "fpr": 0.20417124039517015,
            "logloss": 0.689631834561664,
            "mae": 0.4971408164200223,
            "precision": 0.5303030303030303,
            "recall": 0.4535637149028078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8275341174339218,
            "auditor_fn_violation": 0.005938024797227285,
            "auditor_fp_violation": 0.018557007125890736,
            "ave_precision_score": 0.8278232226967835,
            "fpr": 0.1600877192982456,
            "logloss": 0.8780908477369608,
            "mae": 0.2791674684429937,
            "precision": 0.7250470809792844,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8404593803206479,
            "auditor_fn_violation": 0.007631705599666189,
            "auditor_fp_violation": 0.0225517484710679,
            "ave_precision_score": 0.8406972217687124,
            "fpr": 0.16245883644346873,
            "logloss": 0.7906513056618868,
            "mae": 0.259839475760951,
            "precision": 0.7243947858472998,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6128339726427221,
            "auditor_fn_violation": 0.06335084146210744,
            "auditor_fp_violation": 0.056678959869983746,
            "ave_precision_score": 0.6097354326559913,
            "fpr": 0.1787280701754386,
            "logloss": 0.6814965653071753,
            "mae": 0.4829292250306983,
            "precision": 0.5945273631840796,
            "recall": 0.48676171079429736
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5867960737448292,
            "auditor_fn_violation": 0.06347426344202015,
            "auditor_fp_violation": 0.06574408028853694,
            "ave_precision_score": 0.5822386135891817,
            "fpr": 0.19319429198682767,
            "logloss": 0.6877217857971005,
            "mae": 0.4867955325529159,
            "precision": 0.5799522673031027,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6114695946165913,
            "auditor_fn_violation": 0.062225318898059816,
            "auditor_fp_violation": 0.055582468641913574,
            "ave_precision_score": 0.6091727042110677,
            "fpr": 0.1787280701754386,
            "logloss": 0.681586752956656,
            "mae": 0.4830356635676141,
            "precision": 0.5914786967418546,
            "recall": 0.48065173116089616
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5835507732779541,
            "auditor_fn_violation": 0.06314708873784061,
            "auditor_fp_violation": 0.06560441822173436,
            "ave_precision_score": 0.5801062401975547,
            "fpr": 0.19209659714599342,
            "logloss": 0.6882407350181098,
            "mae": 0.4870792403571823,
            "precision": 0.5813397129186603,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8134397604041648,
            "auditor_fn_violation": 0.0297303212205667,
            "auditor_fp_violation": 0.016770325457348835,
            "ave_precision_score": 0.814082164905159,
            "fpr": 0.07785087719298246,
            "logloss": 0.7191813210984237,
            "mae": 0.32169800117688746,
            "precision": 0.8070652173913043,
            "recall": 0.604887983706721
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8048949563407464,
            "auditor_fn_violation": 0.02358739950639295,
            "auditor_fp_violation": 0.019439979614238673,
            "ave_precision_score": 0.8053579429220232,
            "fpr": 0.0889132821075741,
            "logloss": 0.6719216955600904,
            "mae": 0.3150561957644432,
            "precision": 0.7896103896103897,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8280930607650462,
            "auditor_fn_violation": 0.006199306821024049,
            "auditor_fp_violation": 0.020640600908446896,
            "ave_precision_score": 0.8283375284355573,
            "fpr": 0.15350877192982457,
            "logloss": 0.882255414300398,
            "mae": 0.2745307608567635,
            "precision": 0.7333333333333333,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8432460289982079,
            "auditor_fn_violation": 0.0068730396189600135,
            "auditor_fp_violation": 0.026494139093617693,
            "ave_precision_score": 0.84347217008769,
            "fpr": 0.16355653128430298,
            "logloss": 0.7912624780529401,
            "mae": 0.26236245101324335,
            "precision": 0.71939736346516,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8063687220014557,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7573023434393901,
            "fpr": 0.08333333333333333,
            "logloss": 0.5870956992071492,
            "mae": 0.40578388398219095,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8115518302554195,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.011658107260467308,
            "ave_precision_score": 0.7597347777526307,
            "fpr": 0.09879253567508232,
            "logloss": 0.5692481225472087,
            "mae": 0.40006982605458613,
            "precision": 0.7547683923705722,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7533848241449274,
            "auditor_fn_violation": 0.005781702218887341,
            "auditor_fp_violation": 0.03400685502354462,
            "ave_precision_score": 0.7511454786737861,
            "fpr": 0.27960526315789475,
            "logloss": 1.3117077218227393,
            "mae": 0.32322000457331634,
            "precision": 0.6423562412342216,
            "recall": 0.9327902240325866
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7241184757392325,
            "auditor_fn_violation": 0.002942201506426138,
            "auditor_fp_violation": 0.02508036694370394,
            "ave_precision_score": 0.7238235437849456,
            "fpr": 0.3029637760702525,
            "logloss": 1.3893673138733598,
            "mae": 0.34246241572417413,
            "precision": 0.6129032258064516,
            "recall": 0.9438444924406048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7576247417398084,
            "auditor_fn_violation": 0.008198002644084755,
            "auditor_fp_violation": 0.021046901696045343,
            "ave_precision_score": 0.7585039322328933,
            "fpr": 0.2324561403508772,
            "logloss": 1.0396025457711027,
            "mae": 0.30814809823877304,
            "precision": 0.6713178294573643,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7340329997206819,
            "auditor_fn_violation": 0.003738800786167625,
            "auditor_fp_violation": 0.026121706915477508,
            "ave_precision_score": 0.734582447976226,
            "fpr": 0.2535675082327113,
            "logloss": 1.0865498087206058,
            "mae": 0.3198054886730574,
            "precision": 0.6413043478260869,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7823017500956094,
            "auditor_fn_violation": 0.006306499446171437,
            "auditor_fp_violation": 0.014168437721381835,
            "ave_precision_score": 0.7813438079428897,
            "fpr": 0.2741228070175439,
            "logloss": 1.4374185628995952,
            "mae": 0.32005999979816924,
            "precision": 0.647887323943662,
            "recall": 0.9368635437881874
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7797225478631383,
            "auditor_fn_violation": 0.005218199448544666,
            "auditor_fp_violation": 0.03487876352516858,
            "ave_precision_score": 0.7782637216432864,
            "fpr": 0.31284302963776073,
            "logloss": 1.4957675635287617,
            "mae": 0.3442991012409286,
            "precision": 0.6047156726768377,
            "recall": 0.9416846652267818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7626036934324185,
            "auditor_fn_violation": 0.007362793439811343,
            "auditor_fp_violation": 0.026070967204233863,
            "ave_precision_score": 0.763468622374966,
            "fpr": 0.25548245614035087,
            "logloss": 1.049958333203527,
            "mae": 0.31614239598659905,
            "precision": 0.6588579795021962,
            "recall": 0.9164969450101833
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7358688427235608,
            "auditor_fn_violation": 0.006825622995165876,
            "auditor_fp_violation": 0.03250940881292144,
            "ave_precision_score": 0.7366436207429434,
            "fpr": 0.28210757409440174,
            "logloss": 1.1238617752964914,
            "mae": 0.3304802355974835,
            "precision": 0.623718887262079,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7493099624955,
            "auditor_fn_violation": 0.006947422017365207,
            "auditor_fp_violation": 0.029501083468766936,
            "ave_precision_score": 0.7474361620720453,
            "fpr": 0.27850877192982454,
            "logloss": 1.29216247561296,
            "mae": 0.3217173521652173,
            "precision": 0.6437587657784011,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7225254021083958,
            "auditor_fn_violation": 0.0065197857716936996,
            "auditor_fp_violation": 0.02325740944017564,
            "ave_precision_score": 0.7222009617502094,
            "fpr": 0.3150384193194292,
            "logloss": 1.3793222924923405,
            "mae": 0.34350879781690163,
            "precision": 0.6008344923504868,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8119067831615105,
            "auditor_fn_violation": 0.028667327687855088,
            "auditor_fp_violation": 0.013420948451889823,
            "ave_precision_score": 0.8125625414417991,
            "fpr": 0.07675438596491228,
            "logloss": 0.7220857287666168,
            "mae": 0.3216309053697339,
            "precision": 0.8108108108108109,
            "recall": 0.6109979633401222
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.800262784615368,
            "auditor_fn_violation": 0.023568432856875304,
            "auditor_fp_violation": 0.019947173435784858,
            "ave_precision_score": 0.8008198997907362,
            "fpr": 0.09110867178924259,
            "logloss": 0.679105472469804,
            "mae": 0.31551211982031957,
            "precision": 0.7860824742268041,
            "recall": 0.6587473002159827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 14289,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.732739494938791,
            "auditor_fn_violation": 0.0006654875477900454,
            "auditor_fp_violation": 0.022216318706505,
            "ave_precision_score": 0.7263856328432898,
            "fpr": 0.3881578947368421,
            "logloss": 1.927683165566936,
            "mae": 0.3926929570121789,
            "precision": 0.5785714285714286,
            "recall": 0.9898167006109979
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6927739891144816,
            "auditor_fn_violation": 0.001977273212215471,
            "auditor_fp_violation": 0.010891190998902307,
            "ave_precision_score": 0.6901284968241157,
            "fpr": 0.4313940724478595,
            "logloss": 2.1834760783830984,
            "mae": 0.42572729751410454,
            "precision": 0.5365566037735849,
            "recall": 0.9827213822894169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8227383610755369,
            "auditor_fn_violation": 0.00844811876942866,
            "auditor_fp_violation": 0.01976549151977331,
            "ave_precision_score": 0.8229996810271436,
            "fpr": 0.15460526315789475,
            "logloss": 1.2171306605763734,
            "mae": 0.27727509998306404,
            "precision": 0.7304015296367112,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8360519323845119,
            "auditor_fn_violation": 0.0036913841623734895,
            "auditor_fp_violation": 0.01865591187078564,
            "ave_precision_score": 0.8362568625586865,
            "fpr": 0.15587266739846323,
            "logloss": 1.07056985108702,
            "mae": 0.2596143366862991,
            "precision": 0.7300380228136882,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6083051488920583,
            "auditor_fn_violation": 0.0640140958302069,
            "auditor_fp_violation": 0.05273315414426803,
            "ave_precision_score": 0.6065914456134148,
            "fpr": 0.17434210526315788,
            "logloss": 0.6844253340807268,
            "mae": 0.49037853929034453,
            "precision": 0.5933503836317136,
            "recall": 0.4725050916496945
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5732781478408047,
            "auditor_fn_violation": 0.063111526269995,
            "auditor_fp_violation": 0.062311333699231614,
            "ave_precision_score": 0.5715205827387124,
            "fpr": 0.18990120746432493,
            "logloss": 0.6877245524867875,
            "mae": 0.4922006693551098,
            "precision": 0.5800970873786407,
            "recall": 0.5161987041036717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8261733307253069,
            "auditor_fn_violation": 0.009298960231536074,
            "auditor_fp_violation": 0.01737977663874652,
            "ave_precision_score": 0.8264316892998145,
            "fpr": 0.15899122807017543,
            "logloss": 0.9135633810793766,
            "mae": 0.27451852582274866,
            "precision": 0.7284644194756554,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8406347478983857,
            "auditor_fn_violation": 0.006465256654330444,
            "auditor_fp_violation": 0.025046063979927865,
            "ave_precision_score": 0.8408651195859611,
            "fpr": 0.1734357848518112,
            "logloss": 0.8297942665606263,
            "mae": 0.2633496263521307,
            "precision": 0.7116788321167883,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7572679383209343,
            "auditor_fn_violation": 0.0100113445528281,
            "auditor_fp_violation": 0.020802079426594993,
            "ave_precision_score": 0.7581159502330916,
            "fpr": 0.21600877192982457,
            "logloss": 1.0724955263636469,
            "mae": 0.30846924788219793,
            "precision": 0.6796747967479675,
            "recall": 0.8513238289205702
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7274840011407753,
            "auditor_fn_violation": 0.01120217737136463,
            "auditor_fp_violation": 0.01922436098478908,
            "ave_precision_score": 0.7280946165717422,
            "fpr": 0.23929747530186607,
            "logloss": 1.1247313313446046,
            "mae": 0.3176646675124649,
            "precision": 0.6455284552845528,
            "recall": 0.857451403887689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6093281524034504,
            "auditor_fn_violation": 0.06591899810626364,
            "auditor_fp_violation": 0.053644726424136355,
            "ave_precision_score": 0.608119386511917,
            "fpr": 0.17653508771929824,
            "logloss": 0.6842272278780301,
            "mae": 0.4901348027939859,
            "precision": 0.5985037406483791,
            "recall": 0.48879837067209775
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5753406105769465,
            "auditor_fn_violation": 0.06379669648382026,
            "auditor_fp_violation": 0.06542065234436258,
            "ave_precision_score": 0.5741734002030954,
            "fpr": 0.19538968166849616,
            "logloss": 0.6870425191011175,
            "mae": 0.49170367077859906,
            "precision": 0.5751789976133651,
            "recall": 0.5205183585313174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8260451462838032,
            "auditor_fn_violation": 0.005629845999928542,
            "auditor_fp_violation": 0.022484581406009087,
            "ave_precision_score": 0.8262947531354432,
            "fpr": 0.15570175438596492,
            "logloss": 0.9026871827830213,
            "mae": 0.2747729944604302,
            "precision": 0.7330827067669173,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.839898175101772,
            "auditor_fn_violation": 0.005865436363334621,
            "auditor_fp_violation": 0.02534989023051592,
            "ave_precision_score": 0.8401290365075798,
            "fpr": 0.1690450054884742,
            "logloss": 0.824323354319132,
            "mae": 0.2643218244542856,
            "precision": 0.7174311926605504,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.748644793878724,
            "auditor_fn_violation": 0.0076196091042269615,
            "auditor_fp_violation": 0.01895028545234821,
            "ave_precision_score": 0.7494955244672137,
            "fpr": 0.21820175438596492,
            "logloss": 1.1002821802654905,
            "mae": 0.31285506942351493,
            "precision": 0.6753670473083198,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7216957560325594,
            "auditor_fn_violation": 0.0070603352829468466,
            "auditor_fp_violation": 0.02596734357848519,
            "ave_precision_score": 0.7223539588093024,
            "fpr": 0.23819978046103182,
            "logloss": 1.126959173839835,
            "mae": 0.3185433604753733,
            "precision": 0.6430921052631579,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.4341336411292998,
            "auditor_fn_violation": 0.0017441133383356594,
            "auditor_fp_violation": 0.005906988373546695,
            "ave_precision_score": 0.5344005380048901,
            "fpr": 0.020833333333333332,
            "logloss": 0.6942212957975383,
            "mae": 0.5004994869232178,
            "precision": 0.32142857142857145,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5005176522731841,
            "auditor_fn_violation": 0.004924216381021034,
            "auditor_fp_violation": 0.002195389681668497,
            "ave_precision_score": 0.5068895730469936,
            "fpr": 0.021953896816684963,
            "logloss": 0.6934496662036058,
            "mae": 0.5001016385468903,
            "precision": 0.47368421052631576,
            "recall": 0.038876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.813461569590465,
            "auditor_fn_violation": 0.034895665844856545,
            "auditor_fp_violation": 0.012212464058007251,
            "ave_precision_score": 0.8140596178094435,
            "fpr": 0.043859649122807015,
            "logloss": 0.8610856474563111,
            "mae": 0.34187631464512036,
            "precision": 0.8596491228070176,
            "recall": 0.4989816700610998
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8027538144653573,
            "auditor_fn_violation": 0.023272078958161947,
            "auditor_fp_violation": 0.009604829857299673,
            "ave_precision_score": 0.8031979854097866,
            "fpr": 0.052689352360043906,
            "logloss": 0.8163877261186493,
            "mae": 0.32962353750089823,
            "precision": 0.8339100346020761,
            "recall": 0.5205183585313174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8164886043137651,
            "auditor_fn_violation": 0.02766239682709831,
            "auditor_fp_violation": 0.017142767845980747,
            "ave_precision_score": 0.8170748000889482,
            "fpr": 0.07456140350877193,
            "logloss": 0.7079338172741911,
            "mae": 0.319265206645991,
            "precision": 0.816711590296496,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8078407526645415,
            "auditor_fn_violation": 0.025043089856872924,
            "auditor_fp_violation": 0.01953553787047201,
            "ave_precision_score": 0.8082798170975974,
            "fpr": 0.09330406147091108,
            "logloss": 0.6635701268451744,
            "mae": 0.3132426989241848,
            "precision": 0.782608695652174,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7535733635136371,
            "auditor_fn_violation": 0.006947422017365207,
            "auditor_fp_violation": 0.027641476017835568,
            "ave_precision_score": 0.7532225735560225,
            "fpr": 0.26864035087719296,
            "logloss": 1.1782506175418583,
            "mae": 0.31598305646889857,
            "precision": 0.6519886363636364,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.727573009635381,
            "auditor_fn_violation": 0.00677820637137174,
            "auditor_fp_violation": 0.032381997804610325,
            "ave_precision_score": 0.7273481328120371,
            "fpr": 0.3018660812294182,
            "logloss": 1.2998206869634221,
            "mae": 0.3383191035528996,
            "precision": 0.6099290780141844,
            "recall": 0.9287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7593029016314568,
            "auditor_fn_violation": 0.006882659806338657,
            "auditor_fp_violation": 0.02710495061882736,
            "ave_precision_score": 0.7601395129754324,
            "fpr": 0.25877192982456143,
            "logloss": 1.0807675713270264,
            "mae": 0.3175495320398101,
            "precision": 0.6574746008708273,
            "recall": 0.9226069246435845
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7336194073227821,
            "auditor_fn_violation": 0.006825622995165876,
            "auditor_fp_violation": 0.035498667084836136,
            "ave_precision_score": 0.7340755879584011,
            "fpr": 0.2897914379802415,
            "logloss": 1.213515001656768,
            "mae": 0.333230264970862,
            "precision": 0.6173913043478261,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8222796418193601,
            "auditor_fn_violation": 0.0037629077786114967,
            "auditor_fp_violation": 0.016210359628286868,
            "ave_precision_score": 0.8225689190365513,
            "fpr": 0.16337719298245615,
            "logloss": 0.9327999086677223,
            "mae": 0.27744007386706415,
            "precision": 0.7245841035120147,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8372363430694201,
            "auditor_fn_violation": 0.00566154488101984,
            "auditor_fp_violation": 0.026599498196644193,
            "ave_precision_score": 0.8374805836419412,
            "fpr": 0.1778265642151482,
            "logloss": 0.8491051540564982,
            "mae": 0.26633301943886184,
            "precision": 0.7091561938958707,
            "recall": 0.8531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.749926506648936,
            "auditor_fn_violation": 0.011599135312823814,
            "auditor_fp_violation": 0.021640725924073845,
            "ave_precision_score": 0.7506166863730223,
            "fpr": 0.2236842105263158,
            "logloss": 1.1395021996848933,
            "mae": 0.31284319993747295,
            "precision": 0.6725521669341894,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7211218627271905,
            "auditor_fn_violation": 0.008689096310275422,
            "auditor_fp_violation": 0.01639681668496158,
            "ave_precision_score": 0.7210821725838793,
            "fpr": 0.24368825466520308,
            "logloss": 1.2238228767845614,
            "mae": 0.3211724775340858,
            "precision": 0.6413570274636511,
            "recall": 0.857451403887689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8256918753662168,
            "auditor_fn_violation": 0.008030514167291957,
            "auditor_fp_violation": 0.015421198483143729,
            "ave_precision_score": 0.8259769686252978,
            "fpr": 0.16337719298245615,
            "logloss": 0.9253903504118868,
            "mae": 0.2806793226718748,
            "precision": 0.7209737827715356,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8371971155606877,
            "auditor_fn_violation": 0.007681493054650034,
            "auditor_fp_violation": 0.020603830170926773,
            "ave_precision_score": 0.8374416879601494,
            "fpr": 0.15916575192096596,
            "logloss": 0.8332277274915985,
            "mae": 0.2602775332113658,
            "precision": 0.725897920604915,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8258158943877119,
            "auditor_fn_violation": 0.006920623861078359,
            "auditor_fp_violation": 0.021961078468141854,
            "ave_precision_score": 0.8260361897979751,
            "fpr": 0.15679824561403508,
            "logloss": 0.9004281884097006,
            "mae": 0.2756331860101755,
            "precision": 0.7317073170731707,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8412326388174078,
            "auditor_fn_violation": 0.004665795781342981,
            "auditor_fp_violation": 0.02502156186294496,
            "ave_precision_score": 0.8414608615077948,
            "fpr": 0.1712403951701427,
            "logloss": 0.8174838949421731,
            "mae": 0.26506831856020974,
            "precision": 0.7158469945355191,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6085524891884742,
            "auditor_fn_violation": 0.0640140958302069,
            "auditor_fp_violation": 0.05273315414426803,
            "ave_precision_score": 0.6068930658988471,
            "fpr": 0.17434210526315788,
            "logloss": 0.6844303471735054,
            "mae": 0.49038812142322985,
            "precision": 0.5933503836317136,
            "recall": 0.4725050916496945
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5735865247766168,
            "auditor_fn_violation": 0.063111526269995,
            "auditor_fp_violation": 0.062311333699231614,
            "ave_precision_score": 0.5717054285535375,
            "fpr": 0.18990120746432493,
            "logloss": 0.6877637913209066,
            "mae": 0.49222774062669633,
            "precision": 0.5800970873786407,
            "recall": 0.5161987041036717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8280511043140897,
            "auditor_fn_violation": 0.006248436774216601,
            "auditor_fp_violation": 0.021049506188273538,
            "ave_precision_score": 0.828303870414759,
            "fpr": 0.15789473684210525,
            "logloss": 0.8576130998270538,
            "mae": 0.2730945776496894,
            "precision": 0.7318435754189944,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8433454128085242,
            "auditor_fn_violation": 0.006261365172015663,
            "auditor_fp_violation": 0.027177748157440812,
            "ave_precision_score": 0.8435700114785432,
            "fpr": 0.1734357848518112,
            "logloss": 0.787384556602435,
            "mae": 0.2641022072684411,
            "precision": 0.7137681159420289,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7908755819894655,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7737219934715243,
            "fpr": 0.08333333333333333,
            "logloss": 0.584106026389063,
            "mae": 0.3834382976944509,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7976915147138062,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.012812156970362247,
            "ave_precision_score": 0.7799713762559293,
            "fpr": 0.09769484083424808,
            "logloss": 0.5512708709433979,
            "mae": 0.37301633567533954,
            "precision": 0.7568306010928961,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8263043088974116,
            "auditor_fn_violation": 0.01023689570157574,
            "auditor_fp_violation": 0.021229216152019004,
            "ave_precision_score": 0.8265918241046428,
            "fpr": 0.15460526315789475,
            "logloss": 0.9227510287948866,
            "mae": 0.2750410380336435,
            "precision": 0.7339622641509433,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8417089179654776,
            "auditor_fn_violation": 0.0068730396189600135,
            "auditor_fp_violation": 0.026869021483456167,
            "ave_precision_score": 0.8419265194268933,
            "fpr": 0.16355653128430298,
            "logloss": 0.8257802325527303,
            "mae": 0.2630641948333992,
            "precision": 0.71939736346516,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7580348231890272,
            "auditor_fn_violation": 0.008198002644084755,
            "auditor_fp_violation": 0.02053902571154728,
            "ave_precision_score": 0.7589211885834455,
            "fpr": 0.23135964912280702,
            "logloss": 1.0372411000357287,
            "mae": 0.3082909325669135,
            "precision": 0.672360248447205,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7341861614572827,
            "auditor_fn_violation": 0.008660646335998936,
            "auditor_fp_violation": 0.026121706915477508,
            "ave_precision_score": 0.7347354296706557,
            "fpr": 0.2535675082327113,
            "logloss": 1.084340751567054,
            "mae": 0.3197946209337916,
            "precision": 0.6413043478260869,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8063687220014557,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7573023434393901,
            "fpr": 0.08333333333333333,
            "logloss": 0.5870961307632712,
            "mae": 0.4057843031917225,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.811239128361483,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.011658107260467308,
            "ave_precision_score": 0.7597549557302292,
            "fpr": 0.09879253567508232,
            "logloss": 0.5692482252252589,
            "mae": 0.40007010794987924,
            "precision": 0.7547683923705722,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7919767399487843,
            "auditor_fn_violation": 0.007398524314860474,
            "auditor_fp_violation": 0.018958098929032798,
            "ave_precision_score": 0.791932128945416,
            "fpr": 0.24780701754385964,
            "logloss": 1.2303075836104689,
            "mae": 0.3112675813472817,
            "precision": 0.6641901931649331,
            "recall": 0.9103869653767821
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7918769150085014,
            "auditor_fn_violation": 0.0037340591237882102,
            "auditor_fp_violation": 0.02092235769170456,
            "ave_precision_score": 0.7918917937021069,
            "fpr": 0.2667398463227223,
            "logloss": 1.2574195239509298,
            "mae": 0.32305744719409735,
            "precision": 0.6340361445783133,
            "recall": 0.9092872570194385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8142962835403467,
            "auditor_fn_violation": 0.008055079143888233,
            "auditor_fp_violation": 0.023000270867191742,
            "ave_precision_score": 0.814633551400819,
            "fpr": 0.1524122807017544,
            "logloss": 1.1637052949153395,
            "mae": 0.2796428069765655,
            "precision": 0.7326923076923076,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8373676849000543,
            "auditor_fn_violation": 0.005379415969444729,
            "auditor_fp_violation": 0.02981172573310334,
            "ave_precision_score": 0.8375849248897862,
            "fpr": 0.16355653128430298,
            "logloss": 1.0094536836261454,
            "mae": 0.26100771506670106,
            "precision": 0.7178030303030303,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8084238353691015,
            "auditor_fn_violation": 0.01224899060277986,
            "auditor_fp_violation": 0.010793015793640878,
            "ave_precision_score": 0.8086176428042865,
            "fpr": 0.1600877192982456,
            "logloss": 1.3973642730689404,
            "mae": 0.29298146516030354,
            "precision": 0.7213740458015268,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8194774114874749,
            "auditor_fn_violation": 0.007719426353685339,
            "auditor_fp_violation": 0.018562803826250595,
            "ave_precision_score": 0.8187756297765181,
            "fpr": 0.1668496158068057,
            "logloss": 1.2482433451808144,
            "mae": 0.26340618152210565,
            "precision": 0.7185185185185186,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8231981218848939,
            "auditor_fn_violation": 0.00844811876942866,
            "auditor_fp_violation": 0.01780170437971414,
            "ave_precision_score": 0.8234189349012944,
            "fpr": 0.15679824561403508,
            "logloss": 1.2688421058813513,
            "mae": 0.27603599178021576,
            "precision": 0.7276190476190476,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8348376532579491,
            "auditor_fn_violation": 0.0077621013151000645,
            "auditor_fp_violation": 0.017950250901677907,
            "ave_precision_score": 0.8350202292415966,
            "fpr": 0.15697036223929747,
            "logloss": 1.1354148528728047,
            "mae": 0.2591347865157707,
            "precision": 0.7296786389413988,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8240431459592601,
            "auditor_fn_violation": 0.005069317897595315,
            "auditor_fp_violation": 0.017270387965162316,
            "ave_precision_score": 0.8242960674036754,
            "fpr": 0.14692982456140352,
            "logloss": 1.1691209775090987,
            "mae": 0.2763727378167199,
            "precision": 0.7387914230019493,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8385342690356992,
            "auditor_fn_violation": 0.005277470228287341,
            "auditor_fp_violation": 0.020753293084522506,
            "ave_precision_score": 0.8387558783306259,
            "fpr": 0.15477497255762898,
            "logloss": 1.0293114386048665,
            "mae": 0.26314581251516306,
            "precision": 0.7298850574712644,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8083490865444841,
            "auditor_fn_violation": 0.012371815485761245,
            "auditor_fp_violation": 0.012889632037338002,
            "ave_precision_score": 0.8085758144073223,
            "fpr": 0.16337719298245615,
            "logloss": 1.3788597806042544,
            "mae": 0.29246641774336113,
            "precision": 0.718336483931947,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8193577658390405,
            "auditor_fn_violation": 0.006579056551436373,
            "auditor_fp_violation": 0.018562803826250595,
            "ave_precision_score": 0.8187028574081183,
            "fpr": 0.1668496158068057,
            "logloss": 1.2390945425094788,
            "mae": 0.2639209879500682,
            "precision": 0.7195571955719557,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8272357570220524,
            "auditor_fn_violation": 0.008702701254153716,
            "auditor_fp_violation": 0.017218298120598417,
            "ave_precision_score": 0.8275204334407811,
            "fpr": 0.15021929824561403,
            "logloss": 0.9222857582045535,
            "mae": 0.27496218884453266,
            "precision": 0.7360308285163777,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8414754389192858,
            "auditor_fn_violation": 0.008779187895484278,
            "auditor_fp_violation": 0.02405617845381842,
            "ave_precision_score": 0.8416904641006491,
            "fpr": 0.15916575192096596,
            "logloss": 0.8245637926347993,
            "mae": 0.2628132944945476,
            "precision": 0.722753346080306,
            "recall": 0.816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8275603029323574,
            "auditor_fn_violation": 0.005938024797227285,
            "auditor_fp_violation": 0.01607492603242073,
            "ave_precision_score": 0.8278493051118925,
            "fpr": 0.15899122807017543,
            "logloss": 0.8780576735335098,
            "mae": 0.2791672067351231,
            "precision": 0.7264150943396226,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8404441897200392,
            "auditor_fn_violation": 0.007631705599666189,
            "auditor_fp_violation": 0.0225517484710679,
            "ave_precision_score": 0.840666840567495,
            "fpr": 0.16245883644346873,
            "logloss": 0.7906170741034633,
            "mae": 0.25983979304941135,
            "precision": 0.7243947858472998,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 14289,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7328914102932909,
            "auditor_fn_violation": 0.0006654875477900454,
            "auditor_fp_violation": 0.022216318706505,
            "ave_precision_score": 0.7265714250701294,
            "fpr": 0.3881578947368421,
            "logloss": 1.9260623625375373,
            "mae": 0.39256307796887613,
            "precision": 0.5785714285714286,
            "recall": 0.9898167006109979
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6924973215973158,
            "auditor_fn_violation": 0.001977273212215471,
            "auditor_fp_violation": 0.010891190998902307,
            "ave_precision_score": 0.6898602076516216,
            "fpr": 0.4313940724478595,
            "logloss": 2.181643165718271,
            "mae": 0.4254672837154337,
            "precision": 0.5365566037735849,
            "recall": 0.9827213822894169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7919749691018136,
            "auditor_fn_violation": 0.007398524314860474,
            "auditor_fp_violation": 0.018958098929032798,
            "ave_precision_score": 0.7919116828189051,
            "fpr": 0.24780701754385964,
            "logloss": 1.2299690744980796,
            "mae": 0.3112565804906313,
            "precision": 0.6641901931649331,
            "recall": 0.9103869653767821
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7918933692250543,
            "auditor_fn_violation": 0.0037340591237882102,
            "auditor_fp_violation": 0.02092235769170456,
            "ave_precision_score": 0.7919082312899516,
            "fpr": 0.2667398463227223,
            "logloss": 1.2570192711921926,
            "mae": 0.3230352827694633,
            "precision": 0.6340361445783133,
            "recall": 0.9092872570194385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.810102866538551,
            "auditor_fn_violation": 0.015958302068817667,
            "auditor_fp_violation": 0.012493749218652338,
            "ave_precision_score": 0.8103097077252888,
            "fpr": 0.16228070175438597,
            "logloss": 1.3958596016072973,
            "mae": 0.2927194813670918,
            "precision": 0.7175572519083969,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8198873617082301,
            "auditor_fn_violation": 0.010230136583584841,
            "auditor_fp_violation": 0.018160969107730913,
            "ave_precision_score": 0.8191973181847076,
            "fpr": 0.16245883644346873,
            "logloss": 1.23520340774772,
            "mae": 0.26296737683995364,
            "precision": 0.7233644859813084,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7908755819894655,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7737219934715243,
            "fpr": 0.08333333333333333,
            "logloss": 0.5841062856738977,
            "mae": 0.38343828119206846,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7976915147138062,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.012812156970362247,
            "ave_precision_score": 0.7799713762559293,
            "fpr": 0.09769484083424808,
            "logloss": 0.5512711781299098,
            "mae": 0.3730162924521579,
            "precision": 0.7568306010928961,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7907543644647745,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7734384005444841,
            "fpr": 0.08333333333333333,
            "logloss": 0.5803565638840232,
            "mae": 0.38636786319936317,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7971166734501423,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.012812156970362247,
            "ave_precision_score": 0.7790352026466263,
            "fpr": 0.09769484083424808,
            "logloss": 0.5505308101870836,
            "mae": 0.37660758209575285,
            "precision": 0.7568306010928961,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7460612319640885,
            "auditor_fn_violation": 0.007909922464001145,
            "auditor_fp_violation": 0.032681168479393265,
            "ave_precision_score": 0.7428555102319925,
            "fpr": 0.2817982456140351,
            "logloss": 1.4672244830966734,
            "mae": 0.3267138586399882,
            "precision": 0.6405594405594406,
            "recall": 0.9327902240325866
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7112933629410864,
            "auditor_fn_violation": 0.006560089901918715,
            "auditor_fp_violation": 0.02774619727144426,
            "ave_precision_score": 0.7092590870177371,
            "fpr": 0.31394072447859495,
            "logloss": 1.6317239426233574,
            "mae": 0.35058207028281174,
            "precision": 0.6022253129346314,
            "recall": 0.9352051835853131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8209660674221041,
            "auditor_fn_violation": 0.004863865366062817,
            "auditor_fp_violation": 0.0171714172604909,
            "ave_precision_score": 0.8212527271310311,
            "fpr": 0.16228070175438597,
            "logloss": 0.9468661084643479,
            "mae": 0.27944727681360165,
            "precision": 0.7233644859813084,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8352528568026623,
            "auditor_fn_violation": 0.005571453295810983,
            "auditor_fp_violation": 0.02461972714442528,
            "ave_precision_score": 0.8354969034252132,
            "fpr": 0.1756311745334797,
            "logloss": 0.8566220904856297,
            "mae": 0.2666685441442681,
            "precision": 0.706959706959707,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7520469046800574,
            "auditor_fn_violation": 0.007226569478686537,
            "auditor_fp_violation": 0.01819237821394341,
            "ave_precision_score": 0.7529367200001594,
            "fpr": 0.21710526315789475,
            "logloss": 1.0651268291781038,
            "mae": 0.312391080947344,
            "precision": 0.6754098360655738,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7266226080060273,
            "auditor_fn_violation": 0.005886773844041985,
            "auditor_fp_violation": 0.019736455229731848,
            "ave_precision_score": 0.7274500471081494,
            "fpr": 0.23600439077936333,
            "logloss": 1.0626840227650831,
            "mae": 0.31520884688084566,
            "precision": 0.6434494195688225,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7952636732703389,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7851114044835429,
            "fpr": 0.08333333333333333,
            "logloss": 0.5897443081904578,
            "mae": 0.40719802313271847,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8022137478564034,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.012812156970362247,
            "ave_precision_score": 0.7922390036215482,
            "fpr": 0.09769484083424808,
            "logloss": 0.5690835485900312,
            "mae": 0.39982028796238384,
            "precision": 0.7568306010928961,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 14289,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.826193019967481,
            "auditor_fn_violation": 0.010194465287454896,
            "auditor_fp_violation": 0.01652550318789849,
            "ave_precision_score": 0.8264595298198355,
            "fpr": 0.14473684210526316,
            "logloss": 1.135695045729394,
            "mae": 0.27698936324193574,
            "precision": 0.7411764705882353,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8410376072915157,
            "auditor_fn_violation": 0.006074069508028826,
            "auditor_fp_violation": 0.019150854633840367,
            "ave_precision_score": 0.8412559540862204,
            "fpr": 0.14928649835345773,
            "logloss": 0.9913815149960797,
            "mae": 0.25917128695872405,
            "precision": 0.7359223300970874,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8178163413998573,
            "auditor_fn_violation": 0.023439454032229266,
            "auditor_fp_violation": 0.01328811934825187,
            "ave_precision_score": 0.8182846682879723,
            "fpr": 0.07456140350877193,
            "logloss": 0.709765510000392,
            "mae": 0.3206788213571615,
            "precision": 0.816711590296496,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8086830993358505,
            "auditor_fn_violation": 0.02432946966877118,
            "auditor_fp_violation": 0.020456817469029324,
            "ave_precision_score": 0.8091357846508536,
            "fpr": 0.0889132821075741,
            "logloss": 0.6608890266340068,
            "mae": 0.3133427738197613,
            "precision": 0.7890625,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8261493657452186,
            "auditor_fn_violation": 0.0084302533319041,
            "auditor_fp_violation": 0.016895341084302205,
            "ave_precision_score": 0.8263908929985946,
            "fpr": 0.15789473684210525,
            "logloss": 0.9178924112612022,
            "mae": 0.27472363291994795,
            "precision": 0.7298311444652908,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8385207406934633,
            "auditor_fn_violation": 0.005865436363334621,
            "auditor_fp_violation": 0.024776540693115887,
            "ave_precision_score": 0.8387071617351913,
            "fpr": 0.1756311745334797,
            "logloss": 0.8430106936303149,
            "mae": 0.26529715989833286,
            "precision": 0.7096188747731398,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.744770310181238,
            "auditor_fn_violation": 0.00613677778968807,
            "auditor_fp_violation": 0.0284384506396633,
            "ave_precision_score": 0.7418166108154918,
            "fpr": 0.2883771929824561,
            "logloss": 1.3981544337894742,
            "mae": 0.32518275614867026,
            "precision": 0.6372413793103449,
            "recall": 0.9409368635437881
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7142409130158935,
            "auditor_fn_violation": 0.006074069508028821,
            "auditor_fp_violation": 0.024629527991218446,
            "ave_precision_score": 0.7135978396169769,
            "fpr": 0.3227222832052689,
            "logloss": 1.5211177857560025,
            "mae": 0.35205028744191424,
            "precision": 0.5961538461538461,
            "recall": 0.937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8166733996101563,
            "auditor_fn_violation": 0.027267124021867303,
            "auditor_fp_violation": 0.014384610576322046,
            "ave_precision_score": 0.8172254340403455,
            "fpr": 0.07456140350877193,
            "logloss": 0.7214224534579824,
            "mae": 0.3189248278225276,
            "precision": 0.8162162162162162,
            "recall": 0.615071283095723
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8078164808630948,
            "auditor_fn_violation": 0.024718285983883093,
            "auditor_fp_violation": 0.019724204171240396,
            "ave_precision_score": 0.8082569850765371,
            "fpr": 0.09001097694840834,
            "logloss": 0.6694720716507109,
            "mae": 0.312262889450902,
            "precision": 0.7875647668393783,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7616177414701408,
            "auditor_fn_violation": 0.009140404473505559,
            "auditor_fp_violation": 0.029797995582781196,
            "ave_precision_score": 0.7624927728835509,
            "fpr": 0.24451754385964913,
            "logloss": 1.0062002138229722,
            "mae": 0.3088550277449512,
            "precision": 0.6646616541353384,
            "recall": 0.90020366598778
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7270736883611146,
            "auditor_fn_violation": 0.007498939053042606,
            "auditor_fp_violation": 0.029128116669280238,
            "ave_precision_score": 0.7286896465630018,
            "fpr": 0.2722283205268935,
            "logloss": 1.0644297491638817,
            "mae": 0.3273797819522327,
            "precision": 0.6270676691729323,
            "recall": 0.9006479481641468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7940424090552654,
            "auditor_fn_violation": 0.01178002286776004,
            "auditor_fp_violation": 0.00919125307330083,
            "ave_precision_score": 0.7705548921021853,
            "fpr": 0.08333333333333333,
            "logloss": 0.5892219598071672,
            "mae": 0.406299135990833,
            "precision": 0.7828571428571428,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8089286479630746,
            "auditor_fn_violation": 0.01002387427008035,
            "auditor_fp_violation": 0.011658107260467308,
            "ave_precision_score": 0.7827638522165042,
            "fpr": 0.09879253567508232,
            "logloss": 0.5702826471893145,
            "mae": 0.40006453737731035,
            "precision": 0.7547683923705722,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7580451611384802,
            "auditor_fn_violation": 0.008198002644084755,
            "auditor_fp_violation": 0.02053902571154728,
            "ave_precision_score": 0.7589249042410476,
            "fpr": 0.23135964912280702,
            "logloss": 1.037466471708164,
            "mae": 0.3082981822114737,
            "precision": 0.672360248447205,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7341703802365512,
            "auditor_fn_violation": 0.008660646335998936,
            "auditor_fp_violation": 0.026121706915477508,
            "ave_precision_score": 0.7347196775386752,
            "fpr": 0.2535675082327113,
            "logloss": 1.084421582063715,
            "mae": 0.3198119493960726,
            "precision": 0.6413043478260869,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8282087138178735,
            "auditor_fn_violation": 0.008555311394576055,
            "auditor_fp_violation": 0.021229216152019004,
            "ave_precision_score": 0.8284075014695594,
            "fpr": 0.15460526315789475,
            "logloss": 0.9091452496035402,
            "mae": 0.2742820422724638,
            "precision": 0.7344632768361582,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.843200895608879,
            "auditor_fn_violation": 0.007370914168798441,
            "auditor_fp_violation": 0.026869021483456167,
            "ave_precision_score": 0.8434242383148471,
            "fpr": 0.16355653128430298,
            "logloss": 0.8168800482470234,
            "mae": 0.26315438488323767,
            "precision": 0.7199248120300752,
            "recall": 0.8272138228941684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7523844769683422,
            "auditor_fn_violation": 0.007418622932075608,
            "auditor_fp_violation": 0.029287515106054932,
            "ave_precision_score": 0.751774704214651,
            "fpr": 0.2675438596491228,
            "logloss": 1.1905458064325378,
            "mae": 0.31671501686006004,
            "precision": 0.651925820256776,
            "recall": 0.9307535641547862
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7234600839086462,
            "auditor_fn_violation": 0.0080892760192796,
            "auditor_fp_violation": 0.024061078877215,
            "ave_precision_score": 0.7231938978356192,
            "fpr": 0.3040614709110867,
            "logloss": 1.3194888288953575,
            "mae": 0.3395100611060485,
            "precision": 0.6070921985815603,
            "recall": 0.9244060475161987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.73687259276354,
            "auditor_fn_violation": 0.006804498517168686,
            "auditor_fp_violation": 0.02903487935991999,
            "ave_precision_score": 0.7354562173298342,
            "fpr": 0.30153508771929827,
            "logloss": 1.1907109030300773,
            "mae": 0.3392142092863268,
            "precision": 0.6288798920377868,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6964501107951181,
            "auditor_fn_violation": 0.0010929531784548347,
            "auditor_fp_violation": 0.025281284302963777,
            "ave_precision_score": 0.6963123017768038,
            "fpr": 0.33479692645444564,
            "logloss": 1.3230315052414208,
            "mae": 0.36523779209498236,
            "precision": 0.5938748335552596,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8137594097772153,
            "auditor_fn_violation": 0.008055079143888233,
            "auditor_fp_violation": 0.021575613618368968,
            "ave_precision_score": 0.8140280822441699,
            "fpr": 0.15460526315789475,
            "logloss": 1.1653251149992991,
            "mae": 0.2799927415828278,
            "precision": 0.7298850574712644,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8368719112913181,
            "auditor_fn_violation": 0.005379415969444729,
            "auditor_fp_violation": 0.029657362396111032,
            "ave_precision_score": 0.8371183417654904,
            "fpr": 0.16465422612513722,
            "logloss": 1.010954020443598,
            "mae": 0.26127565020306925,
            "precision": 0.7164461247637051,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.81157452622544,
            "auditor_fn_violation": 0.011257458820166509,
            "auditor_fp_violation": 0.013431366420802605,
            "ave_precision_score": 0.8118195991276755,
            "fpr": 0.15789473684210525,
            "logloss": 1.3785290855975474,
            "mae": 0.29274497562342683,
            "precision": 0.7225433526011561,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8222585594866242,
            "auditor_fn_violation": 0.008857425324744603,
            "auditor_fp_violation": 0.023443625529245733,
            "ave_precision_score": 0.8221783377769865,
            "fpr": 0.15806805708013172,
            "logloss": 1.1944435743019448,
            "mae": 0.26295876229049003,
            "precision": 0.7283018867924528,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8222797002185371,
            "auditor_fn_violation": 0.0037629077786114967,
            "auditor_fp_violation": 0.016210359628286868,
            "ave_precision_score": 0.8225688200367507,
            "fpr": 0.16337719298245615,
            "logloss": 0.9434671864564868,
            "mae": 0.2775521556509749,
            "precision": 0.7245841035120147,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.836806517969731,
            "auditor_fn_violation": 0.00566154488101984,
            "auditor_fp_violation": 0.02481084365689196,
            "ave_precision_score": 0.8370317623722031,
            "fpr": 0.18111964873765093,
            "logloss": 0.8617959667392789,
            "mae": 0.2667246823555146,
            "precision": 0.7053571428571429,
            "recall": 0.8531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7581765666316769,
            "auditor_fn_violation": 0.009281094794011508,
            "auditor_fp_violation": 0.030032399883318756,
            "ave_precision_score": 0.7588635309226359,
            "fpr": 0.2565789473684211,
            "logloss": 1.1321279148314285,
            "mae": 0.3109395943523982,
            "precision": 0.6578947368421053,
            "recall": 0.9164969450101833
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7314513452368588,
            "auditor_fn_violation": 0.006825622995165876,
            "auditor_fp_violation": 0.03406774345303435,
            "ave_precision_score": 0.7319784648811566,
            "fpr": 0.2854006586169045,
            "logloss": 1.2621787630842392,
            "mae": 0.33129723900999897,
            "precision": 0.6209912536443148,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8137485234130409,
            "auditor_fn_violation": 0.02363597384499946,
            "auditor_fp_violation": 0.01878359794974372,
            "ave_precision_score": 0.8143905525671393,
            "fpr": 0.08114035087719298,
            "logloss": 0.6985922407634881,
            "mae": 0.3198676077600563,
            "precision": 0.8052631578947368,
            "recall": 0.6232179226069247
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8049855826075571,
            "auditor_fn_violation": 0.024260715564269678,
            "auditor_fp_violation": 0.022211169045005492,
            "ave_precision_score": 0.805453599438735,
            "fpr": 0.09769484083424808,
            "logloss": 0.6569023296852361,
            "mae": 0.31452139255196315,
            "precision": 0.7769423558897243,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8228595150360228,
            "auditor_fn_violation": 0.009310126129988926,
            "auditor_fp_violation": 0.02206004917281327,
            "ave_precision_score": 0.8230898442056054,
            "fpr": 0.1611842105263158,
            "logloss": 0.9461881794834301,
            "mae": 0.2764627522640091,
            "precision": 0.7267657992565055,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8374042151709611,
            "auditor_fn_violation": 0.005763490622177232,
            "auditor_fp_violation": 0.02700133291516387,
            "ave_precision_score": 0.8375986559514874,
            "fpr": 0.17453347969264543,
            "logloss": 0.8600395151423249,
            "mae": 0.2643631999971045,
            "precision": 0.7119565217391305,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8165196981528813,
            "auditor_fn_violation": 0.017885536141780116,
            "auditor_fp_violation": 0.015340459224069678,
            "ave_precision_score": 0.8170516395102202,
            "fpr": 0.0756578947368421,
            "logloss": 0.723288535910014,
            "mae": 0.3194601178374437,
            "precision": 0.8135135135135135,
            "recall": 0.6130346232179226
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8089915435913344,
            "auditor_fn_violation": 0.02472539847745221,
            "auditor_fp_violation": 0.02018974439391564,
            "ave_precision_score": 0.8094092500375557,
            "fpr": 0.09110867178924259,
            "logloss": 0.6715122635461752,
            "mae": 0.31290313213093224,
            "precision": 0.7871794871794872,
            "recall": 0.6630669546436285
        }
    }
]