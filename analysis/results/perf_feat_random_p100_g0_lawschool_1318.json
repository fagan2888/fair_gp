[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 1318,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8204868375037591,
            "auditor_fn_violation": 0.026801345880293256,
            "auditor_fp_violation": 0.027715024219481424,
            "ave_precision_score": 0.8207666786978128,
            "fpr": 0.14144736842105263,
            "logloss": 1.0497001130294192,
            "mae": 0.2799788992382931,
            "precision": 0.7388663967611336,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8220074420181319,
            "auditor_fn_violation": 0.015481442459207758,
            "auditor_fp_violation": 0.026760697512392934,
            "ave_precision_score": 0.8224132977227675,
            "fpr": 0.13391877058177826,
            "logloss": 0.9162398402645162,
            "mae": 0.26480817891107794,
            "precision": 0.7468879668049793,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7716866747827116,
            "auditor_fn_violation": 0.03641673049567787,
            "auditor_fp_violation": 0.04154709569748037,
            "ave_precision_score": 0.7713593697272789,
            "fpr": 0.1524122807017544,
            "logloss": 2.133911255988221,
            "mae": 0.300015795109313,
            "precision": 0.717479674796748,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.759587156311387,
            "auditor_fn_violation": 0.023819745975312317,
            "auditor_fp_violation": 0.02982822830047768,
            "ave_precision_score": 0.7595122344903134,
            "fpr": 0.14050493962678376,
            "logloss": 1.9622097296420986,
            "mae": 0.2822437605200548,
            "precision": 0.732776617954071,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7810828965561735,
            "auditor_fn_violation": 0.035757923915818654,
            "auditor_fp_violation": 0.038382281108804504,
            "ave_precision_score": 0.7810420563204091,
            "fpr": 0.22478070175438597,
            "logloss": 2.438915112179424,
            "mae": 0.3377217313512504,
            "precision": 0.6644844517184942,
            "recall": 0.8440748440748441
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7792235322306919,
            "auditor_fn_violation": 0.032793923458411756,
            "auditor_fp_violation": 0.03396839240335022,
            "ave_precision_score": 0.7782587129065797,
            "fpr": 0.23380900109769484,
            "logloss": 2.3270521055670446,
            "mae": 0.3358007141889511,
            "precision": 0.6570048309178744,
            "recall": 0.8625792811839323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.8231031885609987,
            "auditor_fn_violation": 0.002122314622314623,
            "auditor_fp_violation": 0.02102159400822243,
            "ave_precision_score": 0.8233778511851803,
            "fpr": 0.3607456140350877,
            "logloss": 1.579614558453529,
            "mae": 0.3742496793058894,
            "precision": 0.5877192982456141,
            "recall": 0.975051975051975
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.8337983208792719,
            "auditor_fn_violation": 0.003044768776267513,
            "auditor_fp_violation": 0.015164729410703279,
            "ave_precision_score": 0.8336363906227667,
            "fpr": 0.38309549945115257,
            "logloss": 1.5152605097691156,
            "mae": 0.37575312568593755,
            "precision": 0.5717791411042945,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 1318,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.729683529579072,
            "auditor_fn_violation": 0.030596892438997707,
            "auditor_fp_violation": 0.022675235071437306,
            "ave_precision_score": 0.7301782121631921,
            "fpr": 0.35526315789473684,
            "logloss": 3.0366544577990453,
            "mae": 0.42580657450375164,
            "precision": 0.5597826086956522,
            "recall": 0.8565488565488566
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7030664793946152,
            "auditor_fn_violation": 0.033051522036281956,
            "auditor_fp_violation": 0.022871148669984822,
            "ave_precision_score": 0.7037382293773379,
            "fpr": 0.34577387486278816,
            "logloss": 2.8371772808786355,
            "mae": 0.4117911887625818,
            "precision": 0.5661157024793388,
            "recall": 0.86892177589852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 1318,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6659550145353083,
            "auditor_fn_violation": 0.01592989750884488,
            "auditor_fp_violation": 0.023641979077624456,
            "ave_precision_score": 0.6668880469415601,
            "fpr": 0.18530701754385964,
            "logloss": 1.3505368636724617,
            "mae": 0.38323120471506017,
            "precision": 0.6731141199226306,
            "recall": 0.7234927234927235
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6287882315373426,
            "auditor_fn_violation": 0.0172382183461243,
            "auditor_fp_violation": 0.02381346204933111,
            "ave_precision_score": 0.6302995370709383,
            "fpr": 0.17672886937431395,
            "logloss": 1.2278374232704257,
            "mae": 0.3718520482951244,
            "precision": 0.6836935166994106,
            "recall": 0.7357293868921776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8342530935821209,
            "auditor_fn_violation": 0.0383270416165153,
            "auditor_fp_violation": 0.036983046363007296,
            "ave_precision_score": 0.8245506203000293,
            "fpr": 0.1524122807017544,
            "logloss": 0.5386743545092917,
            "mae": 0.3608594142031251,
            "precision": 0.7279843444227005,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8157813461494072,
            "auditor_fn_violation": 0.02879302302374317,
            "auditor_fp_violation": 0.03278047606874878,
            "ave_precision_score": 0.8059224791725059,
            "fpr": 0.14818880351262348,
            "logloss": 0.5347561602739537,
            "mae": 0.3625805659462932,
            "precision": 0.7310756972111554,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7705835503096682,
            "auditor_fn_violation": 0.008559926323084222,
            "auditor_fp_violation": 0.021179325925021374,
            "ave_precision_score": 0.6718150504763931,
            "fpr": 0.15570175438596492,
            "logloss": 8.24617731182515,
            "mae": 0.32971606873429293,
            "precision": 0.6946236559139785,
            "recall": 0.6715176715176715
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7801237799451175,
            "auditor_fn_violation": 0.015100846362174323,
            "auditor_fp_violation": 0.024156804956167396,
            "ave_precision_score": 0.6783879579753613,
            "fpr": 0.15477497255762898,
            "logloss": 8.117585416614864,
            "mae": 0.31034958473433577,
            "precision": 0.701271186440678,
            "recall": 0.6997885835095138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8441072732989132,
            "auditor_fn_violation": 0.007623007623007636,
            "auditor_fp_violation": 0.004729413440794564,
            "ave_precision_score": 0.8414169767781488,
            "fpr": 0.07346491228070176,
            "logloss": 0.5097709595535351,
            "mae": 0.30649513259362593,
            "precision": 0.8333333333333334,
            "recall": 0.6964656964656964
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8694603983279575,
            "auditor_fn_violation": 0.013170017382102247,
            "auditor_fp_violation": 0.012861575167035073,
            "ave_precision_score": 0.865680080213046,
            "fpr": 0.06805708013172337,
            "logloss": 0.48268088490972594,
            "mae": 0.3027966421753839,
            "precision": 0.8393782383419689,
            "recall": 0.6849894291754757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.7665487549522858,
            "auditor_fn_violation": 0.0020197322828901933,
            "auditor_fp_violation": 0.004294378638010339,
            "ave_precision_score": 0.7676945293334392,
            "fpr": 0.01644736842105263,
            "logloss": 1.6831305654174875,
            "mae": 0.4948791707542704,
            "precision": 0.3181818181818182,
            "recall": 0.014553014553014554
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.7733896174957227,
            "auditor_fn_violation": 0.0029148091333780694,
            "auditor_fp_violation": 0.004250434817476906,
            "ave_precision_score": 0.7746963040618178,
            "fpr": 0.015367727771679473,
            "logloss": 1.6721913431582995,
            "mae": 0.487713495919374,
            "precision": 0.3333333333333333,
            "recall": 0.014799154334038054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7871736649171948,
            "auditor_fn_violation": 0.0009232410548200038,
            "auditor_fp_violation": 0.01472249358896081,
            "ave_precision_score": 0.7876186623996253,
            "fpr": 0.20065789473684212,
            "logloss": 0.5757996832471508,
            "mae": 0.3967601001487989,
            "precision": 0.6795096322241682,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7468348262698996,
            "auditor_fn_violation": 0.003339498680677553,
            "auditor_fp_violation": 0.009859204346671082,
            "ave_precision_score": 0.7485875997971103,
            "fpr": 0.1756311745334797,
            "logloss": 0.5788668531578597,
            "mae": 0.398652210635359,
            "precision": 0.699812382739212,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.850190079453056,
            "auditor_fn_violation": 0.018633512054564694,
            "auditor_fp_violation": 0.008390320348434894,
            "ave_precision_score": 0.8203524582258992,
            "fpr": 0.06469298245614036,
            "logloss": 0.5211041300825549,
            "mae": 0.3302460909012313,
            "precision": 0.8422459893048129,
            "recall": 0.6548856548856549
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8641283897946432,
            "auditor_fn_violation": 0.01804814540627473,
            "auditor_fp_violation": 0.012375381561734058,
            "ave_precision_score": 0.8381727286795614,
            "fpr": 0.059275521405049394,
            "logloss": 0.49569127505092475,
            "mae": 0.3196577483912854,
            "precision": 0.8532608695652174,
            "recall": 0.6638477801268499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.748571566931042,
            "auditor_fn_violation": 0.04108536674326149,
            "auditor_fp_violation": 0.035583811617210075,
            "ave_precision_score": 0.7489848364018147,
            "fpr": 0.17324561403508773,
            "logloss": 0.7572502899338266,
            "mae": 0.39384594892975366,
            "precision": 0.6694560669456067,
            "recall": 0.6652806652806653
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7672114783121793,
            "auditor_fn_violation": 0.028758212405112057,
            "auditor_fp_violation": 0.04225373291430462,
            "ave_precision_score": 0.7676055140616628,
            "fpr": 0.16794731064763996,
            "logloss": 0.693035231952516,
            "mae": 0.3813474107295272,
            "precision": 0.6723768736616702,
            "recall": 0.6638477801268499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.6916989658092162,
            "mae": 0.4987853625625895,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6924263579469617,
            "mae": 0.4991488204829387,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8494541458628335,
            "auditor_fn_violation": 0.040084619031987456,
            "auditor_fp_violation": 0.044325212683681364,
            "ave_precision_score": 0.8497362008242124,
            "fpr": 0.16447368421052633,
            "logloss": 0.6181824466786744,
            "mae": 0.3056123762599945,
            "precision": 0.7237569060773481,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8454931413575255,
            "auditor_fn_violation": 0.04390547292546119,
            "auditor_fp_violation": 0.041877810023607964,
            "ave_precision_score": 0.8460767335764756,
            "fpr": 0.15477497255762898,
            "logloss": 0.5854275554984165,
            "mae": 0.3008312609523131,
            "precision": 0.7288461538461538,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.5857704607823843,
            "auditor_fn_violation": 0.008858554911186482,
            "auditor_fp_violation": 0.019070297553628855,
            "ave_precision_score": 0.5654939422364065,
            "fpr": 0.08881578947368421,
            "logloss": 6.587006949311669,
            "mae": 0.5466711967573503,
            "precision": 0.425531914893617,
            "recall": 0.12474012474012475
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.5932720171752096,
            "auditor_fn_violation": 0.003214180453605573,
            "auditor_fp_violation": 0.0182648401826484,
            "ave_precision_score": 0.5715730807871244,
            "fpr": 0.09769484083424808,
            "logloss": 6.310483860216409,
            "mae": 0.5407316592422537,
            "precision": 0.43312101910828027,
            "recall": 0.14376321353065538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8385552190854371,
            "auditor_fn_violation": 0.01845798227377175,
            "auditor_fp_violation": 0.010522245288395,
            "ave_precision_score": 0.8389089657091364,
            "fpr": 0.17214912280701755,
            "logloss": 0.5296112659799085,
            "mae": 0.32117201090659364,
            "precision": 0.7160940325497287,
            "recall": 0.8232848232848233
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8423526369819658,
            "auditor_fn_violation": 0.010900365047354052,
            "auditor_fp_violation": 0.022831050228310508,
            "ave_precision_score": 0.8426165458808816,
            "fpr": 0.14709110867178923,
            "logloss": 0.507972629928897,
            "mae": 0.31176449026206804,
            "precision": 0.7471698113207547,
            "recall": 0.8372093023255814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8436909204936605,
            "auditor_fn_violation": 0.0006838822628296324,
            "auditor_fp_violation": 0.010140635812268489,
            "ave_precision_score": 0.8440359093241698,
            "fpr": 0.1118421052631579,
            "logloss": 0.5041375919519278,
            "mae": 0.3396027518085024,
            "precision": 0.7829787234042553,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8331349652581311,
            "auditor_fn_violation": 0.010983910532068708,
            "auditor_fp_violation": 0.009322887689277182,
            "ave_precision_score": 0.8335900792851987,
            "fpr": 0.10647639956092206,
            "logloss": 0.5089690600120517,
            "mae": 0.341595780885442,
            "precision": 0.7815315315315315,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7531541019977113,
            "auditor_fn_violation": 0.006957362220520123,
            "auditor_fp_violation": 0.010534965604265895,
            "ave_precision_score": 0.7468747925292172,
            "fpr": 0.14802631578947367,
            "logloss": 0.6124420488572812,
            "mae": 0.40130464356850115,
            "precision": 0.6823529411764706,
            "recall": 0.6029106029106029
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7551185380460578,
            "auditor_fn_violation": 0.004878128024172495,
            "auditor_fp_violation": 0.00991433970397326,
            "ave_precision_score": 0.7506833823213589,
            "fpr": 0.14928649835345773,
            "logloss": 0.6110151304179567,
            "mae": 0.401171531008902,
            "precision": 0.6784869976359338,
            "recall": 0.6067653276955602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7702143891060094,
            "auditor_fn_violation": 0.0008024218550534343,
            "auditor_fp_violation": 0.010456099645866407,
            "ave_precision_score": 0.574103787567632,
            "fpr": 0.44846491228070173,
            "logloss": 0.6876774897803821,
            "mae": 0.49274777457640884,
            "precision": 0.5373303167420814,
            "recall": 0.9875259875259875
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7465015575970577,
            "auditor_fn_violation": 0.0024088948092726202,
            "auditor_fp_violation": 0.00785929456816485,
            "ave_precision_score": 0.5506035911788504,
            "fpr": 0.4522502744237102,
            "logloss": 0.6900957269782327,
            "mae": 0.49397998606595983,
            "precision": 0.5296803652968036,
            "recall": 0.9809725158562368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.831042048143931,
            "auditor_fn_violation": 0.017780938833570414,
            "auditor_fp_violation": 0.02042628322546506,
            "ave_precision_score": 0.83126566902147,
            "fpr": 0.18092105263157895,
            "logloss": 0.9994351152138552,
            "mae": 0.29399442467398934,
            "precision": 0.6955719557195572,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8401327329977605,
            "auditor_fn_violation": 0.012603764652369561,
            "auditor_fp_violation": 0.026334651569603382,
            "ave_precision_score": 0.8407115287785929,
            "fpr": 0.17014270032930845,
            "logloss": 0.9088526687278746,
            "mae": 0.275588897890657,
            "precision": 0.7113594040968343,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8363203226389704,
            "auditor_fn_violation": 0.0018328044643834127,
            "auditor_fp_violation": 0.013249481011112469,
            "ave_precision_score": 0.8316304612562945,
            "fpr": 0.09429824561403509,
            "logloss": 0.5208078640340609,
            "mae": 0.333010474207664,
            "precision": 0.8045454545454546,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8151529421583483,
            "auditor_fn_violation": 0.0069714065578564055,
            "auditor_fp_violation": 0.013691111679172368,
            "ave_precision_score": 0.809396418713683,
            "fpr": 0.07793633369923161,
            "logloss": 0.5318853140471413,
            "mae": 0.3330712710046153,
            "precision": 0.8233830845771144,
            "recall": 0.6997885835095138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8316390525925008,
            "auditor_fn_violation": 0.01151657730605099,
            "auditor_fp_violation": 0.008922029551837834,
            "ave_precision_score": 0.8284294088112693,
            "fpr": 0.10635964912280702,
            "logloss": 0.5057088517563932,
            "mae": 0.3288780720781927,
            "precision": 0.7940552016985138,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8592276366997549,
            "auditor_fn_violation": 0.013515802860504572,
            "auditor_fp_violation": 0.012886636693081517,
            "ave_precision_score": 0.8472391726031816,
            "fpr": 0.09549945115257959,
            "logloss": 0.4882451940580299,
            "mae": 0.32143376977412946,
            "precision": 0.8036117381489842,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8185572206001881,
            "auditor_fn_violation": 0.0030318780318780436,
            "auditor_fp_violation": 0.008998351447063133,
            "ave_precision_score": 0.8191996241902191,
            "fpr": 0.07785087719298246,
            "logloss": 0.5212024167658681,
            "mae": 0.33710535959414156,
            "precision": 0.8165374677002584,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8343943869516517,
            "auditor_fn_violation": 0.00897417748309945,
            "auditor_fp_violation": 0.011207514447969767,
            "ave_precision_score": 0.8286381526287896,
            "fpr": 0.06476399560922064,
            "logloss": 0.5097400581550471,
            "mae": 0.328104495971528,
            "precision": 0.837465564738292,
            "recall": 0.642706131078224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 1318,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8464077448611049,
            "auditor_fn_violation": 0.011012784039099829,
            "auditor_fp_violation": 0.00478792689380063,
            "ave_precision_score": 0.8245271273274306,
            "fpr": 0.12719298245614036,
            "logloss": 0.5197037744612835,
            "mae": 0.3192839079226057,
            "precision": 0.7637474541751528,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8723356020574922,
            "auditor_fn_violation": 0.008588939970248533,
            "auditor_fp_violation": 0.007728974632723344,
            "ave_precision_score": 0.8536247468139293,
            "fpr": 0.11086717892425905,
            "logloss": 0.4767237784974068,
            "mae": 0.3010822681241907,
            "precision": 0.7846481876332623,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6381553504820993,
            "auditor_fn_violation": 0.051006218769376666,
            "auditor_fp_violation": 0.041076444010257666,
            "ave_precision_score": 0.5859593391393061,
            "fpr": 0.2982456140350877,
            "logloss": 0.6889548763556965,
            "mae": 0.46862055965434474,
            "precision": 0.5474209650582362,
            "recall": 0.683991683991684
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6470095910461592,
            "auditor_fn_violation": 0.059010960703452985,
            "auditor_fp_violation": 0.03067530788084749,
            "ave_precision_score": 0.5870372697380533,
            "fpr": 0.31174533479692645,
            "logloss": 0.6763436238444267,
            "mae": 0.466898123153249,
            "precision": 0.5367047308319739,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.7195609271429583,
            "auditor_fn_violation": 0.001126126126126134,
            "auditor_fp_violation": 0.0012898400293076084,
            "ave_precision_score": 0.7495979505349264,
            "fpr": 0.009868421052631578,
            "logloss": 0.8653697514685156,
            "mae": 0.42598119540498336,
            "precision": 0.35714285714285715,
            "recall": 0.010395010395010396
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.7981763734807709,
            "auditor_fn_violation": 0.0015061394327725913,
            "auditor_fp_violation": 0.0016239868878095728,
            "ave_precision_score": 0.7646738689746865,
            "fpr": 0.003293084522502744,
            "logloss": 0.8486346608069699,
            "mae": 0.41507812271850353,
            "precision": 0.7857142857142857,
            "recall": 0.023255813953488372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8312141632588289,
            "auditor_fn_violation": 0.00546193967246599,
            "auditor_fp_violation": 0.02265488256604389,
            "ave_precision_score": 0.8317282796335859,
            "fpr": 0.23793859649122806,
            "logloss": 0.5980520645811854,
            "mae": 0.33935386620527297,
            "precision": 0.6692073170731707,
            "recall": 0.9126819126819127
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8376193043091789,
            "auditor_fn_violation": 0.012529501999289865,
            "auditor_fp_violation": 0.01834503706599703,
            "ave_precision_score": 0.8379870279539743,
            "fpr": 0.2261251372118551,
            "logloss": 0.5836990104448226,
            "mae": 0.3386369467223253,
            "precision": 0.6786271450858035,
            "recall": 0.919661733615222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8504179893787754,
            "auditor_fn_violation": 0.0014931429405113674,
            "auditor_fp_violation": 0.009586030040297962,
            "ave_precision_score": 0.8507373284622817,
            "fpr": 0.10307017543859649,
            "logloss": 0.4965810549140635,
            "mae": 0.3255688807040682,
            "precision": 0.7929515418502202,
            "recall": 0.7484407484407485
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8445227010773204,
            "auditor_fn_violation": 0.0061405931265273335,
            "auditor_fp_violation": 0.01129522978913232,
            "ave_precision_score": 0.8448938919591965,
            "fpr": 0.09110867178924259,
            "logloss": 0.50033221827186,
            "mae": 0.32850894321300067,
            "precision": 0.8047058823529412,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7378291236238252,
            "auditor_fn_violation": 0.0002621548674180362,
            "auditor_fp_violation": 0.00559185085684048,
            "ave_precision_score": 0.7304323465283635,
            "fpr": 0.0756578947368421,
            "logloss": 1.2917981146410464,
            "mae": 0.3829882316779356,
            "precision": 0.8050847457627118,
            "recall": 0.5925155925155925
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7510521443438664,
            "auditor_fn_violation": 0.010269132496176635,
            "auditor_fp_violation": 0.011230069821411566,
            "ave_precision_score": 0.7359484478986055,
            "fpr": 0.06476399560922064,
            "logloss": 1.311669289366452,
            "mae": 0.38678201818222857,
            "precision": 0.8161993769470405,
            "recall": 0.5539112050739958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8272957822258807,
            "auditor_fn_violation": 0.00652195717985192,
            "auditor_fp_violation": 0.027254548784955434,
            "ave_precision_score": 0.8276110474269334,
            "fpr": 0.13815789473684212,
            "logloss": 0.5386184558351292,
            "mae": 0.3243015589623451,
            "precision": 0.7469879518072289,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8385942608196884,
            "auditor_fn_violation": 0.01604769518894044,
            "auditor_fp_violation": 0.031216636843450673,
            "ave_precision_score": 0.8389483982505062,
            "fpr": 0.13172338090010977,
            "logloss": 0.5149655037878852,
            "mae": 0.3195883440820891,
            "precision": 0.7505197505197505,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6636134566264149,
            "auditor_fn_violation": 0.012093318014370642,
            "auditor_fp_violation": 0.00021878943297920026,
            "ave_precision_score": 0.6624823561777633,
            "fpr": 0.009868421052631578,
            "logloss": 7.885944305104746,
            "mae": 0.46056295861103935,
            "precision": 0.9010989010989011,
            "recall": 0.1704781704781705
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6610632099596874,
            "auditor_fn_violation": 0.011947004314196012,
            "auditor_fp_violation": 0.000616513540742523,
            "ave_precision_score": 0.6585109771348305,
            "fpr": 0.0043907793633369925,
            "logloss": 8.094153864832121,
            "mae": 0.4567559958327869,
            "precision": 0.9506172839506173,
            "recall": 0.16279069767441862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8554761511511649,
            "auditor_fn_violation": 0.008749133749133753,
            "auditor_fp_violation": 0.010669800952497253,
            "ave_precision_score": 0.8507372257146281,
            "fpr": 0.08442982456140351,
            "logloss": 0.4825199512776014,
            "mae": 0.3040237029393514,
            "precision": 0.8257918552036199,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8611238525440297,
            "auditor_fn_violation": 0.011069776724692105,
            "auditor_fp_violation": 0.013954257702660035,
            "ave_precision_score": 0.8546903462834733,
            "fpr": 0.08562019758507135,
            "logloss": 0.48458422605837953,
            "mae": 0.3056520527979087,
            "precision": 0.8142857142857143,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.8147112904940833,
            "auditor_fn_violation": 0.004684593500382982,
            "auditor_fp_violation": 0.0031978874099401647,
            "ave_precision_score": 0.8150951270172155,
            "fpr": 0.023026315789473683,
            "logloss": 1.0813920663912102,
            "mae": 0.38513925669914373,
            "precision": 0.8900523560209425,
            "recall": 0.35343035343035345
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8131088155587218,
            "auditor_fn_violation": 0.002046864375509107,
            "auditor_fp_violation": 0.0027367186442716885,
            "ave_precision_score": 0.8134503741420429,
            "fpr": 0.019758507135016465,
            "logloss": 1.0742910218806532,
            "mae": 0.38390342897521706,
            "precision": 0.8994413407821229,
            "recall": 0.3403805496828753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5711700297145617,
            "auditor_fn_violation": 0.007953550716708613,
            "auditor_fp_violation": 0.014017788089713854,
            "ave_precision_score": 0.5727568312808357,
            "fpr": 0.33771929824561403,
            "logloss": 0.748457133937093,
            "mae": 0.48372115145780537,
            "precision": 0.5290519877675841,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.5544722572318042,
            "auditor_fn_violation": 0.0038593372522354166,
            "auditor_fp_violation": 0.010721320842668762,
            "ave_precision_score": 0.5556603204939903,
            "fpr": 0.3578485181119649,
            "logloss": 0.7487171152434587,
            "mae": 0.4914755708038087,
            "precision": 0.4914196567862715,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7634136228996822,
            "auditor_fn_violation": 0.04553516066673962,
            "auditor_fp_violation": 0.01389058493100501,
            "ave_precision_score": 0.7641016206090192,
            "fpr": 0.09758771929824561,
            "logloss": 0.887366533868056,
            "mae": 0.3818749592254066,
            "precision": 0.7741116751269036,
            "recall": 0.6340956340956341
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7844280851055662,
            "auditor_fn_violation": 0.04306537666249713,
            "auditor_fp_violation": 0.013473076402568309,
            "ave_precision_score": 0.78512177873502,
            "fpr": 0.08232711306256861,
            "logloss": 0.9176816513275108,
            "mae": 0.3690337048981934,
            "precision": 0.7983870967741935,
            "recall": 0.627906976744186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7524219954529899,
            "auditor_fn_violation": 0.011113086770981507,
            "auditor_fp_violation": 0.02129126470468514,
            "ave_precision_score": 0.7407927217827435,
            "fpr": 0.16776315789473684,
            "logloss": 1.7561025985897332,
            "mae": 0.3338240905927306,
            "precision": 0.6838842975206612,
            "recall": 0.6881496881496881
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7555773034125212,
            "auditor_fn_violation": 0.016323859430080558,
            "auditor_fp_violation": 0.023525254499797005,
            "ave_precision_score": 0.7456852734160065,
            "fpr": 0.16794731064763996,
            "logloss": 1.6685529478477847,
            "mae": 0.3150384195891907,
            "precision": 0.6958250497017893,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7773953625198787,
            "auditor_fn_violation": 0.0028745851114272223,
            "auditor_fp_violation": 0.00971832132535515,
            "ave_precision_score": 0.7767324213757464,
            "fpr": 0.09868421052631579,
            "logloss": 0.5404348413740018,
            "mae": 0.3649851972923467,
            "precision": 0.7986577181208053,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.7915910266860955,
            "auditor_fn_violation": 0.009043798720361661,
            "auditor_fp_violation": 0.00989930278834539,
            "ave_precision_score": 0.7782137515537176,
            "fpr": 0.08781558726673985,
            "logloss": 0.5447095584901587,
            "mae": 0.3685676306649699,
            "precision": 0.8067632850241546,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7523436227151674,
            "auditor_fn_violation": 0.012134350950140422,
            "auditor_fp_violation": 0.017757560955753655,
            "ave_precision_score": 0.7529268018264617,
            "fpr": 0.13706140350877194,
            "logloss": 1.1496881910892156,
            "mae": 0.3350335804369459,
            "precision": 0.7113163972286374,
            "recall": 0.6403326403326404
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7586802529194367,
            "auditor_fn_violation": 0.019069256886120545,
            "auditor_fp_violation": 0.021931341443243168,
            "ave_precision_score": 0.7592448388507596,
            "fpr": 0.141602634467618,
            "logloss": 1.0441644381036954,
            "mae": 0.31506325797789453,
            "precision": 0.7120535714285714,
            "recall": 0.6744186046511628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 1318,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5736804556092756,
            "auditor_fn_violation": 0.005851752562278871,
            "auditor_fp_violation": 0.018355415801685183,
            "ave_precision_score": 0.5751905203407021,
            "fpr": 0.21052631578947367,
            "logloss": 0.688242963181895,
            "mae": 0.49520542407244966,
            "precision": 0.5282555282555282,
            "recall": 0.446985446985447
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5504626675939743,
            "auditor_fn_violation": 0.005913163751470765,
            "auditor_fp_violation": 0.008520918855790972,
            "ave_precision_score": 0.5519757832187904,
            "fpr": 0.21953896816684962,
            "logloss": 0.6911821551125228,
            "mae": 0.4970501605687105,
            "precision": 0.5012468827930174,
            "recall": 0.4249471458773784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6859226393136577,
            "auditor_fn_violation": 0.004684593500382996,
            "auditor_fp_violation": 0.005177168559449671,
            "ave_precision_score": 0.6845941572624843,
            "fpr": 0.05263157894736842,
            "logloss": 7.887766724722279,
            "mae": 0.41112458702589944,
            "precision": 0.7635467980295566,
            "recall": 0.32224532224532226
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6993998995101127,
            "auditor_fn_violation": 0.015207598925976402,
            "auditor_fp_violation": 0.004892009884265873,
            "ave_precision_score": 0.6978265571037663,
            "fpr": 0.03732162458836443,
            "logloss": 7.740995049671311,
            "mae": 0.40387669847284935,
            "precision": 0.8023255813953488,
            "recall": 0.2917547568710359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7002991075619454,
            "auditor_fn_violation": 0.02986057920268448,
            "auditor_fp_violation": 0.0054468392559124034,
            "ave_precision_score": 0.7008446714411231,
            "fpr": 0.03179824561403509,
            "logloss": 0.6805830124738013,
            "mae": 0.48400680279653324,
            "precision": 0.8027210884353742,
            "recall": 0.24532224532224534
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6278949625478181,
            "auditor_fn_violation": 0.03060549590046948,
            "auditor_fp_violation": 0.01959310106310994,
            "ave_precision_score": 0.629653864425613,
            "fpr": 0.050493962678375415,
            "logloss": 0.7376641660052875,
            "mae": 0.4889311456457844,
            "precision": 0.7088607594936709,
            "recall": 0.23678646934460887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7494555298749197,
            "auditor_fn_violation": 0.01206140350877194,
            "auditor_fp_violation": 0.019650343957341155,
            "ave_precision_score": 0.7498287108558821,
            "fpr": 0.14802631578947367,
            "logloss": 0.6765858061072851,
            "mae": 0.38212609890845334,
            "precision": 0.6867749419953596,
            "recall": 0.6153846153846154
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7315310910408643,
            "auditor_fn_violation": 0.0021118441969538424,
            "auditor_fp_violation": 0.018069360279486142,
            "ave_precision_score": 0.7321150160573409,
            "fpr": 0.15697036223929747,
            "logloss": 0.6773106733755433,
            "mae": 0.3783907851929604,
            "precision": 0.6757369614512472,
            "recall": 0.6300211416490487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5207108610030124,
            "auditor_fn_violation": 0.0019673013094065727,
            "auditor_fp_violation": 0.007708511417755533,
            "ave_precision_score": 0.5218916180261954,
            "fpr": 0.4440789473684211,
            "logloss": 2.736309584636209,
            "mae": 0.445425454294949,
            "precision": 0.5408163265306123,
            "recall": 0.9916839916839917
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.49371646281026527,
            "auditor_fn_violation": 0.0009236417476787121,
            "auditor_fp_violation": 0.012435529224245543,
            "ave_precision_score": 0.4922073411920177,
            "fpr": 0.4478594950603732,
            "logloss": 3.216574438283684,
            "mae": 0.4550554764899308,
            "precision": 0.5315729047072331,
            "recall": 0.9788583509513742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6680371682458185,
            "auditor_fn_violation": 0.003950559871612511,
            "auditor_fp_violation": 0.009761570399316173,
            "ave_precision_score": 0.5681860961168449,
            "fpr": 0.2719298245614035,
            "logloss": 7.684184802219819,
            "mae": 0.4181776829541218,
            "precision": 0.5927750410509032,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6768619059172118,
            "auditor_fn_violation": 0.0043745344079758105,
            "auditor_fp_violation": 0.0018445283170182782,
            "ave_precision_score": 0.5757917418802357,
            "fpr": 0.27552140504939626,
            "logloss": 7.420145050274173,
            "mae": 0.39088566378847145,
            "precision": 0.5977564102564102,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.7593670354462794,
            "auditor_fn_violation": 0.0006154940365466923,
            "auditor_fp_violation": 0.003017258924573615,
            "ave_precision_score": 0.7607364379132953,
            "fpr": 0.007675438596491228,
            "logloss": 1.700287174030318,
            "mae": 0.5084254596058918,
            "precision": 0.125,
            "recall": 0.002079002079002079
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.7536092282075976,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027066448130159543,
            "ave_precision_score": 0.7549832517098245,
            "fpr": 0.005488474204171241,
            "logloss": 1.6996320507882174,
            "mae": 0.5015812068508015,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7771208104194934,
            "auditor_fn_violation": 0.01825281759492286,
            "auditor_fp_violation": 0.005983636585663697,
            "ave_precision_score": 0.754804996528847,
            "fpr": 0.0756578947368421,
            "logloss": 0.5762218358562028,
            "mae": 0.37301066807030064,
            "precision": 0.8257575757575758,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.806472606457432,
            "auditor_fn_violation": 0.012311355455868265,
            "auditor_fp_violation": 0.007801653058258027,
            "ave_precision_score": 0.769824168232286,
            "fpr": 0.06695938529088913,
            "logloss": 0.572992216462415,
            "mae": 0.371351246072877,
            "precision": 0.8333333333333334,
            "recall": 0.6448202959830867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8447592669937937,
            "auditor_fn_violation": 0.005083524820366927,
            "auditor_fp_violation": 0.0078026417552000725,
            "ave_precision_score": 0.8346214824199973,
            "fpr": 0.13596491228070176,
            "logloss": 0.5030643673336703,
            "mae": 0.3248072765336633,
            "precision": 0.7633587786259542,
            "recall": 0.8316008316008316
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8162076511496608,
            "auditor_fn_violation": 0.013364956846436443,
            "auditor_fp_violation": 0.01261597221177993,
            "ave_precision_score": 0.8052819357699332,
            "fpr": 0.13172338090010977,
            "logloss": 0.5194508818205879,
            "mae": 0.3306613147067587,
            "precision": 0.7609561752988048,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.809255701295512,
            "auditor_fn_violation": 0.01815023525549842,
            "auditor_fp_violation": 0.015368685635201699,
            "ave_precision_score": 0.8095462194632896,
            "fpr": 0.125,
            "logloss": 0.9507379607876674,
            "mae": 0.2875884209751753,
            "precision": 0.7553648068669528,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8166120007025592,
            "auditor_fn_violation": 0.013360315430618963,
            "auditor_fp_violation": 0.02019457768822459,
            "ave_precision_score": 0.8171554972508346,
            "fpr": 0.13172338090010977,
            "logloss": 0.8634368195937538,
            "mae": 0.2676549550197305,
            "precision": 0.7463002114164905,
            "recall": 0.7463002114164905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7911015186364232,
            "auditor_fn_violation": 0.006341868183973451,
            "auditor_fp_violation": 0.00520006512801726,
            "ave_precision_score": 0.7917994598419034,
            "fpr": 0.08114035087719298,
            "logloss": 0.5813807413959851,
            "mae": 0.3817167511687761,
            "precision": 0.7891737891737892,
            "recall": 0.5758835758835759
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.795753738169771,
            "auditor_fn_violation": 0.008414886877092994,
            "auditor_fp_violation": 0.007009708835190396,
            "ave_precision_score": 0.7964306078202064,
            "fpr": 0.06476399560922064,
            "logloss": 0.5796388210187412,
            "mae": 0.38056994663627103,
            "precision": 0.8150470219435737,
            "recall": 0.5496828752642706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7957165293361491,
            "auditor_fn_violation": 0.007887442097968437,
            "auditor_fp_violation": 0.01632525338869215,
            "ave_precision_score": 0.7395345145443865,
            "fpr": 0.07785087719298246,
            "logloss": 0.6126973471427541,
            "mae": 0.38200308998491156,
            "precision": 0.7717041800643086,
            "recall": 0.498960498960499
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7887591393647198,
            "auditor_fn_violation": 0.01077504682028207,
            "auditor_fp_violation": 0.008034725250489955,
            "ave_precision_score": 0.7310914317416135,
            "fpr": 0.07135016465422613,
            "logloss": 0.6160178289506946,
            "mae": 0.381616894601467,
            "precision": 0.7727272727272727,
            "recall": 0.46723044397463004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7636695760839689,
            "auditor_fn_violation": 0.049839059707480766,
            "auditor_fp_violation": 0.05011041234175928,
            "ave_precision_score": 0.7443099680227516,
            "fpr": 0.1600877192982456,
            "logloss": 0.5936027396577027,
            "mae": 0.40614808488049003,
            "precision": 0.6762749445676275,
            "recall": 0.6340956340956341
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7751110888219436,
            "auditor_fn_violation": 0.03357368131574856,
            "auditor_fp_violation": 0.043998015127137136,
            "ave_precision_score": 0.7542214269733442,
            "fpr": 0.14709110867178923,
            "logloss": 0.5860014568676163,
            "mae": 0.4041260257772243,
            "precision": 0.6832151300236406,
            "recall": 0.6109936575052854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8441223222475112,
            "auditor_fn_violation": 0.002094959331801446,
            "auditor_fp_violation": 0.006706150527129893,
            "ave_precision_score": 0.8222454141846371,
            "fpr": 0.09868421052631579,
            "logloss": 0.511414365375583,
            "mae": 0.3399420052995546,
            "precision": 0.799554565701559,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8163200244617691,
            "auditor_fn_violation": 0.0032350668247842452,
            "auditor_fp_violation": 0.01382895007242782,
            "ave_precision_score": 0.7929522241334064,
            "fpr": 0.09659714599341383,
            "logloss": 0.5267712928546813,
            "mae": 0.34640235648900436,
            "precision": 0.7953488372093023,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6704884287121129,
            "auditor_fn_violation": 0.12829631250683884,
            "auditor_fp_violation": 0.11661985590426181,
            "ave_precision_score": 0.5338442810608802,
            "fpr": 0.2631578947368421,
            "logloss": 0.691900354796398,
            "mae": 0.49892747356441985,
            "precision": 0.5384615384615384,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6584884564669862,
            "auditor_fn_violation": 0.12882713743000165,
            "auditor_fp_violation": 0.12017502969790837,
            "ave_precision_score": 0.5286229161030128,
            "fpr": 0.24368825466520308,
            "logloss": 0.6919276978312687,
            "mae": 0.4989689937276453,
            "precision": 0.5365344467640919,
            "recall": 0.5433403805496829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8081087885350309,
            "auditor_fn_violation": 0.022529361345150822,
            "auditor_fp_violation": 0.014585114177555262,
            "ave_precision_score": 0.8141252658765938,
            "fpr": 0.09210526315789473,
            "logloss": 0.5518673693298259,
            "mae": 0.3516623266020855,
            "precision": 0.7966101694915254,
            "recall": 0.683991683991684
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8349785288995383,
            "auditor_fn_violation": 0.016207824034643534,
            "auditor_fp_violation": 0.01932494273441299,
            "ave_precision_score": 0.8335656074819576,
            "fpr": 0.09110867178924259,
            "logloss": 0.5254444537947359,
            "mae": 0.3431486805796656,
            "precision": 0.7995169082125604,
            "recall": 0.6997885835095138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8197730772669113,
            "auditor_fn_violation": 0.015469416785206259,
            "auditor_fp_violation": 0.011995257866243333,
            "ave_precision_score": 0.8196751431255804,
            "fpr": 0.10964912280701754,
            "logloss": 0.8326154634088964,
            "mae": 0.33557893444303855,
            "precision": 0.7849462365591398,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8241748777769478,
            "auditor_fn_violation": 0.021879634163605274,
            "auditor_fp_violation": 0.01746036519655755,
            "ave_precision_score": 0.8245101205808739,
            "fpr": 0.11306256860592755,
            "logloss": 0.7729391230302509,
            "mae": 0.339633295441421,
            "precision": 0.7711111111111111,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5810917177048194,
            "auditor_fn_violation": 0.008979374110953064,
            "auditor_fp_violation": 0.012091932266862062,
            "ave_precision_score": 0.5823179864377181,
            "fpr": 0.30153508771929827,
            "logloss": 0.6906231232471074,
            "mae": 0.49836384609603046,
            "precision": 0.5416666666666666,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.554086853913147,
            "auditor_fn_violation": 0.00182639712417876,
            "auditor_fp_violation": 0.006916981188818554,
            "ave_precision_score": 0.555777493845006,
            "fpr": 0.30954994511525796,
            "logloss": 0.6967444581215795,
            "mae": 0.5011579939680487,
            "precision": 0.524451939291737,
            "recall": 0.6575052854122622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6588767481369854,
            "auditor_fn_violation": 0.09026561987088304,
            "auditor_fp_violation": 0.0437197256482273,
            "ave_precision_score": 0.6446579102530013,
            "fpr": 0.10855263157894737,
            "logloss": 2.9032391406292977,
            "mae": 0.4648243423898029,
            "precision": 0.6655405405405406,
            "recall": 0.4095634095634096
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.646288898372378,
            "auditor_fn_violation": 0.09373803384984557,
            "auditor_fp_violation": 0.0432912800926274,
            "ave_precision_score": 0.6359755578979946,
            "fpr": 0.09001097694840834,
            "logloss": 2.773183698364711,
            "mae": 0.47102999309159727,
            "precision": 0.6951672862453532,
            "recall": 0.3953488372093023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5410067319102638,
            "auditor_fn_violation": 0.009439854834591678,
            "auditor_fp_violation": 0.010738490658200026,
            "ave_precision_score": 0.5299725111703169,
            "fpr": 0.14692982456140352,
            "logloss": 10.585493109931548,
            "mae": 0.5082966353881367,
            "precision": 0.5592105263157895,
            "recall": 0.35343035343035345
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5634269097730615,
            "auditor_fn_violation": 0.0058412218062998044,
            "auditor_fp_violation": 0.02038504528617757,
            "ave_precision_score": 0.5481444180794003,
            "fpr": 0.1394072447859495,
            "logloss": 10.503870121863638,
            "mae": 0.5028424350869339,
            "precision": 0.5528169014084507,
            "recall": 0.33192389006342493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7373487601440114,
            "auditor_fn_violation": 0.014728544333807506,
            "auditor_fp_violation": 0.025837505596938988,
            "ave_precision_score": 0.7377823266932444,
            "fpr": 0.15570175438596492,
            "logloss": 1.443286224442565,
            "mae": 0.3545491915663884,
            "precision": 0.69593147751606,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7576103721277689,
            "auditor_fn_violation": 0.01761881444315775,
            "auditor_fp_violation": 0.02404904039416769,
            "ave_precision_score": 0.7583878834589826,
            "fpr": 0.15697036223929747,
            "logloss": 1.3655486525983307,
            "mae": 0.3364111799767198,
            "precision": 0.7075664621676891,
            "recall": 0.7315010570824524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8428407367139596,
            "auditor_fn_violation": 0.0004376846482109652,
            "auditor_fp_violation": 0.013531872023446087,
            "ave_precision_score": 0.7623906848776605,
            "fpr": 0.18859649122807018,
            "logloss": 0.5383422803103024,
            "mae": 0.34838214500895104,
            "precision": 0.7084745762711865,
            "recall": 0.8690228690228691
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8393277154739098,
            "auditor_fn_violation": 0.00831973785283463,
            "auditor_fp_violation": 0.003293084522502744,
            "ave_precision_score": 0.7580473021016579,
            "fpr": 0.1778265642151482,
            "logloss": 0.5220272344405654,
            "mae": 0.3473764104826704,
            "precision": 0.7162872154115587,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7739050784050685,
            "auditor_fn_violation": 0.013755151913046658,
            "auditor_fp_violation": 0.013974539015752845,
            "ave_precision_score": 0.7393867185606078,
            "fpr": 0.125,
            "logloss": 4.086136928157559,
            "mae": 0.308353031686863,
            "precision": 0.7472283813747228,
            "recall": 0.7006237006237006
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.781872725047431,
            "auditor_fn_violation": 0.01614748562901628,
            "auditor_fp_violation": 0.02000411009027162,
            "ave_precision_score": 0.745815785857371,
            "fpr": 0.13721185510428102,
            "logloss": 3.8844302096209256,
            "mae": 0.2907616503915661,
            "precision": 0.7329059829059829,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6990498975969748,
            "auditor_fn_violation": 0.00537987380092644,
            "auditor_fp_violation": 0.0026076647535311624,
            "ave_precision_score": 0.6994980744313157,
            "fpr": 0.04276315789473684,
            "logloss": 2.6938670044318993,
            "mae": 0.4711810416086999,
            "precision": 0.7678571428571429,
            "recall": 0.2681912681912682
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6778393579693588,
            "auditor_fn_violation": 0.006484057897020915,
            "auditor_fp_violation": 0.0035913166824554288,
            "ave_precision_score": 0.6785039569137951,
            "fpr": 0.027442371020856202,
            "logloss": 2.757864587392804,
            "mae": 0.47160169400763574,
            "precision": 0.8175182481751825,
            "recall": 0.23678646934460887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7626482149904157,
            "auditor_fn_violation": 0.011113086770981507,
            "auditor_fp_violation": 0.02129126470468514,
            "ave_precision_score": 0.6957838448075861,
            "fpr": 0.16776315789473684,
            "logloss": 0.6398965406247392,
            "mae": 0.37328641732599127,
            "precision": 0.6838842975206612,
            "recall": 0.6881496881496881
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7589023560931345,
            "auditor_fn_violation": 0.016323859430080558,
            "auditor_fp_violation": 0.023525254499797005,
            "ave_precision_score": 0.6917370583709479,
            "fpr": 0.16794731064763996,
            "logloss": 0.6315669680953412,
            "mae": 0.36225734868635856,
            "precision": 0.6958250497017893,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7545387813608478,
            "auditor_fn_violation": 0.0007203559835138787,
            "auditor_fp_violation": 0.01651097000040706,
            "ave_precision_score": 0.7563456753550448,
            "fpr": 0.4199561403508772,
            "logloss": 0.6859181389400699,
            "mae": 0.4961718652201326,
            "precision": 0.552570093457944,
            "recall": 0.9833679833679834
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7519474828635397,
            "auditor_fn_violation": 0.004697112807290736,
            "auditor_fp_violation": 0.011232575974016213,
            "ave_precision_score": 0.7529865899678537,
            "fpr": 0.41931942919868276,
            "logloss": 0.6861856890222331,
            "mae": 0.4963127499615976,
            "precision": 0.5489964580873672,
            "recall": 0.9830866807610994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7990430864757032,
            "auditor_fn_violation": 0.005664824743772117,
            "auditor_fp_violation": 0.005871697805999922,
            "ave_precision_score": 0.7994907405493104,
            "fpr": 0.14035087719298245,
            "logloss": 0.5617721614880253,
            "mae": 0.37111975464830993,
            "precision": 0.7333333333333333,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.792237023348429,
            "auditor_fn_violation": 0.007071196997932246,
            "auditor_fp_violation": 0.009287801552812152,
            "ave_precision_score": 0.793600147619598,
            "fpr": 0.14709110867178923,
            "logloss": 0.5691431949474663,
            "mae": 0.3789593983854604,
            "precision": 0.7178947368421053,
            "recall": 0.7209302325581395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7836117749360252,
            "auditor_fn_violation": 0.0038821716453295444,
            "auditor_fp_violation": 0.006100663491675826,
            "ave_precision_score": 0.7841246916279482,
            "fpr": 0.06578947368421052,
            "logloss": 0.6127215799355415,
            "mae": 0.3932381387648843,
            "precision": 0.7959183673469388,
            "recall": 0.4864864864864865
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7863915967643185,
            "auditor_fn_violation": 0.004601963783032388,
            "auditor_fp_violation": 0.005247883554125381,
            "ave_precision_score": 0.7868098312049965,
            "fpr": 0.052689352360043906,
            "logloss": 0.6294392331449651,
            "mae": 0.3992284480870817,
            "precision": 0.808,
            "recall": 0.427061310782241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6364134981417259,
            "auditor_fn_violation": 0.007725589962432076,
            "auditor_fp_violation": 0.006510257662718291,
            "ave_precision_score": 0.6384701780724633,
            "fpr": 0.16557017543859648,
            "logloss": 0.8212408628193567,
            "mae": 0.43108028719169006,
            "precision": 0.6745689655172413,
            "recall": 0.6507276507276507
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6754384002748033,
            "auditor_fn_violation": 0.009693596934808996,
            "auditor_fp_violation": 0.012550812244059168,
            "ave_precision_score": 0.6774197595643476,
            "fpr": 0.150384193194292,
            "logloss": 0.7417388328776994,
            "mae": 0.41777175913527037,
            "precision": 0.6893424036281179,
            "recall": 0.642706131078224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7815614084877953,
            "auditor_fn_violation": 0.0014315935368566953,
            "auditor_fp_violation": 0.023400293076077675,
            "ave_precision_score": 0.7824833835898575,
            "fpr": 0.3980263157894737,
            "logloss": 1.092507200537872,
            "mae": 0.4099016106246333,
            "precision": 0.5642256902761105,
            "recall": 0.9771309771309772
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7744610863867103,
            "auditor_fn_violation": 0.008317417144925888,
            "auditor_fp_violation": 0.01359337172759125,
            "ave_precision_score": 0.7757147172017871,
            "fpr": 0.3951701427003293,
            "logloss": 1.0786605631080544,
            "mae": 0.4124444886862119,
            "precision": 0.5604395604395604,
            "recall": 0.9704016913319239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7838629888326392,
            "auditor_fn_violation": 0.018879709669183363,
            "auditor_fp_violation": 0.006347437619570971,
            "ave_precision_score": 0.7791868530657058,
            "fpr": 0.09758771929824561,
            "logloss": 0.6134639168614288,
            "mae": 0.3485228136689385,
            "precision": 0.7802469135802469,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.769567140447123,
            "auditor_fn_violation": 0.005994388528276673,
            "auditor_fp_violation": 0.012726242926384277,
            "ave_precision_score": 0.7719116546021948,
            "fpr": 0.09659714599341383,
            "logloss": 0.5962978103813964,
            "mae": 0.34369048315831585,
            "precision": 0.7755102040816326,
            "recall": 0.642706131078224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7656693249572506,
            "auditor_fn_violation": 0.008600959258853997,
            "auditor_fp_violation": 0.012778829323889785,
            "ave_precision_score": 0.5464053002752695,
            "fpr": 0.42214912280701755,
            "logloss": 0.6827436062384374,
            "mae": 0.48768047086502375,
            "precision": 0.5470588235294118,
            "recall": 0.9667359667359667
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7526969678015417,
            "auditor_fn_violation": 0.00880244509785265,
            "auditor_fp_violation": 0.014886546471587762,
            "ave_precision_score": 0.5301927893449547,
            "fpr": 0.43468715697036225,
            "logloss": 0.6929013317399062,
            "mae": 0.4924707799397499,
            "precision": 0.5308056872037915,
            "recall": 0.9471458773784355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7962329239005768,
            "auditor_fn_violation": 0.006401137980085348,
            "auditor_fp_violation": 0.010224589897016323,
            "ave_precision_score": 0.7434157325276656,
            "fpr": 0.13267543859649122,
            "logloss": 0.5675224092305302,
            "mae": 0.37619215060687183,
            "precision": 0.7505154639175258,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7913897422563037,
            "auditor_fn_violation": 0.005711262163410334,
            "auditor_fp_violation": 0.005759138685472836,
            "ave_precision_score": 0.7400353853504094,
            "fpr": 0.12184412733260154,
            "logloss": 0.5502758645187598,
            "mae": 0.37068033961806157,
            "precision": 0.75764192139738,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6704884287121129,
            "auditor_fn_violation": 0.12829631250683884,
            "auditor_fp_violation": 0.11661985590426181,
            "ave_precision_score": 0.5338442810608802,
            "fpr": 0.2631578947368421,
            "logloss": 0.691900354796398,
            "mae": 0.49892747356441985,
            "precision": 0.5384615384615384,
            "recall": 0.5821205821205822
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6584884564669862,
            "auditor_fn_violation": 0.12882713743000165,
            "auditor_fp_violation": 0.12017502969790837,
            "ave_precision_score": 0.5286229161030128,
            "fpr": 0.24368825466520308,
            "logloss": 0.6919276978312687,
            "mae": 0.4989689937276453,
            "precision": 0.5365344467640919,
            "recall": 0.5433403805496829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5194480890820418,
            "auditor_fn_violation": 0.00359266148739836,
            "auditor_fp_violation": 0.009776834778361219,
            "ave_precision_score": 0.5256822231829916,
            "fpr": 0.03837719298245614,
            "logloss": 0.7556697126531231,
            "mae": 0.5083466227117338,
            "precision": 0.4696969696969697,
            "recall": 0.06444906444906445
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5704894083592258,
            "auditor_fn_violation": 0.0028475086040245646,
            "auditor_fp_violation": 0.008548486534442058,
            "ave_precision_score": 0.5215158089640066,
            "fpr": 0.029637760702524697,
            "logloss": 0.7492936680469341,
            "mae": 0.5043714797261256,
            "precision": 0.5846153846153846,
            "recall": 0.080338266384778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 1318,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7510240683825797,
            "auditor_fn_violation": 0.02420943210416895,
            "auditor_fp_violation": 0.01701723857206822,
            "ave_precision_score": 0.6168890800579856,
            "fpr": 0.17653508771929824,
            "logloss": 0.6535294362244142,
            "mae": 0.46877891243549813,
            "precision": 0.6631799163179917,
            "recall": 0.659043659043659
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7174854944947266,
            "auditor_fn_violation": 0.026936456696750783,
            "auditor_fp_violation": 0.017525525164278306,
            "ave_precision_score": 0.5816089235363567,
            "fpr": 0.1942919868276619,
            "logloss": 0.6706273698020598,
            "mae": 0.4772261015408387,
            "precision": 0.6209850107066381,
            "recall": 0.6131078224101479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6386645974065922,
            "auditor_fn_violation": 0.004559215085530886,
            "auditor_fp_violation": 0.002162453698050231,
            "ave_precision_score": 0.6382269189830454,
            "fpr": 0.09868421052631579,
            "logloss": 5.432876548587399,
            "mae": 0.4467564557706152,
            "precision": 0.6590909090909091,
            "recall": 0.36174636174636177
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6348937891185722,
            "auditor_fn_violation": 0.007045669210936119,
            "auditor_fp_violation": 0.006410738362680384,
            "ave_precision_score": 0.6347870450729949,
            "fpr": 0.10757409440175632,
            "logloss": 5.103121056374323,
            "mae": 0.43888396578034267,
            "precision": 0.6524822695035462,
            "recall": 0.3890063424947146
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.45512706532443375,
            "auditor_fn_violation": 0.0006154940365466923,
            "auditor_fp_violation": 0.003017258924573615,
            "ave_precision_score": 0.5210129664077032,
            "fpr": 0.007675438596491228,
            "logloss": 0.8937675429323632,
            "mae": 0.5173101888217947,
            "precision": 0.125,
            "recall": 0.002079002079002079
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5179037813694689,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027066448130159543,
            "ave_precision_score": 0.5214093707144427,
            "fpr": 0.005488474204171241,
            "logloss": 0.8800743564661798,
            "mae": 0.5113584924280709,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6980990121758198,
            "auditor_fn_violation": 0.0760157931210563,
            "auditor_fp_violation": 0.09130133919485489,
            "ave_precision_score": 0.6388730581574612,
            "fpr": 0.17214912280701755,
            "logloss": 0.7220784444333251,
            "mae": 0.4401579927653074,
            "precision": 0.6025316455696202,
            "recall": 0.49480249480249483
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6897623059641791,
            "auditor_fn_violation": 0.0797070338336006,
            "auditor_fp_violation": 0.09173771609300833,
            "ave_precision_score": 0.6324097716694526,
            "fpr": 0.17892425905598244,
            "logloss": 0.7116699172353281,
            "mae": 0.43596911217718826,
            "precision": 0.5820512820512821,
            "recall": 0.4799154334038055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6689029537639802,
            "auditor_fn_violation": 0.04168718313455156,
            "auditor_fp_violation": 0.048446595025847694,
            "ave_precision_score": 0.6708822990119712,
            "fpr": 0.21820175438596492,
            "logloss": 0.8106838801772315,
            "mae": 0.43760047009901,
            "precision": 0.6401446654611211,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6912745839035431,
            "auditor_fn_violation": 0.04189573987649192,
            "auditor_fp_violation": 0.04419850733550869,
            "ave_precision_score": 0.6923640568016318,
            "fpr": 0.20636663007683864,
            "logloss": 0.7139751476311726,
            "mae": 0.4267636304956367,
            "precision": 0.6624775583482945,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8376805672550949,
            "auditor_fn_violation": 0.02525121275121276,
            "auditor_fp_violation": 0.011140452639719951,
            "ave_precision_score": 0.8108237733001697,
            "fpr": 0.09539473684210527,
            "logloss": 0.7529693343111941,
            "mae": 0.34112682571300185,
            "precision": 0.7918660287081339,
            "recall": 0.6881496881496881
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.85931208512476,
            "auditor_fn_violation": 0.013699138785295065,
            "auditor_fp_violation": 0.011187465227132612,
            "ave_precision_score": 0.8343640905414835,
            "fpr": 0.08232711306256861,
            "logloss": 0.5783708239173584,
            "mae": 0.3238864518996884,
            "precision": 0.8184019370460048,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8130430658122869,
            "auditor_fn_violation": 0.01727714556661925,
            "auditor_fp_violation": 0.012733036186754589,
            "ave_precision_score": 0.8133480468078391,
            "fpr": 0.1074561403508772,
            "logloss": 0.6342080165549178,
            "mae": 0.32105654651406856,
            "precision": 0.7683215130023641,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8162097110488192,
            "auditor_fn_violation": 0.015298106534417263,
            "auditor_fp_violation": 0.019926419359527645,
            "ave_precision_score": 0.8166464938290307,
            "fpr": 0.11306256860592755,
            "logloss": 0.5866571877101004,
            "mae": 0.309221940842035,
            "precision": 0.7643020594965675,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7977354015175513,
            "auditor_fn_violation": 0.010707316628369271,
            "auditor_fp_violation": 0.007166625961655884,
            "ave_precision_score": 0.7973875450131338,
            "fpr": 0.0800438596491228,
            "logloss": 0.5789263884920858,
            "mae": 0.35546931384433583,
            "precision": 0.8137755102040817,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8141593219572416,
            "auditor_fn_violation": 0.006029199146907772,
            "auditor_fp_violation": 0.008275315900535814,
            "ave_precision_score": 0.811072466884661,
            "fpr": 0.07135016465422613,
            "logloss": 0.5746099780127528,
            "mae": 0.34972428686867757,
            "precision": 0.8284960422163589,
            "recall": 0.6638477801268499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.8362889070480464,
            "auditor_fn_violation": 0.007340336287704709,
            "auditor_fp_violation": 0.019434098587536135,
            "ave_precision_score": 0.8365333021752979,
            "fpr": 0.43969298245614036,
            "logloss": 1.7665574664847574,
            "mae": 0.4394265394792351,
            "precision": 0.5401376146788991,
            "recall": 0.9792099792099792
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.8381643456559558,
            "auditor_fn_violation": 0.007811502820820464,
            "auditor_fp_violation": 0.02769298628132065,
            "ave_precision_score": 0.8385821241810357,
            "fpr": 0.43249176728869376,
            "logloss": 1.6851672109678177,
            "mae": 0.4332082914749064,
            "precision": 0.5397196261682243,
            "recall": 0.9767441860465116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.5406749604176926,
            "auditor_fn_violation": 0.014749060801692391,
            "auditor_fp_violation": 0.006998717792160214,
            "ave_precision_score": 0.722015570904448,
            "fpr": 0.08333333333333333,
            "logloss": 1.1430011040641046,
            "mae": 0.36879027994034497,
            "precision": 0.8031088082901554,
            "recall": 0.6444906444906445
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7880569541513085,
            "auditor_fn_violation": 0.014956962471832416,
            "auditor_fp_violation": 0.002927186242224662,
            "ave_precision_score": 0.7239404866041577,
            "fpr": 0.0801317233809001,
            "logloss": 1.0775168676579814,
            "mae": 0.3693256683310918,
            "precision": 0.8,
            "recall": 0.6173361522198731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 1318,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.820457660784206,
            "auditor_fn_violation": 0.0033099901520954296,
            "auditor_fp_violation": 0.003917857288232182,
            "ave_precision_score": 0.8199417139682614,
            "fpr": 0.051535087719298246,
            "logloss": 0.5699070601545858,
            "mae": 0.3495953973615542,
            "precision": 0.8621700879765396,
            "recall": 0.6112266112266113
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8008361492791387,
            "auditor_fn_violation": 0.005286572616110821,
            "auditor_fp_violation": 0.004064979524733222,
            "ave_precision_score": 0.8005628624081084,
            "fpr": 0.048298572996706916,
            "logloss": 0.591357386688647,
            "mae": 0.3608820853994098,
            "precision": 0.8562091503267973,
            "recall": 0.5539112050739958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7102763989692239,
            "auditor_fn_violation": 0.0006496881496881497,
            "auditor_fp_violation": 0.0033708837057841875,
            "ave_precision_score": 0.6853770151833275,
            "fpr": 0.46710526315789475,
            "logloss": 5.716575045204912,
            "mae": 0.4636600119210606,
            "precision": 0.5298013245033113,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7194979162181608,
            "auditor_fn_violation": 0.001318162092164594,
            "auditor_fp_violation": 0.0070924118711436735,
            "ave_precision_score": 0.6990344390756338,
            "fpr": 0.4698133918770582,
            "logloss": 5.561884758884938,
            "mae": 0.4672833962964546,
            "precision": 0.5239154616240267,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.715285444963053,
            "auditor_fn_violation": 0.010550023707918452,
            "auditor_fp_violation": 0.01899397565840355,
            "ave_precision_score": 0.6951262263071853,
            "fpr": 0.16228070175438597,
            "logloss": 0.6318214348484816,
            "mae": 0.4160348666472393,
            "precision": 0.7022132796780685,
            "recall": 0.7255717255717256
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.695599744938312,
            "auditor_fn_violation": 0.020125178984597467,
            "auditor_fp_violation": 0.018074372584695426,
            "ave_precision_score": 0.675062076740081,
            "fpr": 0.16575192096597147,
            "logloss": 0.6475455602268408,
            "mae": 0.4259250323512028,
            "precision": 0.6800847457627118,
            "recall": 0.678646934460888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6985415516338856,
            "auditor_fn_violation": 0.00652195717985192,
            "auditor_fp_violation": 0.011382138641266758,
            "ave_precision_score": 0.6505791598988088,
            "fpr": 0.2631578947368421,
            "logloss": 0.6512329547104876,
            "mae": 0.4542629130740176,
            "precision": 0.6091205211726385,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6991630005314876,
            "auditor_fn_violation": 0.01621014474255227,
            "auditor_fp_violation": 0.01877609531399587,
            "ave_precision_score": 0.6516648232804246,
            "fpr": 0.265642151481888,
            "logloss": 0.642364510490071,
            "mae": 0.4500184006473759,
            "precision": 0.6140350877192983,
            "recall": 0.813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6112170888486678,
            "auditor_fn_violation": 0.0075181456760404376,
            "auditor_fp_violation": 0.003994179183457482,
            "ave_precision_score": 0.595630511992068,
            "fpr": 0.02850877192982456,
            "logloss": 0.8036761008501767,
            "mae": 0.4752429925689572,
            "precision": 0.7739130434782608,
            "recall": 0.18503118503118504
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6086893492624758,
            "auditor_fn_violation": 0.0058969187961095725,
            "auditor_fp_violation": 0.003894561147617402,
            "ave_precision_score": 0.5880281252433677,
            "fpr": 0.02305159165751921,
            "logloss": 0.7975289271638272,
            "mae": 0.4713341683378335,
            "precision": 0.8073394495412844,
            "recall": 0.18604651162790697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8643463808333309,
            "auditor_fn_violation": 0.017632764343290662,
            "auditor_fp_violation": 0.014529144787723373,
            "ave_precision_score": 0.8631348071125945,
            "fpr": 0.08991228070175439,
            "logloss": 0.4916826755440819,
            "mae": 0.30892075807379005,
            "precision": 0.8148984198645598,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8609300608436835,
            "auditor_fn_violation": 0.015875962803693643,
            "auditor_fp_violation": 0.011443092792806342,
            "ave_precision_score": 0.8585057296153882,
            "fpr": 0.0889132821075741,
            "logloss": 0.48512609734858453,
            "mae": 0.3045949812796535,
            "precision": 0.8137931034482758,
            "recall": 0.7484143763213531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8021624066946542,
            "auditor_fn_violation": 0.03256875296348981,
            "auditor_fp_violation": 0.010901310701347339,
            "ave_precision_score": 0.803462126984628,
            "fpr": 0.049342105263157895,
            "logloss": 0.9473262438172705,
            "mae": 0.367840749991892,
            "precision": 0.8584905660377359,
            "recall": 0.5675675675675675
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7977300889216125,
            "auditor_fn_violation": 0.020173913850681024,
            "auditor_fp_violation": 0.0056313249026359695,
            "ave_precision_score": 0.7982993739958991,
            "fpr": 0.05598243688254665,
            "logloss": 1.0896201131405916,
            "mae": 0.372992426029912,
            "precision": 0.8305647840531561,
            "recall": 0.5285412262156448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8161194901326736,
            "auditor_fn_violation": 0.011655633366159691,
            "auditor_fp_violation": 0.007884051776773721,
            "ave_precision_score": 0.806670297289094,
            "fpr": 0.041666666666666664,
            "logloss": 0.5867720954186652,
            "mae": 0.3620717094132775,
            "precision": 0.8661971830985915,
            "recall": 0.5114345114345115
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.845322325912432,
            "auditor_fn_violation": 0.011830968918758985,
            "auditor_fp_violation": 0.0042805086487326385,
            "ave_precision_score": 0.831263597588454,
            "fpr": 0.024149286498353458,
            "logloss": 0.5714601876165826,
            "mae": 0.35092350851200543,
            "precision": 0.9147286821705426,
            "recall": 0.4989429175475687
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7637061403508771,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5274122807017544,
            "fpr": 0.4725877192982456,
            "logloss": 0.691817073230089,
            "mae": 0.49798764066215145,
            "precision": 0.5274122807017544,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7596048298572997,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5192096597145993,
            "fpr": 0.4807903402854007,
            "logloss": 0.6930235667443637,
            "mae": 0.4985898021939819,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 1318,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5271851392235855,
            "auditor_fn_violation": 0.0328924572345625,
            "auditor_fp_violation": 0.02552458582651525,
            "ave_precision_score": 0.5291334270762593,
            "fpr": 0.32127192982456143,
            "logloss": 0.691871460450648,
            "mae": 0.49871853768433394,
            "precision": 0.5499231950844854,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5665052510007953,
            "auditor_fn_violation": 0.021264646567789047,
            "auditor_fp_violation": 0.01892395831766991,
            "ave_precision_score": 0.5682524904601339,
            "fpr": 0.34796926454445665,
            "logloss": 0.6894502556780097,
            "mae": 0.4975897923651694,
            "precision": 0.5331369661266568,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.815884971540921,
            "auditor_fn_violation": 0.016321990006200535,
            "auditor_fp_violation": 0.022163878373427787,
            "ave_precision_score": 0.8162211240048141,
            "fpr": 0.33771929824561403,
            "logloss": 1.5604720596617598,
            "mae": 0.4016520281367122,
            "precision": 0.5798090040927695,
            "recall": 0.8835758835758836
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8447174485786231,
            "auditor_fn_violation": 0.0075863941536726395,
            "auditor_fp_violation": 0.02081860968678105,
            "ave_precision_score": 0.8449870963773903,
            "fpr": 0.33479692645444564,
            "logloss": 1.3641091845738877,
            "mae": 0.3901469685441329,
            "precision": 0.5833333333333334,
            "recall": 0.9027484143763214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.8126721596498059,
            "auditor_fn_violation": 0.0018305248568406464,
            "auditor_fp_violation": 0.013753205519599467,
            "ave_precision_score": 0.7761744486034348,
            "fpr": 0.4276315789473684,
            "logloss": 3.487242123938428,
            "mae": 0.4175096341404944,
            "precision": 0.5501730103806228,
            "recall": 0.9916839916839917
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.8203657326245781,
            "auditor_fn_violation": 0.001670909694293147,
            "auditor_fp_violation": 0.009342936910114352,
            "ave_precision_score": 0.7826228860908472,
            "fpr": 0.43029637760702527,
            "logloss": 3.4677131261147767,
            "mae": 0.41968032977752023,
            "precision": 0.5452436194895591,
            "recall": 0.9936575052854123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8275579340450245,
            "auditor_fn_violation": 0.005334281650071127,
            "auditor_fp_violation": 0.010522245288395004,
            "ave_precision_score": 0.8325982541537742,
            "fpr": 0.11732456140350878,
            "logloss": 0.5147769411514057,
            "mae": 0.32630260635918956,
            "precision": 0.7747368421052632,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8326750859165923,
            "auditor_fn_violation": 0.0119237972351086,
            "auditor_fp_violation": 0.00743826093058459,
            "ave_precision_score": 0.8386699237498348,
            "fpr": 0.10318331503841932,
            "logloss": 0.4941634083060362,
            "mae": 0.3164388108119352,
            "precision": 0.7952069716775599,
            "recall": 0.7716701902748414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 1318,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7829503354871863,
            "auditor_fn_violation": 0.039416694021957195,
            "auditor_fp_violation": 0.016912931981926976,
            "ave_precision_score": 0.7820092751706291,
            "fpr": 0.08662280701754387,
            "logloss": 0.5908247889983319,
            "mae": 0.37323009572400334,
            "precision": 0.7870619946091644,
            "recall": 0.6070686070686071
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8125861041685541,
            "auditor_fn_violation": 0.03783218032828735,
            "auditor_fp_violation": 0.019833691713155802,
            "ave_precision_score": 0.8091214434221551,
            "fpr": 0.07574094401756312,
            "logloss": 0.5556783853148268,
            "mae": 0.3574015765433516,
            "precision": 0.8140161725067385,
            "recall": 0.638477801268499
        }
    }
]