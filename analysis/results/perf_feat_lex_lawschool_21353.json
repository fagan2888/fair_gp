[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7909268995746112,
            "auditor_fn_violation": 0.014485464694794841,
            "auditor_fp_violation": 0.014254385964912283,
            "ave_precision_score": 0.7605748610256768,
            "fpr": 0.14692982456140352,
            "logloss": 2.2294184254138814,
            "mae": 0.2839711126705288,
            "precision": 0.7403100775193798,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7984185309982188,
            "auditor_fn_violation": 0.02575145386178387,
            "auditor_fp_violation": 0.02681511682609378,
            "ave_precision_score": 0.7762825853597561,
            "fpr": 0.13830954994511527,
            "logloss": 1.7439345017640397,
            "mae": 0.28244694948978133,
            "precision": 0.7423312883435583,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6893105567076174,
            "auditor_fn_violation": 0.019111570247933883,
            "auditor_fp_violation": 0.008441445318904736,
            "ave_precision_score": 0.6628471293808618,
            "fpr": 0.11951754385964912,
            "logloss": 3.8153844941885344,
            "mae": 0.41176511959617645,
            "precision": 0.6656441717791411,
            "recall": 0.44834710743801653
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6819285467417104,
            "auditor_fn_violation": 0.01289207557745757,
            "auditor_fp_violation": 0.009602963029339074,
            "ave_precision_score": 0.6617317331855942,
            "fpr": 0.11306256860592755,
            "logloss": 3.556268040287915,
            "mae": 0.4094762153724944,
            "precision": 0.6600660066006601,
            "recall": 0.425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8069454972470366,
            "auditor_fn_violation": 0.02789709293895898,
            "auditor_fp_violation": 0.02326201016560092,
            "ave_precision_score": 0.8078265764672667,
            "fpr": 0.13596491228070176,
            "logloss": 0.9915177650432415,
            "mae": 0.27495284497109906,
            "precision": 0.746938775510204,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8199616433739254,
            "auditor_fn_violation": 0.026055071583716755,
            "auditor_fp_violation": 0.022486565061443538,
            "ave_precision_score": 0.8202064814318373,
            "fpr": 0.13611416026344675,
            "logloss": 0.9099143000910687,
            "mae": 0.2872043484645268,
            "precision": 0.7304347826086957,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7866504297630331,
            "auditor_fn_violation": 0.016787190082644628,
            "auditor_fp_violation": 0.028150106574848333,
            "ave_precision_score": 0.7569154440538394,
            "fpr": 0.16666666666666666,
            "logloss": 2.114439751752933,
            "mae": 0.289636276315912,
            "precision": 0.7236363636363636,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7945851034152442,
            "auditor_fn_violation": 0.030303384169839083,
            "auditor_fp_violation": 0.03493706300668823,
            "ave_precision_score": 0.7726483577114767,
            "fpr": 0.1602634467618002,
            "logloss": 1.6897728485809778,
            "mae": 0.29102749076700524,
            "precision": 0.7176015473887815,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7944623115220619,
            "auditor_fn_violation": 0.007050166739161956,
            "auditor_fp_violation": 0.01659083456304312,
            "ave_precision_score": 0.7564296107025985,
            "fpr": 0.19407894736842105,
            "logloss": 2.5409956123152537,
            "mae": 0.289499180074097,
            "precision": 0.7035175879396985,
            "recall": 0.8677685950413223
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7962944383853533,
            "auditor_fn_violation": 0.013424574351309063,
            "auditor_fp_violation": 0.03419779913428966,
            "ave_precision_score": 0.7684575357042387,
            "fpr": 0.18221734357848518,
            "logloss": 2.026691362002916,
            "mae": 0.29358776330613584,
            "precision": 0.7087719298245614,
            "recall": 0.8595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 21353,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.809907122186144,
            "auditor_fn_violation": 0.022609467884587505,
            "auditor_fp_violation": 0.020008403016888016,
            "ave_precision_score": 0.8107837750397682,
            "fpr": 0.13486842105263158,
            "logloss": 0.9522546972199093,
            "mae": 0.27371109787383635,
            "precision": 0.7520161290322581,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8238383082031037,
            "auditor_fn_violation": 0.02373122825046127,
            "auditor_fp_violation": 0.021523281833772664,
            "ave_precision_score": 0.824076900132352,
            "fpr": 0.13391877058177826,
            "logloss": 0.8715962864020552,
            "mae": 0.2851906756134078,
            "precision": 0.7365010799136069,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7892776566341237,
            "auditor_fn_violation": 0.015126594896331742,
            "auditor_fp_violation": 0.017725754222003606,
            "ave_precision_score": 0.7591201511560906,
            "fpr": 0.15679824561403508,
            "logloss": 2.2314122343521237,
            "mae": 0.2866965198176843,
            "precision": 0.7291666666666666,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7949570439653846,
            "auditor_fn_violation": 0.02840460564728963,
            "auditor_fp_violation": 0.030914671027576793,
            "ave_precision_score": 0.7720065983108049,
            "fpr": 0.15148188803512624,
            "logloss": 1.7777709414287861,
            "mae": 0.2909772261608212,
            "precision": 0.7261904761904762,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7392385703622213,
            "auditor_fn_violation": 0.002147672901261424,
            "auditor_fp_violation": 0.011743728480078703,
            "ave_precision_score": 0.7000523004401742,
            "fpr": 0.17324561403508773,
            "logloss": 2.822253702826283,
            "mae": 0.3336237374439901,
            "precision": 0.6865079365079365,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.731345646873117,
            "auditor_fn_violation": 0.014277039493659069,
            "auditor_fp_violation": 0.02824884069983647,
            "ave_precision_score": 0.6969696987458066,
            "fpr": 0.17453347969264543,
            "logloss": 2.5253744008943513,
            "mae": 0.3473705344130086,
            "precision": 0.6701244813278008,
            "recall": 0.6872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8178056796646515,
            "auditor_fn_violation": 0.007568961142525737,
            "auditor_fp_violation": 0.005169904902443024,
            "ave_precision_score": 0.8188950356533942,
            "fpr": 0.13048245614035087,
            "logloss": 0.8666309404361524,
            "mae": 0.27159381186411324,
            "precision": 0.758130081300813,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8312802224269551,
            "auditor_fn_violation": 0.014475558773384401,
            "auditor_fp_violation": 0.02121961115218133,
            "ave_precision_score": 0.8315093385996709,
            "fpr": 0.12623490669593854,
            "logloss": 0.8022660398756483,
            "mae": 0.2771817170797351,
            "precision": 0.7542735042735043,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.815279198838608,
            "auditor_fn_violation": 0.003534145280556767,
            "auditor_fp_violation": 0.007426934743400561,
            "ave_precision_score": 0.8161069740007891,
            "fpr": 0.12828947368421054,
            "logloss": 0.8788990097556363,
            "mae": 0.27254950870033334,
            "precision": 0.7607361963190185,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8293107441909421,
            "auditor_fn_violation": 0.016640586682859622,
            "auditor_fp_violation": 0.019265664553417414,
            "ave_precision_score": 0.829545086602498,
            "fpr": 0.12184412733260154,
            "logloss": 0.8089231819376402,
            "mae": 0.27874876505253393,
            "precision": 0.7597402597402597,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7609228245724626,
            "auditor_fn_violation": 0.03707907423517471,
            "auditor_fp_violation": 0.052654636005902616,
            "ave_precision_score": 0.729943179702997,
            "fpr": 0.22478070175438597,
            "logloss": 2.456277483137537,
            "mae": 0.3362050634867458,
            "precision": 0.657190635451505,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7664939148361146,
            "auditor_fn_violation": 0.04746479202186048,
            "auditor_fp_violation": 0.059780809506385806,
            "ave_precision_score": 0.744130505826001,
            "fpr": 0.21295279912184412,
            "logloss": 2.036683652964534,
            "mae": 0.334561476530452,
            "precision": 0.6566371681415929,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7991848723698614,
            "auditor_fn_violation": 0.004999909380890242,
            "auditor_fp_violation": 0.02326969585177898,
            "ave_precision_score": 0.7687688174259306,
            "fpr": 0.2138157894736842,
            "logloss": 2.231829559242835,
            "mae": 0.2823976730778987,
            "precision": 0.6894904458598726,
            "recall": 0.8946280991735537
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.798656460218568,
            "auditor_fn_violation": 0.016376672816871808,
            "auditor_fp_violation": 0.03284123748291853,
            "ave_precision_score": 0.7764003607290899,
            "fpr": 0.2239297475301866,
            "logloss": 1.8686230187149688,
            "mae": 0.29194231694695844,
            "precision": 0.6741214057507987,
            "recall": 0.8978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6804300364032821,
            "auditor_fn_violation": 0.021576410033347836,
            "auditor_fp_violation": 0.02960270126250205,
            "ave_precision_score": 0.6091846655210291,
            "fpr": 0.22039473684210525,
            "logloss": 7.316641740847837,
            "mae": 0.39897934694777343,
            "precision": 0.6171428571428571,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6756711478936065,
            "auditor_fn_violation": 0.03194992643109046,
            "auditor_fp_violation": 0.033811988022431815,
            "ave_precision_score": 0.6129755798872634,
            "fpr": 0.20087815587266739,
            "logloss": 6.845507669990805,
            "mae": 0.38222128088662083,
            "precision": 0.6295546558704453,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7878994650586921,
            "auditor_fn_violation": 0.015767725097868644,
            "auditor_fp_violation": 0.02048491555992786,
            "ave_precision_score": 0.7577301330745307,
            "fpr": 0.15789473684210525,
            "logloss": 2.2089268581243666,
            "mae": 0.28801146099050556,
            "precision": 0.7272727272727273,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7961371953479975,
            "auditor_fn_violation": 0.02730691080645538,
            "auditor_fp_violation": 0.028898496830126123,
            "ave_precision_score": 0.7741186881967013,
            "fpr": 0.13721185510428102,
            "logloss": 1.7345683286357239,
            "mae": 0.2843314475040441,
            "precision": 0.745417515274949,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7864320186964793,
            "auditor_fn_violation": 0.003472977381470211,
            "auditor_fp_violation": 0.002946179701590425,
            "ave_precision_score": 0.7567447167463759,
            "fpr": 0.1074561403508772,
            "logloss": 2.258487972902975,
            "mae": 0.29437795688064444,
            "precision": 0.7627118644067796,
            "recall": 0.6508264462809917
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7920340107647303,
            "auditor_fn_violation": 0.015708713828619478,
            "auditor_fp_violation": 0.011365248624147803,
            "ave_precision_score": 0.7701679658997488,
            "fpr": 0.10537870472008781,
            "logloss": 1.8403458992456583,
            "mae": 0.3066201165589752,
            "precision": 0.7473684210526316,
            "recall": 0.6042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7894594198751349,
            "auditor_fn_violation": 0.0010896947948383386,
            "auditor_fp_violation": 0.009479012952943115,
            "ave_precision_score": 0.7593822061532544,
            "fpr": 0.13596491228070176,
            "logloss": 2.2240726883389828,
            "mae": 0.2800854169963611,
            "precision": 0.7484787018255578,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7942790374407078,
            "auditor_fn_violation": 0.018917719597356192,
            "auditor_fp_violation": 0.025652705282625317,
            "ave_precision_score": 0.7721469646964749,
            "fpr": 0.13391877058177826,
            "logloss": 1.821215815937673,
            "mae": 0.28402829445557776,
            "precision": 0.7431578947368421,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6708882399864962,
            "auditor_fn_violation": 0.016619544729592577,
            "auditor_fp_violation": 0.01237907853746517,
            "ave_precision_score": 0.581901051423314,
            "fpr": 0.22478070175438597,
            "logloss": 6.903806297516796,
            "mae": 0.36279952251509695,
            "precision": 0.6422338568935427,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.6712434748061376,
            "auditor_fn_violation": 0.021318635121563866,
            "auditor_fp_violation": 0.012940851422896273,
            "ave_precision_score": 0.5877156033827743,
            "fpr": 0.21624588364434688,
            "logloss": 6.271766034144671,
            "mae": 0.3646932163225749,
            "precision": 0.6391941391941391,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7734054755621405,
            "auditor_fn_violation": 0.02635656807307525,
            "auditor_fp_violation": 0.06302006476471553,
            "ave_precision_score": 0.7741228420948079,
            "fpr": 0.22478070175438597,
            "logloss": 0.599705879726955,
            "mae": 0.3497324677494665,
            "precision": 0.6751188589540412,
            "recall": 0.8801652892561983
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7912119770629142,
            "auditor_fn_violation": 0.02975920779129785,
            "auditor_fp_violation": 0.06489840722238402,
            "ave_precision_score": 0.7915405610284563,
            "fpr": 0.24039517014270034,
            "logloss": 0.592315455706116,
            "mae": 0.3504254797904964,
            "precision": 0.6507177033492823,
            "recall": 0.8680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8180774221003932,
            "auditor_fn_violation": 0.006680893866898651,
            "auditor_fp_violation": 0.012138260370552552,
            "ave_precision_score": 0.8189088852611373,
            "fpr": 0.13815789473684212,
            "logloss": 0.8604051095620552,
            "mae": 0.26972677032278425,
            "precision": 0.7543859649122807,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8306982585297561,
            "auditor_fn_violation": 0.019968704019431537,
            "auditor_fp_violation": 0.03060851124203799,
            "ave_precision_score": 0.8309348051112109,
            "fpr": 0.1394072447859495,
            "logloss": 0.800987312836161,
            "mae": 0.27518176547172934,
            "precision": 0.7402862985685071,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7782871531276111,
            "auditor_fn_violation": 0.011316061331013485,
            "auditor_fp_violation": 0.018747950483685858,
            "ave_precision_score": 0.7486120630560085,
            "fpr": 0.17214912280701755,
            "logloss": 2.1843431247157006,
            "mae": 0.3077804419342755,
            "precision": 0.7166064981949458,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7831591132089433,
            "auditor_fn_violation": 0.01637200177499592,
            "auditor_fp_violation": 0.03424260300534411,
            "ave_precision_score": 0.7612964253041677,
            "fpr": 0.1734357848518112,
            "logloss": 1.7257827601300642,
            "mae": 0.31596327796639795,
            "precision": 0.7035647279549718,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7949701147517273,
            "auditor_fn_violation": 0.004460725677830945,
            "auditor_fp_violation": 0.01252766847024102,
            "ave_precision_score": 0.7646612591931641,
            "fpr": 0.16337719298245615,
            "logloss": 2.1762050807780065,
            "mae": 0.2809648786369188,
            "precision": 0.7320143884892086,
            "recall": 0.8409090909090909
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7979030600610272,
            "auditor_fn_violation": 0.01162155218721536,
            "auditor_fp_violation": 0.02961535876699747,
            "ave_precision_score": 0.7749419833654592,
            "fpr": 0.15806805708013172,
            "logloss": 1.7818240857826766,
            "mae": 0.2871695503765772,
            "precision": 0.7323420074349443,
            "recall": 0.8382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7855404410850733,
            "auditor_fn_violation": 0.03571752211106278,
            "auditor_fp_violation": 0.03261805213969504,
            "ave_precision_score": 0.785956629242899,
            "fpr": 0.1425438596491228,
            "logloss": 0.9922565529212287,
            "mae": 0.3086256245889613,
            "precision": 0.7245762711864406,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7987623010590431,
            "auditor_fn_violation": 0.05049396267837542,
            "auditor_fp_violation": 0.042810098792535674,
            "ave_precision_score": 0.7990804635405242,
            "fpr": 0.13830954994511527,
            "logloss": 0.9626909705421879,
            "mae": 0.3007947759935034,
            "precision": 0.7230769230769231,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8195873911429217,
            "auditor_fn_violation": 0.006397709148905323,
            "auditor_fp_violation": 0.00935091818330874,
            "ave_precision_score": 0.8201623969743681,
            "fpr": 0.13815789473684212,
            "logloss": 0.8522415442401954,
            "mae": 0.2696627021835908,
            "precision": 0.7529411764705882,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8323570210227329,
            "auditor_fn_violation": 0.01703061867949646,
            "auditor_fp_violation": 0.02577716047999882,
            "ave_precision_score": 0.8325874657942273,
            "fpr": 0.1350164654226125,
            "logloss": 0.7874741752728929,
            "mae": 0.2759040204014278,
            "precision": 0.7484662576687117,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8145952603154717,
            "auditor_fn_violation": 0.0074692801217920825,
            "auditor_fp_violation": 0.007368011149368751,
            "ave_precision_score": 0.815362689624886,
            "fpr": 0.12719298245614036,
            "logloss": 0.9078738330422992,
            "mae": 0.26988806728308395,
            "precision": 0.7618069815195072,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8319817901915284,
            "auditor_fn_violation": 0.018380549781628792,
            "auditor_fp_violation": 0.022277480329856058,
            "ave_precision_score": 0.8322202999235128,
            "fpr": 0.12733260153677278,
            "logloss": 0.8393275149956089,
            "mae": 0.27524145749886453,
            "precision": 0.7510729613733905,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6459663613546605,
            "auditor_fn_violation": 0.008101348412353203,
            "auditor_fp_violation": 0.006673737497950487,
            "ave_precision_score": 0.6282473275973122,
            "fpr": 0.06030701754385965,
            "logloss": 3.3337070574223713,
            "mae": 0.4862954669358156,
            "precision": 0.6258503401360545,
            "recall": 0.19008264462809918
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6503394379923593,
            "auditor_fn_violation": 0.001202793283041787,
            "auditor_fp_violation": 0.009941481166194982,
            "ave_precision_score": 0.632358344881473,
            "fpr": 0.054884742041712405,
            "logloss": 3.226877519650119,
            "mae": 0.47452633126323546,
            "precision": 0.6124031007751938,
            "recall": 0.16808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5852571460022988,
            "auditor_fn_violation": 0.02501087429317095,
            "auditor_fp_violation": 0.01490510739465488,
            "ave_precision_score": 0.5746144347804739,
            "fpr": 0.3881578947368421,
            "logloss": 1.6854988431892197,
            "mae": 0.48576543844517384,
            "precision": 0.5163934426229508,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.5621291705971871,
            "auditor_fn_violation": 0.025088165915407436,
            "auditor_fp_violation": 0.014523921533487163,
            "ave_precision_score": 0.5488400357883545,
            "fpr": 0.4039517014270033,
            "logloss": 1.892770893366454,
            "mae": 0.492535762488842,
            "precision": 0.49171270718232046,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 21353,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8679435141692176,
            "auditor_fn_violation": 0.012990249383790058,
            "auditor_fp_violation": 0.0176463354648303,
            "ave_precision_score": 0.8681174064725361,
            "fpr": 0.10964912280701754,
            "logloss": 0.4983382349251267,
            "mae": 0.3041742189714313,
            "precision": 0.7885835095137421,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8477134365140956,
            "auditor_fn_violation": 0.019090548146764138,
            "auditor_fp_violation": 0.009319205179327498,
            "ave_precision_score": 0.84797335013104,
            "fpr": 0.12843029637760703,
            "logloss": 0.49415986457570366,
            "mae": 0.3067468532691296,
            "precision": 0.7577639751552795,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7862161245797163,
            "auditor_fn_violation": 4.530955487893394e-05,
            "auditor_fp_violation": 0.007373134940154124,
            "ave_precision_score": 0.7565277075186072,
            "fpr": 0.11293859649122807,
            "logloss": 2.207645938057558,
            "mae": 0.2908806306586006,
            "precision": 0.7599067599067599,
            "recall": 0.6735537190082644
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7916648377227413,
            "auditor_fn_violation": 0.016521475115024407,
            "auditor_fp_violation": 0.011925297012328532,
            "ave_precision_score": 0.769822520337912,
            "fpr": 0.1119648737650933,
            "logloss": 1.7847393420737274,
            "mae": 0.3010780332820798,
            "precision": 0.745,
            "recall": 0.6340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 21353,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8242075815585674,
            "auditor_fn_violation": 0.008540851094678847,
            "auditor_fp_violation": 0.012002479914740119,
            "ave_precision_score": 0.8247572356070441,
            "fpr": 0.14583333333333334,
            "logloss": 0.7679468718928113,
            "mae": 0.2707901685887613,
            "precision": 0.7452107279693486,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8368836212066069,
            "auditor_fn_violation": 0.014811873788448513,
            "auditor_fp_violation": 0.02576969316815639,
            "ave_precision_score": 0.83710287075285,
            "fpr": 0.14489571899012074,
            "logloss": 0.715768726658024,
            "mae": 0.27563917760679524,
            "precision": 0.7391304347826086,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.762058237078684,
            "auditor_fn_violation": 0.032620614035087724,
            "auditor_fp_violation": 0.03664535169699951,
            "ave_precision_score": 0.7325511263979602,
            "fpr": 0.19298245614035087,
            "logloss": 2.33772427032884,
            "mae": 0.3247615026955732,
            "precision": 0.6862745098039216,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7702691346192225,
            "auditor_fn_violation": 0.04266996753625897,
            "auditor_fp_violation": 0.044878544172883214,
            "ave_precision_score": 0.7484482975728608,
            "fpr": 0.19099890230515917,
            "logloss": 1.881192174222716,
            "mae": 0.32258542549375213,
            "precision": 0.6807339449541284,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8688381108352725,
            "auditor_fn_violation": 0.019673408728432654,
            "auditor_fp_violation": 0.011733480898507953,
            "ave_precision_score": 0.8690710813069152,
            "fpr": 0.08114035087719298,
            "logloss": 0.5574010824371507,
            "mae": 0.29404317901508803,
            "precision": 0.8266978922716628,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8520049769614844,
            "auditor_fn_violation": 0.026143821379358678,
            "auditor_fp_violation": 0.009680125251710638,
            "ave_precision_score": 0.852254571848348,
            "fpr": 0.07793633369923161,
            "logloss": 0.5098979579490297,
            "mae": 0.2990009966241576,
            "precision": 0.8255528255528255,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7787144020039761,
            "auditor_fn_violation": 0.014100333478323911,
            "auditor_fp_violation": 0.022360222987374986,
            "ave_precision_score": 0.7489470457634146,
            "fpr": 0.17543859649122806,
            "logloss": 2.2227438956279717,
            "mae": 0.30576727451529895,
            "precision": 0.7127468581687613,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7837524237233242,
            "auditor_fn_violation": 0.02602938085339935,
            "auditor_fp_violation": 0.03797376982260156,
            "ave_precision_score": 0.7617576254863185,
            "fpr": 0.17233809001097694,
            "logloss": 1.7700914928565201,
            "mae": 0.3120533959062431,
            "precision": 0.7026515151515151,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 21353,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7906705027850778,
            "auditor_fn_violation": 0.00654496520226186,
            "auditor_fp_violation": 0.006999098212821779,
            "ave_precision_score": 0.7605930956736784,
            "fpr": 0.13048245614035087,
            "logloss": 3.3569546080535932,
            "mae": 0.2668793645097291,
            "precision": 0.762,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7941075374520957,
            "auditor_fn_violation": 0.011163790083378098,
            "auditor_fp_violation": 0.0228873107969862,
            "ave_precision_score": 0.7718137379470345,
            "fpr": 0.13172338090010977,
            "logloss": 2.776300663106618,
            "mae": 0.27843604962647983,
            "precision": 0.75,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7874982408292786,
            "auditor_fn_violation": 0.018230299405538643,
            "auditor_fp_violation": 0.027130472208558784,
            "ave_precision_score": 0.7576251750923702,
            "fpr": 0.16447368421052633,
            "logloss": 2.143622740795538,
            "mae": 0.28938508120361867,
            "precision": 0.7247706422018348,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7946621068623481,
            "auditor_fn_violation": 0.0296844711212836,
            "auditor_fp_violation": 0.031606641924973436,
            "ave_precision_score": 0.7726386740534926,
            "fpr": 0.15367727771679474,
            "logloss": 1.7210315790575565,
            "mae": 0.29039942638914823,
            "precision": 0.7276264591439688,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7868412288448443,
            "auditor_fn_violation": 0.01981613382630129,
            "auditor_fp_violation": 0.027130472208558784,
            "ave_precision_score": 0.7570258405220578,
            "fpr": 0.16447368421052633,
            "logloss": 2.142998343180031,
            "mae": 0.2897753159366466,
            "precision": 0.7237569060773481,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7945068437132002,
            "auditor_fn_violation": 0.02915897891024593,
            "auditor_fp_violation": 0.032161712105259234,
            "ave_precision_score": 0.7724891535489236,
            "fpr": 0.15477497255762898,
            "logloss": 1.7197413600360856,
            "mae": 0.29065644559355885,
            "precision": 0.72568093385214,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7600931286138769,
            "auditor_fn_violation": 0.016950304480208796,
            "auditor_fp_violation": 0.026164637645515656,
            "ave_precision_score": 0.756906234377136,
            "fpr": 0.1611842105263158,
            "logloss": 4.380809128624989,
            "mae": 0.3244172349187921,
            "precision": 0.6993865030674846,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7604561859927398,
            "auditor_fn_violation": 0.02704533246140552,
            "auditor_fp_violation": 0.03305530042240094,
            "ave_precision_score": 0.7585725282490907,
            "fpr": 0.1668496158068057,
            "logloss": 4.5669583678672145,
            "mae": 0.34310397563308875,
            "precision": 0.6833333333333333,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.712059013537869,
            "auditor_fn_violation": 0.015835689430187053,
            "auditor_fp_violation": 0.01066260862436465,
            "ave_precision_score": 0.6845057819383189,
            "fpr": 0.10855263157894737,
            "logloss": 3.4673209475098594,
            "mae": 0.40519584285144256,
            "precision": 0.6876971608832808,
            "recall": 0.45041322314049587
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7113082643103023,
            "auditor_fn_violation": 0.014559637527150443,
            "auditor_fp_violation": 0.012552551207090966,
            "ave_precision_score": 0.6888352171689079,
            "fpr": 0.10098792535675083,
            "logloss": 3.1237794242980743,
            "mae": 0.39460870690150684,
            "precision": 0.6933333333333334,
            "recall": 0.4425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 21353,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8259340919871716,
            "auditor_fn_violation": 0.00311729737567058,
            "auditor_fp_violation": 0.011559272011805219,
            "ave_precision_score": 0.8263266743128965,
            "fpr": 0.13596491228070176,
            "logloss": 0.796821578976742,
            "mae": 0.2679463905177811,
            "precision": 0.753968253968254,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8337187937409594,
            "auditor_fn_violation": 0.016208515309339745,
            "auditor_fp_violation": 0.02960789145515506,
            "ave_precision_score": 0.8339463498984856,
            "fpr": 0.13721185510428102,
            "logloss": 0.7659257389777637,
            "mae": 0.27577052191903967,
            "precision": 0.7448979591836735,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 21353,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6727956897478098,
            "auditor_fn_violation": 0.022160903291286074,
            "auditor_fp_violation": 0.016572901295294318,
            "ave_precision_score": 0.583807705590198,
            "fpr": 0.22697368421052633,
            "logloss": 6.822157107625858,
            "mae": 0.37076218020790785,
            "precision": 0.6526845637583892,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6763309785597288,
            "auditor_fn_violation": 0.03073545554335895,
            "auditor_fp_violation": 0.016761625982262655,
            "ave_precision_score": 0.592801106951063,
            "fpr": 0.22283205268935236,
            "logloss": 6.175646195255867,
            "mae": 0.3661703967829731,
            "precision": 0.6493955094991365,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8672244674979964,
            "auditor_fn_violation": 0.006035232709873864,
            "auditor_fp_violation": 0.01751311690441057,
            "ave_precision_score": 0.8674398999343819,
            "fpr": 0.1206140350877193,
            "logloss": 0.4781714937676788,
            "mae": 0.3057684036004439,
            "precision": 0.78,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8575591825027022,
            "auditor_fn_violation": 0.01655884345003153,
            "auditor_fp_violation": 0.017214642900702175,
            "ave_precision_score": 0.8578345865291899,
            "fpr": 0.13062568605927552,
            "logloss": 0.483849972518969,
            "mae": 0.30977025226527327,
            "precision": 0.765748031496063,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6586531083478758,
            "auditor_fn_violation": 0.007843083949543297,
            "auditor_fp_violation": 0.006461100180357436,
            "ave_precision_score": 0.6553209156918205,
            "fpr": 0.047149122807017545,
            "logloss": 4.539008922559407,
            "mae": 0.47401098112034956,
            "precision": 0.6950354609929078,
            "recall": 0.2024793388429752
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6568334258620567,
            "auditor_fn_violation": 0.012504379101758643,
            "auditor_fp_violation": 0.016739224046735418,
            "ave_precision_score": 0.6564054882623827,
            "fpr": 0.048298572996706916,
            "logloss": 4.401283681343621,
            "mae": 0.4575146561173772,
            "precision": 0.6923076923076923,
            "recall": 0.21063829787234042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6223601831839004,
            "auditor_fn_violation": 0.02091942148760331,
            "auditor_fp_violation": 0.029618072634858182,
            "ave_precision_score": 0.6233484716875121,
            "fpr": 0.33881578947368424,
            "logloss": 1.6982370200202594,
            "mae": 0.39253903540902946,
            "precision": 0.5863453815261044,
            "recall": 0.9049586776859504
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6096964096184632,
            "auditor_fn_violation": 0.018964430016115096,
            "auditor_fp_violation": 0.03378958608690458,
            "ave_precision_score": 0.6097249801848716,
            "fpr": 0.3468715697036224,
            "logloss": 1.7565296840796587,
            "mae": 0.3967025146686923,
            "precision": 0.5746971736204576,
            "recall": 0.9085106382978724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6798252287689808,
            "auditor_fn_violation": 0.008083224590401629,
            "auditor_fp_violation": 0.012988809640924743,
            "ave_precision_score": 0.6724961469663114,
            "fpr": 0.10416666666666667,
            "logloss": 2.435007635763456,
            "mae": 0.4222752949861406,
            "precision": 0.671280276816609,
            "recall": 0.40082644628099173
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6736161791655106,
            "auditor_fn_violation": 0.01862577948011305,
            "auditor_fp_violation": 0.02420155768125033,
            "ave_precision_score": 0.6688645605929651,
            "fpr": 0.09440175631174534,
            "logloss": 2.330419419223362,
            "mae": 0.4189831446627912,
            "precision": 0.6730038022813688,
            "recall": 0.37659574468085105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7869663678477844,
            "auditor_fn_violation": 0.02296514789038713,
            "auditor_fp_violation": 0.028887932447942292,
            "ave_precision_score": 0.7567255119263063,
            "fpr": 0.16228070175438597,
            "logloss": 2.184419942466012,
            "mae": 0.2922674952227553,
            "precision": 0.7264325323475046,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7877080222697067,
            "auditor_fn_violation": 0.035359787000490465,
            "auditor_fp_violation": 0.04155807950695829,
            "ave_precision_score": 0.7655688216355648,
            "fpr": 0.16245883644346873,
            "logloss": 1.794769865413396,
            "mae": 0.2993097165959829,
            "precision": 0.7120622568093385,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.5867839066256842,
            "auditor_fn_violation": 0.004458460200086997,
            "auditor_fp_violation": 0.01413397688145598,
            "ave_precision_score": 0.5450470472202955,
            "fpr": 0.3673245614035088,
            "logloss": 5.036445580168176,
            "mae": 0.4198130394859043,
            "precision": 0.5727040816326531,
            "recall": 0.9276859504132231
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5838541521254629,
            "auditor_fn_violation": 0.002592428241119183,
            "auditor_fp_violation": 0.006377084313418017,
            "ave_precision_score": 0.5360847701412792,
            "fpr": 0.36882546652030734,
            "logloss": 5.0857203100465185,
            "mae": 0.429050488088742,
            "precision": 0.5670103092783505,
            "recall": 0.9361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.8416422187959094,
            "auditor_fn_violation": 0.005357854864433812,
            "auditor_fp_violation": 0.021468683390719803,
            "ave_precision_score": 0.8420605912757613,
            "fpr": 0.4100877192982456,
            "logloss": 1.2358627157150721,
            "mae": 0.4010610982396317,
            "precision": 0.5563463819691578,
            "recall": 0.96900826446281
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.85705432102559,
            "auditor_fn_violation": 0.0035383142209869907,
            "auditor_fp_violation": 0.02631978514054727,
            "ave_precision_score": 0.8572640718193036,
            "fpr": 0.40065861690450055,
            "logloss": 1.1967299188664644,
            "mae": 0.39203659751619735,
            "precision": 0.5581113801452785,
            "recall": 0.9808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.592612399751192,
            "auditor_fn_violation": 0.0243674786138901,
            "auditor_fp_violation": 0.029541215773077563,
            "ave_precision_score": 0.5511243068675934,
            "fpr": 0.3782894736842105,
            "logloss": 4.99993465298558,
            "mae": 0.4197706149123609,
            "precision": 0.5638432364096081,
            "recall": 0.9214876033057852
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.5875161987622632,
            "auditor_fn_violation": 0.018698180629189345,
            "auditor_fp_violation": 0.03901919348053894,
            "ave_precision_score": 0.5418880412438403,
            "fpr": 0.36663007683863885,
            "logloss": 4.986389413863953,
            "mae": 0.4198844454893875,
            "precision": 0.5639686684073107,
            "recall": 0.9191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7366743738445634,
            "auditor_fn_violation": 0.0031263592866463716,
            "auditor_fp_violation": 0.009996515822265958,
            "ave_precision_score": 0.7342220031791798,
            "fpr": 0.21600877192982457,
            "logloss": 0.830806313506723,
            "mae": 0.3812880205774778,
            "precision": 0.6749174917491749,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6880754035890446,
            "auditor_fn_violation": 0.012471681808627415,
            "auditor_fp_violation": 0.02144363050745363,
            "ave_precision_score": 0.6843096243597101,
            "fpr": 0.2349066959385291,
            "logloss": 1.0779812413714822,
            "mae": 0.3972054459440852,
            "precision": 0.654281098546042,
            "recall": 0.8617021276595744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7926725694561257,
            "auditor_fn_violation": 0.005067873713208645,
            "auditor_fp_violation": 0.0115823290703394,
            "ave_precision_score": 0.7629373739222856,
            "fpr": 0.13267543859649122,
            "logloss": 2.1142637297068623,
            "mae": 0.27382107740273215,
            "precision": 0.758,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7973187460025158,
            "auditor_fn_violation": 0.011717308545671115,
            "auditor_fp_violation": 0.02270062800092595,
            "ave_precision_score": 0.7753311953313856,
            "fpr": 0.132821075740944,
            "logloss": 1.70303557600978,
            "mae": 0.285997115937905,
            "precision": 0.7489626556016598,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8157479725880159,
            "auditor_fn_violation": 0.010461976221545603,
            "auditor_fp_violation": 0.009663469421216592,
            "ave_precision_score": 0.8162806510240631,
            "fpr": 0.11074561403508772,
            "logloss": 0.9569773499215097,
            "mae": 0.2755883777756849,
            "precision": 0.7745535714285714,
            "recall": 0.7169421487603306
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8320369243864274,
            "auditor_fn_violation": 0.01910456127239181,
            "auditor_fp_violation": 0.022685693377241134,
            "ave_precision_score": 0.8322749078000558,
            "fpr": 0.10757409440175632,
            "logloss": 0.8785035267478776,
            "mae": 0.27486187903623494,
            "precision": 0.7741935483870968,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7902105325909395,
            "auditor_fn_violation": 0.012285685805422653,
            "auditor_fp_violation": 0.01959337596327267,
            "ave_precision_score": 0.7603266132119976,
            "fpr": 0.14692982456140352,
            "logloss": 2.180747259705589,
            "mae": 0.2792140141044887,
            "precision": 0.7418111753371869,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.800289317203454,
            "auditor_fn_violation": 0.02367517574795058,
            "auditor_fp_violation": 0.027128743923474995,
            "ave_precision_score": 0.7782629774094328,
            "fpr": 0.1350164654226125,
            "logloss": 1.6922271119548216,
            "mae": 0.2784321496300972,
            "precision": 0.7489795918367347,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7963908125024876,
            "auditor_fn_violation": 0.006279904306220096,
            "auditor_fp_violation": 0.014930726348581736,
            "ave_precision_score": 0.7658677808839585,
            "fpr": 0.16228070175438597,
            "logloss": 2.1879662930596266,
            "mae": 0.2806769641169363,
            "precision": 0.7338129496402878,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7988587023064805,
            "auditor_fn_violation": 0.00997500992596399,
            "auditor_fp_violation": 0.02997378973543315,
            "ave_precision_score": 0.7758190018790325,
            "fpr": 0.15806805708013172,
            "logloss": 1.792345908249391,
            "mae": 0.28715247996805726,
            "precision": 0.7318435754189944,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7889888107614345,
            "auditor_fn_violation": 0.02253697259678121,
            "auditor_fp_violation": 0.01862497950483686,
            "ave_precision_score": 0.758147018490746,
            "fpr": 0.15570175438596492,
            "logloss": 2.282016020172158,
            "mae": 0.293057031855537,
            "precision": 0.7258687258687259,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7947924906856334,
            "auditor_fn_violation": 0.026419412850036208,
            "auditor_fp_violation": 0.029087668730133843,
            "ave_precision_score": 0.7725143099416688,
            "fpr": 0.14050493962678376,
            "logloss": 1.7990559136006519,
            "mae": 0.28861266215450765,
            "precision": 0.7387755102040816,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8121494723578944,
            "auditor_fn_violation": 0.01141800782949109,
            "auditor_fp_violation": 0.019647175766519104,
            "ave_precision_score": 0.8129701555681956,
            "fpr": 0.16557017543859648,
            "logloss": 0.9453415413572995,
            "mae": 0.2752565422956792,
            "precision": 0.7224264705882353,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8313032679586528,
            "auditor_fn_violation": 0.019403507952448797,
            "auditor_fp_violation": 0.024634661768110102,
            "ave_precision_score": 0.8315449200389342,
            "fpr": 0.16245883644346873,
            "logloss": 0.868893831297376,
            "mae": 0.2800924498976496,
            "precision": 0.7153846153846154,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8172096400721791,
            "auditor_fn_violation": 0.006680893866898651,
            "auditor_fp_violation": 0.013032361862600431,
            "ave_precision_score": 0.8180544197509352,
            "fpr": 0.13925438596491227,
            "logloss": 0.8735478895879302,
            "mae": 0.26988892058797476,
            "precision": 0.7529182879377432,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8300709826146895,
            "auditor_fn_violation": 0.02061097227736647,
            "auditor_fp_violation": 0.031108821135479442,
            "ave_precision_score": 0.8303082709536318,
            "fpr": 0.14050493962678376,
            "logloss": 0.8136023516460689,
            "mae": 0.2754155818467868,
            "precision": 0.7382413087934561,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7875899574707645,
            "auditor_fn_violation": 0.019224844135131217,
            "auditor_fp_violation": 0.027130472208558784,
            "ave_precision_score": 0.7577325455919623,
            "fpr": 0.16447368421052633,
            "logloss": 2.142934452507224,
            "mae": 0.28918655040577407,
            "precision": 0.7242647058823529,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7948346936172146,
            "auditor_fn_violation": 0.02915897891024593,
            "auditor_fp_violation": 0.031606641924973436,
            "ave_precision_score": 0.7728196038751285,
            "fpr": 0.15367727771679474,
            "logloss": 1.7198421822143628,
            "mae": 0.29020382892930807,
            "precision": 0.7270955165692008,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7930342680604343,
            "auditor_fn_violation": 0.01048010004349718,
            "auditor_fp_violation": 0.01427488112805378,
            "ave_precision_score": 0.7608341194418431,
            "fpr": 0.14912280701754385,
            "logloss": 2.2844775086215576,
            "mae": 0.2844309117315054,
            "precision": 0.7409523809523809,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7953791280966469,
            "auditor_fn_violation": 0.020949622813368523,
            "auditor_fp_violation": 0.02620777546291112,
            "ave_precision_score": 0.7713389682530203,
            "fpr": 0.14270032930845225,
            "logloss": 1.8700893548185893,
            "mae": 0.29156851810472173,
            "precision": 0.74,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 21353,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8734631506828903,
            "auditor_fn_violation": 0.0020457264027838253,
            "auditor_fp_violation": 0.015563514510575503,
            "ave_precision_score": 0.873753810651339,
            "fpr": 0.10197368421052631,
            "logloss": 0.4643190175685531,
            "mae": 0.29102815055950104,
            "precision": 0.8070539419087137,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8704905599686583,
            "auditor_fn_violation": 0.015372398813555363,
            "auditor_fp_violation": 0.009326672491169904,
            "ave_precision_score": 0.8707289612888006,
            "fpr": 0.10208562019758508,
            "logloss": 0.458500122587385,
            "mae": 0.29437900547236695,
            "precision": 0.802547770700637,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7272031168170978,
            "auditor_fn_violation": 0.02138157894736843,
            "auditor_fp_violation": 0.00862846368257092,
            "ave_precision_score": 0.6988486214210416,
            "fpr": 0.12171052631578948,
            "logloss": 2.8899080900079115,
            "mae": 0.3864181859178747,
            "precision": 0.6855524079320113,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7286744905100088,
            "auditor_fn_violation": 0.018520681037905513,
            "auditor_fp_violation": 0.007616658079258051,
            "ave_precision_score": 0.7068592467123174,
            "fpr": 0.1141602634467618,
            "logloss": 2.500039256890346,
            "mae": 0.3786806609133405,
            "precision": 0.6867469879518072,
            "recall": 0.4851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8083398735180022,
            "auditor_fn_violation": 0.007177033492822963,
            "auditor_fp_violation": 0.00996833497294639,
            "ave_precision_score": 0.7769371759919093,
            "fpr": 0.12390350877192982,
            "logloss": 2.193309953813292,
            "mae": 0.2510418856688989,
            "precision": 0.7717171717171717,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8126227747483109,
            "auditor_fn_violation": 0.01973982296751291,
            "auditor_fp_violation": 0.02110262326665024,
            "ave_precision_score": 0.7904043847354723,
            "fpr": 0.11855104281009879,
            "logloss": 1.741009270783575,
            "mae": 0.25192047892544234,
            "precision": 0.7721518987341772,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8000442569651842,
            "auditor_fn_violation": 0.007451156299840516,
            "auditor_fp_violation": 0.012742867683226767,
            "ave_precision_score": 0.7659653452798756,
            "fpr": 0.1425438596491228,
            "logloss": 2.3264922725726755,
            "mae": 0.2794263276772925,
            "precision": 0.7475728155339806,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7985922102420007,
            "auditor_fn_violation": 0.01644206740313427,
            "auditor_fp_violation": 0.02371120420359875,
            "ave_precision_score": 0.7722293301209945,
            "fpr": 0.14050493962678376,
            "logloss": 1.9194982769309132,
            "mae": 0.2854757998893896,
            "precision": 0.7429718875502008,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8170943266823628,
            "auditor_fn_violation": 0.004082390894591851,
            "auditor_fp_violation": 0.009891478111165768,
            "ave_precision_score": 0.8179157453552899,
            "fpr": 0.13706140350877194,
            "logloss": 0.8871888879317406,
            "mae": 0.27043855709633724,
            "precision": 0.7514910536779325,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8311604846377942,
            "auditor_fn_violation": 0.013865987808580704,
            "auditor_fp_violation": 0.02274045366408547,
            "ave_precision_score": 0.8313896657931313,
            "fpr": 0.1394072447859495,
            "logloss": 0.8192524138951242,
            "mae": 0.2767320894081334,
            "precision": 0.7397540983606558,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7936294795232672,
            "auditor_fn_violation": 0.004431274467159643,
            "auditor_fp_violation": 0.009412403672733233,
            "ave_precision_score": 0.7638998966834464,
            "fpr": 0.10307017543859649,
            "logloss": 2.1974867958692674,
            "mae": 0.27933776692605117,
            "precision": 0.7767220902612827,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7988552989131456,
            "auditor_fn_violation": 0.017072658056379485,
            "auditor_fp_violation": 0.018103253009948948,
            "ave_precision_score": 0.77691645795213,
            "fpr": 0.09989023051591657,
            "logloss": 1.7730553893543175,
            "mae": 0.29292259147587774,
            "precision": 0.7642487046632125,
            "recall": 0.6276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7861189847269087,
            "auditor_fn_violation": 0.0025463969841960326,
            "auditor_fp_violation": 0.0019470404984423676,
            "ave_precision_score": 0.756463594935382,
            "fpr": 0.10526315789473684,
            "logloss": 2.2229802401930594,
            "mae": 0.2944072698400576,
            "precision": 0.7669902912621359,
            "recall": 0.6528925619834711
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7922477016038916,
            "auditor_fn_violation": 0.015307004227292906,
            "auditor_fp_violation": 0.010416900020161742,
            "ave_precision_score": 0.7703945641907506,
            "fpr": 0.10537870472008781,
            "logloss": 1.799379658333168,
            "mae": 0.305629453877797,
            "precision": 0.7453580901856764,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 21353,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5050374886548177,
            "auditor_fn_violation": 0.01985011599246049,
            "auditor_fp_violation": 0.024217597147073295,
            "ave_precision_score": 0.4818171782601821,
            "fpr": 0.21162280701754385,
            "logloss": 6.169480714895016,
            "mae": 0.5370400389186012,
            "precision": 0.48118279569892475,
            "recall": 0.36983471074380164
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5021111721180983,
            "auditor_fn_violation": 0.006443702267790839,
            "auditor_fp_violation": 0.026755378331354503,
            "ave_precision_score": 0.47809452170417754,
            "fpr": 0.20197585071350166,
            "logloss": 5.982010721427651,
            "mae": 0.5273626919860894,
            "precision": 0.47875354107648727,
            "recall": 0.3595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8254431147757393,
            "auditor_fn_violation": 0.0384768740031898,
            "auditor_fp_violation": 0.013380779636005905,
            "ave_precision_score": 0.8261054794231322,
            "fpr": 0.06030701754385965,
            "logloss": 0.7632693339412254,
            "mae": 0.33734978347811195,
            "precision": 0.84593837535014,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.829303923568775,
            "auditor_fn_violation": 0.05084429081906721,
            "auditor_fp_violation": 0.017309228850706033,
            "ave_precision_score": 0.8295745381537453,
            "fpr": 0.052689352360043906,
            "logloss": 0.6961982434312353,
            "mae": 0.3357858632518356,
            "precision": 0.8549848942598187,
            "recall": 0.6021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8173045781713699,
            "auditor_fn_violation": 0.0029632448890822096,
            "auditor_fp_violation": 0.010726656009181839,
            "ave_precision_score": 0.8178885319645215,
            "fpr": 0.13267543859649122,
            "logloss": 0.8657003858726877,
            "mae": 0.2706523419666293,
            "precision": 0.7565392354124748,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8296808570197505,
            "auditor_fn_violation": 0.017264170773290982,
            "auditor_fp_violation": 0.026909702776097638,
            "ave_precision_score": 0.8299165247735621,
            "fpr": 0.12952799121844127,
            "logloss": 0.8094863307934398,
            "mae": 0.27794056359635505,
            "precision": 0.7494692144373672,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 21353,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7903428098467874,
            "auditor_fn_violation": 0.012682144410613314,
            "auditor_fp_violation": 0.02029021151008363,
            "ave_precision_score": 0.7603534196874179,
            "fpr": 0.14912280701754385,
            "logloss": 2.1803585331841147,
            "mae": 0.28058091795291384,
            "precision": 0.7394636015325671,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7996341642963937,
            "auditor_fn_violation": 0.023892379195179482,
            "auditor_fp_violation": 0.03010820134859653,
            "ave_precision_score": 0.7776114219666301,
            "fpr": 0.13830954994511527,
            "logloss": 1.7008182999825987,
            "mae": 0.2799165644352549,
            "precision": 0.7459677419354839,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7913615196106873,
            "auditor_fn_violation": 0.013753715383500073,
            "auditor_fp_violation": 0.014461899491719953,
            "ave_precision_score": 0.7609033037152323,
            "fpr": 0.14583333333333334,
            "logloss": 2.239342964094422,
            "mae": 0.28530945940950436,
            "precision": 0.7412451361867705,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7983320136697059,
            "auditor_fn_violation": 0.02719714132237196,
            "auditor_fp_violation": 0.026591097470821484,
            "ave_precision_score": 0.7761379108041239,
            "fpr": 0.13721185510428102,
            "logloss": 1.7590384010375708,
            "mae": 0.28279172453593676,
            "precision": 0.7438524590163934,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8094038174398812,
            "auditor_fn_violation": 0.0035794548354357,
            "auditor_fp_violation": 0.010022134776192822,
            "ave_precision_score": 0.8100921480385559,
            "fpr": 0.13157894736842105,
            "logloss": 0.9198892300762883,
            "mae": 0.2742279431167818,
            "precision": 0.7560975609756098,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8241205003693577,
            "auditor_fn_violation": 0.014372795852114815,
            "auditor_fp_violation": 0.021904114737735562,
            "ave_precision_score": 0.8243665603557995,
            "fpr": 0.132821075740944,
            "logloss": 0.8547522623191967,
            "mae": 0.28072489925217603,
            "precision": 0.7452631578947368,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7875791744579919,
            "auditor_fn_violation": 0.0164360410323329,
            "auditor_fp_violation": 0.02511682242990655,
            "ave_precision_score": 0.7543796663716852,
            "fpr": 0.1875,
            "logloss": 2.394795195854393,
            "mae": 0.3089053924072926,
            "precision": 0.703125,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7871405538023684,
            "auditor_fn_violation": 0.02416329962398113,
            "auditor_fp_violation": 0.038225169321296035,
            "ave_precision_score": 0.7623867899722645,
            "fpr": 0.18551042810098792,
            "logloss": 1.9501456162860737,
            "mae": 0.31496409795699415,
            "precision": 0.696588868940754,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7881362183163312,
            "auditor_fn_violation": 0.02152203856749312,
            "auditor_fp_violation": 0.026715445154943434,
            "ave_precision_score": 0.7578684186110402,
            "fpr": 0.1600877192982456,
            "logloss": 2.187873258219776,
            "mae": 0.29108100685723975,
            "precision": 0.7296296296296296,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7900308073195403,
            "auditor_fn_violation": 0.03463577550972744,
            "auditor_fp_violation": 0.03900923706474907,
            "ave_precision_score": 0.767910998901275,
            "fpr": 0.16245883644346873,
            "logloss": 1.7915750961774957,
            "mae": 0.29540362947188015,
            "precision": 0.7148362235067437,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6758699150457123,
            "auditor_fn_violation": 0.027443997390169644,
            "auditor_fp_violation": 0.0222987374979505,
            "ave_precision_score": 0.6731637778801431,
            "fpr": 0.20614035087719298,
            "logloss": 1.9034804077205825,
            "mae": 0.36557182599371063,
            "precision": 0.670753064798599,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.693677028875846,
            "auditor_fn_violation": 0.025396454679216203,
            "auditor_fp_violation": 0.0306159785538804,
            "ave_precision_score": 0.689337196695982,
            "fpr": 0.1964873765093304,
            "logloss": 1.687503591989952,
            "mae": 0.35395831161626273,
            "precision": 0.6751361161524501,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.796125012294846,
            "auditor_fn_violation": 0.002421795708278965,
            "auditor_fp_violation": 0.010936731431382199,
            "ave_precision_score": 0.7968566725938615,
            "fpr": 0.14583333333333334,
            "logloss": 0.9156949959168206,
            "mae": 0.28344549191506385,
            "precision": 0.7361111111111112,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8099283933705624,
            "auditor_fn_violation": 0.01731555223392578,
            "auditor_fp_violation": 0.0253141871457694,
            "ave_precision_score": 0.8102124910342643,
            "fpr": 0.141602634467618,
            "logloss": 0.863250801226329,
            "mae": 0.2913802339214479,
            "precision": 0.7318087318087318,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7786022361846421,
            "auditor_fn_violation": 0.01105100043497173,
            "auditor_fp_violation": 0.003151131333005415,
            "ave_precision_score": 0.7489472328481805,
            "fpr": 0.09539473684210527,
            "logloss": 2.7096881419380323,
            "mae": 0.3390316162476246,
            "precision": 0.7448680351906158,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7852133101729218,
            "auditor_fn_violation": 0.01386832332951866,
            "auditor_fp_violation": 0.006347215066048375,
            "ave_precision_score": 0.7633664757167236,
            "fpr": 0.0801317233809001,
            "logloss": 2.295482097487702,
            "mae": 0.3398916045464937,
            "precision": 0.760655737704918,
            "recall": 0.49361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.817999997329334,
            "auditor_fn_violation": 0.00456267217630854,
            "auditor_fp_violation": 0.00845937858665355,
            "ave_precision_score": 0.8189589752069386,
            "fpr": 0.13267543859649122,
            "logloss": 0.8877422174855047,
            "mae": 0.2699647753411062,
            "precision": 0.7575150300601202,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8321780118517853,
            "auditor_fn_violation": 0.014391480019618376,
            "auditor_fp_violation": 0.025232046715502887,
            "ave_precision_score": 0.8324069032008297,
            "fpr": 0.13611416026344675,
            "logloss": 0.8155214671610241,
            "mae": 0.2758381707232751,
            "precision": 0.7453798767967146,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.7385024607210471,
            "auditor_fn_violation": 0.003987240829346106,
            "auditor_fp_violation": 0.002838580095097558,
            "ave_precision_score": 0.7396008479195075,
            "fpr": 0.017543859649122806,
            "logloss": 3.228438800141103,
            "mae": 0.525763246847054,
            "precision": 0.5428571428571428,
            "recall": 0.03925619834710744
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.7409960991154569,
            "auditor_fn_violation": 0.006119064857416459,
            "auditor_fp_violation": 0.006777830048960674,
            "ave_precision_score": 0.7420956426496371,
            "fpr": 0.015367727771679473,
            "logloss": 3.147946305136977,
            "mae": 0.510071016752909,
            "precision": 0.5625,
            "recall": 0.03829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 21353,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8213129087720262,
            "auditor_fn_violation": 0.007344678845875022,
            "auditor_fp_violation": 0.012512297097884909,
            "ave_precision_score": 0.82188122234141,
            "fpr": 0.15350877192982457,
            "logloss": 0.8158136938930236,
            "mae": 0.2711193734929773,
            "precision": 0.7358490566037735,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8340885079614846,
            "auditor_fn_violation": 0.012728589111801386,
            "auditor_fp_violation": 0.028286177259048518,
            "ave_precision_score": 0.8343145975973333,
            "fpr": 0.15148188803512624,
            "logloss": 0.7597947218686789,
            "mae": 0.27630146044567033,
            "precision": 0.7335907335907336,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8152749951905373,
            "auditor_fn_violation": 0.0020072132811367266,
            "auditor_fp_violation": 0.007260411542875883,
            "ave_precision_score": 0.8160445278143291,
            "fpr": 0.12938596491228072,
            "logloss": 0.8999448830647204,
            "mae": 0.2713081459859719,
            "precision": 0.7596741344195519,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8294027135114561,
            "auditor_fn_violation": 0.016640586682859622,
            "auditor_fp_violation": 0.02082135452058614,
            "ave_precision_score": 0.8296384153520941,
            "fpr": 0.12294182217343579,
            "logloss": 0.8258852660201428,
            "mae": 0.2776608699219132,
            "precision": 0.7580993520518359,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7212259756846222,
            "auditor_fn_violation": 0.02666693852399594,
            "auditor_fp_violation": 0.040003996556812596,
            "ave_precision_score": 0.7113051533483781,
            "fpr": 0.24671052631578946,
            "logloss": 1.7961750235841663,
            "mae": 0.35162303194206906,
            "precision": 0.6462264150943396,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7230492802711379,
            "auditor_fn_violation": 0.021711002639138666,
            "auditor_fp_violation": 0.03234341669342456,
            "ave_precision_score": 0.7199175623326043,
            "fpr": 0.2579582875960483,
            "logloss": 1.475748612873419,
            "mae": 0.36689310736744124,
            "precision": 0.6322378716744914,
            "recall": 0.8595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.744296423128241,
            "auditor_fn_violation": 0.014179625199362039,
            "auditor_fp_violation": 0.019844441711756027,
            "ave_precision_score": 0.7413879332587583,
            "fpr": 0.16557017543859648,
            "logloss": 4.401045609254562,
            "mae": 0.32975956394092887,
            "precision": 0.6955645161290323,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7495712961939798,
            "auditor_fn_violation": 0.028785295560174697,
            "auditor_fp_violation": 0.024256317968094663,
            "ave_precision_score": 0.748021136351783,
            "fpr": 0.17233809001097694,
            "logloss": 4.611842456804896,
            "mae": 0.35243151258757693,
            "precision": 0.6742738589211619,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 21353,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7930095870653547,
            "auditor_fn_violation": 0.008273524720893146,
            "auditor_fp_violation": 0.014364547466797842,
            "ave_precision_score": 0.763292713224767,
            "fpr": 0.15460526315789475,
            "logloss": 2.084352363398648,
            "mae": 0.2717261813024954,
            "precision": 0.7379182156133829,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7967137114825467,
            "auditor_fn_violation": 0.016780717939136325,
            "auditor_fp_violation": 0.02507274406286482,
            "ave_precision_score": 0.7748619395309413,
            "fpr": 0.145993413830955,
            "logloss": 1.6821783344645558,
            "mae": 0.27791510321226476,
            "precision": 0.7412451361867705,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6249246259186503,
            "auditor_fn_violation": 0.0012890568363056402,
            "auditor_fp_violation": 0.02319540088539105,
            "ave_precision_score": 0.6005542130377417,
            "fpr": 0.3267543859649123,
            "logloss": 3.3048115562842604,
            "mae": 0.4191950725334321,
            "precision": 0.5832167832167832,
            "recall": 0.8615702479338843
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.619380370556959,
            "auditor_fn_violation": 0.010855501319569333,
            "auditor_fp_violation": 0.017876744550729184,
            "ave_precision_score": 0.5899337605320933,
            "fpr": 0.3380900109769484,
            "logloss": 3.3805876553205714,
            "mae": 0.43628895200142875,
            "precision": 0.5625,
            "recall": 0.8425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.68228383868592,
            "auditor_fn_violation": 0.021861860229085112,
            "auditor_fp_violation": 0.03513895720609936,
            "ave_precision_score": 0.665479865897377,
            "fpr": 0.29385964912280704,
            "logloss": 2.4938362878407307,
            "mae": 0.37074002319169724,
            "precision": 0.6115942028985507,
            "recall": 0.871900826446281
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6711247097845606,
            "auditor_fn_violation": 0.023612116682626062,
            "auditor_fp_violation": 0.03282630285923371,
            "ave_precision_score": 0.6547379270621323,
            "fpr": 0.2996706915477497,
            "logloss": 2.390278102493661,
            "mae": 0.3808546523158114,
            "precision": 0.6049204052098408,
            "recall": 0.8893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7255897011314331,
            "auditor_fn_violation": 0.017351294040887342,
            "auditor_fp_violation": 0.007619076897852105,
            "ave_precision_score": 0.7000442716401681,
            "fpr": 0.09868421052631579,
            "logloss": 3.1085069641491256,
            "mae": 0.3872784226586228,
            "precision": 0.7106109324758842,
            "recall": 0.45661157024793386
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7255707658489947,
            "auditor_fn_violation": 0.01859074666604386,
            "auditor_fp_violation": 0.005934023810768363,
            "ave_precision_score": 0.7045794080919188,
            "fpr": 0.09110867178924259,
            "logloss": 2.7742741162316995,
            "mae": 0.37741542694858343,
            "precision": 0.7147766323024055,
            "recall": 0.4425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 21353,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.795295985474767,
            "auditor_fn_violation": 0.003978178918370314,
            "auditor_fp_violation": 0.003350959173635022,
            "ave_precision_score": 0.7960254257638587,
            "fpr": 0.013157894736842105,
            "logloss": 2.1570284234946535,
            "mae": 0.4344719342206263,
            "precision": 0.883495145631068,
            "recall": 0.18801652892561985
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.8161384227862041,
            "auditor_fn_violation": 0.012462339724875647,
            "auditor_fp_violation": 0.0018120676737581236,
            "ave_precision_score": 0.8164153026766541,
            "fpr": 0.007683863885839737,
            "logloss": 2.1687300500503346,
            "mae": 0.4224156428261241,
            "precision": 0.9230769230769231,
            "recall": 0.17872340425531916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7817349669806539,
            "auditor_fn_violation": 0.008778726257793246,
            "auditor_fp_violation": 0.014213395638629292,
            "ave_precision_score": 0.7519655086357965,
            "fpr": 0.17105263157894737,
            "logloss": 2.2027730470074194,
            "mae": 0.29988633651743857,
            "precision": 0.7209302325581395,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7880035927950731,
            "auditor_fn_violation": 0.01439848658243221,
            "auditor_fp_violation": 0.03484994436852677,
            "ave_precision_score": 0.7661206340682103,
            "fpr": 0.1800219538968167,
            "logloss": 1.735889625431577,
            "mae": 0.3070333839944154,
            "precision": 0.7012750455373407,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7649748523880205,
            "auditor_fn_violation": 0.016175511091779043,
            "auditor_fp_violation": 0.025744486801114942,
            "ave_precision_score": 0.7623288899217215,
            "fpr": 0.15899122807017543,
            "logloss": 4.375638064683632,
            "mae": 0.32165420702622854,
            "precision": 0.702258726899384,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7649739823828975,
            "auditor_fn_violation": 0.03161828245790224,
            "auditor_fp_violation": 0.033869237413223625,
            "ave_precision_score": 0.7634503724646156,
            "fpr": 0.15697036223929747,
            "logloss": 4.581740608983684,
            "mae": 0.3405080892411488,
            "precision": 0.6937901498929336,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7885409379741586,
            "auditor_fn_violation": 0.009320175438596496,
            "auditor_fp_violation": 0.018443084931956063,
            "ave_precision_score": 0.7589316527722164,
            "fpr": 0.15021929824561403,
            "logloss": 2.1139711753595467,
            "mae": 0.2826856101233524,
            "precision": 0.7395437262357415,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7956914591693043,
            "auditor_fn_violation": 0.02424270733587127,
            "auditor_fp_violation": 0.02969003188542157,
            "ave_precision_score": 0.7736864301646644,
            "fpr": 0.145993413830955,
            "logloss": 1.6971641009236638,
            "mae": 0.28723969363337065,
            "precision": 0.7329317269076305,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7842452812097163,
            "auditor_fn_violation": 0.010971708713933595,
            "auditor_fp_violation": 0.014318433349729468,
            "ave_precision_score": 0.7544538829369962,
            "fpr": 0.17214912280701755,
            "logloss": 2.1571402246866693,
            "mae": 0.2947838277190417,
            "precision": 0.7196428571428571,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.788565173197079,
            "auditor_fn_violation": 0.013410561225681392,
            "auditor_fp_violation": 0.03814302889102954,
            "ave_precision_score": 0.7666669783109321,
            "fpr": 0.1800219538968167,
            "logloss": 1.736245628262632,
            "mae": 0.30274978896059135,
            "precision": 0.7018181818181818,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 21353,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.818788429856562,
            "auditor_fn_violation": 0.00532840365376251,
            "auditor_fp_violation": 0.006322757829152327,
            "ave_precision_score": 0.8195644876294514,
            "fpr": 0.12719298245614036,
            "logloss": 0.8844424577654308,
            "mae": 0.26931303008749,
            "precision": 0.7622950819672131,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8329068011184892,
            "auditor_fn_violation": 0.01812364247845483,
            "auditor_fp_violation": 0.019810778317913336,
            "ave_precision_score": 0.8331306825741932,
            "fpr": 0.12184412733260154,
            "logloss": 0.8146949949209248,
            "mae": 0.27556917271001746,
            "precision": 0.7592190889370932,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8186469365026606,
            "auditor_fn_violation": 0.0066922212556183875,
            "auditor_fp_violation": 0.014259509755697666,
            "ave_precision_score": 0.8194756184146272,
            "fpr": 0.13815789473684212,
            "logloss": 0.8535729193442207,
            "mae": 0.2715613541107178,
            "precision": 0.7504950495049505,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8297670906018665,
            "auditor_fn_violation": 0.020603965714552634,
            "auditor_fp_violation": 0.028149276541937676,
            "ave_precision_score": 0.8300014990603702,
            "fpr": 0.1394072447859495,
            "logloss": 0.800153678869678,
            "mae": 0.2775919678207466,
            "precision": 0.7381443298969073,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8421359135081098,
            "auditor_fn_violation": 0.0062617804842685235,
            "auditor_fp_violation": 0.024256025577963608,
            "ave_precision_score": 0.8425627954546249,
            "fpr": 0.3991228070175439,
            "logloss": 1.0946353969968878,
            "mae": 0.3879965067347879,
            "precision": 0.5625,
            "recall": 0.9669421487603306
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.8578900672402316,
            "auditor_fn_violation": 0.004180582478921924,
            "auditor_fp_violation": 0.030526370811771484,
            "ave_precision_score": 0.8580951623452057,
            "fpr": 0.38419319429198684,
            "logloss": 1.0641010120541003,
            "mae": 0.3796510170776712,
            "precision": 0.5679012345679012,
            "recall": 0.9787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.5910277895819274,
            "auditor_fn_violation": 0.023234739741916775,
            "auditor_fp_violation": 0.025052775045089355,
            "ave_precision_score": 0.5512672068362638,
            "fpr": 0.35635964912280704,
            "logloss": 4.847209058931651,
            "mae": 0.4136916273335457,
            "precision": 0.577373211963589,
            "recall": 0.9173553719008265
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.5896919595468018,
            "auditor_fn_violation": 0.015318681831982626,
            "auditor_fp_violation": 0.033535697484262654,
            "ave_precision_score": 0.5469079812161801,
            "fpr": 0.3556531284302964,
            "logloss": 4.722436483357926,
            "mae": 0.41379014601154174,
            "precision": 0.571994715984148,
            "recall": 0.9212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8228874605561374,
            "auditor_fn_violation": 0.00801979121357112,
            "auditor_fp_violation": 0.016616453516969998,
            "ave_precision_score": 0.8234947414001967,
            "fpr": 0.13486842105263158,
            "logloss": 0.8324790797471731,
            "mae": 0.26934261866232917,
            "precision": 0.7505070993914807,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8364648285173515,
            "auditor_fn_violation": 0.016638251161921667,
            "auditor_fp_violation": 0.025219601195765544,
            "ave_precision_score": 0.8366929367597471,
            "fpr": 0.12733260153677278,
            "logloss": 0.7816226397273666,
            "mae": 0.27292688935495013,
            "precision": 0.7542372881355932,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7481128381131444,
            "auditor_fn_violation": 0.04266800782949109,
            "auditor_fp_violation": 0.05748893261190359,
            "ave_precision_score": 0.7471754062429096,
            "fpr": 0.18859649122807018,
            "logloss": 2.1436061049314863,
            "mae": 0.3169835539403059,
            "precision": 0.6844036697247706,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7344946509727466,
            "auditor_fn_violation": 0.04126865497349184,
            "auditor_fp_violation": 0.04704406460718206,
            "ave_precision_score": 0.7347466103651246,
            "fpr": 0.1778265642151482,
            "logloss": 2.0101145906476634,
            "mae": 0.3239393224253302,
            "precision": 0.6746987951807228,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7907928762498394,
            "auditor_fn_violation": 0.022731803682760624,
            "auditor_fp_violation": 0.024563453025086078,
            "ave_precision_score": 0.758363540279122,
            "fpr": 0.16447368421052633,
            "logloss": 2.3546842421402547,
            "mae": 0.2924297753814572,
            "precision": 0.722735674676525,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7948430814097419,
            "auditor_fn_violation": 0.03278837844781278,
            "auditor_fp_violation": 0.029829421706479887,
            "ave_precision_score": 0.7700641555097588,
            "fpr": 0.145993413830955,
            "logloss": 1.9070362266999514,
            "mae": 0.2881709230389328,
            "precision": 0.7361111111111112,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 21353,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.820393560810274,
            "auditor_fn_violation": 0.0022926634768740024,
            "auditor_fp_violation": 0.011615633710444337,
            "ave_precision_score": 0.8208134621548456,
            "fpr": 0.12938596491228072,
            "logloss": 0.8556703222025421,
            "mae": 0.2711388611463263,
            "precision": 0.7601626016260162,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8280744530788249,
            "auditor_fn_violation": 0.01934979097087606,
            "auditor_fp_violation": 0.025232046715502887,
            "ave_precision_score": 0.828310954401771,
            "fpr": 0.13611416026344675,
            "logloss": 0.8256893238954793,
            "mae": 0.2805682461394247,
            "precision": 0.7389473684210527,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 21353,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7896251526443263,
            "auditor_fn_violation": 0.00045762650427723736,
            "auditor_fp_violation": 0.012061403508771931,
            "ave_precision_score": 0.759977505871686,
            "fpr": 0.11732456140350878,
            "logloss": 2.1172308071412353,
            "mae": 0.28306250654094856,
            "precision": 0.7663755458515283,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7940904751978763,
            "auditor_fn_violation": 0.01410187542331318,
            "auditor_fp_violation": 0.015011785907191271,
            "ave_precision_score": 0.7722442937905567,
            "fpr": 0.1141602634467618,
            "logloss": 1.6967175992477461,
            "mae": 0.2944096600848074,
            "precision": 0.750599520383693,
            "recall": 0.6659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7573469294666414,
            "auditor_fn_violation": 0.0262229048861824,
            "auditor_fp_violation": 0.03147032300377111,
            "ave_precision_score": 0.7269410241589739,
            "fpr": 0.24342105263157895,
            "logloss": 2.389859178716541,
            "mae": 0.3591570121643599,
            "precision": 0.6413570274636511,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7605154189958261,
            "auditor_fn_violation": 0.037111427703949366,
            "auditor_fp_violation": 0.03714738731204156,
            "ave_precision_score": 0.7382454390595588,
            "fpr": 0.23819978046103182,
            "logloss": 1.9808712282038663,
            "mae": 0.3590734744261496,
            "precision": 0.642504118616145,
            "recall": 0.8297872340425532
        }
    }
]