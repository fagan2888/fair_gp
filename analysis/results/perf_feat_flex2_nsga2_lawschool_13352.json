[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5234763767701547,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5257366616159208,
            "fpr": 0.4758771929824561,
            "logloss": 0.6929778768211338,
            "mae": 0.49940564404976995,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5535476195675302,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5548974786668404,
            "fpr": 0.4774972557628979,
            "logloss": 0.6908709473708396,
            "mae": 0.4982981939608912,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5234763767701547,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5257366616159209,
            "fpr": 0.4758771929824561,
            "logloss": 0.6929775935627285,
            "mae": 0.49940565346102966,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5535483575374791,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.554898954606738,
            "fpr": 0.4774972557628979,
            "logloss": 0.6908712454068462,
            "mae": 0.4982984866190428,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7193067505423874,
            "auditor_fn_violation": 0.01360750201864495,
            "auditor_fp_violation": 0.002314253375373919,
            "ave_precision_score": 0.6658801773425109,
            "fpr": 0.017543859649122806,
            "logloss": 0.9422617304873842,
            "mae": 0.4495839803692019,
            "precision": 0.9069767441860465,
            "recall": 0.3263598326359833
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7166271268946129,
            "auditor_fn_violation": 0.007333339482884264,
            "auditor_fp_violation": 0.0016124758696392755,
            "ave_precision_score": 0.6695009455734738,
            "fpr": 0.015367727771679473,
            "logloss": 0.9230481453838334,
            "mae": 0.43953257005837565,
            "precision": 0.9213483146067416,
            "recall": 0.3445378151260504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6657930200086938,
            "auditor_fn_violation": 0.036794391837333934,
            "auditor_fp_violation": 0.005298023284016494,
            "ave_precision_score": 0.6636536156240277,
            "fpr": 0.03179824561403509,
            "logloss": 0.695105946988821,
            "mae": 0.4769331599798119,
            "precision": 0.7433628318584071,
            "recall": 0.17573221757322174
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.690762147427314,
            "auditor_fn_violation": 0.03940401627171176,
            "auditor_fp_violation": 0.008877449310471,
            "ave_precision_score": 0.6925097850443114,
            "fpr": 0.024149286498353458,
            "logloss": 0.6865850203643076,
            "mae": 0.4695613376700356,
            "precision": 0.7981651376146789,
            "recall": 0.18277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6659957585355661,
            "auditor_fn_violation": 0.036794391837333934,
            "auditor_fp_violation": 0.005298023284016494,
            "ave_precision_score": 0.6639435016109874,
            "fpr": 0.03179824561403509,
            "logloss": 0.6947583241954955,
            "mae": 0.4768776531053478,
            "precision": 0.7433628318584071,
            "recall": 0.17573221757322174
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6907583425788154,
            "auditor_fn_violation": 0.03940401627171176,
            "auditor_fp_violation": 0.008877449310471,
            "ave_precision_score": 0.6925630700731868,
            "fpr": 0.024149286498353458,
            "logloss": 0.6864214952974674,
            "mae": 0.46957583407421594,
            "precision": 0.7981651376146789,
            "recall": 0.18277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6552678538796649,
            "auditor_fn_violation": 0.05894672612493579,
            "auditor_fp_violation": 0.01627051499717035,
            "ave_precision_score": 0.637351315623867,
            "fpr": 0.046052631578947366,
            "logloss": 0.695549101342313,
            "mae": 0.4769686024734064,
            "precision": 0.7358490566037735,
            "recall": 0.24476987447698745
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6818106756693271,
            "auditor_fn_violation": 0.06458642732614452,
            "auditor_fp_violation": 0.01913017146750445,
            "ave_precision_score": 0.6739278575049827,
            "fpr": 0.042810098792535674,
            "logloss": 0.6858093256761162,
            "mae": 0.4689703450712282,
            "precision": 0.7650602409638554,
            "recall": 0.2668067226890756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6325918166711604,
            "auditor_fn_violation": 0.08202350803787713,
            "auditor_fp_violation": 0.055534501576521955,
            "ave_precision_score": 0.6188576840739658,
            "fpr": 0.17434210526315788,
            "logloss": 0.7347705256561724,
            "mae": 0.4800350293762198,
            "precision": 0.636986301369863,
            "recall": 0.5836820083682008
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.675330061408352,
            "auditor_fn_violation": 0.05803023734191812,
            "auditor_fp_violation": 0.04916158825088005,
            "ave_precision_score": 0.6653753631435491,
            "fpr": 0.15148188803512624,
            "logloss": 0.702203939413714,
            "mae": 0.4660592372939729,
            "precision": 0.6980306345733042,
            "recall": 0.6701680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7311077867336321,
            "auditor_fn_violation": 0.0065560082213903,
            "auditor_fp_violation": 0.008519282076158144,
            "ave_precision_score": 0.6696994716968758,
            "fpr": 0.12828947368421054,
            "logloss": 0.6901195990498816,
            "mae": 0.48058040465407986,
            "precision": 0.7037974683544304,
            "recall": 0.5815899581589958
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7416521606934706,
            "auditor_fn_violation": 0.007259544871735742,
            "auditor_fp_violation": 0.002182772499589948,
            "ave_precision_score": 0.6767548864849509,
            "fpr": 0.12623490669593854,
            "logloss": 0.6936135281718689,
            "mae": 0.48260677030921373,
            "precision": 0.7195121951219512,
            "recall": 0.6197478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5701383403514728,
            "auditor_fn_violation": 0.01858759083902227,
            "auditor_fp_violation": 0.019726736195327027,
            "ave_precision_score": 0.5495426378782099,
            "fpr": 0.03508771929824561,
            "logloss": 0.6951632108834256,
            "mae": 0.49887338829667943,
            "precision": 0.5362318840579711,
            "recall": 0.07740585774058577
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.6340257548181765,
            "auditor_fn_violation": 0.02323146602219374,
            "auditor_fp_violation": 0.012945228812596996,
            "ave_precision_score": 0.5781521258009622,
            "fpr": 0.020856201975850714,
            "logloss": 0.6861187492189892,
            "mae": 0.49460670662763745,
            "precision": 0.7076923076923077,
            "recall": 0.09663865546218488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6627153562174292,
            "auditor_fn_violation": 0.08406050429420835,
            "auditor_fp_violation": 0.05704280863448946,
            "ave_precision_score": 0.6447946331508102,
            "fpr": 0.18201754385964913,
            "logloss": 0.6689458604956525,
            "mae": 0.4735942619378891,
            "precision": 0.6475583864118896,
            "recall": 0.6380753138075314
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6966796169369965,
            "auditor_fn_violation": 0.06385770554105287,
            "auditor_fp_violation": 0.051122298345887426,
            "ave_precision_score": 0.6842001145366017,
            "fpr": 0.16355653128430298,
            "logloss": 0.655104816716637,
            "mae": 0.46509525774462857,
            "precision": 0.6959183673469388,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5714768263193848,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.5037258596009115,
            "fpr": 0.01206140350877193,
            "logloss": 0.760173321704823,
            "mae": 0.4880764266279967,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5569534663734741,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.49662739195415917,
            "fpr": 0.01646542261251372,
            "logloss": 0.7814586066712377,
            "mae": 0.49338674461867754,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6325918166711604,
            "auditor_fn_violation": 0.08202350803787713,
            "auditor_fp_violation": 0.055534501576521955,
            "ave_precision_score": 0.6188576840739658,
            "fpr": 0.17434210526315788,
            "logloss": 0.7347705282324665,
            "mae": 0.48003502700706585,
            "precision": 0.636986301369863,
            "recall": 0.5836820083682008
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.675330061408352,
            "auditor_fn_violation": 0.05803023734191812,
            "auditor_fp_violation": 0.04916158825088005,
            "ave_precision_score": 0.6653753631435491,
            "fpr": 0.15148188803512624,
            "logloss": 0.7022039440886937,
            "mae": 0.4660592339330156,
            "precision": 0.6980306345733042,
            "recall": 0.6701680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6054778271395995,
            "auditor_fn_violation": 0.016848803494090875,
            "auditor_fp_violation": 0.012058877031287905,
            "ave_precision_score": 0.6042503859145054,
            "fpr": 0.13267543859649122,
            "logloss": 4.1899703559418535,
            "mae": 0.40671904221275645,
            "precision": 0.6620111731843575,
            "recall": 0.49581589958158995
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6173480447450893,
            "auditor_fn_violation": 0.0023983248623269363,
            "auditor_fp_violation": 0.017752375184526294,
            "ave_precision_score": 0.6138586680229372,
            "fpr": 0.12184412733260154,
            "logloss": 3.982456619791494,
            "mae": 0.3935461045475534,
            "precision": 0.6873239436619718,
            "recall": 0.5126050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.5935213485231057,
            "auditor_fn_violation": 0.019057843353152755,
            "auditor_fp_violation": 0.01398910582908886,
            "ave_precision_score": 0.5921856218681618,
            "fpr": 0.14583333333333334,
            "logloss": 4.311380270877036,
            "mae": 0.4128507494105199,
            "precision": 0.6490765171503958,
            "recall": 0.5146443514644351
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6117045892560135,
            "auditor_fn_violation": 0.0007171913770996997,
            "auditor_fp_violation": 0.01857249201963234,
            "ave_precision_score": 0.6076643257569023,
            "fpr": 0.13391877058177826,
            "logloss": 4.045998169943607,
            "mae": 0.39695719033626015,
            "precision": 0.6711590296495957,
            "recall": 0.523109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6195130215280605,
            "auditor_fn_violation": 0.0014153453717977024,
            "auditor_fp_violation": 0.013405489530277303,
            "ave_precision_score": 0.5962262256522739,
            "fpr": 0.1074561403508772,
            "logloss": 0.7584193228051908,
            "mae": 0.5017343885673765,
            "precision": 0.507537688442211,
            "recall": 0.2112970711297071
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5936452346881521,
            "auditor_fn_violation": 0.007328727319687506,
            "auditor_fp_violation": 0.01795425009778317,
            "ave_precision_score": 0.5759798986192076,
            "fpr": 0.12294182217343579,
            "logloss": 0.779150675042559,
            "mae": 0.5084486590978474,
            "precision": 0.4666666666666667,
            "recall": 0.20588235294117646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5903574987047108,
            "auditor_fn_violation": 0.07424943110915365,
            "auditor_fp_violation": 0.05680026679602232,
            "ave_precision_score": 0.5759976055526325,
            "fpr": 0.1425438596491228,
            "logloss": 0.6803711558871192,
            "mae": 0.488645670085884,
            "precision": 0.6072507552870091,
            "recall": 0.4205020920502092
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6161809776213217,
            "auditor_fn_violation": 0.0754596020625594,
            "auditor_fp_violation": 0.043440957896463406,
            "ave_precision_score": 0.5979128070023357,
            "fpr": 0.13721185510428102,
            "logloss": 0.6799675618470677,
            "mae": 0.4884608359813167,
            "precision": 0.6165644171779141,
            "recall": 0.4222689075630252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 13352,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6639157622835282,
            "auditor_fn_violation": 0.055063128532628645,
            "auditor_fp_violation": 0.053399628102514356,
            "ave_precision_score": 0.6595216885971255,
            "fpr": 0.21710526315789475,
            "logloss": 0.6413084578933408,
            "mae": 0.44382183482511,
            "precision": 0.623574144486692,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7236250978046751,
            "auditor_fn_violation": 0.05265476113606804,
            "auditor_fp_violation": 0.05064789229973378,
            "ave_precision_score": 0.711431626062907,
            "fpr": 0.1800219538968167,
            "logloss": 0.6079656443917663,
            "mae": 0.42352703216262255,
            "precision": 0.6864244741873805,
            "recall": 0.7542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5234763767701547,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5257366616159209,
            "fpr": 0.4758771929824561,
            "logloss": 0.6929808056946616,
            "mae": 0.49940605788377296,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5535483575374791,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.554898954606738,
            "fpr": 0.4774972557628979,
            "logloss": 0.6908696584556429,
            "mae": 0.4982963075491259,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7382134213080453,
            "auditor_fn_violation": 0.016796043455920135,
            "auditor_fp_violation": 0.02093439243269464,
            "ave_precision_score": 0.6633864898707431,
            "fpr": 0.14692982456140352,
            "logloss": 0.6658788420018525,
            "mae": 0.4304599650857741,
            "precision": 0.6954545454545454,
            "recall": 0.6401673640167364
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7650441286165306,
            "auditor_fn_violation": 0.007614681437887996,
            "auditor_fp_violation": 0.01466621244811184,
            "ave_precision_score": 0.6917119696276451,
            "fpr": 0.13391877058177826,
            "logloss": 0.6404018475582778,
            "mae": 0.4201966619321465,
            "precision": 0.7227272727272728,
            "recall": 0.6680672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5716456523481696,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.5052812185536235,
            "fpr": 0.01206140350877193,
            "logloss": 0.7541290960787905,
            "mae": 0.4849392710367969,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5574753877707099,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.4977455978523861,
            "fpr": 0.01646542261251372,
            "logloss": 0.7738745462790946,
            "mae": 0.48987208031175167,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.658761958631347,
            "auditor_fn_violation": 0.08406050429420835,
            "auditor_fp_violation": 0.05704280863448946,
            "ave_precision_score": 0.6435365059749967,
            "fpr": 0.18201754385964913,
            "logloss": 0.6685530087785205,
            "mae": 0.4735265599334972,
            "precision": 0.6475583864118896,
            "recall": 0.6380753138075314
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.682078686901706,
            "auditor_fn_violation": 0.06385770554105287,
            "auditor_fp_violation": 0.051122298345887426,
            "ave_precision_score": 0.6762865269496278,
            "fpr": 0.16355653128430298,
            "logloss": 0.6558566517644382,
            "mae": 0.4650344001166967,
            "precision": 0.6959183673469388,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5694163817694167,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.50211787696838,
            "fpr": 0.01206140350877193,
            "logloss": 0.769624164998365,
            "mae": 0.49462505588471367,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5566914131740183,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.4963085035303829,
            "fpr": 0.01646542261251372,
            "logloss": 0.7791214176580025,
            "mae": 0.5018143604471708,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5212512371543478,
            "auditor_fn_violation": 0.0151490126991118,
            "auditor_fp_violation": 0.008665817770232039,
            "ave_precision_score": 0.5234296196874718,
            "fpr": 0.42214912280701755,
            "logloss": 0.6933412212664477,
            "mae": 0.4996977586037757,
            "precision": 0.5199501246882793,
            "recall": 0.8723849372384938
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5543863784566176,
            "auditor_fn_violation": 0.004326209078582036,
            "auditor_fp_violation": 0.013374213003267849,
            "ave_precision_score": 0.5556718758639823,
            "fpr": 0.41712403951701427,
            "logloss": 0.6909926446941974,
            "mae": 0.4984695313071053,
            "precision": 0.5291201982651796,
            "recall": 0.8970588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6325918166711604,
            "auditor_fn_violation": 0.08202350803787713,
            "auditor_fp_violation": 0.055534501576521955,
            "ave_precision_score": 0.6188576840739658,
            "fpr": 0.17434210526315788,
            "logloss": 0.7347705309024517,
            "mae": 0.48003502960496564,
            "precision": 0.636986301369863,
            "recall": 0.5836820083682008
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.675330061408352,
            "auditor_fn_violation": 0.05803023734191812,
            "auditor_fp_violation": 0.04916158825088005,
            "ave_precision_score": 0.6653753631435491,
            "fpr": 0.15148188803512624,
            "logloss": 0.7022039476647295,
            "mae": 0.46605923625029233,
            "precision": 0.6980306345733042,
            "recall": 0.6701680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5527723734695397,
            "auditor_fn_violation": 0.05815991338178082,
            "auditor_fp_violation": 0.04672467458970005,
            "ave_precision_score": 0.5628899767267116,
            "fpr": 0.3048245614035088,
            "logloss": 0.6995830239467947,
            "mae": 0.4826899258166617,
            "precision": 0.5628930817610063,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.604332107209444,
            "auditor_fn_violation": 0.040291857687092404,
            "auditor_fp_violation": 0.046118323933532705,
            "ave_precision_score": 0.6149698328134873,
            "fpr": 0.28869374313940727,
            "logloss": 0.6741749610927777,
            "mae": 0.46973962424594895,
            "precision": 0.5935085007727975,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7394931085239346,
            "auditor_fn_violation": 0.016796043455920135,
            "auditor_fp_violation": 0.02262207939202847,
            "ave_precision_score": 0.6645149972085311,
            "fpr": 0.14912280701754385,
            "logloss": 0.6531347018742174,
            "mae": 0.46897500652100954,
            "precision": 0.6923076923076923,
            "recall": 0.6401673640167364
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7651654535105311,
            "auditor_fn_violation": 0.006115728398933681,
            "auditor_fp_violation": 0.01466621244811184,
            "ave_precision_score": 0.6911857896367228,
            "fpr": 0.13391877058177826,
            "logloss": 0.6435439630957777,
            "mae": 0.46437678192501924,
            "precision": 0.7258426966292135,
            "recall": 0.6785714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.47445112812304213,
            "auditor_fn_violation": 0.014644351464435146,
            "auditor_fp_violation": 0.007736074056108029,
            "ave_precision_score": 0.4629918742000988,
            "fpr": 0.26644736842105265,
            "logloss": 7.644792110647727,
            "mae": 0.5087967983698041,
            "precision": 0.5290697674418605,
            "recall": 0.5711297071129707
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.4730253424776816,
            "auditor_fn_violation": 0.009445710227010674,
            "auditor_fp_violation": 0.014194329838373902,
            "ave_precision_score": 0.4625777470221808,
            "fpr": 0.26344676180021953,
            "logloss": 7.379128512820679,
            "mae": 0.5081986128739271,
            "precision": 0.5228628230616302,
            "recall": 0.5525210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5695381439520341,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.503876101390668,
            "fpr": 0.01206140350877193,
            "logloss": 0.758756680285164,
            "mae": 0.4880398563272728,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5571860161229468,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.49746078010340217,
            "fpr": 0.01646542261251372,
            "logloss": 0.770442981655768,
            "mae": 0.49425500504566205,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6627153562174292,
            "auditor_fn_violation": 0.08406050429420835,
            "auditor_fp_violation": 0.05704280863448946,
            "ave_precision_score": 0.6447946331508102,
            "fpr": 0.18201754385964913,
            "logloss": 0.6689461362610887,
            "mae": 0.47359519319510773,
            "precision": 0.6475583864118896,
            "recall": 0.6380753138075314
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6966796169369965,
            "auditor_fn_violation": 0.06385770554105287,
            "auditor_fp_violation": 0.051122298345887426,
            "ave_precision_score": 0.6842001145366017,
            "fpr": 0.16355653128430298,
            "logloss": 0.6551048719368957,
            "mae": 0.46509607957367316,
            "precision": 0.6959183673469388,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6304029081258137,
            "auditor_fn_violation": 0.01929641048227263,
            "auditor_fp_violation": 0.020742380143908164,
            "ave_precision_score": 0.6318668758277539,
            "fpr": 0.09539473684210527,
            "logloss": 3.2895436805093,
            "mae": 0.40822846725823203,
            "precision": 0.7090301003344481,
            "recall": 0.4435146443514644
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6693923063800628,
            "auditor_fn_violation": 0.005359333634661341,
            "auditor_fp_violation": 0.018065281300074443,
            "ave_precision_score": 0.6699698620668801,
            "fpr": 0.0801317233809001,
            "logloss": 2.9837505336780183,
            "mae": 0.37756000390640865,
            "precision": 0.7550335570469798,
            "recall": 0.4726890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.5909475938843993,
            "auditor_fn_violation": 0.013772663877266392,
            "auditor_fp_violation": 0.012933038240763202,
            "ave_precision_score": 0.5896482982052526,
            "fpr": 0.14144736842105263,
            "logloss": 4.438826396462989,
            "mae": 0.4168727308928632,
            "precision": 0.6504065040650406,
            "recall": 0.502092050209205
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.608141927152566,
            "auditor_fn_violation": 0.007218035402964707,
            "auditor_fp_violation": 0.01602382123976432,
            "ave_precision_score": 0.6046608823136528,
            "fpr": 0.12952799121844127,
            "logloss": 4.249933689213006,
            "mae": 0.40056430180676095,
            "precision": 0.6722222222222223,
            "recall": 0.5084033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 13352,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6639157622835282,
            "auditor_fn_violation": 0.055063128532628645,
            "auditor_fp_violation": 0.053399628102514356,
            "ave_precision_score": 0.6595216885971255,
            "fpr": 0.21710526315789475,
            "logloss": 0.6436351335289873,
            "mae": 0.4455778330825923,
            "precision": 0.623574144486692,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7236250978046751,
            "auditor_fn_violation": 0.05265476113606804,
            "auditor_fp_violation": 0.05064789229973378,
            "ave_precision_score": 0.711431626062907,
            "fpr": 0.1800219538968167,
            "logloss": 0.6098080948684262,
            "mae": 0.42513705567676113,
            "precision": 0.6864244741873805,
            "recall": 0.7542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6210342698358917,
            "auditor_fn_violation": 0.012712875284445427,
            "auditor_fp_violation": 0.02249575551782683,
            "ave_precision_score": 0.6190894783973006,
            "fpr": 0.13815789473684212,
            "logloss": 3.604244984429522,
            "mae": 0.3957364572297779,
            "precision": 0.6684210526315789,
            "recall": 0.5313807531380753
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6292039845905464,
            "auditor_fn_violation": 0.009565626470127018,
            "auditor_fp_violation": 0.0173158206846083,
            "ave_precision_score": 0.626269199881487,
            "fpr": 0.12294182217343579,
            "logloss": 3.342033331585696,
            "mae": 0.3826620356086237,
            "precision": 0.6956521739130435,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7421804988128153,
            "auditor_fn_violation": 0.037138479042795276,
            "auditor_fp_violation": 0.007771444740884471,
            "ave_precision_score": 0.6931333650421446,
            "fpr": 0.019736842105263157,
            "logloss": 0.7437664789603102,
            "mae": 0.4788999579634452,
            "precision": 0.8666666666666667,
            "recall": 0.24476987447698745
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7461843031506807,
            "auditor_fn_violation": 0.03415768063537161,
            "auditor_fp_violation": 0.008720996252696922,
            "ave_precision_score": 0.6992245403755466,
            "fpr": 0.019758507135016465,
            "logloss": 0.761245492121591,
            "mae": 0.482988184160511,
            "precision": 0.8775510204081632,
            "recall": 0.2710084033613445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6308058392033808,
            "auditor_fn_violation": 0.02001211186963225,
            "auditor_fp_violation": 0.019989489853666425,
            "ave_precision_score": 0.6322725708785714,
            "fpr": 0.0668859649122807,
            "logloss": 3.36372687422612,
            "mae": 0.41367470411083523,
            "precision": 0.7489711934156379,
            "recall": 0.3807531380753138
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6728924790504826,
            "auditor_fn_violation": 0.015109446632659656,
            "auditor_fp_violation": 0.017737234566032024,
            "ave_precision_score": 0.6735503330427264,
            "fpr": 0.059275521405049394,
            "logloss": 3.02687071118797,
            "mae": 0.383101798294825,
            "precision": 0.784,
            "recall": 0.4117647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6321382135026528,
            "auditor_fn_violation": 0.018750458782940627,
            "auditor_fp_violation": 0.0252319306330342,
            "ave_precision_score": 0.6336155104492972,
            "fpr": 0.09758771929824561,
            "logloss": 3.1676286593087455,
            "mae": 0.40801697598687914,
            "precision": 0.7052980132450332,
            "recall": 0.4456066945606695
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6733277262406177,
            "auditor_fn_violation": 0.006586169045005496,
            "auditor_fp_violation": 0.022567091865702722,
            "ave_precision_score": 0.673900005851432,
            "fpr": 0.07903402854006586,
            "logloss": 2.8516378692423197,
            "mae": 0.37665267489618137,
            "precision": 0.7567567567567568,
            "recall": 0.47058823529411764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.5992667048617633,
            "auditor_fn_violation": 0.011483337003596869,
            "auditor_fp_violation": 0.015540363004284904,
            "ave_precision_score": 0.5980820083415257,
            "fpr": 0.14144736842105263,
            "logloss": 4.282696117556164,
            "mae": 0.4107593549951359,
            "precision": 0.6504065040650406,
            "recall": 0.502092050209205
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.616795217430997,
            "auditor_fn_violation": 0.003468346723980485,
            "auditor_fp_violation": 0.017598445563167923,
            "ave_precision_score": 0.6142836309716598,
            "fpr": 0.12294182217343579,
            "logloss": 4.056549713555827,
            "mae": 0.39557893472290867,
            "precision": 0.6880222841225627,
            "recall": 0.5189075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5234763767701547,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5257366616159208,
            "fpr": 0.4758771929824561,
            "logloss": 0.6929779490846854,
            "mae": 0.499405641696955,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5535483575374791,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.554898954606738,
            "fpr": 0.4774972557628979,
            "logloss": 0.6908708717754968,
            "mae": 0.49829811950415603,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.5903780108351749,
            "auditor_fn_violation": 0.013290941789620493,
            "auditor_fp_violation": 0.013125050529549693,
            "ave_precision_score": 0.5891863270947953,
            "fpr": 0.14364035087719298,
            "logloss": 4.447152234154668,
            "mae": 0.4172325737009547,
            "precision": 0.6478494623655914,
            "recall": 0.50418410041841
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6079438296142542,
            "auditor_fn_violation": 0.006620760268981352,
            "auditor_fp_violation": 0.015620071413250563,
            "ave_precision_score": 0.6044628330372208,
            "fpr": 0.13062568605927552,
            "logloss": 4.2575798251707955,
            "mae": 0.4008242785178904,
            "precision": 0.6712707182320442,
            "recall": 0.5105042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6282313524699942,
            "auditor_fn_violation": 0.019484511487924853,
            "auditor_fp_violation": 0.017271000080847282,
            "ave_precision_score": 0.6297504133487369,
            "fpr": 0.06359649122807018,
            "logloss": 3.841980028196787,
            "mae": 0.4183732126509238,
            "precision": 0.7478260869565218,
            "recall": 0.3598326359832636
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6670509386122451,
            "auditor_fn_violation": 0.013737328081616833,
            "auditor_fp_violation": 0.01530968873411812,
            "ave_precision_score": 0.6677066111747013,
            "fpr": 0.05817782656421515,
            "logloss": 3.5004411282812966,
            "mae": 0.39091372070226266,
            "precision": 0.78099173553719,
            "recall": 0.39705882352941174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.5937731239186699,
            "auditor_fn_violation": 0.011198891580415487,
            "auditor_fp_violation": 0.013870361387339323,
            "ave_precision_score": 0.5925420051435999,
            "fpr": 0.14364035087719298,
            "logloss": 4.426067321491955,
            "mae": 0.41382775893928725,
            "precision": 0.6430517711171662,
            "recall": 0.49372384937238495
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6111106348806485,
            "auditor_fn_violation": 0.0036343845990646517,
            "auditor_fp_violation": 0.014444150043529278,
            "ave_precision_score": 0.6086416850554452,
            "fpr": 0.12843029637760703,
            "logloss": 4.230119150397654,
            "mae": 0.40036855473679034,
            "precision": 0.675,
            "recall": 0.5105042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7424297414964942,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.6930149052065413,
            "fpr": 0.01206140350877193,
            "logloss": 0.7496786579892917,
            "mae": 0.4821381830495962,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.745549525555382,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.6981316901439589,
            "fpr": 0.01646542261251372,
            "logloss": 0.7706751689200053,
            "mae": 0.48654320606252366,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5701232517790034,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.5027460905755567,
            "fpr": 0.01206140350877193,
            "logloss": 0.767288817259173,
            "mae": 0.4931464042155105,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.556698086237386,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.49638370215251193,
            "fpr": 0.01646542261251372,
            "logloss": 0.7778847753094418,
            "mae": 0.5001622920551232,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.45729236466843354,
            "auditor_fn_violation": 0.009932650664317696,
            "auditor_fp_violation": 0.026389057320721165,
            "ave_precision_score": 0.45246969604959786,
            "fpr": 0.21162280701754385,
            "logloss": 7.512624182178061,
            "mae": 0.526457574117902,
            "precision": 0.5292682926829269,
            "recall": 0.45397489539748953
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.4541649857251967,
            "auditor_fn_violation": 0.008873801990609638,
            "auditor_fp_violation": 0.018678476349092196,
            "ave_precision_score": 0.45024448174838816,
            "fpr": 0.2283205268935236,
            "logloss": 7.303610220906673,
            "mae": 0.5244442340666294,
            "precision": 0.5218390804597701,
            "recall": 0.47689075630252103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.5942274176547567,
            "auditor_fn_violation": 0.009604620861777885,
            "auditor_fp_violation": 0.015297821165817778,
            "ave_precision_score": 0.5937474360538766,
            "fpr": 0.14364035087719298,
            "logloss": 4.468771023557465,
            "mae": 0.41494595151825175,
            "precision": 0.6440217391304348,
            "recall": 0.49581589958158995
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6122626296353684,
            "auditor_fn_violation": 0.005359333634661336,
            "auditor_fp_violation": 0.012435494656623388,
            "ave_precision_score": 0.6098664868077495,
            "fpr": 0.132821075740944,
            "logloss": 4.303486954749742,
            "mae": 0.40178878746661933,
            "precision": 0.6648199445983379,
            "recall": 0.5042016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.45728661082821054,
            "auditor_fn_violation": 0.009932650664317696,
            "auditor_fp_violation": 0.026389057320721165,
            "ave_precision_score": 0.4524639446389817,
            "fpr": 0.21162280701754385,
            "logloss": 7.513749696145203,
            "mae": 0.5264638804205538,
            "precision": 0.5292682926829269,
            "recall": 0.45397489539748953
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.45416867280121126,
            "auditor_fn_violation": 0.008873801990609638,
            "auditor_fp_violation": 0.018678476349092196,
            "ave_precision_score": 0.45024816832137915,
            "fpr": 0.2283205268935236,
            "logloss": 7.304906365998273,
            "mae": 0.5244445382846711,
            "precision": 0.5218390804597701,
            "recall": 0.47689075630252103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6086846703390691,
            "auditor_fn_violation": 0.01512607355208104,
            "auditor_fp_violation": 0.016043132023607413,
            "ave_precision_score": 0.6067067976726519,
            "fpr": 0.14802631578947367,
            "logloss": 3.641701074828017,
            "mae": 0.40009179135752154,
            "precision": 0.6564885496183206,
            "recall": 0.5397489539748954
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6213739251144274,
            "auditor_fn_violation": 0.009095185824055198,
            "auditor_fp_violation": 0.016273641444919693,
            "ave_precision_score": 0.6178203632879296,
            "fpr": 0.13611416026344675,
            "logloss": 3.376958647108053,
            "mae": 0.38671230816365726,
            "precision": 0.6787564766839378,
            "recall": 0.5504201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7446694758345684,
            "auditor_fn_violation": 0.055255817367687005,
            "auditor_fp_violation": 0.05079988277144475,
            "ave_precision_score": 0.7043178864002827,
            "fpr": 0.19846491228070176,
            "logloss": 0.6412761421265422,
            "mae": 0.4491651977101962,
            "precision": 0.6372745490981964,
            "recall": 0.6652719665271967
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7717208344959441,
            "auditor_fn_violation": 0.05148327168408527,
            "auditor_fp_violation": 0.05299216472992922,
            "ave_precision_score": 0.7298430705090524,
            "fpr": 0.1734357848518112,
            "logloss": 0.6159516133531735,
            "mae": 0.43374388888354326,
            "precision": 0.6871287128712872,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.5823991479973765,
            "auditor_fn_violation": 0.013008790281142192,
            "auditor_fp_violation": 0.020259822944457922,
            "ave_precision_score": 0.5810040245054767,
            "fpr": 0.14802631578947367,
            "logloss": 4.455245998072135,
            "mae": 0.41768413982532954,
            "precision": 0.6465968586387435,
            "recall": 0.5167364016736402
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6055333295637723,
            "auditor_fn_violation": 0.001438994917396158,
            "auditor_fp_violation": 0.016700102199174838,
            "ave_precision_score": 0.6017566971174517,
            "fpr": 0.141602634467618,
            "logloss": 4.128260460075021,
            "mae": 0.4017036631171968,
            "precision": 0.6569148936170213,
            "recall": 0.5189075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5527723734695397,
            "auditor_fn_violation": 0.05815991338178082,
            "auditor_fp_violation": 0.047644312393887944,
            "ave_precision_score": 0.5628899767267116,
            "fpr": 0.30153508771929827,
            "logloss": 0.6992462055627295,
            "mae": 0.48260016483663204,
            "precision": 0.5655608214849921,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.604332107209444,
            "auditor_fn_violation": 0.040291857687092404,
            "auditor_fp_violation": 0.04587607403762445,
            "ave_precision_score": 0.6149698328134873,
            "fpr": 0.2854006586169045,
            "logloss": 0.6738558735045244,
            "mae": 0.469650849711475,
            "precision": 0.5962732919254659,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.5944610376294053,
            "auditor_fn_violation": 0.020489246127871986,
            "auditor_fp_violation": 0.01338275123292102,
            "ave_precision_score": 0.593225692765829,
            "fpr": 0.13925438596491227,
            "logloss": 4.25706928912979,
            "mae": 0.4163417647903652,
            "precision": 0.6481994459833795,
            "recall": 0.4895397489539749
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6209494161170546,
            "auditor_fn_violation": 0.004856607846212031,
            "auditor_fp_violation": 0.02151481888035127,
            "ave_precision_score": 0.6179156728659158,
            "fpr": 0.12184412733260154,
            "logloss": 3.9875834847066067,
            "mae": 0.3958336568617448,
            "precision": 0.6855524079320113,
            "recall": 0.5084033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6195350468121053,
            "auditor_fn_violation": 0.007822249137488078,
            "auditor_fp_violation": 0.022435120058210047,
            "ave_precision_score": 0.6183521624789825,
            "fpr": 0.07785087719298246,
            "logloss": 3.6180635295912595,
            "mae": 0.41083705641677803,
            "precision": 0.7258687258687259,
            "recall": 0.39330543933054396
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6437206488196175,
            "auditor_fn_violation": 0.007545498989936279,
            "auditor_fp_violation": 0.021716693793608136,
            "ave_precision_score": 0.6415684273820595,
            "fpr": 0.07025246981339188,
            "logloss": 3.289684136399093,
            "mae": 0.3947225172558855,
            "precision": 0.7575757575757576,
            "recall": 0.42016806722689076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6553702588743338,
            "auditor_fn_violation": 0.05894672612493579,
            "auditor_fp_violation": 0.01627051499717035,
            "ave_precision_score": 0.6370258532817616,
            "fpr": 0.046052631578947366,
            "logloss": 0.6958222179871175,
            "mae": 0.47703438583892166,
            "precision": 0.7358490566037735,
            "recall": 0.24476987447698745
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6817852326061606,
            "auditor_fn_violation": 0.06458642732614452,
            "auditor_fp_violation": 0.01913017146750445,
            "ave_precision_score": 0.6736222544373964,
            "fpr": 0.042810098792535674,
            "logloss": 0.6859665716576219,
            "mae": 0.46899570939472635,
            "precision": 0.7650602409638554,
            "recall": 0.2668067226890756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 13352,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.45546182875366065,
            "auditor_fn_violation": 0.00855171401306614,
            "auditor_fp_violation": 0.027311221602393083,
            "ave_precision_score": 0.45066176872774927,
            "fpr": 0.21052631578947367,
            "logloss": 7.749476649297616,
            "mae": 0.529318264818007,
            "precision": 0.5247524752475248,
            "recall": 0.4435146443514644
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.45195338696128584,
            "auditor_fn_violation": 0.008859965501019284,
            "auditor_fp_violation": 0.017411711268405322,
            "ave_precision_score": 0.4480344441406085,
            "fpr": 0.2261251372118551,
            "logloss": 7.534045848266218,
            "mae": 0.5272493132406673,
            "precision": 0.5175644028103045,
            "recall": 0.4642857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6552595100993802,
            "auditor_fn_violation": 0.05894672612493579,
            "auditor_fp_violation": 0.01627051499717035,
            "ave_precision_score": 0.6373425918007813,
            "fpr": 0.046052631578947366,
            "logloss": 0.6920175815821519,
            "mae": 0.4788634012077461,
            "precision": 0.7358490566037735,
            "recall": 0.24476987447698745
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6818286008372281,
            "auditor_fn_violation": 0.06521598760250533,
            "auditor_fp_violation": 0.01913017146750445,
            "ave_precision_score": 0.6739454923184638,
            "fpr": 0.042810098792535674,
            "logloss": 0.6811795524663242,
            "mae": 0.4705036148089415,
            "precision": 0.7664670658682635,
            "recall": 0.2689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6324391681424486,
            "auditor_fn_violation": 0.024526536005285184,
            "auditor_fp_violation": 0.018807098391139143,
            "ave_precision_score": 0.6339424909682151,
            "fpr": 0.08881578947368421,
            "logloss": 3.761359479973427,
            "mae": 0.41305395319417015,
            "precision": 0.7157894736842105,
            "recall": 0.42677824267782427
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6737237003610439,
            "auditor_fn_violation": 0.013324539475504818,
            "auditor_fp_violation": 0.022440920044917174,
            "ave_precision_score": 0.6743534745709113,
            "fpr": 0.0801317233809001,
            "logloss": 3.425538266037411,
            "mae": 0.3823458296175152,
            "precision": 0.75,
            "recall": 0.46008403361344535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.5910515374430616,
            "auditor_fn_violation": 0.013290941789620493,
            "auditor_fp_violation": 0.013577289999191531,
            "ave_precision_score": 0.5897380043409219,
            "fpr": 0.1425438596491228,
            "logloss": 4.431798317362037,
            "mae": 0.4166559262312202,
            "precision": 0.6495956873315364,
            "recall": 0.50418410041841
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6081706127955229,
            "auditor_fn_violation": 0.007218035402964707,
            "auditor_fp_violation": 0.01602382123976432,
            "ave_precision_score": 0.6046894193790878,
            "fpr": 0.12952799121844127,
            "logloss": 4.2426149145712415,
            "mae": 0.40046592949755494,
            "precision": 0.6722222222222223,
            "recall": 0.5084033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6316227849535372,
            "auditor_fn_violation": 0.019085370329589672,
            "auditor_fp_violation": 0.021581170668607003,
            "ave_precision_score": 0.6331157530398046,
            "fpr": 0.10307017543859649,
            "logloss": 3.4108347547657574,
            "mae": 0.4082876863058939,
            "precision": 0.6948051948051948,
            "recall": 0.4476987447698745
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6704720430954247,
            "auditor_fn_violation": 0.00686289883681245,
            "auditor_fp_violation": 0.023387208700808768,
            "ave_precision_score": 0.6711287840974309,
            "fpr": 0.0845225027442371,
            "logloss": 3.0712006776891774,
            "mae": 0.37770626994670786,
            "precision": 0.7458745874587459,
            "recall": 0.47478991596638653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5701066398511018,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.5039175899378463,
            "fpr": 0.01206140350877193,
            "logloss": 0.7404828672118865,
            "mae": 0.48981057619675994,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5572268761582684,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.49702015759101936,
            "fpr": 0.01646542261251372,
            "logloss": 0.772568414707533,
            "mae": 0.49624946794414365,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7225656825473769,
            "auditor_fn_violation": 0.023347463847904287,
            "auditor_fp_violation": 0.02651285471743876,
            "ave_precision_score": 0.724020601042194,
            "fpr": 0.15899122807017543,
            "logloss": 1.1009264377325787,
            "mae": 0.3135650749638997,
            "precision": 0.7105788423153693,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7872478112478325,
            "auditor_fn_violation": 0.014883450636017303,
            "auditor_fp_violation": 0.022274373241480253,
            "ave_precision_score": 0.7869053423747527,
            "fpr": 0.13611416026344675,
            "logloss": 0.9118859634821443,
            "mae": 0.2762768537955375,
            "precision": 0.7494949494949495,
            "recall": 0.7794117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5234763767701547,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5257366616159209,
            "fpr": 0.4758771929824561,
            "logloss": 0.6929805568517754,
            "mae": 0.49940606239333485,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5535476195675302,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5548974786668404,
            "fpr": 0.4774972557628979,
            "logloss": 0.690869909168485,
            "mae": 0.49829655676327733,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6295946598044189,
            "auditor_fn_violation": 0.013020259854657587,
            "auditor_fp_violation": 0.024163230657288377,
            "ave_precision_score": 0.6292888052909482,
            "fpr": 0.0712719298245614,
            "logloss": 3.9629679218657587,
            "mae": 0.40988842502372125,
            "precision": 0.7410358565737052,
            "recall": 0.3891213389121339
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6610352184976072,
            "auditor_fn_violation": 0.007547805071534655,
            "auditor_fp_violation": 0.017754898620941997,
            "ave_precision_score": 0.6603229961556785,
            "fpr": 0.06147091108671789,
            "logloss": 3.6034946920686335,
            "mae": 0.3916729479459209,
            "precision": 0.7732793522267206,
            "recall": 0.4012605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6065509836464682,
            "auditor_fn_violation": 0.007122605153050001,
            "auditor_fp_violation": 0.026881720430107534,
            "ave_precision_score": 0.606086849947004,
            "fpr": 0.13815789473684212,
            "logloss": 3.394229026614984,
            "mae": 0.4016964934712265,
            "precision": 0.6692913385826772,
            "recall": 0.5334728033472803
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6392377618311387,
            "auditor_fn_violation": 0.009625584591685206,
            "auditor_fp_violation": 0.021348272076914344,
            "ave_precision_score": 0.636900524961018,
            "fpr": 0.12184412733260154,
            "logloss": 3.1375524109766673,
            "mae": 0.38487408734661704,
            "precision": 0.6925207756232687,
            "recall": 0.5252100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7446928571459366,
            "auditor_fn_violation": 0.055255817367687005,
            "auditor_fp_violation": 0.05079988277144475,
            "ave_precision_score": 0.7043402941076393,
            "fpr": 0.19846491228070176,
            "logloss": 0.6388829191560379,
            "mae": 0.4465940178355627,
            "precision": 0.6372745490981964,
            "recall": 0.6652719665271967
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7717485307002173,
            "auditor_fn_violation": 0.05148327168408527,
            "auditor_fp_violation": 0.05299216472992922,
            "ave_precision_score": 0.7306437509307455,
            "fpr": 0.1734357848518112,
            "logloss": 0.6115083243859204,
            "mae": 0.4310830740411955,
            "precision": 0.6871287128712872,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5702828965199389,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.5032424159468954,
            "fpr": 0.01206140350877193,
            "logloss": 0.7589550556889723,
            "mae": 0.4884963011565177,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.557207799260359,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.4970203107816076,
            "fpr": 0.01646542261251372,
            "logloss": 0.7702729086095732,
            "mae": 0.49464018604463594,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6278579314775128,
            "auditor_fn_violation": 0.009097665712398149,
            "auditor_fp_violation": 0.024413351928207615,
            "ave_precision_score": 0.6275810211834523,
            "fpr": 0.0800438596491228,
            "logloss": 3.805303378217593,
            "mae": 0.4059590608538826,
            "precision": 0.7402135231316725,
            "recall": 0.4351464435146444
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.661370832325963,
            "auditor_fn_violation": 0.006613842024186192,
            "auditor_fp_violation": 0.01716189106324993,
            "ave_precision_score": 0.6606570631518379,
            "fpr": 0.07244785949506037,
            "logloss": 3.439061703631124,
            "mae": 0.3860128664321014,
            "precision": 0.7564575645756457,
            "recall": 0.43067226890756305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.6218951047264691,
            "auditor_fn_violation": 0.0016195037803714482,
            "auditor_fp_violation": 0.004102999434069044,
            "ave_precision_score": 0.5929302881584273,
            "fpr": 0.015350877192982455,
            "logloss": 0.7238455568048373,
            "mae": 0.49217314728976863,
            "precision": 0.65,
            "recall": 0.05439330543933055
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6504359574334448,
            "auditor_fn_violation": 0.008191201837485838,
            "auditor_fp_violation": 0.0005803903756135107,
            "ave_precision_score": 0.6284971375964498,
            "fpr": 0.010976948408342482,
            "logloss": 0.7185826879891142,
            "mae": 0.48554153969560465,
            "precision": 0.6875,
            "recall": 0.046218487394957986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5700640133446471,
            "auditor_fn_violation": 0.03800787271526097,
            "auditor_fp_violation": 0.006391988034602636,
            "ave_precision_score": 0.5023095553263903,
            "fpr": 0.01206140350877193,
            "logloss": 0.7739294100258227,
            "mae": 0.496148163379219,
            "precision": 0.8513513513513513,
            "recall": 0.13179916317991633
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5566642816375932,
            "auditor_fn_violation": 0.03998745491610476,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.49619553547274525,
            "fpr": 0.01646542261251372,
            "logloss": 0.7846557356317532,
            "mae": 0.503508850204238,
            "precision": 0.8192771084337349,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7423929887222582,
            "auditor_fn_violation": 0.044047750128459226,
            "auditor_fp_violation": 0.007038766270514998,
            "ave_precision_score": 0.6930224727078182,
            "fpr": 0.015350877192982455,
            "logloss": 0.7472854434069774,
            "mae": 0.4796385509615535,
            "precision": 0.8461538461538461,
            "recall": 0.16108786610878661
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7456573640815856,
            "auditor_fn_violation": 0.041998358069901945,
            "auditor_fp_violation": 0.00749460615466142,
            "ave_precision_score": 0.6984241601506285,
            "fpr": 0.01646542261251372,
            "logloss": 0.7721106061553094,
            "mae": 0.4835087376535266,
            "precision": 0.8387096774193549,
            "recall": 0.1638655462184874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6289920705330119,
            "auditor_fn_violation": 0.02047548263965354,
            "auditor_fp_violation": 0.019484194356859892,
            "ave_precision_score": 0.6305010022911889,
            "fpr": 0.09868421052631579,
            "logloss": 3.8810108951379974,
            "mae": 0.41304084656159124,
            "precision": 0.6938775510204082,
            "recall": 0.42677824267782427
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6661258833322236,
            "auditor_fn_violation": 0.009378833860657325,
            "auditor_fp_violation": 0.022592326229859825,
            "ave_precision_score": 0.6667723245338967,
            "fpr": 0.08342480790340286,
            "logloss": 3.5522119204721987,
            "mae": 0.38633980328898343,
            "precision": 0.7406143344709898,
            "recall": 0.45588235294117646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5401583232226999,
            "auditor_fn_violation": 0.0016195037803714482,
            "auditor_fp_violation": 0.004102999434069044,
            "ave_precision_score": 0.5420371733810183,
            "fpr": 0.015350877192982455,
            "logloss": 0.7290875602587387,
            "mae": 0.4928449278599338,
            "precision": 0.65,
            "recall": 0.05439330543933055
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5677323104551844,
            "auditor_fn_violation": 0.008191201837485838,
            "auditor_fp_violation": 0.0005803903756135107,
            "ave_precision_score": 0.569883866189381,
            "fpr": 0.010976948408342482,
            "logloss": 0.7236240311905996,
            "mae": 0.4861470186159371,
            "precision": 0.6875,
            "recall": 0.046218487394957986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7394891037000009,
            "auditor_fn_violation": 0.016796043455920135,
            "auditor_fp_violation": 0.023407813889562614,
            "ave_precision_score": 0.6644991825026662,
            "fpr": 0.14802631578947367,
            "logloss": 0.6785802313089492,
            "mae": 0.42608714753990634,
            "precision": 0.6938775510204082,
            "recall": 0.6401673640167364
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7658420557874529,
            "auditor_fn_violation": 0.011221393057771966,
            "auditor_fp_violation": 0.01466621244811184,
            "ave_precision_score": 0.6924378731828207,
            "fpr": 0.13391877058177826,
            "logloss": 0.6509062818801099,
            "mae": 0.4149828881974016,
            "precision": 0.7246049661399548,
            "recall": 0.6743697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6294495244909502,
            "auditor_fn_violation": 0.0132060669456067,
            "auditor_fp_violation": 0.020762591963780424,
            "ave_precision_score": 0.6309159024273977,
            "fpr": 0.06907894736842106,
            "logloss": 2.994605979859653,
            "mae": 0.41735040116317323,
            "precision": 0.7396694214876033,
            "recall": 0.37447698744769875
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6755519474901166,
            "auditor_fn_violation": 0.011606508684703306,
            "auditor_fp_violation": 0.013500384824053397,
            "ave_precision_score": 0.6761083177364311,
            "fpr": 0.054884742041712405,
            "logloss": 2.6683286168311096,
            "mae": 0.38314416019872777,
            "precision": 0.7991967871485943,
            "recall": 0.4180672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6124164375256791,
            "auditor_fn_violation": 0.01905784335315278,
            "auditor_fp_violation": 0.02154074702886248,
            "ave_precision_score": 0.6129476417848239,
            "fpr": 0.07236842105263158,
            "logloss": 4.061247808613076,
            "mae": 0.4166606521687418,
            "precision": 0.7272727272727273,
            "recall": 0.3682008368200837
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6372966519592251,
            "auditor_fn_violation": 0.0025090167790497303,
            "auditor_fp_violation": 0.022400545062265798,
            "ave_precision_score": 0.6351767680166209,
            "fpr": 0.06915477497255763,
            "logloss": 3.7614538900375543,
            "mae": 0.40176533478656384,
            "precision": 0.748,
            "recall": 0.39285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6052543591546898,
            "auditor_fn_violation": 0.007326763561623732,
            "auditor_fp_violation": 0.025881235346430595,
            "ave_precision_score": 0.6047573782559761,
            "fpr": 0.14035087719298245,
            "logloss": 3.437378375310037,
            "mae": 0.4018074660059103,
            "precision": 0.6701030927835051,
            "recall": 0.5439330543933054
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.637762517521334,
            "auditor_fn_violation": 0.007896023392891733,
            "auditor_fp_violation": 0.021348272076914344,
            "ave_precision_score": 0.6348496144222745,
            "fpr": 0.12184412733260154,
            "logloss": 3.1579808433873104,
            "mae": 0.38528837187958265,
            "precision": 0.6958904109589041,
            "recall": 0.5336134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6286029400200348,
            "auditor_fn_violation": 0.02047548263965354,
            "auditor_fp_violation": 0.019484194356859892,
            "ave_precision_score": 0.6301127530727852,
            "fpr": 0.09868421052631579,
            "logloss": 3.9103183368823844,
            "mae": 0.4132697224962836,
            "precision": 0.6938775510204082,
            "recall": 0.42677824267782427
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6657370805491916,
            "auditor_fn_violation": 0.0058021013015524606,
            "auditor_fp_violation": 0.01964495249630948,
            "ave_precision_score": 0.6663836514717579,
            "fpr": 0.08232711306256861,
            "logloss": 3.5827806194063783,
            "mae": 0.3866351517452178,
            "precision": 0.7422680412371134,
            "recall": 0.453781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 13352,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.4682845664358114,
            "auditor_fn_violation": 0.01373596124201717,
            "auditor_fp_violation": 0.017703027730616862,
            "ave_precision_score": 0.4512384522805232,
            "fpr": 0.2532894736842105,
            "logloss": 8.353968645697837,
            "mae": 0.5251070879163995,
            "precision": 0.5177453027139874,
            "recall": 0.5188284518828452
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.4613314607969597,
            "auditor_fn_violation": 0.002589729634993409,
            "auditor_fp_violation": 0.009677378654251376,
            "ave_precision_score": 0.4473440111830612,
            "fpr": 0.2678375411635565,
            "logloss": 8.079244844071859,
            "mae": 0.522201682125,
            "precision": 0.5129740518962076,
            "recall": 0.5399159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6230882187478893,
            "auditor_fn_violation": 0.008141103281215591,
            "auditor_fp_violation": 0.022814091680814944,
            "ave_precision_score": 0.6219036195655065,
            "fpr": 0.07675438596491228,
            "logloss": 3.34177928003102,
            "mae": 0.4078086709394232,
            "precision": 0.7338403041825095,
            "recall": 0.40376569037656906
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6485161457487612,
            "auditor_fn_violation": 0.009072125008071297,
            "auditor_fp_violation": 0.021716693793608136,
            "ave_precision_score": 0.6463564245929576,
            "fpr": 0.07025246981339188,
            "logloss": 3.011384992023827,
            "mae": 0.3911493036795899,
            "precision": 0.7602996254681648,
            "recall": 0.4264705882352941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6308058392033808,
            "auditor_fn_violation": 0.02001211186963225,
            "auditor_fp_violation": 0.019989489853666425,
            "ave_precision_score": 0.6322725708785714,
            "fpr": 0.0668859649122807,
            "logloss": 3.3637220925589992,
            "mae": 0.41367461183640747,
            "precision": 0.7489711934156379,
            "recall": 0.3807531380753138
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6728924790504826,
            "auditor_fn_violation": 0.015109446632659656,
            "auditor_fp_violation": 0.017737234566032024,
            "ave_precision_score": 0.6735503330427264,
            "fpr": 0.059275521405049394,
            "logloss": 3.0268676335342524,
            "mae": 0.38310172726351055,
            "precision": 0.784,
            "recall": 0.4117647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7225763771193563,
            "auditor_fn_violation": 0.023347463847904287,
            "auditor_fp_violation": 0.027018150214245293,
            "ave_precision_score": 0.7240308047106975,
            "fpr": 0.15789473684210525,
            "logloss": 1.1007227293636093,
            "mae": 0.3136069078381431,
            "precision": 0.712,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.787339001743877,
            "auditor_fn_violation": 0.014883450636017303,
            "auditor_fp_violation": 0.022274373241480253,
            "ave_precision_score": 0.78705465047191,
            "fpr": 0.13611416026344675,
            "logloss": 0.9113372116277444,
            "mae": 0.2762756366009694,
            "precision": 0.7494949494949495,
            "recall": 0.7794117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5701383403514728,
            "auditor_fn_violation": 0.01858759083902227,
            "auditor_fp_violation": 0.019726736195327027,
            "ave_precision_score": 0.5495426378782099,
            "fpr": 0.03508771929824561,
            "logloss": 0.6951644918190754,
            "mae": 0.4988727219925638,
            "precision": 0.5362318840579711,
            "recall": 0.07740585774058577
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.6340257548181765,
            "auditor_fn_violation": 0.02323146602219374,
            "auditor_fp_violation": 0.012945228812596996,
            "ave_precision_score": 0.5781521258009622,
            "fpr": 0.020856201975850714,
            "logloss": 0.6861170090271431,
            "mae": 0.494604716316667,
            "precision": 0.7076923076923077,
            "recall": 0.09663865546218488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.458364550979096,
            "auditor_fn_violation": 0.01102455406298174,
            "auditor_fp_violation": 0.02464073490177056,
            "ave_precision_score": 0.4535254881004236,
            "fpr": 0.21600877192982457,
            "logloss": 7.433003941259661,
            "mae": 0.5263476484293248,
            "precision": 0.5218446601941747,
            "recall": 0.4497907949790795
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.45801111305401787,
            "auditor_fn_violation": 0.01098617273473605,
            "auditor_fp_violation": 0.016314016427571073,
            "ave_precision_score": 0.4541350277383843,
            "fpr": 0.2261251372118551,
            "logloss": 7.121105815539142,
            "mae": 0.5211864761220578,
            "precision": 0.5220417633410673,
            "recall": 0.4726890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6228693768503077,
            "auditor_fn_violation": 0.009113723115319708,
            "auditor_fp_violation": 0.022303743229040347,
            "ave_precision_score": 0.6216889631937375,
            "fpr": 0.07236842105263158,
            "logloss": 3.467117521039693,
            "mae": 0.40896306516633624,
            "precision": 0.7431906614785992,
            "recall": 0.399581589958159
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6498750726922523,
            "auditor_fn_violation": 0.005599166120894037,
            "auditor_fp_violation": 0.022092685819549065,
            "ave_precision_score": 0.6477112903505775,
            "fpr": 0.07354555433589462,
            "logloss": 3.133440388755108,
            "mae": 0.3917810043837699,
            "precision": 0.75,
            "recall": 0.4222689075630252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.5919322864266017,
            "auditor_fn_violation": 0.012125633120458045,
            "auditor_fp_violation": 0.029125232435928544,
            "ave_precision_score": 0.5923013284640817,
            "fpr": 0.15570175438596492,
            "logloss": 3.9628284919145518,
            "mae": 0.4241575333079749,
            "precision": 0.645,
            "recall": 0.5397489539748954
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6119487076173986,
            "auditor_fn_violation": 0.0010561853720632167,
            "auditor_fp_violation": 0.024055919350972153,
            "ave_precision_score": 0.6102826893213875,
            "fpr": 0.145993413830955,
            "logloss": 3.778371618830876,
            "mae": 0.4108820258381961,
            "precision": 0.659846547314578,
            "recall": 0.542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.4566639460069729,
            "auditor_fn_violation": 0.009932650664317696,
            "auditor_fp_violation": 0.026389057320721165,
            "ave_precision_score": 0.45186068199358403,
            "fpr": 0.21162280701754385,
            "logloss": 7.544882039887814,
            "mae": 0.5272423150958965,
            "precision": 0.5292682926829269,
            "recall": 0.45397489539748953
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.4530300474064164,
            "auditor_fn_violation": 0.008873801990609638,
            "auditor_fp_violation": 0.018678476349092196,
            "ave_precision_score": 0.4491065483842246,
            "fpr": 0.2283205268935236,
            "logloss": 7.341664972663265,
            "mae": 0.5256758797052856,
            "precision": 0.5218390804597701,
            "recall": 0.47689075630252103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.6218951047264691,
            "auditor_fn_violation": 0.0016195037803714482,
            "auditor_fp_violation": 0.004102999434069044,
            "ave_precision_score": 0.5929302881584273,
            "fpr": 0.015350877192982455,
            "logloss": 0.7237830297448294,
            "mae": 0.49216667873164016,
            "precision": 0.65,
            "recall": 0.05439330543933055
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6504359574334448,
            "auditor_fn_violation": 0.008191201837485838,
            "auditor_fp_violation": 0.0005803903756135107,
            "ave_precision_score": 0.6284971375964498,
            "fpr": 0.010976948408342482,
            "logloss": 0.7185221323407426,
            "mae": 0.48553470938179755,
            "precision": 0.6875,
            "recall": 0.046218487394957986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.5948349596503668,
            "auditor_fn_violation": 0.009230712765176553,
            "auditor_fp_violation": 0.017349320882852293,
            "ave_precision_score": 0.5935570649195396,
            "fpr": 0.14144736842105263,
            "logloss": 4.347966580550765,
            "mae": 0.41589891991450706,
            "precision": 0.6485013623978202,
            "recall": 0.497907949790795
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6139035866588742,
            "auditor_fn_violation": 0.008039000451992007,
            "auditor_fp_violation": 0.02039441311177562,
            "ave_precision_score": 0.6104179319423213,
            "fpr": 0.12184412733260154,
            "logloss": 4.135100510400908,
            "mae": 0.3981002824442286,
            "precision": 0.6791907514450867,
            "recall": 0.49369747899159666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.47101413277640725,
            "auditor_fn_violation": 0.009707847023416283,
            "auditor_fp_violation": 0.004385964912280698,
            "ave_precision_score": 0.4987545165059505,
            "fpr": 0.4375,
            "logloss": 0.9075855831737728,
            "mae": 0.5060563641028446,
            "precision": 0.527810650887574,
            "recall": 0.9330543933054394
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5039445132177476,
            "auditor_fn_violation": 0.007527050337149131,
            "auditor_fp_violation": 0.009553730269881525,
            "ave_precision_score": 0.5308864890492659,
            "fpr": 0.44127332601536773,
            "logloss": 0.8867953204898301,
            "mae": 0.4993321851946974,
            "precision": 0.5298245614035088,
            "recall": 0.9516806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6379504697730904,
            "auditor_fn_violation": 0.004101519489099342,
            "auditor_fp_violation": 0.021929824561403508,
            "ave_precision_score": 0.6384748891346093,
            "fpr": 0.06798245614035088,
            "logloss": 2.1778982098272617,
            "mae": 0.41841859454129,
            "precision": 0.7292576419213974,
            "recall": 0.3493723849372385
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6710714517147586,
            "auditor_fn_violation": 0.0016419300980545914,
            "auditor_fp_violation": 0.024149286498353465,
            "ave_precision_score": 0.6689530372121189,
            "fpr": 0.06366630076838639,
            "logloss": 1.8939844092478642,
            "mae": 0.4031776307967842,
            "precision": 0.7542372881355932,
            "recall": 0.3739495798319328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6547173944638965,
            "auditor_fn_violation": 0.060871320560816275,
            "auditor_fp_violation": 0.014976958525345625,
            "ave_precision_score": 0.6007901413816731,
            "fpr": 0.02850877192982456,
            "logloss": 0.7898148777226768,
            "mae": 0.485210182014526,
            "precision": 0.8266666666666667,
            "recall": 0.2594142259414226
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6824413875682245,
            "auditor_fn_violation": 0.07781641745611527,
            "auditor_fp_violation": 0.01081040160490556,
            "ave_precision_score": 0.6289165600742137,
            "fpr": 0.02305159165751921,
            "logloss": 0.7485740451057246,
            "mae": 0.48216089656991573,
            "precision": 0.8757396449704142,
            "recall": 0.31092436974789917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.5928898894214243,
            "auditor_fn_violation": 0.01891332672685899,
            "auditor_fp_violation": 0.014277124262268579,
            "ave_precision_score": 0.5923700964501996,
            "fpr": 0.13706140350877194,
            "logloss": 4.277546189715765,
            "mae": 0.4167782186501988,
            "precision": 0.6527777777777778,
            "recall": 0.4916317991631799
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6201546662996886,
            "auditor_fn_violation": 0.003722015699803539,
            "auditor_fp_violation": 0.02151481888035127,
            "ave_precision_score": 0.617121910886978,
            "fpr": 0.12184412733260154,
            "logloss": 4.012498438389048,
            "mae": 0.3965872161429572,
            "precision": 0.6855524079320113,
            "recall": 0.5084033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6235551589667553,
            "auditor_fn_violation": 0.007638735961242021,
            "auditor_fp_violation": 0.02209657207534967,
            "ave_precision_score": 0.6223721719337293,
            "fpr": 0.0756578947368421,
            "logloss": 3.325876254544647,
            "mae": 0.40796694518396615,
            "precision": 0.735632183908046,
            "recall": 0.401673640167364
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6492213619966137,
            "auditor_fn_violation": 0.008458707302899228,
            "auditor_fp_violation": 0.021716693793608136,
            "ave_precision_score": 0.6470610428466204,
            "fpr": 0.07025246981339188,
            "logloss": 2.9963994690849893,
            "mae": 0.3912289722367015,
            "precision": 0.7602996254681648,
            "recall": 0.4264705882352941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5171281639100143,
            "auditor_fn_violation": 0.013006496366439113,
            "auditor_fp_violation": 0.004969581211092262,
            "ave_precision_score": 0.5192366120778495,
            "fpr": 0.34539473684210525,
            "logloss": 0.6936128924316696,
            "mae": 0.4998490791114276,
            "precision": 0.527027027027027,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5515304213096828,
            "auditor_fn_violation": 0.00045199199328468904,
            "auditor_fp_violation": 0.025246981339187707,
            "ave_precision_score": 0.5528833058409481,
            "fpr": 0.33479692645444564,
            "logloss": 0.6910734825996816,
            "mae": 0.4985209633437784,
            "precision": 0.5343511450381679,
            "recall": 0.7352941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.5947731732316991,
            "auditor_fn_violation": 0.019007377229685107,
            "auditor_fp_violation": 0.01448682189344329,
            "ave_precision_score": 0.593496010159722,
            "fpr": 0.14473684210526316,
            "logloss": 4.392220897771231,
            "mae": 0.4133427263973991,
            "precision": 0.648936170212766,
            "recall": 0.5104602510460251
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6105949311303285,
            "auditor_fn_violation": 0.002961008772334406,
            "auditor_fp_violation": 0.014812571760223074,
            "ave_precision_score": 0.6071335939255361,
            "fpr": 0.132821075740944,
            "logloss": 4.1638720523883475,
            "mae": 0.3982264760911575,
            "precision": 0.670299727520436,
            "recall": 0.5168067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.5862090304693116,
            "auditor_fn_violation": 0.007936944872641852,
            "auditor_fp_violation": 0.016624221844934922,
            "ave_precision_score": 0.5848442577696831,
            "fpr": 0.14583333333333334,
            "logloss": 4.523246489855171,
            "mae": 0.4182695927315067,
            "precision": 0.6453333333333333,
            "recall": 0.5062761506276151
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6042938959328652,
            "auditor_fn_violation": 0.007822228781743218,
            "auditor_fp_violation": 0.014716681176426064,
            "ave_precision_score": 0.6002426122444618,
            "fpr": 0.13391877058177826,
            "logloss": 4.272430378187076,
            "mae": 0.40225681376058403,
            "precision": 0.6666666666666666,
            "recall": 0.5126050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6071890887322297,
            "auditor_fn_violation": 0.008599886221830732,
            "auditor_fp_violation": 0.025881235346430595,
            "ave_precision_score": 0.6066710758684573,
            "fpr": 0.14035087719298245,
            "logloss": 3.23072221923338,
            "mae": 0.3988359688736677,
            "precision": 0.6709511568123393,
            "recall": 0.5460251046025104
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6394921217113545,
            "auditor_fn_violation": 0.008883026317003209,
            "auditor_fp_violation": 0.023947411585096588,
            "ave_precision_score": 0.6370595557606703,
            "fpr": 0.12623490669593854,
            "logloss": 2.947038486184103,
            "mae": 0.38278705426835535,
            "precision": 0.6900269541778976,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7157007674528901,
            "auditor_fn_violation": 0.05643718343977098,
            "auditor_fp_violation": 0.05435463659147871,
            "ave_precision_score": 0.6658416858570221,
            "fpr": 0.20394736842105263,
            "logloss": 0.6385173749559996,
            "mae": 0.4435500936876786,
            "precision": 0.6316831683168317,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7397278156327701,
            "auditor_fn_violation": 0.05086293573411802,
            "auditor_fp_violation": 0.05299216472992922,
            "ave_precision_score": 0.6924749411033343,
            "fpr": 0.1734357848518112,
            "logloss": 0.6117697588240492,
            "mae": 0.4261354902756894,
            "precision": 0.6877470355731226,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6148737091046517,
            "auditor_fn_violation": 0.016635469426704852,
            "auditor_fp_violation": 0.02154074702886248,
            "ave_precision_score": 0.6154047142702426,
            "fpr": 0.07236842105263158,
            "logloss": 3.8909179497784825,
            "mae": 0.4145442120013928,
            "precision": 0.7317073170731707,
            "recall": 0.37656903765690375
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6399002409765733,
            "auditor_fn_violation": 0.007086588751856404,
            "auditor_fp_violation": 0.022400545062265798,
            "ave_precision_score": 0.6377807460410038,
            "fpr": 0.06915477497255763,
            "logloss": 3.5799681654126236,
            "mae": 0.399533731716445,
            "precision": 0.7519685039370079,
            "recall": 0.4012605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 13352,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.4683214359937407,
            "auditor_fn_violation": 0.013713022094986422,
            "auditor_fp_violation": 0.019964225078826107,
            "ave_precision_score": 0.45053390611710614,
            "fpr": 0.25877192982456143,
            "logloss": 8.393149397082292,
            "mae": 0.5262398019266673,
            "precision": 0.51440329218107,
            "recall": 0.5230125523012552
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.46019460501612597,
            "auditor_fn_violation": 0.0025643627374111024,
            "auditor_fp_violation": 0.011547245038293146,
            "ave_precision_score": 0.446220822456569,
            "fpr": 0.2722283205268935,
            "logloss": 8.082032011657057,
            "mae": 0.5238111252612091,
            "precision": 0.5098814229249012,
            "recall": 0.542016806722689
        }
    }
]