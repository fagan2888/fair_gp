[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 12498,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.405532157814246,
            "mae": 0.5328947368421053,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.743301155673105,
            "mae": 0.5137211855104281,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 12498,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.405532157814246,
            "mae": 0.5328947368421053,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.743301155673105,
            "mae": 0.5137211855104281,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 12498,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5781387776113511,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.027690264393377812,
            "ave_precision_score": 0.5346052437765461,
            "fpr": 0.08552631578947369,
            "logloss": 0.6941385003798616,
            "mae": 0.4991142487055377,
            "precision": 0.5357142857142857,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5658069825870269,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.030898994729578046,
            "ave_precision_score": 0.5158489159605759,
            "fpr": 0.0867178924259056,
            "logloss": 0.6951724507146907,
            "mae": 0.49968992394490247,
            "precision": 0.5269461077844312,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5700891127556862,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.029075035005353758,
            "ave_precision_score": 0.5312279168296219,
            "fpr": 0.08771929824561403,
            "logloss": 0.6947353962724275,
            "mae": 0.49952722177432296,
            "precision": 0.5294117647058824,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5539945957982366,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.031035277384760623,
            "ave_precision_score": 0.5125086811045039,
            "fpr": 0.09001097694840834,
            "logloss": 0.6949688991506439,
            "mae": 0.4996449732427147,
            "precision": 0.5176470588235295,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8283538137021276,
            "auditor_fn_violation": 0.004746949678723557,
            "auditor_fp_violation": 0.009127131208302455,
            "ave_precision_score": 0.8284325125022592,
            "fpr": 0.3684210526315789,
            "logloss": 0.6875842613480608,
            "mae": 0.49395930203364086,
            "precision": 0.5508021390374331,
            "recall": 0.8477366255144033
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7848104572242278,
            "auditor_fn_violation": 0.006163978721607703,
            "auditor_fp_violation": 0.004616265211002722,
            "ave_precision_score": 0.7848061711547156,
            "fpr": 0.36882546652030734,
            "logloss": 0.6890851397134207,
            "mae": 0.49554389904935064,
            "precision": 0.5234042553191489,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6351963197339955,
            "auditor_fn_violation": 0.0628654970760234,
            "auditor_fp_violation": 0.06397743184251709,
            "ave_precision_score": 0.6362339315173527,
            "fpr": 0.19517543859649122,
            "logloss": 0.7129661864698482,
            "mae": 0.46960922077456063,
            "precision": 0.6180257510729614,
            "recall": 0.5925925925925926
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6272661404577634,
            "auditor_fn_violation": 0.05496918010639198,
            "auditor_fp_violation": 0.06524965743496221,
            "ave_precision_score": 0.6282821462298341,
            "fpr": 0.20087815587266739,
            "logloss": 0.689349879962898,
            "mae": 0.4642052805033892,
            "precision": 0.6114649681528662,
            "recall": 0.6153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8295274003784444,
            "auditor_fn_violation": 0.004746949678723557,
            "auditor_fp_violation": 0.009127131208302455,
            "ave_precision_score": 0.8296055901692829,
            "fpr": 0.3684210526315789,
            "logloss": 0.6847877216610846,
            "mae": 0.4925026761760053,
            "precision": 0.5508021390374331,
            "recall": 0.8477366255144033
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7872050625948455,
            "auditor_fn_violation": 0.006163978721607703,
            "auditor_fp_violation": 0.004616265211002722,
            "ave_precision_score": 0.7871991561560763,
            "fpr": 0.36882546652030734,
            "logloss": 0.6864434823190814,
            "mae": 0.4941469083502316,
            "precision": 0.5234042553191489,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5692586060187844,
            "auditor_fn_violation": 0.002711898057901957,
            "auditor_fp_violation": 0.005680648216786099,
            "ave_precision_score": 0.5583744807459605,
            "fpr": 0.44846491228070173,
            "logloss": 0.6900633933988911,
            "mae": 0.49557651731332664,
            "precision": 0.5378531073446328,
            "recall": 0.9794238683127572
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5432584352172567,
            "auditor_fn_violation": 0.0022516817247882014,
            "auditor_fp_violation": 0.0049408657169830675,
            "ave_precision_score": 0.5275347896591446,
            "fpr": 0.47310647639956094,
            "logloss": 0.6898794985995687,
            "mae": 0.4964186223520275,
            "precision": 0.5184357541899441,
            "recall": 0.9914529914529915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 12498,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5781387776113511,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.027690264393377812,
            "ave_precision_score": 0.5346052437765461,
            "fpr": 0.08552631578947369,
            "logloss": 0.6941385003798616,
            "mae": 0.4991142487055377,
            "precision": 0.5357142857142857,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5658069825870269,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.030898994729578046,
            "ave_precision_score": 0.5158489159605759,
            "fpr": 0.0867178924259056,
            "logloss": 0.6951724507146907,
            "mae": 0.49968992394490247,
            "precision": 0.5269461077844312,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6350109605743385,
            "auditor_fn_violation": 0.0032894736842105413,
            "auditor_fp_violation": 0.0017708590725640397,
            "ave_precision_score": 0.6361436373908846,
            "fpr": 0.007675438596491228,
            "logloss": 1.0241262180687922,
            "mae": 0.4935371696825322,
            "precision": 0.631578947368421,
            "recall": 0.024691358024691357
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6421647191805567,
            "auditor_fn_violation": 0.001217315432463634,
            "auditor_fp_violation": 0.0010060137818932388,
            "ave_precision_score": 0.6431563275302216,
            "fpr": 0.0021953896816684962,
            "logloss": 0.8601678221054148,
            "mae": 0.4795986394185844,
            "precision": 0.8823529411764706,
            "recall": 0.03205128205128205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7441859702330906,
            "auditor_fn_violation": 0.01663688542343513,
            "auditor_fp_violation": 0.02244718309859155,
            "ave_precision_score": 0.7386928038341087,
            "fpr": 0.22039473684210525,
            "logloss": 1.1770210068889086,
            "mae": 0.39222370340489476,
            "precision": 0.6448763250883393,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7534178986919194,
            "auditor_fn_violation": 0.014544456641053785,
            "auditor_fp_violation": 0.024689461386168062,
            "ave_precision_score": 0.750907249309113,
            "fpr": 0.21953896816684962,
            "logloss": 0.8517767177906653,
            "mae": 0.38291273491573985,
            "precision": 0.648506151142355,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5744037381034285,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.029075035005353758,
            "ave_precision_score": 0.5322497420020641,
            "fpr": 0.08771929824561403,
            "logloss": 0.6947297116697523,
            "mae": 0.4995317927708751,
            "precision": 0.5294117647058824,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5614026431873659,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.031035277384760623,
            "ave_precision_score": 0.5144593839111822,
            "fpr": 0.09001097694840834,
            "logloss": 0.6949303451969187,
            "mae": 0.4996277177961938,
            "precision": 0.5176470588235295,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5661606336304658,
            "auditor_fn_violation": 0.04495614035087719,
            "auditor_fp_violation": 0.0347685528374928,
            "ave_precision_score": 0.5435872111954198,
            "fpr": 0.14035087719298245,
            "logloss": 0.693686074159553,
            "mae": 0.498863473665296,
            "precision": 0.5586206896551724,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5330036464567164,
            "auditor_fn_violation": 0.03821291527109311,
            "auditor_fp_violation": 0.039142856434895304,
            "ave_precision_score": 0.5186707597332615,
            "fpr": 0.13611416026344675,
            "logloss": 0.6949368520481582,
            "mae": 0.4995194074547513,
            "precision": 0.5555555555555556,
            "recall": 0.3311965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8295939349545918,
            "auditor_fn_violation": 0.004746949678723557,
            "auditor_fp_violation": 0.009127131208302455,
            "ave_precision_score": 0.8296720638016459,
            "fpr": 0.3684210526315789,
            "logloss": 0.6842426139842622,
            "mae": 0.4922176722371787,
            "precision": 0.5508021390374331,
            "recall": 0.8477366255144033
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7873556849240976,
            "auditor_fn_violation": 0.006163978721607703,
            "auditor_fp_violation": 0.004616265211002722,
            "ave_precision_score": 0.7873496713915982,
            "fpr": 0.36882546652030734,
            "logloss": 0.6859296325135823,
            "mae": 0.49387387867554877,
            "precision": 0.5234042553191489,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5661606336304658,
            "auditor_fn_violation": 0.04495614035087719,
            "auditor_fp_violation": 0.0347685528374928,
            "ave_precision_score": 0.5435872111954198,
            "fpr": 0.14035087719298245,
            "logloss": 0.693686074159553,
            "mae": 0.498863473665296,
            "precision": 0.5586206896551724,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5330036464567164,
            "auditor_fn_violation": 0.03821291527109311,
            "auditor_fp_violation": 0.039142856434895304,
            "ave_precision_score": 0.5186707597332615,
            "fpr": 0.13611416026344675,
            "logloss": 0.6949368520481582,
            "mae": 0.4995194074547513,
            "precision": 0.5555555555555556,
            "recall": 0.3311965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 12498,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5781387776113511,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.027690264393377812,
            "ave_precision_score": 0.5346052437765461,
            "fpr": 0.08552631578947369,
            "logloss": 0.6941385003798616,
            "mae": 0.4991142487055377,
            "precision": 0.5357142857142857,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5658069825870269,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.030898994729578046,
            "ave_precision_score": 0.5158489159605759,
            "fpr": 0.0867178924259056,
            "logloss": 0.6951724507146907,
            "mae": 0.49968992394490247,
            "precision": 0.5269461077844312,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5877150037055952,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5891727537643883,
            "fpr": 0.46710526315789475,
            "logloss": 3.7601241844060054,
            "mae": 0.46630357343115303,
            "precision": 0.5328947368421053,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5959184867917346,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5971268726180272,
            "fpr": 0.4862788144895719,
            "logloss": 3.847713015128445,
            "mae": 0.48521921329780937,
            "precision": 0.5137211855104281,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5732842253854302,
            "auditor_fn_violation": 0.02612627247130172,
            "auditor_fp_violation": 0.031134173461823577,
            "ave_precision_score": 0.562917422592367,
            "fpr": 0.1337719298245614,
            "logloss": 2.1617490213094737,
            "mae": 0.4955264629077232,
            "precision": 0.6038961038961039,
            "recall": 0.38271604938271603
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5875108137547245,
            "auditor_fn_violation": 0.031467252103915114,
            "auditor_fp_violation": 0.025041318423184904,
            "ave_precision_score": 0.5726892070090438,
            "fpr": 0.12623490669593854,
            "logloss": 1.9598666632208974,
            "mae": 0.4833584586822895,
            "precision": 0.6290322580645161,
            "recall": 0.4166666666666667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5581120682247694,
            "auditor_fn_violation": 0.002711898057901957,
            "auditor_fp_violation": 0.005680648216786099,
            "ave_precision_score": 0.5587417758778302,
            "fpr": 0.44846491228070173,
            "logloss": 0.6910378869576086,
            "mae": 0.49655089775721234,
            "precision": 0.5378531073446328,
            "recall": 0.9794238683127572
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5193752945276177,
            "auditor_fn_violation": 0.0022516817247882014,
            "auditor_fp_violation": 0.0049408657169830675,
            "ave_precision_score": 0.5189467607199538,
            "fpr": 0.47310647639956094,
            "logloss": 0.6900769853246864,
            "mae": 0.49701888177188114,
            "precision": 0.5184357541899441,
            "recall": 0.9914529914529915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.8313975099009965,
            "auditor_fn_violation": 0.008383871200635332,
            "auditor_fp_violation": 0.004710279219174711,
            "ave_precision_score": 0.8314667526794177,
            "fpr": 0.3651315789473684,
            "logloss": 0.6805784912080678,
            "mae": 0.49045439247499434,
            "precision": 0.5548128342245989,
            "recall": 0.8539094650205762
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7888212537752268,
            "auditor_fn_violation": 0.0037058928387139175,
            "auditor_fp_violation": 0.0072898831190392034,
            "ave_precision_score": 0.7888112947134898,
            "fpr": 0.36553238199780463,
            "logloss": 0.6830815139728039,
            "mae": 0.4923787886107138,
            "precision": 0.5269886363636364,
            "recall": 0.7927350427350427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6389801318688657,
            "auditor_fn_violation": 0.014985380116959067,
            "auditor_fp_violation": 0.008324067210279229,
            "ave_precision_score": 0.5386845445905124,
            "fpr": 0.20723684210526316,
            "logloss": 0.6918496700501237,
            "mae": 0.4980162218735929,
            "precision": 0.5467625899280576,
            "recall": 0.4691358024691358
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.6071811100319543,
            "auditor_fn_violation": 0.005666732340716973,
            "auditor_fp_violation": 0.007131299665735823,
            "ave_precision_score": 0.5054561738136908,
            "fpr": 0.2327113062568606,
            "logloss": 0.6969631658835516,
            "mae": 0.5004928731630452,
            "precision": 0.5023474178403756,
            "recall": 0.45726495726495725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6367513535917251,
            "auditor_fn_violation": 0.061850227420402866,
            "auditor_fp_violation": 0.07487799604645418,
            "ave_precision_score": 0.6377735010942627,
            "fpr": 0.22697368421052633,
            "logloss": 0.7076838106166062,
            "mae": 0.46763596883637976,
            "precision": 0.603448275862069,
            "recall": 0.6481481481481481
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6306233252614992,
            "auditor_fn_violation": 0.05455402628838414,
            "auditor_fp_violation": 0.06874344914055203,
            "ave_precision_score": 0.6316255184008623,
            "fpr": 0.24039517014270034,
            "logloss": 0.6859813615654442,
            "mae": 0.4626958085646118,
            "precision": 0.5852272727272727,
            "recall": 0.6602564102564102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.8320073189274462,
            "auditor_fn_violation": 0.007675438596491231,
            "auditor_fp_violation": 0.004934210526315783,
            "ave_precision_score": 0.8320819708051667,
            "fpr": 0.35635964912280704,
            "logloss": 0.6790831463614343,
            "mae": 0.48951848164985057,
            "precision": 0.5602165087956699,
            "recall": 0.8518518518518519
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7909141905978406,
            "auditor_fn_violation": 0.001935038982239861,
            "auditor_fp_violation": 0.005979091762828537,
            "ave_precision_score": 0.7908976587054026,
            "fpr": 0.3534577387486279,
            "logloss": 0.6809755010681641,
            "mae": 0.4912786344403624,
            "precision": 0.5366906474820143,
            "recall": 0.7970085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5741541214038951,
            "auditor_fn_violation": 0.0008866688325752654,
            "auditor_fp_violation": 0.006370459599703484,
            "ave_precision_score": 0.577960700582068,
            "fpr": 0.41776315789473684,
            "logloss": 2.2694448702441776,
            "mae": 0.43604790764092877,
            "precision": 0.5580046403712297,
            "recall": 0.9897119341563786
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5769225298497073,
            "auditor_fn_violation": 0.0018294914013904137,
            "auditor_fp_violation": 0.014810207818659837,
            "ave_precision_score": 0.5798069601248458,
            "fpr": 0.4313940724478595,
            "logloss": 2.2912824739099635,
            "mae": 0.4542009720065591,
            "precision": 0.5392731535756154,
            "recall": 0.9829059829059829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 12498,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5689289285346968,
            "auditor_fn_violation": 0.04495614035087719,
            "auditor_fp_violation": 0.03430009883864592,
            "ave_precision_score": 0.5473758409663202,
            "fpr": 0.13815789473684212,
            "logloss": 0.6926532163562567,
            "mae": 0.4984028379253128,
            "precision": 0.5625,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5335300289053949,
            "auditor_fn_violation": 0.03821291527109311,
            "auditor_fp_violation": 0.039142856434895304,
            "ave_precision_score": 0.5198138062249654,
            "fpr": 0.13611416026344675,
            "logloss": 0.6944949443141555,
            "mae": 0.49936109696209235,
            "precision": 0.5555555555555556,
            "recall": 0.3311965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5104668246055861,
            "auditor_fn_violation": 0.04348963973720309,
            "auditor_fp_violation": 0.039967877440079076,
            "ave_precision_score": 0.5211661572415587,
            "fpr": 0.2850877192982456,
            "logloss": 0.697937267156459,
            "mae": 0.5000576926231907,
            "precision": 0.5289855072463768,
            "recall": 0.6008230452674898
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.49781588410745575,
            "auditor_fn_violation": 0.028385262743111265,
            "auditor_fp_violation": 0.04358567099384747,
            "ave_precision_score": 0.5021871062459717,
            "fpr": 0.270032930845225,
            "logloss": 0.6967679205875036,
            "mae": 0.49959720950880376,
            "precision": 0.5185909980430529,
            "recall": 0.5662393162393162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5836357896966623,
            "auditor_fn_violation": 0.008474117392246048,
            "auditor_fp_violation": 0.011088460588089948,
            "ave_precision_score": 0.5786340956587197,
            "fpr": 0.43859649122807015,
            "logloss": 2.315306449884905,
            "mae": 0.4633795239615826,
            "precision": 0.5412844036697247,
            "recall": 0.9711934156378601
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6100008935995072,
            "auditor_fn_violation": 0.00722414553369548,
            "auditor_fp_violation": 0.01506790593027779,
            "ave_precision_score": 0.6083795194397132,
            "fpr": 0.45773874862788144,
            "logloss": 2.0355297583888814,
            "mae": 0.4665937048066845,
            "precision": 0.5234285714285715,
            "recall": 0.9786324786324786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.8313975099009965,
            "auditor_fn_violation": 0.008383871200635332,
            "auditor_fp_violation": 0.004710279219174711,
            "ave_precision_score": 0.8314667526794177,
            "fpr": 0.3651315789473684,
            "logloss": 0.6805784913096133,
            "mae": 0.49045439257302825,
            "precision": 0.5548128342245989,
            "recall": 0.8539094650205762
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7888212537752268,
            "auditor_fn_violation": 0.0037058928387139175,
            "auditor_fp_violation": 0.0072898831190392034,
            "ave_precision_score": 0.7888112947134898,
            "fpr": 0.36553238199780463,
            "logloss": 0.6830815148384772,
            "mae": 0.49237878911777855,
            "precision": 0.5269886363636364,
            "recall": 0.7927350427350427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7215349162981238,
            "auditor_fn_violation": 0.019245000360984768,
            "auditor_fp_violation": 0.02717033193311919,
            "ave_precision_score": 0.7194094418960266,
            "fpr": 0.2916666666666667,
            "logloss": 0.9873305964042687,
            "mae": 0.41608276721811915,
            "precision": 0.605925925925926,
            "recall": 0.8415637860082305
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7395798353288734,
            "auditor_fn_violation": 0.016932177470047945,
            "auditor_fp_violation": 0.033599869168651035,
            "ave_precision_score": 0.738081469241829,
            "fpr": 0.30735455543358947,
            "logloss": 0.7558649155879581,
            "mae": 0.4107732124475741,
            "precision": 0.5936139332365747,
            "recall": 0.8739316239316239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.651922073257521,
            "auditor_fn_violation": 0.021717746011118335,
            "auditor_fp_violation": 0.009719133514537527,
            "ave_precision_score": 0.6288695831879534,
            "fpr": 0.2050438596491228,
            "logloss": 2.6755023103246405,
            "mae": 0.3953655761517922,
            "precision": 0.626,
            "recall": 0.6440329218106996
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6798605461683446,
            "auditor_fn_violation": 0.03074249204874892,
            "auditor_fp_violation": 0.007944039863915585,
            "ave_precision_score": 0.6591134045257014,
            "fpr": 0.1964873765093304,
            "logloss": 2.2542226426148853,
            "mae": 0.3784867144417491,
            "precision": 0.6286307053941909,
            "recall": 0.6474358974358975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 12498,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.5338063807550806,
            "auditor_fn_violation": 0.035232113204822786,
            "auditor_fp_violation": 0.034912692529445684,
            "ave_precision_score": 0.531282268715413,
            "fpr": 0.16557017543859648,
            "logloss": 0.6949522824075717,
            "mae": 0.4993838395661952,
            "precision": 0.49498327759197325,
            "recall": 0.3045267489711934
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5159627545973795,
            "auditor_fn_violation": 0.03328970699991556,
            "auditor_fp_violation": 0.044167969611445757,
            "ave_precision_score": 0.5141755030183826,
            "fpr": 0.15587266739846323,
            "logloss": 0.6951401973934033,
            "mae": 0.49947272219851563,
            "precision": 0.5086505190311419,
            "recall": 0.3141025641025641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6739248975534189,
            "auditor_fn_violation": 0.00925925925925926,
            "auditor_fp_violation": 0.011392183510419238,
            "ave_precision_score": 0.633705343637237,
            "fpr": 0.20614035087719298,
            "logloss": 5.047439460870008,
            "mae": 0.37800604669902826,
            "precision": 0.6349514563106796,
            "recall": 0.6728395061728395
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6937420128165032,
            "auditor_fn_violation": 0.014804807340482434,
            "auditor_fp_violation": 0.004891308387825753,
            "ave_precision_score": 0.6578427623562841,
            "fpr": 0.2030735455543359,
            "logloss": 4.493320580725497,
            "mae": 0.36955313422826136,
            "precision": 0.6307385229540918,
            "recall": 0.6752136752136753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7431559093431896,
            "auditor_fn_violation": 0.016659446971337814,
            "auditor_fp_violation": 0.030902520385470717,
            "ave_precision_score": 0.7394499794625576,
            "fpr": 0.20394736842105263,
            "logloss": 1.0511410531508174,
            "mae": 0.3984782660646708,
            "precision": 0.654275092936803,
            "recall": 0.7242798353909465
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7535607723046538,
            "auditor_fn_violation": 0.011352228695807185,
            "auditor_fp_violation": 0.024905035768002327,
            "ave_precision_score": 0.7519524342442492,
            "fpr": 0.2074643249176729,
            "logloss": 0.7488255972576362,
            "mae": 0.3909092146555762,
            "precision": 0.653211009174312,
            "recall": 0.7606837606837606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 12498,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7214353661977508,
            "auditor_fn_violation": 0.019245000360984768,
            "auditor_fp_violation": 0.026750782472613463,
            "ave_precision_score": 0.7193100106030377,
            "fpr": 0.2905701754385965,
            "logloss": 0.9874748935131945,
            "mae": 0.4161052543623933,
            "precision": 0.6068249258160238,
            "recall": 0.8415637860082305
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7394692199836582,
            "auditor_fn_violation": 0.016932177470047945,
            "auditor_fp_violation": 0.03403349579877742,
            "ave_precision_score": 0.7379711799075047,
            "fpr": 0.3084522502744237,
            "logloss": 0.7557811494325204,
            "mae": 0.41073478107315503,
            "precision": 0.5927536231884057,
            "recall": 0.8739316239316239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 12498,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.6937774227496332,
            "auditor_fn_violation": 0.0022155440040430453,
            "auditor_fp_violation": 0.0009832386129643357,
            "ave_precision_score": 0.6947900722474167,
            "fpr": 0.0043859649122807015,
            "logloss": 2.7457788680142614,
            "mae": 0.47820857237298164,
            "precision": 0.7142857142857143,
            "recall": 0.0205761316872428
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7151807310825864,
            "auditor_fn_violation": 5.62920431197169e-05,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.715736493695627,
            "fpr": 0.0,
            "logloss": 2.6529461938218724,
            "mae": 0.4627728849745872,
            "precision": 1.0,
            "recall": 0.02564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5754156609961143,
            "auditor_fn_violation": 0.009868421052631578,
            "auditor_fp_violation": 0.011706202125030898,
            "ave_precision_score": 0.5688243714224104,
            "fpr": 0.4342105263157895,
            "logloss": 2.5103880269259897,
            "mae": 0.46237691851063123,
            "precision": 0.5416666666666666,
            "recall": 0.9629629629629629
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6017082187214503,
            "auditor_fn_violation": 0.00804976216611782,
            "auditor_fp_violation": 0.011586503556977304,
            "ave_precision_score": 0.5984008642554981,
            "fpr": 0.4456641053787047,
            "logloss": 2.2174804339161795,
            "mae": 0.4627834203539453,
            "precision": 0.52954808806489,
            "recall": 0.9764957264957265
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7214599506957549,
            "auditor_fn_violation": 0.019646595913652448,
            "auditor_fp_violation": 0.028009430854130633,
            "ave_precision_score": 0.7186001486174615,
            "fpr": 0.29385964912280704,
            "logloss": 1.0092480419510357,
            "mae": 0.4158915674548822,
            "precision": 0.604135893648449,
            "recall": 0.8415637860082305
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7409087216204784,
            "auditor_fn_violation": 0.015825100622027077,
            "auditor_fp_violation": 0.03319597693601902,
            "ave_precision_score": 0.7394080872818842,
            "fpr": 0.30735455543358947,
            "logloss": 0.7575416123444867,
            "mae": 0.41063639901964527,
            "precision": 0.5947901591895803,
            "recall": 0.8782051282051282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6913259595359807,
            "auditor_fn_violation": 0.0205761316872428,
            "auditor_fp_violation": 0.009873568898772764,
            "ave_precision_score": 0.6887085830930118,
            "fpr": 0.1962719298245614,
            "logloss": 4.768903884840767,
            "mae": 0.3553541142763312,
            "precision": 0.6577437858508605,
            "recall": 0.7078189300411523
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7176723526063149,
            "auditor_fn_violation": 0.01696501449520111,
            "auditor_fp_violation": 0.009257309086584098,
            "ave_precision_score": 0.7156069311124784,
            "fpr": 0.21514818880351264,
            "logloss": 4.461004126042644,
            "mae": 0.36302509823249524,
            "precision": 0.6280834914611005,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6759936885572638,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.010115517667407961,
            "ave_precision_score": 0.6349599237633619,
            "fpr": 0.21271929824561403,
            "logloss": 4.972574714795924,
            "mae": 0.37583121199568614,
            "precision": 0.6414048059149723,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6961039984276545,
            "auditor_fn_violation": 0.016078414816065756,
            "auditor_fp_violation": 2.9734397494390745e-05,
            "ave_precision_score": 0.6593854531177612,
            "fpr": 0.21514818880351264,
            "logloss": 4.426044926760954,
            "mae": 0.3710991989635066,
            "precision": 0.6252390057361377,
            "recall": 0.6987179487179487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6913178026577961,
            "auditor_fn_violation": 0.0205761316872428,
            "auditor_fp_violation": 0.009873568898772764,
            "ave_precision_score": 0.6887061261711234,
            "fpr": 0.1962719298245614,
            "logloss": 4.768885457465875,
            "mae": 0.3553539671291058,
            "precision": 0.6577437858508605,
            "recall": 0.7078189300411523
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7176758715432817,
            "auditor_fn_violation": 0.01696501449520111,
            "auditor_fp_violation": 0.009257309086584098,
            "ave_precision_score": 0.7156104464305166,
            "fpr": 0.21514818880351264,
            "logloss": 4.460960795055422,
            "mae": 0.3630234154178619,
            "precision": 0.6280834914611005,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.673541661554919,
            "auditor_fn_violation": 0.010894971482203447,
            "auditor_fp_violation": 0.012362552508030636,
            "ave_precision_score": 0.6343717421417701,
            "fpr": 0.19407894736842105,
            "logloss": 5.018050078499699,
            "mae": 0.3784411313042228,
            "precision": 0.6431451612903226,
            "recall": 0.6563786008230452
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.692690647624835,
            "auditor_fn_violation": 0.016425549081970605,
            "auditor_fp_violation": 0.0033575090504072394,
            "ave_precision_score": 0.6570283239276262,
            "fpr": 0.1986827661909989,
            "logloss": 4.497465167327319,
            "mae": 0.36874077234306524,
            "precision": 0.6321138211382114,
            "recall": 0.6645299145299145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5741108007023281,
            "auditor_fn_violation": 0.0008866688325752654,
            "auditor_fp_violation": 0.006370459599703484,
            "ave_precision_score": 0.5777989665056863,
            "fpr": 0.41776315789473684,
            "logloss": 2.269348768675313,
            "mae": 0.4360476528996961,
            "precision": 0.5580046403712297,
            "recall": 0.9897119341563786
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5768682209684749,
            "auditor_fn_violation": 0.0018294914013904137,
            "auditor_fp_violation": 0.014810207818659837,
            "ave_precision_score": 0.5796891865861216,
            "fpr": 0.4313940724478595,
            "logloss": 2.2911606143120578,
            "mae": 0.45420067092458977,
            "precision": 0.5392731535756154,
            "recall": 0.9829059829059829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6754959856956572,
            "auditor_fn_violation": 0.008943397588621761,
            "auditor_fp_violation": 0.011335557202866326,
            "ave_precision_score": 0.6329596131435736,
            "fpr": 0.22039473684210525,
            "logloss": 5.072659900282183,
            "mae": 0.3775111041574024,
            "precision": 0.6352087114337568,
            "recall": 0.720164609053498
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6954709332788767,
            "auditor_fn_violation": 0.014687532250649707,
            "auditor_fp_violation": 0.003409544246022411,
            "ave_precision_score": 0.6575276992380095,
            "fpr": 0.22283205268935236,
            "logloss": 4.510876572863931,
            "mae": 0.3730173954027201,
            "precision": 0.6198501872659176,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.5807786697494347,
            "auditor_fn_violation": 0.004297974875460257,
            "auditor_fp_violation": 0.015482147269582417,
            "ave_precision_score": 0.5837600623302188,
            "fpr": 0.3782894736842105,
            "logloss": 1.798964227856428,
            "mae": 0.4124624590918655,
            "precision": 0.573019801980198,
            "recall": 0.9526748971193416
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5604513220654177,
            "auditor_fn_violation": 0.0033118485368759804,
            "auditor_fp_violation": 0.02076204305045185,
            "ave_precision_score": 0.5642580142467573,
            "fpr": 0.40285400658616904,
            "logloss": 1.8807640589231747,
            "mae": 0.43024866929909367,
            "precision": 0.5518925518925519,
            "recall": 0.9658119658119658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.685526243116406,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.009950786590890373,
            "ave_precision_score": 0.6228339181248794,
            "fpr": 0.23903508771929824,
            "logloss": 6.163665742246346,
            "mae": 0.39570172087110417,
            "precision": 0.6141592920353982,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6948503756233387,
            "auditor_fn_violation": 0.011469503785639906,
            "auditor_fp_violation": 0.004715379869317328,
            "ave_precision_score": 0.6371224385015765,
            "fpr": 0.2414928649835346,
            "logloss": 5.499810638578491,
            "mae": 0.38871255159186224,
            "precision": 0.6028880866425993,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5577082448085137,
            "auditor_fn_violation": 0.003587286116525883,
            "auditor_fp_violation": 0.004880158141833474,
            "ave_precision_score": 0.5583446975518256,
            "fpr": 0.45394736842105265,
            "logloss": 0.6902104065767211,
            "mae": 0.4968525979406478,
            "precision": 0.5369127516778524,
            "recall": 0.9876543209876543
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.517974744395034,
            "auditor_fn_violation": 0.0016746882828112247,
            "auditor_fp_violation": 0.002609193380131981,
            "ave_precision_score": 0.5175200827113261,
            "fpr": 0.47859495060373214,
            "logloss": 0.6917341928005711,
            "mae": 0.4982262336363777,
            "precision": 0.516093229744728,
            "recall": 0.9935897435897436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5716069212335283,
            "auditor_fn_violation": 0.02612627247130172,
            "auditor_fp_violation": 0.030601371386212012,
            "ave_precision_score": 0.5611641691649097,
            "fpr": 0.13486842105263158,
            "logloss": 2.199027399091767,
            "mae": 0.4961529843705265,
            "precision": 0.6019417475728155,
            "recall": 0.38271604938271603
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5842161509108882,
            "auditor_fn_violation": 0.031467252103915114,
            "auditor_fp_violation": 0.030383598506342098,
            "ave_precision_score": 0.5693964637055264,
            "fpr": 0.12733260153677278,
            "logloss": 1.9628256093029373,
            "mae": 0.4852489251827435,
            "precision": 0.6270096463022508,
            "recall": 0.4166666666666667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6859066630489867,
            "auditor_fn_violation": 0.010342213558587835,
            "auditor_fp_violation": 0.01163928012519563,
            "ave_precision_score": 0.6232354698736785,
            "fpr": 0.23464912280701755,
            "logloss": 6.167224553425743,
            "mae": 0.3951008455034079,
            "precision": 0.6171735241502684,
            "recall": 0.7098765432098766
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.694672367607009,
            "auditor_fn_violation": 0.01258127163725408,
            "auditor_fp_violation": 0.010176597542452051,
            "ave_precision_score": 0.637054532745945,
            "fpr": 0.24368825466520308,
            "logloss": 5.505974355980928,
            "mae": 0.38778769719421285,
            "precision": 0.6,
            "recall": 0.7115384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.685529245336902,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.009950786590890373,
            "ave_precision_score": 0.6228388775301241,
            "fpr": 0.23903508771929824,
            "logloss": 6.164083331774888,
            "mae": 0.39570293996754413,
            "precision": 0.6141592920353982,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.694854739305313,
            "auditor_fn_violation": 0.011469503785639906,
            "auditor_fp_violation": 0.004715379869317328,
            "ave_precision_score": 0.6371267965018328,
            "fpr": 0.2414928649835346,
            "logloss": 5.500344451421069,
            "mae": 0.3887373729591057,
            "precision": 0.6028880866425993,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5639152740698216,
            "auditor_fn_violation": 0.025061367410295295,
            "auditor_fp_violation": 0.028992669467094973,
            "ave_precision_score": 0.5424792407956509,
            "fpr": 0.08442982456140351,
            "logloss": 0.6956259164461893,
            "mae": 0.49914093054177466,
            "precision": 0.5333333333333333,
            "recall": 0.18106995884773663
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.550647694166202,
            "auditor_fn_violation": 0.018660812294182226,
            "auditor_fp_violation": 0.030482713164656706,
            "ave_precision_score": 0.528092263846427,
            "fpr": 0.07683863885839737,
            "logloss": 0.6935263326908744,
            "mae": 0.49818554864102477,
            "precision": 0.5625,
            "recall": 0.19230769230769232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5637615045345921,
            "auditor_fn_violation": 0.04495614035087719,
            "auditor_fp_violation": 0.035962853142245295,
            "ave_precision_score": 0.542241948120787,
            "fpr": 0.1425438596491228,
            "logloss": 0.6939507485993024,
            "mae": 0.4991075667111497,
            "precision": 0.5547945205479452,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5295921996954805,
            "auditor_fn_violation": 0.03821291527109311,
            "auditor_fp_violation": 0.04479734769174351,
            "ave_precision_score": 0.5170765388575439,
            "fpr": 0.1394072447859495,
            "logloss": 0.6946389238299876,
            "mae": 0.49944243420622875,
            "precision": 0.549645390070922,
            "recall": 0.3311965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6907609486454614,
            "auditor_fn_violation": 0.0205761316872428,
            "auditor_fp_violation": 0.009873568898772764,
            "ave_precision_score": 0.6882278922780807,
            "fpr": 0.1962719298245614,
            "logloss": 4.767752892141375,
            "mae": 0.35567418434234727,
            "precision": 0.6577437858508605,
            "recall": 0.7078189300411523
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7170995165743133,
            "auditor_fn_violation": 0.016592079709533063,
            "auditor_fp_violation": 0.009257309086584098,
            "ave_precision_score": 0.7150226956344016,
            "fpr": 0.21514818880351264,
            "logloss": 4.459416423413109,
            "mae": 0.36331718849833033,
            "precision": 0.6273764258555133,
            "recall": 0.7051282051282052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6977268357212717,
            "auditor_fn_violation": 0.020287343874088516,
            "auditor_fp_violation": 0.013425582736183182,
            "ave_precision_score": 0.677590455247568,
            "fpr": 0.18530701754385964,
            "logloss": 5.454861067096986,
            "mae": 0.35751053149618617,
            "precision": 0.6640159045725647,
            "recall": 0.6872427983539094
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7055278476024575,
            "auditor_fn_violation": 0.02126431928846858,
            "auditor_fp_violation": 0.00925483122012623,
            "ave_precision_score": 0.6883470955064095,
            "fpr": 0.20417124039517015,
            "logloss": 5.128164950738929,
            "mae": 0.364280829918487,
            "precision": 0.6331360946745562,
            "recall": 0.6858974358974359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6797645498027797,
            "auditor_fn_violation": 0.007659645512959358,
            "auditor_fp_violation": 0.01179114158636027,
            "ave_precision_score": 0.6151160313011779,
            "fpr": 0.2598684210526316,
            "logloss": 6.106063512415649,
            "mae": 0.39992331025130157,
            "precision": 0.606312292358804,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6885933929013783,
            "auditor_fn_violation": 0.008190492273917086,
            "auditor_fp_violation": 0.006610947709584133,
            "ave_precision_score": 0.6287692814235305,
            "fpr": 0.265642151481888,
            "logloss": 5.448595904325319,
            "mae": 0.39487810294193265,
            "precision": 0.5898305084745763,
            "recall": 0.7435897435897436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6818800911364016,
            "auditor_fn_violation": 0.006432297307053647,
            "auditor_fp_violation": 0.01301118112181865,
            "ave_precision_score": 0.6198557810113963,
            "fpr": 0.2642543859649123,
            "logloss": 5.908164098397874,
            "mae": 0.39792959781327997,
            "precision": 0.6062091503267973,
            "recall": 0.7633744855967078
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6943607628497881,
            "auditor_fn_violation": 0.0066166605683619945,
            "auditor_fp_violation": 0.009814829039603755,
            "ave_precision_score": 0.637281752588948,
            "fpr": 0.2623490669593853,
            "logloss": 5.232915459900287,
            "mae": 0.39115825574274316,
            "precision": 0.5935374149659864,
            "recall": 0.7457264957264957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6902001824089874,
            "auditor_fn_violation": 0.009245722330517653,
            "auditor_fp_violation": 0.014933901655547333,
            "ave_precision_score": 0.6421056059147412,
            "fpr": 0.23464912280701755,
            "logloss": 5.171614311328908,
            "mae": 0.3729225937704761,
            "precision": 0.6310344827586207,
            "recall": 0.7530864197530864
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7102534712546573,
            "auditor_fn_violation": 0.013449107302016199,
            "auditor_fp_violation": 0.0014198174803567167,
            "ave_precision_score": 0.6678274065155604,
            "fpr": 0.23929747530186607,
            "logloss": 4.573054815686455,
            "mae": 0.37249436143661246,
            "precision": 0.6134751773049646,
            "recall": 0.7393162393162394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6855242873437404,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.009950786590890373,
            "ave_precision_score": 0.6228339181248794,
            "fpr": 0.23903508771929824,
            "logloss": 6.163674864400795,
            "mae": 0.39570184735584696,
            "precision": 0.6141592920353982,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6948503756233387,
            "auditor_fn_violation": 0.011469503785639906,
            "auditor_fp_violation": 0.004715379869317328,
            "ave_precision_score": 0.6371224385015765,
            "fpr": 0.2414928649835346,
            "logloss": 5.4998158252908596,
            "mae": 0.3887132783935424,
            "precision": 0.6028880866425993,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5744037381034285,
            "auditor_fn_violation": 0.026478232618583522,
            "auditor_fp_violation": 0.029075035005353758,
            "ave_precision_score": 0.5322497420020641,
            "fpr": 0.08771929824561403,
            "logloss": 0.6947297116697523,
            "mae": 0.4995317927708751,
            "precision": 0.5294117647058824,
            "recall": 0.18518518518518517
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5614026431873659,
            "auditor_fn_violation": 0.009766669481268822,
            "auditor_fp_violation": 0.031035277384760623,
            "ave_precision_score": 0.5144593839111822,
            "fpr": 0.09001097694840834,
            "logloss": 0.6949303451969187,
            "mae": 0.4996277177961938,
            "precision": 0.5176470588235295,
            "recall": 0.18803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 12498,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7009461632825196,
            "auditor_fn_violation": 0.019046458739441198,
            "auditor_fp_violation": 0.011824602586277905,
            "ave_precision_score": 0.6822457559878968,
            "fpr": 0.18640350877192982,
            "logloss": 5.410188422966163,
            "mae": 0.3575577008581655,
            "precision": 0.6606786427145709,
            "recall": 0.6810699588477366
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7093514289482434,
            "auditor_fn_violation": 0.020537213731505726,
            "auditor_fp_violation": 0.009782616775651497,
            "ave_precision_score": 0.6930876987641335,
            "fpr": 0.2052689352360044,
            "logloss": 5.101410797443287,
            "mae": 0.36394303629517605,
            "precision": 0.6326129666011788,
            "recall": 0.688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6841408927612961,
            "auditor_fn_violation": 0.008316186556927303,
            "auditor_fp_violation": 0.012921093814348077,
            "ave_precision_score": 0.6421496701983149,
            "fpr": 0.21600877192982457,
            "logloss": 4.856309323637519,
            "mae": 0.37088856196637304,
            "precision": 0.6411657559198543,
            "recall": 0.7242798353909465
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7066202743738867,
            "auditor_fn_violation": 0.014513965117697283,
            "auditor_fp_violation": 0.004353611366469015,
            "ave_precision_score": 0.6701180328111215,
            "fpr": 0.2239297475301866,
            "logloss": 4.254064409195284,
            "mae": 0.3683687402624822,
            "precision": 0.6236162361623616,
            "recall": 0.7222222222222222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6776512430589798,
            "auditor_fn_violation": 0.009342736986499177,
            "auditor_fp_violation": 0.011953298739807276,
            "ave_precision_score": 0.6373996382695509,
            "fpr": 0.2236842105263158,
            "logloss": 4.839993015793572,
            "mae": 0.3755157969700764,
            "precision": 0.6337522441651705,
            "recall": 0.7263374485596708
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6989005902748047,
            "auditor_fn_violation": 0.01742707834914202,
            "auditor_fp_violation": 0.0009019433906629074,
            "ave_precision_score": 0.6626665400594745,
            "fpr": 0.2239297475301866,
            "logloss": 4.305768503666026,
            "mae": 0.370679549359524,
            "precision": 0.620817843866171,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6986693112898025,
            "auditor_fn_violation": 0.008347772723991051,
            "auditor_fp_violation": 0.015057449962935517,
            "ave_precision_score": 0.6466361392164646,
            "fpr": 0.23684210526315788,
            "logloss": 5.396222381601026,
            "mae": 0.3725823629375265,
            "precision": 0.6301369863013698,
            "recall": 0.757201646090535
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7081552533643913,
            "auditor_fn_violation": 0.012130935292296436,
            "auditor_fp_violation": 0.002812378429676919,
            "ave_precision_score": 0.6608668976179833,
            "fpr": 0.2414928649835346,
            "logloss": 4.928705589634121,
            "mae": 0.3735896434196223,
            "precision": 0.6126760563380281,
            "recall": 0.7435897435897436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6993483585465999,
            "auditor_fn_violation": 0.019005847953216384,
            "auditor_fp_violation": 0.009111687669878925,
            "ave_precision_score": 0.6803006022746143,
            "fpr": 0.1875,
            "logloss": 5.407712999061146,
            "mae": 0.3570982824136078,
            "precision": 0.6607142857142857,
            "recall": 0.6851851851851852
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7043582505465688,
            "auditor_fn_violation": 0.020537213731505726,
            "auditor_fp_violation": 0.009740493045867792,
            "ave_precision_score": 0.6872967017863214,
            "fpr": 0.2030735455543359,
            "logloss": 5.123899096961024,
            "mae": 0.3636508442317613,
            "precision": 0.6351084812623274,
            "recall": 0.688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 12498,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6815164292668074,
            "auditor_fn_violation": 0.0069512129088152505,
            "auditor_fp_violation": 0.014625030887076852,
            "ave_precision_score": 0.6194854617873242,
            "fpr": 0.2675438596491228,
            "logloss": 5.887642207435795,
            "mae": 0.3993047643397535,
            "precision": 0.6032520325203252,
            "recall": 0.7633744855967078
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6935739687829021,
            "auditor_fn_violation": 0.005347744096371978,
            "auditor_fp_violation": 0.006494487986064486,
            "ave_precision_score": 0.6365819406140103,
            "fpr": 0.2645444566410538,
            "logloss": 5.208165962220124,
            "mae": 0.3918969630528616,
            "precision": 0.5935919055649241,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6349833112361802,
            "auditor_fn_violation": 0.0032894736842105413,
            "auditor_fp_violation": 0.0017708590725640397,
            "ave_precision_score": 0.6361160418137832,
            "fpr": 0.007675438596491228,
            "logloss": 1.0229456372201997,
            "mae": 0.4934671573216057,
            "precision": 0.631578947368421,
            "recall": 0.024691358024691357
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.642260268449248,
            "auditor_fn_violation": 0.001217315432463634,
            "auditor_fp_violation": 0.0010060137818932388,
            "ave_precision_score": 0.6432385286653697,
            "fpr": 0.0021953896816684962,
            "logloss": 0.859250316626332,
            "mae": 0.4795422166901884,
            "precision": 0.8823529411764706,
            "recall": 0.03205128205128205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6347448175660193,
            "auditor_fn_violation": 0.0032894736842105413,
            "auditor_fp_violation": 0.0017708590725640397,
            "ave_precision_score": 0.6358789921791619,
            "fpr": 0.007675438596491228,
            "logloss": 1.0199879371308676,
            "mae": 0.49334475947825734,
            "precision": 0.631578947368421,
            "recall": 0.024691358024691357
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6419787954676243,
            "auditor_fn_violation": 0.001217315432463634,
            "auditor_fp_violation": 0.0010060137818932388,
            "ave_precision_score": 0.6429685959745218,
            "fpr": 0.0021953896816684962,
            "logloss": 0.8570231988770028,
            "mae": 0.47945507014322253,
            "precision": 0.8823529411764706,
            "recall": 0.03205128205128205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 12498,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.6348602087993381,
            "auditor_fn_violation": 0.0004986102086492062,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6360674573084477,
            "fpr": 0.0,
            "logloss": 1.0251244538041249,
            "mae": 0.4975482558218294,
            "precision": 1.0,
            "recall": 0.00205761316872428
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8640975005164377,
            "mae": 0.48459563994898736,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7506222907530322,
            "auditor_fn_violation": 0.04186746444300051,
            "auditor_fp_violation": 0.053439790791532826,
            "ave_precision_score": 0.7451106156382452,
            "fpr": 0.23903508771929824,
            "logloss": 1.247384606780356,
            "mae": 0.3816014741805795,
            "precision": 0.6420361247947455,
            "recall": 0.8045267489711934
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7599968072679719,
            "auditor_fn_violation": 0.03667426609248783,
            "auditor_fp_violation": 0.054822795380265785,
            "ave_precision_score": 0.7574680889220834,
            "fpr": 0.26125137211855104,
            "logloss": 0.8753031362211287,
            "mae": 0.3746380983508051,
            "precision": 0.6198083067092651,
            "recall": 0.8290598290598291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5732953988005391,
            "auditor_fn_violation": 0.02612627247130172,
            "auditor_fp_violation": 0.031134173461823577,
            "ave_precision_score": 0.5629285912953315,
            "fpr": 0.1337719298245614,
            "logloss": 2.1617664596509227,
            "mae": 0.49552857619301793,
            "precision": 0.6038961038961039,
            "recall": 0.38271604938271603
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5874984377508241,
            "auditor_fn_violation": 0.031467252103915114,
            "auditor_fp_violation": 0.025041318423184904,
            "ave_precision_score": 0.5726768440684104,
            "fpr": 0.12623490669593854,
            "logloss": 1.9598811461578143,
            "mae": 0.48336000313612293,
            "precision": 0.6290322580645161,
            "recall": 0.4166666666666667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 12498,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7010036730884718,
            "auditor_fn_violation": 0.019046458739441198,
            "auditor_fp_violation": 0.011824602586277905,
            "ave_precision_score": 0.6822685890874913,
            "fpr": 0.18640350877192982,
            "logloss": 5.410596023460359,
            "mae": 0.3575780716550337,
            "precision": 0.6606786427145709,
            "recall": 0.6810699588477366
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7094220692746833,
            "auditor_fn_violation": 0.020537213731505726,
            "auditor_fp_violation": 0.00846191395360939,
            "ave_precision_score": 0.6931949407711258,
            "fpr": 0.2030735455543359,
            "logloss": 5.1016121156434275,
            "mae": 0.36388753880290625,
            "precision": 0.6351084812623274,
            "recall": 0.688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.685322564169137,
            "auditor_fn_violation": 0.009141939210165336,
            "auditor_fp_violation": 0.011335557202866324,
            "ave_precision_score": 0.6231988223627918,
            "fpr": 0.23684210526315788,
            "logloss": 6.136443176267841,
            "mae": 0.39597374180394984,
            "precision": 0.6156583629893239,
            "recall": 0.7119341563786008
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6941247041723215,
            "auditor_fn_violation": 0.012440541529454818,
            "auditor_fp_violation": 0.002016983296702208,
            "ave_precision_score": 0.6365272872291868,
            "fpr": 0.24039517014270034,
            "logloss": 5.491126413366404,
            "mae": 0.38827159311195775,
            "precision": 0.6025408348457351,
            "recall": 0.7094017094017094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 12498,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.6192004464420879,
            "auditor_fn_violation": 0.007470128510576866,
            "auditor_fp_violation": 0.011155382587925214,
            "ave_precision_score": 0.5436444743756218,
            "fpr": 0.31359649122807015,
            "logloss": 0.6968554770239641,
            "mae": 0.49595097542266575,
            "precision": 0.5111111111111111,
            "recall": 0.6152263374485597
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.6101304106043315,
            "auditor_fn_violation": 0.002917804235038051,
            "auditor_fp_violation": 0.01558825788642948,
            "ave_precision_score": 0.5267746691952218,
            "fpr": 0.3216245883644347,
            "logloss": 0.6896166314165312,
            "mae": 0.4939470125278448,
            "precision": 0.5025466893039049,
            "recall": 0.6324786324786325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7001903381440373,
            "auditor_fn_violation": 0.019966969893870486,
            "auditor_fp_violation": 0.01828514949345194,
            "ave_precision_score": 0.6775813936922406,
            "fpr": 0.18311403508771928,
            "logloss": 5.6020979498950485,
            "mae": 0.35688024675292024,
            "precision": 0.6639839034205232,
            "recall": 0.6790123456790124
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7022289348422847,
            "auditor_fn_violation": 0.02126431928846858,
            "auditor_fp_violation": 0.008806337391252639,
            "ave_precision_score": 0.6827401654644234,
            "fpr": 0.2052689352360044,
            "logloss": 5.280312976909856,
            "mae": 0.3641030032941258,
            "precision": 0.6318897637795275,
            "recall": 0.6858974358974359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.685529245336902,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.009950786590890373,
            "ave_precision_score": 0.6228388775301241,
            "fpr": 0.23903508771929824,
            "logloss": 6.164075895063667,
            "mae": 0.39570286163981294,
            "precision": 0.6141592920353982,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6948591813513159,
            "auditor_fn_violation": 0.011469503785639906,
            "auditor_fp_violation": 0.004715379869317328,
            "ave_precision_score": 0.6371332726549226,
            "fpr": 0.2414928649835346,
            "logloss": 5.50033508087524,
            "mae": 0.38873732566244906,
            "precision": 0.6028880866425993,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6859037952235305,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.01062515443538423,
            "ave_precision_score": 0.6230764972706219,
            "fpr": 0.24013157894736842,
            "logloss": 6.1826351236553485,
            "mae": 0.39611743870761945,
            "precision": 0.6130742049469965,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6946155821141905,
            "auditor_fn_violation": 0.011469503785639906,
            "auditor_fp_violation": 0.010176597542452051,
            "ave_precision_score": 0.636870124848786,
            "fpr": 0.24368825466520308,
            "logloss": 5.519243999519566,
            "mae": 0.3893348146398071,
            "precision": 0.6007194244604317,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7004022166881355,
            "auditor_fn_violation": 0.019745866724424237,
            "auditor_fp_violation": 0.019188596491228074,
            "ave_precision_score": 0.6844141301300095,
            "fpr": 0.18311403508771928,
            "logloss": 5.294350668216977,
            "mae": 0.3561131441307689,
            "precision": 0.6646586345381527,
            "recall": 0.6810699588477366
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7113937358509179,
            "auditor_fn_violation": 0.020537213731505726,
            "auditor_fp_violation": 0.00875182432917961,
            "ave_precision_score": 0.6983147441543489,
            "fpr": 0.19978046103183314,
            "logloss": 4.966315182150315,
            "mae": 0.3623658626217167,
            "precision": 0.6388888888888888,
            "recall": 0.688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 12498,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6777705935634437,
            "auditor_fn_violation": 0.009342736986499177,
            "auditor_fp_violation": 0.012110308047113093,
            "ave_precision_score": 0.6371567937933041,
            "fpr": 0.2225877192982456,
            "logloss": 4.854545066848198,
            "mae": 0.3743842259444464,
            "precision": 0.6348920863309353,
            "recall": 0.7263374485596708
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6997488607019631,
            "auditor_fn_violation": 0.01742707834914202,
            "auditor_fp_violation": 0.0009019433906629074,
            "ave_precision_score": 0.6634146085927132,
            "fpr": 0.2239297475301866,
            "logloss": 4.302374578494316,
            "mae": 0.37037269842870535,
            "precision": 0.620817843866171,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6759367891567474,
            "auditor_fn_violation": 0.009640549418814535,
            "auditor_fp_violation": 0.010115517667407961,
            "ave_precision_score": 0.634941646799378,
            "fpr": 0.21271929824561403,
            "logloss": 4.976824093276722,
            "mae": 0.3758340144308268,
            "precision": 0.6414048059149723,
            "recall": 0.7139917695473251
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6954584953476329,
            "auditor_fn_violation": 0.016078414816065756,
            "auditor_fp_violation": 2.9734397494390745e-05,
            "ave_precision_score": 0.6582732768423206,
            "fpr": 0.21514818880351264,
            "logloss": 4.450498324140212,
            "mae": 0.3711760339957488,
            "precision": 0.6252390057361377,
            "recall": 0.6987179487179487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6619766947352681,
            "auditor_fn_violation": 0.01487257237744567,
            "auditor_fp_violation": 0.015227328885594273,
            "ave_precision_score": 0.6412292260590753,
            "fpr": 0.2050438596491228,
            "logloss": 5.688933451811942,
            "mae": 0.36762612745197404,
            "precision": 0.6471698113207547,
            "recall": 0.7057613168724279
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6808622123303764,
            "auditor_fn_violation": 0.014354470995524785,
            "auditor_fp_violation": 0.011685618215291911,
            "ave_precision_score": 0.6654703843685901,
            "fpr": 0.22283205268935236,
            "logloss": 5.181050489953647,
            "mae": 0.3744289082806682,
            "precision": 0.6148007590132827,
            "recall": 0.6923076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5579099248536322,
            "auditor_fn_violation": 0.04495614035087719,
            "auditor_fp_violation": 0.03519582406721028,
            "ave_precision_score": 0.5388686988765616,
            "fpr": 0.14473684210526316,
            "logloss": 0.6943595329541052,
            "mae": 0.49932654143164035,
            "precision": 0.5510204081632653,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5284888376571927,
            "auditor_fn_violation": 0.03821291527109311,
            "auditor_fp_violation": 0.04479734769174351,
            "ave_precision_score": 0.5163000054275065,
            "fpr": 0.1394072447859495,
            "logloss": 0.6947199955126259,
            "mae": 0.4994837096376032,
            "precision": 0.549645390070922,
            "recall": 0.3311965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6900505343904094,
            "auditor_fn_violation": 0.008647841311096674,
            "auditor_fp_violation": 0.015556791038629444,
            "ave_precision_score": 0.6420010228302497,
            "fpr": 0.23903508771929824,
            "logloss": 5.1727488026241835,
            "mae": 0.37397814263291385,
            "precision": 0.6273504273504273,
            "recall": 0.7551440329218106
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7102047831124224,
            "auditor_fn_violation": 0.01300815296424517,
            "auditor_fp_violation": 0.0019178686383876055,
            "ave_precision_score": 0.6677829300031759,
            "fpr": 0.24368825466520308,
            "logloss": 4.577277050913812,
            "mae": 0.37353220117803615,
            "precision": 0.6118881118881119,
            "recall": 0.7478632478632479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 12498,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6519325026931513,
            "auditor_fn_violation": 0.022218612374557793,
            "auditor_fp_violation": 0.009719133514537527,
            "ave_precision_score": 0.628879941032338,
            "fpr": 0.2050438596491228,
            "logloss": 2.671664139064221,
            "mae": 0.3954249936412902,
            "precision": 0.626746506986028,
            "recall": 0.6460905349794238
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6800837643335872,
            "auditor_fn_violation": 0.03248050888006981,
            "auditor_fp_violation": 0.007944039863915585,
            "ave_precision_score": 0.6593365145045504,
            "fpr": 0.1964873765093304,
            "logloss": 2.2501871820997343,
            "mae": 0.378018744034068,
            "precision": 0.6286307053941909,
            "recall": 0.6474358974358975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6856405682252613,
            "auditor_fn_violation": 0.009435239332900164,
            "auditor_fp_violation": 0.011036982126678196,
            "ave_precision_score": 0.6429997975168125,
            "fpr": 0.2149122807017544,
            "logloss": 4.8690794093661856,
            "mae": 0.36964454689824927,
            "precision": 0.6429872495446266,
            "recall": 0.7263374485596708
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7070975635195558,
            "auditor_fn_violation": 0.01586731965436686,
            "auditor_fp_violation": 0.004353611366469015,
            "ave_precision_score": 0.6700494624118276,
            "fpr": 0.2239297475301866,
            "logloss": 4.2715467215468506,
            "mae": 0.3671336542914949,
            "precision": 0.6243093922651933,
            "recall": 0.7243589743589743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6615129077603047,
            "auditor_fn_violation": 0.01487257237744567,
            "auditor_fp_violation": 0.016390742113499716,
            "ave_precision_score": 0.6412758244181607,
            "fpr": 0.20614035087719298,
            "logloss": 5.788378523767529,
            "mae": 0.3678581681184655,
            "precision": 0.6459510357815442,
            "recall": 0.7057613168724279
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.680618778134058,
            "auditor_fn_violation": 0.01472740578119284,
            "auditor_fp_violation": 0.013858707098839617,
            "ave_precision_score": 0.6645324932216654,
            "fpr": 0.2239297475301866,
            "logloss": 5.30826786466488,
            "mae": 0.37561512070101377,
            "precision": 0.6143667296786389,
            "recall": 0.6944444444444444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6927221899489409,
            "auditor_fn_violation": 0.02233593242365172,
            "auditor_fp_violation": 0.03206078576723499,
            "ave_precision_score": 0.6933803899674034,
            "fpr": 0.3092105263157895,
            "logloss": 0.6652681302449849,
            "mae": 0.4345155648840905,
            "precision": 0.5948275862068966,
            "recall": 0.8518518518518519
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7007007129275523,
            "auditor_fn_violation": 0.012454614540234742,
            "auditor_fp_violation": 0.031198816570979726,
            "ave_precision_score": 0.7012348236046011,
            "fpr": 0.3227222832052689,
            "logloss": 0.6670770900301016,
            "mae": 0.4359659342057304,
            "precision": 0.5847457627118644,
            "recall": 0.8846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7004576750869089,
            "auditor_fn_violation": 0.019533788174139057,
            "auditor_fp_violation": 0.01425438596491228,
            "ave_precision_score": 0.681888994762522,
            "fpr": 0.18640350877192982,
            "logloss": 5.347787112048142,
            "mae": 0.3583230469716193,
            "precision": 0.6626984126984127,
            "recall": 0.6872427983539094
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7151422030149421,
            "auditor_fn_violation": 0.020537213731505726,
            "auditor_fp_violation": 0.0060732506882274105,
            "ave_precision_score": 0.7015369590206016,
            "fpr": 0.20087815587266739,
            "logloss": 4.951695696183265,
            "mae": 0.36223891601747465,
            "precision": 0.6376237623762376,
            "recall": 0.688034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6056189409296319,
            "auditor_fn_violation": 0.017922893653887814,
            "auditor_fp_violation": 0.01764424264887572,
            "ave_precision_score": 0.5920197619479138,
            "fpr": 0.20065789473684212,
            "logloss": 5.932581271681664,
            "mae": 0.37806832996606876,
            "precision": 0.642578125,
            "recall": 0.676954732510288
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.600809089377699,
            "auditor_fn_violation": 0.02165836359030651,
            "auditor_fp_violation": 0.006871123687659978,
            "ave_precision_score": 0.5942681804913417,
            "fpr": 0.21844127332601537,
            "logloss": 5.468731612706407,
            "mae": 0.38412062422776877,
            "precision": 0.6143410852713178,
            "recall": 0.6773504273504274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 12498,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6531841824310336,
            "auditor_fn_violation": 0.02425817630495993,
            "auditor_fp_violation": 0.010609710896960715,
            "ave_precision_score": 0.6305286444810452,
            "fpr": 0.20065789473684212,
            "logloss": 2.65793016243669,
            "mae": 0.39460256555000806,
            "precision": 0.6288032454361054,
            "recall": 0.6378600823045267
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6804004728279356,
            "auditor_fn_violation": 0.03282764314597466,
            "auditor_fp_violation": 0.00839748942570489,
            "ave_precision_score": 0.6596528004938667,
            "fpr": 0.19319429198682767,
            "logloss": 2.257771939147827,
            "mae": 0.37739618549349924,
            "precision": 0.6310272536687631,
            "recall": 0.6431623931623932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6580018783679616,
            "auditor_fn_violation": 0.018383149231102455,
            "auditor_fp_violation": 0.017806399802322712,
            "ave_precision_score": 0.6365400058237667,
            "fpr": 0.20723684210526316,
            "logloss": 5.781258639391071,
            "mae": 0.3695247649764109,
            "precision": 0.6454033771106942,
            "recall": 0.7078189300411523
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6741119694723818,
            "auditor_fn_violation": 0.014354470995524785,
            "auditor_fp_violation": 0.012171280041033475,
            "ave_precision_score": 0.6578421409401851,
            "fpr": 0.22063666300768386,
            "logloss": 5.283876642833975,
            "mae": 0.3762462839501055,
            "precision": 0.6171428571428571,
            "recall": 0.6923076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6994368118116412,
            "auditor_fn_violation": 0.018884015594541916,
            "auditor_fp_violation": 0.012625092661230545,
            "ave_precision_score": 0.6732241563752857,
            "fpr": 0.20065789473684212,
            "logloss": 5.758278907201933,
            "mae": 0.3590688954060116,
            "precision": 0.6494252873563219,
            "recall": 0.6975308641975309
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.706864650186033,
            "auditor_fn_violation": 0.017366095302429004,
            "auditor_fp_violation": 0.010382260458454858,
            "ave_precision_score": 0.6830610064238092,
            "fpr": 0.21734357848518113,
            "logloss": 5.416242250531301,
            "mae": 0.36759172070966234,
            "precision": 0.625,
            "recall": 0.7051282051282052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6372116251251582,
            "auditor_fn_violation": 0.014985380116959067,
            "auditor_fp_violation": 0.008324067210279229,
            "ave_precision_score": 0.5372686982818978,
            "fpr": 0.20723684210526316,
            "logloss": 0.6917896492831711,
            "mae": 0.4980183405834332,
            "precision": 0.5467625899280576,
            "recall": 0.4691358024691358
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.6077958546433897,
            "auditor_fn_violation": 0.005666732340716973,
            "auditor_fp_violation": 0.007131299665735823,
            "ave_precision_score": 0.5065188697402626,
            "fpr": 0.2327113062568606,
            "logloss": 0.6961665106915857,
            "mae": 0.5001711291225237,
            "precision": 0.5023474178403756,
            "recall": 0.45726495726495725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 12498,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6776502059627688,
            "auditor_fn_violation": 0.009841347195148368,
            "auditor_fp_violation": 0.011953298739807276,
            "ave_precision_score": 0.6374227040504933,
            "fpr": 0.2236842105263158,
            "logloss": 4.835983739744522,
            "mae": 0.375441631345264,
            "precision": 0.6344086021505376,
            "recall": 0.7283950617283951
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6985168096735883,
            "auditor_fn_violation": 0.01742707834914202,
            "auditor_fp_violation": 0.0009019433906629074,
            "ave_precision_score": 0.6623759946416021,
            "fpr": 0.2239297475301866,
            "logloss": 4.301128360626795,
            "mae": 0.370334074833825,
            "precision": 0.620817843866171,
            "recall": 0.7136752136752137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 12498,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6831329935021688,
            "auditor_fn_violation": 0.0073482961519023915,
            "auditor_fp_violation": 0.009930195206325678,
            "ave_precision_score": 0.61874078218071,
            "fpr": 0.24342105263157895,
            "logloss": 6.287614874711749,
            "mae": 0.4003187848887661,
            "precision": 0.6112084063047285,
            "recall": 0.7181069958847737
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.68964125321512,
            "auditor_fn_violation": 0.011305318659874093,
            "auditor_fp_violation": 0.009911465831460495,
            "ave_precision_score": 0.6294854725109015,
            "fpr": 0.2491767288693743,
            "logloss": 5.6452496485784165,
            "mae": 0.39317131187831,
            "precision": 0.5960854092526691,
            "recall": 0.7158119658119658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6999555623948086,
            "auditor_fn_violation": 0.019966969893870486,
            "auditor_fp_violation": 0.017425459187875796,
            "ave_precision_score": 0.6773521564732312,
            "fpr": 0.18311403508771928,
            "logloss": 5.609901778750382,
            "mae": 0.3569906208702864,
            "precision": 0.6639839034205232,
            "recall": 0.6790123456790124
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7015355724845819,
            "auditor_fn_violation": 0.021991424845431436,
            "auditor_fp_violation": 0.008806337391252639,
            "ave_precision_score": 0.681791193026529,
            "fpr": 0.2052689352360044,
            "logloss": 5.289466904594175,
            "mae": 0.3644276453790763,
            "precision": 0.631163708086785,
            "recall": 0.6837606837606838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.67443403759345,
            "auditor_fn_violation": 0.009516460905349796,
            "auditor_fp_violation": 0.013456469813030232,
            "ave_precision_score": 0.6361814102668703,
            "fpr": 0.21929824561403508,
            "logloss": 4.723904502120228,
            "mae": 0.37679853056144086,
            "precision": 0.635036496350365,
            "recall": 0.7160493827160493
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6941713275972099,
            "auditor_fn_violation": 0.014035482751179794,
            "auditor_fp_violation": 0.0015759230672022194,
            "ave_precision_score": 0.6596784842211769,
            "fpr": 0.21844127332601537,
            "logloss": 4.215892862394928,
            "mae": 0.3712653013691609,
            "precision": 0.6252354048964218,
            "recall": 0.7094017094017094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6810591687440309,
            "auditor_fn_violation": 0.007282867662984632,
            "auditor_fp_violation": 0.01301118112181865,
            "ave_precision_score": 0.6197469357603542,
            "fpr": 0.2642543859649123,
            "logloss": 5.857336074070535,
            "mae": 0.39813115638244584,
            "precision": 0.6068515497553018,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.693791784635348,
            "auditor_fn_violation": 0.003841931942919872,
            "auditor_fp_violation": 0.008370232894668385,
            "ave_precision_score": 0.6368317361413748,
            "fpr": 0.26125137211855104,
            "logloss": 5.199975666217044,
            "mae": 0.39123467716836796,
            "precision": 0.5959252971137521,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6028092688595617,
            "auditor_fn_violation": 0.020445274709407272,
            "auditor_fp_violation": 0.017353389341899346,
            "ave_precision_score": 0.5879947160143291,
            "fpr": 0.20614035087719298,
            "logloss": 6.059229236430519,
            "mae": 0.37914912953394836,
            "precision": 0.6377649325626205,
            "recall": 0.6810699588477366
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.5975509201335844,
            "auditor_fn_violation": 0.023464399973730395,
            "auditor_fp_violation": 0.009259786953041957,
            "ave_precision_score": 0.5900273680373814,
            "fpr": 0.22283205268935236,
            "logloss": 5.610324910104106,
            "mae": 0.3866397686609683,
            "precision": 0.6096153846153847,
            "recall": 0.6773504273504274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 12498,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6872155809469591,
            "auditor_fn_violation": 0.0205761316872428,
            "auditor_fp_violation": 0.01122745243390166,
            "ave_precision_score": 0.684297929407109,
            "fpr": 0.20065789473684212,
            "logloss": 4.8527867799261815,
            "mae": 0.3564102225248769,
            "precision": 0.6527514231499051,
            "recall": 0.7078189300411523
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7156516760581925,
            "auditor_fn_violation": 0.01696501449520111,
            "auditor_fp_violation": 0.008652709670865007,
            "ave_precision_score": 0.713410032198467,
            "fpr": 0.21734357848518113,
            "logloss": 4.523077791349131,
            "mae": 0.3639159376333266,
            "precision": 0.6257088846880907,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6680607812551814,
            "auditor_fn_violation": 0.012954840805718001,
            "auditor_fp_violation": 0.007387159212585456,
            "ave_precision_score": 0.6683844929168579,
            "fpr": 0.21600877192982457,
            "logloss": 0.6899618168557144,
            "mae": 0.4935529957313025,
            "precision": 0.5471264367816092,
            "recall": 0.4897119341563786
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.641907603043032,
            "auditor_fn_violation": 0.011223226096991203,
            "auditor_fp_violation": 0.01450295237788455,
            "ave_precision_score": 0.6422736590530163,
            "fpr": 0.19319429198682767,
            "logloss": 0.6864165238641114,
            "mae": 0.49155476738409465,
            "precision": 0.5544303797468354,
            "recall": 0.46794871794871795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.8296427958159583,
            "auditor_fn_violation": 0.004746949678723557,
            "auditor_fp_violation": 0.005044889218351053,
            "ave_precision_score": 0.829720937641869,
            "fpr": 0.36622807017543857,
            "logloss": 0.6827761548032314,
            "mae": 0.49144906405228794,
            "precision": 0.5522788203753352,
            "recall": 0.8477366255144033
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7874900547604677,
            "auditor_fn_violation": 0.006163978721607703,
            "auditor_fp_violation": 0.008149702779918383,
            "ave_precision_score": 0.7874839205774936,
            "fpr": 0.36663007683863885,
            "logloss": 0.6845487420796725,
            "mae": 0.49313795995110343,
            "precision": 0.5248933143669986,
            "recall": 0.7884615384615384
        }
    }
]