[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.832694772194557,
            "auditor_fn_violation": 0.011213696004717675,
            "auditor_fp_violation": 0.018408981168517632,
            "ave_precision_score": 0.8330861750352986,
            "fpr": 0.12938596491228072,
            "logloss": 0.7604268019920395,
            "mae": 0.2684552297525735,
            "precision": 0.757201646090535,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8290988298659603,
            "auditor_fn_violation": 0.016362083140050245,
            "auditor_fp_violation": 0.019360497689263637,
            "ave_precision_score": 0.8294847448917169,
            "fpr": 0.13062568605927552,
            "logloss": 0.7748892443312464,
            "mae": 0.27736479153517873,
            "precision": 0.7520833333333333,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7708802279589178,
            "auditor_fn_violation": 0.011139982308712963,
            "auditor_fp_violation": 0.01900249476903268,
            "ave_precision_score": 0.7723449292300211,
            "fpr": 0.3026315789473684,
            "logloss": 0.9977442993937629,
            "mae": 0.37942205160946113,
            "precision": 0.6134453781512605,
            "recall": 0.9201680672268907
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7777555388915385,
            "auditor_fn_violation": 0.016387343899985765,
            "auditor_fp_violation": 0.025984693114436602,
            "ave_precision_score": 0.7780796868907502,
            "fpr": 0.29857299670691545,
            "logloss": 1.0203542577362172,
            "mae": 0.38280406305448866,
            "precision": 0.6114285714285714,
            "recall": 0.895397489539749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7338107767521151,
            "auditor_fn_violation": 0.009723297213622297,
            "auditor_fp_violation": 0.023056494447126995,
            "ave_precision_score": 0.703577951996692,
            "fpr": 0.16228070175438597,
            "logloss": 0.6479417761551387,
            "mae": 0.40153462034568455,
            "precision": 0.6985743380855397,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7352697492858267,
            "auditor_fn_violation": 0.016097993377088036,
            "auditor_fp_violation": 0.019766112411049967,
            "ave_precision_score": 0.7051598763608445,
            "fpr": 0.1734357848518112,
            "logloss": 0.6474705179938189,
            "mae": 0.40749938578296835,
            "precision": 0.6814516129032258,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6901174937907624,
            "auditor_fn_violation": 0.005675954592363263,
            "auditor_fp_violation": 0.02048124899404476,
            "ave_precision_score": 0.6911969001048597,
            "fpr": 0.32456140350877194,
            "logloss": 0.7080889243767255,
            "mae": 0.4121952924750778,
            "precision": 0.6021505376344086,
            "recall": 0.9411764705882353
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6704652022833092,
            "auditor_fn_violation": 0.0012125164769047781,
            "auditor_fp_violation": 0.03134641271804961,
            "ave_precision_score": 0.6715530402717282,
            "fpr": 0.33260153677277715,
            "logloss": 0.7294033629282232,
            "mae": 0.423598243556426,
            "precision": 0.596,
            "recall": 0.9351464435146444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7609649122807017,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5219298245614035,
            "fpr": 0.4780701754385965,
            "logloss": 0.6922850790234776,
            "mae": 0.4993481787673214,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7623490669593853,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5246981339187706,
            "fpr": 0.47530186608122943,
            "logloss": 0.6921204653505629,
            "mae": 0.4992658961748318,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7615318876008743,
            "auditor_fn_violation": 0.019324506118236773,
            "auditor_fp_violation": 0.016266296475132787,
            "ave_precision_score": 0.570241092995351,
            "fpr": 0.34100877192982454,
            "logloss": 0.6717593224570603,
            "mae": 0.46574197356638153,
            "precision": 0.5762942779291553,
            "recall": 0.8886554621848739
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7800643677246826,
            "auditor_fn_violation": 0.013852082175548504,
            "auditor_fp_violation": 0.019968919771943136,
            "ave_precision_score": 0.592853766416275,
            "fpr": 0.3227222832052689,
            "logloss": 0.6446662939274134,
            "mae": 0.453455020122549,
            "precision": 0.5989085948158254,
            "recall": 0.9184100418410042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8092952916503098,
            "auditor_fn_violation": 0.009564352056612126,
            "auditor_fp_violation": 0.004320577820698535,
            "ave_precision_score": 0.7556880203527587,
            "fpr": 0.09320175438596491,
            "logloss": 0.5648409399041159,
            "mae": 0.3659417787403391,
            "precision": 0.7961630695443646,
            "recall": 0.6974789915966386
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8427243742454131,
            "auditor_fn_violation": 0.002746533534807033,
            "auditor_fp_violation": 0.010824842887672612,
            "ave_precision_score": 0.8027179887986164,
            "fpr": 0.0867178924259056,
            "logloss": 0.5315607367933157,
            "mae": 0.35429477921465224,
            "precision": 0.8077858880778589,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.868535745758906,
            "auditor_fn_violation": 0.003234188412206989,
            "auditor_fp_violation": 0.005351681957186545,
            "ave_precision_score": 0.8687423699963149,
            "fpr": 0.09539473684210527,
            "logloss": 0.4737535549002432,
            "mae": 0.3092061576909353,
            "precision": 0.8044943820224719,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8685874038967212,
            "auditor_fn_violation": 0.011459199279838702,
            "auditor_fp_violation": 0.007952583639023179,
            "ave_precision_score": 0.86882397005823,
            "fpr": 0.07574094401756312,
            "logloss": 0.47554282250184776,
            "mae": 0.30858351882704577,
            "precision": 0.8368794326241135,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.42654081369389857,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005331562852084339,
            "ave_precision_score": 0.520828726227333,
            "fpr": 0.0010964912280701754,
            "logloss": 17.92891117960678,
            "mae": 0.5231044675589434,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.055924881978118,
            "mae": 0.5250122502711208,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8040558520163115,
            "auditor_fn_violation": 0.006099808344390388,
            "auditor_fp_violation": 0.007474247545469181,
            "ave_precision_score": 0.8043499087296446,
            "fpr": 0.0756578947368421,
            "logloss": 0.5863028686761669,
            "mae": 0.39571089316322877,
            "precision": 0.7952522255192879,
            "recall": 0.5630252100840336
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8169607226334735,
            "auditor_fn_violation": 0.009530195793853839,
            "auditor_fp_violation": 0.010406552705830458,
            "ave_precision_score": 0.8183443927596247,
            "fpr": 0.07574094401756312,
            "logloss": 0.5559370317336109,
            "mae": 0.3799798225188622,
            "precision": 0.8130081300813008,
            "recall": 0.6276150627615062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8087230216313083,
            "auditor_fn_violation": 0.01193240454076367,
            "auditor_fp_violation": 0.017020762916465478,
            "ave_precision_score": 0.8088671107572625,
            "fpr": 0.13157894736842105,
            "logloss": 0.8294933305032481,
            "mae": 0.2747745027337467,
            "precision": 0.7520661157024794,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8086240034202781,
            "auditor_fn_violation": 0.015087562979667386,
            "auditor_fp_violation": 0.021185763937302104,
            "ave_precision_score": 0.8089686289806575,
            "fpr": 0.1350164654226125,
            "logloss": 0.8615439612322496,
            "mae": 0.28266465654558987,
            "precision": 0.7421383647798742,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.832594649064936,
            "auditor_fn_violation": 0.0008569217160548509,
            "auditor_fp_violation": 0.004929180750040243,
            "ave_precision_score": 0.8178082996748138,
            "fpr": 0.07017543859649122,
            "logloss": 0.5599440009787482,
            "mae": 0.31957491656373205,
            "precision": 0.8236914600550964,
            "recall": 0.6281512605042017
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8506875761463154,
            "auditor_fn_violation": 0.013121816570139949,
            "auditor_fp_violation": 0.008312566704608546,
            "ave_precision_score": 0.8369289417817608,
            "fpr": 0.06147091108671789,
            "logloss": 0.5379050359056411,
            "mae": 0.3108510659633431,
            "precision": 0.8461538461538461,
            "recall": 0.6443514644351465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8307599621411438,
            "auditor_fn_violation": 0.012218045112781956,
            "auditor_fp_violation": 0.020916324641879935,
            "ave_precision_score": 0.8268393958559945,
            "fpr": 0.16557017543859648,
            "logloss": 0.5057718628206,
            "mae": 0.3307528347675607,
            "precision": 0.7298747763864043,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8356935731829066,
            "auditor_fn_violation": 0.022296065292175135,
            "auditor_fp_violation": 0.023753812144611787,
            "ave_precision_score": 0.8272022172153628,
            "fpr": 0.15916575192096596,
            "logloss": 0.5072113844959691,
            "mae": 0.3311584818572558,
            "precision": 0.7324723247232472,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8088374994760902,
            "auditor_fn_violation": 0.006472983930414276,
            "auditor_fp_violation": 0.007685498149042336,
            "ave_precision_score": 0.7884213062892882,
            "fpr": 0.08991228070175439,
            "logloss": 0.5426764857921221,
            "mae": 0.3620269671736056,
            "precision": 0.8024096385542169,
            "recall": 0.6995798319327731
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8451988576611564,
            "auditor_fn_violation": 0.0031231485011183695,
            "auditor_fp_violation": 0.010946527304208508,
            "ave_precision_score": 0.8214389077709306,
            "fpr": 0.07244785949506037,
            "logloss": 0.5149135057112874,
            "mae": 0.3522140847602869,
            "precision": 0.835,
            "recall": 0.698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8316708656812751,
            "auditor_fn_violation": 0.005546955624355006,
            "auditor_fp_violation": 0.005311443746982137,
            "ave_precision_score": 0.8304103942340066,
            "fpr": 0.0800438596491228,
            "logloss": 0.5189277726520684,
            "mae": 0.31596510987238663,
            "precision": 0.8215158924205379,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8504969131808844,
            "auditor_fn_violation": 0.01274060873838579,
            "auditor_fp_violation": 0.009014787191701125,
            "ave_precision_score": 0.8433804168770476,
            "fpr": 0.06805708013172337,
            "logloss": 0.5086037245658833,
            "mae": 0.311732146406442,
            "precision": 0.8453865336658354,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8005482846507879,
            "auditor_fn_violation": 0.007136407194456735,
            "auditor_fp_violation": 0.004214952518911964,
            "ave_precision_score": 0.8008464159866765,
            "fpr": 0.09210526315789473,
            "logloss": 0.8137303915024129,
            "mae": 0.3214376564919321,
            "precision": 0.7868020304568528,
            "recall": 0.6512605042016807
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8173047513728258,
            "auditor_fn_violation": 0.004781172925976793,
            "auditor_fp_violation": 0.009118725964158872,
            "ave_precision_score": 0.8178685671250344,
            "fpr": 0.09220636663007684,
            "logloss": 0.7582634830222574,
            "mae": 0.2958475841059157,
            "precision": 0.7951219512195122,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8277670406546943,
            "auditor_fn_violation": 0.00809468524251806,
            "auditor_fp_violation": 0.019837437630774186,
            "ave_precision_score": 0.7611673518408433,
            "fpr": 0.14473684210526316,
            "logloss": 0.5447264305816502,
            "mae": 0.3713623572206288,
            "precision": 0.7375745526838966,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8160889126249551,
            "auditor_fn_violation": 0.015128898768652773,
            "auditor_fp_violation": 0.01686850224228889,
            "ave_precision_score": 0.761410309026545,
            "fpr": 0.14709110867178923,
            "logloss": 0.5530694601150029,
            "mae": 0.3736110055485881,
            "precision": 0.7276422764227642,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.7540418712110161,
            "auditor_fn_violation": 0.020994582043343653,
            "auditor_fp_violation": 0.02192982456140351,
            "ave_precision_score": 0.7524101338091195,
            "fpr": 0.1162280701754386,
            "logloss": 0.5353908938777042,
            "mae": 0.34347912386517254,
            "precision": 0.7827868852459017,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.7958193616551799,
            "auditor_fn_violation": 0.009690946084352565,
            "auditor_fp_violation": 0.024146751406342298,
            "ave_precision_score": 0.7854386676814951,
            "fpr": 0.1207464324917673,
            "logloss": 0.5173249647196096,
            "mae": 0.33876578668469787,
            "precision": 0.7764227642276422,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7820193056237713,
            "auditor_fn_violation": 0.009665708388618601,
            "auditor_fp_violation": 0.02440447448897473,
            "ave_precision_score": 0.6501751525687233,
            "fpr": 0.1600877192982456,
            "logloss": 0.618151008834839,
            "mae": 0.4323972769800508,
            "precision": 0.7002053388090349,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7706530587230583,
            "auditor_fn_violation": 0.01482576964942658,
            "auditor_fp_violation": 0.019203321984571434,
            "ave_precision_score": 0.6365447050375312,
            "fpr": 0.17233809001097694,
            "logloss": 0.6295317875128611,
            "mae": 0.4377315531512385,
            "precision": 0.6815415821501014,
            "recall": 0.702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8019004048345065,
            "auditor_fn_violation": 0.024912925696594444,
            "auditor_fp_violation": 0.011254124416545953,
            "ave_precision_score": 0.7888764288172124,
            "fpr": 0.08442982456140351,
            "logloss": 0.6131688126647316,
            "mae": 0.3528814933363863,
            "precision": 0.78,
            "recall": 0.5735294117647058
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.826277084661438,
            "auditor_fn_violation": 0.00802832879405133,
            "auditor_fp_violation": 0.005582272608584328,
            "ave_precision_score": 0.8087881861498472,
            "fpr": 0.06366630076838639,
            "logloss": 0.6189954858149135,
            "mae": 0.34829772328988584,
            "precision": 0.8209876543209876,
            "recall": 0.5564853556485355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8060868789811463,
            "auditor_fn_violation": 0.011029411764705887,
            "auditor_fp_violation": 0.01214187992918075,
            "ave_precision_score": 0.7540308917579714,
            "fpr": 0.10197368421052631,
            "logloss": 0.5510094227437997,
            "mae": 0.3517096564827258,
            "precision": 0.786697247706422,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8284455473331669,
            "auditor_fn_violation": 0.007477184940912786,
            "auditor_fp_violation": 0.014396787531403457,
            "ave_precision_score": 0.7776431736185261,
            "fpr": 0.08562019758507135,
            "logloss": 0.5296211789772285,
            "mae": 0.3424960213879984,
            "precision": 0.8156028368794326,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6065298253828505,
            "auditor_fn_violation": 0.007251584844464105,
            "auditor_fp_violation": 0.058546595847416706,
            "ave_precision_score": 0.5752027836204633,
            "fpr": 0.16885964912280702,
            "logloss": 0.7632721545250023,
            "mae": 0.476891987540416,
            "precision": 0.5792349726775956,
            "recall": 0.44537815126050423
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5414933343609555,
            "auditor_fn_violation": 0.027518153300662762,
            "auditor_fp_violation": 0.042513493027229426,
            "ave_precision_score": 0.5932372208350785,
            "fpr": 0.15477497255762898,
            "logloss": 0.7489767835564701,
            "mae": 0.4699407499263106,
            "precision": 0.6016949152542372,
            "recall": 0.4456066945606695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 18313,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6627833860439823,
            "auditor_fn_violation": 0.01160069290874245,
            "auditor_fp_violation": 0.020310236600676,
            "ave_precision_score": 0.6640420329466983,
            "fpr": 0.125,
            "logloss": 0.6498104427120118,
            "mae": 0.46619654450108083,
            "precision": 0.6902173913043478,
            "recall": 0.5336134453781513
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6673329317309321,
            "auditor_fn_violation": 0.009929775087379262,
            "auditor_fp_violation": 0.011473826442530729,
            "ave_precision_score": 0.6689615507949132,
            "fpr": 0.11086717892425905,
            "logloss": 0.6330360251364814,
            "mae": 0.45636061326274496,
            "precision": 0.7292225201072386,
            "recall": 0.5690376569037657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8318320041629408,
            "auditor_fn_violation": 0.00445046439628483,
            "auditor_fp_violation": 0.004873853211009172,
            "ave_precision_score": 0.8321089754083881,
            "fpr": 0.10197368421052631,
            "logloss": 0.5208891529282238,
            "mae": 0.3241492539538038,
            "precision": 0.7924107142857143,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8563368991640031,
            "auditor_fn_violation": 0.012584451313329878,
            "auditor_fp_violation": 0.014308059311012694,
            "ave_precision_score": 0.8567385480947037,
            "fpr": 0.09001097694840834,
            "logloss": 0.4902586877131863,
            "mae": 0.31472764753161,
            "precision": 0.8101851851851852,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6348587322489123,
            "auditor_fn_violation": 0.0016677723721067416,
            "auditor_fp_violation": 0.021768871720585867,
            "ave_precision_score": 0.5995524362492155,
            "fpr": 0.25,
            "logloss": 3.78344941833699,
            "mae": 0.3913124942560112,
            "precision": 0.6161616161616161,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6249959330383672,
            "auditor_fn_violation": 0.01690174482958173,
            "auditor_fp_violation": 0.028200363532194402,
            "ave_precision_score": 0.5826439705080588,
            "fpr": 0.270032930845225,
            "logloss": 4.2635216150838,
            "mae": 0.41303461005981157,
            "precision": 0.5993485342019544,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7629396442912659,
            "auditor_fn_violation": 0.004155609612265964,
            "auditor_fp_violation": 0.007559753742153549,
            "ave_precision_score": 0.764288079894515,
            "fpr": 0.03618421052631579,
            "logloss": 0.78744512056297,
            "mae": 0.3873808603634723,
            "precision": 0.8341708542713567,
            "recall": 0.3487394957983193
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7788446710835984,
            "auditor_fn_violation": 0.0014834955380312294,
            "auditor_fp_violation": 0.0013207829378167298,
            "ave_precision_score": 0.7799306108049671,
            "fpr": 0.027442371020856202,
            "logloss": 0.7988175325128458,
            "mae": 0.38237266235910233,
            "precision": 0.8717948717948718,
            "recall": 0.35564853556485354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8025311250066226,
            "auditor_fn_violation": 0.01229175880878668,
            "auditor_fp_violation": 0.018813878158699508,
            "ave_precision_score": 0.7709539277550826,
            "fpr": 0.16337719298245615,
            "logloss": 2.4862629499246456,
            "mae": 0.28033867991415035,
            "precision": 0.726605504587156,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8115093592154893,
            "auditor_fn_violation": 0.005947760748453353,
            "auditor_fp_violation": 0.014766910965033478,
            "ave_precision_score": 0.7842661405878508,
            "fpr": 0.145993413830955,
            "logloss": 2.1879689255918273,
            "mae": 0.27258223848689334,
            "precision": 0.745697896749522,
            "recall": 0.8158995815899581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.625966718023576,
            "auditor_fn_violation": 0.004938817632316087,
            "auditor_fp_violation": 0.020873571543537757,
            "ave_precision_score": 0.6268927286010766,
            "fpr": 0.34978070175438597,
            "logloss": 0.6819827850236834,
            "mae": 0.4603511940875793,
            "precision": 0.5636114911080712,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.577245222464041,
            "auditor_fn_violation": 0.009374038368797912,
            "auditor_fp_violation": 0.02481094551326742,
            "ave_precision_score": 0.5787841799097282,
            "fpr": 0.3545554335894621,
            "logloss": 0.6728320811591703,
            "mae": 0.4575186001993593,
            "precision": 0.5733157199471598,
            "recall": 0.9079497907949791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7794043889250866,
            "auditor_fn_violation": 0.014189886480908152,
            "auditor_fp_violation": 0.02164815708997264,
            "ave_precision_score": 0.7783714543243366,
            "fpr": 0.16228070175438597,
            "logloss": 1.0558827347139257,
            "mae": 0.2921541266312771,
            "precision": 0.7131782945736435,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7864404995108772,
            "auditor_fn_violation": 0.016029100395445715,
            "auditor_fp_violation": 0.02450926956393883,
            "ave_precision_score": 0.7867897925935121,
            "fpr": 0.16355653128430298,
            "logloss": 0.9924167197203958,
            "mae": 0.2931759915093285,
            "precision": 0.7117988394584139,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7828418780238404,
            "auditor_fn_violation": 0.050696594427244585,
            "auditor_fp_violation": 0.06036234508289071,
            "ave_precision_score": 0.7425575671231874,
            "fpr": 0.19078947368421054,
            "logloss": 0.5888305111119779,
            "mae": 0.4001998054966527,
            "precision": 0.6847826086956522,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7637371441375376,
            "auditor_fn_violation": 0.05373422924828572,
            "auditor_fp_violation": 0.06073826949549134,
            "ave_precision_score": 0.7283960363024459,
            "fpr": 0.19099890230515917,
            "logloss": 0.5940473522338631,
            "mae": 0.40067640319875514,
            "precision": 0.6864864864864865,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8522373619545749,
            "auditor_fn_violation": 0.007099550346454373,
            "auditor_fp_violation": 0.008434934814099468,
            "ave_precision_score": 0.852623768101634,
            "fpr": 0.20833333333333334,
            "logloss": 0.6019138784876119,
            "mae": 0.2973184469163626,
            "precision": 0.695024077046549,
            "recall": 0.9096638655462185
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8599008856495147,
            "auditor_fn_violation": 0.003545692121857907,
            "auditor_fp_violation": 0.022374722090538285,
            "ave_precision_score": 0.8601138788803033,
            "fpr": 0.19978046103183314,
            "logloss": 0.5922207785748141,
            "mae": 0.2956247860770243,
            "precision": 0.7040650406504065,
            "recall": 0.9058577405857741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8183337137983356,
            "auditor_fn_violation": 0.004187859354268031,
            "auditor_fp_violation": 0.007803697891517785,
            "ave_precision_score": 0.8207110977962677,
            "fpr": 0.07346491228070176,
            "logloss": 0.523602343267545,
            "mae": 0.3313645056669453,
            "precision": 0.8255208333333334,
            "recall": 0.6659663865546218
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8583900785063823,
            "auditor_fn_violation": 0.003949864280826166,
            "auditor_fp_violation": 0.009316463141029708,
            "ave_precision_score": 0.8561415709056817,
            "fpr": 0.06147091108671789,
            "logloss": 0.5006169651291879,
            "mae": 0.32212333748797944,
            "precision": 0.8534031413612565,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 18313,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8460489998529463,
            "auditor_fn_violation": 0.0237358101135191,
            "auditor_fp_violation": 0.012657431997424754,
            "ave_precision_score": 0.846237464998066,
            "fpr": 0.07785087719298246,
            "logloss": 1.0502301328296566,
            "mae": 0.3234548642050411,
            "precision": 0.8255528255528255,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8354922658542364,
            "auditor_fn_violation": 0.027019827400116662,
            "auditor_fp_violation": 0.015400683967824614,
            "ave_precision_score": 0.8358039631966788,
            "fpr": 0.0867178924259056,
            "logloss": 1.0898914971406397,
            "mae": 0.32988863149556674,
            "precision": 0.8058968058968059,
            "recall": 0.6861924686192469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7976369761121521,
            "auditor_fn_violation": 0.006410787999410291,
            "auditor_fp_violation": 0.0051379164654756174,
            "ave_precision_score": 0.7833384172664486,
            "fpr": 0.0800438596491228,
            "logloss": 0.550684734202253,
            "mae": 0.36010898808180763,
            "precision": 0.8128205128205128,
            "recall": 0.6659663865546218
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8141575220318757,
            "auditor_fn_violation": 0.006983451905809513,
            "auditor_fp_violation": 0.008852541302986593,
            "ave_precision_score": 0.8016921187433799,
            "fpr": 0.06915477497255763,
            "logloss": 0.5259640874383483,
            "mae": 0.34795518565011074,
            "precision": 0.8359375,
            "recall": 0.6715481171548117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7881706959118361,
            "auditor_fn_violation": 0.015512125902992783,
            "auditor_fp_violation": 0.005185699340093359,
            "ave_precision_score": 0.7887185292738592,
            "fpr": 0.1206140350877193,
            "logloss": 0.5963275776161916,
            "mae": 0.3648333447860023,
            "precision": 0.75,
            "recall": 0.6932773109243697
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7586521500407687,
            "auditor_fn_violation": 0.0053093524519012255,
            "auditor_fp_violation": 0.0075824602053931635,
            "ave_precision_score": 0.7592974681899276,
            "fpr": 0.13172338090010977,
            "logloss": 0.6141505244181423,
            "mae": 0.3722598918829276,
            "precision": 0.7254004576659039,
            "recall": 0.6631799163179917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.8257831240358242,
            "auditor_fn_violation": 0.04550208241191214,
            "auditor_fp_violation": 0.047931253017865785,
            "ave_precision_score": 0.7638296468544987,
            "fpr": 0.17434210526315788,
            "logloss": 0.5614177551867372,
            "mae": 0.39856731620404806,
            "precision": 0.689453125,
            "recall": 0.7415966386554622
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8104369808327393,
            "auditor_fn_violation": 0.04426833357063138,
            "auditor_fp_violation": 0.048792915938884004,
            "ave_precision_score": 0.7436182730236554,
            "fpr": 0.18441273326015367,
            "logloss": 0.5794292526944198,
            "mae": 0.40492737939342055,
            "precision": 0.6750483558994197,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6925475935504792,
            "auditor_fn_violation": 0.01915634674922602,
            "auditor_fp_violation": 0.009201975696121035,
            "ave_precision_score": 0.7212045707090949,
            "fpr": 0.06030701754385965,
            "logloss": 0.7560067794760406,
            "mae": 0.42942112431812446,
            "precision": 0.7544642857142857,
            "recall": 0.3550420168067227
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7585215562217923,
            "auditor_fn_violation": 0.021623210504801836,
            "auditor_fp_violation": 0.008520444249524039,
            "ave_precision_score": 0.7586936508476331,
            "fpr": 0.048298572996706916,
            "logloss": 0.7337397080734674,
            "mae": 0.4223057095914196,
            "precision": 0.8070175438596491,
            "recall": 0.38493723849372385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7706825456608964,
            "auditor_fn_violation": 0.0362671384343211,
            "auditor_fp_violation": 0.022382504426203126,
            "ave_precision_score": 0.7718766196622097,
            "fpr": 0.12609649122807018,
            "logloss": 0.702494573192965,
            "mae": 0.32683804198142286,
            "precision": 0.7438752783964365,
            "recall": 0.7016806722689075
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7462862190199526,
            "auditor_fn_violation": 0.04772446481635428,
            "auditor_fp_violation": 0.02165222086735638,
            "ave_precision_score": 0.7476175818267836,
            "fpr": 0.12623490669593854,
            "logloss": 0.7485804085896757,
            "mae": 0.3378337599153289,
            "precision": 0.7362385321100917,
            "recall": 0.6715481171548117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7632983367511936,
            "auditor_fn_violation": 0.0017576109391124833,
            "auditor_fp_violation": 0.00488894253983583,
            "ave_precision_score": 0.7609827820847246,
            "fpr": 0.09758771929824561,
            "logloss": 0.7348461615467993,
            "mae": 0.36137229185388015,
            "precision": 0.7890995260663507,
            "recall": 0.6995798319327731
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7482401144919246,
            "auditor_fn_violation": 0.010834569579615032,
            "auditor_fp_violation": 0.008976760811533653,
            "ave_precision_score": 0.7465483810973386,
            "fpr": 0.08342480790340286,
            "logloss": 0.7744986961364526,
            "mae": 0.361992228837555,
            "precision": 0.8109452736318408,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7906725585511516,
            "auditor_fn_violation": 0.00744969040247678,
            "auditor_fp_violation": 0.006780138419443104,
            "ave_precision_score": 0.772657876294187,
            "fpr": 0.039473684210526314,
            "logloss": 0.6110868230351566,
            "mae": 0.39938245581364945,
            "precision": 0.8604651162790697,
            "recall": 0.46638655462184875
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8229236619319364,
            "auditor_fn_violation": 0.0109815412737853,
            "auditor_fp_violation": 0.0077827324742751535,
            "ave_precision_score": 0.8007848161165317,
            "fpr": 0.029637760702524697,
            "logloss": 0.5866232899835724,
            "mae": 0.39170893944971646,
            "precision": 0.8977272727272727,
            "recall": 0.49581589958158995
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6629911078027173,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5007104662002113,
            "fpr": 0.4780701754385965,
            "logloss": 0.6931113403529866,
            "mae": 0.49815989808555233,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6620643164605806,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5086453100428237,
            "fpr": 0.47530186608122943,
            "logloss": 0.6926875309146613,
            "mae": 0.49796025342135214,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5842600133884388,
            "auditor_fn_violation": 0.005270529264337314,
            "auditor_fp_violation": 0.008955516658619036,
            "ave_precision_score": 0.5810569182833858,
            "fpr": 0.3717105263157895,
            "logloss": 1.5660313140599211,
            "mae": 0.4726067511957106,
            "precision": 0.5285118219749653,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.6005345596867164,
            "auditor_fn_violation": 0.01023290420660546,
            "auditor_fp_violation": 0.009874183383485904,
            "ave_precision_score": 0.5963081528750318,
            "fpr": 0.38419319429198684,
            "logloss": 1.4710344948080865,
            "mae": 0.47890020553002177,
            "precision": 0.5138888888888888,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7748780650139055,
            "auditor_fn_violation": 0.0008154577620521956,
            "auditor_fp_violation": 0.01688998873330115,
            "ave_precision_score": 0.7764742607341257,
            "fpr": 0.1162280701754386,
            "logloss": 0.5998701932622718,
            "mae": 0.3661449992398143,
            "precision": 0.7275064267352185,
            "recall": 0.5945378151260504
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7820005107411895,
            "auditor_fn_violation": 0.008905566093630152,
            "auditor_fp_violation": 0.007100792723271897,
            "ave_precision_score": 0.7824590782433404,
            "fpr": 0.11525795828759605,
            "logloss": 0.5992298205165015,
            "mae": 0.36680253753980413,
            "precision": 0.7400990099009901,
            "recall": 0.6255230125523012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 18313,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6997402194946158,
            "auditor_fn_violation": 0.03408797729618163,
            "auditor_fp_violation": 0.04460154112345083,
            "ave_precision_score": 0.6570269132799853,
            "fpr": 0.18969298245614036,
            "logloss": 0.6682813650429044,
            "mae": 0.44821780127587546,
            "precision": 0.6350210970464135,
            "recall": 0.6323529411764706
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6553240357528244,
            "auditor_fn_violation": 0.036809520091489877,
            "auditor_fp_violation": 0.042003939532985354,
            "ave_precision_score": 0.6184456113465538,
            "fpr": 0.19758507135016465,
            "logloss": 0.6906506881412332,
            "mae": 0.45832225121762177,
            "precision": 0.6129032258064516,
            "recall": 0.5962343096234309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.547849542191185,
            "auditor_fn_violation": 0.008030185758513931,
            "auditor_fp_violation": 0.020503882987284727,
            "ave_precision_score": 0.5562757406002372,
            "fpr": 0.3826754385964912,
            "logloss": 0.687422514165578,
            "mae": 0.49655605486610477,
            "precision": 0.5653798256537983,
            "recall": 0.9537815126050421
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.5542536614749883,
            "auditor_fn_violation": 0.006779069393603976,
            "auditor_fp_violation": 0.023158065521988125,
            "ave_precision_score": 0.5622789888496518,
            "fpr": 0.38638858397365533,
            "logloss": 0.6873628211976054,
            "mae": 0.4965537744937168,
            "precision": 0.5670356703567035,
            "recall": 0.9644351464435147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.5857585318823635,
            "auditor_fn_violation": 0.03455329500221141,
            "auditor_fp_violation": 0.012554321583775953,
            "ave_precision_score": 0.5867004733988312,
            "fpr": 0.02631578947368421,
            "logloss": 2.668995466685846,
            "mae": 0.5040289949511334,
            "precision": 0.7142857142857143,
            "recall": 0.12605042016806722
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5928480273836676,
            "auditor_fn_violation": 0.03606317945703146,
            "auditor_fp_violation": 0.018747005422561813,
            "ave_precision_score": 0.5936020190747976,
            "fpr": 0.031833150384193196,
            "logloss": 2.718788160469712,
            "mae": 0.4990692923824215,
            "precision": 0.6813186813186813,
            "recall": 0.1297071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7357458612456536,
            "auditor_fn_violation": 0.08689001916556097,
            "auditor_fp_violation": 0.09964992757122165,
            "ave_precision_score": 0.5712730984563273,
            "fpr": 0.27850877192982454,
            "logloss": 0.7113096284833553,
            "mae": 0.45948503130491364,
            "precision": 0.5869918699186992,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7344873211602161,
            "auditor_fn_violation": 0.09157255119896753,
            "auditor_fp_violation": 0.09082727657600334,
            "ave_precision_score": 0.5770912268969968,
            "fpr": 0.2601536772777168,
            "logloss": 0.7058693678794796,
            "mae": 0.4577089739159878,
            "precision": 0.596252129471891,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8564499093139699,
            "auditor_fn_violation": 0.008062435500515996,
            "auditor_fp_violation": 0.013278609367455344,
            "ave_precision_score": 0.8371578145343503,
            "fpr": 0.16885964912280702,
            "logloss": 0.4988862814132744,
            "mae": 0.32955727280166586,
            "precision": 0.7317073170731707,
            "recall": 0.8823529411764706
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8541020484893267,
            "auditor_fn_violation": 0.0082625649316352,
            "auditor_fp_violation": 0.017114406167371844,
            "ave_precision_score": 0.8373425611930272,
            "fpr": 0.16465422612513722,
            "logloss": 0.5095455912784773,
            "mae": 0.33477752546970985,
            "precision": 0.7330960854092526,
            "recall": 0.8619246861924686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.5972460771260685,
            "auditor_fn_violation": 0.005611455108359136,
            "auditor_fp_violation": 0.013313817801384204,
            "ave_precision_score": 0.5989828827292222,
            "fpr": 0.3059210526315789,
            "logloss": 1.5458111848246399,
            "mae": 0.39308088024763654,
            "precision": 0.6014285714285714,
            "recall": 0.884453781512605
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6046400410956299,
            "auditor_fn_violation": 0.0022229468743254223,
            "auditor_fp_violation": 0.009803200807173297,
            "ave_precision_score": 0.6058399287443559,
            "fpr": 0.3084522502744237,
            "logloss": 1.5113629189216693,
            "mae": 0.4026967633298867,
            "precision": 0.5956834532374101,
            "recall": 0.8661087866108786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7484208330403723,
            "auditor_fn_violation": 0.007804437564499486,
            "auditor_fp_violation": 0.009616932238854027,
            "ave_precision_score": 0.7047712364061157,
            "fpr": 0.2149122807017544,
            "logloss": 0.5847763244799403,
            "mae": 0.35853765761120276,
            "precision": 0.6888888888888889,
            "recall": 0.9117647058823529
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.775141166671349,
            "auditor_fn_violation": 0.006301411387550581,
            "auditor_fp_violation": 0.010383736877729987,
            "ave_precision_score": 0.7305631383305347,
            "fpr": 0.21734357848518113,
            "logloss": 0.5754841956835038,
            "mae": 0.35549202469779684,
            "precision": 0.6816720257234726,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7931968556067098,
            "auditor_fn_violation": 0.011001769128704115,
            "auditor_fp_violation": 0.015823676162884277,
            "ave_precision_score": 0.7935181048908788,
            "fpr": 0.13596491228070176,
            "logloss": 0.9051754163176104,
            "mae": 0.28117353577989534,
            "precision": 0.7474541751527495,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7554032864661,
            "auditor_fn_violation": 0.016219704311322795,
            "auditor_fp_violation": 0.024605603060363086,
            "ave_precision_score": 0.7566513078950842,
            "fpr": 0.14709110867178923,
            "logloss": 1.1259280872292792,
            "mae": 0.296409836533216,
            "precision": 0.7248459958932238,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8324851011186839,
            "auditor_fn_violation": 0.005014834881320952,
            "auditor_fp_violation": 0.006694632222758734,
            "ave_precision_score": 0.8316875638330158,
            "fpr": 0.07785087719298246,
            "logloss": 0.5085113044007742,
            "mae": 0.3156486241588075,
            "precision": 0.8251231527093597,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8555023233114989,
            "auditor_fn_violation": 0.00860473340712538,
            "auditor_fp_violation": 0.009014787191701125,
            "ave_precision_score": 0.8535672661316591,
            "fpr": 0.06805708013172337,
            "logloss": 0.48758010956612263,
            "mae": 0.30494353713306194,
            "precision": 0.8446115288220551,
            "recall": 0.7050209205020921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7431038540835346,
            "auditor_fn_violation": 0.016604010025062663,
            "auditor_fp_violation": 0.007313294704651538,
            "ave_precision_score": 0.7435784094832771,
            "fpr": 0.07236842105263158,
            "logloss": 0.8046220603348494,
            "mae": 0.3627675025853565,
            "precision": 0.8047337278106509,
            "recall": 0.5714285714285714
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7429398960522094,
            "auditor_fn_violation": 0.007151091494472488,
            "auditor_fp_violation": 0.0046240078283641345,
            "ave_precision_score": 0.744150613369988,
            "fpr": 0.06147091108671789,
            "logloss": 0.8588615659256695,
            "mae": 0.3639152766502862,
            "precision": 0.8271604938271605,
            "recall": 0.5606694560669456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8290975344248666,
            "auditor_fn_violation": 0.007486547250479139,
            "auditor_fp_violation": 0.007202639626589417,
            "ave_precision_score": 0.7633082766515118,
            "fpr": 0.10526315789473684,
            "logloss": 0.5450591809274871,
            "mae": 0.35542963116772863,
            "precision": 0.7832957110609481,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8396758732274137,
            "auditor_fn_violation": 0.007169462956243781,
            "auditor_fp_violation": 0.014728884584866011,
            "ave_precision_score": 0.7778746645956807,
            "fpr": 0.08781558726673985,
            "logloss": 0.5348350846342957,
            "mae": 0.35059613447419635,
            "precision": 0.8113207547169812,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.772851992154972,
            "auditor_fn_violation": 0.010964912280701757,
            "auditor_fp_violation": 0.006591521809109932,
            "ave_precision_score": 0.7732009121385933,
            "fpr": 0.0756578947368421,
            "logloss": 0.8678708331706286,
            "mae": 0.36374230711200906,
            "precision": 0.7876923076923077,
            "recall": 0.5378151260504201
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7961865378402941,
            "auditor_fn_violation": 0.015489438705914236,
            "auditor_fp_violation": 0.008991971363600642,
            "ave_precision_score": 0.7965519308901374,
            "fpr": 0.06366630076838639,
            "logloss": 0.8496864265744586,
            "mae": 0.35673968164158315,
            "precision": 0.8215384615384616,
            "recall": 0.5585774058577406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5026705812268132,
            "auditor_fn_violation": 0.0728844169246646,
            "auditor_fp_violation": 0.06569893771125061,
            "ave_precision_score": 0.4917089793416396,
            "fpr": 0.2324561403508772,
            "logloss": 0.7165143109795465,
            "mae": 0.5052683676282564,
            "precision": 0.4976303317535545,
            "recall": 0.4411764705882353
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5134494503663468,
            "auditor_fn_violation": 0.06627045547446596,
            "auditor_fp_violation": 0.07108905017707619,
            "ave_precision_score": 0.5059655786554157,
            "fpr": 0.2414928649835346,
            "logloss": 0.7129982217593637,
            "mae": 0.5032338893897709,
            "precision": 0.5033860045146726,
            "recall": 0.4665271966527197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6869136132941321,
            "auditor_fn_violation": 0.013222394220846234,
            "auditor_fp_violation": 0.023031345565749237,
            "ave_precision_score": 0.6672568125301623,
            "fpr": 0.1787280701754386,
            "logloss": 0.7535508024079605,
            "mae": 0.4026656143465324,
            "precision": 0.6733466933867736,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6928644213242181,
            "auditor_fn_violation": 0.01714975956349407,
            "auditor_fp_violation": 0.016587107029049624,
            "ave_precision_score": 0.6752531534152941,
            "fpr": 0.1668496158068057,
            "logloss": 0.8396079981662457,
            "mae": 0.41299784129115413,
            "precision": 0.679324894514768,
            "recall": 0.6736401673640168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7350240417094447,
            "auditor_fn_violation": 0.0076731350434910825,
            "auditor_fp_violation": 0.030359729599227434,
            "ave_precision_score": 0.7360482810707613,
            "fpr": 0.28399122807017546,
            "logloss": 0.7531779057763307,
            "mae": 0.35963981632927533,
            "precision": 0.6321022727272727,
            "recall": 0.9348739495798319
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7103707846749807,
            "auditor_fn_violation": 0.003931492819054881,
            "auditor_fp_violation": 0.02587821924996768,
            "ave_precision_score": 0.7112870563444558,
            "fpr": 0.29308452250274425,
            "logloss": 0.7922298890992382,
            "mae": 0.36741397880287646,
            "precision": 0.6244725738396625,
            "recall": 0.9288702928870293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6345770268603126,
            "auditor_fn_violation": 0.016495743034055727,
            "auditor_fp_violation": 0.02726138741348786,
            "ave_precision_score": 0.6357493049210662,
            "fpr": 0.35635964912280704,
            "logloss": 0.6626394613463945,
            "mae": 0.47222279365329695,
            "precision": 0.574607329842932,
            "recall": 0.9222689075630253
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6384624481662773,
            "auditor_fn_violation": 0.01468798368614195,
            "auditor_fp_violation": 0.037311484220319775,
            "ave_precision_score": 0.6395572816772719,
            "fpr": 0.35236004390779363,
            "logloss": 0.6547492552332538,
            "mae": 0.469323084063002,
            "precision": 0.5831168831168831,
            "recall": 0.9393305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8494423490669227,
            "auditor_fn_violation": 0.005335028748341439,
            "auditor_fp_violation": 0.007542149525189124,
            "ave_precision_score": 0.850202686786504,
            "fpr": 0.0668859649122807,
            "logloss": 0.5095089390583526,
            "mae": 0.31916137444051473,
            "precision": 0.8328767123287671,
            "recall": 0.6386554621848739
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8670851322505143,
            "auditor_fn_violation": 0.008891787497301695,
            "auditor_fp_violation": 0.009478709029744237,
            "ave_precision_score": 0.866334263077658,
            "fpr": 0.054884742041712405,
            "logloss": 0.5083423501981963,
            "mae": 0.3166481842410584,
            "precision": 0.8648648648648649,
            "recall": 0.6694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5739122974158093,
            "auditor_fn_violation": 0.0020801083591331444,
            "auditor_fp_violation": 0.0006614155802349915,
            "ave_precision_score": 0.6415445106362182,
            "fpr": 0.009868421052631578,
            "logloss": 0.7361956628674994,
            "mae": 0.45842500965584787,
            "precision": 0.4375,
            "recall": 0.014705882352941176
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.6111849845559891,
            "auditor_fn_violation": 0.0014077132582246848,
            "auditor_fp_violation": 0.0036023657478648197,
            "ave_precision_score": 0.6343285727912137,
            "fpr": 0.009879253567508232,
            "logloss": 0.7421492648689239,
            "mae": 0.4609577316876693,
            "precision": 0.55,
            "recall": 0.02301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7163859187095007,
            "auditor_fn_violation": 0.007666224384490643,
            "auditor_fp_violation": 0.011694229840656689,
            "ave_precision_score": 0.7172194153378451,
            "fpr": 0.16337719298245615,
            "logloss": 0.6132645622279264,
            "mae": 0.4258435672116384,
            "precision": 0.6809421841541756,
            "recall": 0.6680672268907563
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7478920898115144,
            "auditor_fn_violation": 0.003623770834385863,
            "auditor_fp_violation": 0.006375756408078836,
            "ave_precision_score": 0.7487769052039888,
            "fpr": 0.14050493962678376,
            "logloss": 0.5931406352227646,
            "mae": 0.41689220247493747,
            "precision": 0.7217391304347827,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7644609915866732,
            "auditor_fn_violation": 0.0014973094500958278,
            "auditor_fp_violation": 0.007391256236922578,
            "ave_precision_score": 0.5386759903249871,
            "fpr": 0.43969298245614036,
            "logloss": 15.211964653092389,
            "mae": 0.4479013547902514,
            "precision": 0.539609644087256,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7660117579980762,
            "auditor_fn_violation": 0.0015592778178377712,
            "auditor_fp_violation": 0.008421575661088624,
            "ave_precision_score": 0.5436239095606041,
            "fpr": 0.43688254665203075,
            "logloss": 14.966996228184895,
            "mae": 0.4475454610221253,
            "precision": 0.5398843930635838,
            "recall": 0.9769874476987448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7464822813705667,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7212227241627198,
            "fpr": 0.4780701754385965,
            "logloss": 6.267332585856377,
            "mae": 0.47802564606331943,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.75649725411647,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.738572619317899,
            "fpr": 0.47530186608122943,
            "logloss": 6.075573980412746,
            "mae": 0.4752496115855145,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7543450128847407,
            "auditor_fn_violation": 0.001990269792127377,
            "auditor_fp_violation": 0.002552611459842269,
            "ave_precision_score": 0.5471773095221483,
            "fpr": 0.4199561403508772,
            "logloss": 0.6844555496783142,
            "mae": 0.49033745682161106,
            "precision": 0.5413173652694611,
            "recall": 0.9495798319327731
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7530372019146087,
            "auditor_fn_violation": 0.003274713060731462,
            "auditor_fp_violation": 0.006330124751877874,
            "ave_precision_score": 0.5481322505515002,
            "fpr": 0.41712403951701427,
            "logloss": 0.6852581864565183,
            "mae": 0.4908715962513087,
            "precision": 0.5416164053075995,
            "recall": 0.9393305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.49491006156045597,
            "auditor_fn_violation": 0.006180432699395553,
            "auditor_fp_violation": 0.012597074682118143,
            "ave_precision_score": 0.4969573766240664,
            "fpr": 0.3190789473684211,
            "logloss": 0.6953391097736664,
            "mae": 0.5006652198927967,
            "precision": 0.5182119205298014,
            "recall": 0.657563025210084
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.49178361306244484,
            "auditor_fn_violation": 0.012377772368402923,
            "auditor_fp_violation": 0.01186423061225007,
            "ave_precision_score": 0.49388674219071427,
            "fpr": 0.3172338090010977,
            "logloss": 0.6959214619878514,
            "mae": 0.5009452323424175,
            "precision": 0.5093378607809848,
            "recall": 0.6276150627615062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.765084001954825,
            "auditor_fn_violation": 0.007168656936458796,
            "auditor_fp_violation": 0.020418376790600358,
            "ave_precision_score": 0.5595925645725022,
            "fpr": 0.38048245614035087,
            "logloss": 0.6659491208940992,
            "mae": 0.4737590773913421,
            "precision": 0.561314791403287,
            "recall": 0.9327731092436975
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7714933520583283,
            "auditor_fn_violation": 0.004505600999407521,
            "auditor_fp_violation": 0.022881740492771203,
            "ave_precision_score": 0.5629667327652296,
            "fpr": 0.38638858397365533,
            "logloss": 0.6626567953142669,
            "mae": 0.4736613026205716,
            "precision": 0.5643564356435643,
            "recall": 0.9539748953974896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 18313,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5876596891914622,
            "auditor_fn_violation": 0.005722025652366219,
            "auditor_fp_violation": 0.014596410751649767,
            "ave_precision_score": 0.5888823770243687,
            "fpr": 0.3300438596491228,
            "logloss": 0.6926108824011445,
            "mae": 0.49794148624335466,
            "precision": 0.5121555915721232,
            "recall": 0.6638655462184874
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.617633336096544,
            "auditor_fn_violation": 0.0028613551708775685,
            "auditor_fp_violation": 0.011298905093760397,
            "ave_precision_score": 0.6183471745453841,
            "fpr": 0.3084522502744237,
            "logloss": 0.6884529787151238,
            "mae": 0.4958447992278245,
            "precision": 0.5415986949429038,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8353458230068895,
            "auditor_fn_violation": 0.003796255344242964,
            "auditor_fp_violation": 0.004521768871720586,
            "ave_precision_score": 0.8324375920670839,
            "fpr": 0.08662280701754387,
            "logloss": 0.5071394969439743,
            "mae": 0.34849450373695345,
            "precision": 0.8145539906103286,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8265306782586446,
            "auditor_fn_violation": 0.008666737090603458,
            "auditor_fp_violation": 0.014503261395872366,
            "ave_precision_score": 0.8261935319321594,
            "fpr": 0.08122941822173436,
            "logloss": 0.5083757906505874,
            "mae": 0.3490781248777156,
            "precision": 0.8250591016548463,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 18313,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7633750091407911,
            "auditor_fn_violation": 0.029126124133864076,
            "auditor_fp_violation": 0.01297682279092226,
            "ave_precision_score": 0.7385215594708164,
            "fpr": 0.08552631578947369,
            "logloss": 0.6289182731539185,
            "mae": 0.42655945706524345,
            "precision": 0.7712609970674487,
            "recall": 0.5525210084033614
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7724593446621915,
            "auditor_fn_violation": 0.034069875854847095,
            "auditor_fp_violation": 0.02454983103611746,
            "ave_precision_score": 0.7504869589489982,
            "fpr": 0.08342480790340286,
            "logloss": 0.6176229777190987,
            "mae": 0.42166409547451955,
            "precision": 0.7923497267759563,
            "recall": 0.606694560669456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 18313,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7115151096760362,
            "auditor_fn_violation": 0.00544099218634823,
            "auditor_fp_violation": 0.0033976138741348785,
            "ave_precision_score": 0.7119076484359979,
            "fpr": 0.09539473684210527,
            "logloss": 0.648697306248919,
            "mae": 0.46173827493922753,
            "precision": 0.7229299363057324,
            "recall": 0.47689075630252103
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7295077768631516,
            "auditor_fn_violation": 0.004377000767008536,
            "auditor_fp_violation": 0.009646025102481094,
            "ave_precision_score": 0.7300053588959304,
            "fpr": 0.0867178924259056,
            "logloss": 0.6463996605865241,
            "mae": 0.4546118223575546,
            "precision": 0.7561728395061729,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7639573122260784,
            "auditor_fn_violation": 0.007712295444493591,
            "auditor_fp_violation": 0.031325446644133274,
            "ave_precision_score": 0.7646148763341545,
            "fpr": 0.24671052631578946,
            "logloss": 0.5964927511686026,
            "mae": 0.4057647033917244,
            "precision": 0.6405750798722045,
            "recall": 0.842436974789916
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7794180554997402,
            "auditor_fn_violation": 0.02262904803677967,
            "auditor_fp_violation": 0.025984693114436592,
            "ave_precision_score": 0.7802491825758386,
            "fpr": 0.24368825466520308,
            "logloss": 0.6145933436496569,
            "mae": 0.40405587542348637,
            "precision": 0.6384364820846905,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6092732324200917,
            "auditor_fn_violation": 0.0014189886480908153,
            "auditor_fp_violation": 0.005583051665861921,
            "ave_precision_score": 0.6088948132382003,
            "fpr": 0.43859649122807015,
            "logloss": 0.962009331805695,
            "mae": 0.45763804317883977,
            "precision": 0.5397008055235903,
            "recall": 0.9852941176470589
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5912017734724271,
            "auditor_fn_violation": 0.0035365063909722637,
            "auditor_fp_violation": 0.00552143040031639,
            "ave_precision_score": 0.5917589988275359,
            "fpr": 0.44127332601536773,
            "logloss": 0.9161132149018661,
            "mae": 0.46280220718072923,
            "precision": 0.5405714285714286,
            "recall": 0.9895397489539749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7858556836961083,
            "auditor_fn_violation": 0.02559247383163792,
            "auditor_fp_violation": 0.029841662642845667,
            "ave_precision_score": 0.6620708837253253,
            "fpr": 0.3980263157894737,
            "logloss": 10.707257507324309,
            "mae": 0.4420701695551012,
            "precision": 0.5473815461346634,
            "recall": 0.9222689075630253
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7841572286000619,
            "auditor_fn_violation": 0.024955334383568565,
            "auditor_fp_violation": 0.028727662670516636,
            "ave_precision_score": 0.6608319515774909,
            "fpr": 0.40065861690450055,
            "logloss": 10.62832940917507,
            "mae": 0.4460901259845089,
            "precision": 0.5448877805486284,
            "recall": 0.9142259414225942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 18313,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7108318012939067,
            "auditor_fn_violation": 0.010015848444641023,
            "auditor_fp_violation": 0.007260482053758252,
            "ave_precision_score": 0.711303535259617,
            "fpr": 0.0581140350877193,
            "logloss": 3.340011126418116,
            "mae": 0.409927804747986,
            "precision": 0.7735042735042735,
            "recall": 0.3802521008403361
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7276735878681118,
            "auditor_fn_violation": 0.01453641912652887,
            "auditor_fp_violation": 0.0077371008180741946,
            "ave_precision_score": 0.7281146415588151,
            "fpr": 0.052689352360043906,
            "logloss": 3.378465535594399,
            "mae": 0.40171997343820437,
            "precision": 0.7957446808510639,
            "recall": 0.3912133891213389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8348705037220746,
            "auditor_fn_violation": 0.006221896653398213,
            "auditor_fp_violation": 0.006136327056172543,
            "ave_precision_score": 0.7922208329151486,
            "fpr": 0.09649122807017543,
            "logloss": 0.5274692973804003,
            "mae": 0.3390734601161328,
            "precision": 0.7967667436489607,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8423943429747937,
            "auditor_fn_violation": 0.005525217127713809,
            "auditor_fp_violation": 0.015083797466429044,
            "ave_precision_score": 0.7998693476815427,
            "fpr": 0.07903402854006586,
            "logloss": 0.5197374914246906,
            "mae": 0.3374442511721709,
            "precision": 0.8260869565217391,
            "recall": 0.7154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.776348368868471,
            "auditor_fn_violation": 0.006756320949432406,
            "auditor_fp_violation": 0.017478472557540654,
            "ave_precision_score": 0.591595644863831,
            "fpr": 0.32127192982456143,
            "logloss": 0.6515657480119537,
            "mae": 0.4485608706324312,
            "precision": 0.5953038674033149,
            "recall": 0.9054621848739496
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7970104598945248,
            "auditor_fn_violation": 0.0043953722287798135,
            "auditor_fp_violation": 0.006246466715509448,
            "ave_precision_score": 0.6189103813527642,
            "fpr": 0.29747530186608123,
            "logloss": 0.6182123117529158,
            "mae": 0.4326446370173626,
            "precision": 0.6230876216968011,
            "recall": 0.9372384937238494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7913363366162323,
            "auditor_fn_violation": 0.011510854341736697,
            "auditor_fp_violation": 0.03108150249476904,
            "ave_precision_score": 0.7918467763138535,
            "fpr": 0.17653508771929824,
            "logloss": 1.7119850777869372,
            "mae": 0.3625331622488602,
            "precision": 0.7029520295202952,
            "recall": 0.8004201680672269
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7727159918151772,
            "auditor_fn_violation": 0.010462547478746516,
            "auditor_fp_violation": 0.03326801246251233,
            "ave_precision_score": 0.7731192279517152,
            "fpr": 0.2052689352360044,
            "logloss": 1.8791665551074492,
            "mae": 0.3758746777805089,
            "precision": 0.6730769230769231,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6779859271516014,
            "auditor_fn_violation": 0.009253372401592228,
            "auditor_fp_violation": 0.014012956703685821,
            "ave_precision_score": 0.6824922764805994,
            "fpr": 0.13596491228070176,
            "logloss": 5.709497947068659,
            "mae": 0.41127701932777894,
            "precision": 0.6675603217158177,
            "recall": 0.523109243697479
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6856842034580084,
            "auditor_fn_violation": 0.017664160493090036,
            "auditor_fp_violation": 0.012769258460235815,
            "ave_precision_score": 0.6914743843429669,
            "fpr": 0.13830954994511527,
            "logloss": 5.597593077076432,
            "mae": 0.40890404818066617,
            "precision": 0.6684210526315789,
            "recall": 0.5313807531380753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7868898002580306,
            "auditor_fn_violation": 0.01320396579684506,
            "auditor_fp_violation": 0.02983411797843233,
            "ave_precision_score": 0.7178894300417797,
            "fpr": 0.2532894736842105,
            "logloss": 0.5864701452325007,
            "mae": 0.4029090754491718,
            "precision": 0.631578947368421,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.8110296748287993,
            "auditor_fn_violation": 0.01644934758346385,
            "auditor_fp_violation": 0.030175200208891577,
            "ave_precision_score": 0.7432376181261366,
            "fpr": 0.2579582875960483,
            "logloss": 0.5684215945251929,
            "mae": 0.3924989912793874,
            "precision": 0.6362229102167183,
            "recall": 0.8598326359832636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7469503266020254,
            "auditor_fn_violation": 0.013028895768833855,
            "auditor_fp_violation": 0.015350877192982457,
            "ave_precision_score": 0.7477799371590202,
            "fpr": 0.1425438596491228,
            "logloss": 0.5831631245884181,
            "mae": 0.4050039877142888,
            "precision": 0.7245762711864406,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7488545036748444,
            "auditor_fn_violation": 0.0014513454799314832,
            "auditor_fp_violation": 0.004000375193617658,
            "ave_precision_score": 0.7495936382049533,
            "fpr": 0.14818880351262348,
            "logloss": 0.5876075673670836,
            "mae": 0.4081663508724695,
            "precision": 0.7157894736842105,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7310176976103844,
            "auditor_fn_violation": 0.008702823234556982,
            "auditor_fp_violation": 0.024263640753259305,
            "ave_precision_score": 0.7268131393552413,
            "fpr": 0.2236842105263158,
            "logloss": 0.8784748836485101,
            "mae": 0.38999771297370134,
            "precision": 0.6565656565656566,
            "recall": 0.819327731092437
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7563451475911629,
            "auditor_fn_violation": 0.011785292726278998,
            "auditor_fp_violation": 0.021160413017190467,
            "ave_precision_score": 0.7547144241606434,
            "fpr": 0.23819978046103182,
            "logloss": 0.7599938470934808,
            "mae": 0.38877082145011255,
            "precision": 0.6465798045602605,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8075550427445005,
            "auditor_fn_violation": 0.0073990122364735395,
            "auditor_fp_violation": 0.004526798647996142,
            "ave_precision_score": 0.8079435173294571,
            "fpr": 0.07894736842105263,
            "logloss": 0.6605027980938883,
            "mae": 0.33302614788245466,
            "precision": 0.8048780487804879,
            "recall": 0.6239495798319328
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8410535743512572,
            "auditor_fn_violation": 0.003123148501118364,
            "auditor_fp_violation": 0.009334208785107856,
            "ave_precision_score": 0.8413819612020013,
            "fpr": 0.05598243688254665,
            "logloss": 0.6793844029080417,
            "mae": 0.32062704363265415,
            "precision": 0.8571428571428571,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.544110751427363,
            "auditor_fn_violation": 0.0026675143741707427,
            "auditor_fp_violation": 0.009234669241912121,
            "ave_precision_score": 0.5480426612818812,
            "fpr": 0.0581140350877193,
            "logloss": 6.397076923642132,
            "mae": 0.5012643531586196,
            "precision": 0.6187050359712231,
            "recall": 0.18067226890756302
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.552880620747312,
            "auditor_fn_violation": 0.004530861759343047,
            "auditor_fp_violation": 0.005610158620707138,
            "ave_precision_score": 0.557279284253638,
            "fpr": 0.06586169045005488,
            "logloss": 6.301542955395437,
            "mae": 0.4945380124559928,
            "precision": 0.5973154362416108,
            "recall": 0.18619246861924685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 18313,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6609261090989825,
            "auditor_fn_violation": 0.04917624944714729,
            "auditor_fp_violation": 0.016952860936745532,
            "ave_precision_score": 0.648439048186651,
            "fpr": 0.17214912280701755,
            "logloss": 0.8438640573853434,
            "mae": 0.4386541538083213,
            "precision": 0.5922077922077922,
            "recall": 0.4789915966386555
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6927978785575423,
            "auditor_fn_violation": 0.04663595570640568,
            "auditor_fp_violation": 0.031386974190228234,
            "ave_precision_score": 0.678720312339214,
            "fpr": 0.17014270032930845,
            "logloss": 0.7970472890892027,
            "mae": 0.4275106937697609,
            "precision": 0.6144278606965174,
            "recall": 0.5167364016736402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6988376068809061,
            "auditor_fn_violation": 0.023945433436532517,
            "auditor_fp_violation": 0.019643791244165463,
            "ave_precision_score": 0.6824654246061038,
            "fpr": 0.16557017543859648,
            "logloss": 0.7545010258944236,
            "mae": 0.4404723253698505,
            "precision": 0.6504629629629629,
            "recall": 0.5903361344537815
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.764057653760485,
            "auditor_fn_violation": 0.029950075552636547,
            "auditor_fp_violation": 0.01961907707440242,
            "ave_precision_score": 0.7451343782489644,
            "fpr": 0.14489571899012074,
            "logloss": 0.6621528373303754,
            "mae": 0.4099341664242463,
            "precision": 0.6930232558139535,
            "recall": 0.6234309623430963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.770155598308789,
            "auditor_fn_violation": 0.015290984814978623,
            "auditor_fp_violation": 0.006709721551585388,
            "ave_precision_score": 0.7587105069418504,
            "fpr": 0.07236842105263158,
            "logloss": 0.6625918295561855,
            "mae": 0.36501342498926087,
            "precision": 0.811965811965812,
            "recall": 0.5987394957983193
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7772527418093373,
            "auditor_fn_violation": 0.0049740732745752825,
            "auditor_fp_violation": 0.006961362662657844,
            "ave_precision_score": 0.7635953340939725,
            "fpr": 0.06037321624588365,
            "logloss": 0.6646935442203742,
            "mae": 0.3717762731040218,
            "precision": 0.8275862068965517,
            "recall": 0.5523012552301255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5662193859833465,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5598760631161698,
            "fpr": 0.4780701754385965,
            "logloss": 0.7430552999532071,
            "mae": 0.4586485166168004,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.595781898892781,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5791436949373313,
            "fpr": 0.47530186608122943,
            "logloss": 0.7346873319951251,
            "mae": 0.4538147582311662,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8319052383789782,
            "auditor_fn_violation": 0.0037225416482382437,
            "auditor_fp_violation": 0.0024847094801223255,
            "ave_precision_score": 0.8286432555436278,
            "fpr": 0.05592105263157895,
            "logloss": 0.5589821588760189,
            "mae": 0.36748473059125897,
            "precision": 0.8375796178343949,
            "recall": 0.5525210084033614
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8288495697114195,
            "auditor_fn_violation": 0.008942309017172727,
            "auditor_fp_violation": 0.006928406466512702,
            "ave_precision_score": 0.8257898471762231,
            "fpr": 0.04061470911086718,
            "logloss": 0.5527676713215723,
            "mae": 0.3604202583144862,
            "precision": 0.8778877887788779,
            "recall": 0.5564853556485355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6481534719150819,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5276794928497714,
            "fpr": 0.4780701754385965,
            "logloss": 0.6919775663105152,
            "mae": 0.4987298217520379,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.655411519233551,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5356828568714511,
            "fpr": 0.47530186608122943,
            "logloss": 0.6911231305116027,
            "mae": 0.49831594462975715,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8518818541439779,
            "auditor_fn_violation": 0.005279743476337901,
            "auditor_fp_violation": 0.006196684371479157,
            "ave_precision_score": 0.8520781970504716,
            "fpr": 0.10526315789473684,
            "logloss": 0.4938139068779925,
            "mae": 0.3258048404547337,
            "precision": 0.7837837837837838,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8554275041464269,
            "auditor_fn_violation": 0.006664247757533452,
            "auditor_fp_violation": 0.011415519326273946,
            "ave_precision_score": 0.8556692270443256,
            "fpr": 0.0889132821075741,
            "logloss": 0.49151956171609085,
            "mae": 0.3241566326244275,
            "precision": 0.8137931034482758,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.5898282231204326,
            "auditor_fn_violation": 0.03329785861713106,
            "auditor_fp_violation": 0.02740976581361663,
            "ave_precision_score": 0.5584556269158247,
            "fpr": 0.40899122807017546,
            "logloss": 0.6932333201895354,
            "mae": 0.497014398212757,
            "precision": 0.5278481012658228,
            "recall": 0.8760504201680672
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6117031090154635,
            "auditor_fn_violation": 0.03906232059119364,
            "auditor_fp_violation": 0.0419861938889072,
            "ave_precision_score": 0.5775210229424612,
            "fpr": 0.3754116355653128,
            "logloss": 0.6839972877545256,
            "mae": 0.49265680685394025,
            "precision": 0.5482166446499339,
            "recall": 0.8682008368200836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.8060907344485512,
            "auditor_fn_violation": 0.004376750700280112,
            "auditor_fp_violation": 0.02085345243843554,
            "ave_precision_score": 0.8070623622954299,
            "fpr": 0.3574561403508772,
            "logloss": 0.9267371206487774,
            "mae": 0.35811459533298357,
            "precision": 0.5868187579214195,
            "recall": 0.9726890756302521
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7781127529714053,
            "auditor_fn_violation": 0.00035365063909722605,
            "auditor_fp_violation": 0.02036692921769597,
            "ave_precision_score": 0.7791354182658583,
            "fpr": 0.3589462129527991,
            "logloss": 0.9723978413129791,
            "mae": 0.36102183868354093,
            "precision": 0.587641866330391,
            "recall": 0.9748953974895398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.841210776394211,
            "auditor_fn_violation": 0.00791731166150671,
            "auditor_fp_violation": 0.009380532753903116,
            "ave_precision_score": 0.8414671164020311,
            "fpr": 0.23026315789473684,
            "logloss": 0.5796372430185804,
            "mae": 0.3323454644838389,
            "precision": 0.6703296703296703,
            "recall": 0.8970588235294118
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8675309580992009,
            "auditor_fn_violation": 0.004289736323594928,
            "auditor_fp_violation": 0.018402232909043432,
            "ave_precision_score": 0.8678239556413376,
            "fpr": 0.2239297475301866,
            "logloss": 0.532299033307121,
            "mae": 0.32061865604170786,
            "precision": 0.6832298136645962,
            "recall": 0.9205020920502092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8331633157928311,
            "auditor_fn_violation": 0.013761425622880734,
            "auditor_fp_violation": 0.009224609689361028,
            "ave_precision_score": 0.8338175643424268,
            "fpr": 0.19736842105263158,
            "logloss": 0.553735709217416,
            "mae": 0.3266448628304428,
            "precision": 0.6974789915966386,
            "recall": 0.8718487394957983
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8671804634909778,
            "auditor_fn_violation": 0.002163239623568748,
            "auditor_fp_violation": 0.02184742295221605,
            "ave_precision_score": 0.8673897863808242,
            "fpr": 0.1964873765093304,
            "logloss": 0.5245714668676602,
            "mae": 0.32417971665769585,
            "precision": 0.6976351351351351,
            "recall": 0.8640167364016736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8045653007791811,
            "auditor_fn_violation": 0.008343468966533985,
            "auditor_fp_violation": 0.003973523257685499,
            "ave_precision_score": 0.6869187538563183,
            "fpr": 0.10087719298245613,
            "logloss": 0.5889667072547959,
            "mae": 0.39160735967258614,
            "precision": 0.7728395061728395,
            "recall": 0.657563025210084
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8181678355074906,
            "auditor_fn_violation": 0.00013319309784181306,
            "auditor_fp_violation": 0.007787802658297485,
            "ave_precision_score": 0.7032219287674366,
            "fpr": 0.10098792535675083,
            "logloss": 0.5715517165196424,
            "mae": 0.3830637573934151,
            "precision": 0.7825059101654847,
            "recall": 0.6924686192468619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8044953371606459,
            "auditor_fn_violation": 0.013254643962848298,
            "auditor_fp_violation": 0.026728231128279413,
            "ave_precision_score": 0.7693671034441889,
            "fpr": 0.16776315789473684,
            "logloss": 2.2425722676268616,
            "mae": 0.28099323496765766,
            "precision": 0.7262969588550984,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7890848372552567,
            "auditor_fn_violation": 0.01566626402546285,
            "auditor_fp_violation": 0.024096049566119007,
            "ave_precision_score": 0.7538346822148423,
            "fpr": 0.1690450054884742,
            "logloss": 2.345490937371646,
            "mae": 0.2926030958216519,
            "precision": 0.7194899817850637,
            "recall": 0.8263598326359832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8168927812060345,
            "auditor_fn_violation": 0.01798383827215097,
            "auditor_fp_violation": 0.003186363270561727,
            "ave_precision_score": 0.811973560200659,
            "fpr": 0.12390350877192982,
            "logloss": 0.535156172279548,
            "mae": 0.33881063352077545,
            "precision": 0.7674897119341564,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8469025367753306,
            "auditor_fn_violation": 0.012862319672620552,
            "auditor_fp_violation": 0.01217858202163448,
            "ave_precision_score": 0.8387852778684628,
            "fpr": 0.11964873765093303,
            "logloss": 0.4988731433167413,
            "mae": 0.32524266866834184,
            "precision": 0.7775510204081633,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7725661361529451,
            "auditor_fn_violation": 0.0266843579537078,
            "auditor_fp_violation": 0.021147694350555288,
            "ave_precision_score": 0.766695467603944,
            "fpr": 0.14802631578947367,
            "logloss": 0.5777557657877964,
            "mae": 0.39746027510218,
            "precision": 0.7163865546218487,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7617994156787492,
            "auditor_fn_violation": 0.03051040513666071,
            "auditor_fp_violation": 0.028484293837444833,
            "ave_precision_score": 0.7577467910570124,
            "fpr": 0.15587266739846323,
            "logloss": 0.5822134050436496,
            "mae": 0.39681102765231313,
            "precision": 0.7084188911704312,
            "recall": 0.7217573221757322
        }
    }
]