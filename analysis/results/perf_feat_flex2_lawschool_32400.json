[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6063400172621951,
            "auditor_fn_violation": 0.01297439103958243,
            "auditor_fp_violation": 0.02384612231513364,
            "ave_precision_score": 0.6055663697272482,
            "fpr": 0.14692982456140352,
            "logloss": 2.368712268904579,
            "mae": 0.35490668826896266,
            "precision": 0.7015590200445434,
            "recall": 0.6508264462809917
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6266536673004731,
            "auditor_fn_violation": 0.008594717051638372,
            "auditor_fp_violation": 0.02569750915367977,
            "ave_precision_score": 0.6219232355008301,
            "fpr": 0.1437980241492865,
            "logloss": 2.349475007607951,
            "mae": 0.34114464820204854,
            "precision": 0.7069351230425056,
            "recall": 0.6723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5949013667192322,
            "auditor_fn_violation": 0.1018558793678411,
            "auditor_fp_violation": 0.06428307919331037,
            "ave_precision_score": 0.5900693375391707,
            "fpr": 0.17105263157894737,
            "logloss": 4.862660182346686,
            "mae": 0.4382249348082538,
            "precision": 0.61,
            "recall": 0.5041322314049587
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.577456569926792,
            "auditor_fn_violation": 0.08883387439568396,
            "auditor_fp_violation": 0.06132156484986971,
            "ave_precision_score": 0.5693876736898302,
            "fpr": 0.1800219538968167,
            "logloss": 5.240368426563585,
            "mae": 0.43568231202511376,
            "precision": 0.59,
            "recall": 0.502127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6362165809440958,
            "auditor_fn_violation": 0.007711686240394376,
            "auditor_fp_violation": 0.007911132972618461,
            "ave_precision_score": 0.6301967103097863,
            "fpr": 0.13596491228070176,
            "logloss": 2.3610683484521897,
            "mae": 0.3369407493651046,
            "precision": 0.7213483146067415,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6440402294643053,
            "auditor_fn_violation": 0.001994534881005206,
            "auditor_fp_violation": 0.020027330361343222,
            "ave_precision_score": 0.6330586593313874,
            "fpr": 0.1350164654226125,
            "logloss": 2.4400024896807624,
            "mae": 0.33852992007974925,
            "precision": 0.711943793911007,
            "recall": 0.6468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6690493152689996,
            "auditor_fn_violation": 0.12640459620124694,
            "auditor_fp_violation": 0.09804886046892933,
            "ave_precision_score": 0.5732679112656733,
            "fpr": 0.18859649122807018,
            "logloss": 13.358477569210923,
            "mae": 0.49419353041158426,
            "precision": 0.5497382198952879,
            "recall": 0.43388429752066116
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6586005424259799,
            "auditor_fn_violation": 0.12031436111824742,
            "auditor_fp_violation": 0.09691077309079504,
            "ave_precision_score": 0.5640409381842448,
            "fpr": 0.18441273326015367,
            "logloss": 13.493319676130874,
            "mae": 0.4889718375491016,
            "precision": 0.5371900826446281,
            "recall": 0.4148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4298245614035088,
            "auc_prc": 0.4754122739048937,
            "auditor_fn_violation": 0.051797883137596076,
            "auditor_fp_violation": 0.03987846368257092,
            "ave_precision_score": 0.4638845347625604,
            "fpr": 0.28289473684210525,
            "logloss": 5.560755091224412,
            "mae": 0.5664636897161579,
            "precision": 0.4625,
            "recall": 0.45867768595041325
        },
        "train": {
            "accuracy": 0.43468715697036225,
            "auc_prc": 0.4633153364078964,
            "auditor_fn_violation": 0.053569843753649274,
            "auditor_fp_violation": 0.039733566313462816,
            "ave_precision_score": 0.45173789425703315,
            "fpr": 0.287596048298573,
            "logloss": 5.669285728916261,
            "mae": 0.5650421347508513,
            "precision": 0.453027139874739,
            "recall": 0.46170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7201818870003085,
            "auditor_fn_violation": 0.0025418660287081342,
            "auditor_fp_violation": 0.012338088211182173,
            "ave_precision_score": 0.6102507191294106,
            "fpr": 0.3815789473684211,
            "logloss": 8.827883979207506,
            "mae": 0.3979750066596507,
            "precision": 0.5745721271393643,
            "recall": 0.9710743801652892
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7094503782127081,
            "auditor_fn_violation": 0.004414134572716445,
            "auditor_fp_violation": 0.020684453803475295,
            "ave_precision_score": 0.6008322407943714,
            "fpr": 0.40065861690450055,
            "logloss": 9.13011484218472,
            "mae": 0.42650228722790823,
            "precision": 0.5493827160493827,
            "recall": 0.9468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6446933827364627,
            "auditor_fn_violation": 0.11608307959982601,
            "auditor_fp_violation": 0.08548020167240532,
            "ave_precision_score": 0.5501766615416647,
            "fpr": 0.16885964912280702,
            "logloss": 16.206608628869198,
            "mae": 0.4885773104670321,
            "precision": 0.5561959654178674,
            "recall": 0.3987603305785124
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.6258385219576912,
            "auditor_fn_violation": 0.10570567765140015,
            "auditor_fp_violation": 0.08562019758507135,
            "ave_precision_score": 0.5335786557190135,
            "fpr": 0.16136114160263446,
            "logloss": 16.075613500530213,
            "mae": 0.48960755540602524,
            "precision": 0.5362776025236593,
            "recall": 0.3617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8162688196213091,
            "auditor_fn_violation": 0.010597904886182402,
            "auditor_fp_violation": 0.009842802098704705,
            "ave_precision_score": 0.8175564852740189,
            "fpr": 0.19078947368421054,
            "logloss": 0.8150684266595197,
            "mae": 0.2712393571897729,
            "precision": 0.7080536912751678,
            "recall": 0.871900826446281
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8376217029263053,
            "auditor_fn_violation": 0.0058504799495527485,
            "auditor_fp_violation": 0.025968821483954,
            "ave_precision_score": 0.8388838168110286,
            "fpr": 0.18990120746432493,
            "logloss": 0.7271980017119182,
            "mae": 0.27459531633520956,
            "precision": 0.7006920415224913,
            "recall": 0.8617021276595744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.6646122382401563,
            "auditor_fn_violation": 0.014802631578947371,
            "auditor_fp_violation": 0.016365387768486634,
            "ave_precision_score": 0.6648497883407775,
            "fpr": 0.14473684210526316,
            "logloss": 1.5504302571614652,
            "mae": 0.30813780816458636,
            "precision": 0.7333333333333333,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7001085368781539,
            "auditor_fn_violation": 0.00883294018730878,
            "auditor_fp_violation": 0.028671988370906357,
            "ave_precision_score": 0.6992790879316642,
            "fpr": 0.12952799121844127,
            "logloss": 1.4031265682626979,
            "mae": 0.29789265018191025,
            "precision": 0.7467811158798283,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6775696291441542,
            "auditor_fn_violation": 0.12297919385239961,
            "auditor_fp_violation": 0.0975287957042138,
            "ave_precision_score": 0.5827473907179176,
            "fpr": 0.18969298245614036,
            "logloss": 10.552745312205232,
            "mae": 0.48364896358439646,
            "precision": 0.5564102564102564,
            "recall": 0.44834710743801653
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6664260522675605,
            "auditor_fn_violation": 0.11749772286708551,
            "auditor_fp_violation": 0.09632085545524467,
            "ave_precision_score": 0.5764934410635812,
            "fpr": 0.18331503841931943,
            "logloss": 10.625178545781507,
            "mae": 0.4794534270156499,
            "precision": 0.5461956521739131,
            "recall": 0.4276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 32400,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.6016341406553172,
            "auditor_fn_violation": 0.0979320719153255,
            "auditor_fp_violation": 0.08314887686505985,
            "ave_precision_score": 0.5183398866842959,
            "fpr": 0.20614035087719298,
            "logloss": 17.88050066098136,
            "mae": 0.5265398026234143,
            "precision": 0.5052631578947369,
            "recall": 0.39669421487603307
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6020498736736621,
            "auditor_fn_violation": 0.10007940771189014,
            "auditor_fp_violation": 0.07528543799517613,
            "ave_precision_score": 0.5143951848222186,
            "fpr": 0.19319429198682767,
            "logloss": 17.020832882231826,
            "mae": 0.5022971523789431,
            "precision": 0.5178082191780822,
            "recall": 0.4021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8534811163668492,
            "auditor_fn_violation": 0.017566514426562273,
            "auditor_fp_violation": 0.029507911132972624,
            "ave_precision_score": 0.8538543995549972,
            "fpr": 0.1699561403508772,
            "logloss": 0.6517439586800515,
            "mae": 0.2647284844782982,
            "precision": 0.7299651567944251,
            "recall": 0.8657024793388429
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8535838411541725,
            "auditor_fn_violation": 0.01242497138986851,
            "auditor_fp_violation": 0.02652389166423979,
            "ave_precision_score": 0.8537807133475789,
            "fpr": 0.16794731064763996,
            "logloss": 0.6700447524349417,
            "mae": 0.26743481563404964,
            "precision": 0.720292504570384,
            "recall": 0.8382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7098549418866531,
            "auditor_fn_violation": 0.0010081375960562672,
            "auditor_fp_violation": 0.01719031808493196,
            "ave_precision_score": 0.7110526310983791,
            "fpr": 0.14144736842105263,
            "logloss": 2.6474033478656382,
            "mae": 0.32168730539584245,
            "precision": 0.7183406113537117,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7007718016373741,
            "auditor_fn_violation": 0.009349090314594676,
            "auditor_fp_violation": 0.02126441502323579,
            "ave_precision_score": 0.6996763127654959,
            "fpr": 0.14050493962678376,
            "logloss": 2.9448792669382735,
            "mae": 0.33255374957416817,
            "precision": 0.7057471264367816,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7419001029465855,
            "auditor_fn_violation": 0.07374583152095114,
            "auditor_fp_violation": 0.04597577471716675,
            "ave_precision_score": 0.7427116310624755,
            "fpr": 0.14692982456140352,
            "logloss": 1.3386597725474378,
            "mae": 0.3255856788632125,
            "precision": 0.7054945054945055,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.721688921318757,
            "auditor_fn_violation": 0.06947474134105612,
            "auditor_fp_violation": 0.059409933018212784,
            "ave_precision_score": 0.7223859339218366,
            "fpr": 0.15697036223929747,
            "logloss": 1.4223042888933783,
            "mae": 0.33540236310136257,
            "precision": 0.6822222222222222,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.5479285969010899,
            "auditor_fn_violation": 0.0032894736842105274,
            "auditor_fp_violation": 0.014095548450565673,
            "ave_precision_score": 0.5458567497242084,
            "fpr": 0.2225877192982456,
            "logloss": 3.4023627264831635,
            "mae": 0.3973229302141612,
            "precision": 0.6413427561837456,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.5417851823107657,
            "auditor_fn_violation": 0.011385664572482893,
            "auditor_fp_violation": 0.018153035088898355,
            "ave_precision_score": 0.533368838735293,
            "fpr": 0.22941822173435786,
            "logloss": 3.640728093883123,
            "mae": 0.40452970785343156,
            "precision": 0.6227436823104693,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8270774174224398,
            "auditor_fn_violation": 0.01116427432216906,
            "auditor_fp_violation": 0.0058488071815051695,
            "ave_precision_score": 0.8274161297605132,
            "fpr": 0.15460526315789475,
            "logloss": 0.7959520219298571,
            "mae": 0.2640763254355574,
            "precision": 0.7374301675977654,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7663383374326362,
            "auditor_fn_violation": 0.014064507088306047,
            "auditor_fp_violation": 0.013197229129485679,
            "ave_precision_score": 0.7675905472259833,
            "fpr": 0.17014270032930845,
            "logloss": 1.1369361816822012,
            "mae": 0.28677008894828077,
            "precision": 0.7053231939163498,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.6707117666231289,
            "auditor_fn_violation": 0.010915071770334928,
            "auditor_fp_violation": 0.008774491719954088,
            "ave_precision_score": 0.6720888163213503,
            "fpr": 0.16776315789473684,
            "logloss": 1.4856991202184981,
            "mae": 0.29868390638921083,
            "precision": 0.7156133828996283,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.706706771710781,
            "auditor_fn_violation": 0.012693556297732209,
            "auditor_fp_violation": 0.030927116547314143,
            "ave_precision_score": 0.7058761666564508,
            "fpr": 0.1690450054884742,
            "logloss": 1.4079511884764055,
            "mae": 0.3029763309222433,
            "precision": 0.7032755298651252,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 32400,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7490329148371374,
            "auditor_fn_violation": 0.03563143395679282,
            "auditor_fp_violation": 0.025693248893261186,
            "ave_precision_score": 0.7496036599146569,
            "fpr": 0.16776315789473684,
            "logloss": 1.4595692942029952,
            "mae": 0.33244818005469345,
            "precision": 0.6864754098360656,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7444671752115097,
            "auditor_fn_violation": 0.03725155896022608,
            "auditor_fp_violation": 0.026553760911609436,
            "ave_precision_score": 0.745024453018529,
            "fpr": 0.15367727771679474,
            "logloss": 1.5585628162577299,
            "mae": 0.3321579673664203,
            "precision": 0.6875,
            "recall": 0.6553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6906040262734128,
            "auditor_fn_violation": 0.005505110917790343,
            "auditor_fp_violation": 0.014515699294966397,
            "ave_precision_score": 0.5998947120146336,
            "fpr": 0.3574561403508772,
            "logloss": 8.466405486590212,
            "mae": 0.38123672040566847,
            "precision": 0.5868187579214195,
            "recall": 0.9566115702479339
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6763919945418868,
            "auditor_fn_violation": 0.0029194011724315125,
            "auditor_fp_violation": 0.022404424631177013,
            "ave_precision_score": 0.5893692175746831,
            "fpr": 0.3699231613611416,
            "logloss": 8.605596788623059,
            "mae": 0.40209913097676303,
            "precision": 0.5662805662805663,
            "recall": 0.9361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7894838482195742,
            "auditor_fn_violation": 0.014870595911265773,
            "auditor_fp_violation": 0.012256107558616168,
            "ave_precision_score": 0.7909675589110396,
            "fpr": 0.13815789473684212,
            "logloss": 0.8991597605896484,
            "mae": 0.2850841605626523,
            "precision": 0.7428571428571429,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7819142314081444,
            "auditor_fn_violation": 0.018964430016115093,
            "auditor_fp_violation": 0.017411282112552304,
            "ave_precision_score": 0.7832756693798768,
            "fpr": 0.13611416026344675,
            "logloss": 0.9984120378930447,
            "mae": 0.29114682045498574,
            "precision": 0.7356076759061834,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 32400,
        "test": {
            "accuracy": 0.41776315789473684,
            "auc_prc": 0.4733938624770476,
            "auditor_fn_violation": 0.08067819341742788,
            "auditor_fp_violation": 0.06091162485653388,
            "ave_precision_score": 0.45082796808502645,
            "fpr": 0.23684210526315788,
            "logloss": 9.584433249768589,
            "mae": 0.5832132915420322,
            "precision": 0.43896103896103894,
            "recall": 0.34917355371900827
        },
        "train": {
            "accuracy": 0.42151481888035125,
            "auc_prc": 0.45249232665506245,
            "auditor_fn_violation": 0.06208048205152159,
            "auditor_fp_violation": 0.06512989388949873,
            "ave_precision_score": 0.4351765267179786,
            "fpr": 0.21514818880351264,
            "logloss": 10.189376702641939,
            "mae": 0.5771863594403676,
            "precision": 0.41492537313432837,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6559505829605589,
            "auditor_fn_violation": 0.12033311584746993,
            "auditor_fp_violation": 0.09072440154123627,
            "ave_precision_score": 0.5656049365369291,
            "fpr": 0.18092105263157895,
            "logloss": 16.151889796775805,
            "mae": 0.4915681864135026,
            "precision": 0.547945205479452,
            "recall": 0.4132231404958678
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.634207725556919,
            "auditor_fn_violation": 0.11042109442511153,
            "auditor_fp_violation": 0.09101159673529127,
            "ave_precision_score": 0.5467914435162123,
            "fpr": 0.1734357848518112,
            "logloss": 16.06481474546605,
            "mae": 0.48970306516699935,
            "precision": 0.5339233038348082,
            "recall": 0.3851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.824492083642382,
            "auditor_fn_violation": 0.012854320719153255,
            "auditor_fp_violation": 0.013316732251188724,
            "ave_precision_score": 0.824820547549474,
            "fpr": 0.15679824561403508,
            "logloss": 0.7957621794665581,
            "mae": 0.2601985622374359,
            "precision": 0.7418772563176895,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.772243647120753,
            "auditor_fn_violation": 0.010864843403321112,
            "auditor_fp_violation": 0.015429955370366222,
            "ave_precision_score": 0.7735058200042515,
            "fpr": 0.16575192096597147,
            "logloss": 1.0874994078577165,
            "mae": 0.2840905507249894,
            "precision": 0.7145557655954632,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8505178797611059,
            "auditor_fn_violation": 0.006628787878787886,
            "auditor_fp_violation": 0.011725795212329889,
            "ave_precision_score": 0.7965819053362931,
            "fpr": 0.0756578947368421,
            "logloss": 6.685032248431592,
            "mae": 0.22728948449194172,
            "precision": 0.8341346153846154,
            "recall": 0.7169421487603306
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8177925644680761,
            "auditor_fn_violation": 0.010640633393278379,
            "auditor_fp_violation": 0.009406323817488942,
            "ave_precision_score": 0.7611515276561442,
            "fpr": 0.0801317233809001,
            "logloss": 7.7424046787211855,
            "mae": 0.2596537352489353,
            "precision": 0.8083989501312336,
            "recall": 0.6553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6339777368152744,
            "auditor_fn_violation": 0.11669022763520373,
            "auditor_fp_violation": 0.08444007214297426,
            "ave_precision_score": 0.5477116587586841,
            "fpr": 0.17105263157894737,
            "logloss": 16.17404410138278,
            "mae": 0.48896557457371537,
            "precision": 0.5542857142857143,
            "recall": 0.40082644628099173
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.6130095811036522,
            "auditor_fn_violation": 0.1041385431020389,
            "auditor_fp_violation": 0.08621011522062175,
            "ave_precision_score": 0.5309334459133266,
            "fpr": 0.16245883644346873,
            "logloss": 16.1316629673159,
            "mae": 0.49098993818342596,
            "precision": 0.5360501567398119,
            "recall": 0.3638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5754951878410515,
            "auditor_fn_violation": 0.08652312599681021,
            "auditor_fp_violation": 0.07425141416625676,
            "ave_precision_score": 0.5581070531374673,
            "fpr": 0.2225877192982456,
            "logloss": 5.302427025574915,
            "mae": 0.5022891571571234,
            "precision": 0.532258064516129,
            "recall": 0.4772727272727273
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5557456086884812,
            "auditor_fn_violation": 0.07391456664408996,
            "auditor_fp_violation": 0.07197741884898856,
            "ave_precision_score": 0.5375340191319768,
            "fpr": 0.2074643249176729,
            "logloss": 5.455078869171443,
            "mae": 0.48759751533258294,
            "precision": 0.5286783042394015,
            "recall": 0.451063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7524459155608076,
            "auditor_fn_violation": 0.010366826156299842,
            "auditor_fp_violation": 0.00998114444990983,
            "ave_precision_score": 0.7534605519385743,
            "fpr": 0.14035087719298245,
            "logloss": 0.854638949300593,
            "mae": 0.28944582041471806,
            "precision": 0.7450199203187251,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7507748507319735,
            "auditor_fn_violation": 0.008818927061681112,
            "auditor_fp_violation": 0.020131872727136964,
            "ave_precision_score": 0.7515800084180984,
            "fpr": 0.15477497255762898,
            "logloss": 0.9558917095771942,
            "mae": 0.3075981420863858,
            "precision": 0.7134146341463414,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6720724733949452,
            "auditor_fn_violation": 0.006189285196462241,
            "auditor_fp_violation": 0.02203230037711101,
            "ave_precision_score": 0.6721529035918921,
            "fpr": 0.13596491228070176,
            "logloss": 1.577866585472309,
            "mae": 0.334317865502521,
            "precision": 0.7383966244725738,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7124865925117042,
            "auditor_fn_violation": 0.006331597262769468,
            "auditor_fp_violation": 0.022250100186433894,
            "ave_precision_score": 0.7112536394221598,
            "fpr": 0.13062568605927552,
            "logloss": 1.3199246300215979,
            "mae": 0.3286918961458188,
            "precision": 0.7295454545454545,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8452660180598299,
            "auditor_fn_violation": 0.016603686385384946,
            "auditor_fp_violation": 0.019121987211018213,
            "ave_precision_score": 0.8459251540781378,
            "fpr": 0.1337719298245614,
            "logloss": 0.6312218333718144,
            "mae": 0.2542487708533272,
            "precision": 0.7621832358674464,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8310617969682608,
            "auditor_fn_violation": 0.01978186234439592,
            "auditor_fp_violation": 0.021578042120617,
            "ave_precision_score": 0.8307581367149343,
            "fpr": 0.13721185510428102,
            "logloss": 0.8312179593637546,
            "mae": 0.26880665841136003,
            "precision": 0.7422680412371134,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7208686643172165,
            "auditor_fn_violation": 0.007217812092214006,
            "auditor_fp_violation": 0.023756455976389576,
            "ave_precision_score": 0.6583458429773646,
            "fpr": 0.33881578947368424,
            "logloss": 5.683833354106543,
            "mae": 0.36582573310266686,
            "precision": 0.5955497382198953,
            "recall": 0.9400826446280992
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7072741944370925,
            "auditor_fn_violation": 0.006392320807156036,
            "auditor_fp_violation": 0.030070864789384463,
            "ave_precision_score": 0.6533153629369834,
            "fpr": 0.33699231613611413,
            "logloss": 5.599554086718398,
            "mae": 0.38000161163079976,
            "precision": 0.5851351351351352,
            "recall": 0.9212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7924499320349208,
            "auditor_fn_violation": 0.007208750181238222,
            "auditor_fp_violation": 0.016201426463354655,
            "ave_precision_score": 0.793840035889191,
            "fpr": 0.14473684210526316,
            "logloss": 0.7435697445774454,
            "mae": 0.3373710705885692,
            "precision": 0.7476099426386233,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7372360673270846,
            "auditor_fn_violation": 0.0019665086297498704,
            "auditor_fp_violation": 0.015098904545352721,
            "ave_precision_score": 0.7384649405403357,
            "fpr": 0.14818880351262348,
            "logloss": 0.9871663955530223,
            "mae": 0.3541467458993733,
            "precision": 0.7222222222222222,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.3376209369812868,
            "auditor_fn_violation": 0.0007612005219660776,
            "auditor_fp_violation": 0.0025721429742580765,
            "ave_precision_score": 0.5268028318824861,
            "fpr": 0.015350877192982455,
            "logloss": 18.413403403918696,
            "mae": 0.5431889666828276,
            "precision": 0.2222222222222222,
            "recall": 0.008264462809917356
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.424915286607227,
            "auditor_fn_violation": 0.0013849639162015132,
            "auditor_fp_violation": 0.0026658303277403168,
            "ave_precision_score": 0.5152040245733479,
            "fpr": 0.006586169045005488,
            "logloss": 17.546234563054508,
            "mae": 0.5153489295359487,
            "precision": 0.5384615384615384,
            "recall": 0.014893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5311462354605822,
            "auditor_fn_violation": 0.02663975279106859,
            "auditor_fp_violation": 0.018266314149860637,
            "ave_precision_score": 0.531764409966181,
            "fpr": 0.18640350877192982,
            "logloss": 3.7998539859111853,
            "mae": 0.48621396229683717,
            "precision": 0.5514511873350924,
            "recall": 0.4318181818181818
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5146467613651828,
            "auditor_fn_violation": 0.029310787771212373,
            "auditor_fp_violation": 0.012316086332081323,
            "ave_precision_score": 0.5161295978868916,
            "fpr": 0.16575192096597147,
            "logloss": 4.07737112349142,
            "mae": 0.4812698632181108,
            "precision": 0.5492537313432836,
            "recall": 0.39148936170212767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8285516637955983,
            "auditor_fn_violation": 0.00912987530810498,
            "auditor_fp_violation": 0.0072706591244466314,
            "ave_precision_score": 0.8288962286896249,
            "fpr": 0.16776315789473684,
            "logloss": 0.7962050527751683,
            "mae": 0.2645575884876963,
            "precision": 0.7262969588550984,
            "recall": 0.8388429752066116
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7677941504748521,
            "auditor_fn_violation": 0.014242006679589886,
            "auditor_fp_violation": 0.013764744829508832,
            "ave_precision_score": 0.7691368655996516,
            "fpr": 0.17672886937431395,
            "logloss": 1.1517084796737702,
            "mae": 0.28436931722542746,
            "precision": 0.7012987012987013,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7922255895583252,
            "auditor_fn_violation": 0.013928157169783965,
            "auditor_fp_violation": 0.010501209214625353,
            "ave_precision_score": 0.7926950403719127,
            "fpr": 0.13925438596491227,
            "logloss": 0.8561851621042532,
            "mae": 0.2791141513061065,
            "precision": 0.744466800804829,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7490711249808546,
            "auditor_fn_violation": 0.021865147021043044,
            "auditor_fp_violation": 0.016345945623035166,
            "ave_precision_score": 0.7503587971656194,
            "fpr": 0.141602634467618,
            "logloss": 1.2089613239683086,
            "mae": 0.29589372594503294,
            "precision": 0.7261146496815286,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7717696901431086,
            "auditor_fn_violation": 0.001531462954907931,
            "auditor_fp_violation": 0.00398630923102149,
            "ave_precision_score": 0.5492783555054562,
            "fpr": 0.4473684210526316,
            "logloss": 14.948380533753953,
            "mae": 0.4516730512476545,
            "precision": 0.5400225479143179,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7571429126225446,
            "auditor_fn_violation": 0.0027559147067753465,
            "auditor_fp_violation": 0.004659602589663753,
            "ave_precision_score": 0.5244646647572364,
            "fpr": 0.4643249176728869,
            "logloss": 15.896450225154627,
            "mae": 0.4704990112680773,
            "precision": 0.5236486486486487,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 32400,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7068250798540412,
            "auditor_fn_violation": 0.013613255763375385,
            "auditor_fp_violation": 0.024927242170847682,
            "ave_precision_score": 0.7068845179452427,
            "fpr": 0.16557017543859648,
            "logloss": 1.9732053648541583,
            "mae": 0.28481358299543424,
            "precision": 0.7264492753623188,
            "recall": 0.8285123966942148
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.734706187653698,
            "auditor_fn_violation": 0.011065698203984398,
            "auditor_fp_violation": 0.03007086478938447,
            "ave_precision_score": 0.733005472452807,
            "fpr": 0.15477497255762898,
            "logloss": 1.711659539280518,
            "mae": 0.28652218656775574,
            "precision": 0.7191235059760956,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 32400,
        "test": {
            "accuracy": 0.28618421052631576,
            "auc_prc": 0.44104122091911435,
            "auditor_fn_violation": 0.008978088299260549,
            "auditor_fp_violation": 0.010211715035251697,
            "ave_precision_score": 0.3897201445876587,
            "fpr": 0.34868421052631576,
            "logloss": 19.844593720645463,
            "mae": 0.7144740093500299,
            "precision": 0.32196162046908317,
            "recall": 0.3119834710743802
        },
        "train": {
            "accuracy": 0.3216245883644347,
            "auc_prc": 0.45564988897257436,
            "auditor_fn_violation": 0.0024476259429665717,
            "auditor_fp_violation": 0.006197868829200182,
            "ave_precision_score": 0.3884549198860312,
            "fpr": 0.3391877058177827,
            "logloss": 18.969012370704174,
            "mae": 0.6857475978696413,
            "precision": 0.3425531914893617,
            "recall": 0.3425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 32400,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8444312209845202,
            "auditor_fn_violation": 0.013828476149050313,
            "auditor_fp_violation": 0.0068658796524020405,
            "ave_precision_score": 0.8447559627433643,
            "fpr": 0.15789473684210525,
            "logloss": 0.7391083885411222,
            "mae": 0.2617481030174992,
            "precision": 0.7352941176470589,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8333955693250712,
            "auditor_fn_violation": 0.014094868860499333,
            "auditor_fp_violation": 0.021550661977194834,
            "ave_precision_score": 0.8336272010992145,
            "fpr": 0.16465422612513722,
            "logloss": 0.8242906376621677,
            "mae": 0.2743436316618369,
            "precision": 0.7142857142857143,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7733990030228332,
            "auditor_fn_violation": 0.0014408438451500654,
            "auditor_fp_violation": 0.008833415313985902,
            "ave_precision_score": 0.5496532551691459,
            "fpr": 0.4342105263157895,
            "logloss": 14.965217897500715,
            "mae": 0.4379352376906057,
            "precision": 0.548460661345496,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.758935525355597,
            "auditor_fn_violation": 0.0008734848307915082,
            "auditor_fp_violation": 0.007260716214769836,
            "ave_precision_score": 0.524948817707359,
            "fpr": 0.4621295279912184,
            "logloss": 15.937548771238058,
            "mae": 0.4683313478751482,
            "precision": 0.5242937853107345,
            "recall": 0.9872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7724945779905735,
            "auditor_fn_violation": 0.004118638538494998,
            "auditor_fp_violation": 0.010232210198393196,
            "ave_precision_score": 0.6040538835427596,
            "fpr": 0.3881578947368421,
            "logloss": 11.74276371982229,
            "mae": 0.40308858121361857,
            "precision": 0.5709090909090909,
            "recall": 0.9731404958677686
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7454989678252039,
            "auditor_fn_violation": 0.004208608730177266,
            "auditor_fp_violation": 0.01579087544274936,
            "ave_precision_score": 0.5734183798299407,
            "fpr": 0.4094401756311745,
            "logloss": 12.625629015133962,
            "mae": 0.43872423780622105,
            "precision": 0.543451652386781,
            "recall": 0.9446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 32400,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8361637536844598,
            "auditor_fn_violation": 0.011427069740466872,
            "auditor_fp_violation": 0.0002971798655517291,
            "ave_precision_score": 0.7361020783693824,
            "fpr": 0.10307017543859649,
            "logloss": 8.191815024957366,
            "mae": 0.24338448831929324,
            "precision": 0.7911111111111111,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8086640990012453,
            "auditor_fn_violation": 0.006777681761916997,
            "auditor_fp_violation": 0.00756438689636118,
            "ave_precision_score": 0.700046667456963,
            "fpr": 0.1141602634467618,
            "logloss": 8.94817683313958,
            "mae": 0.265955299643457,
            "precision": 0.7614678899082569,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 32400,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.5933358625146091,
            "auditor_fn_violation": 0.10000724952878064,
            "auditor_fp_violation": 0.0849345179537629,
            "ave_precision_score": 0.5186268825000092,
            "fpr": 0.21162280701754385,
            "logloss": 18.096758412108876,
            "mae": 0.5380388961881711,
            "precision": 0.4960835509138381,
            "recall": 0.3925619834710744
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5920634296974294,
            "auditor_fn_violation": 0.09615106149426632,
            "auditor_fp_violation": 0.07477766078989226,
            "ave_precision_score": 0.5100432889181378,
            "fpr": 0.1942919868276619,
            "logloss": 17.378205512029325,
            "mae": 0.5122055913977445,
            "precision": 0.505586592178771,
            "recall": 0.3851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6062224391281795,
            "auditor_fn_violation": 0.014372190807597508,
            "auditor_fp_violation": 0.02384612231513364,
            "ave_precision_score": 0.6054816402342837,
            "fpr": 0.14692982456140352,
            "logloss": 2.362222557448088,
            "mae": 0.3555468567507869,
            "precision": 0.6995515695067265,
            "recall": 0.6446280991735537
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6259856862254031,
            "auditor_fn_violation": 0.003690123081953434,
            "auditor_fp_violation": 0.02216547065221991,
            "ave_precision_score": 0.6214918945809125,
            "fpr": 0.1437980241492865,
            "logloss": 2.349345534301365,
            "mae": 0.3412970974411106,
            "precision": 0.7062780269058296,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8321486589890543,
            "auditor_fn_violation": 0.017086233144845586,
            "auditor_fp_violation": 0.015819704049844244,
            "ave_precision_score": 0.8325421068132971,
            "fpr": 0.16776315789473684,
            "logloss": 0.7376352578634101,
            "mae": 0.27823202989127777,
            "precision": 0.7228260869565217,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7961168163802843,
            "auditor_fn_violation": 0.021019688441506878,
            "auditor_fp_violation": 0.020124405415294557,
            "ave_precision_score": 0.7976163348589707,
            "fpr": 0.16136114160263446,
            "logloss": 0.8922512464758323,
            "mae": 0.29233421744596144,
            "precision": 0.7134502923976608,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.33767400704443745,
            "auditor_fn_violation": 0.0007612005219660776,
            "auditor_fp_violation": 0.0016754795868175107,
            "ave_precision_score": 0.5268596024579517,
            "fpr": 0.01425438596491228,
            "logloss": 18.39366329584227,
            "mae": 0.5406944076700189,
            "precision": 0.23529411764705882,
            "recall": 0.008264462809917356
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.42569024445500625,
            "auditor_fn_violation": 0.0017516407034589233,
            "auditor_fp_violation": 0.0026658303277403168,
            "ave_precision_score": 0.5159903657819274,
            "fpr": 0.006586169045005488,
            "logloss": 17.5390100670993,
            "mae": 0.5163066019935765,
            "precision": 0.45454545454545453,
            "recall": 0.010638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7175957671425345,
            "auditor_fn_violation": 0.009886544874583158,
            "auditor_fp_violation": 0.010537075750122991,
            "ave_precision_score": 0.5499271867921837,
            "fpr": 0.3366228070175439,
            "logloss": 15.166545168407637,
            "mae": 0.46159406310830686,
            "precision": 0.5478645066273933,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6939253643350477,
            "auditor_fn_violation": 0.014727795034682491,
            "auditor_fp_violation": 0.006854992271332257,
            "ave_precision_score": 0.5212970957080632,
            "fpr": 0.3556531284302964,
            "logloss": 15.939001159922276,
            "mae": 0.4879097256291119,
            "precision": 0.5221238938053098,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8561077188319031,
            "auditor_fn_violation": 0.015921777584457016,
            "auditor_fp_violation": 0.016967433185768162,
            "ave_precision_score": 0.8564149519696154,
            "fpr": 0.13267543859649122,
            "logloss": 0.6644239218181486,
            "mae": 0.2568223453749857,
            "precision": 0.762278978388998,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8388569813039459,
            "auditor_fn_violation": 0.0223742905855151,
            "auditor_fp_violation": 0.02095327702980205,
            "ave_precision_score": 0.8393205504037763,
            "fpr": 0.132821075740944,
            "logloss": 0.8175002873742485,
            "mae": 0.2694468779574322,
            "precision": 0.7425531914893617,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.845050443659924,
            "auditor_fn_violation": 0.011800873568218065,
            "auditor_fp_violation": 0.01641662567634039,
            "ave_precision_score": 0.8453422810022748,
            "fpr": 0.15570175438596492,
            "logloss": 0.8591486330101673,
            "mae": 0.26827875486556924,
            "precision": 0.7432188065099458,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8511234424299684,
            "auditor_fn_violation": 0.00466637083401453,
            "auditor_fp_violation": 0.027029179765576197,
            "ave_precision_score": 0.8512406106537705,
            "fpr": 0.15916575192096596,
            "logloss": 0.7981346084198977,
            "mae": 0.2672690896572878,
            "precision": 0.7304832713754646,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7458625366081156,
            "auditor_fn_violation": 0.010042862838915471,
            "auditor_fp_violation": 0.01912198721101821,
            "ave_precision_score": 0.7470793508601186,
            "fpr": 0.13596491228070176,
            "logloss": 1.2457619148951335,
            "mae": 0.2767434811039471,
            "precision": 0.756385068762279,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.792587207398971,
            "auditor_fn_violation": 0.010890534133638514,
            "auditor_fp_violation": 0.015559388775634663,
            "ave_precision_score": 0.7915048578957355,
            "fpr": 0.11964873765093303,
            "logloss": 1.1414919700590398,
            "mae": 0.27582392557236185,
            "precision": 0.7609649122807017,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 32400,
        "test": {
            "accuracy": 0.28399122807017546,
            "auc_prc": 0.4423302013631266,
            "auditor_fn_violation": 0.010244490358126742,
            "auditor_fp_violation": 0.00908448106246926,
            "ave_precision_score": 0.39101958304218365,
            "fpr": 0.34868421052631576,
            "logloss": 20.375410960095444,
            "mae": 0.7185516341104305,
            "precision": 0.31905781584582443,
            "recall": 0.30785123966942146
        },
        "train": {
            "accuracy": 0.31613611416026344,
            "auc_prc": 0.45867217149274037,
            "auditor_fn_violation": 0.0024616390685942443,
            "auditor_fp_violation": 0.00439326846728446,
            "ave_precision_score": 0.3896866086097174,
            "fpr": 0.33699231613611413,
            "logloss": 19.461115332003864,
            "mae": 0.6903950170474714,
            "precision": 0.33405639913232105,
            "recall": 0.3276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7980622875193044,
            "auditor_fn_violation": 0.007222343047701905,
            "auditor_fp_violation": 0.01927570093457944,
            "ave_precision_score": 0.7995435523038956,
            "fpr": 0.14583333333333334,
            "logloss": 0.7144173765395564,
            "mae": 0.34133894034337753,
            "precision": 0.744721689059501,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.748242671115426,
            "auditor_fn_violation": 0.005815447135483569,
            "auditor_fp_violation": 0.02265831323381896,
            "ave_precision_score": 0.7499019740139874,
            "fpr": 0.13721185510428102,
            "logloss": 0.9197044522169497,
            "mae": 0.35657442239126713,
            "precision": 0.7340425531914894,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.745429170371682,
            "auditor_fn_violation": 0.0017262940408873423,
            "auditor_fp_violation": 0.013660026233808836,
            "ave_precision_score": 0.7449423536447752,
            "fpr": 0.42105263157894735,
            "logloss": 3.2486291433122685,
            "mae": 0.42028756015761337,
            "precision": 0.5560693641618497,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7496379956006752,
            "auditor_fn_violation": 0.0027138753298923328,
            "auditor_fp_violation": 0.014354662465059204,
            "ave_precision_score": 0.7483595020182706,
            "fpr": 0.433589462129528,
            "logloss": 3.3230857281218142,
            "mae": 0.43492404886775615,
            "precision": 0.540162980209546,
            "recall": 0.9872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 32400,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7137950758171712,
            "auditor_fn_violation": 0.0042228505147165465,
            "auditor_fp_violation": 0.012294535989506477,
            "ave_precision_score": 0.7142976028839012,
            "fpr": 0.14144736842105263,
            "logloss": 1.067943685188766,
            "mae": 0.29673811758529706,
            "precision": 0.7404426559356136,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6825426613407084,
            "auditor_fn_violation": 0.009879253567508232,
            "auditor_fp_violation": 0.009466062312228227,
            "ave_precision_score": 0.6817519700386298,
            "fpr": 0.1756311745334797,
            "logloss": 1.3205831489952295,
            "mae": 0.32819363237536797,
            "precision": 0.6850393700787402,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 32400,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.5927471321839493,
            "auditor_fn_violation": 0.09951790633608816,
            "auditor_fp_violation": 0.08099944663059519,
            "ave_precision_score": 0.5180758541395758,
            "fpr": 0.22916666666666666,
            "logloss": 18.218894620522104,
            "mae": 0.5510510425886412,
            "precision": 0.4775,
            "recall": 0.39462809917355374
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5951239646045317,
            "auditor_fn_violation": 0.0933344232431044,
            "auditor_fp_violation": 0.07494194165042527,
            "ave_precision_score": 0.5095891926339033,
            "fpr": 0.1986827661909989,
            "logloss": 17.303704894270442,
            "mae": 0.5112976742207187,
            "precision": 0.5081521739130435,
            "recall": 0.39787234042553193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8312351739179732,
            "auditor_fn_violation": 0.006644646222995507,
            "auditor_fp_violation": 0.00620234874569602,
            "ave_precision_score": 0.8325759406772333,
            "fpr": 0.07346491228070176,
            "logloss": 0.7732730157574218,
            "mae": 0.29729662168597665,
            "precision": 0.820855614973262,
            "recall": 0.6342975206611571
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.832251551503575,
            "auditor_fn_violation": 0.015134175677884956,
            "auditor_fp_violation": 0.010230217224101498,
            "ave_precision_score": 0.8329740003617374,
            "fpr": 0.06476399560922064,
            "logloss": 0.8676378700468583,
            "mae": 0.2991993509997718,
            "precision": 0.830945558739255,
            "recall": 0.6170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8193221010062107,
            "auditor_fn_violation": 0.020810678555893868,
            "auditor_fp_violation": 0.017882029840957533,
            "ave_precision_score": 0.8195975939664234,
            "fpr": 0.1611842105263158,
            "logloss": 0.7935054291565898,
            "mae": 0.28193087999496397,
            "precision": 0.7282809611829945,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.765374428467192,
            "auditor_fn_violation": 0.02538244155358853,
            "auditor_fp_violation": 0.022205296315379437,
            "ave_precision_score": 0.7667101459418166,
            "fpr": 0.150384193194292,
            "logloss": 1.0445444597063043,
            "mae": 0.2985846066369608,
            "precision": 0.7226720647773279,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5662047172102969,
            "auditor_fn_violation": 0.087891474554154,
            "auditor_fp_violation": 0.07200207001147729,
            "ave_precision_score": 0.5348576358025927,
            "fpr": 0.22039473684210525,
            "logloss": 7.6404702175538155,
            "mae": 0.5112895792566514,
            "precision": 0.5191387559808612,
            "recall": 0.44834710743801653
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5298487535313307,
            "auditor_fn_violation": 0.06997220730083847,
            "auditor_fp_violation": 0.06953560787652055,
            "ave_precision_score": 0.5011877402830486,
            "fpr": 0.20087815587266739,
            "logloss": 8.243245367894337,
            "mae": 0.5127544861727402,
            "precision": 0.5093833780160858,
            "recall": 0.40425531914893614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.7233453683769816,
            "auditor_fn_violation": 0.02163984341017834,
            "auditor_fp_violation": 0.025157812756189547,
            "ave_precision_score": 0.71263602780796,
            "fpr": 0.15789473684210525,
            "logloss": 1.8055821033737447,
            "mae": 0.27593658080916894,
            "precision": 0.7391304347826086,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7512305116926498,
            "auditor_fn_violation": 0.01775930121213537,
            "auditor_fp_violation": 0.027994952097194537,
            "ave_precision_score": 0.7432507997159888,
            "fpr": 0.15477497255762898,
            "logloss": 1.62133748599697,
            "mae": 0.2908746199495395,
            "precision": 0.7251461988304093,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6824961871670093,
            "auditor_fn_violation": 0.0025418660287081342,
            "auditor_fp_violation": 0.011495224626988041,
            "ave_precision_score": 0.5829168760873418,
            "fpr": 0.37390350877192985,
            "logloss": 8.533542514854476,
            "mae": 0.390499042074893,
            "precision": 0.5795314426633785,
            "recall": 0.9710743801652892
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6628867288684736,
            "auditor_fn_violation": 0.005096106686596445,
            "auditor_fp_violation": 0.02258612921934234,
            "ave_precision_score": 0.5671473902863835,
            "fpr": 0.3973655323819978,
            "logloss": 8.826234203396693,
            "mae": 0.4270829379889381,
            "precision": 0.5497512437810945,
            "recall": 0.9404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7539736213598061,
            "auditor_fn_violation": 0.01580397274177179,
            "auditor_fp_violation": 0.013831673225118876,
            "ave_precision_score": 0.7547313006243076,
            "fpr": 0.11513157894736842,
            "logloss": 2.194857753059993,
            "mae": 0.31226706600806914,
            "precision": 0.7494033412887828,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7394323556194298,
            "auditor_fn_violation": 0.018163346334399883,
            "auditor_fp_violation": 0.020983146277171686,
            "ave_precision_score": 0.740952982655478,
            "fpr": 0.12184412733260154,
            "logloss": 2.6408559439447674,
            "mae": 0.3216672009179775,
            "precision": 0.7238805970149254,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7138958416013518,
            "auditor_fn_violation": 0.009388139770914891,
            "auditor_fp_violation": 0.02233972782423349,
            "ave_precision_score": 0.703685415646645,
            "fpr": 0.17105263157894737,
            "logloss": 1.8637111522034282,
            "mae": 0.2805273428632016,
            "precision": 0.7301038062283737,
            "recall": 0.871900826446281
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7458820049305837,
            "auditor_fn_violation": 0.010930237989583579,
            "auditor_fp_violation": 0.02878648715248998,
            "ave_precision_score": 0.738997671599805,
            "fpr": 0.1778265642151482,
            "logloss": 1.5932031568143152,
            "mae": 0.29536689525642124,
            "precision": 0.7011070110701108,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4232456140350877,
            "auc_prc": 0.5165048698286292,
            "auditor_fn_violation": 0.01971871828331159,
            "auditor_fp_violation": 0.026487436464994272,
            "ave_precision_score": 0.49305730877559195,
            "fpr": 0.28399122807017546,
            "logloss": 5.522969339046822,
            "mae": 0.5651879692061349,
            "precision": 0.45588235294117646,
            "recall": 0.44834710743801653
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5186649128207563,
            "auditor_fn_violation": 0.012871055889016068,
            "auditor_fp_violation": 0.03251267576185249,
            "ave_precision_score": 0.49740622669240053,
            "fpr": 0.23819978046103182,
            "logloss": 5.4006732224415686,
            "mae": 0.528405796396282,
            "precision": 0.49061032863849763,
            "recall": 0.44468085106382976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8398432239740172,
            "auditor_fn_violation": 0.009594298245614039,
            "auditor_fp_violation": 0.001667793900639452,
            "ave_precision_score": 0.8406364935199815,
            "fpr": 0.09320175438596491,
            "logloss": 0.6229353727109275,
            "mae": 0.2727349717790314,
            "precision": 0.8102678571428571,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.84153521449603,
            "auditor_fn_violation": 0.003232360978116169,
            "auditor_fp_violation": 0.01584563572959371,
            "ave_precision_score": 0.8417455642333114,
            "fpr": 0.10098792535675083,
            "logloss": 0.672228903575914,
            "mae": 0.28601211494540363,
            "precision": 0.7830188679245284,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7300108740591955,
            "auditor_fn_violation": 0.03650137741046832,
            "auditor_fp_violation": 0.030148384981144458,
            "ave_precision_score": 0.7305045919208999,
            "fpr": 0.16228070175438597,
            "logloss": 1.716297231087933,
            "mae": 0.34507825337009085,
            "precision": 0.6851063829787234,
            "recall": 0.6652892561983471
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7147736121944658,
            "auditor_fn_violation": 0.03458906509096855,
            "auditor_fp_violation": 0.02480392083653806,
            "ave_precision_score": 0.7149999246662039,
            "fpr": 0.15916575192096596,
            "logloss": 1.7486719008954468,
            "mae": 0.3476856631202531,
            "precision": 0.6741573033707865,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6101141903302999,
            "auditor_fn_violation": 0.016850623459475148,
            "auditor_fp_violation": 0.020279963928512876,
            "ave_precision_score": 0.610326333970316,
            "fpr": 0.14692982456140352,
            "logloss": 2.319086096474577,
            "mae": 0.3756056659439071,
            "precision": 0.6801909307875895,
            "recall": 0.5888429752066116
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6315362315433591,
            "auditor_fn_violation": 0.011780367610995632,
            "auditor_fp_violation": 0.024674487431269612,
            "ave_precision_score": 0.6297420192847529,
            "fpr": 0.13391877058177826,
            "logloss": 2.0601050439581416,
            "mae": 0.36321337859522823,
            "precision": 0.6934673366834171,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6610436506749044,
            "auditor_fn_violation": 0.01275010874293171,
            "auditor_fp_violation": 0.016457616002623392,
            "ave_precision_score": 0.661315121760644,
            "fpr": 0.15570175438596492,
            "logloss": 1.4742625171279624,
            "mae": 0.31171567896883706,
            "precision": 0.7237354085603113,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.6975726931027192,
            "auditor_fn_violation": 0.007088306046663708,
            "auditor_fp_violation": 0.029473479841991685,
            "ave_precision_score": 0.6967441979223798,
            "fpr": 0.14489571899012074,
            "logloss": 1.3781299286649784,
            "mae": 0.3051829223436471,
            "precision": 0.7278350515463917,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7919502253560308,
            "auditor_fn_violation": 0.010783674061186022,
            "auditor_fp_violation": 0.011484977045417278,
            "ave_precision_score": 0.7924180932674922,
            "fpr": 0.1524122807017544,
            "logloss": 0.8585280519804686,
            "mae": 0.2761417970271756,
            "precision": 0.7362428842504743,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.749668719317105,
            "auditor_fn_violation": 0.017376275778312363,
            "auditor_fp_violation": 0.01992527709949695,
            "ave_precision_score": 0.7510646783893502,
            "fpr": 0.1602634467618002,
            "logloss": 1.2088520457752483,
            "mae": 0.29502317739138784,
            "precision": 0.7142857142857143,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5344485725837614,
            "auditor_fn_violation": 0.025251014934029294,
            "auditor_fp_violation": 0.04161030496802755,
            "ave_precision_score": 0.5262945985157786,
            "fpr": 0.2916666666666667,
            "logloss": 3.6366156778918124,
            "mae": 0.49350067964668365,
            "precision": 0.5325131810193322,
            "recall": 0.6260330578512396
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5619563806785326,
            "auditor_fn_violation": 0.01475115024406194,
            "auditor_fp_violation": 0.043531938937301964,
            "ave_precision_score": 0.5555561231019328,
            "fpr": 0.2645444566410538,
            "logloss": 2.976697420216498,
            "mae": 0.46538164517996183,
            "precision": 0.5512104283054003,
            "recall": 0.6297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6340640808226079,
            "auditor_fn_violation": 0.10113092648977816,
            "auditor_fp_violation": 0.06291502705361535,
            "ave_precision_score": 0.6311053037351009,
            "fpr": 0.1611842105263158,
            "logloss": 4.1910124286705654,
            "mae": 0.4236357861185764,
            "precision": 0.6269035532994924,
            "recall": 0.5103305785123967
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6237067875511291,
            "auditor_fn_violation": 0.08820561926337671,
            "auditor_fp_violation": 0.06321328384994686,
            "ave_precision_score": 0.6189353510696822,
            "fpr": 0.1690450054884742,
            "logloss": 4.438181826205235,
            "mae": 0.42159861550966365,
            "precision": 0.6061381074168798,
            "recall": 0.5042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6700877314625052,
            "auditor_fn_violation": 0.07693562418442801,
            "auditor_fp_violation": 0.030348212821774058,
            "ave_precision_score": 0.6715757947238088,
            "fpr": 0.1074561403508772,
            "logloss": 2.3672943361053576,
            "mae": 0.43378852514279725,
            "precision": 0.6487455197132617,
            "recall": 0.3739669421487603
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6799568346239626,
            "auditor_fn_violation": 0.0572296050634094,
            "auditor_fp_violation": 0.03361037060268674,
            "ave_precision_score": 0.680744043562376,
            "fpr": 0.09769484083424808,
            "logloss": 2.2849324945779355,
            "mae": 0.4171236389331218,
            "precision": 0.6615969581749049,
            "recall": 0.3702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7068698723448141,
            "auditor_fn_violation": 0.004494707843990147,
            "auditor_fp_violation": 0.012061403508771931,
            "ave_precision_score": 0.7073683303468925,
            "fpr": 0.1425438596491228,
            "logloss": 1.0746944022119704,
            "mae": 0.3002112605762646,
            "precision": 0.7379032258064516,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6692881429086182,
            "auditor_fn_violation": 0.004631338019945351,
            "auditor_fp_violation": 0.010576202672799826,
            "ave_precision_score": 0.668848756158799,
            "fpr": 0.17672886937431395,
            "logloss": 1.3901383577197333,
            "mae": 0.3331911939364727,
            "precision": 0.6830708661417323,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.6954742489938464,
            "auditor_fn_violation": 0.012813542119762218,
            "auditor_fp_violation": 0.018742826692900477,
            "ave_precision_score": 0.69556945692501,
            "fpr": 0.14692982456140352,
            "logloss": 1.5368418752501811,
            "mae": 0.29992018067431,
            "precision": 0.7372549019607844,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7489615563218786,
            "auditor_fn_violation": 0.016930191279164824,
            "auditor_fp_violation": 0.019061558029724878,
            "ave_precision_score": 0.7473743261586431,
            "fpr": 0.13062568605927552,
            "logloss": 1.2976252744301249,
            "mae": 0.28842142572634183,
            "precision": 0.75,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7241512240068091,
            "auditor_fn_violation": 0.016642199507032038,
            "auditor_fp_violation": 0.019557509427775045,
            "ave_precision_score": 0.7242479418226296,
            "fpr": 0.13048245614035087,
            "logloss": 1.5390486355745372,
            "mae": 0.2829003181578309,
            "precision": 0.7610441767068273,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7784172848489586,
            "auditor_fn_violation": 0.00795478431464138,
            "auditor_fp_violation": 0.01915614397972874,
            "ave_precision_score": 0.777026628735876,
            "fpr": 0.10647639956092206,
            "logloss": 1.281969522779164,
            "mae": 0.2731146191124486,
            "precision": 0.7844444444444445,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.605745171907651,
            "auditor_fn_violation": 0.013837538060026104,
            "auditor_fp_violation": 0.024599319560583702,
            "ave_precision_score": 0.6049113028545492,
            "fpr": 0.14692982456140352,
            "logloss": 2.346427712327564,
            "mae": 0.3566963225911347,
            "precision": 0.7008928571428571,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6259468347124668,
            "auditor_fn_violation": 0.004885909802181392,
            "auditor_fp_violation": 0.022750410079875348,
            "ave_precision_score": 0.6215185326323405,
            "fpr": 0.14270032930845225,
            "logloss": 2.299844241869512,
            "mae": 0.34213984680941933,
            "precision": 0.70917225950783,
            "recall": 0.674468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 32400,
        "test": {
            "accuracy": 0.41776315789473684,
            "auc_prc": 0.5195700874964029,
            "auditor_fn_violation": 0.07735247208931421,
            "auditor_fp_violation": 0.0592258976881456,
            "ave_precision_score": 0.4594118367555128,
            "fpr": 0.2565789473684211,
            "logloss": 12.972268587130266,
            "mae": 0.5818471512675383,
            "precision": 0.44418052256532065,
            "recall": 0.38636363636363635
        },
        "train": {
            "accuracy": 0.42371020856201974,
            "auc_prc": 0.491865687338352,
            "auditor_fn_violation": 0.06517504729429902,
            "auditor_fp_violation": 0.0687366055093827,
            "ave_precision_score": 0.44092097324058294,
            "fpr": 0.23819978046103182,
            "logloss": 13.174143277388,
            "mae": 0.5784503514700243,
            "precision": 0.42744063324538256,
            "recall": 0.3446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7388826185684996,
            "auditor_fn_violation": 0.001968700159489633,
            "auditor_fp_violation": 0.01357804558124284,
            "ave_precision_score": 0.6286610114066258,
            "fpr": 0.37280701754385964,
            "logloss": 8.532859893613777,
            "mae": 0.38844678690588996,
            "precision": 0.5807644882860666,
            "recall": 0.9731404958677686
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7191457925200786,
            "auditor_fn_violation": 0.00546979003666768,
            "auditor_fp_violation": 0.021281838750868084,
            "ave_precision_score": 0.6089910146689443,
            "fpr": 0.40175631174533477,
            "logloss": 9.076583452374832,
            "mae": 0.42902543377301994,
            "precision": 0.5475896168108776,
            "recall": 0.9425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 32400,
        "test": {
            "accuracy": 0.2719298245614035,
            "auc_prc": 0.45447458166442545,
            "auditor_fn_violation": 0.00861334638248515,
            "auditor_fp_violation": 0.019250081980652575,
            "ave_precision_score": 0.40177895218221155,
            "fpr": 0.35855263157894735,
            "logloss": 21.767792584537858,
            "mae": 0.7271174287695736,
            "precision": 0.310126582278481,
            "recall": 0.3037190082644628
        },
        "train": {
            "accuracy": 0.29198682766191,
            "auc_prc": 0.4641193977246306,
            "auditor_fn_violation": 0.00458229208024851,
            "auditor_fp_violation": 0.01390413465056715,
            "ave_precision_score": 0.3972354125887218,
            "fpr": 0.3578485181119649,
            "logloss": 21.073556208250917,
            "mae": 0.7071479512671386,
            "precision": 0.3165618448637317,
            "recall": 0.32127659574468087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 32400,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8034108415349533,
            "auditor_fn_violation": 0.04626105553139047,
            "auditor_fp_violation": 0.045455709952451226,
            "ave_precision_score": 0.7448057750423069,
            "fpr": 0.12609649122807018,
            "logloss": 7.357570712493863,
            "mae": 0.301920354515619,
            "precision": 0.735632183908046,
            "recall": 0.6611570247933884
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7818647155991247,
            "auditor_fn_violation": 0.045610388397131975,
            "auditor_fp_violation": 0.03618908229226561,
            "ave_precision_score": 0.7197356391337482,
            "fpr": 0.10976948408342481,
            "logloss": 8.21416760883324,
            "mae": 0.30874360054142397,
            "precision": 0.7442455242966752,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8422357797672251,
            "auditor_fn_violation": 0.01622535160214586,
            "auditor_fp_violation": 0.021386702738153806,
            "ave_precision_score": 0.8425528376776475,
            "fpr": 0.16228070175438597,
            "logloss": 0.8723365217363805,
            "mae": 0.2643048930766823,
            "precision": 0.7366548042704626,
            "recall": 0.8553719008264463
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.842318903966589,
            "auditor_fn_violation": 0.015769437373006057,
            "auditor_fp_violation": 0.029254438694614325,
            "ave_precision_score": 0.842450318110571,
            "fpr": 0.1756311745334797,
            "logloss": 0.8478374473072805,
            "mae": 0.2750169514765191,
            "precision": 0.706959706959707,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6706254964747431,
            "auditor_fn_violation": 0.12591525300855447,
            "auditor_fp_violation": 0.0970650926381374,
            "ave_precision_score": 0.5748436134285805,
            "fpr": 0.19298245614035087,
            "logloss": 13.509674098462375,
            "mae": 0.49735627557178774,
            "precision": 0.5452196382428941,
            "recall": 0.4359504132231405
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6562167295751903,
            "auditor_fn_violation": 0.11937548170119344,
            "auditor_fp_violation": 0.09648513631577768,
            "ave_precision_score": 0.5616577816030708,
            "fpr": 0.1877058177826564,
            "logloss": 13.682625353975633,
            "mae": 0.4898010884070188,
            "precision": 0.5353260869565217,
            "recall": 0.41914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6079606523532805,
            "auditor_fn_violation": 0.016508536320139197,
            "auditor_fp_violation": 0.021074151500245945,
            "ave_precision_score": 0.6072411708588311,
            "fpr": 0.15021929824561403,
            "logloss": 2.2487668317411114,
            "mae": 0.3507516302604716,
            "precision": 0.7034632034632035,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6290304862448355,
            "auditor_fn_violation": 0.005084429081906724,
            "auditor_fp_violation": 0.019594226274483453,
            "ave_precision_score": 0.6242097297181096,
            "fpr": 0.14489571899012074,
            "logloss": 2.296706266015695,
            "mae": 0.3391151055087223,
            "precision": 0.7098901098901099,
            "recall": 0.6872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.771669409113949,
            "auditor_fn_violation": 0.007412643178193423,
            "auditor_fp_violation": 0.01617068371864241,
            "ave_precision_score": 0.7719044455649201,
            "fpr": 0.14912280701754385,
            "logloss": 1.006120855093413,
            "mae": 0.27721651796666036,
            "precision": 0.7404580152671756,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7142462254431909,
            "auditor_fn_violation": 0.007454982833921109,
            "auditor_fp_violation": 0.01968383401659237,
            "ave_precision_score": 0.7143867496033367,
            "fpr": 0.16575192096597147,
            "logloss": 1.481229809997972,
            "mae": 0.3024504650092624,
            "precision": 0.703921568627451,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7998731039701341,
            "auditor_fn_violation": 0.013300619834710745,
            "auditor_fp_violation": 0.013075914084276113,
            "ave_precision_score": 0.8006095425604247,
            "fpr": 0.14035087719298245,
            "logloss": 0.8279721796166902,
            "mae": 0.2961229450418109,
            "precision": 0.7455268389662028,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.740872501042637,
            "auditor_fn_violation": 0.00738024616390686,
            "auditor_fp_violation": 0.013463563251864968,
            "ave_precision_score": 0.7424176367839355,
            "fpr": 0.14818880351262348,
            "logloss": 0.9871279557733315,
            "mae": 0.31021381903098016,
            "precision": 0.7233606557377049,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 32400,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8300135393733472,
            "auditor_fn_violation": 0.0021476729012614186,
            "auditor_fp_violation": 0.007209173635022148,
            "ave_precision_score": 0.8311213178843003,
            "fpr": 0.29714912280701755,
            "logloss": 0.6996847633681932,
            "mae": 0.3322676142025515,
            "precision": 0.6312925170068027,
            "recall": 0.9586776859504132
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7847410853062687,
            "auditor_fn_violation": 0.006469392998108231,
            "auditor_fp_violation": 0.01763281236387714,
            "ave_precision_score": 0.7857509869763686,
            "fpr": 0.29198682766191,
            "logloss": 0.7846262779814979,
            "mae": 0.34603439266751257,
            "precision": 0.623229461756374,
            "recall": 0.9361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7544032200239563,
            "auditor_fn_violation": 0.013008373205741629,
            "auditor_fp_violation": 0.01372151172323332,
            "ave_precision_score": 0.754878537874585,
            "fpr": 0.16666666666666666,
            "logloss": 1.0089448441832198,
            "mae": 0.28943512722702525,
            "precision": 0.7169459962756052,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7270532239456089,
            "auditor_fn_violation": 0.013452600602564401,
            "auditor_fp_violation": 0.022703117104873417,
            "ave_precision_score": 0.7283598531709737,
            "fpr": 0.18221734357848518,
            "logloss": 1.3073229960350605,
            "mae": 0.31047194309183873,
            "precision": 0.6902985074626866,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7718474844699732,
            "auditor_fn_violation": 0.0014408438451500654,
            "auditor_fp_violation": 0.007816342843089033,
            "ave_precision_score": 0.5493561432697771,
            "fpr": 0.4375,
            "logloss": 14.881818655948603,
            "mae": 0.4409130398907061,
            "precision": 0.5465909090909091,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7572237078550808,
            "auditor_fn_violation": 0.0002569073031739732,
            "auditor_fp_violation": 0.00773613506873661,
            "ave_precision_score": 0.5245454560915719,
            "fpr": 0.4610318331503842,
            "logloss": 15.830555411757961,
            "mae": 0.4666947791054596,
            "precision": 0.5254237288135594,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6803316261330499,
            "auditor_fn_violation": 0.0043542482238654485,
            "auditor_fp_violation": 0.013534493359567147,
            "ave_precision_score": 0.5879456329324769,
            "fpr": 0.37609649122807015,
            "logloss": 8.804269536728576,
            "mae": 0.3974293524244196,
            "precision": 0.5754950495049505,
            "recall": 0.9607438016528925
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6596155576241971,
            "auditor_fn_violation": 0.0018497325828526054,
            "auditor_fp_violation": 0.02215053602853511,
            "ave_precision_score": 0.5684189583442025,
            "fpr": 0.38638858397365533,
            "logloss": 9.147152263871039,
            "mae": 0.41815595008470635,
            "precision": 0.5561160151324086,
            "recall": 0.9382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8601966527181576,
            "auditor_fn_violation": 0.013051417282876612,
            "auditor_fp_violation": 0.01661132972618463,
            "ave_precision_score": 0.8606438076972349,
            "fpr": 0.11842105263157894,
            "logloss": 0.5302644775361288,
            "mae": 0.2684638134855829,
            "precision": 0.7826961770623743,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8601182990923664,
            "auditor_fn_violation": 0.018572062498540307,
            "auditor_fp_violation": 0.015218381534831281,
            "ave_precision_score": 0.8603003514468852,
            "fpr": 0.1141602634467618,
            "logloss": 0.5573281221220426,
            "mae": 0.2737053863855163,
            "precision": 0.7748917748917749,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7715235024421793,
            "auditor_fn_violation": 0.0014408438451500654,
            "auditor_fp_violation": 0.007716428922774236,
            "ave_precision_score": 0.5487206730534199,
            "fpr": 0.43859649122807015,
            "logloss": 14.940005092593907,
            "mae": 0.44241977596820187,
            "precision": 0.5459704880817253,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7569149877862106,
            "auditor_fn_violation": 0.0002569073031739732,
            "auditor_fp_violation": 0.006543854277898519,
            "ave_precision_score": 0.5239443932357207,
            "fpr": 0.4632272228320527,
            "logloss": 15.869242379722861,
            "mae": 0.4673606290096351,
            "precision": 0.52423900789177,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.621780258716327,
            "auditor_fn_violation": 0.12033311584746993,
            "auditor_fp_violation": 0.09072440154123627,
            "ave_precision_score": 0.5408470282325749,
            "fpr": 0.18092105263157895,
            "logloss": 16.393780142475354,
            "mae": 0.4916400320976982,
            "precision": 0.547945205479452,
            "recall": 0.4132231404958678
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6025630828994176,
            "auditor_fn_violation": 0.10979283929280426,
            "auditor_fp_violation": 0.09101159673529127,
            "ave_precision_score": 0.5229097204655588,
            "fpr": 0.1734357848518112,
            "logloss": 16.328304261724625,
            "mae": 0.4910185510694377,
            "precision": 0.5325443786982249,
            "recall": 0.3829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6606995967753356,
            "auditor_fn_violation": 0.008948637088589248,
            "auditor_fp_violation": 0.018942654533530088,
            "ave_precision_score": 0.6620036800987725,
            "fpr": 0.13048245614035087,
            "logloss": 1.6561296218747308,
            "mae": 0.3303964242950843,
            "precision": 0.7325842696629213,
            "recall": 0.6735537190082644
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7048480713510759,
            "auditor_fn_violation": 0.004764462713408228,
            "auditor_fp_violation": 0.023310458468056093,
            "ave_precision_score": 0.7039937287166019,
            "fpr": 0.1163556531284303,
            "logloss": 1.6747907013284433,
            "mae": 0.3182233632772329,
            "precision": 0.7482185273159145,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8366608337713266,
            "auditor_fn_violation": 0.008613346382485138,
            "auditor_fp_violation": 0.017953762911952786,
            "ave_precision_score": 0.8370791604091253,
            "fpr": 0.14912280701754385,
            "logloss": 0.6574478250988177,
            "mae": 0.26617017461547327,
            "precision": 0.7476808905380334,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8361174700400594,
            "auditor_fn_violation": 0.014083191255809611,
            "auditor_fp_violation": 0.023118797464100897,
            "ave_precision_score": 0.8363469642133611,
            "fpr": 0.14489571899012074,
            "logloss": 0.701434478678818,
            "mae": 0.2723109884634561,
            "precision": 0.7396449704142012,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8421322029762031,
            "auditor_fn_violation": 0.01622535160214586,
            "auditor_fp_violation": 0.021386702738153806,
            "ave_precision_score": 0.8424482215597746,
            "fpr": 0.16228070175438597,
            "logloss": 0.8727039772622966,
            "mae": 0.2643223067362119,
            "precision": 0.7366548042704626,
            "recall": 0.8553719008264463
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8422443587145464,
            "auditor_fn_violation": 0.015769437373006057,
            "auditor_fp_violation": 0.02906277769065915,
            "ave_precision_score": 0.8423758558020913,
            "fpr": 0.17672886937431395,
            "logloss": 0.8482344384391467,
            "mae": 0.2750390153303008,
            "precision": 0.7056672760511883,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.773400258968807,
            "auditor_fn_violation": 0.0014408438451500654,
            "auditor_fp_violation": 0.008833415313985902,
            "ave_precision_score": 0.5496545110081459,
            "fpr": 0.4342105263157895,
            "logloss": 14.966023448128421,
            "mae": 0.43793683987685295,
            "precision": 0.548460661345496,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7589342893558607,
            "auditor_fn_violation": 0.0008734848307915082,
            "auditor_fp_violation": 0.007260716214769836,
            "ave_precision_score": 0.5249475817661898,
            "fpr": 0.4621295279912184,
            "logloss": 15.937747368223551,
            "mae": 0.4682774394184522,
            "precision": 0.5242937853107345,
            "recall": 0.9872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7382722415556865,
            "auditor_fn_violation": 0.013452406843555177,
            "auditor_fp_violation": 0.015576323987538944,
            "ave_precision_score": 0.7387837024078499,
            "fpr": 0.12171052631578948,
            "logloss": 2.2638049028961187,
            "mae": 0.31910172979708556,
            "precision": 0.7331730769230769,
            "recall": 0.6301652892561983
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7300056691287802,
            "auditor_fn_violation": 0.013503982063199194,
            "auditor_fp_violation": 0.02346229380885175,
            "ave_precision_score": 0.7317931235521891,
            "fpr": 0.1207464324917673,
            "logloss": 2.640597038636541,
            "mae": 0.3243269427546439,
            "precision": 0.7222222222222222,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.67060261053339,
            "auditor_fn_violation": 0.12640459620124694,
            "auditor_fp_violation": 0.09758515740285294,
            "ave_precision_score": 0.5748207274399496,
            "fpr": 0.19188596491228072,
            "logloss": 13.87774832691508,
            "mae": 0.4973678183137991,
            "precision": 0.5454545454545454,
            "recall": 0.43388429752066116
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6562489149307665,
            "auditor_fn_violation": 0.11984492140972045,
            "auditor_fp_violation": 0.09648513631577768,
            "ave_precision_score": 0.5616899514359232,
            "fpr": 0.1877058177826564,
            "logloss": 14.03281967830967,
            "mae": 0.4896319169748048,
            "precision": 0.5340599455040872,
            "recall": 0.41702127659574467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7523758685112989,
            "auditor_fn_violation": 0.018930332028418154,
            "auditor_fp_violation": 0.027540375471388757,
            "ave_precision_score": 0.7519058275928718,
            "fpr": 0.19956140350877194,
            "logloss": 1.4288247718489144,
            "mae": 0.29425569971730986,
            "precision": 0.6930860033726813,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7439091955290369,
            "auditor_fn_violation": 0.02059929467267674,
            "auditor_fp_violation": 0.030601043930195568,
            "ave_precision_score": 0.7426972823392721,
            "fpr": 0.1942919868276619,
            "logloss": 1.604743700814976,
            "mae": 0.3082958549408972,
            "precision": 0.6775956284153005,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8141333916048146,
            "auditor_fn_violation": 0.01200703204291721,
            "auditor_fp_violation": 0.01397770126250205,
            "ave_precision_score": 0.8150157778641518,
            "fpr": 0.15350877192982457,
            "logloss": 0.7742674779192756,
            "mae": 0.2789673470832977,
            "precision": 0.7378277153558053,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8263663574972365,
            "auditor_fn_violation": 0.01713805264264194,
            "auditor_fp_violation": 0.022782768431192462,
            "ave_precision_score": 0.8265781846164253,
            "fpr": 0.15806805708013172,
            "logloss": 0.8238722568950642,
            "mae": 0.28861923237556575,
            "precision": 0.7203883495145631,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6904696084514919,
            "auditor_fn_violation": 0.10430259533130347,
            "auditor_fp_violation": 0.08306177242170848,
            "ave_precision_score": 0.6328027719534207,
            "fpr": 0.1600877192982456,
            "logloss": 7.9615158664903225,
            "mae": 0.43522269322320223,
            "precision": 0.6167979002624672,
            "recall": 0.4855371900826446
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.663634581922517,
            "auditor_fn_violation": 0.09586145689796109,
            "auditor_fp_violation": 0.08106513736120134,
            "ave_precision_score": 0.6120367337539188,
            "fpr": 0.15697036223929747,
            "logloss": 8.219867150993618,
            "mae": 0.4441006016506939,
            "precision": 0.5890804597701149,
            "recall": 0.43617021276595747
        }
    }
]