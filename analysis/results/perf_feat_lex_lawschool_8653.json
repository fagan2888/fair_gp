[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8051189209744287,
            "auditor_fn_violation": 0.014295590228180059,
            "auditor_fp_violation": 0.008959320935132287,
            "ave_precision_score": 0.8050038704969384,
            "fpr": 0.09100877192982457,
            "logloss": 1.0644480439296868,
            "mae": 0.27751962709746164,
            "precision": 0.7930174563591023,
            "recall": 0.6638830897703549
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8610367749938117,
            "auditor_fn_violation": 0.012400485296666475,
            "auditor_fp_violation": 0.007218098873100434,
            "ave_precision_score": 0.8612589700600943,
            "fpr": 0.07354555433589462,
            "logloss": 0.8621354447306661,
            "mae": 0.24357515208396516,
            "precision": 0.8349753694581281,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7493813310451813,
            "auditor_fn_violation": 0.001762626817565839,
            "auditor_fp_violation": 0.02036992018151615,
            "ave_precision_score": 0.7498680723049072,
            "fpr": 0.16557017543859648,
            "logloss": 1.149924406557536,
            "mae": 0.2947829706615386,
            "precision": 0.7140151515151515,
            "recall": 0.7870563674321504
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7833720052797835,
            "auditor_fn_violation": 0.006482176902189614,
            "auditor_fp_violation": 0.017558082155912952,
            "ave_precision_score": 0.7837201562787588,
            "fpr": 0.14709110867178923,
            "logloss": 1.1678243126324117,
            "mae": 0.27515335181032163,
            "precision": 0.7341269841269841,
            "recall": 0.7789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7947481374371794,
            "auditor_fn_violation": 0.01224453356773981,
            "auditor_fp_violation": 0.0241734532636441,
            "ave_precision_score": 0.79537133418751,
            "fpr": 0.14364035087719298,
            "logloss": 1.042892069588226,
            "mae": 0.2769116620804636,
            "precision": 0.7374749498997996,
            "recall": 0.7682672233820459
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8399175264020073,
            "auditor_fn_violation": 0.022584782483101282,
            "auditor_fp_violation": 0.023303356529270187,
            "ave_precision_score": 0.8401526675414183,
            "fpr": 0.14050493962678376,
            "logloss": 1.0017243727940006,
            "mae": 0.26805818374479135,
            "precision": 0.7414141414141414,
            "recall": 0.7726315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8001959506034044,
            "auditor_fn_violation": 0.006606416877266236,
            "auditor_fp_violation": 0.01878975730318869,
            "ave_precision_score": 0.8005965556462491,
            "fpr": 0.14144736842105263,
            "logloss": 0.9016923848643631,
            "mae": 0.2855826855772957,
            "precision": 0.7351129363449692,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8473448063090212,
            "auditor_fn_violation": 0.01106476399560922,
            "auditor_fp_violation": 0.015498645504989987,
            "ave_precision_score": 0.8475573444166923,
            "fpr": 0.12952799121844127,
            "logloss": 0.8664858724097246,
            "mae": 0.2637316906585413,
            "precision": 0.7536534446764092,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8382313914354489,
            "auditor_fn_violation": 0.00936023513899572,
            "auditor_fp_violation": 0.013859345245330416,
            "ave_precision_score": 0.83866835139381,
            "fpr": 0.13267543859649122,
            "logloss": 0.5167933750289065,
            "mae": 0.29864071574539003,
            "precision": 0.7589641434262948,
            "recall": 0.7954070981210856
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8890622479769614,
            "auditor_fn_violation": 0.01356057542319025,
            "auditor_fp_violation": 0.010702524698133918,
            "ave_precision_score": 0.8891994049138743,
            "fpr": 0.11964873765093303,
            "logloss": 0.45881917990619603,
            "mae": 0.2768178889839721,
            "precision": 0.782435129740519,
            "recall": 0.8252631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8018922827387451,
            "auditor_fn_violation": 0.01141587005091016,
            "auditor_fp_violation": 0.025753616141971563,
            "ave_precision_score": 0.8025587553819207,
            "fpr": 0.14035087719298245,
            "logloss": 0.9114563269956336,
            "mae": 0.27361356239982854,
            "precision": 0.7429718875502008,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8498146649487401,
            "auditor_fn_violation": 0.022094863943613152,
            "auditor_fp_violation": 0.01983907189397678,
            "ave_precision_score": 0.8500158137153229,
            "fpr": 0.14050493962678376,
            "logloss": 0.8693108637302808,
            "mae": 0.2632195746942628,
            "precision": 0.7450199203187251,
            "recall": 0.7873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.770920662969727,
            "auditor_fn_violation": 0.025729773284987004,
            "auditor_fp_violation": 0.013884668368380539,
            "ave_precision_score": 0.7700117591277998,
            "fpr": 0.08991228070175439,
            "logloss": 2.7459137570566092,
            "mae": 0.30498880819749746,
            "precision": 0.7864583333333334,
            "recall": 0.6304801670146137
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8214140121732811,
            "auditor_fn_violation": 0.02903691721069964,
            "auditor_fp_violation": 0.016528363830451462,
            "ave_precision_score": 0.8212002848915627,
            "fpr": 0.07793633369923161,
            "logloss": 2.756240668856272,
            "mae": 0.27821998772093937,
            "precision": 0.8136482939632546,
            "recall": 0.6526315789473685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7920246128106501,
            "auditor_fn_violation": 0.011729480276892652,
            "auditor_fp_violation": 0.0039022932620234184,
            "ave_precision_score": 0.7920682380811921,
            "fpr": 0.09868421052631579,
            "logloss": 1.0636713746410145,
            "mae": 0.283685342945791,
            "precision": 0.7831325301204819,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8442082494436955,
            "auditor_fn_violation": 0.014884742041712409,
            "auditor_fp_violation": 0.010700007049416408,
            "ave_precision_score": 0.8440017470920702,
            "fpr": 0.08232711306256861,
            "logloss": 0.8938499428967188,
            "mae": 0.2486129584525836,
            "precision": 0.8201438848920863,
            "recall": 0.72
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 8653,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7846277091847961,
            "auditor_fn_violation": 0.004674394755155122,
            "auditor_fp_violation": 0.010278655646043515,
            "ave_precision_score": 0.7850459667206021,
            "fpr": 0.07675438596491228,
            "logloss": 0.737163507841703,
            "mae": 0.34428971417294535,
            "precision": 0.7865853658536586,
            "recall": 0.5386221294363257
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.801274195773357,
            "auditor_fn_violation": 0.001599168062857477,
            "auditor_fp_violation": 0.007565534396116782,
            "ave_precision_score": 0.801600638583138,
            "fpr": 0.05598243688254665,
            "logloss": 0.704277203738666,
            "mae": 0.33793001470801254,
            "precision": 0.8282828282828283,
            "recall": 0.5178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8514684858341955,
            "auditor_fn_violation": 0.0044363256784968694,
            "auditor_fp_violation": 0.015626899234228758,
            "ave_precision_score": 0.8518247742006044,
            "fpr": 0.19407894736842105,
            "logloss": 0.5323604758419026,
            "mae": 0.29636500448217257,
            "precision": 0.7088815789473685,
            "recall": 0.8997912317327766
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.889193764458872,
            "auditor_fn_violation": 0.008340169853833268,
            "auditor_fp_violation": 0.016938740571405552,
            "ave_precision_score": 0.8893355648462382,
            "fpr": 0.1942919868276619,
            "logloss": 0.4970297607812642,
            "mae": 0.2887956033495043,
            "precision": 0.7079207920792079,
            "recall": 0.9031578947368422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7802120122867054,
            "auditor_fn_violation": 0.021455975533824126,
            "auditor_fp_violation": 0.017564118147562906,
            "ave_precision_score": 0.7795957846833894,
            "fpr": 0.10087719298245613,
            "logloss": 2.625248001965332,
            "mae": 0.299584802858375,
            "precision": 0.773955773955774,
            "recall": 0.6576200417536534
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8286196380209354,
            "auditor_fn_violation": 0.02796233173493558,
            "auditor_fp_violation": 0.01637730490740088,
            "ave_precision_score": 0.8284281645030216,
            "fpr": 0.08232711306256861,
            "logloss": 2.6778223326596686,
            "mae": 0.2736507058163711,
            "precision": 0.8125,
            "recall": 0.6842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7924096205878477,
            "auditor_fn_violation": 0.006066183203310994,
            "auditor_fp_violation": 0.02070671771808274,
            "ave_precision_score": 0.792994325736748,
            "fpr": 0.15679824561403508,
            "logloss": 0.9735321853986653,
            "mae": 0.29085126043409304,
            "precision": 0.7260536398467433,
            "recall": 0.791231732776618
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8461997792683977,
            "auditor_fn_violation": 0.010537870472008784,
            "auditor_fp_violation": 0.016369751961248354,
            "ave_precision_score": 0.8465553859633557,
            "fpr": 0.15148188803512624,
            "logloss": 0.8263079581117362,
            "mae": 0.27174516567835993,
            "precision": 0.7335907335907336,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7724354839661296,
            "auditor_fn_violation": 0.0039189832619126105,
            "auditor_fp_violation": 0.022471739394676067,
            "ave_precision_score": 0.7383702337467273,
            "fpr": 0.18311403508771928,
            "logloss": 3.5103322511907833,
            "mae": 0.284562243598208,
            "precision": 0.7023172905525846,
            "recall": 0.8225469728601252
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8034335314220251,
            "auditor_fn_violation": 0.009232191345542784,
            "auditor_fp_violation": 0.024657851539290423,
            "ave_precision_score": 0.7697811142125872,
            "fpr": 0.17233809001097694,
            "logloss": 3.6385956393576437,
            "mae": 0.2725018306203893,
            "precision": 0.7160940325497287,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8010017469127071,
            "auditor_fn_violation": 0.015257023037761426,
            "auditor_fp_violation": 0.011620781167699854,
            "ave_precision_score": 0.8008948730601172,
            "fpr": 0.09649122807017543,
            "logloss": 1.06219359123705,
            "mae": 0.2821338398321561,
            "precision": 0.7889688249400479,
            "recall": 0.6868475991649269
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.855174205254614,
            "auditor_fn_violation": 0.012594603963256111,
            "auditor_fp_violation": 0.010659724669936255,
            "ave_precision_score": 0.8554042946883433,
            "fpr": 0.07793633369923161,
            "logloss": 0.8755669312541405,
            "mae": 0.24405595393626708,
            "precision": 0.8272506082725061,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7586751206214506,
            "auditor_fn_violation": 0.025619895249606273,
            "auditor_fp_violation": 0.008409809164944696,
            "ave_precision_score": 0.7601469756420874,
            "fpr": 0.02850877192982456,
            "logloss": 2.3362810291626985,
            "mae": 0.40237894525732426,
            "precision": 0.8452380952380952,
            "recall": 0.2964509394572025
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.8037229060068146,
            "auditor_fn_violation": 0.023629325784274086,
            "auditor_fp_violation": 0.006691910291140898,
            "ave_precision_score": 0.8041191951084056,
            "fpr": 0.019758507135016465,
            "logloss": 2.0990547714114904,
            "mae": 0.36569207122038955,
            "precision": 0.8959537572254336,
            "recall": 0.3263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8028084732077883,
            "auditor_fn_violation": 0.012919825660183874,
            "auditor_fp_violation": 0.013545338519508935,
            "ave_precision_score": 0.8028930089698941,
            "fpr": 0.09320175438596491,
            "logloss": 0.9575473509228384,
            "mae": 0.28436387631561605,
            "precision": 0.7906403940886699,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8574072679643636,
            "auditor_fn_violation": 0.012442082153792831,
            "auditor_fp_violation": 0.01067986585967633,
            "ave_precision_score": 0.8576213442771239,
            "fpr": 0.07683863885839737,
            "logloss": 0.820663029082462,
            "mae": 0.24673423495503788,
            "precision": 0.8284313725490197,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7928583512845886,
            "auditor_fn_violation": 0.006368347800607991,
            "auditor_fp_violation": 0.019597564928487507,
            "ave_precision_score": 0.7933070104529092,
            "fpr": 0.14473684210526316,
            "logloss": 1.0144236538672253,
            "mae": 0.2857523045978396,
            "precision": 0.7354709418837675,
            "recall": 0.7661795407098121
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8367686956722072,
            "auditor_fn_violation": 0.015938529088913283,
            "auditor_fp_violation": 0.016216175389480267,
            "ave_precision_score": 0.8370241551124487,
            "fpr": 0.13062568605927552,
            "logloss": 0.9752550313841615,
            "mae": 0.26616357735628116,
            "precision": 0.7520833333333333,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.833352849842734,
            "auditor_fn_violation": 0.014009449511042747,
            "auditor_fp_violation": 0.015925712086220175,
            "ave_precision_score": 0.8343703849462479,
            "fpr": 0.08552631578947369,
            "logloss": 0.5723013384082608,
            "mae": 0.2933627009453471,
            "precision": 0.8125,
            "recall": 0.7056367432150313
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8918326072520324,
            "auditor_fn_violation": 0.012421283725229658,
            "auditor_fp_violation": 0.010579159910975945,
            "ave_precision_score": 0.891963814970406,
            "fpr": 0.07244785949506037,
            "logloss": 0.506498218529584,
            "mae": 0.26744732647821884,
            "precision": 0.8413461538461539,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7920239001991413,
            "auditor_fn_violation": 0.010893949382851712,
            "auditor_fp_violation": 0.018766966492443582,
            "ave_precision_score": 0.7924115693855268,
            "fpr": 0.13596491228070176,
            "logloss": 1.020788997423754,
            "mae": 0.2865879573597426,
            "precision": 0.7389473684210527,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.835822230497034,
            "auditor_fn_violation": 0.010341440868912128,
            "auditor_fp_violation": 0.015367727771679471,
            "ave_precision_score": 0.8360676386939613,
            "fpr": 0.11964873765093303,
            "logloss": 0.9731696227661866,
            "mae": 0.2645868988459311,
            "precision": 0.7650862068965517,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.800771364798415,
            "auditor_fn_violation": 0.017163864776764463,
            "auditor_fp_violation": 0.01293758356630607,
            "ave_precision_score": 0.8006589071517414,
            "fpr": 0.10526315789473684,
            "logloss": 1.037838861661763,
            "mae": 0.28130236728962804,
            "precision": 0.7793103448275862,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8534775059612616,
            "auditor_fn_violation": 0.015945461898434345,
            "auditor_fp_violation": 0.011279066254443653,
            "ave_precision_score": 0.8535876920658084,
            "fpr": 0.09220636663007684,
            "logloss": 0.8614015645756604,
            "mae": 0.2464930321933798,
            "precision": 0.8055555555555556,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7955530879216205,
            "auditor_fn_violation": 0.014723656741017471,
            "auditor_fp_violation": 0.014056865605121352,
            "ave_precision_score": 0.796010352598293,
            "fpr": 0.11074561403508772,
            "logloss": 0.996156379548998,
            "mae": 0.2960529998266203,
            "precision": 0.764018691588785,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8362478731603133,
            "auditor_fn_violation": 0.014637471835461324,
            "auditor_fp_violation": 0.010312289146919909,
            "ave_precision_score": 0.8364961395725247,
            "fpr": 0.10208562019758508,
            "logloss": 0.9527317888975626,
            "mae": 0.2700863124943108,
            "precision": 0.7822014051522248,
            "recall": 0.7031578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.812052256613405,
            "auditor_fn_violation": 0.005097883016518332,
            "auditor_fp_violation": 0.014373404643247859,
            "ave_precision_score": 0.8126785254823472,
            "fpr": 0.22478070175438597,
            "logloss": 0.8040349898368677,
            "mae": 0.30049069890172403,
            "precision": 0.6846153846153846,
            "recall": 0.9290187891440501
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8596046971897029,
            "auditor_fn_violation": 0.008317060488763071,
            "auditor_fp_violation": 0.011530831126194624,
            "ave_precision_score": 0.8600405732619725,
            "fpr": 0.21514818880351264,
            "logloss": 0.7352995115872458,
            "mae": 0.29350824320433777,
            "precision": 0.6927899686520376,
            "recall": 0.9305263157894736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7988540813268986,
            "auditor_fn_violation": 0.00981348203494122,
            "auditor_fp_violation": 0.018766966492443582,
            "ave_precision_score": 0.7993346475992098,
            "fpr": 0.13596491228070176,
            "logloss": 0.9075940365703344,
            "mae": 0.2875218931153163,
            "precision": 0.7394957983193278,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8463535972879521,
            "auditor_fn_violation": 0.013068345947195106,
            "auditor_fp_violation": 0.018137141360940193,
            "ave_precision_score": 0.8465689552983954,
            "fpr": 0.12294182217343579,
            "logloss": 0.8736890549435778,
            "mae": 0.26415694655509786,
            "precision": 0.7601713062098501,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7153943319314313,
            "auditor_fn_violation": 0.008060011720323777,
            "auditor_fp_violation": 0.02210961873505936,
            "ave_precision_score": 0.7143169835734947,
            "fpr": 0.16666666666666666,
            "logloss": 1.4254642584811748,
            "mae": 0.3006705603840546,
            "precision": 0.7071290944123314,
            "recall": 0.7661795407098121
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7571503363509657,
            "auditor_fn_violation": 0.006981339187705824,
            "auditor_fp_violation": 0.023534980211281087,
            "ave_precision_score": 0.7568151571287098,
            "fpr": 0.14489571899012074,
            "logloss": 1.2978770912577726,
            "mae": 0.2811969638128218,
            "precision": 0.7322515212981744,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8027655145783797,
            "auditor_fn_violation": 0.00812868549243673,
            "auditor_fp_violation": 0.014710202179814435,
            "ave_precision_score": 0.8029053120270391,
            "fpr": 0.10964912280701754,
            "logloss": 0.9003149515898904,
            "mae": 0.2811836809412893,
            "precision": 0.7732426303854876,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8557771833385504,
            "auditor_fn_violation": 0.015434744930383042,
            "auditor_fp_violation": 0.009758406429067766,
            "ave_precision_score": 0.8559418145078916,
            "fpr": 0.09001097694840834,
            "logloss": 0.7802598231539124,
            "mae": 0.24856313413205613,
            "precision": 0.8093023255813954,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8027981216732656,
            "auditor_fn_violation": 0.009822638537889608,
            "auditor_fp_violation": 0.01144605161865402,
            "ave_precision_score": 0.8033398594147108,
            "fpr": 0.11513157894736842,
            "logloss": 0.9182367320434905,
            "mae": 0.2803229399525519,
            "precision": 0.7702407002188184,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8576173268290188,
            "auditor_fn_violation": 0.014087468946790688,
            "auditor_fp_violation": 0.0143405270949355,
            "ave_precision_score": 0.8578326502170283,
            "fpr": 0.10098792535675083,
            "logloss": 0.7690388487911579,
            "mae": 0.2560047827932307,
            "precision": 0.7978021978021979,
            "recall": 0.7642105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8145095897965169,
            "auditor_fn_violation": 0.009332765630150536,
            "auditor_fp_violation": 0.016482820793322802,
            "ave_precision_score": 0.8149112254563445,
            "fpr": 0.14583333333333334,
            "logloss": 0.7229678364928042,
            "mae": 0.3270644886156424,
            "precision": 0.73558648111332,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7945436201928203,
            "auditor_fn_violation": 0.012825697613958055,
            "auditor_fp_violation": 0.012840008459299695,
            "ave_precision_score": 0.795273539977191,
            "fpr": 0.13611416026344675,
            "logloss": 0.6725829614212904,
            "mae": 0.3213129474448721,
            "precision": 0.751503006012024,
            "recall": 0.7894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7970086462929984,
            "auditor_fn_violation": 0.0159002673698861,
            "auditor_fp_violation": 0.014568392690733767,
            "ave_precision_score": 0.7974422594548702,
            "fpr": 0.11074561403508772,
            "logloss": 0.9866045990147749,
            "mae": 0.2944102435115797,
            "precision": 0.7651162790697674,
            "recall": 0.6868475991649269
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8371488885388386,
            "auditor_fn_violation": 0.0122017447570628,
            "auditor_fp_violation": 0.012069607951741718,
            "ave_precision_score": 0.8373975394845163,
            "fpr": 0.10208562019758508,
            "logloss": 0.9449745274729137,
            "mae": 0.2696525952280709,
            "precision": 0.7827102803738317,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7935881669219154,
            "auditor_fn_violation": 0.011656228253305497,
            "auditor_fp_violation": 0.02484958064908229,
            "ave_precision_score": 0.7932812074831103,
            "fpr": 0.15899122807017543,
            "logloss": 1.0130959362032048,
            "mae": 0.29817351401585374,
            "precision": 0.7232824427480916,
            "recall": 0.791231732776618
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8470043141500825,
            "auditor_fn_violation": 0.01643769137442949,
            "auditor_fp_violation": 0.018852153596712964,
            "ave_precision_score": 0.8472240793454904,
            "fpr": 0.14928649835345773,
            "logloss": 0.8537352405437701,
            "mae": 0.27176110613198295,
            "precision": 0.7374517374517374,
            "recall": 0.8042105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8101226789155874,
            "auditor_fn_violation": 0.010172874775665683,
            "auditor_fp_violation": 0.013955573112920878,
            "ave_precision_score": 0.810082681520815,
            "fpr": 0.10307017543859649,
            "logloss": 0.8769872352533321,
            "mae": 0.2703465971797786,
            "precision": 0.7873303167420814,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8647950114690236,
            "auditor_fn_violation": 0.00950950372638512,
            "auditor_fp_violation": 0.013449279448937052,
            "ave_precision_score": 0.8649979370394407,
            "fpr": 0.08562019758507135,
            "logloss": 0.7480073746417827,
            "mae": 0.2375571941535749,
            "precision": 0.8198614318706697,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8507919634965664,
            "auditor_fn_violation": 0.005308482584331391,
            "auditor_fp_violation": 0.025424415542320007,
            "ave_precision_score": 0.8520544601819213,
            "fpr": 0.1962719298245614,
            "logloss": 0.5297186596213587,
            "mae": 0.2973115629242864,
            "precision": 0.7084690553745928,
            "recall": 0.9081419624217119
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.883428990116001,
            "auditor_fn_violation": 0.014154486105494255,
            "auditor_fp_violation": 0.023565191995891206,
            "ave_precision_score": 0.8835913676612894,
            "fpr": 0.18880351262349068,
            "logloss": 0.5040031881391986,
            "mae": 0.2889860216507731,
            "precision": 0.7104377104377104,
            "recall": 0.888421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7906574751975881,
            "auditor_fn_violation": 0.00990962531589935,
            "auditor_fp_violation": 0.019443093877881772,
            "ave_precision_score": 0.7913985648914584,
            "fpr": 0.14035087719298245,
            "logloss": 0.9869809900584745,
            "mae": 0.2882595041262884,
            "precision": 0.7349896480331263,
            "recall": 0.7411273486430062
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8389469838643218,
            "auditor_fn_violation": 0.0127355710901843,
            "auditor_fp_violation": 0.018499682776261597,
            "ave_precision_score": 0.8391843843969862,
            "fpr": 0.12733260153677278,
            "logloss": 0.9479878537132453,
            "mae": 0.26537940008784466,
            "precision": 0.7547568710359408,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7906280825368057,
            "auditor_fn_violation": 0.004287532505585469,
            "auditor_fp_violation": 0.01198036951501155,
            "ave_precision_score": 0.790310218403505,
            "fpr": 0.17434210526315788,
            "logloss": 1.0254683044206971,
            "mae": 0.30009500891065755,
            "precision": 0.7066420664206642,
            "recall": 0.7995824634655533
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8448118221911427,
            "auditor_fn_violation": 0.0012941244439309057,
            "auditor_fp_violation": 0.025619593349379157,
            "ave_precision_score": 0.8450811826361304,
            "fpr": 0.16245883644346873,
            "logloss": 0.8661297654601038,
            "mae": 0.2748319307373031,
            "precision": 0.724907063197026,
            "recall": 0.8210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.805816678686301,
            "auditor_fn_violation": 0.007446526022781386,
            "auditor_fp_violation": 0.01963048498845266,
            "ave_precision_score": 0.8059311745829507,
            "fpr": 0.13267543859649122,
            "logloss": 0.9187863456069126,
            "mae": 0.28659383349723805,
            "precision": 0.7484407484407485,
            "recall": 0.7515657620041754
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8527501075265296,
            "auditor_fn_violation": 0.009648159916806287,
            "auditor_fp_violation": 0.0160197987895145,
            "ave_precision_score": 0.8529260078180346,
            "fpr": 0.11525795828759605,
            "logloss": 0.864804023916769,
            "mae": 0.2631652192967744,
            "precision": 0.7741935483870968,
            "recall": 0.7578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7922004322690472,
            "auditor_fn_violation": 0.006677379775116287,
            "auditor_fp_violation": 0.014507617195413484,
            "ave_precision_score": 0.7921280748258299,
            "fpr": 0.18530701754385964,
            "logloss": 1.0143371842911761,
            "mae": 0.28044998297465484,
            "precision": 0.7111111111111111,
            "recall": 0.8684759916492694
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8421763842602128,
            "auditor_fn_violation": 0.011959096423825758,
            "auditor_fp_violation": 0.025478605021198607,
            "ave_precision_score": 0.8424008954445918,
            "fpr": 0.1756311745334797,
            "logloss": 0.9338332634815628,
            "mae": 0.2673333231520071,
            "precision": 0.7192982456140351,
            "recall": 0.8631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.803177296049031,
            "auditor_fn_violation": 0.010269018056623815,
            "auditor_fp_violation": 0.005234289534459709,
            "ave_precision_score": 0.8035672114318031,
            "fpr": 0.08333333333333333,
            "logloss": 0.947563075865452,
            "mae": 0.28539759937876974,
            "precision": 0.8061224489795918,
            "recall": 0.6597077244258872
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8550106450597791,
            "auditor_fn_violation": 0.011820440233404596,
            "auditor_fp_violation": 0.0075025931781790385,
            "ave_precision_score": 0.855235212723067,
            "fpr": 0.06915477497255763,
            "logloss": 0.8081787433205637,
            "mae": 0.248676611956023,
            "precision": 0.8417085427135679,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7950412420572055,
            "auditor_fn_violation": 0.006549188733838771,
            "auditor_fp_violation": 0.018766966492443582,
            "ave_precision_score": 0.7955697758781832,
            "fpr": 0.13596491228070176,
            "logloss": 1.0003171836809543,
            "mae": 0.2881451829204622,
            "precision": 0.7394957983193278,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8420181660937124,
            "auditor_fn_violation": 0.01343809578831822,
            "auditor_fp_violation": 0.017545493912325405,
            "ave_precision_score": 0.8422512581357144,
            "fpr": 0.12623490669593854,
            "logloss": 0.9751170535653401,
            "mae": 0.2644325540097545,
            "precision": 0.7553191489361702,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7932712717921927,
            "auditor_fn_violation": 0.006430154195509651,
            "auditor_fp_violation": 0.021028321380819257,
            "ave_precision_score": 0.793811324916289,
            "fpr": 0.1524122807017544,
            "logloss": 0.9834119177347241,
            "mae": 0.2850868375677657,
            "precision": 0.7236580516898609,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8398539695555447,
            "auditor_fn_violation": 0.011039343694032016,
            "auditor_fp_violation": 0.02038288401695889,
            "ave_precision_score": 0.840089231298119,
            "fpr": 0.14050493962678376,
            "logloss": 0.9421361074121583,
            "mae": 0.26499060135779606,
            "precision": 0.7408906882591093,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.7705731455457566,
            "auditor_fn_violation": 0.0006226422004907972,
            "auditor_fp_violation": 0.002147400834650136,
            "ave_precision_score": 0.7712328620731632,
            "fpr": 0.0043859649122807015,
            "logloss": 10.411761137743273,
            "mae": 0.5285083025612867,
            "precision": 0.2,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.7895302563100111,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003816755455744771,
            "ave_precision_score": 0.7907469143240801,
            "fpr": 0.008781558726673985,
            "logloss": 10.296815985425017,
            "mae": 0.5301858783210545,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8037870091110235,
            "auditor_fn_violation": 0.007361828370508735,
            "auditor_fp_violation": 0.020126818200235003,
            "ave_precision_score": 0.8035669533448123,
            "fpr": 0.14802631578947367,
            "logloss": 0.9618362301144096,
            "mae": 0.28753774403593724,
            "precision": 0.735812133072407,
            "recall": 0.7849686847599165
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8563605593395536,
            "auditor_fn_violation": 0.011831994915939685,
            "auditor_fp_violation": 0.018962930140283392,
            "ave_precision_score": 0.8566043940018399,
            "fpr": 0.132821075740944,
            "logloss": 0.8035114553236979,
            "mae": 0.2581245213373821,
            "precision": 0.7613412228796844,
            "recall": 0.8126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8053964528373163,
            "auditor_fn_violation": 0.01223079881331722,
            "auditor_fp_violation": 0.007338641059924641,
            "ave_precision_score": 0.8057640694633927,
            "fpr": 0.08552631578947369,
            "logloss": 0.9496442070119957,
            "mae": 0.28593273968876975,
            "precision": 0.8005115089514067,
            "recall": 0.6534446764091858
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8560564502726813,
            "auditor_fn_violation": 0.012571494598185918,
            "auditor_fp_violation": 0.010050453680298896,
            "ave_precision_score": 0.8562900572325015,
            "fpr": 0.07025246981339188,
            "logloss": 0.8105538127920723,
            "mae": 0.2473780129784778,
            "precision": 0.8395989974937343,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7889977931934546,
            "auditor_fn_violation": 0.012391037614914113,
            "auditor_fp_violation": 0.02259329038531665,
            "ave_precision_score": 0.790545117990046,
            "fpr": 0.1337719298245614,
            "logloss": 0.8506971302733457,
            "mae": 0.2700232108267022,
            "precision": 0.7545271629778671,
            "recall": 0.7828810020876826
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8499746860962178,
            "auditor_fn_violation": 0.0169969380091282,
            "auditor_fp_violation": 0.015554033776775196,
            "ave_precision_score": 0.8502065308882768,
            "fpr": 0.12623490669593854,
            "logloss": 0.7746448707613176,
            "mae": 0.2528962968017185,
            "precision": 0.7657841140529531,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8009604735229638,
            "auditor_fn_violation": 0.01415595355821705,
            "auditor_fp_violation": 0.006371297759410074,
            "ave_precision_score": 0.8012664737434949,
            "fpr": 0.08552631578947369,
            "logloss": 0.9740997793639002,
            "mae": 0.28573119403666797,
            "precision": 0.8015267175572519,
            "recall": 0.6576200417536534
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8539124155773687,
            "auditor_fn_violation": 0.01192674331272749,
            "auditor_fp_violation": 0.0056898861015720215,
            "ave_precision_score": 0.8541666388503357,
            "fpr": 0.06695938529088913,
            "logloss": 0.8427836070038927,
            "mae": 0.2463859038132019,
            "precision": 0.8447837150127226,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8430744116963336,
            "auditor_fn_violation": 0.004278376002637077,
            "auditor_fp_violation": 0.00982790405575139,
            "ave_precision_score": 0.8435516621926732,
            "fpr": 0.1699561403508772,
            "logloss": 0.5266383189188528,
            "mae": 0.29091185358406063,
            "precision": 0.7256637168141593,
            "recall": 0.8559498956158664
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8902323449593302,
            "auditor_fn_violation": 0.006449823791091341,
            "auditor_fp_violation": 0.012991067382350277,
            "ave_precision_score": 0.8903722010448947,
            "fpr": 0.1668496158068057,
            "logloss": 0.47792356412418846,
            "mae": 0.27814547065645456,
            "precision": 0.7314487632508834,
            "recall": 0.871578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.769137364884324,
            "auditor_fn_violation": 0.02599989012196462,
            "auditor_fp_violation": 0.013702341882419677,
            "ave_precision_score": 0.7682624080738458,
            "fpr": 0.09429824561403509,
            "logloss": 2.7532938519929195,
            "mae": 0.30579436412930544,
            "precision": 0.7800511508951407,
            "recall": 0.6367432150313153
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8194482239532686,
            "auditor_fn_violation": 0.028389854988734184,
            "auditor_fp_violation": 0.018884883030040583,
            "ave_precision_score": 0.8192347502564581,
            "fpr": 0.0845225027442371,
            "logloss": 2.765913530908229,
            "mae": 0.27966024048215526,
            "precision": 0.8035714285714286,
            "recall": 0.6631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8047361003175513,
            "auditor_fn_violation": 0.006583525619895253,
            "auditor_fp_violation": 0.007569081479680729,
            "ave_precision_score": 0.8046027604991801,
            "fpr": 0.09210526315789473,
            "logloss": 1.0680168553638596,
            "mae": 0.27787433781543014,
            "precision": 0.7910447761194029,
            "recall": 0.6638830897703549
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8604907964861686,
            "auditor_fn_violation": 0.013202380264602236,
            "auditor_fp_violation": 0.006918498675716777,
            "ave_precision_score": 0.8607095873385612,
            "fpr": 0.07244785949506037,
            "logloss": 0.8644523381188178,
            "mae": 0.243913765729232,
            "precision": 0.8366336633663366,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8271400231036273,
            "auditor_fn_violation": 0.036108669376991545,
            "auditor_fp_violation": 0.027546493253920022,
            "ave_precision_score": 0.8275839620719934,
            "fpr": 0.16776315789473684,
            "logloss": 0.6080110393666225,
            "mae": 0.3242306763056644,
            "precision": 0.7129455909943715,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8476583878426909,
            "auditor_fn_violation": 0.030677682130683462,
            "auditor_fp_violation": 0.03821790753179791,
            "ave_precision_score": 0.8478510355313211,
            "fpr": 0.1800219538968167,
            "logloss": 0.5711975180231694,
            "mae": 0.3164696486550779,
            "precision": 0.70018281535649,
            "recall": 0.8063157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7705974733044731,
            "auditor_fn_violation": 0.004383675786543601,
            "auditor_fp_violation": 0.019045520845994906,
            "ave_precision_score": 0.7193402291939979,
            "fpr": 0.15021929824561403,
            "logloss": 4.608467282404708,
            "mae": 0.28888531293403164,
            "precision": 0.7276341948310139,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8005583684689083,
            "auditor_fn_violation": 0.013964989311918662,
            "auditor_fp_violation": 0.01798104714045459,
            "ave_precision_score": 0.7506285689935285,
            "fpr": 0.13721185510428102,
            "logloss": 4.571514767861729,
            "mae": 0.2664016343284404,
            "precision": 0.7464503042596349,
            "recall": 0.7747368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7692700333737953,
            "auditor_fn_violation": 0.02599989012196462,
            "auditor_fp_violation": 0.014256918277217295,
            "ave_precision_score": 0.7683881603968433,
            "fpr": 0.09539473684210527,
            "logloss": 2.7485617940920846,
            "mae": 0.3056393963020644,
            "precision": 0.7780612244897959,
            "recall": 0.6367432150313153
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8200347157545446,
            "auditor_fn_violation": 0.02966549194060893,
            "auditor_fp_violation": 0.017140152468806333,
            "ave_precision_score": 0.8198207982855974,
            "fpr": 0.0845225027442371,
            "logloss": 2.760980507835024,
            "mae": 0.27961843697248556,
            "precision": 0.80306905370844,
            "recall": 0.6610526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8092375770925945,
            "auditor_fn_violation": 0.007341226238874851,
            "auditor_fp_violation": 0.017442567156922332,
            "ave_precision_score": 0.809409429837965,
            "fpr": 0.12828947368421054,
            "logloss": 0.9030605031950478,
            "mae": 0.27270483680894075,
            "precision": 0.7577639751552795,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8641543180260672,
            "auditor_fn_violation": 0.007741637298515227,
            "auditor_fp_violation": 0.014118974007794645,
            "ave_precision_score": 0.8643583356938382,
            "fpr": 0.1141602634467618,
            "logloss": 0.7515368573371242,
            "mae": 0.24392464742751654,
            "precision": 0.7828810020876826,
            "recall": 0.7894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.40679684445327924,
            "auditor_fn_violation": 8.46976522726492e-05,
            "auditor_fp_violation": 0.004274543170860175,
            "ave_precision_score": 0.5304303293752183,
            "fpr": 0.020833333333333332,
            "logloss": 16.22670418892946,
            "mae": 0.5164602068637302,
            "precision": 0.5869565217391305,
            "recall": 0.05636743215031315
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.40235019892360263,
            "auditor_fn_violation": 0.0044300652839563285,
            "auditor_fp_violation": 0.00017371776150817278,
            "ave_precision_score": 0.5253628359652083,
            "fpr": 0.01646542261251372,
            "logloss": 16.194059437750962,
            "mae": 0.5156177530677206,
            "precision": 0.5833333333333334,
            "recall": 0.04421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7932918159840721,
            "auditor_fn_violation": 0.009712760502508884,
            "auditor_fp_violation": 0.02281106924354768,
            "ave_precision_score": 0.7948250976067279,
            "fpr": 0.12390350877192982,
            "logloss": 0.8697380671916891,
            "mae": 0.2679752776826368,
            "precision": 0.7679671457905544,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8511546963665375,
            "auditor_fn_violation": 0.015333063724074183,
            "auditor_fp_violation": 0.016613963886846803,
            "ave_precision_score": 0.8513797259857286,
            "fpr": 0.12184412733260154,
            "logloss": 0.8000394047843974,
            "mae": 0.2502577529039361,
            "precision": 0.7701863354037267,
            "recall": 0.783157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7970704655394338,
            "auditor_fn_violation": 0.012732117349741785,
            "auditor_fp_violation": 0.024621672541631227,
            "ave_precision_score": 0.7984402142302788,
            "fpr": 0.12390350877192982,
            "logloss": 0.8640870819750581,
            "mae": 0.2626292978492237,
            "precision": 0.7679671457905544,
            "recall": 0.7807933194154488
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8591142837759209,
            "auditor_fn_violation": 0.014937893581373854,
            "auditor_fp_violation": 0.020392954611828926,
            "ave_precision_score": 0.8593269183028528,
            "fpr": 0.11855104281009879,
            "logloss": 0.781530804952279,
            "mae": 0.2438054589181698,
            "precision": 0.7768595041322314,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7907410244356554,
            "auditor_fn_violation": 0.011322015895689118,
            "auditor_fp_violation": 0.02259075807301163,
            "ave_precision_score": 0.7903644587712415,
            "fpr": 0.16557017543859648,
            "logloss": 1.0159042105525316,
            "mae": 0.3020201149853063,
            "precision": 0.7177570093457943,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8444103914881298,
            "auditor_fn_violation": 0.01117337801143914,
            "auditor_fp_violation": 0.02229126174483127,
            "ave_precision_score": 0.8445498609201125,
            "fpr": 0.15697036223929747,
            "logloss": 0.8621641823476319,
            "mae": 0.2748717491103132,
            "precision": 0.7291666666666666,
            "recall": 0.8105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7949744604869438,
            "auditor_fn_violation": 0.007654836464857346,
            "auditor_fp_violation": 0.018556784571127593,
            "ave_precision_score": 0.7953989365618426,
            "fpr": 0.13815789473684212,
            "logloss": 0.9650033247936627,
            "mae": 0.28724715797563094,
            "precision": 0.7385892116182573,
            "recall": 0.7432150313152401
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8408176068829671,
            "auditor_fn_violation": 0.013664567566006123,
            "auditor_fp_violation": 0.01855758869676432,
            "ave_precision_score": 0.8410569773069034,
            "fpr": 0.12403951701427003,
            "logloss": 0.9327600110298387,
            "mae": 0.2630795646598071,
            "precision": 0.7580299785867237,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7751058026899731,
            "auditor_fn_violation": 0.028330220122330885,
            "auditor_fp_violation": 0.01208166200721203,
            "ave_precision_score": 0.7745535533264362,
            "fpr": 0.08333333333333333,
            "logloss": 2.761371066109323,
            "mae": 0.3000190400659176,
            "precision": 0.7973333333333333,
            "recall": 0.6242171189979123
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8257881370959936,
            "auditor_fn_violation": 0.02972788722629846,
            "auditor_fp_violation": 0.011634054723612527,
            "ave_precision_score": 0.8255588188009987,
            "fpr": 0.06915477497255763,
            "logloss": 2.7734954584156943,
            "mae": 0.27206478998785694,
            "precision": 0.8301886792452831,
            "recall": 0.6484210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.798487228891151,
            "auditor_fn_violation": 0.005999798556935134,
            "auditor_fp_violation": 0.01413283497427171,
            "ave_precision_score": 0.7991442497075472,
            "fpr": 0.14583333333333334,
            "logloss": 0.9896604116523207,
            "mae": 0.28102234278430505,
            "precision": 0.7318548387096774,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8461053651126947,
            "auditor_fn_violation": 0.013234733375700504,
            "auditor_fp_violation": 0.017548011561042912,
            "ave_precision_score": 0.8463244469980795,
            "fpr": 0.1394072447859495,
            "logloss": 0.9376717607069612,
            "mae": 0.2626708852428517,
            "precision": 0.7413441955193483,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8063165026176702,
            "auditor_fn_violation": 0.009948540453430034,
            "auditor_fp_violation": 0.007052489769458289,
            "ave_precision_score": 0.8063557399774961,
            "fpr": 0.08552631578947369,
            "logloss": 1.0052433534585905,
            "mae": 0.2794676472391219,
            "precision": 0.8010204081632653,
            "recall": 0.6555323590814196
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8617970712658289,
            "auditor_fn_violation": 0.014145242359466178,
            "auditor_fp_violation": 0.005256850522160343,
            "ave_precision_score": 0.862015052087544,
            "fpr": 0.06915477497255763,
            "logloss": 0.8308238170315904,
            "mae": 0.24609476775430364,
            "precision": 0.8405063291139241,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 8653,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7955132544034961,
            "auditor_fn_violation": 0.004454638684393657,
            "auditor_fp_violation": 0.012838823386410602,
            "ave_precision_score": 0.7970514252457996,
            "fpr": 0.125,
            "logloss": 0.9249354737255782,
            "mae": 0.26361760048967176,
            "precision": 0.7649484536082474,
            "recall": 0.7745302713987474
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8560766941878258,
            "auditor_fn_violation": 0.013720030042174588,
            "auditor_fp_violation": 0.015181421766583752,
            "ave_precision_score": 0.8563018235220472,
            "fpr": 0.11525795828759605,
            "logloss": 0.8313737746543665,
            "mae": 0.2417035617169557,
            "precision": 0.779874213836478,
            "recall": 0.783157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7830908716801528,
            "auditor_fn_violation": 0.02599989012196463,
            "auditor_fp_violation": 0.014487358696973382,
            "ave_precision_score": 0.7824807457479483,
            "fpr": 0.09539473684210527,
            "logloss": 2.6402964358890118,
            "mae": 0.29407864010433094,
            "precision": 0.7846534653465347,
            "recall": 0.6617954070981211
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.833194375169544,
            "auditor_fn_violation": 0.030703102432260678,
            "auditor_fp_violation": 0.016757469863744854,
            "ave_precision_score": 0.8329638388059167,
            "fpr": 0.08122941822173436,
            "logloss": 2.6775730025666884,
            "mae": 0.2714420646285764,
            "precision": 0.815,
            "recall": 0.6863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7945045623532085,
            "auditor_fn_violation": 0.013169340365527605,
            "auditor_fp_violation": 0.0014155625785016827,
            "ave_precision_score": 0.7953517628026098,
            "fpr": 0.03070175438596491,
            "logloss": 1.3644205317440143,
            "mae": 0.37962705140920383,
            "precision": 0.8313253012048193,
            "recall": 0.2881002087682672
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.8366167191614553,
            "auditor_fn_violation": 0.007300248425674517,
            "auditor_fp_violation": 0.0077342168601899335,
            "ave_precision_score": 0.8369832699774957,
            "fpr": 0.026344676180021953,
            "logloss": 1.1926957041445378,
            "mae": 0.3368888101682988,
            "precision": 0.8888888888888888,
            "recall": 0.40421052631578946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8021699002777836,
            "auditor_fn_violation": 0.012651997948943344,
            "auditor_fp_violation": 0.016039666139945712,
            "ave_precision_score": 0.8020246759601852,
            "fpr": 0.11293859649122807,
            "logloss": 0.9991574757363902,
            "mae": 0.28010629316356667,
            "precision": 0.7700892857142857,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8555535839856294,
            "auditor_fn_violation": 0.013900283089722113,
            "auditor_fp_violation": 0.011792666592815637,
            "ave_precision_score": 0.8556700386472516,
            "fpr": 0.10098792535675083,
            "logloss": 0.8321387664463876,
            "mae": 0.24734370301661837,
            "precision": 0.7941834451901566,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7843162705902362,
            "auditor_fn_violation": 0.02480496648719921,
            "auditor_fp_violation": 0.013904926866820634,
            "ave_precision_score": 0.7839467242748298,
            "fpr": 0.09429824561403509,
            "logloss": 2.6272637663577765,
            "mae": 0.2942335732827654,
            "precision": 0.7860696517412935,
            "recall": 0.6597077244258872
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8338013738448816,
            "auditor_fn_violation": 0.030157721416604086,
            "auditor_fp_violation": 0.017334011420054585,
            "ave_precision_score": 0.8335701332458999,
            "fpr": 0.0845225027442371,
            "logloss": 2.666947165905813,
            "mae": 0.27239838728274574,
            "precision": 0.8084577114427861,
            "recall": 0.6842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.768225668235623,
            "auditor_fn_violation": 0.01457944181958027,
            "auditor_fp_violation": 0.019931830152749085,
            "ave_precision_score": 0.7690397003350263,
            "fpr": 0.1524122807017544,
            "logloss": 0.9486414152278948,
            "mae": 0.30226377559833045,
            "precision": 0.719758064516129,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8185808821482784,
            "auditor_fn_violation": 0.015155121613033685,
            "auditor_fp_violation": 0.02029728396056355,
            "ave_precision_score": 0.8188930624095303,
            "fpr": 0.132821075740944,
            "logloss": 0.912721567406012,
            "mae": 0.27350321451032833,
            "precision": 0.7468619246861925,
            "recall": 0.751578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 8653,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7876453592344286,
            "auditor_fn_violation": 0.0029483939493828593,
            "auditor_fp_violation": 0.016171346379806332,
            "ave_precision_score": 0.7880736618889821,
            "fpr": 0.10197368421052631,
            "logloss": 0.6969312152564131,
            "mae": 0.32919979019264667,
            "precision": 0.7590673575129534,
            "recall": 0.6116910229645094
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8044622947737139,
            "auditor_fn_violation": 0.006546883124386165,
            "auditor_fp_violation": 0.01228109044401253,
            "ave_precision_score": 0.8047798932648711,
            "fpr": 0.0889132821075741,
            "logloss": 0.6661590953445089,
            "mae": 0.3240567009016593,
            "precision": 0.7737430167597765,
            "recall": 0.5831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7991721108100218,
            "auditor_fn_violation": 0.003168150020144314,
            "auditor_fp_violation": 0.01205887119646692,
            "ave_precision_score": 0.7995714447575997,
            "fpr": 0.09539473684210527,
            "logloss": 0.6613842486602672,
            "mae": 0.32436665876797,
            "precision": 0.768,
            "recall": 0.6012526096033403
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8159380112356197,
            "auditor_fn_violation": 0.004527124617251137,
            "auditor_fp_violation": 0.0100001007059487,
            "ave_precision_score": 0.8162131954754357,
            "fpr": 0.08122941822173436,
            "logloss": 0.6254452548279353,
            "mae": 0.3223495641459887,
            "precision": 0.7932960893854749,
            "recall": 0.5978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7770461609127643,
            "auditor_fn_violation": 0.01690519356847233,
            "auditor_fp_violation": 0.0206358129735424,
            "ave_precision_score": 0.7772401360229532,
            "fpr": 0.1162280701754386,
            "logloss": 1.0429671013252726,
            "mae": 0.2909536172244253,
            "precision": 0.7623318385650224,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8379837935223149,
            "auditor_fn_violation": 0.01497486856548617,
            "auditor_fp_violation": 0.006870663350084089,
            "ave_precision_score": 0.8382810277042405,
            "fpr": 0.09110867178924259,
            "logloss": 0.8762451611761386,
            "mae": 0.25119055518377015,
            "precision": 0.8078703703703703,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8615216632032356,
            "auditor_fn_violation": 0.00412500457825148,
            "auditor_fp_violation": 0.011309306754183382,
            "ave_precision_score": 0.8519320117411511,
            "fpr": 0.08662280701754387,
            "logloss": 2.062665568791392,
            "mae": 0.22912764623414544,
            "precision": 0.8167053364269141,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8673068085628287,
            "auditor_fn_violation": 0.0024519036339476644,
            "auditor_fp_violation": 0.011334454526228867,
            "ave_precision_score": 0.8631195768448272,
            "fpr": 0.0845225027442371,
            "logloss": 1.9182492005867633,
            "mae": 0.22633351847748642,
            "precision": 0.8192488262910798,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8304704991812175,
            "auditor_fn_violation": 0.012267424825110796,
            "auditor_fp_violation": 0.01615868481828127,
            "ave_precision_score": 0.8314883585857238,
            "fpr": 0.08881578947368421,
            "logloss": 0.5782603563273839,
            "mae": 0.29655147787963326,
            "precision": 0.802439024390244,
            "recall": 0.6868475991649269
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8854566799758483,
            "auditor_fn_violation": 0.014304696978450517,
            "auditor_fp_violation": 0.012477467043978292,
            "ave_precision_score": 0.8855972573322564,
            "fpr": 0.06915477497255763,
            "logloss": 0.514131342593597,
            "mae": 0.2711169238461576,
            "precision": 0.8481927710843373,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 8653,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6997722005756047,
            "auditor_fn_violation": 0.03542879903307329,
            "auditor_fp_violation": 0.02957234309792959,
            "ave_precision_score": 0.6871956840453233,
            "fpr": 0.17543859649122806,
            "logloss": 3.7160777048523745,
            "mae": 0.33256295383493295,
            "precision": 0.6850393700787402,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7330729752011466,
            "auditor_fn_violation": 0.039170373793980015,
            "auditor_fp_violation": 0.031264161774036,
            "ave_precision_score": 0.7239344462082595,
            "fpr": 0.1437980241492865,
            "logloss": 3.5074883138815403,
            "mae": 0.3068263418815645,
            "precision": 0.7253668763102725,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8450699125290285,
            "auditor_fn_violation": 0.002600446837343889,
            "auditor_fp_violation": 0.011630910416919903,
            "ave_precision_score": 0.8455049762544287,
            "fpr": 0.16337719298245615,
            "logloss": 0.5214833613964486,
            "mae": 0.2859674565730976,
            "precision": 0.7348754448398577,
            "recall": 0.8622129436325678
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8915269968174662,
            "auditor_fn_violation": 0.008053613726962854,
            "auditor_fp_violation": 0.007877722837087991,
            "ave_precision_score": 0.8916649626282809,
            "fpr": 0.15916575192096596,
            "logloss": 0.4750121766102232,
            "mae": 0.27378094530467334,
            "precision": 0.7410714285714286,
            "recall": 0.8736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7959358829976115,
            "auditor_fn_violation": 0.013199099000109878,
            "auditor_fp_violation": 0.008566812527855442,
            "ave_precision_score": 0.7962815119483239,
            "fpr": 0.11732456140350878,
            "logloss": 0.9812562759622108,
            "mae": 0.29081054976103293,
            "precision": 0.7584650112866818,
            "recall": 0.7014613778705637
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8367737331936217,
            "auditor_fn_violation": 0.014914784216303665,
            "auditor_fp_violation": 0.011898407838951049,
            "ave_precision_score": 0.8370284606723382,
            "fpr": 0.10647639956092206,
            "logloss": 0.9374449244301458,
            "mae": 0.2683100659303506,
            "precision": 0.7795454545454545,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7969448901546182,
            "auditor_fn_violation": 0.012656576200417543,
            "auditor_fp_violation": 0.013188282484502248,
            "ave_precision_score": 0.797432884599383,
            "fpr": 0.10635964912280702,
            "logloss": 0.9722181950676139,
            "mae": 0.2968426447010554,
            "precision": 0.7662650602409639,
            "recall": 0.6638830897703549
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8381460096044616,
            "auditor_fn_violation": 0.015309954359003996,
            "auditor_fp_violation": 0.01189840783895105,
            "ave_precision_score": 0.8383876875802224,
            "fpr": 0.09879253567508232,
            "logloss": 0.935082624641614,
            "mae": 0.2703065302914701,
            "precision": 0.7857142857142857,
            "recall": 0.6947368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7613189080296214,
            "auditor_fn_violation": 0.030587298099109993,
            "auditor_fp_violation": 0.01593077671083019,
            "ave_precision_score": 0.7611346326776898,
            "fpr": 0.10855263157894737,
            "logloss": 2.7945150227183064,
            "mae": 0.3123097108093115,
            "precision": 0.754950495049505,
            "recall": 0.6367432150313153
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8107758926409475,
            "auditor_fn_violation": 0.03769368536599458,
            "auditor_fp_violation": 0.017271070202116844,
            "ave_precision_score": 0.8106088819404855,
            "fpr": 0.10098792535675083,
            "logloss": 2.8350156244417866,
            "mae": 0.29115477768172154,
            "precision": 0.7722772277227723,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.84448390323003,
            "auditor_fn_violation": 0.009728784382668573,
            "auditor_fp_violation": 0.010719277987115599,
            "ave_precision_score": 0.8448473143479733,
            "fpr": 0.14144736842105263,
            "logloss": 0.4959924809547824,
            "mae": 0.30899788872155015,
            "precision": 0.7566037735849057,
            "recall": 0.837160751565762
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8731275188769544,
            "auditor_fn_violation": 0.009987867583338148,
            "auditor_fp_violation": 0.013796714971953396,
            "ave_precision_score": 0.8733086411466653,
            "fpr": 0.14050493962678376,
            "logloss": 0.4711971986006394,
            "mae": 0.30191733533134185,
            "precision": 0.7616387337057728,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7924605542915906,
            "auditor_fn_violation": 0.008803977584880792,
            "auditor_fp_violation": 0.019210121145820682,
            "ave_precision_score": 0.7928792496511179,
            "fpr": 0.13706140350877194,
            "logloss": 0.9786591483531758,
            "mae": 0.2887080037130125,
            "precision": 0.7373949579831933,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8392856878068242,
            "auditor_fn_violation": 0.014140620486452144,
            "auditor_fp_violation": 0.02065479007844994,
            "ave_precision_score": 0.8395219576752229,
            "fpr": 0.1251372118551043,
            "logloss": 0.9407369585065557,
            "mae": 0.2655482759241288,
            "precision": 0.7574468085106383,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.81135557898253,
            "auditor_fn_violation": 0.024296780573563347,
            "auditor_fp_violation": 0.01357572626716908,
            "ave_precision_score": 0.8114082398625373,
            "fpr": 0.1206140350877193,
            "logloss": 2.2893690148788206,
            "mae": 0.3211986594107512,
            "precision": 0.7613882863340564,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8343630263407926,
            "auditor_fn_violation": 0.03693338725518517,
            "auditor_fp_violation": 0.008408946716482546,
            "ave_precision_score": 0.8341222218698345,
            "fpr": 0.10976948408342481,
            "logloss": 2.4533321790750033,
            "mae": 0.31337855210168514,
            "precision": 0.7807017543859649,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8067203792264859,
            "auditor_fn_violation": 0.013274640149434126,
            "auditor_fp_violation": 0.023907560471617843,
            "ave_precision_score": 0.8088567556999835,
            "fpr": 0.12390350877192982,
            "logloss": 0.9158490831416536,
            "mae": 0.2796359381914914,
            "precision": 0.7616033755274262,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.856428329020253,
            "auditor_fn_violation": 0.018441273326015365,
            "auditor_fp_violation": 0.015131068792233563,
            "ave_precision_score": 0.8565977926697851,
            "fpr": 0.1163556531284303,
            "logloss": 0.861759182901929,
            "mae": 0.2624484245271716,
            "precision": 0.7730192719486081,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8082034690106839,
            "auditor_fn_violation": 0.007384719627879726,
            "auditor_fp_violation": 0.012327296300798183,
            "ave_precision_score": 0.8088584722220792,
            "fpr": 0.10526315789473684,
            "logloss": 0.9173581228132778,
            "mae": 0.27307916841219887,
            "precision": 0.7842696629213484,
            "recall": 0.7286012526096033
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8612792830063096,
            "auditor_fn_violation": 0.008377144837945584,
            "auditor_fp_violation": 0.010156194926434306,
            "ave_precision_score": 0.8614374677844596,
            "fpr": 0.08562019758507135,
            "logloss": 0.7751172614593411,
            "mae": 0.23942535229557266,
            "precision": 0.8202764976958525,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7876539888070219,
            "auditor_fn_violation": 0.00796386843936564,
            "auditor_fp_violation": 0.017903447996434518,
            "ave_precision_score": 0.7883423667435098,
            "fpr": 0.13925438596491227,
            "logloss": 0.9825533367985065,
            "mae": 0.29206304518652,
            "precision": 0.7331932773109243,
            "recall": 0.7286012526096033
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8362705728197201,
            "auditor_fn_violation": 0.012936622566294995,
            "auditor_fp_violation": 0.019995166114462386,
            "ave_precision_score": 0.8364885286604626,
            "fpr": 0.1251372118551043,
            "logloss": 0.9367179036372075,
            "mae": 0.2671743292522873,
            "precision": 0.7548387096774194,
            "recall": 0.7389473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7915875033514498,
            "auditor_fn_violation": 0.008694099549500057,
            "auditor_fp_violation": 0.022246363599530007,
            "ave_precision_score": 0.7931256005737859,
            "fpr": 0.125,
            "logloss": 0.876565396588011,
            "mae": 0.26915553577434453,
            "precision": 0.7654320987654321,
            "recall": 0.7766179540709812
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8497122918703375,
            "auditor_fn_violation": 0.01559882142238142,
            "auditor_fp_violation": 0.015564104371645241,
            "ave_precision_score": 0.8499417693862358,
            "fpr": 0.1207464324917673,
            "logloss": 0.8066174224619792,
            "mae": 0.25127715559268565,
            "precision": 0.7708333333333334,
            "recall": 0.7789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8027703287083343,
            "auditor_fn_violation": 0.012919825660183874,
            "auditor_fp_violation": 0.013545338519508935,
            "ave_precision_score": 0.8028550966802637,
            "fpr": 0.09320175438596491,
            "logloss": 0.957890687494582,
            "mae": 0.28436499998058534,
            "precision": 0.7906403940886699,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8573923312575703,
            "auditor_fn_violation": 0.012442082153792831,
            "auditor_fp_violation": 0.01067986585967633,
            "ave_precision_score": 0.8576057291228093,
            "fpr": 0.07683863885839737,
            "logloss": 0.8209495810036773,
            "mae": 0.24673110388873734,
            "precision": 0.8284313725490197,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.844399575715259,
            "auditor_fn_violation": 0.0038800681243819396,
            "auditor_fp_violation": 0.013335156598192947,
            "ave_precision_score": 0.8448141621322409,
            "fpr": 0.15350877192982457,
            "logloss": 0.515298038934981,
            "mae": 0.28677701478335893,
            "precision": 0.7435897435897436,
            "recall": 0.8475991649269311
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8913455447098783,
            "auditor_fn_violation": 0.009190594488416434,
            "auditor_fp_violation": 0.011601325290284901,
            "ave_precision_score": 0.8914857421328652,
            "fpr": 0.14928649835345773,
            "logloss": 0.4661933564483211,
            "mae": 0.27282646025484225,
            "precision": 0.7495395948434622,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.7728381840616896,
            "auditor_fn_violation": 0.0006226422004907972,
            "auditor_fp_violation": 0.002147400834650136,
            "ave_precision_score": 0.7734905762265343,
            "fpr": 0.0043859649122807015,
            "logloss": 9.756547655260364,
            "mae": 0.52850735896702,
            "precision": 0.2,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.7901584869550862,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003816755455744771,
            "ave_precision_score": 0.7913738124909063,
            "fpr": 0.008781558726673985,
            "logloss": 9.623605706649558,
            "mae": 0.5301844628552886,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.779952584333259,
            "auditor_fn_violation": 0.021865729040764757,
            "auditor_fp_violation": 0.016171346379806332,
            "ave_precision_score": 0.7795924331010813,
            "fpr": 0.10197368421052631,
            "logloss": 2.6950792962006753,
            "mae": 0.2971117781601774,
            "precision": 0.7759036144578313,
            "recall": 0.6722338204592901
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8301829309509294,
            "auditor_fn_violation": 0.02906002657576984,
            "auditor_fp_violation": 0.016432693179186098,
            "ave_precision_score": 0.829907856285686,
            "fpr": 0.0867178924259056,
            "logloss": 2.7033195063373197,
            "mae": 0.27375372698285655,
            "precision": 0.8044554455445545,
            "recall": 0.6842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8474568462835628,
            "auditor_fn_violation": 0.016051349668534595,
            "auditor_fp_violation": 0.01554839755277339,
            "ave_precision_score": 0.8479231468086077,
            "fpr": 0.125,
            "logloss": 0.5099627408152846,
            "mae": 0.300050503902388,
            "precision": 0.7755905511811023,
            "recall": 0.8225469728601252
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8730602913020686,
            "auditor_fn_violation": 0.020199896007857186,
            "auditor_fp_violation": 0.023326015367727777,
            "ave_precision_score": 0.8742698671482232,
            "fpr": 0.11964873765093303,
            "logloss": 0.4925142276541566,
            "mae": 0.2803759600108152,
            "precision": 0.7841584158415842,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7699322422736365,
            "auditor_fn_violation": 0.02599989012196462,
            "auditor_fp_violation": 0.014256918277217295,
            "ave_precision_score": 0.7690492756290892,
            "fpr": 0.09539473684210527,
            "logloss": 2.7563859082082045,
            "mae": 0.3053652652113179,
            "precision": 0.7780612244897959,
            "recall": 0.6367432150313153
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8194850984493293,
            "auditor_fn_violation": 0.03022473857530765,
            "auditor_fp_violation": 0.019463942235067824,
            "ave_precision_score": 0.8192691621487059,
            "fpr": 0.0845225027442371,
            "logloss": 2.7746122925329453,
            "mae": 0.2799369737110752,
            "precision": 0.8025641025641026,
            "recall": 0.6589473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.793148322861579,
            "auditor_fn_violation": 0.012704647840896614,
            "auditor_fp_violation": 0.01692597544669989,
            "ave_precision_score": 0.7936063149989228,
            "fpr": 0.11513157894736842,
            "logloss": 0.9975152562765707,
            "mae": 0.29558226216921824,
            "precision": 0.7586206896551724,
            "recall": 0.6889352818371608
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8341857082129032,
            "auditor_fn_violation": 0.01289271477266163,
            "auditor_fp_violation": 0.013212620469491135,
            "ave_precision_score": 0.8344443890480444,
            "fpr": 0.10098792535675083,
            "logloss": 0.9615709143142036,
            "mae": 0.26979171469278374,
            "precision": 0.7865429234338747,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8050126327977734,
            "auditor_fn_violation": 0.014812932644764312,
            "auditor_fp_violation": 0.009270795348648761,
            "ave_precision_score": 0.8048979408123532,
            "fpr": 0.09210526315789473,
            "logloss": 1.063934166917859,
            "mae": 0.27751418260915306,
            "precision": 0.7915632754342432,
            "recall": 0.6659707724425887
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8609271863367748,
            "auditor_fn_violation": 0.012400485296666475,
            "auditor_fp_violation": 0.008026264111421065,
            "ave_precision_score": 0.861155713424985,
            "fpr": 0.07464324917672886,
            "logloss": 0.8618329786001155,
            "mae": 0.24361780264323266,
            "precision": 0.8329238329238329,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7754169326644758,
            "auditor_fn_violation": 0.02691096216532983,
            "auditor_fp_violation": 0.01291226044325595,
            "ave_precision_score": 0.7746086699358743,
            "fpr": 0.09320175438596491,
            "logloss": 2.6341880517235756,
            "mae": 0.3038149866658147,
            "precision": 0.7831632653061225,
            "recall": 0.6409185803757829
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8247978644290275,
            "auditor_fn_violation": 0.02689236813218558,
            "auditor_fp_violation": 0.012467396449108251,
            "ave_precision_score": 0.8245747532432306,
            "fpr": 0.07683863885839737,
            "logloss": 2.685235619462141,
            "mae": 0.2791703760650237,
            "precision": 0.8191214470284238,
            "recall": 0.6673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8023295534562365,
            "auditor_fn_violation": 0.014533659304838306,
            "auditor_fp_violation": 0.01339846440581824,
            "ave_precision_score": 0.8027704117015632,
            "fpr": 0.10635964912280702,
            "logloss": 0.9012460219910441,
            "mae": 0.282991638761896,
            "precision": 0.7754629629629629,
            "recall": 0.6993736951983298
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8551544177186867,
            "auditor_fn_violation": 0.013958056502397597,
            "auditor_fp_violation": 0.01117836030574326,
            "ave_precision_score": 0.8553683922310493,
            "fpr": 0.08342480790340286,
            "logloss": 0.7772476300531622,
            "mae": 0.2483099350934702,
            "precision": 0.8203309692671394,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 8653,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8003068805932795,
            "auditor_fn_violation": 0.016296286122404142,
            "auditor_fp_violation": 0.010699019488675502,
            "ave_precision_score": 0.8000822439984578,
            "fpr": 0.09429824561403509,
            "logloss": 1.0632528343664078,
            "mae": 0.2828239795372459,
            "precision": 0.7937649880095923,
            "recall": 0.6910229645093946
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8531275671735083,
            "auditor_fn_violation": 0.011836616788953723,
            "auditor_fp_violation": 0.014058550438574409,
            "ave_precision_score": 0.853245167238466,
            "fpr": 0.07903402854006586,
            "logloss": 0.880040859953559,
            "mae": 0.24520900137957546,
            "precision": 0.8256658595641646,
            "recall": 0.7178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7971743924436662,
            "auditor_fn_violation": 0.009822638537889611,
            "auditor_fp_violation": 0.02449505692638062,
            "ave_precision_score": 0.7985443437352431,
            "fpr": 0.13048245614035087,
            "logloss": 0.8606675526620474,
            "mae": 0.26474519357568715,
            "precision": 0.7591093117408907,
            "recall": 0.7828810020876826
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.857704664725023,
            "auditor_fn_violation": 0.018161650008666014,
            "auditor_fp_violation": 0.0247535221905558,
            "ave_precision_score": 0.8579249950882368,
            "fpr": 0.12733260153677278,
            "logloss": 0.7896628431496878,
            "mae": 0.24794003607678008,
            "precision": 0.7651821862348178,
            "recall": 0.7957894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8103185781728746,
            "auditor_fn_violation": 0.005963172545141561,
            "auditor_fp_violation": 0.018921437543049306,
            "ave_precision_score": 0.8105498974318569,
            "fpr": 0.13486842105263158,
            "logloss": 0.9127958548156786,
            "mae": 0.2744968315672887,
            "precision": 0.7520161290322581,
            "recall": 0.778705636743215
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8649900488356724,
            "auditor_fn_violation": 0.011730313709630834,
            "auditor_fp_violation": 0.017059587709846027,
            "ave_precision_score": 0.8651876190025245,
            "fpr": 0.1207464324917673,
            "logloss": 0.7608389000986525,
            "mae": 0.24730683587960106,
            "precision": 0.778672032193159,
            "recall": 0.8147368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7940548051550161,
            "auditor_fn_violation": 0.010990092663809846,
            "auditor_fp_violation": 0.02011922126331997,
            "ave_precision_score": 0.7945605114234366,
            "fpr": 0.14473684210526316,
            "logloss": 0.941182076700406,
            "mae": 0.2892092336307397,
            "precision": 0.7300613496932515,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8372571913586614,
            "auditor_fn_violation": 0.011055520249581147,
            "auditor_fp_violation": 0.023268109447225044,
            "ave_precision_score": 0.83749567774998,
            "fpr": 0.13391877058177826,
            "logloss": 0.9035038188940239,
            "mae": 0.26902242400168036,
            "precision": 0.7458333333333333,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.7657350504651114,
            "auditor_fn_violation": 0.0006226422004907972,
            "auditor_fp_violation": 0.002147400834650136,
            "ave_precision_score": 0.7660884480483651,
            "fpr": 0.0043859649122807015,
            "logloss": 12.395837578491967,
            "mae": 0.5285087630056063,
            "precision": 0.2,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.7851982982948622,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003816755455744771,
            "ave_precision_score": 0.7864272301535814,
            "fpr": 0.008781558726673985,
            "logloss": 12.296024388231741,
            "mae": 0.5301865935750006,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8019802362652069,
            "auditor_fn_violation": 0.014998351829469297,
            "auditor_fp_violation": 0.011499230177059278,
            "ave_precision_score": 0.8023835590591692,
            "fpr": 0.10416666666666667,
            "logloss": 0.8972074151921017,
            "mae": 0.2902802880281716,
            "precision": 0.7785547785547785,
            "recall": 0.697286012526096
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8390419342249648,
            "auditor_fn_violation": 0.011725691836616798,
            "auditor_fp_violation": 0.010581677559693454,
            "ave_precision_score": 0.8392912340727378,
            "fpr": 0.09769484083424808,
            "logloss": 0.8377986664270495,
            "mae": 0.26692765208531827,
            "precision": 0.7915690866510539,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.769454880290561,
            "auditor_fn_violation": 0.02599989012196462,
            "auditor_fp_violation": 0.014256918277217295,
            "ave_precision_score": 0.768509206278333,
            "fpr": 0.09539473684210527,
            "logloss": 2.7599585247061054,
            "mae": 0.30597378902044314,
            "precision": 0.7780612244897959,
            "recall": 0.6367432150313153
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8188686063943462,
            "auditor_fn_violation": 0.03022473857530765,
            "auditor_fp_violation": 0.019463942235067824,
            "ave_precision_score": 0.8186622163763124,
            "fpr": 0.0845225027442371,
            "logloss": 2.777555607869414,
            "mae": 0.2804153062599378,
            "precision": 0.8025641025641026,
            "recall": 0.6589473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8335253691540235,
            "auditor_fn_violation": 0.008593378017067723,
            "auditor_fp_violation": 0.014644362059884128,
            "ave_precision_score": 0.8340546094037435,
            "fpr": 0.13157894736842105,
            "logloss": 0.5250319253998614,
            "mae": 0.29833623591478325,
            "precision": 0.76,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8795104878467292,
            "auditor_fn_violation": 0.0037899358715119307,
            "auditor_fp_violation": 0.01481384505382734,
            "ave_precision_score": 0.8796647315818243,
            "fpr": 0.1251372118551043,
            "logloss": 0.475844789922594,
            "mae": 0.28194074094695226,
            "precision": 0.7738095238095238,
            "recall": 0.8210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 8653,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8014538789915872,
            "auditor_fn_violation": 0.008620847525912906,
            "auditor_fp_violation": 0.009632916008265475,
            "ave_precision_score": 0.8012519755077672,
            "fpr": 0.12280701754385964,
            "logloss": 1.0151180889786484,
            "mae": 0.2813220755428917,
            "precision": 0.7611940298507462,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8567744646127842,
            "auditor_fn_violation": 0.012488300883933217,
            "auditor_fp_violation": 0.013600338371987635,
            "ave_precision_score": 0.8569457624294686,
            "fpr": 0.11745334796926454,
            "logloss": 0.8363141875330186,
            "mae": 0.2520199963238273,
            "precision": 0.7718550106609808,
            "recall": 0.7621052631578947
        }
    }
]