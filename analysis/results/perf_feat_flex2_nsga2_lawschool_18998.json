[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7051371591458389,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.10791782086795938,
            "ave_precision_score": 0.5315530012226677,
            "fpr": 0.3092105263157895,
            "logloss": 0.6880788876900816,
            "mae": 0.4956125576833361,
            "precision": 0.5429497568881686,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7369525483445265,
            "auditor_fn_violation": 0.09442820678983772,
            "auditor_fp_violation": 0.09703037664488111,
            "ave_precision_score": 0.5779923317050665,
            "fpr": 0.2854006586169045,
            "logloss": 0.6832588339588631,
            "mae": 0.4931824691143831,
            "precision": 0.5886075949367089,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7046731585201963,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.1094952293013235,
            "ave_precision_score": 0.5315530012226677,
            "fpr": 0.31359649122807015,
            "logloss": 0.6886703602271765,
            "mae": 0.49570226005948426,
            "precision": 0.5394524959742351,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7368421035928927,
            "auditor_fn_violation": 0.09367877657721997,
            "auditor_fp_violation": 0.0970888494935454,
            "ave_precision_score": 0.5780741580987767,
            "fpr": 0.287596048298573,
            "logloss": 0.6831244077476767,
            "mae": 0.4929101192336182,
            "precision": 0.5874015748031496,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.7308744729375649,
            "auditor_fn_violation": 0.032832217605417054,
            "auditor_fp_violation": 0.07685056940597107,
            "ave_precision_score": 0.7226557218763957,
            "fpr": 0.31469298245614036,
            "logloss": 0.6400460748553123,
            "mae": 0.4317490832978173,
            "precision": 0.5729166666666666,
            "recall": 0.8442982456140351
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7510065046376024,
            "auditor_fn_violation": 0.04100926207574535,
            "auditor_fp_violation": 0.07079467259191534,
            "ave_precision_score": 0.7436497992231591,
            "fpr": 0.3018660812294182,
            "logloss": 0.6435692802046615,
            "mae": 0.43028693511247895,
            "precision": 0.5907738095238095,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.731617443496966,
            "auditor_fn_violation": 0.05537280701754386,
            "auditor_fp_violation": 0.09535626346568177,
            "ave_precision_score": 0.7321240919475663,
            "fpr": 0.2741228070175439,
            "logloss": 0.633640040095153,
            "mae": 0.43962018711394385,
            "precision": 0.5777027027027027,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7492962128474916,
            "auditor_fn_violation": 0.059650236511358284,
            "auditor_fp_violation": 0.08613316393926267,
            "ave_precision_score": 0.7496612672693959,
            "fpr": 0.270032930845225,
            "logloss": 0.6401536054113934,
            "mae": 0.4393404353201455,
            "precision": 0.5886287625418061,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7051371591458389,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.10791782086795938,
            "ave_precision_score": 0.5315530012226677,
            "fpr": 0.3092105263157895,
            "logloss": 0.6880788876900816,
            "mae": 0.4956125576833361,
            "precision": 0.5429497568881686,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7369525483445265,
            "auditor_fn_violation": 0.09442820678983772,
            "auditor_fp_violation": 0.09703037664488111,
            "ave_precision_score": 0.5779923317050665,
            "fpr": 0.2854006586169045,
            "logloss": 0.6832588339588631,
            "mae": 0.4931824691143831,
            "precision": 0.5886075949367089,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.33441053787047204,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.10738400277008311,
            "ave_precision_score": 0.5265930055655055,
            "fpr": 0.31798245614035087,
            "logloss": 0.6890881760270525,
            "mae": 0.49451448039658236,
            "precision": 0.536,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.4553990031991102,
            "auditor_fn_violation": 0.09367877657721997,
            "auditor_fp_violation": 0.09844967215336896,
            "ave_precision_score": 0.5751436693379769,
            "fpr": 0.2897914379802415,
            "logloss": 0.6840456599842547,
            "mae": 0.4920232067647279,
            "precision": 0.5855572998430141,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7106685270663936,
            "auditor_fn_violation": 0.062187403816558955,
            "auditor_fp_violation": 0.10886041859033549,
            "ave_precision_score": 0.7111620592297481,
            "fpr": 0.24451754385964913,
            "logloss": 0.6553682558544257,
            "mae": 0.4514838301233555,
            "precision": 0.5960144927536232,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7313997727845557,
            "auditor_fn_violation": 0.0627206961765834,
            "auditor_fp_violation": 0.1025294822760822,
            "ave_precision_score": 0.7317649906364783,
            "fpr": 0.23600439077936333,
            "logloss": 0.6522444645526786,
            "mae": 0.4462038991414624,
            "precision": 0.6160714285714286,
            "recall": 0.6927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7323743235880458,
            "auditor_fn_violation": 0.05537280701754386,
            "auditor_fp_violation": 0.09535626346568177,
            "ave_precision_score": 0.7328759302026226,
            "fpr": 0.2741228070175439,
            "logloss": 0.6327906713949123,
            "mae": 0.439496791937895,
            "precision": 0.5777027027027027,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7498025746048816,
            "auditor_fn_violation": 0.059650236511358284,
            "auditor_fp_violation": 0.08613316393926267,
            "ave_precision_score": 0.7501689536820662,
            "fpr": 0.270032930845225,
            "logloss": 0.6392389713738138,
            "mae": 0.4391763734372596,
            "precision": 0.5886287625418061,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8015106205023831,
            "auditor_fn_violation": 0.005756578947368423,
            "auditor_fp_violation": 0.01905153508771929,
            "ave_precision_score": 0.8029225643985822,
            "fpr": 0.3125,
            "logloss": 0.6401511980714312,
            "mae": 0.37810405087657273,
            "precision": 0.5945945945945946,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8713751643248158,
            "auditor_fn_violation": 0.007710314363932129,
            "auditor_fp_violation": 0.027912811666928026,
            "ave_precision_score": 0.8716161350229465,
            "fpr": 0.27771679473106475,
            "logloss": 0.557543148647082,
            "mae": 0.3479454902815505,
            "precision": 0.6476323119777159,
            "recall": 0.9337349397590361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6944749926557454,
            "auditor_fn_violation": 0.017738631117266854,
            "auditor_fp_violation": 0.013956217297630042,
            "ave_precision_score": 0.6961253733288937,
            "fpr": 0.08662280701754387,
            "logloss": 0.6188418241372852,
            "mae": 0.41712220296623154,
            "precision": 0.7620481927710844,
            "recall": 0.5548245614035088
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7989636805713614,
            "auditor_fn_violation": 0.015085589338693962,
            "auditor_fp_violation": 0.021326642621922534,
            "ave_precision_score": 0.7995432165457657,
            "fpr": 0.06037321624588365,
            "logloss": 0.58444739520166,
            "mae": 0.40562116178049085,
            "precision": 0.8401162790697675,
            "recall": 0.5803212851405622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.8128438368600581,
            "auditor_fn_violation": 0.0028085564789165902,
            "auditor_fp_violation": 0.02362505771006465,
            "ave_precision_score": 0.8132630093001735,
            "fpr": 0.39144736842105265,
            "logloss": 0.8749153819146972,
            "mae": 0.4072673986134887,
            "precision": 0.5498108448928121,
            "recall": 0.956140350877193
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8669972767476017,
            "auditor_fn_violation": 0.004042514735120504,
            "auditor_fp_violation": 0.024478860736279483,
            "ave_precision_score": 0.8671875996416455,
            "fpr": 0.34357848518111966,
            "logloss": 0.7495566721652874,
            "mae": 0.3679707379424873,
            "precision": 0.6047979797979798,
            "recall": 0.9618473895582329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7019119616276613,
            "auditor_fn_violation": 0.0009954986149584488,
            "auditor_fp_violation": 0.0034626038781163542,
            "ave_precision_score": 0.6942047810637202,
            "fpr": 0.4934210526315789,
            "logloss": 0.7853092966442943,
            "mae": 0.44775996677446783,
            "precision": 0.5022123893805309,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7266387011914344,
            "auditor_fn_violation": 0.0012696229484347934,
            "auditor_fp_violation": 0.0005687813460981393,
            "ave_precision_score": 0.7197396702871512,
            "fpr": 0.4522502744237102,
            "logloss": 0.7615419735158373,
            "mae": 0.4339438204773171,
            "precision": 0.5462555066079295,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8024263620190691,
            "auditor_fn_violation": 0.019044321329639898,
            "auditor_fp_violation": 0.022963796552785475,
            "ave_precision_score": 0.802937598283594,
            "fpr": 0.1337719298245614,
            "logloss": 0.5544238849365386,
            "mae": 0.3640904777127792,
            "precision": 0.7336244541484717,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8552074858176839,
            "auditor_fn_violation": 0.016967981696269164,
            "auditor_fp_violation": 0.02346090159816927,
            "ave_precision_score": 0.8557148400324847,
            "fpr": 0.09989023051591657,
            "logloss": 0.518186191037347,
            "mae": 0.34467422482189564,
            "precision": 0.796420581655481,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.804283362758101,
            "auditor_fn_violation": 0.0012888581101877458,
            "auditor_fp_violation": 7.694675284703374e-05,
            "ave_precision_score": 0.804635564752559,
            "fpr": 0.06359649122807018,
            "logloss": 0.5487206001792985,
            "mae": 0.3598371268854591,
            "precision": 0.8220858895705522,
            "recall": 0.5877192982456141
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8596096900126473,
            "auditor_fn_violation": 0.004844845903923055,
            "auditor_fp_violation": 0.004526330057967856,
            "ave_precision_score": 0.8598739044168198,
            "fpr": 0.03732162458836443,
            "logloss": 0.5392153328211962,
            "mae": 0.34363382571842904,
            "precision": 0.8988095238095238,
            "recall": 0.606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6141979630544945,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6138863889887995,
            "fpr": 0.5,
            "logloss": 1.869130200136622,
            "mae": 0.4878602716091432,
            "precision": 0.5,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6434367356940591,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6435131561715952,
            "fpr": 0.45334796926454446,
            "logloss": 1.7448966590790884,
            "mae": 0.4495507808469653,
            "precision": 0.5466520307354555,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.804283362758101,
            "auditor_fn_violation": 0.0012888581101877458,
            "auditor_fp_violation": 7.694675284703374e-05,
            "ave_precision_score": 0.804635564752559,
            "fpr": 0.06359649122807018,
            "logloss": 0.5487205451862159,
            "mae": 0.3598371663727193,
            "precision": 0.8220858895705522,
            "recall": 0.5877192982456141
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8596096900126473,
            "auditor_fn_violation": 0.004844845903923055,
            "auditor_fp_violation": 0.004526330057967856,
            "ave_precision_score": 0.8598739044168198,
            "fpr": 0.03732162458836443,
            "logloss": 0.539215250994994,
            "mae": 0.34363385147135755,
            "precision": 0.8988095238095238,
            "recall": 0.606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.804483595831602,
            "auditor_fn_violation": 0.003325542474607574,
            "auditor_fp_violation": 0.0006877116035703321,
            "ave_precision_score": 0.8048804712225527,
            "fpr": 0.08662280701754387,
            "logloss": 0.5432494012399748,
            "mae": 0.36089367319404947,
            "precision": 0.7864864864864864,
            "recall": 0.6381578947368421
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8607766553602325,
            "auditor_fn_violation": 0.0093502440056604,
            "auditor_fp_violation": 0.006902453999144171,
            "ave_precision_score": 0.8611014643391409,
            "fpr": 0.05378704720087816,
            "logloss": 0.5167968638956407,
            "mae": 0.34116613361820924,
            "precision": 0.8696808510638298,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 18998,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8035996220130015,
            "auditor_fn_violation": 0.004518217143736542,
            "auditor_fp_violation": 0.00031740535549400136,
            "ave_precision_score": 0.8039971959340182,
            "fpr": 0.08552631578947369,
            "logloss": 0.5443218371391855,
            "mae": 0.3615578571048549,
            "precision": 0.7874659400544959,
            "recall": 0.6337719298245614
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8600298126698263,
            "auditor_fn_violation": 0.006784547630698433,
            "auditor_fp_violation": 0.006251279093564531,
            "ave_precision_score": 0.8603576919672488,
            "fpr": 0.05159165751920966,
            "logloss": 0.5189344869958763,
            "mae": 0.3417511101999718,
            "precision": 0.8739946380697051,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7246056231005746,
            "auditor_fn_violation": 0.03440481686672822,
            "auditor_fp_violation": 0.0715027700831025,
            "ave_precision_score": 0.7228246303511534,
            "fpr": 0.29276315789473684,
            "logloss": 0.6306270311658145,
            "mae": 0.42133493220286544,
            "precision": 0.588597842835131,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7341284939871846,
            "auditor_fn_violation": 0.03968894237763348,
            "auditor_fp_violation": 0.05816187942367035,
            "ave_precision_score": 0.7326026291150218,
            "fpr": 0.2711306256860593,
            "logloss": 0.6419097466419004,
            "mae": 0.4235286254407153,
            "precision": 0.6122448979591837,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7606610626535404,
            "auditor_fn_violation": 0.03807421514312096,
            "auditor_fp_violation": 0.09935749461372731,
            "ave_precision_score": 0.7608570504436788,
            "fpr": 0.26535087719298245,
            "logloss": 0.6397362207968182,
            "mae": 0.43842219512321445,
            "precision": 0.6077795786061588,
            "recall": 0.8223684210526315
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7615551355720824,
            "auditor_fn_violation": 0.04035020432994327,
            "auditor_fp_violation": 0.09036447189715159,
            "ave_precision_score": 0.7617295747786439,
            "fpr": 0.26125137211855104,
            "logloss": 0.6349766649928789,
            "mae": 0.43186031777563,
            "precision": 0.6246056782334385,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6151255362861852,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6148106892020094,
            "fpr": 0.5,
            "logloss": 1.8455982100181778,
            "mae": 0.4854249848346961,
            "precision": 0.5,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6476246670214251,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6477081540319988,
            "fpr": 0.45334796926454446,
            "logloss": 1.7215379450010757,
            "mae": 0.44717855753150126,
            "precision": 0.5466520307354555,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 18998,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8052843324867323,
            "auditor_fn_violation": 0.00024526777469991573,
            "auditor_fp_violation": 0.002611380424746078,
            "ave_precision_score": 0.805649307019087,
            "fpr": 0.06469298245614036,
            "logloss": 0.5465202738350176,
            "mae": 0.35928090340294466,
            "precision": 0.8206686930091185,
            "recall": 0.5921052631578947
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8609014193464777,
            "auditor_fn_violation": 0.0020432994326372443,
            "auditor_fp_violation": 0.0058977841448213,
            "ave_precision_score": 0.8611639583029513,
            "fpr": 0.038419319429198684,
            "logloss": 0.5352452435036695,
            "mae": 0.34314785047791313,
            "precision": 0.8964497041420119,
            "recall": 0.608433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.4662049777680375,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.1094952293013235,
            "ave_precision_score": 0.5443416066539724,
            "fpr": 0.31359649122807015,
            "logloss": 0.6878919402935991,
            "mae": 0.49548792326005925,
            "precision": 0.5394524959742351,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5295991521708442,
            "auditor_fn_violation": 0.09367877657721997,
            "auditor_fp_violation": 0.0970888494935454,
            "ave_precision_score": 0.5895764316094535,
            "fpr": 0.287596048298573,
            "logloss": 0.6832863379145249,
            "mae": 0.49322374624687804,
            "precision": 0.5874015748031496,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.752212389380531,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0023661126500461828,
            "ave_precision_score": 0.504424778761062,
            "fpr": 0.49122807017543857,
            "logloss": 16.968418039085275,
            "mae": 0.49268955248816493,
            "precision": 0.504424778761062,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7738285981934269,
            "auditor_fn_violation": 0.0006524451262789908,
            "auditor_fp_violation": 0.002158179687063958,
            "ave_precision_score": 0.5485649066103275,
            "fpr": 0.4489571899012075,
            "logloss": 15.509337716933992,
            "mae": 0.45054037481317405,
            "precision": 0.5485651214128036,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7999337363540214,
            "auditor_fn_violation": 0.005756578947368423,
            "auditor_fp_violation": 0.02028508771929824,
            "ave_precision_score": 0.8013551243247533,
            "fpr": 0.31030701754385964,
            "logloss": 0.6363052075464073,
            "mae": 0.3777873157196793,
            "precision": 0.5962910128388017,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8709469116922532,
            "auditor_fn_violation": 0.007811707863286297,
            "auditor_fp_violation": 0.028986585796945064,
            "ave_precision_score": 0.8711883524350148,
            "fpr": 0.27442371020856204,
            "logloss": 0.5543035231795925,
            "mae": 0.3476356662458175,
            "precision": 0.6493688639551192,
            "recall": 0.929718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6028152940615383,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.1094952293013235,
            "ave_precision_score": 0.5958133412916017,
            "fpr": 0.31359649122807015,
            "logloss": 0.689029946697929,
            "mae": 0.4955424494518523,
            "precision": 0.5394524959742351,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.641485455779844,
            "auditor_fn_violation": 0.09367877657721997,
            "auditor_fp_violation": 0.0970888494935454,
            "ave_precision_score": 0.6370643614307967,
            "fpr": 0.287596048298573,
            "logloss": 0.6825813130781239,
            "mae": 0.49230448572879043,
            "precision": 0.5874015748031496,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8129567384817591,
            "auditor_fn_violation": 0.010560941828254858,
            "auditor_fp_violation": 0.010041551246537406,
            "ave_precision_score": 0.8132727864964822,
            "fpr": 0.11403508771929824,
            "logloss": 0.5412486772435726,
            "mae": 0.37022749115835485,
            "precision": 0.7475728155339806,
            "recall": 0.6754385964912281
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8508141338440088,
            "auditor_fn_violation": 0.014699853199846593,
            "auditor_fp_violation": 0.011303864789511037,
            "ave_precision_score": 0.8511139785365532,
            "fpr": 0.07903402854006586,
            "logloss": 0.5224807652317116,
            "mae": 0.35551821072427425,
            "precision": 0.8273381294964028,
            "recall": 0.6927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7051371591458389,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.10791782086795938,
            "ave_precision_score": 0.5315530012226677,
            "fpr": 0.3092105263157895,
            "logloss": 0.6880788901423949,
            "mae": 0.4956125594152693,
            "precision": 0.5429497568881686,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7369525483445265,
            "auditor_fn_violation": 0.09442820678983772,
            "auditor_fp_violation": 0.09703037664488111,
            "ave_precision_score": 0.5779923317050665,
            "fpr": 0.2854006586169045,
            "logloss": 0.6832588347634384,
            "mae": 0.49318246999765725,
            "precision": 0.5886075949367089,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7526360190442882,
            "auditor_fn_violation": 0.0417436134195137,
            "auditor_fp_violation": 0.09435595567867036,
            "ave_precision_score": 0.7530819428211375,
            "fpr": 0.27631578947368424,
            "logloss": 0.6366414575812922,
            "mae": 0.43874615590954036,
            "precision": 0.5935483870967742,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7540103387741435,
            "auditor_fn_violation": 0.042104752710071906,
            "auditor_fp_violation": 0.09248012587609605,
            "ave_precision_score": 0.7543507348645363,
            "fpr": 0.25686059275521406,
            "logloss": 0.6322842095535963,
            "mae": 0.4321500753531995,
            "precision": 0.6261980830670927,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.586175084319356,
            "auditor_fn_violation": 0.012578389504462923,
            "auditor_fp_violation": 0.02746037242228378,
            "ave_precision_score": 0.5769602014870258,
            "fpr": 0.15350877192982457,
            "logloss": 3.4384339058139557,
            "mae": 0.4081214598748357,
            "precision": 0.6306068601583114,
            "recall": 0.5241228070175439
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6283746402683816,
            "auditor_fn_violation": 0.017186198140531395,
            "auditor_fp_violation": 0.02999922922154034,
            "ave_precision_score": 0.6180933738480916,
            "fpr": 0.14050493962678376,
            "logloss": 3.6466471774132683,
            "mae": 0.41889232018026773,
            "precision": 0.6743002544529262,
            "recall": 0.5321285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6129489599333828,
            "auditor_fn_violation": 0.01547110649430595,
            "auditor_fp_violation": 0.02744834949215144,
            "ave_precision_score": 0.6027327062891111,
            "fpr": 0.15460526315789475,
            "logloss": 2.7474994002347284,
            "mae": 0.38193482265206175,
            "precision": 0.650990099009901,
            "recall": 0.5767543859649122
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.653242369826914,
            "auditor_fn_violation": 0.007948368666763657,
            "auditor_fp_violation": 0.03228764388972021,
            "ave_precision_score": 0.6422090624284346,
            "fpr": 0.14270032930845225,
            "logloss": 2.7538577305168674,
            "mae": 0.3837466174972933,
            "precision": 0.6962616822429907,
            "recall": 0.5983935742971888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6774501174510021,
            "auditor_fn_violation": 0.06447656971375809,
            "auditor_fp_violation": 0.11253462603878117,
            "ave_precision_score": 0.6758435749042389,
            "fpr": 0.2532894736842105,
            "logloss": 0.6593766306490954,
            "mae": 0.451872178859878,
            "precision": 0.5904255319148937,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7038885641661611,
            "auditor_fn_violation": 0.06535692715979174,
            "auditor_fp_violation": 0.10472487195775071,
            "ave_precision_score": 0.7029117142645007,
            "fpr": 0.23600439077936333,
            "logloss": 0.6530522227447196,
            "mae": 0.44519132329917765,
            "precision": 0.6187943262411347,
            "recall": 0.7008032128514057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7465735756616616,
            "auditor_fn_violation": 0.007035818713450292,
            "auditor_fp_violation": 0.02268967374576793,
            "ave_precision_score": 0.7475654958382264,
            "fpr": 0.17324561403508773,
            "logloss": 1.066627927679422,
            "mae": 0.2890650305530077,
            "precision": 0.6955684007707129,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7863521771446595,
            "auditor_fn_violation": 0.001589232892051191,
            "auditor_fp_violation": 0.027995205226409532,
            "ave_precision_score": 0.7869882573104834,
            "fpr": 0.1668496158068057,
            "logloss": 1.1058528360652873,
            "mae": 0.28571692918200287,
            "precision": 0.7261261261261261,
            "recall": 0.8092369477911646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 18998,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7052824539070778,
            "auditor_fn_violation": 0.033683441058787324,
            "auditor_fp_violation": 0.0742151431209603,
            "ave_precision_score": 0.6909936600551083,
            "fpr": 0.27960526315789475,
            "logloss": 0.6633417157346475,
            "mae": 0.4356731977099308,
            "precision": 0.5799011532125206,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7220972757533585,
            "auditor_fn_violation": 0.030239509079126606,
            "auditor_fp_violation": 0.07264188303835555,
            "ave_precision_score": 0.7139816630049359,
            "fpr": 0.2524698133918771,
            "logloss": 0.6779025816290554,
            "mae": 0.4354681568322489,
            "precision": 0.6160267111853088,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.7509916741005055,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0023661126500461828,
            "ave_precision_score": 0.5084507879869165,
            "fpr": 0.49122807017543857,
            "logloss": 16.71107552550364,
            "mae": 0.4933946549549307,
            "precision": 0.504424778761062,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7775950862693294,
            "auditor_fn_violation": 0.0006524451262789908,
            "auditor_fp_violation": 0.002158179687063958,
            "ave_precision_score": 0.5587555723439895,
            "fpr": 0.4489571899012075,
            "logloss": 15.132157473984961,
            "mae": 0.45078147133213237,
            "precision": 0.5485651214128036,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8015106205023831,
            "auditor_fn_violation": 0.005756578947368423,
            "auditor_fp_violation": 0.01905153508771929,
            "ave_precision_score": 0.8029225643985822,
            "fpr": 0.3125,
            "logloss": 0.6401513138855653,
            "mae": 0.3781040486544697,
            "precision": 0.5945945945945946,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8713751643248158,
            "auditor_fn_violation": 0.007710314363932129,
            "auditor_fp_violation": 0.027912811666928026,
            "ave_precision_score": 0.8716161350229465,
            "fpr": 0.27771679473106475,
            "logloss": 0.5575432101427981,
            "mae": 0.34794547382239194,
            "precision": 0.6476323119777159,
            "recall": 0.9337349397590361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.8105988985107813,
            "auditor_fn_violation": 0.0016735918744228992,
            "auditor_fp_violation": 0.02002539242843953,
            "ave_precision_score": 0.8110250876698284,
            "fpr": 0.40789473684210525,
            "logloss": 0.9645114321692472,
            "mae": 0.4168592956194883,
            "precision": 0.5407407407407407,
            "recall": 0.9605263157894737
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.8641195478880818,
            "auditor_fn_violation": 0.005021182424538991,
            "auditor_fp_violation": 0.019734586424199268,
            "ave_precision_score": 0.8643114336614058,
            "fpr": 0.3589462129527991,
            "logloss": 0.828811973724476,
            "mae": 0.37690303169607986,
            "precision": 0.595797280593325,
            "recall": 0.9678714859437751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8126821477736459,
            "auditor_fn_violation": 0.01351136888273315,
            "auditor_fp_violation": 0.008468951985226224,
            "ave_precision_score": 0.8129917781850592,
            "fpr": 0.10855263157894737,
            "logloss": 0.5409290469341974,
            "mae": 0.36979136739555224,
            "precision": 0.7512562814070352,
            "recall": 0.6557017543859649
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.851359074683123,
            "auditor_fn_violation": 0.016635146513606574,
            "auditor_fp_violation": 0.014402925768718622,
            "ave_precision_score": 0.8516440477431494,
            "fpr": 0.07244785949506037,
            "logloss": 0.5226186220766853,
            "mae": 0.35501947316507737,
            "precision": 0.8378378378378378,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8152992370041969,
            "auditor_fn_violation": 0.011318386426592804,
            "auditor_fp_violation": 0.007526354262850111,
            "ave_precision_score": 0.8156213865069504,
            "fpr": 0.09758771929824561,
            "logloss": 0.5381805141385724,
            "mae": 0.3684785447038481,
            "precision": 0.7729591836734694,
            "recall": 0.6644736842105263
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8520978757988183,
            "auditor_fn_violation": 0.012184853574561698,
            "auditor_fp_violation": 0.013246758079220081,
            "ave_precision_score": 0.8523961121966224,
            "fpr": 0.06915477497255763,
            "logloss": 0.5213602141123169,
            "mae": 0.3544081062381079,
            "precision": 0.844059405940594,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8126413280498417,
            "auditor_fn_violation": 0.012782779316712834,
            "auditor_fp_violation": 0.009098953524161282,
            "ave_precision_score": 0.8129512600428888,
            "fpr": 0.10964912280701754,
            "logloss": 0.540894842220933,
            "mae": 0.3697951184626538,
            "precision": 0.75,
            "recall": 0.6578947368421053
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8513979777528701,
            "auditor_fn_violation": 0.016635146513606574,
            "auditor_fp_violation": 0.014402925768718622,
            "ave_precision_score": 0.8516829586277513,
            "fpr": 0.07244785949506037,
            "logloss": 0.5225250125125268,
            "mae": 0.3549994009738107,
            "precision": 0.8378378378378378,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 18998,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7557815574121136,
            "auditor_fn_violation": 0.0585180055401662,
            "auditor_fp_violation": 0.10936057248384119,
            "ave_precision_score": 0.755982551954081,
            "fpr": 0.24342105263157895,
            "logloss": 0.6407267335047705,
            "mae": 0.43652175857048287,
            "precision": 0.6021505376344086,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7570290166417825,
            "auditor_fn_violation": 0.05921159941632612,
            "auditor_fp_violation": 0.10305839577081832,
            "ave_precision_score": 0.7571977739647002,
            "fpr": 0.2349066959385291,
            "logloss": 0.6407981710289643,
            "mae": 0.43264523832256263,
            "precision": 0.6225749559082893,
            "recall": 0.7088353413654619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.752212389380531,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0023661126500461828,
            "ave_precision_score": 0.504424778761062,
            "fpr": 0.49122807017543857,
            "logloss": 16.970369610532643,
            "mae": 0.49409141744437973,
            "precision": 0.504424778761062,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7738285981934269,
            "auditor_fn_violation": 0.0006524451262789908,
            "auditor_fp_violation": 0.002158179687063958,
            "ave_precision_score": 0.5485649066103275,
            "fpr": 0.4489571899012075,
            "logloss": 15.509292875032925,
            "mae": 0.45078990862803975,
            "precision": 0.5485651214128036,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6431929389035118,
            "auditor_fn_violation": 0.029537934749153585,
            "auditor_fp_violation": 0.055882579255155454,
            "ave_precision_score": 0.644137751172663,
            "fpr": 0.2741228070175439,
            "logloss": 0.7240487397441437,
            "mae": 0.4370749752086244,
            "precision": 0.5915032679738562,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6853504682543069,
            "auditor_fn_violation": 0.028958865098153316,
            "auditor_fp_violation": 0.04694572390715576,
            "ave_precision_score": 0.6859625970056674,
            "fpr": 0.2579582875960483,
            "logloss": 0.7170336620857027,
            "mae": 0.4323153185712339,
            "precision": 0.6209677419354839,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 18998,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8035996220130015,
            "auditor_fn_violation": 0.004518217143736542,
            "auditor_fp_violation": 0.00031740535549400136,
            "ave_precision_score": 0.8039971959340182,
            "fpr": 0.08552631578947369,
            "logloss": 0.544321893635671,
            "mae": 0.3615579067263752,
            "precision": 0.7874659400544959,
            "recall": 0.6337719298245614
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8600298126698263,
            "auditor_fn_violation": 0.006784547630698433,
            "auditor_fp_violation": 0.006251279093564531,
            "ave_precision_score": 0.8603576919672488,
            "fpr": 0.05159165751920966,
            "logloss": 0.5189342204749867,
            "mae": 0.34175109033703877,
            "precision": 0.8739946380697051,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6779932156717297,
            "auditor_fn_violation": 0.007497499230532472,
            "auditor_fp_violation": 0.027506059556786713,
            "ave_precision_score": 0.6688031074949506,
            "fpr": 0.2642543859649123,
            "logloss": 2.0133132454401075,
            "mae": 0.3212208929721562,
            "precision": 0.6314984709480123,
            "recall": 0.9057017543859649
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7052803539640746,
            "auditor_fn_violation": 0.008746291422550796,
            "auditor_fp_violation": 0.035511624136528794,
            "ave_precision_score": 0.6957747795781335,
            "fpr": 0.25686059275521406,
            "logloss": 1.898256777874778,
            "mae": 0.3214785031236084,
            "precision": 0.6558823529411765,
            "recall": 0.8955823293172691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7028738153908444,
            "auditor_fn_violation": 0.0009954986149584488,
            "auditor_fp_violation": 0.0034626038781163542,
            "ave_precision_score": 0.6951544375898756,
            "fpr": 0.4934210526315789,
            "logloss": 0.7810364199633957,
            "mae": 0.44746348363134947,
            "precision": 0.5022123893805309,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.727189891578903,
            "auditor_fn_violation": 0.0012696229484347934,
            "auditor_fp_violation": 0.0005687813460981393,
            "ave_precision_score": 0.7202888451590144,
            "fpr": 0.4522502744237102,
            "logloss": 0.7575101228958521,
            "mae": 0.433723368020534,
            "precision": 0.5462555066079295,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.42985098538291866,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000569886888273315,
            "ave_precision_score": 0.5243624970816267,
            "fpr": 0.4967105263157895,
            "logloss": 0.7495450222120191,
            "mae": 0.4961886465418757,
            "precision": 0.5016501650165016,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.447773545613113,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005289134947361202,
            "ave_precision_score": 0.5703824423384309,
            "fpr": 0.4522502744237102,
            "logloss": 0.7244828552247159,
            "mae": 0.48360293868082677,
            "precision": 0.5472527472527473,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8030964921693181,
            "auditor_fn_violation": 0.019376154201292715,
            "auditor_fp_violation": 0.0231128808864266,
            "ave_precision_score": 0.803574390777311,
            "fpr": 0.13596491228070176,
            "logloss": 0.5547976798247084,
            "mae": 0.36491139890756785,
            "precision": 0.7316017316017316,
            "recall": 0.7412280701754386
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8551633744715084,
            "auditor_fn_violation": 0.017020882652453946,
            "auditor_fp_violation": 0.02471009427417919,
            "ave_precision_score": 0.8556705913390765,
            "fpr": 0.10537870472008781,
            "logloss": 0.5169301903362175,
            "mae": 0.34543142488745626,
            "precision": 0.788546255506608,
            "recall": 0.7188755020080321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7202412450825287,
            "auditor_fn_violation": 0.03440481686672822,
            "auditor_fp_violation": 0.0715027700831025,
            "ave_precision_score": 0.717535690388911,
            "fpr": 0.29276315789473684,
            "logloss": 0.6300444265824182,
            "mae": 0.42132553796022476,
            "precision": 0.588597842835131,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7329022594859158,
            "auditor_fn_violation": 0.03968894237763348,
            "auditor_fp_violation": 0.05816187942367035,
            "ave_precision_score": 0.7307120033889584,
            "fpr": 0.2711306256860593,
            "logloss": 0.6413524073132656,
            "mae": 0.42349620397753696,
            "precision": 0.6122448979591837,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 18998,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8063219576292573,
            "auditor_fn_violation": 0.0004063750384733813,
            "auditor_fp_violation": 0.0032894736842105296,
            "ave_precision_score": 0.8066858633367312,
            "fpr": 0.06359649122807018,
            "logloss": 0.5460901246867597,
            "mae": 0.35702814898257584,
            "precision": 0.8226299694189603,
            "recall": 0.5899122807017544
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8611717700374173,
            "auditor_fn_violation": 0.0016267044026820835,
            "auditor_fp_violation": 0.0058977841448213,
            "ave_precision_score": 0.861433792473649,
            "fpr": 0.038419319429198684,
            "logloss": 0.5372901630939694,
            "mae": 0.3413473531110805,
            "precision": 0.8955223880597015,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.5699133925039201,
            "auditor_fn_violation": 0.013398353339489076,
            "auditor_fp_violation": 0.02384868421052632,
            "ave_precision_score": 0.559601343742858,
            "fpr": 0.125,
            "logloss": 4.2841801597039355,
            "mae": 0.42009156870327424,
            "precision": 0.632258064516129,
            "recall": 0.4298245614035088
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6076031959259027,
            "auditor_fn_violation": 0.023100084200688608,
            "auditor_fp_violation": 0.028167965915644945,
            "ave_precision_score": 0.5968227418201035,
            "fpr": 0.13062568605927552,
            "logloss": 4.525297639814202,
            "mae": 0.4443942850456098,
            "precision": 0.65,
            "recall": 0.44377510040160645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.682086389138402,
            "auditor_fn_violation": 0.01777229532163743,
            "auditor_fp_violation": 0.01959978070175438,
            "ave_precision_score": 0.6717253539888007,
            "fpr": 0.1962719298245614,
            "logloss": 1.8781938226222523,
            "mae": 0.2970647132635592,
            "precision": 0.6780575539568345,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7093565801792718,
            "auditor_fn_violation": 0.013026860460502826,
            "auditor_fp_violation": 0.03272619025470241,
            "ave_precision_score": 0.6982100891835504,
            "fpr": 0.19209659714599342,
            "logloss": 1.8266196269620243,
            "mae": 0.299137882843601,
            "precision": 0.7023809523809523,
            "recall": 0.8293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7629595879631524,
            "auditor_fn_violation": 0.036501615881809786,
            "auditor_fp_violation": 0.09585641735918744,
            "ave_precision_score": 0.7631561550601011,
            "fpr": 0.2730263157894737,
            "logloss": 0.6358892463455326,
            "mae": 0.43726711654872225,
            "precision": 0.6028708133971292,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7672693642007662,
            "auditor_fn_violation": 0.03245473661936439,
            "auditor_fp_violation": 0.09089338539188768,
            "ave_precision_score": 0.7674738449035472,
            "fpr": 0.2601536772777168,
            "logloss": 0.6303345310300733,
            "mae": 0.43008533208482747,
            "precision": 0.6359447004608295,
            "recall": 0.8313253012048193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.724010110631077,
            "auditor_fn_violation": 0.039646814404432136,
            "auditor_fp_violation": 0.07650430901815944,
            "ave_precision_score": 0.7209419251967613,
            "fpr": 0.2817982456140351,
            "logloss": 0.630738453490497,
            "mae": 0.4236973730332561,
            "precision": 0.5914149443561209,
            "recall": 0.8157894736842105
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.729808100886116,
            "auditor_fn_violation": 0.045391224613051555,
            "auditor_fp_violation": 0.07011691911876103,
            "ave_precision_score": 0.7276823202689637,
            "fpr": 0.2645444566410538,
            "logloss": 0.6414750613297213,
            "mae": 0.4255861630203237,
            "precision": 0.610032362459547,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.4662049777680375,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.1094952293013235,
            "ave_precision_score": 0.5443416066539724,
            "fpr": 0.31359649122807015,
            "logloss": 0.6878924157275224,
            "mae": 0.49548834232253985,
            "precision": 0.5394524959742351,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5295991521708442,
            "auditor_fn_violation": 0.09367877657721997,
            "auditor_fp_violation": 0.0970888494935454,
            "ave_precision_score": 0.5895764316094535,
            "fpr": 0.287596048298573,
            "logloss": 0.683286542753728,
            "mae": 0.493223969976936,
            "precision": 0.5874015748031496,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6821041760766802,
            "auditor_fn_violation": 0.01777229532163743,
            "auditor_fp_violation": 0.018582640812557717,
            "ave_precision_score": 0.6717431331158513,
            "fpr": 0.19736842105263158,
            "logloss": 1.8779227956863433,
            "mae": 0.2971663290226709,
            "precision": 0.6768402154398564,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7092525617520151,
            "auditor_fn_violation": 0.013026860460502826,
            "auditor_fp_violation": 0.03272619025470241,
            "ave_precision_score": 0.6981061866182872,
            "fpr": 0.19209659714599342,
            "logloss": 1.8266004902152786,
            "mae": 0.2992741392074624,
            "precision": 0.7023809523809523,
            "recall": 0.8293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6315209757231358,
            "auditor_fn_violation": 0.02215345106186519,
            "auditor_fp_violation": 0.024661434287473073,
            "ave_precision_score": 0.6215367218972174,
            "fpr": 0.1600877192982456,
            "logloss": 2.393212345673728,
            "mae": 0.35881850012507055,
            "precision": 0.665903890160183,
            "recall": 0.6381578947368421
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6600562354904341,
            "auditor_fn_violation": 0.0014151005779429449,
            "auditor_fp_violation": 0.03471160925253095,
            "ave_precision_score": 0.649247586665048,
            "fpr": 0.14818880351262348,
            "logloss": 2.393310821083841,
            "mae": 0.367667783897776,
            "precision": 0.7058823529411765,
            "recall": 0.6506024096385542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8015106205023831,
            "auditor_fn_violation": 0.005756578947368423,
            "auditor_fp_violation": 0.01905153508771929,
            "ave_precision_score": 0.8029225643985822,
            "fpr": 0.3125,
            "logloss": 0.6401542652579216,
            "mae": 0.3781043941914839,
            "precision": 0.5945945945945946,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8713751643248158,
            "auditor_fn_violation": 0.007710314363932129,
            "auditor_fp_violation": 0.027912811666928026,
            "ave_precision_score": 0.8716161350229465,
            "fpr": 0.27771679473106475,
            "logloss": 0.5575455252261305,
            "mae": 0.34794573046667776,
            "precision": 0.6476323119777159,
            "recall": 0.9337349397590361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5362521889878445,
            "auditor_fn_violation": 0.08212863573407202,
            "auditor_fp_violation": 0.10567674669128962,
            "ave_precision_score": 0.5553460184778256,
            "fpr": 0.32127192982456143,
            "logloss": 0.6873237494446028,
            "mae": 0.4947944344593245,
            "precision": 0.5378548895899053,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5990452609134367,
            "auditor_fn_violation": 0.09068105572674892,
            "auditor_fp_violation": 0.09132661604335497,
            "ave_precision_score": 0.6015895951740549,
            "fpr": 0.300768386388584,
            "logloss": 0.6820388328451782,
            "mae": 0.49222943749438264,
            "precision": 0.5791090629800307,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.607917277332982,
            "auditor_fn_violation": 0.01587026777469991,
            "auditor_fp_violation": 0.029576408125577103,
            "ave_precision_score": 0.5974834529803092,
            "fpr": 0.1600877192982456,
            "logloss": 2.6784830875316974,
            "mae": 0.37883464345608137,
            "precision": 0.6507177033492823,
            "recall": 0.5964912280701754
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6488120243546908,
            "auditor_fn_violation": 0.00245989446259242,
            "auditor_fp_violation": 0.03280592595742646,
            "ave_precision_score": 0.6377759607265521,
            "fpr": 0.15148188803512624,
            "logloss": 2.6471026483640365,
            "mae": 0.3826295325036732,
            "precision": 0.6905829596412556,
            "recall": 0.6184738955823293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6283637447453987,
            "auditor_fn_violation": 0.02248768851954448,
            "auditor_fp_violation": 0.024889869959987695,
            "ave_precision_score": 0.6181378231876384,
            "fpr": 0.16557017543859648,
            "logloss": 2.4275081002699666,
            "mae": 0.3611526575877415,
            "precision": 0.6621923937360179,
            "recall": 0.6491228070175439
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6590569140549873,
            "auditor_fn_violation": 0.0026053720921005645,
            "auditor_fp_violation": 0.0327447952520047,
            "ave_precision_score": 0.6482484845859797,
            "fpr": 0.15367727771679474,
            "logloss": 2.3853417644010295,
            "mae": 0.368460140273059,
            "precision": 0.7002141327623126,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6854164086388859,
            "auditor_fn_violation": 0.012792397660818713,
            "auditor_fp_violation": 0.017875692520775633,
            "ave_precision_score": 0.6805034426465184,
            "fpr": 0.23574561403508773,
            "logloss": 1.6099013169276934,
            "mae": 0.3131003073661518,
            "precision": 0.6504065040650406,
            "recall": 0.8771929824561403
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.715925486726972,
            "auditor_fn_violation": 0.0022747411159456713,
            "auditor_fp_violation": 0.03116602833806875,
            "ave_precision_score": 0.7110803354093644,
            "fpr": 0.22941822173435786,
            "logloss": 1.5721094341244788,
            "mae": 0.31109278683521646,
            "precision": 0.6749611197511665,
            "recall": 0.8714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7055018904899999,
            "auditor_fn_violation": 0.08554795706371192,
            "auditor_fp_violation": 0.1027046783625731,
            "ave_precision_score": 0.5386841783978921,
            "fpr": 0.2916666666666667,
            "logloss": 0.6829686878406719,
            "mae": 0.49023568630218506,
            "precision": 0.551433389544688,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7355064977633949,
            "auditor_fn_violation": 0.0948249639612236,
            "auditor_fp_violation": 0.09071796684589482,
            "ave_precision_score": 0.5833103022183639,
            "fpr": 0.2689352360043908,
            "logloss": 0.680917526875481,
            "mae": 0.48915975170391973,
            "precision": 0.5957095709570958,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8012102694244607,
            "auditor_fn_violation": 0.010272391505078488,
            "auditor_fp_violation": 0.004821194983071715,
            "ave_precision_score": 0.8015818246801079,
            "fpr": 0.051535087719298246,
            "logloss": 0.5637802509205379,
            "mae": 0.3607429789395578,
            "precision": 0.8406779661016949,
            "recall": 0.543859649122807
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.864552310286163,
            "auditor_fn_violation": 0.014803450905708455,
            "auditor_fp_violation": 0.004148914398407413,
            "ave_precision_score": 0.8648605992093886,
            "fpr": 0.02854006586169045,
            "logloss": 0.5532738759423872,
            "mae": 0.3428740339231898,
            "precision": 0.9136212624584718,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.46770121458165304,
            "auditor_fn_violation": 0.086413608033241,
            "auditor_fp_violation": 0.10791782086795938,
            "ave_precision_score": 0.5456281818016012,
            "fpr": 0.3092105263157895,
            "logloss": 0.6851145063475783,
            "mae": 0.4915874191935648,
            "precision": 0.5429497568881686,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5302971729060943,
            "auditor_fn_violation": 0.09442820678983772,
            "auditor_fp_violation": 0.09703037664488111,
            "ave_precision_score": 0.5901681289448839,
            "fpr": 0.2854006586169045,
            "logloss": 0.6839075898109349,
            "mae": 0.49125062172944145,
            "precision": 0.5886075949367089,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6720712250150891,
            "auditor_fn_violation": 0.015435037703908897,
            "auditor_fp_violation": 0.02275459756848261,
            "ave_precision_score": 0.6593347184341386,
            "fpr": 0.2225877192982456,
            "logloss": 2.0952882915898696,
            "mae": 0.3099749123256365,
            "precision": 0.6582491582491582,
            "recall": 0.8574561403508771
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7040536021438204,
            "auditor_fn_violation": 0.012167219922500102,
            "auditor_fp_violation": 0.034775397814710174,
            "ave_precision_score": 0.6908976553152313,
            "fpr": 0.20965971459934138,
            "logloss": 2.0044534094604303,
            "mae": 0.30745875994592364,
            "precision": 0.6873977086743044,
            "recall": 0.8433734939759037
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6854164086388859,
            "auditor_fn_violation": 0.012792397660818713,
            "auditor_fp_violation": 0.017875692520775633,
            "ave_precision_score": 0.6805034426465184,
            "fpr": 0.23574561403508773,
            "logloss": 1.6098645887808876,
            "mae": 0.31309657367212096,
            "precision": 0.6504065040650406,
            "recall": 0.8771929824561403
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7159254581857006,
            "auditor_fn_violation": 0.0022747411159456713,
            "auditor_fp_violation": 0.03116602833806875,
            "ave_precision_score": 0.7110843026460926,
            "fpr": 0.22941822173435786,
            "logloss": 1.5720779240919038,
            "mae": 0.3110907694137748,
            "precision": 0.6749611197511665,
            "recall": 0.8714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8024315524104597,
            "auditor_fn_violation": 0.003178862726992921,
            "auditor_fp_violation": 0.00024767236072638105,
            "ave_precision_score": 0.8028655448727774,
            "fpr": 0.09100877192982457,
            "logloss": 0.5455032126437057,
            "mae": 0.3603123924654108,
            "precision": 0.7838541666666666,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8616504344658487,
            "auditor_fn_violation": 0.00490656368613863,
            "auditor_fp_violation": 0.00791509742373945,
            "ave_precision_score": 0.8620050543439899,
            "fpr": 0.0570801317233809,
            "logloss": 0.5111173014734927,
            "mae": 0.3395671022458628,
            "precision": 0.8649350649350649,
            "recall": 0.6686746987951807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6098450462703611,
            "auditor_fn_violation": 0.011835372422283788,
            "auditor_fp_violation": 0.02654662973222531,
            "ave_precision_score": 0.5987877833398231,
            "fpr": 0.18201754385964913,
            "logloss": 2.6826185193712613,
            "mae": 0.37611309601225823,
            "precision": 0.6399132321041214,
            "recall": 0.6469298245614035
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.6624651624727348,
            "auditor_fn_violation": 0.011532408448282712,
            "auditor_fp_violation": 0.03438735072811986,
            "ave_precision_score": 0.649394131766118,
            "fpr": 0.1602634467618002,
            "logloss": 2.640948701877162,
            "mae": 0.35890319398308923,
            "precision": 0.7026476578411406,
            "recall": 0.6927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6847917774477679,
            "auditor_fn_violation": 0.01677679670667898,
            "auditor_fp_violation": 0.02050390504770699,
            "ave_precision_score": 0.6803211329353736,
            "fpr": 0.21162280701754385,
            "logloss": 1.5306468554475097,
            "mae": 0.30612317977151354,
            "precision": 0.6649305555555556,
            "recall": 0.8399122807017544
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7161097392609135,
            "auditor_fn_violation": 0.006116673058865541,
            "auditor_fp_violation": 0.03238066887623159,
            "ave_precision_score": 0.7113152973614523,
            "fpr": 0.2052689352360044,
            "logloss": 1.486115641568247,
            "mae": 0.3073527263980573,
            "precision": 0.6903973509933775,
            "recall": 0.8373493975903614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6222374367027069,
            "auditor_fn_violation": 0.01218403739612189,
            "auditor_fp_violation": 0.030692136041859042,
            "ave_precision_score": 0.6117958712567805,
            "fpr": 0.16228070175438597,
            "logloss": 2.3840161251595906,
            "mae": 0.36238660927467287,
            "precision": 0.662870159453303,
            "recall": 0.6381578947368421
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6585947509174009,
            "auditor_fn_violation": 0.003293084522502751,
            "auditor_fp_violation": 0.0357508312447009,
            "ave_precision_score": 0.6475635381328793,
            "fpr": 0.15477497255762898,
            "logloss": 2.287450644134637,
            "mae": 0.36522971596269577,
            "precision": 0.7019027484143763,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6200236570654073,
            "auditor_fn_violation": 0.015682710064635282,
            "auditor_fp_violation": 0.026551438904278243,
            "ave_precision_score": 0.6095794641225845,
            "fpr": 0.15899122807017543,
            "logloss": 2.6518959282297705,
            "mae": 0.36899487160944644,
            "precision": 0.6580188679245284,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.6537047637292841,
            "auditor_fn_violation": 0.0024312397779923207,
            "auditor_fp_violation": 0.033582020130607085,
            "ave_precision_score": 0.642674491217637,
            "fpr": 0.145993413830955,
            "logloss": 2.6395937808548275,
            "mae": 0.375967495718362,
            "precision": 0.7004504504504504,
            "recall": 0.6244979919678715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6759775460992957,
            "auditor_fn_violation": 0.014256790550938751,
            "auditor_fp_violation": 0.021460930286241915,
            "ave_precision_score": 0.6633873067174678,
            "fpr": 0.22039473684210525,
            "logloss": 2.0602964652066516,
            "mae": 0.3061599407142391,
            "precision": 0.6593220338983051,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7063723072322239,
            "auditor_fn_violation": 0.01220248722662329,
            "auditor_fp_violation": 0.03447240214435883,
            "ave_precision_score": 0.693201920408135,
            "fpr": 0.2052689352360044,
            "logloss": 1.9900447664343062,
            "mae": 0.3041245908059038,
            "precision": 0.6929392446633826,
            "recall": 0.8473895582329317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8135097918832619,
            "auditor_fn_violation": 0.014754539858417978,
            "auditor_fp_violation": 0.00766582025238535,
            "ave_precision_score": 0.8138122918999042,
            "fpr": 0.10087719298245613,
            "logloss": 0.5398328260418171,
            "mae": 0.3692619844049771,
            "precision": 0.7628865979381443,
            "recall": 0.6491228070175439
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8515109044270113,
            "auditor_fn_violation": 0.016835729305807214,
            "auditor_fp_violation": 0.01492918140669727,
            "ave_precision_score": 0.8517966963366764,
            "fpr": 0.07244785949506037,
            "logloss": 0.522685250803905,
            "mae": 0.3550116493193889,
            "precision": 0.837037037037037,
            "recall": 0.6807228915662651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.5915235937687897,
            "auditor_fn_violation": 0.005780624807633121,
            "auditor_fp_violation": 0.02961969067405356,
            "ave_precision_score": 0.5808239859735305,
            "fpr": 0.16447368421052633,
            "logloss": 3.0824631958132094,
            "mae": 0.3947835514148105,
            "precision": 0.6341463414634146,
            "recall": 0.5701754385964912
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6470294928145728,
            "auditor_fn_violation": 0.006374565220266365,
            "auditor_fp_violation": 0.03404714506316397,
            "ave_precision_score": 0.6343021606751864,
            "fpr": 0.14489571899012074,
            "logloss": 3.0759580901343253,
            "mae": 0.3805530786948886,
            "precision": 0.7,
            "recall": 0.6184738955823293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 18998,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7319502021988409,
            "auditor_fn_violation": 0.05380020775623269,
            "auditor_fp_violation": 0.10485918744228993,
            "ave_precision_score": 0.73244583422733,
            "fpr": 0.2532894736842105,
            "logloss": 0.6604937797734354,
            "mae": 0.45079522726959304,
            "precision": 0.5989583333333334,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7491845285030098,
            "auditor_fn_violation": 0.05657977684613316,
            "auditor_fp_violation": 0.09882708781292941,
            "ave_precision_score": 0.749538272888531,
            "fpr": 0.24368825466520308,
            "logloss": 0.6503792241907637,
            "mae": 0.4419014863465411,
            "precision": 0.6179001721170396,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6764287363436062,
            "auditor_fn_violation": 0.010301246537396122,
            "auditor_fp_violation": 0.016707063711911364,
            "ave_precision_score": 0.6677838768427643,
            "fpr": 0.21710526315789475,
            "logloss": 1.8289113486886417,
            "mae": 0.30532706467732956,
            "precision": 0.6632653061224489,
            "recall": 0.8552631578947368
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7045104470157534,
            "auditor_fn_violation": 0.0006744871913559851,
            "auditor_fp_violation": 0.02731213603974027,
            "ave_precision_score": 0.6949842391194738,
            "fpr": 0.20417124039517015,
            "logloss": 1.7582418616375564,
            "mae": 0.31235695892169657,
            "precision": 0.693069306930693,
            "recall": 0.8433734939759037
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6074197761109545,
            "auditor_fn_violation": 0.013908125577100644,
            "auditor_fp_violation": 0.03149526777469992,
            "ave_precision_score": 0.5969864536764913,
            "fpr": 0.16447368421052633,
            "logloss": 2.6909964480887796,
            "mae": 0.3788195301183768,
            "precision": 0.6411483253588517,
            "recall": 0.5877192982456141
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.648715767926335,
            "auditor_fn_violation": 0.0027640749606549176,
            "auditor_fp_violation": 0.033207262327804105,
            "ave_precision_score": 0.6376890675011694,
            "fpr": 0.15477497255762898,
            "logloss": 2.66224066962052,
            "mae": 0.38236021149789423,
            "precision": 0.6866666666666666,
            "recall": 0.6204819277108434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6657763887284635,
            "auditor_fn_violation": 0.005208333333333335,
            "auditor_fp_violation": 0.020126385041551263,
            "ave_precision_score": 0.6515654221078813,
            "fpr": 0.2642543859649123,
            "logloss": 2.650130257921379,
            "mae": 0.3349206731244532,
            "precision": 0.6234375,
            "recall": 0.875
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7078550027964879,
            "auditor_fn_violation": 0.004787536534722866,
            "auditor_fp_violation": 0.027724103837147806,
            "ave_precision_score": 0.6933980907739945,
            "fpr": 0.2414928649835346,
            "logloss": 2.3201705525662,
            "mae": 0.3160396678991001,
            "precision": 0.6646341463414634,
            "recall": 0.8755020080321285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6298266803489275,
            "auditor_fn_violation": 0.024300746383502627,
            "auditor_fp_violation": 0.025757925515543248,
            "ave_precision_score": 0.6193850498531641,
            "fpr": 0.1600877192982456,
            "logloss": 2.4815366502840424,
            "mae": 0.3586609797596501,
            "precision": 0.664367816091954,
            "recall": 0.6337719298245614
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.659952769136275,
            "auditor_fn_violation": 0.0014724099471431298,
            "auditor_fp_violation": 0.0335315208522152,
            "ave_precision_score": 0.6489193645551432,
            "fpr": 0.15148188803512624,
            "logloss": 2.423364319283584,
            "mae": 0.36614378133034015,
            "precision": 0.7006507592190889,
            "recall": 0.6485943775100401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6812106615886357,
            "auditor_fn_violation": 0.019248711141889814,
            "auditor_fp_violation": 0.018582640812557717,
            "ave_precision_score": 0.6703699103870936,
            "fpr": 0.19736842105263158,
            "logloss": 1.9090058113855337,
            "mae": 0.29789568554367596,
            "precision": 0.6768402154398564,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7075510514468253,
            "auditor_fn_violation": 0.014071654345152293,
            "auditor_fp_violation": 0.03246040457895562,
            "ave_precision_score": 0.6956598234713285,
            "fpr": 0.1942919868276619,
            "logloss": 1.8958897858859274,
            "mae": 0.299520759127983,
            "precision": 0.6994906621392191,
            "recall": 0.8273092369477911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.804483595831602,
            "auditor_fn_violation": 0.003325542474607574,
            "auditor_fp_violation": 0.0006877116035703321,
            "ave_precision_score": 0.8048804712225527,
            "fpr": 0.08662280701754387,
            "logloss": 0.5432496295643302,
            "mae": 0.3608936518185625,
            "precision": 0.7864864864864864,
            "recall": 0.6381578947368421
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8607766553602325,
            "auditor_fn_violation": 0.0093502440056604,
            "auditor_fp_violation": 0.006902453999144171,
            "ave_precision_score": 0.8611014643391409,
            "fpr": 0.05378704720087816,
            "logloss": 0.5167961429823151,
            "mae": 0.34116592140956226,
            "precision": 0.8696808510638298,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8152927903224776,
            "auditor_fn_violation": 0.007189712219144356,
            "auditor_fp_violation": 0.004607186826715916,
            "ave_precision_score": 0.8155923472049886,
            "fpr": 0.08442982456140351,
            "logloss": 0.538365829054971,
            "mae": 0.3663548295194152,
            "precision": 0.7896174863387978,
            "recall": 0.6337719298245614
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8501593052995282,
            "auditor_fn_violation": 0.008556729662888665,
            "auditor_fp_violation": 0.008712454450979823,
            "ave_precision_score": 0.8504578756775265,
            "fpr": 0.050493962678375415,
            "logloss": 0.5336370755689203,
            "mae": 0.35421817640722325,
            "precision": 0.8743169398907104,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6254004477885986,
            "auditor_fn_violation": 0.008937846260387815,
            "auditor_fp_violation": 0.027580601723607268,
            "ave_precision_score": 0.6149814229246819,
            "fpr": 0.17653508771929824,
            "logloss": 2.517184196504192,
            "mae": 0.3654994972341847,
            "precision": 0.6438053097345132,
            "recall": 0.6381578947368421
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.660704035781128,
            "auditor_fn_violation": 0.0003570814542472952,
            "auditor_fp_violation": 0.03171886254362208,
            "ave_precision_score": 0.6496681518411526,
            "fpr": 0.150384193194292,
            "logloss": 2.4252053422785824,
            "mae": 0.366682710799835,
            "precision": 0.7066381156316917,
            "recall": 0.6626506024096386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6716574650439432,
            "auditor_fn_violation": 0.015625,
            "auditor_fp_violation": 0.02165810634041244,
            "ave_precision_score": 0.6589208405678507,
            "fpr": 0.2225877192982456,
            "logloss": 2.106256165905272,
            "mae": 0.3095621699483987,
            "precision": 0.657672849915683,
            "recall": 0.8552631578947368
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7035632826402548,
            "auditor_fn_violation": 0.012705046310378729,
            "auditor_fp_violation": 0.035910302650148974,
            "ave_precision_score": 0.6903968670194888,
            "fpr": 0.21075740944017562,
            "logloss": 2.0179769224575272,
            "mae": 0.30680466715210847,
            "precision": 0.6872964169381107,
            "recall": 0.8473895582329317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7824463799825129,
            "auditor_fn_violation": 0.012575984918436442,
            "auditor_fp_violation": 0.04602377654662974,
            "ave_precision_score": 0.7220605556393354,
            "fpr": 0.25219298245614036,
            "logloss": 3.279799131273256,
            "mae": 0.3417653815796305,
            "precision": 0.6400625978090767,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8064604505867589,
            "auditor_fn_violation": 0.025670188988665976,
            "auditor_fp_violation": 0.040346265578362926,
            "ave_precision_score": 0.7544585436547466,
            "fpr": 0.2217343578485181,
            "logloss": 2.974995369702896,
            "mae": 0.32866684587429046,
            "precision": 0.6813880126182965,
            "recall": 0.8674698795180723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7965383837768653,
            "auditor_fn_violation": 0.0033207333025546334,
            "auditor_fp_violation": 0.021511426592797797,
            "ave_precision_score": 0.7979416826398387,
            "fpr": 0.3059210526315789,
            "logloss": 0.6466426177871554,
            "mae": 0.3804071502425103,
            "precision": 0.596820809248555,
            "recall": 0.9057017543859649
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8692826127774481,
            "auditor_fn_violation": 0.009010796203474714,
            "auditor_fp_violation": 0.02332269304678094,
            "ave_precision_score": 0.8695030832933947,
            "fpr": 0.278814489571899,
            "logloss": 0.5608107686593957,
            "mae": 0.3492749455281657,
            "precision": 0.6447552447552447,
            "recall": 0.9257028112449799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.684738735983408,
            "auditor_fn_violation": 0.01677679670667898,
            "auditor_fp_violation": 0.02050390504770699,
            "ave_precision_score": 0.6802681513227854,
            "fpr": 0.21162280701754385,
            "logloss": 1.531211136175831,
            "mae": 0.30622120458100777,
            "precision": 0.6649305555555556,
            "recall": 0.8399122807017544
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.715936354806847,
            "auditor_fn_violation": 0.006116673058865541,
            "auditor_fp_violation": 0.03238066887623159,
            "ave_precision_score": 0.7111421879276586,
            "fpr": 0.2052689352360044,
            "logloss": 1.4871233903629242,
            "mae": 0.3074792787634981,
            "precision": 0.6903973509933775,
            "recall": 0.8373493975903614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6802917849620488,
            "auditor_fn_violation": 0.01715191212680825,
            "auditor_fp_violation": 0.02100405894121269,
            "ave_precision_score": 0.6693098066750222,
            "fpr": 0.19846491228070176,
            "logloss": 1.9401440505273797,
            "mae": 0.2993200257937192,
            "precision": 0.6767857142857143,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7050155322855204,
            "auditor_fn_violation": 0.009363469244706605,
            "auditor_fp_violation": 0.03244179958165335,
            "ave_precision_score": 0.6929528273535596,
            "fpr": 0.19319429198682767,
            "logloss": 1.9339287765072881,
            "mae": 0.30083208414764206,
            "precision": 0.7016949152542373,
            "recall": 0.8313253012048193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6125405124760878,
            "auditor_fn_violation": 0.008824830717143742,
            "auditor_fp_violation": 0.025623268698060944,
            "ave_precision_score": 0.6023246073336788,
            "fpr": 0.1600877192982456,
            "logloss": 2.778861642352495,
            "mae": 0.3824201309509959,
            "precision": 0.6421568627450981,
            "recall": 0.5745614035087719
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6525579429696026,
            "auditor_fn_violation": 0.007948368666763654,
            "auditor_fp_violation": 0.03000986064857022,
            "ave_precision_score": 0.6415253058601104,
            "fpr": 0.145993413830955,
            "logloss": 2.7941733025678226,
            "mae": 0.3845053298489897,
            "precision": 0.6928406466512702,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.671701606493478,
            "auditor_fn_violation": 0.016630116959064325,
            "auditor_fp_violation": 0.022593490304709144,
            "ave_precision_score": 0.6595392459695082,
            "fpr": 0.22149122807017543,
            "logloss": 2.0853855573072404,
            "mae": 0.3093699535388075,
            "precision": 0.6576271186440678,
            "recall": 0.8508771929824561
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7042695987019686,
            "auditor_fn_violation": 0.012506667724685793,
            "auditor_fp_violation": 0.03303184378181123,
            "ave_precision_score": 0.6911067371434277,
            "fpr": 0.20856201975850713,
            "logloss": 2.0163434574625585,
            "mae": 0.3061676402069948,
            "precision": 0.6905537459283387,
            "recall": 0.8514056224899599
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.5921895202293569,
            "auditor_fn_violation": 0.008036126500461684,
            "auditor_fp_violation": 0.03153374115112342,
            "ave_precision_score": 0.5814889745501248,
            "fpr": 0.15899122807017543,
            "logloss": 3.172861386207713,
            "mae": 0.39433631779615774,
            "precision": 0.631979695431472,
            "recall": 0.5460526315789473
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.6469177082705058,
            "auditor_fn_violation": 0.010681584736310793,
            "auditor_fp_violation": 0.03967382781872354,
            "ave_precision_score": 0.6342059864579754,
            "fpr": 0.12952799121844127,
            "logloss": 3.2005157719848807,
            "mae": 0.38197415456609013,
            "precision": 0.7170263788968825,
            "recall": 0.6004016064257028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8051754286922168,
            "auditor_fn_violation": 0.014403470298553402,
            "auditor_fp_violation": 0.0193136349646045,
            "ave_precision_score": 0.8056545785550917,
            "fpr": 0.18640350877192982,
            "logloss": 0.7916206697828029,
            "mae": 0.2873244899149623,
            "precision": 0.6875,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8240759348075779,
            "auditor_fn_violation": 0.011926961413160875,
            "auditor_fp_violation": 0.026995851085601593,
            "ave_precision_score": 0.8246484037859474,
            "fpr": 0.1668496158068057,
            "logloss": 0.8407833920493187,
            "mae": 0.2877649736497154,
            "precision": 0.7290552584670231,
            "recall": 0.821285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8018010312881823,
            "auditor_fn_violation": 0.01871248845798708,
            "auditor_fp_violation": 0.018120960295475535,
            "ave_precision_score": 0.8022712423636611,
            "fpr": 0.12828947368421054,
            "logloss": 0.5544827991507806,
            "mae": 0.3646295272679836,
            "precision": 0.738255033557047,
            "recall": 0.7236842105263158
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8545197782384221,
            "auditor_fn_violation": 0.016425746895375137,
            "auditor_fp_violation": 0.01800697953184511,
            "ave_precision_score": 0.855017573860731,
            "fpr": 0.09110867178924259,
            "logloss": 0.5190430266018067,
            "mae": 0.3454088852342124,
            "precision": 0.8100686498855835,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6725349216591905,
            "auditor_fn_violation": 0.015384541397353034,
            "auditor_fp_violation": 0.020364439058171757,
            "ave_precision_score": 0.659797810955558,
            "fpr": 0.22039473684210525,
            "logloss": 2.098175304955842,
            "mae": 0.30838065902726514,
            "precision": 0.6593220338983051,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7042427750908699,
            "auditor_fn_violation": 0.007776440559163108,
            "auditor_fp_violation": 0.03337470730352458,
            "ave_precision_score": 0.6910772656711259,
            "fpr": 0.2052689352360044,
            "logloss": 2.0089949282938244,
            "mae": 0.30692638556028684,
            "precision": 0.6903973509933775,
            "recall": 0.8373493975903614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.623769205074268,
            "auditor_fn_violation": 0.008372768544167436,
            "auditor_fp_violation": 0.029232552323791943,
            "ave_precision_score": 0.6133193936067635,
            "fpr": 0.16337719298245615,
            "logloss": 2.367489530609264,
            "mae": 0.36096936557362275,
            "precision": 0.6666666666666666,
            "recall": 0.6535087719298246
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6597704196663925,
            "auditor_fn_violation": 0.0035862439880267522,
            "auditor_fp_violation": 0.03538670486892779,
            "ave_precision_score": 0.6487381878945424,
            "fpr": 0.15367727771679474,
            "logloss": 2.2665105041205784,
            "mae": 0.3636631378999722,
            "precision": 0.7052631578947368,
            "recall": 0.6726907630522089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.609842598752072,
            "auditor_fn_violation": 0.011835372422283788,
            "auditor_fp_violation": 0.02654662973222531,
            "ave_precision_score": 0.5987853366208143,
            "fpr": 0.18201754385964913,
            "logloss": 2.682664162366012,
            "mae": 0.376116277271965,
            "precision": 0.6399132321041214,
            "recall": 0.6469298245614035
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.6624547389812976,
            "auditor_fn_violation": 0.011532408448282712,
            "auditor_fp_violation": 0.03438735072811986,
            "ave_precision_score": 0.649383719757288,
            "fpr": 0.1602634467618002,
            "logloss": 2.641002212300952,
            "mae": 0.35890709983976415,
            "precision": 0.7026476578411406,
            "recall": 0.6927710843373494
        }
    }
]