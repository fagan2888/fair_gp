[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8042482574445138,
            "auditor_fn_violation": 0.008491538096801265,
            "auditor_fp_violation": 0.0030096267350510847,
            "ave_precision_score": 0.8049490342016684,
            "fpr": 0.049342105263157895,
            "logloss": 1.124405589261278,
            "mae": 0.32694061594219426,
            "precision": 0.845360824742268,
            "recall": 0.5114345114345115
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7708512666086211,
            "auditor_fn_violation": 0.008092308477778065,
            "auditor_fp_violation": 0.006608724418447289,
            "ave_precision_score": 0.7712867446287315,
            "fpr": 0.06256860592755215,
            "logloss": 1.1770429696739557,
            "mae": 0.33498454783260817,
            "precision": 0.803448275862069,
            "recall": 0.492600422832981
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8210723687449538,
            "auditor_fn_violation": 0.012369150527045264,
            "auditor_fp_violation": 0.0089474701835796,
            "ave_precision_score": 0.8224353215337767,
            "fpr": 0.06798245614035088,
            "logloss": 0.9946943435586226,
            "mae": 0.2988634192372229,
            "precision": 0.8176470588235294,
            "recall": 0.577962577962578
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8121674377225678,
            "auditor_fn_violation": 0.013016850660125366,
            "auditor_fp_violation": 0.010255176458204899,
            "ave_precision_score": 0.8124683587228831,
            "fpr": 0.07903402854006586,
            "logloss": 0.9648437215499879,
            "mae": 0.30749151412814013,
            "precision": 0.7931034482758621,
            "recall": 0.5835095137420718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8530152170041094,
            "auditor_fn_violation": 0.01589114418061787,
            "auditor_fp_violation": 0.013129910041926162,
            "ave_precision_score": 0.8533109612439539,
            "fpr": 0.08223684210526316,
            "logloss": 0.6993737660070446,
            "mae": 0.2693719367370323,
            "precision": 0.8192771084337349,
            "recall": 0.7068607068607069
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.827012952135449,
            "auditor_fn_violation": 0.015653174844454557,
            "auditor_fp_violation": 0.012854056709221146,
            "ave_precision_score": 0.8273889748671858,
            "fpr": 0.09330406147091108,
            "logloss": 0.7352125350091623,
            "mae": 0.28064522481817655,
            "precision": 0.7916666666666666,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8646714669669642,
            "auditor_fn_violation": 0.01776726118831383,
            "auditor_fp_violation": 0.019556213619896613,
            "ave_precision_score": 0.8650447968871257,
            "fpr": 0.08881578947368421,
            "logloss": 0.5561887799518968,
            "mae": 0.273125402604133,
            "precision": 0.8071428571428572,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8481227008020541,
            "auditor_fn_violation": 0.01862832238345985,
            "auditor_fp_violation": 0.017949064954463214,
            "ave_precision_score": 0.8483593471066544,
            "fpr": 0.10318331503841932,
            "logloss": 0.5643377475021597,
            "mae": 0.2849505572206914,
            "precision": 0.7819025522041764,
            "recall": 0.7124735729386892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 24481,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8043150680759421,
            "auditor_fn_violation": 0.010157931210562793,
            "auditor_fp_violation": 0.00399672324663166,
            "ave_precision_score": 0.8058280281255936,
            "fpr": 0.047149122807017545,
            "logloss": 1.0692364206651943,
            "mae": 0.3254811189540292,
            "precision": 0.8506944444444444,
            "recall": 0.5093555093555093
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7747041768830094,
            "auditor_fn_violation": 0.010252887540815459,
            "auditor_fp_violation": 0.011753855715782245,
            "ave_precision_score": 0.7751445123333705,
            "fpr": 0.06147091108671789,
            "logloss": 1.126900477981657,
            "mae": 0.33389713008752325,
            "precision": 0.8075601374570447,
            "recall": 0.49682875264270615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8442241861841253,
            "auditor_fn_violation": 0.008147317357843676,
            "auditor_fp_violation": 0.01938321732405259,
            "ave_precision_score": 0.8449380021277565,
            "fpr": 0.13596491228070176,
            "logloss": 0.7552879460246986,
            "mae": 0.2630268288968056,
            "precision": 0.7544554455445545,
            "recall": 0.7920997920997921
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8217536123823797,
            "auditor_fn_violation": 0.010378205767887439,
            "auditor_fp_violation": 0.021660676961941572,
            "ave_precision_score": 0.8221110452653253,
            "fpr": 0.15477497255762898,
            "logloss": 0.8029250990002702,
            "mae": 0.2723270329919893,
            "precision": 0.7283236994219653,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8338604991328531,
            "auditor_fn_violation": 0.011555330634278006,
            "auditor_fp_violation": 0.02074683518541133,
            "ave_precision_score": 0.8342009639986236,
            "fpr": 0.11732456140350878,
            "logloss": 0.7866923738449417,
            "mae": 0.27364362243892326,
            "precision": 0.7723404255319148,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8095423752916608,
            "auditor_fn_violation": 0.015026583709094632,
            "auditor_fp_violation": 0.01839516011808991,
            "ave_precision_score": 0.810087198847518,
            "fpr": 0.13611416026344675,
            "logloss": 0.8357476898194505,
            "mae": 0.28294600294656047,
            "precision": 0.7405857740585774,
            "recall": 0.7484143763213531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.860379195290872,
            "auditor_fn_violation": 0.007607050370208272,
            "auditor_fp_violation": 0.02023293442422763,
            "ave_precision_score": 0.86157873143718,
            "fpr": 0.12280701754385964,
            "logloss": 0.5563047143272827,
            "mae": 0.26107473123086794,
            "precision": 0.7764471057884231,
            "recall": 0.8087318087318087
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8441152958873233,
            "auditor_fn_violation": 0.009561316584010786,
            "auditor_fp_violation": 0.018420221644136352,
            "ave_precision_score": 0.8443587693416864,
            "fpr": 0.14270032930845225,
            "logloss": 0.5798386121287372,
            "mae": 0.2759079885408608,
            "precision": 0.7450980392156863,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.8271193702043669,
            "auditor_fn_violation": 0.006517397964766398,
            "auditor_fp_violation": 0.0039432979199739504,
            "ave_precision_score": 0.8275109667087452,
            "fpr": 0.020833333333333332,
            "logloss": 0.7768204416664158,
            "mae": 0.3700323127345575,
            "precision": 0.9086538461538461,
            "recall": 0.39293139293139295
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7869197992911696,
            "auditor_fn_violation": 0.01670909694293148,
            "auditor_fp_violation": 0.0027367186442716876,
            "ave_precision_score": 0.787572464331922,
            "fpr": 0.03293084522502744,
            "logloss": 0.770552532150671,
            "mae": 0.38266585400263314,
            "precision": 0.8578199052132701,
            "recall": 0.38266384778012685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8261355372899264,
            "auditor_fn_violation": 0.02336369770580297,
            "auditor_fp_violation": 0.03339082916106974,
            "ave_precision_score": 0.8264628790245094,
            "fpr": 0.19956140350877194,
            "logloss": 1.0753941775527665,
            "mae": 0.2880502524713444,
            "precision": 0.6910016977928692,
            "recall": 0.8461538461538461
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7887480964720355,
            "auditor_fn_violation": 0.02743540889712998,
            "auditor_fp_violation": 0.03662491416427329,
            "ave_precision_score": 0.7910142635761408,
            "fpr": 0.20965971459934138,
            "logloss": 1.204667535104387,
            "mae": 0.2975028024172737,
            "precision": 0.6789915966386555,
            "recall": 0.854122621564482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7906189451572198,
            "auditor_fn_violation": 0.007483951562898934,
            "auditor_fp_violation": 0.00373977286603981,
            "ave_precision_score": 0.7910125483643922,
            "fpr": 0.01206140350877193,
            "logloss": 1.1859453421344657,
            "mae": 0.4143928163525848,
            "precision": 0.907563025210084,
            "recall": 0.22453222453222454
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7277266405609655,
            "auditor_fn_violation": 0.006052406225995191,
            "auditor_fp_violation": 0.004205324070593306,
            "ave_precision_score": 0.7292176756311332,
            "fpr": 0.021953896816684963,
            "logloss": 1.1787819537921382,
            "mae": 0.4308839642878334,
            "precision": 0.8230088495575221,
            "recall": 0.19661733615221988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8473164577045986,
            "auditor_fn_violation": 0.0038046649888755155,
            "auditor_fp_violation": 0.016462632800097698,
            "ave_precision_score": 0.8475836587021885,
            "fpr": 0.3267543859649123,
            "logloss": 1.456921995688341,
            "mae": 0.34147761866070053,
            "precision": 0.6104575163398693,
            "recall": 0.9708939708939709
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.8212930911975193,
            "auditor_fn_violation": 0.005207668547213643,
            "auditor_fp_violation": 0.02626447929667334,
            "ave_precision_score": 0.8215921780470392,
            "fpr": 0.32711306256860595,
            "logloss": 1.5342580797539442,
            "mae": 0.34717603508191497,
            "precision": 0.6026666666666667,
            "recall": 0.9556025369978859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8440098600486521,
            "auditor_fn_violation": 0.006704325783273155,
            "auditor_fp_violation": 0.021110636219318607,
            "ave_precision_score": 0.8442077190043464,
            "fpr": 0.13596491228070176,
            "logloss": 0.7806159280089963,
            "mae": 0.2624221559994791,
            "precision": 0.753968253968254,
            "recall": 0.7900207900207901
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8221161778155108,
            "auditor_fn_violation": 0.010030099581576371,
            "auditor_fp_violation": 0.019202141256785415,
            "ave_precision_score": 0.8224711402453423,
            "fpr": 0.15806805708013172,
            "logloss": 0.8254887998891125,
            "mae": 0.26965602929162164,
            "precision": 0.7262357414448669,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8230416522187903,
            "auditor_fn_violation": 0.034880275011853965,
            "auditor_fp_violation": 0.03211879757398136,
            "ave_precision_score": 0.8235306365939146,
            "fpr": 0.17105263157894737,
            "logloss": 0.6390064214524978,
            "mae": 0.3348435358844315,
            "precision": 0.7148080438756855,
            "recall": 0.8128898128898129
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7834086434972087,
            "auditor_fn_violation": 0.03376862078008276,
            "auditor_fp_violation": 0.035005939581673015,
            "ave_precision_score": 0.7838351493204185,
            "fpr": 0.21075740944017562,
            "logloss": 0.6634820282970223,
            "mae": 0.3591794487984765,
            "precision": 0.6689655172413793,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8517007363323864,
            "auditor_fn_violation": 0.007034868876974143,
            "auditor_fp_violation": 0.01902959254284203,
            "ave_precision_score": 0.8521424881752226,
            "fpr": 0.11842105263157894,
            "logloss": 0.7033084896379204,
            "mae": 0.261652202834989,
            "precision": 0.7763975155279503,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8259716278975475,
            "auditor_fn_violation": 0.009830518701424687,
            "auditor_fp_violation": 0.017297465277255664,
            "ave_precision_score": 0.8263545791082384,
            "fpr": 0.13611416026344675,
            "logloss": 0.7439892638314815,
            "mae": 0.27001717597939867,
            "precision": 0.75,
            "recall": 0.7864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8088348444077262,
            "auditor_fn_violation": 0.018038534485902914,
            "auditor_fp_violation": 0.005741950584116907,
            "ave_precision_score": 0.8092885125906177,
            "fpr": 0.03618421052631579,
            "logloss": 1.2575613157656915,
            "mae": 0.3466579662277264,
            "precision": 0.8613445378151261,
            "recall": 0.4261954261954262
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7671260074484083,
            "auditor_fn_violation": 0.009375659951311541,
            "auditor_fp_violation": 0.006861845831516373,
            "ave_precision_score": 0.7675712378108109,
            "fpr": 0.05159165751920966,
            "logloss": 1.289929468437078,
            "mae": 0.3565523960788921,
            "precision": 0.8049792531120332,
            "recall": 0.41014799154334036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8472435390834381,
            "auditor_fn_violation": 0.00960626618521356,
            "auditor_fp_violation": 0.0196121830097285,
            "ave_precision_score": 0.8477816805149487,
            "fpr": 0.09758771929824561,
            "logloss": 0.7283079731089039,
            "mae": 0.2665039240441622,
            "precision": 0.7968036529680366,
            "recall": 0.7255717255717256
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8220402137844822,
            "auditor_fn_violation": 0.01441855823700462,
            "auditor_fp_violation": 0.014177305284473378,
            "ave_precision_score": 0.8224311724486232,
            "fpr": 0.10647639956092206,
            "logloss": 0.7670900872925854,
            "mae": 0.2770398397312489,
            "precision": 0.7780320366132724,
            "recall": 0.718816067653277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8062502545137538,
            "auditor_fn_violation": 0.015337199547725867,
            "auditor_fp_violation": 0.028493507550779503,
            "ave_precision_score": 0.8068408467386523,
            "fpr": 0.10197368421052631,
            "logloss": 0.562915209264798,
            "mae": 0.3226136231915964,
            "precision": 0.7857142857142857,
            "recall": 0.7089397089397089
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7716356078096716,
            "auditor_fn_violation": 0.012965795086133073,
            "auditor_fp_violation": 0.028600213524201914,
            "ave_precision_score": 0.773334257166261,
            "fpr": 0.11855104281009879,
            "logloss": 0.587766118019402,
            "mae": 0.3372497394199278,
            "precision": 0.7505773672055427,
            "recall": 0.6871035940803383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8091153521207118,
            "auditor_fn_violation": 0.01576804537330853,
            "auditor_fp_violation": 0.006014165343753816,
            "ave_precision_score": 0.8095521288480632,
            "fpr": 0.03289473684210526,
            "logloss": 1.326092088275847,
            "mae": 0.3519748580949716,
            "precision": 0.8678414096916299,
            "recall": 0.4095634095634096
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7662104871349136,
            "auditor_fn_violation": 0.0058760324249309106,
            "auditor_fp_violation": 0.005909507841751502,
            "ave_precision_score": 0.7666585304083452,
            "fpr": 0.04720087815587267,
            "logloss": 1.355360830177437,
            "mae": 0.36192482332927556,
            "precision": 0.8114035087719298,
            "recall": 0.39112050739957716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 24481,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8339032983472429,
            "auditor_fn_violation": 0.013410931174089074,
            "auditor_fp_violation": 0.004177351731998208,
            "ave_precision_score": 0.8342517503217666,
            "fpr": 0.03508771929824561,
            "logloss": 0.8750556298230594,
            "mae": 0.33601159311405027,
            "precision": 0.8740157480314961,
            "recall": 0.46153846153846156
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8121205874158746,
            "auditor_fn_violation": 0.00632857046713531,
            "auditor_fp_violation": 0.009763970547694591,
            "ave_precision_score": 0.8124433605669736,
            "fpr": 0.04061470911086718,
            "logloss": 0.8545123932774581,
            "mae": 0.34858345659739265,
            "precision": 0.852,
            "recall": 0.4503171247357294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.8646543204150763,
            "auditor_fn_violation": 0.0029908450961082544,
            "auditor_fp_violation": 0.021008873692351538,
            "ave_precision_score": 0.8653874448189259,
            "fpr": 0.4276315789473684,
            "logloss": 1.2277311525241916,
            "mae": 0.40884003692193355,
            "precision": 0.5501730103806228,
            "recall": 0.9916839916839917
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.8560516757743584,
            "auditor_fn_violation": 0.001429556071784137,
            "auditor_fp_violation": 0.014134700690194431,
            "ave_precision_score": 0.8562632616642315,
            "fpr": 0.45115257958287597,
            "logloss": 1.3598530563474502,
            "mae": 0.429982710808909,
            "precision": 0.5340136054421769,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8361912344543799,
            "auditor_fn_violation": 0.007789418973629516,
            "auditor_fp_violation": 0.01097508853339846,
            "ave_precision_score": 0.8365485723181834,
            "fpr": 0.04824561403508772,
            "logloss": 1.0433031800056274,
            "mae": 0.31086579260764696,
            "precision": 0.8508474576271187,
            "recall": 0.5218295218295218
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8101103087392587,
            "auditor_fn_violation": 0.008637674836332094,
            "auditor_fp_violation": 0.010956899187505325,
            "ave_precision_score": 0.8104307545026936,
            "fpr": 0.0570801317233809,
            "logloss": 1.0503002643860857,
            "mae": 0.32570975963393206,
            "precision": 0.818815331010453,
            "recall": 0.49682875264270615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8422654334732298,
            "auditor_fn_violation": 0.013971714629609373,
            "auditor_fp_violation": 0.025567834900476254,
            "ave_precision_score": 0.8429965969218557,
            "fpr": 0.11293859649122807,
            "logloss": 0.7774366779118957,
            "mae": 0.2580769908675013,
            "precision": 0.783157894736842,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8209338094283092,
            "auditor_fn_violation": 0.021561697180107826,
            "auditor_fp_violation": 0.018164594078462628,
            "ave_precision_score": 0.8213048151284923,
            "fpr": 0.1350164654226125,
            "logloss": 0.8252726884763015,
            "mae": 0.27415195614067855,
            "precision": 0.7448132780082988,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.731252635021152,
            "auditor_fn_violation": 0.019328792355108145,
            "auditor_fp_violation": 0.0059352993853543385,
            "ave_precision_score": 0.7330012907738704,
            "fpr": 0.01644736842105263,
            "logloss": 1.4517291060720043,
            "mae": 0.46185345516667975,
            "precision": 0.7727272727272727,
            "recall": 0.10602910602910603
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.7121922676365644,
            "auditor_fn_violation": 0.028955472577355,
            "auditor_fp_violation": 0.005067440566590983,
            "ave_precision_score": 0.7129000510507301,
            "fpr": 0.026344676180021953,
            "logloss": 1.423588307457125,
            "mae": 0.4580717834362521,
            "precision": 0.7391304347826086,
            "recall": 0.14376321353065538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 24481,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8394066780200006,
            "auditor_fn_violation": 0.012619907356749463,
            "auditor_fp_violation": 0.016966357308584687,
            "ave_precision_score": 0.8398778251831533,
            "fpr": 0.09758771929824561,
            "logloss": 0.7430576316829457,
            "mae": 0.2727328779296476,
            "precision": 0.7963386727688787,
            "recall": 0.7234927234927235
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8178425875937088,
            "auditor_fn_violation": 0.013429936667881176,
            "auditor_fp_violation": 0.015247432446656547,
            "ave_precision_score": 0.818177339186387,
            "fpr": 0.1119648737650933,
            "logloss": 0.7838766909316173,
            "mae": 0.2855272963998342,
            "precision": 0.7665903890160183,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8434672714291156,
            "auditor_fn_violation": 0.008133639712587088,
            "auditor_fp_violation": 0.019250926038995406,
            "ave_precision_score": 0.8439354215991322,
            "fpr": 0.11293859649122807,
            "logloss": 0.7737855598341842,
            "mae": 0.2629336045233222,
            "precision": 0.7813163481953291,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8195421090350938,
            "auditor_fn_violation": 0.01556034652810494,
            "auditor_fp_violation": 0.018658306141577576,
            "ave_precision_score": 0.8199122596799037,
            "fpr": 0.132821075740944,
            "logloss": 0.8240240301956085,
            "mae": 0.2735541850334484,
            "precision": 0.7463312368972747,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8429834862546617,
            "auditor_fn_violation": 0.01647472371156582,
            "auditor_fp_violation": 0.01897616721618431,
            "ave_precision_score": 0.8434046004232412,
            "fpr": 0.09429824561403509,
            "logloss": 0.7412470834325869,
            "mae": 0.26876268944483545,
            "precision": 0.8009259259259259,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8179922295634525,
            "auditor_fn_violation": 0.014142393995864498,
            "auditor_fp_violation": 0.012889142845686161,
            "ave_precision_score": 0.8183935916472199,
            "fpr": 0.10428100987925357,
            "logloss": 0.7886930942915706,
            "mae": 0.2800081313675757,
            "precision": 0.7800925925925926,
            "recall": 0.7124735729386892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 24481,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8563954160394462,
            "auditor_fn_violation": 0.018553725790567903,
            "auditor_fp_violation": 0.0062329547767330205,
            "ave_precision_score": 0.8566196104190287,
            "fpr": 0.08333333333333333,
            "logloss": 1.0944452579299238,
            "mae": 0.3080870644694885,
            "precision": 0.8199052132701422,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8357200470696047,
            "auditor_fn_violation": 0.0188371860952465,
            "auditor_fp_violation": 0.01870592304106582,
            "ave_precision_score": 0.8359558982561542,
            "fpr": 0.10428100987925357,
            "logloss": 0.8934152083750289,
            "mae": 0.3257136802204432,
            "precision": 0.7785547785547785,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 24481,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8181252104302497,
            "auditor_fn_violation": 0.00813591932012985,
            "auditor_fp_violation": 0.009173891806081328,
            "ave_precision_score": 0.819501065982092,
            "fpr": 0.04057017543859649,
            "logloss": 1.1295522762114054,
            "mae": 0.32252806359961467,
            "precision": 0.8659420289855072,
            "recall": 0.4968814968814969
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8064153117802746,
            "auditor_fn_violation": 0.01171261281541322,
            "auditor_fp_violation": 0.010225102626949159,
            "ave_precision_score": 0.8067403065624715,
            "fpr": 0.05817782656421515,
            "logloss": 1.0894473336400263,
            "mae": 0.3343450661920281,
            "precision": 0.8120567375886525,
            "recall": 0.48414376321353064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8414989165234632,
            "auditor_fn_violation": 0.014338731443994609,
            "auditor_fp_violation": 0.024804615948223228,
            "ave_precision_score": 0.8422342548581929,
            "fpr": 0.1118421052631579,
            "logloss": 0.8094613759917799,
            "mae": 0.25718199173145206,
            "precision": 0.7838983050847458,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8197361690608003,
            "auditor_fn_violation": 0.02120198745425305,
            "auditor_fp_violation": 0.016713531720373518,
            "ave_precision_score": 0.8201033613195625,
            "fpr": 0.13721185510428102,
            "logloss": 0.857018705761747,
            "mae": 0.2739515003372825,
            "precision": 0.7412008281573499,
            "recall": 0.7568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8438678753831103,
            "auditor_fn_violation": 0.011587245139876724,
            "auditor_fp_violation": 0.01884133186795295,
            "ave_precision_score": 0.8444124771952246,
            "fpr": 0.10307017543859649,
            "logloss": 0.7465768267770131,
            "mae": 0.2690541021498694,
            "precision": 0.7887640449438202,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.81925887550448,
            "auditor_fn_violation": 0.013183941629554692,
            "auditor_fp_violation": 0.014295094456891668,
            "ave_precision_score": 0.8196775843644049,
            "fpr": 0.1141602634467618,
            "logloss": 0.7814480921565226,
            "mae": 0.2774033897020659,
            "precision": 0.7668161434977578,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.674477853513314,
            "auditor_fn_violation": 0.008936061567640536,
            "auditor_fp_violation": 0.002996906419180202,
            "ave_precision_score": 0.6747775991855636,
            "fpr": 0.010964912280701754,
            "logloss": 6.088402096984558,
            "mae": 0.4661435456476175,
            "precision": 0.863013698630137,
            "recall": 0.13097713097713098
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6605442370040291,
            "auditor_fn_violation": 0.004536983961587641,
            "auditor_fp_violation": 0.003082567703712615,
            "ave_precision_score": 0.6609982306646124,
            "fpr": 0.015367727771679473,
            "logloss": 5.896450049348691,
            "mae": 0.4654243415272029,
            "precision": 0.8157894736842105,
            "recall": 0.13107822410147993
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8447418304038226,
            "auditor_fn_violation": 0.008404913010176172,
            "auditor_fp_violation": 0.02315097488500835,
            "ave_precision_score": 0.8453434679683635,
            "fpr": 0.12938596491228072,
            "logloss": 0.7689259712025948,
            "mae": 0.26269577743920863,
            "precision": 0.7611336032388664,
            "recall": 0.7817047817047817
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8228005409785389,
            "auditor_fn_violation": 0.00921553110560846,
            "auditor_fp_violation": 0.018893884486414148,
            "ave_precision_score": 0.8231348811858279,
            "fpr": 0.14818880351262348,
            "logloss": 0.8088503632547994,
            "mae": 0.27007744557986,
            "precision": 0.735812133072407,
            "recall": 0.7949260042283298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.8400760226398546,
            "auditor_fn_violation": 0.0009825108509319037,
            "auditor_fp_violation": 0.014040684658281429,
            "ave_precision_score": 0.840047690643803,
            "fpr": 0.43201754385964913,
            "logloss": 1.5749718979811196,
            "mae": 0.40873841082640483,
            "precision": 0.5481651376146789,
            "recall": 0.9937629937629938
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.8159097812517402,
            "auditor_fn_violation": 0.0012206923599974938,
            "auditor_fp_violation": 0.007162584144073722,
            "ave_precision_score": 0.8157847355237863,
            "fpr": 0.4522502744237102,
            "logloss": 1.6899863625565112,
            "mae": 0.4208723270118596,
            "precision": 0.5334088335220838,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.792382590718833,
            "auditor_fn_violation": 0.01719280008753693,
            "auditor_fp_violation": 0.0033632515162616526,
            "ave_precision_score": 0.7891296886899721,
            "fpr": 0.03508771929824561,
            "logloss": 2.8690985271322793,
            "mae": 0.33421415555239403,
            "precision": 0.8865248226950354,
            "recall": 0.5197505197505198
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8041530544130652,
            "auditor_fn_violation": 0.008254758031389904,
            "auditor_fp_violation": 0.012124766301269619,
            "ave_precision_score": 0.7994999448040057,
            "fpr": 0.04171240395170143,
            "logloss": 2.8750747742039997,
            "mae": 0.33551345265876004,
            "precision": 0.8623188405797102,
            "recall": 0.5031712473572939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8456366482078409,
            "auditor_fn_violation": 0.008439107123317652,
            "auditor_fp_violation": 0.012946737493385437,
            "ave_precision_score": 0.8460981598434782,
            "fpr": 0.07675438596491228,
            "logloss": 0.774562791505793,
            "mae": 0.2747891201082546,
            "precision": 0.8205128205128205,
            "recall": 0.6652806652806653
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8196239691042609,
            "auditor_fn_violation": 0.017690756388328704,
            "auditor_fp_violation": 0.008262785137512597,
            "ave_precision_score": 0.8199996812526643,
            "fpr": 0.0889132821075741,
            "logloss": 0.8139868706175276,
            "mae": 0.2899387622425284,
            "precision": 0.7917737789203085,
            "recall": 0.6511627906976745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.81775036659035,
            "auditor_fn_violation": 0.01603020024072656,
            "auditor_fp_violation": 0.012610921154394111,
            "ave_precision_score": 0.8181345284348132,
            "fpr": 0.09868421052631579,
            "logloss": 0.8645912957189789,
            "mae": 0.29590042948362716,
            "precision": 0.7794117647058824,
            "recall": 0.6611226611226612
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7824258813187379,
            "auditor_fn_violation": 0.013471709410238503,
            "auditor_fp_violation": 0.019673297946458553,
            "ave_precision_score": 0.7829870456298186,
            "fpr": 0.10647639956092206,
            "logloss": 0.9270605526443716,
            "mae": 0.30412630851917505,
            "precision": 0.7562814070351759,
            "recall": 0.6363636363636364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8460797535041098,
            "auditor_fn_violation": 0.00859184082868294,
            "auditor_fp_violation": 0.02168559449668254,
            "ave_precision_score": 0.8466830609426712,
            "fpr": 0.11403508771929824,
            "logloss": 0.753369301213378,
            "mae": 0.26252762788038586,
            "precision": 0.7810526315789473,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8233675085720974,
            "auditor_fn_violation": 0.012571274741647199,
            "auditor_fp_violation": 0.01820469252013694,
            "ave_precision_score": 0.8237192031973277,
            "fpr": 0.13391877058177826,
            "logloss": 0.7868263979858462,
            "mae": 0.27149597858747176,
            "precision": 0.7479338842975206,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8570084650793529,
            "auditor_fn_violation": 0.012100156836998945,
            "auditor_fp_violation": 0.0030884926934505656,
            "ave_precision_score": 0.8574621201089768,
            "fpr": 0.05921052631578947,
            "logloss": 0.5327389039715489,
            "mae": 0.3076915488376184,
            "precision": 0.8516483516483516,
            "recall": 0.6444906444906445
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8492912733996858,
            "auditor_fn_violation": 0.005896918796109566,
            "auditor_fp_violation": 0.011538326591782827,
            "ave_precision_score": 0.8494976897224582,
            "fpr": 0.06695938529088913,
            "logloss": 0.5471409798923343,
            "mae": 0.32319266129332125,
            "precision": 0.8346883468834688,
            "recall": 0.6511627906976745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 24481,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.829993333409603,
            "auditor_fn_violation": 0.010260513549987232,
            "auditor_fp_violation": 0.00844120161191843,
            "ave_precision_score": 0.8303716511135386,
            "fpr": 0.03728070175438596,
            "logloss": 1.136566135595113,
            "mae": 0.3246924941245586,
            "precision": 0.8740740740740741,
            "recall": 0.49064449064449067
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8036696094535931,
            "auditor_fn_violation": 0.011343620257923476,
            "auditor_fp_violation": 0.008084848302582841,
            "ave_precision_score": 0.8040295756286303,
            "fpr": 0.050493962678375415,
            "logloss": 1.1300237422177817,
            "mae": 0.33855051922853385,
            "precision": 0.8257575757575758,
            "recall": 0.4608879492600423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7952854076862422,
            "auditor_fn_violation": 0.0017963307436991826,
            "auditor_fp_violation": 0.00373977286603981,
            "ave_precision_score": 0.7956644041066459,
            "fpr": 0.01206140350877193,
            "logloss": 1.1529199622329729,
            "mae": 0.410609640641768,
            "precision": 0.9133858267716536,
            "recall": 0.24116424116424118
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7340777748168295,
            "auditor_fn_violation": 0.005780883400672558,
            "auditor_fp_violation": 0.00488449142645194,
            "ave_precision_score": 0.7355609059496735,
            "fpr": 0.020856201975850714,
            "logloss": 1.1467559729486174,
            "mae": 0.4269715200663734,
            "precision": 0.831858407079646,
            "recall": 0.19873150105708245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8429953376963095,
            "auditor_fn_violation": 0.012314439946018897,
            "auditor_fp_violation": 0.021265824072943387,
            "ave_precision_score": 0.8434111990694358,
            "fpr": 0.18311403508771928,
            "logloss": 0.7996967912959492,
            "mae": 0.2722636137210894,
            "precision": 0.7105719237435009,
            "recall": 0.8523908523908524
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8171854894730237,
            "auditor_fn_violation": 0.009178399779068607,
            "auditor_fp_violation": 0.019337473497436218,
            "ave_precision_score": 0.817580360053528,
            "fpr": 0.19758507135016465,
            "logloss": 0.8791042264542467,
            "mae": 0.27864764212431786,
            "precision": 0.6964586846543002,
            "recall": 0.8731501057082452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 24481,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8442329215362512,
            "auditor_fn_violation": 0.014915472152314266,
            "auditor_fp_violation": 0.01897616721618431,
            "ave_precision_score": 0.8446471949714863,
            "fpr": 0.09429824561403509,
            "logloss": 0.7422318060879334,
            "mae": 0.2689574374548224,
            "precision": 0.8004640371229699,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8189009464107694,
            "auditor_fn_violation": 0.013146810303014834,
            "auditor_fp_violation": 0.012245061626292554,
            "ave_precision_score": 0.8192878051884556,
            "fpr": 0.10318331503841932,
            "logloss": 0.7899000987456031,
            "mae": 0.28070051865314816,
            "precision": 0.780373831775701,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8440334861434055,
            "auditor_fn_violation": 0.011587245139876724,
            "auditor_fp_violation": 0.01884133186795295,
            "ave_precision_score": 0.8445770822606262,
            "fpr": 0.10307017543859649,
            "logloss": 0.7464176757452943,
            "mae": 0.2689940903726917,
            "precision": 0.7887640449438202,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8193527927060378,
            "auditor_fn_violation": 0.011441089990090575,
            "auditor_fp_violation": 0.014295094456891668,
            "ave_precision_score": 0.8197704920174216,
            "fpr": 0.1141602634467618,
            "logloss": 0.7812055948454134,
            "mae": 0.27738789742859943,
            "precision": 0.767337807606264,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8317346833604062,
            "auditor_fn_violation": 0.010041671225881755,
            "auditor_fp_violation": 0.023514775918915633,
            "ave_precision_score": 0.8324817866330435,
            "fpr": 0.14364035087719298,
            "logloss": 0.780197128740349,
            "mae": 0.2716287996299189,
            "precision": 0.745136186770428,
            "recall": 0.7962577962577962
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8087244620417566,
            "auditor_fn_violation": 0.01439070974209973,
            "auditor_fp_violation": 0.020149466941340993,
            "ave_precision_score": 0.809145552195027,
            "fpr": 0.16465422612513722,
            "logloss": 0.8355716707556344,
            "mae": 0.28429747380820286,
            "precision": 0.7115384615384616,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8645740278739747,
            "auditor_fn_violation": 0.014359247911879498,
            "auditor_fp_violation": 0.015539137867871533,
            "ave_precision_score": 0.8648544169803435,
            "fpr": 0.10964912280701754,
            "logloss": 0.5393530896461439,
            "mae": 0.26402292291348467,
            "precision": 0.7933884297520661,
            "recall": 0.7983367983367984
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8516118273338599,
            "auditor_fn_violation": 0.010213435506366865,
            "auditor_fp_violation": 0.019540471858412407,
            "ave_precision_score": 0.8518257779862765,
            "fpr": 0.1350164654226125,
            "logloss": 0.5525004769558669,
            "mae": 0.2771419499081001,
            "precision": 0.7484662576687117,
            "recall": 0.773784355179704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8367093906739379,
            "auditor_fn_violation": 0.013575062917168182,
            "auditor_fp_violation": 0.004945658810599587,
            "ave_precision_score": 0.8370601959925597,
            "fpr": 0.03837719298245614,
            "logloss": 0.8334907869421908,
            "mae": 0.3276395024939209,
            "precision": 0.8694029850746269,
            "recall": 0.48440748440748443
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8148892566768423,
            "auditor_fn_violation": 0.008742106692225414,
            "auditor_fp_violation": 0.012017001739269907,
            "ave_precision_score": 0.8152184896695578,
            "fpr": 0.04720087815587267,
            "logloss": 0.814540201413088,
            "mae": 0.3400290841803403,
            "precision": 0.8395522388059702,
            "recall": 0.47568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 24481,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8030094520800808,
            "auditor_fn_violation": 0.007607050370208275,
            "auditor_fp_violation": 0.0050881263483534825,
            "ave_precision_score": 0.8038366472856158,
            "fpr": 0.044956140350877194,
            "logloss": 1.1245912023387565,
            "mae": 0.33524037603709994,
            "precision": 0.8492647058823529,
            "recall": 0.4802494802494803
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7713111702619142,
            "auditor_fn_violation": 0.003546041684555471,
            "auditor_fp_violation": 0.007588630086863249,
            "ave_precision_score": 0.7717490856859769,
            "fpr": 0.054884742041712405,
            "logloss": 1.1530580842120302,
            "mae": 0.34255740406885254,
            "precision": 0.8141263940520446,
            "recall": 0.4630021141649049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8305911995646517,
            "auditor_fn_violation": 0.012904858299595149,
            "auditor_fp_violation": 0.0203118003826271,
            "ave_precision_score": 0.8310277305947036,
            "fpr": 0.13706140350877194,
            "logloss": 0.8143864108483662,
            "mae": 0.27685490460858425,
            "precision": 0.7474747474747475,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8094087672499202,
            "auditor_fn_violation": 0.009749293924618771,
            "auditor_fp_violation": 0.018893884486414148,
            "ave_precision_score": 0.809758517525268,
            "fpr": 0.14818880351262348,
            "logloss": 0.8704163867879624,
            "mae": 0.28669850400719454,
            "precision": 0.7272727272727273,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8637102294424234,
            "auditor_fn_violation": 0.012608509319035639,
            "auditor_fp_violation": 0.01884133186795295,
            "ave_precision_score": 0.8642167058731134,
            "fpr": 0.10307017543859649,
            "logloss": 0.52690688288385,
            "mae": 0.26517950060186096,
            "precision": 0.796976241900648,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8443887177240329,
            "auditor_fn_violation": 0.013624876132215372,
            "auditor_fp_violation": 0.014861484945541311,
            "ave_precision_score": 0.8446232038717926,
            "fpr": 0.1207464324917673,
            "logloss": 0.5565314040889517,
            "mae": 0.28420230284211573,
            "precision": 0.7639484978540773,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8475314291132185,
            "auditor_fn_violation": 0.013196648065069122,
            "auditor_fp_violation": 0.017788089713843786,
            "ave_precision_score": 0.8479850634671028,
            "fpr": 0.09649122807017543,
            "logloss": 0.7433678391141796,
            "mae": 0.26694100842769525,
            "precision": 0.7962962962962963,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8228590169470342,
            "auditor_fn_violation": 0.012063039709633022,
            "auditor_fp_violation": 0.010956899187505325,
            "ave_precision_score": 0.8232100243223498,
            "fpr": 0.10098792535675083,
            "logloss": 0.7849254782609393,
            "mae": 0.27827879029051544,
            "precision": 0.784037558685446,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8579062560108183,
            "auditor_fn_violation": 0.01008270416165153,
            "auditor_fp_violation": 0.02044154760451012,
            "ave_precision_score": 0.858584550488648,
            "fpr": 0.125,
            "logloss": 0.6184961243364157,
            "mae": 0.26142754578272853,
            "precision": 0.7668711656441718,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8353292568521908,
            "auditor_fn_violation": 0.0063865881648538115,
            "auditor_fp_violation": 0.02162308467287191,
            "ave_precision_score": 0.8356095912260321,
            "fpr": 0.14489571899012074,
            "logloss": 0.6561726916149441,
            "mae": 0.27598862140345504,
            "precision": 0.736,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8448849708258585,
            "auditor_fn_violation": 0.01671636211109896,
            "auditor_fp_violation": 0.020795172385720685,
            "ave_precision_score": 0.8453035987074915,
            "fpr": 0.10307017543859649,
            "logloss": 0.7365555269325401,
            "mae": 0.2662654979463629,
            "precision": 0.7911111111111111,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8198423195257479,
            "auditor_fn_violation": 0.013724666572291211,
            "auditor_fp_violation": 0.016227338115072504,
            "ave_precision_score": 0.820229654806902,
            "fpr": 0.11745334796926454,
            "logloss": 0.7827145088292404,
            "mae": 0.2771062898715341,
            "precision": 0.7637969094922737,
            "recall": 0.7315010570824524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8662598005781394,
            "auditor_fn_violation": 0.011660192581245215,
            "auditor_fp_violation": 0.018363047991207714,
            "ave_precision_score": 0.8667804403268891,
            "fpr": 0.10307017543859649,
            "logloss": 0.5286199501854686,
            "mae": 0.26659267896990824,
            "precision": 0.7978494623655914,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.855321129542636,
            "auditor_fn_violation": 0.01313520676347113,
            "auditor_fp_violation": 0.020625635936223435,
            "ave_precision_score": 0.8555209603990446,
            "fpr": 0.1207464324917673,
            "logloss": 0.5463624092156583,
            "mae": 0.2804700043070325,
            "precision": 0.7654584221748401,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.84280379837767,
            "auditor_fn_violation": 0.014138125980231247,
            "auditor_fp_violation": 0.02657528391745024,
            "ave_precision_score": 0.8433645845162421,
            "fpr": 0.11513157894736842,
            "logloss": 0.7802472933549586,
            "mae": 0.25774750618068476,
            "precision": 0.7794117647058824,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8206790625312188,
            "auditor_fn_violation": 0.022698844055390664,
            "auditor_fp_violation": 0.019826173255341868,
            "ave_precision_score": 0.8210531278694788,
            "fpr": 0.1394072447859495,
            "logloss": 0.8301154115397426,
            "mae": 0.2743365276179116,
            "precision": 0.7386831275720165,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 24481,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8391084914228493,
            "auditor_fn_violation": 0.009850184192289458,
            "auditor_fp_violation": 0.010056681727520661,
            "ave_precision_score": 0.8394438750315942,
            "fpr": 0.04824561403508772,
            "logloss": 1.0189935412190239,
            "mae": 0.3047954186377437,
            "precision": 0.8538205980066446,
            "recall": 0.5343035343035343
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8132431402861875,
            "auditor_fn_violation": 0.0151681468915278,
            "auditor_fp_violation": 0.009989524282112588,
            "ave_precision_score": 0.8135608821662822,
            "fpr": 0.0570801317233809,
            "logloss": 1.0308091031962594,
            "mae": 0.31956663327499535,
            "precision": 0.8260869565217391,
            "recall": 0.5221987315010571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8501586747596339,
            "auditor_fn_violation": 0.007438359412043624,
            "auditor_fp_violation": 0.019899662148410473,
            "ave_precision_score": 0.8504229880970889,
            "fpr": 0.11293859649122807,
            "logloss": 0.713594113616066,
            "mae": 0.2560424248378401,
            "precision": 0.7854166666666667,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8282025570338777,
            "auditor_fn_violation": 0.008178174670401462,
            "auditor_fp_violation": 0.014565758938193271,
            "ave_precision_score": 0.8285081698967571,
            "fpr": 0.12952799121844127,
            "logloss": 0.7608363640652005,
            "mae": 0.27044508741794604,
            "precision": 0.7551867219917012,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8540331472822795,
            "auditor_fn_violation": 0.012836470073312182,
            "auditor_fp_violation": 7.886595839948091e-05,
            "ave_precision_score": 0.8545431228103381,
            "fpr": 0.09210526315789473,
            "logloss": 0.503566367467158,
            "mae": 0.29928757786151355,
            "precision": 0.8133333333333334,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8424866943223464,
            "auditor_fn_violation": 0.017695397804146185,
            "auditor_fp_violation": 0.014806349588239131,
            "ave_precision_score": 0.8427081355803162,
            "fpr": 0.1207464324917673,
            "logloss": 0.5239358616026398,
            "mae": 0.32018015464500993,
            "precision": 0.7613882863340564,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8499873667307232,
            "auditor_fn_violation": 0.017470912207754315,
            "auditor_fp_violation": 0.036888916025562754,
            "ave_precision_score": 0.8504307568117527,
            "fpr": 0.21820175438596492,
            "logloss": 0.5562392092571752,
            "mae": 0.3234738349544881,
            "precision": 0.678513731825525,
            "recall": 0.8731808731808732
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8248794458386357,
            "auditor_fn_violation": 0.01726374613312045,
            "auditor_fp_violation": 0.025908605626813828,
            "ave_precision_score": 0.8252339406001796,
            "fpr": 0.25905598243688255,
            "logloss": 0.5938459895494781,
            "mae": 0.3453377178399177,
            "precision": 0.6456456456456456,
            "recall": 0.9090909090909091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.861256264052622,
            "auditor_fn_violation": 0.007800817011343327,
            "auditor_fp_violation": 0.023285810233239716,
            "ave_precision_score": 0.8624629283813608,
            "fpr": 0.11513157894736842,
            "logloss": 0.5301141578391322,
            "mae": 0.26505846747960804,
            "precision": 0.7803347280334728,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8484432609894357,
            "auditor_fn_violation": 0.008092308477778061,
            "auditor_fp_violation": 0.018179630994090496,
            "ave_precision_score": 0.8486634528355289,
            "fpr": 0.13611416026344675,
            "logloss": 0.5522882537969732,
            "mae": 0.2792142047622199,
            "precision": 0.7459016393442623,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8135247460407562,
            "auditor_fn_violation": 0.009827388116861811,
            "auditor_fp_violation": 0.010199149265274553,
            "ave_precision_score": 0.8148776442788205,
            "fpr": 0.051535087719298246,
            "logloss": 1.164158013118871,
            "mae": 0.3188563060204284,
            "precision": 0.8406779661016949,
            "recall": 0.5155925155925156
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8023633649725788,
            "auditor_fn_violation": 0.015124053441261725,
            "auditor_fp_violation": 0.008601115739139588,
            "ave_precision_score": 0.8026807926309701,
            "fpr": 0.06586169045005488,
            "logloss": 1.1241813188736471,
            "mae": 0.33019151737038205,
            "precision": 0.7972972972972973,
            "recall": 0.4989429175475687
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8149133792810269,
            "auditor_fn_violation": 0.01268373636794691,
            "auditor_fp_violation": 0.010771563479464322,
            "ave_precision_score": 0.8162698408770404,
            "fpr": 0.05263157894736842,
            "logloss": 1.1322886664638157,
            "mae": 0.31533929524913834,
            "precision": 0.840531561461794,
            "recall": 0.525987525987526
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8041615851241625,
            "auditor_fn_violation": 0.017008468263159,
            "auditor_fp_violation": 0.009220135432486756,
            "ave_precision_score": 0.8044741632431831,
            "fpr": 0.06695938529088913,
            "logloss": 1.0942631251975576,
            "mae": 0.3266416821731846,
            "precision": 0.8013029315960912,
            "recall": 0.5200845665961945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8449515392595071,
            "auditor_fn_violation": 0.008808403545245657,
            "auditor_fp_violation": 0.020072658444254488,
            "ave_precision_score": 0.8454943882314467,
            "fpr": 0.13267543859649122,
            "logloss": 0.7667781570986265,
            "mae": 0.26231823876306753,
            "precision": 0.7575150300601202,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8221852574082658,
            "auditor_fn_violation": 0.010002251086671477,
            "auditor_fp_violation": 0.019465287280273073,
            "ave_precision_score": 0.8225403167792315,
            "fpr": 0.15477497255762898,
            "logloss": 0.8118601848994944,
            "mae": 0.2705018989183732,
            "precision": 0.7272727272727273,
            "recall": 0.7949260042283298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7462220454159868,
            "auditor_fn_violation": 3.6473720684262343e-05,
            "auditor_fp_violation": 0.006080310986282412,
            "ave_precision_score": 0.7478806061074034,
            "fpr": 0.023026315789473683,
            "logloss": 1.1809724448465424,
            "mae": 0.42100803365301076,
            "precision": 0.8432835820895522,
            "recall": 0.23492723492723494
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7065554944192852,
            "auditor_fn_violation": 0.01321411083236831,
            "auditor_fp_violation": 0.004814319153521897,
            "ave_precision_score": 0.7071384904592641,
            "fpr": 0.025246981339187707,
            "logloss": 1.2203924978835952,
            "mae": 0.42853475814306147,
            "precision": 0.8203125,
            "recall": 0.2219873150105708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.848024277252923,
            "auditor_fn_violation": 0.0038046649888755155,
            "auditor_fp_violation": 0.016322709325517975,
            "ave_precision_score": 0.848635171450377,
            "fpr": 0.32456140350877194,
            "logloss": 1.458946878137166,
            "mae": 0.3418882350242707,
            "precision": 0.6120576671035387,
            "recall": 0.9708939708939709
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.8229533899010454,
            "auditor_fn_violation": 0.005207668547213643,
            "auditor_fp_violation": 0.026269491601882626,
            "ave_precision_score": 0.8233122797639403,
            "fpr": 0.33040614709110866,
            "logloss": 1.534928499841029,
            "mae": 0.3475728137154365,
            "precision": 0.600265604249668,
            "recall": 0.9556025369978859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7931723374239501,
            "auditor_fn_violation": 0.01120883028777768,
            "auditor_fp_violation": 0.003617657833679325,
            "ave_precision_score": 0.794720691313699,
            "fpr": 0.03728070175438596,
            "logloss": 1.2430131756455172,
            "mae": 0.350225961845556,
            "precision": 0.8577405857740585,
            "recall": 0.4261954261954262
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7652581905441717,
            "auditor_fn_violation": 0.007150101066829443,
            "auditor_fp_violation": 0.007398162488910275,
            "ave_precision_score": 0.765717397953868,
            "fpr": 0.043907793633369926,
            "logloss": 1.2807698792666953,
            "mae": 0.35678844482083105,
            "precision": 0.8253275109170306,
            "recall": 0.39957716701902746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 24481,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.818347670152203,
            "auditor_fn_violation": 0.007317540212277062,
            "auditor_fp_violation": 0.009583485977123782,
            "ave_precision_score": 0.819732478242938,
            "fpr": 0.04276315789473684,
            "logloss": 1.1089771868683242,
            "mae": 0.32074313039101354,
            "precision": 0.8607142857142858,
            "recall": 0.501039501039501
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.8075978747891219,
            "auditor_fn_violation": 0.01279406270088629,
            "auditor_fp_violation": 0.008658757249046412,
            "ave_precision_score": 0.8079119965940595,
            "fpr": 0.05817782656421515,
            "logloss": 1.0687868447461601,
            "mae": 0.3325059017152432,
            "precision": 0.8127208480565371,
            "recall": 0.48625792811839325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8627474745514481,
            "auditor_fn_violation": 0.010887405624247733,
            "auditor_fp_violation": 0.021596552285586358,
            "ave_precision_score": 0.8634396124637207,
            "fpr": 0.11074561403508772,
            "logloss": 0.5440270874298546,
            "mae": 0.2671289120261734,
            "precision": 0.7869198312236287,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.850713586892935,
            "auditor_fn_violation": 0.01116956716476795,
            "auditor_fp_violation": 0.019375065786505878,
            "ave_precision_score": 0.8509229030575138,
            "fpr": 0.12843029637760703,
            "logloss": 0.5653866477560993,
            "mae": 0.2805130377311656,
            "precision": 0.7547169811320755,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.8390849600525038,
            "auditor_fn_violation": 0.005434584381952804,
            "auditor_fp_violation": 0.024880937843448536,
            "ave_precision_score": 0.8394365524517504,
            "fpr": 0.3706140350877193,
            "logloss": 0.9388921263223022,
            "mae": 0.3803424311409368,
            "precision": 0.5785536159600998,
            "recall": 0.9646569646569647
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.8193643722361397,
            "auditor_fn_violation": 0.0033116501857726674,
            "auditor_fp_violation": 0.017395205228836808,
            "ave_precision_score": 0.8196580019308422,
            "fpr": 0.40285400658616904,
            "logloss": 1.0398549919447115,
            "mae": 0.4042988649128593,
            "precision": 0.5567632850241546,
            "recall": 0.9746300211416491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8393707009208196,
            "auditor_fn_violation": 0.011936025093919833,
            "auditor_fp_violation": 0.018948182521268366,
            "ave_precision_score": 0.8397777723788878,
            "fpr": 0.13925438596491227,
            "logloss": 0.7662946982980481,
            "mae": 0.2637776552130242,
            "precision": 0.751953125,
            "recall": 0.8004158004158004
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8182508530613035,
            "auditor_fn_violation": 0.010020816749941406,
            "auditor_fp_violation": 0.024279606433794967,
            "ave_precision_score": 0.8185528406784849,
            "fpr": 0.16575192096597147,
            "logloss": 0.8379091409777679,
            "mae": 0.2764908751253254,
            "precision": 0.7198515769944341,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8438042188751267,
            "auditor_fn_violation": 0.009654137943611633,
            "auditor_fp_violation": 0.01960455082020597,
            "ave_precision_score": 0.8442625405467087,
            "fpr": 0.10526315789473684,
            "logloss": 0.7594085107208569,
            "mae": 0.2670730118612255,
            "precision": 0.7876106194690266,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8186094566137834,
            "auditor_fn_violation": 0.012281186253054636,
            "auditor_fp_violation": 0.013315188788475714,
            "ave_precision_score": 0.8190326745399592,
            "fpr": 0.12184412733260154,
            "logloss": 0.7948052816678441,
            "mae": 0.2754994859063134,
            "precision": 0.7571115973741794,
            "recall": 0.7315010570824524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8014449094987831,
            "auditor_fn_violation": 0.00808120873910348,
            "auditor_fp_violation": 0.0049889078845605905,
            "ave_precision_score": 0.8024478929538387,
            "fpr": 0.047149122807017545,
            "logloss": 1.0914508003150531,
            "mae": 0.33335543818248436,
            "precision": 0.8453237410071942,
            "recall": 0.4885654885654886
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7709822361652823,
            "auditor_fn_violation": 0.0062566285219643565,
            "auditor_fp_violation": 0.006435799888726824,
            "ave_precision_score": 0.7714227852562,
            "fpr": 0.05817782656421515,
            "logloss": 1.1402921771614538,
            "mae": 0.3405613143834469,
            "precision": 0.8093525179856115,
            "recall": 0.47568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8612828291828633,
            "auditor_fn_violation": 0.029899332530911482,
            "auditor_fp_violation": 0.01306885252574592,
            "ave_precision_score": 0.8617034873510915,
            "fpr": 0.06140350877192982,
            "logloss": 0.5586383004227806,
            "mae": 0.2927049950780104,
            "precision": 0.8556701030927835,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8403007539652717,
            "auditor_fn_violation": 0.033661868216280706,
            "auditor_fp_violation": 0.01694660391260545,
            "ave_precision_score": 0.8415603678149935,
            "fpr": 0.07244785949506037,
            "logloss": 0.5619893229652841,
            "mae": 0.31241092832208106,
            "precision": 0.8253968253968254,
            "recall": 0.6596194503171248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8055483839611601,
            "auditor_fn_violation": 0.009943648101542859,
            "auditor_fp_violation": 0.003592217201937559,
            "ave_precision_score": 0.8062378187623158,
            "fpr": 0.03837719298245614,
            "logloss": 1.1897574402109905,
            "mae": 0.33869842321707816,
            "precision": 0.8622047244094488,
            "recall": 0.4553014553014553
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7703371427632879,
            "auditor_fn_violation": 0.010046344536937566,
            "auditor_fp_violation": 0.005806755584961081,
            "ave_precision_score": 0.7707744952028339,
            "fpr": 0.05378704720087816,
            "logloss": 1.2348179665203485,
            "mae": 0.34779764930703255,
            "precision": 0.807843137254902,
            "recall": 0.4355179704016913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8634507521568999,
            "auditor_fn_violation": 0.015875186927818512,
            "auditor_fp_violation": 0.010387409940163633,
            "ave_precision_score": 0.8641382641786126,
            "fpr": 0.06359649122807018,
            "logloss": 0.5662196162539231,
            "mae": 0.28508926924322414,
            "precision": 0.8440860215053764,
            "recall": 0.6528066528066528
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8432548423619965,
            "auditor_fn_violation": 0.01623567252954841,
            "auditor_fp_violation": 0.010881714609365992,
            "ave_precision_score": 0.8434903249112011,
            "fpr": 0.07683863885839737,
            "logloss": 0.5882615523517581,
            "mae": 0.30283337835842,
            "precision": 0.8123324396782842,
            "recall": 0.6405919661733616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8437732050080691,
            "auditor_fn_violation": 0.009109311740890696,
            "auditor_fp_violation": 0.01767615093418,
            "ave_precision_score": 0.8443191247136292,
            "fpr": 0.11513157894736842,
            "logloss": 0.6963447859884159,
            "mae": 0.2661608956126969,
            "precision": 0.7784810126582279,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8179444434065981,
            "auditor_fn_violation": 0.011364506629102144,
            "auditor_fp_violation": 0.019277325834924745,
            "ave_precision_score": 0.8183004563537039,
            "fpr": 0.12843029637760703,
            "logloss": 0.7487773126942834,
            "mae": 0.2806586471363132,
            "precision": 0.7494646680942184,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8470177556610254,
            "auditor_fn_violation": 0.012952730057993224,
            "auditor_fp_violation": 0.01627182806203444,
            "ave_precision_score": 0.8475581128981635,
            "fpr": 0.11293859649122807,
            "logloss": 0.7361138738816309,
            "mae": 0.26316204139667915,
            "precision": 0.7803837953091685,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8232087058393402,
            "auditor_fn_violation": 0.015933980501412155,
            "auditor_fp_violation": 0.018467838543624604,
            "ave_precision_score": 0.8235671384000118,
            "fpr": 0.13062568605927552,
            "logloss": 0.771200158679816,
            "mae": 0.2736094503179943,
            "precision": 0.75,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8404021963100774,
            "auditor_fn_violation": 0.010547744100375685,
            "auditor_fp_violation": 0.011687426222167953,
            "ave_precision_score": 0.8407530647675636,
            "fpr": 0.0581140350877193,
            "logloss": 0.9554256274448628,
            "mae": 0.2947801453894736,
            "precision": 0.8359133126934984,
            "recall": 0.5613305613305614
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8159217648995527,
            "auditor_fn_violation": 0.011104587343323214,
            "auditor_fp_violation": 0.010174979574856274,
            "ave_precision_score": 0.8162408936883374,
            "fpr": 0.07025246981339188,
            "logloss": 0.962082933946755,
            "mae": 0.3087895622040426,
            "precision": 0.8054711246200608,
            "recall": 0.5602536997885835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.843823875303002,
            "auditor_fn_violation": 0.010205802968960863,
            "auditor_fp_violation": 0.010682521268368137,
            "ave_precision_score": 0.8443731519547855,
            "fpr": 0.07894736842105263,
            "logloss": 0.7123387454982699,
            "mae": 0.27636035783914914,
            "precision": 0.8222222222222222,
            "recall": 0.6923076923076923
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8177401829961293,
            "auditor_fn_violation": 0.009958157636405408,
            "auditor_fp_violation": 0.010939356119272816,
            "ave_precision_score": 0.818114453420202,
            "fpr": 0.09549945115257959,
            "logloss": 0.7610139793958326,
            "mae": 0.2919089470445664,
            "precision": 0.7830423940149626,
            "recall": 0.6638477801268499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 24481,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.848929408771016,
            "auditor_fn_violation": 0.012446657183499299,
            "auditor_fp_violation": 0.017164794236170473,
            "ave_precision_score": 0.849464844038164,
            "fpr": 0.09320175438596491,
            "logloss": 0.7259388871949558,
            "mae": 0.26909315787766735,
            "precision": 0.7990543735224587,
            "recall": 0.7027027027027027
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8240581370012653,
            "auditor_fn_violation": 0.011290243976022452,
            "auditor_fp_violation": 0.010385496393646405,
            "ave_precision_score": 0.8244222005608772,
            "fpr": 0.09440175631174534,
            "logloss": 0.7616157009783338,
            "mae": 0.2792518317967692,
            "precision": 0.7927710843373494,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8342564123618234,
            "auditor_fn_violation": 0.01445499142867565,
            "auditor_fp_violation": 0.0031342858305857453,
            "ave_precision_score": 0.8346070232848706,
            "fpr": 0.03618421052631579,
            "logloss": 0.8645485598819476,
            "mae": 0.33442878375748547,
            "precision": 0.8715953307392996,
            "recall": 0.4656964656964657
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.813491265735095,
            "auditor_fn_violation": 0.01012292789792601,
            "auditor_fp_violation": 0.010455668666576445,
            "ave_precision_score": 0.8138096967124989,
            "fpr": 0.04171240395170143,
            "logloss": 0.8431139453708765,
            "mae": 0.34692287437588937,
            "precision": 0.8503937007874016,
            "recall": 0.45665961945031713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8299448457583047,
            "auditor_fn_violation": 0.011680709049130107,
            "auditor_fp_violation": 0.01289840029307609,
            "ave_precision_score": 0.8204642450386063,
            "fpr": 0.12609649122807018,
            "logloss": 0.9965065515405629,
            "mae": 0.2703280355137969,
            "precision": 0.7749510763209393,
            "recall": 0.8232848232848233
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7960188952784789,
            "auditor_fn_violation": 0.007662977514661079,
            "auditor_fp_violation": 0.016771173230280347,
            "ave_precision_score": 0.78342741440311,
            "fpr": 0.14270032930845225,
            "logloss": 1.2130104428476838,
            "mae": 0.2918749822369592,
            "precision": 0.749034749034749,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.732037026558771,
            "auditor_fn_violation": 0.005664824743772114,
            "auditor_fp_violation": 0.025504233321121835,
            "ave_precision_score": 0.6803320929167418,
            "fpr": 0.36293859649122806,
            "logloss": 5.366112306808639,
            "mae": 0.38107220744085657,
            "precision": 0.5810126582278481,
            "recall": 0.9542619542619543
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7297354972525841,
            "auditor_fn_violation": 0.007108328324472097,
            "auditor_fp_violation": 0.023119257777844612,
            "ave_precision_score": 0.6819471116876699,
            "fpr": 0.34577387486278816,
            "logloss": 5.004286046845899,
            "mae": 0.366645223810342,
            "precision": 0.5909090909090909,
            "recall": 0.9619450317124736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8464496740105848,
            "auditor_fn_violation": 0.012052285078600872,
            "auditor_fp_violation": 0.01867851182480564,
            "ave_precision_score": 0.8469917407479945,
            "fpr": 0.11293859649122807,
            "logloss": 0.7456694735590154,
            "mae": 0.26072207160584815,
            "precision": 0.7817796610169492,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8246603488760154,
            "auditor_fn_violation": 0.009273548803326974,
            "auditor_fp_violation": 0.016104536637444926,
            "ave_precision_score": 0.8249769094518795,
            "fpr": 0.13172338090010977,
            "logloss": 0.7907667978160748,
            "mae": 0.27176276277918754,
            "precision": 0.75,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8417459078131289,
            "auditor_fn_violation": 0.015478535215377323,
            "auditor_fp_violation": 0.025567834900476254,
            "ave_precision_score": 0.8424922103517833,
            "fpr": 0.11293859649122807,
            "logloss": 0.7836866046705543,
            "mae": 0.2580770170229775,
            "precision": 0.783157894736842,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8211578657463221,
            "auditor_fn_violation": 0.020823712065128355,
            "auditor_fp_violation": 0.023284663849751145,
            "ave_precision_score": 0.8215208058891663,
            "fpr": 0.132821075740944,
            "logloss": 0.829594288822998,
            "mae": 0.27409669817835935,
            "precision": 0.7484407484407485,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8424765731114161,
            "auditor_fn_violation": 0.009567512856986544,
            "auditor_fp_violation": 0.01401269996336549,
            "ave_precision_score": 0.8428484019304685,
            "fpr": 0.06578947368421052,
            "logloss": 0.9010594826698713,
            "mae": 0.2887218206801267,
            "precision": 0.8255813953488372,
            "recall": 0.5904365904365905
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8170386635557032,
            "auditor_fn_violation": 0.009292114466596895,
            "auditor_fp_violation": 0.014663498889774399,
            "ave_precision_score": 0.8173607648228034,
            "fpr": 0.07354555433589462,
            "logloss": 0.917582755623236,
            "mae": 0.303787902453013,
            "precision": 0.804093567251462,
            "recall": 0.5813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8388630066603581,
            "auditor_fn_violation": 0.008876791771528622,
            "auditor_fp_violation": 0.023522408108438152,
            "ave_precision_score": 0.8392259169675609,
            "fpr": 0.12280701754385964,
            "logloss": 0.8110280491621885,
            "mae": 0.2676703508142917,
            "precision": 0.7632135306553911,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8120863166583899,
            "auditor_fn_violation": 0.014564762835255271,
            "auditor_fp_violation": 0.020327403776270746,
            "ave_precision_score": 0.8124831948188476,
            "fpr": 0.1394072447859495,
            "logloss": 0.860852075720019,
            "mae": 0.27572752273367057,
            "precision": 0.7402862985685071,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8453789562010646,
            "auditor_fn_violation": 0.008856275303643732,
            "auditor_fp_violation": 0.018660703382586397,
            "ave_precision_score": 0.8458428528844133,
            "fpr": 0.11403508771929824,
            "logloss": 0.7723946787653891,
            "mae": 0.2588869225710871,
            "precision": 0.7815126050420168,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8226754514982965,
            "auditor_fn_violation": 0.01052905178195557,
            "auditor_fp_violation": 0.021156940288408047,
            "ave_precision_score": 0.8230387861204875,
            "fpr": 0.132821075740944,
            "logloss": 0.8162784048674857,
            "mae": 0.27059019944666374,
            "precision": 0.7520491803278688,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8558396409570774,
            "auditor_fn_violation": 0.020074224021592445,
            "auditor_fp_violation": 0.003213151788985225,
            "ave_precision_score": 0.8566027314902142,
            "fpr": 0.03618421052631579,
            "logloss": 0.5722956297912843,
            "mae": 0.32172566205707354,
            "precision": 0.8938906752411575,
            "recall": 0.577962577962578
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8466299950740781,
            "auditor_fn_violation": 0.00972144542971388,
            "auditor_fp_violation": 0.007864306873374135,
            "ave_precision_score": 0.846827574849211,
            "fpr": 0.04610318331503842,
            "logloss": 0.5855139569300278,
            "mae": 0.33793029750408,
            "precision": 0.8622950819672132,
            "recall": 0.5560253699788583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8340401069035546,
            "auditor_fn_violation": 0.01332658569500675,
            "auditor_fp_violation": 0.021912016119184276,
            "ave_precision_score": 0.8343601060300678,
            "fpr": 0.12719298245614036,
            "logloss": 0.8383317646642895,
            "mae": 0.27275067392076574,
            "precision": 0.7613168724279835,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8119165141860476,
            "auditor_fn_violation": 0.010670614964388737,
            "auditor_fp_violation": 0.020856201975850714,
            "ave_precision_score": 0.8123010796324108,
            "fpr": 0.14050493962678376,
            "logloss": 0.8907588967299945,
            "mae": 0.2778869780351141,
            "precision": 0.7382413087934561,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8443621573963266,
            "auditor_fn_violation": 0.010224039829302986,
            "auditor_fp_violation": 0.021835694223958972,
            "ave_precision_score": 0.8449068764393377,
            "fpr": 0.1337719298245614,
            "logloss": 0.7732507621014156,
            "mae": 0.2621217046773027,
            "precision": 0.7569721115537849,
            "recall": 0.7900207900207901
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8205512030459147,
            "auditor_fn_violation": 0.009974402591766593,
            "auditor_fp_violation": 0.020036690074132002,
            "ave_precision_score": 0.8209108914757909,
            "fpr": 0.15697036223929747,
            "logloss": 0.821495432588765,
            "mae": 0.2702294072707635,
            "precision": 0.7265774378585086,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8688448786464491,
            "auditor_fn_violation": 0.01810692271218587,
            "auditor_fp_violation": 0.0016561851263890571,
            "ave_precision_score": 0.8695450382168509,
            "fpr": 0.07017543859649122,
            "logloss": 0.48547199579942335,
            "mae": 0.2966197191717424,
            "precision": 0.8457831325301205,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8577503400519058,
            "auditor_fn_violation": 0.022304323710904784,
            "auditor_fp_violation": 0.01558075074307425,
            "ave_precision_score": 0.8579549664172076,
            "fpr": 0.09110867178924259,
            "logloss": 0.49981395690350156,
            "mae": 0.3137793985081279,
            "precision": 0.8014354066985646,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 24481,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7607348962427892,
            "auditor_fn_violation": 0.004025786920523761,
            "auditor_fp_violation": 0.0012440468921724268,
            "ave_precision_score": 0.7623163793004522,
            "fpr": 0.017543859649122806,
            "logloss": 1.2686886964435657,
            "mae": 0.41398945057871805,
            "precision": 0.875968992248062,
            "recall": 0.23492723492723494
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.723952958549452,
            "auditor_fn_violation": 0.01220228218415746,
            "auditor_fp_violation": 0.005984692419890832,
            "ave_precision_score": 0.7246509519762819,
            "fpr": 0.026344676180021953,
            "logloss": 1.2358200571195537,
            "mae": 0.42081823260314266,
            "precision": 0.8208955223880597,
            "recall": 0.23255813953488372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8866073893002052,
            "auditor_fn_violation": 0.022725407593828652,
            "auditor_fp_violation": 0.008090120893882035,
            "ave_precision_score": 0.8867637037593887,
            "fpr": 0.09210526315789473,
            "logloss": 0.4903295785032,
            "mae": 0.2554858660719279,
            "precision": 0.8165938864628821,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8617222697416648,
            "auditor_fn_violation": 0.01728695321220786,
            "auditor_fp_violation": 0.012375381561734055,
            "ave_precision_score": 0.8619556086640799,
            "fpr": 0.10757409440175632,
            "logloss": 0.5188085660125488,
            "mae": 0.26726680122021473,
            "precision": 0.789247311827957,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 24481,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8421644154133695,
            "auditor_fn_violation": 0.008566765145712522,
            "auditor_fp_violation": 0.024565474009850617,
            "ave_precision_score": 0.8427142487728165,
            "fpr": 0.11732456140350878,
            "logloss": 0.7539799531390803,
            "mae": 0.26504575011985293,
            "precision": 0.773784355179704,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8190040408676857,
            "auditor_fn_violation": 0.013297656317082965,
            "auditor_fp_violation": 0.018848773739530554,
            "ave_precision_score": 0.8193702275311493,
            "fpr": 0.1350164654226125,
            "logloss": 0.8005180992148425,
            "mae": 0.2744164669711099,
            "precision": 0.7458677685950413,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8460006636589691,
            "auditor_fn_violation": 0.008644271802166542,
            "auditor_fp_violation": 0.021744107949688615,
            "ave_precision_score": 0.8465424394740392,
            "fpr": 0.12609649122807018,
            "logloss": 0.7598751644761664,
            "mae": 0.26193863983033533,
            "precision": 0.7657841140529531,
            "recall": 0.7817047817047817
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8226492546535465,
            "auditor_fn_violation": 0.009693596934808998,
            "auditor_fp_violation": 0.02154288778952328,
            "ave_precision_score": 0.8230082897217985,
            "fpr": 0.14709110867178923,
            "logloss": 0.8071182841344213,
            "mae": 0.2708741632888295,
            "precision": 0.7346534653465346,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.860762823724402,
            "auditor_fn_violation": 0.01005990808622388,
            "auditor_fp_violation": 0.020133715960434735,
            "ave_precision_score": 0.8619649078721611,
            "fpr": 0.11293859649122807,
            "logloss": 0.546703157734593,
            "mae": 0.26018960840883665,
            "precision": 0.7858627858627859,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8460664592191807,
            "auditor_fn_violation": 0.007953066003253635,
            "auditor_fp_violation": 0.01756311745334797,
            "ave_precision_score": 0.8463091689614161,
            "fpr": 0.13172338090010977,
            "logloss": 0.5720123175788006,
            "mae": 0.27487735784933087,
            "precision": 0.754601226993865,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 24481,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8462299803042495,
            "auditor_fn_violation": 0.006223328591749645,
            "auditor_fp_violation": 0.026180954125452845,
            "ave_precision_score": 0.8468611092233792,
            "fpr": 0.28289473684210525,
            "logloss": 1.2506897837701205,
            "mae": 0.3163982649640573,
            "precision": 0.6396648044692738,
            "recall": 0.9521829521829522
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8218448101453417,
            "auditor_fn_violation": 0.00817121254667524,
            "auditor_fp_violation": 0.03225919632698275,
            "ave_precision_score": 0.8221685127773737,
            "fpr": 0.27771679473106475,
            "logloss": 1.3086564884416274,
            "mae": 0.3177149524820384,
            "precision": 0.6375358166189111,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 24481,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8293928860836697,
            "auditor_fn_violation": 0.005815278841594631,
            "auditor_fp_violation": 0.011176069524158429,
            "ave_precision_score": 0.829829648592985,
            "fpr": 0.041666666666666664,
            "logloss": 1.0638282396581966,
            "mae": 0.32016773259326164,
            "precision": 0.8633093525179856,
            "recall": 0.498960498960499
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8067832739179308,
            "auditor_fn_violation": 0.012615368191913274,
            "auditor_fp_violation": 0.010225102626949159,
            "ave_precision_score": 0.8071167951290854,
            "fpr": 0.05817782656421515,
            "logloss": 1.0593842459290914,
            "mae": 0.33213585661481937,
            "precision": 0.8140350877192982,
            "recall": 0.4904862579281184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 24481,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8632434786085608,
            "auditor_fn_violation": 0.014840245103403005,
            "auditor_fp_violation": 0.014155167501119387,
            "ave_precision_score": 0.8644406684134318,
            "fpr": 0.07675438596491228,
            "logloss": 0.5682302110235029,
            "mae": 0.2732489801728502,
            "precision": 0.829683698296837,
            "recall": 0.7089397089397089
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.847280935791036,
            "auditor_fn_violation": 0.015189033262706458,
            "auditor_fp_violation": 0.012064618638758157,
            "ave_precision_score": 0.8475138460685294,
            "fpr": 0.09001097694840834,
            "logloss": 0.5892896657819771,
            "mae": 0.28631101564555833,
            "precision": 0.8009708737864077,
            "recall": 0.6976744186046512
        }
    }
]