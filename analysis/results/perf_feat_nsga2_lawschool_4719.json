[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.7063247229002215,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005182939534108431,
            "ave_precision_score": 0.7080067170809458,
            "fpr": 0.0010964912280701754,
            "logloss": 0.8271446783766109,
            "mae": 0.511733243585025,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8055892767573195,
            "mae": 0.4988988108450443,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6803992817105176,
            "auditor_fn_violation": 0.0022733769250008937,
            "auditor_fp_violation": 0.0018752344043005476,
            "ave_precision_score": 0.5796561090168884,
            "fpr": 0.4298245614035088,
            "logloss": 0.7039375108193725,
            "mae": 0.47886319585928794,
            "precision": 0.5489067894131185,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6432394007595725,
            "auditor_fn_violation": 0.0015457819356888343,
            "auditor_fp_violation": 0.006507762270660196,
            "ave_precision_score": 0.5460495067840179,
            "fpr": 0.4566410537870472,
            "logloss": 0.7191990603712014,
            "mae": 0.487852244914952,
            "precision": 0.5196304849884527,
            "recall": 0.9719222462203023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.4183705934047609,
            "auditor_fn_violation": 0.001304176939293253,
            "auditor_fp_violation": 0.006703962995374422,
            "ave_precision_score": 0.5432035409297176,
            "fpr": 0.015350877192982455,
            "logloss": 18.38759335166482,
            "mae": 0.5438144515807691,
            "precision": 0.3,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.44037246204848013,
            "auditor_fn_violation": 0.0012043822443710743,
            "auditor_fp_violation": 0.0038076289791437973,
            "ave_precision_score": 0.5115988560879776,
            "fpr": 0.012074643249176729,
            "logloss": 17.269261859898297,
            "mae": 0.5116782951956915,
            "precision": 0.35294117647058826,
            "recall": 0.012958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.6169024092526261,
            "auditor_fn_violation": 0.001159020259406163,
            "auditor_fp_violation": 0.0013803808809434515,
            "ave_precision_score": 0.6187548759046392,
            "fpr": 0.007675438596491228,
            "logloss": 0.8519891333502815,
            "mae": 0.5130083449511674,
            "precision": 0.4166666666666667,
            "recall": 0.010183299389002037
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6029287292269042,
            "auditor_fn_violation": 0.0008155659292591416,
            "auditor_fp_violation": 0.0032783832523130005,
            "ave_precision_score": 0.6045231921377222,
            "fpr": 0.006586169045005488,
            "logloss": 0.8261591519514087,
            "mae": 0.4984039387345707,
            "precision": 0.45454545454545453,
            "recall": 0.01079913606911447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.5481304643018152,
            "auditor_fn_violation": 0.003173348340300864,
            "auditor_fp_violation": 0.006750843855481936,
            "ave_precision_score": 0.5748657808433849,
            "fpr": 0.01864035087719298,
            "logloss": 0.8907376604164531,
            "mae": 0.51436832219591,
            "precision": 0.34615384615384615,
            "recall": 0.018329938900203666
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5552552278470381,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.003974243374627567,
            "ave_precision_score": 0.586803941134419,
            "fpr": 0.010976948408342482,
            "logloss": 0.9247133538827276,
            "mae": 0.49305031572915325,
            "precision": 0.5652173913043478,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8109813122831091,
            "auditor_fn_violation": 0.003461428520384461,
            "auditor_fp_violation": 0.016395278576488734,
            "ave_precision_score": 0.7822099349189794,
            "fpr": 0.09429824561403509,
            "logloss": 1.9201399845931348,
            "mae": 0.310868949836444,
            "precision": 0.7966903073286052,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7812395845755767,
            "auditor_fn_violation": 0.005000082979091642,
            "auditor_fp_violation": 0.00710071350164654,
            "ave_precision_score": 0.7499289835248003,
            "fpr": 0.11525795828759605,
            "logloss": 2.2267898696063386,
            "mae": 0.32738231985865585,
            "precision": 0.7445255474452555,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6461309245629594,
            "auditor_fn_violation": 0.06985386072104906,
            "auditor_fp_violation": 0.02102867025044797,
            "ave_precision_score": 0.655203116212645,
            "fpr": 0.0581140350877193,
            "logloss": 0.848097434921297,
            "mae": 0.48578139963118655,
            "precision": 0.7546296296296297,
            "recall": 0.3319755600814664
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6627670533870751,
            "auditor_fn_violation": 0.06219638543076818,
            "auditor_fp_violation": 0.014662066802571743,
            "ave_precision_score": 0.6514535517059504,
            "fpr": 0.04171240395170143,
            "logloss": 0.820975179884125,
            "mae": 0.46898502265190056,
            "precision": 0.7751479289940828,
            "recall": 0.28293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6978600615530598,
            "auditor_fn_violation": 0.10405947404151927,
            "auditor_fp_violation": 0.0751682501979414,
            "ave_precision_score": 0.6992396131860438,
            "fpr": 0.16337719298245615,
            "logloss": 0.686097501472812,
            "mae": 0.49244964818813297,
            "precision": 0.5940054495912807,
            "recall": 0.4439918533604888
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7038014724502287,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07665242276932728,
            "ave_precision_score": 0.7055222604190996,
            "fpr": 0.14489571899012074,
            "logloss": 0.6882619476111576,
            "mae": 0.49423512757544197,
            "precision": 0.5741935483870968,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7403465960149722,
            "auditor_fn_violation": 0.0044328616857826865,
            "auditor_fp_violation": 0.014064258032254034,
            "ave_precision_score": 0.741504350737151,
            "fpr": 0.20175438596491227,
            "logloss": 0.6865611644618274,
            "mae": 0.4966368925545299,
            "precision": 0.7041800643086816,
            "recall": 0.8920570264765784
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7063084425890636,
            "auditor_fn_violation": 0.003553875953370494,
            "auditor_fp_violation": 0.001852360043907796,
            "ave_precision_score": 0.707104362025732,
            "fpr": 0.2327113062568606,
            "logloss": 0.6876278424167612,
            "mae": 0.4971723878422893,
            "precision": 0.6597110754414125,
            "recall": 0.8876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5466790145491653,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5732325238724029,
            "fpr": 0.019736842105263157,
            "logloss": 0.9390066338958938,
            "mae": 0.518242700127558,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5550487342783418,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.5856172802798291,
            "fpr": 0.014270032930845226,
            "logloss": 0.968687345864087,
            "mae": 0.4951485000616175,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8130786190471768,
            "auditor_fn_violation": 0.0012438810876478459,
            "auditor_fp_violation": 0.014803933825061464,
            "ave_precision_score": 0.8057281551816522,
            "fpr": 0.09429824561403509,
            "logloss": 1.1972577557839699,
            "mae": 0.31080493372732027,
            "precision": 0.8,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.79372508512942,
            "auditor_fn_violation": 0.008617971374584218,
            "auditor_fp_violation": 0.006654774972557632,
            "ave_precision_score": 0.7884964045262992,
            "fpr": 0.11525795828759605,
            "logloss": 1.306490608044987,
            "mae": 0.3267890472880515,
            "precision": 0.7505938242280285,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.5483798734526261,
            "auditor_fn_violation": 0.0023738700110765825,
            "auditor_fp_violation": 0.005391298912364046,
            "ave_precision_score": 0.5744540923761076,
            "fpr": 0.015350877192982455,
            "logloss": 0.8739039780534319,
            "mae": 0.5125819188297579,
            "precision": 0.3,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5559706325613832,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0027246354084992943,
            "ave_precision_score": 0.5862871494520275,
            "fpr": 0.008781558726673985,
            "logloss": 0.9095307127525201,
            "mae": 0.492067162074255,
            "precision": 0.6190476190476191,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6914553397211638,
            "auditor_fn_violation": 0.0032470432700896857,
            "auditor_fp_violation": 0.03778597324665585,
            "ave_precision_score": 0.6753884136357882,
            "fpr": 0.16557017543859648,
            "logloss": 2.3965904108146088,
            "mae": 0.2952896938305393,
            "precision": 0.7182835820895522,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6546416107833454,
            "auditor_fn_violation": 0.006114373638253836,
            "auditor_fp_violation": 0.040732319272385124,
            "ave_precision_score": 0.629927653521672,
            "fpr": 0.19319429198682767,
            "logloss": 2.916065568525004,
            "mae": 0.31889303087486237,
            "precision": 0.6722532588454376,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.197985217770469,
            "mae": 0.5379223656371314,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.3304088489604373,
            "mae": 0.506664342319545,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6948696372930867,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0033337500520898684,
            "ave_precision_score": 0.6894569404057798,
            "fpr": 0.45285087719298245,
            "logloss": 2.955815472742878,
            "mae": 0.4474726751642792,
            "precision": 0.543141592920354,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7132769879498724,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.7086467338125491,
            "fpr": 0.4884742041712404,
            "logloss": 2.8134381277196034,
            "mae": 0.4789375514282746,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7014447321303263,
            "auditor_fn_violation": 0.1050242076678458,
            "auditor_fp_violation": 0.07395976580405884,
            "ave_precision_score": 0.7029794422377292,
            "fpr": 0.16557017543859648,
            "logloss": 0.6860515360024007,
            "mae": 0.49228334962798836,
            "precision": 0.5929919137466307,
            "recall": 0.4480651731160896
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6955066927433498,
            "auditor_fn_violation": 0.09548522616544136,
            "auditor_fp_violation": 0.07721107103653757,
            "ave_precision_score": 0.697005313095389,
            "fpr": 0.14928649835345773,
            "logloss": 0.6887896186225597,
            "mae": 0.4944187311453563,
            "precision": 0.5682539682539682,
            "recall": 0.38660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 4719,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.6602679435701144,
            "auditor_fn_violation": 0.0022108478936649248,
            "auditor_fp_violation": 0.0008126015751968999,
            "ave_precision_score": 0.6603423460179052,
            "fpr": 0.017543859649122806,
            "logloss": 0.6919374064699867,
            "mae": 0.498987470573762,
            "precision": 0.6097560975609756,
            "recall": 0.05091649694501019
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5789819542566428,
            "auditor_fn_violation": 0.005919965480697879,
            "auditor_fp_violation": 0.0024796142386702214,
            "ave_precision_score": 0.5782305084865015,
            "fpr": 0.03293084522502744,
            "logloss": 0.6947513117237977,
            "mae": 0.4988486203155455,
            "precision": 0.4117647058823529,
            "recall": 0.04535637149028078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8117899999309934,
            "auditor_fn_violation": 0.0015855575803051393,
            "auditor_fp_violation": 0.0128375421927741,
            "ave_precision_score": 0.8096633943546409,
            "fpr": 0.08881578947368421,
            "logloss": 1.0637685863168027,
            "mae": 0.3077094151607021,
            "precision": 0.8066825775656324,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7890208620855065,
            "auditor_fn_violation": 0.011870751766861944,
            "auditor_fp_violation": 0.008923671005174851,
            "ave_precision_score": 0.790800040650321,
            "fpr": 0.10867178924259056,
            "logloss": 1.2349964213792564,
            "mae": 0.3231083880799242,
            "precision": 0.7573529411764706,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6517411768948806,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6490330066618684,
            "fpr": 0.4616228070175439,
            "logloss": 2.2954121447758427,
            "mae": 0.43546785388076514,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.674510004011166,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6716785879097056,
            "fpr": 0.49176728869374314,
            "logloss": 2.2863750705445334,
            "mae": 0.45788681919305174,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.5752068977768093,
            "auditor_fn_violation": 0.0031621824418480164,
            "auditor_fp_violation": 0.00340667583447931,
            "ave_precision_score": 0.5770784510669988,
            "fpr": 0.007675438596491228,
            "logloss": 0.8950473764819534,
            "mae": 0.5150293210406968,
            "precision": 0.46153846153846156,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5537062847761527,
            "auditor_fn_violation": 0.0014059028954961526,
            "auditor_fp_violation": 0.0029157519209659713,
            "ave_precision_score": 0.5551511684229312,
            "fpr": 0.007683863885839737,
            "logloss": 0.8618258629868114,
            "mae": 0.4975481704041018,
            "precision": 0.5,
            "recall": 0.01511879049676026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5540450480988959,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5793907898105611,
            "fpr": 0.019736842105263157,
            "logloss": 0.8746502286927836,
            "mae": 0.5133053709328044,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5575689755139067,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.5866081124215682,
            "fpr": 0.014270032930845226,
            "logloss": 0.9093506198145561,
            "mae": 0.49265367284204514,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7054793554040208,
            "auditor_fn_violation": 0.0016145889162825597,
            "auditor_fp_violation": 0.005224611409759567,
            "ave_precision_score": 0.7064587844390279,
            "fpr": 0.39144736842105265,
            "logloss": 1.1707847492365204,
            "mae": 0.38134336051645507,
            "precision": 0.5744934445768772,
            "recall": 0.9816700610997964
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7115427571874461,
            "auditor_fn_violation": 0.0031745429630174044,
            "auditor_fp_violation": 0.013525168574564858,
            "ave_precision_score": 0.7127704687619894,
            "fpr": 0.40504939626783754,
            "logloss": 1.1698441093838479,
            "mae": 0.3939459611356062,
            "precision": 0.5505481120584653,
            "recall": 0.9762419006479481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8119139288458181,
            "auditor_fn_violation": 0.0023403723157180154,
            "auditor_fp_violation": 0.013522523648789433,
            "ave_precision_score": 0.782964308422859,
            "fpr": 0.10197368421052631,
            "logloss": 1.9305832124294378,
            "mae": 0.31181143919360166,
            "precision": 0.7895927601809954,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7790090617620308,
            "auditor_fn_violation": 0.0060788111704082395,
            "auditor_fp_violation": 0.00885506507762271,
            "ave_precision_score": 0.7440546826727691,
            "fpr": 0.12184412733260154,
            "logloss": 2.340293507502942,
            "mae": 0.3287730479739569,
            "precision": 0.7424593967517401,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5526984717708707,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5796679971327168,
            "fpr": 0.019736842105263157,
            "logloss": 0.9148704884580162,
            "mae": 0.5163649294623419,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5555047848330438,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.5875686139426333,
            "fpr": 0.014270032930845226,
            "logloss": 0.9467536821937543,
            "mae": 0.4945546449310301,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 4719,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6233616898659957,
            "auditor_fn_violation": 0.08149989280737487,
            "auditor_fp_violation": 0.06312247364253866,
            "ave_precision_score": 0.6247861538829758,
            "fpr": 0.18640350877192982,
            "logloss": 0.714485496901485,
            "mae": 0.48789057153759097,
            "precision": 0.621380846325167,
            "recall": 0.5682281059063137
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.630516267290387,
            "auditor_fn_violation": 0.07935409075067629,
            "auditor_fp_violation": 0.06764544456641054,
            "ave_precision_score": 0.6322664489435823,
            "fpr": 0.16245883644346873,
            "logloss": 0.6855838533995977,
            "mae": 0.4838766773991925,
            "precision": 0.6042780748663101,
            "recall": 0.48812095032397407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5582840701945208,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5852425358019159,
            "fpr": 0.019736842105263157,
            "logloss": 0.7500503081059481,
            "mae": 0.49899756455826655,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5589781291607092,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.590961513217237,
            "fpr": 0.014270032930845226,
            "logloss": 0.7986375060356693,
            "mae": 0.4862828380320912,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8140491470101248,
            "auditor_fn_violation": 0.0016927502054525372,
            "auditor_fp_violation": 0.0128375421927741,
            "ave_precision_score": 0.8097151166938167,
            "fpr": 0.08881578947368421,
            "logloss": 1.1207230853576977,
            "mae": 0.3068082690847442,
            "precision": 0.8080568720379147,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7920393930363461,
            "auditor_fn_violation": 0.012423155434063632,
            "auditor_fp_violation": 0.008923671005174851,
            "ave_precision_score": 0.7894029471969778,
            "fpr": 0.10867178924259056,
            "logloss": 1.2785512664193919,
            "mae": 0.32245367657555773,
            "precision": 0.7579462102689487,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7711442795080752,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.003750468808601074,
            "ave_precision_score": 0.5432285558828273,
            "fpr": 0.4517543859649123,
            "logloss": 15.63354211291105,
            "mae": 0.45285087719313283,
            "precision": 0.5432372505543237,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7549559471365639,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.5099118942731278,
            "fpr": 0.4884742041712404,
            "logloss": 16.871691895271205,
            "mae": 0.4884742041716563,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7139148131267512,
            "auditor_fn_violation": 0.0014337013613463395,
            "auditor_fp_violation": 0.003674938533983419,
            "ave_precision_score": 0.7148783819377874,
            "fpr": 0.40789473684210525,
            "logloss": 1.0658691740210084,
            "mae": 0.3905640206904265,
            "precision": 0.5649122807017544,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7213991991455336,
            "auditor_fn_violation": 0.0032029929372938857,
            "auditor_fp_violation": 0.009947859495060387,
            "ave_precision_score": 0.7226215260953253,
            "fpr": 0.42590559824368823,
            "logloss": 1.0354175449453054,
            "mae": 0.4033712677649426,
            "precision": 0.5391923990498813,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5582840701945208,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5852425358019159,
            "fpr": 0.019736842105263157,
            "logloss": 0.8429431726884296,
            "mae": 0.5101063281885887,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5589781291607092,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.590961513217237,
            "fpr": 0.014270032930845226,
            "logloss": 0.8811833167576236,
            "mae": 0.49138098931436874,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7829011699784212,
            "auditor_fn_violation": 0.004050987958695109,
            "auditor_fp_violation": 0.022734612659915828,
            "ave_precision_score": 0.7848693607481051,
            "fpr": 0.14144736842105263,
            "logloss": 1.0958905546928936,
            "mae": 0.27683103959056415,
            "precision": 0.7455621301775148,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7510540405755013,
            "auditor_fn_violation": 0.01630420609161366,
            "auditor_fp_violation": 0.014466049866708488,
            "ave_precision_score": 0.7509356902600715,
            "fpr": 0.16245883644346873,
            "logloss": 1.2168486468819266,
            "mae": 0.29519110142314947,
            "precision": 0.704,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6965445103662682,
            "auditor_fn_violation": 0.003599885661199842,
            "auditor_fp_violation": 0.037147872650748,
            "ave_precision_score": 0.6804638804031224,
            "fpr": 0.15789473684210525,
            "logloss": 2.3516492841561143,
            "mae": 0.29528526416190837,
            "precision": 0.7251908396946565,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6575666917534694,
            "auditor_fn_violation": 0.007849822069119213,
            "auditor_fp_violation": 0.04096753959542105,
            "ave_precision_score": 0.632645816585885,
            "fpr": 0.18660812294182216,
            "logloss": 2.9009901651192322,
            "mae": 0.3194136915689118,
            "precision": 0.6792452830188679,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7711442795080752,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.003750468808601074,
            "ave_precision_score": 0.5432285558828273,
            "fpr": 0.4517543859649123,
            "logloss": 15.63413302425335,
            "mae": 0.4528508771930661,
            "precision": 0.5432372505543237,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7549559471365639,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.5099118942731278,
            "fpr": 0.4884742041712404,
            "logloss": 16.871691895271013,
            "mae": 0.48847420417146187,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 4719,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.5741193504502522,
            "auditor_fn_violation": 0.005377496694894058,
            "auditor_fp_violation": 0.001651248072675752,
            "ave_precision_score": 0.5660683226159064,
            "fpr": 0.029605263157894735,
            "logloss": 0.6916644439985281,
            "mae": 0.49507108312345255,
            "precision": 0.5423728813559322,
            "recall": 0.06517311608961303
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5372752443510238,
            "auditor_fn_violation": 0.0010336823987121683,
            "auditor_fp_violation": 0.003937490199153208,
            "ave_precision_score": 0.5298841835406035,
            "fpr": 0.031833150384193196,
            "logloss": 0.6894639726597012,
            "mae": 0.4970170825343624,
            "precision": 0.49122807017543857,
            "recall": 0.06047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8176762179429503,
            "auditor_fn_violation": 0.003468128059456185,
            "auditor_fp_violation": 0.011944201358503147,
            "ave_precision_score": 0.8164382150041893,
            "fpr": 0.0800438596491228,
            "logloss": 1.0009318823379265,
            "mae": 0.30657589019277287,
            "precision": 0.8128205128205128,
            "recall": 0.6456211812627292
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7919923495295114,
            "auditor_fn_violation": 0.0041892587122119235,
            "auditor_fp_violation": 0.0024894150854633873,
            "ave_precision_score": 0.7918657569189596,
            "fpr": 0.09659714599341383,
            "logloss": 1.158891830136481,
            "mae": 0.3202668678838401,
            "precision": 0.7653333333333333,
            "recall": 0.6198704103671706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8131442212913731,
            "auditor_fn_violation": 0.00038634008646872345,
            "auditor_fp_violation": 0.01567643872150686,
            "ave_precision_score": 0.7842318218315985,
            "fpr": 0.09649122807017543,
            "logloss": 1.9275137767005779,
            "mae": 0.30316261288879087,
            "precision": 0.794392523364486,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7779889832171081,
            "auditor_fn_violation": 0.009535483045000749,
            "auditor_fp_violation": 0.008629645601379963,
            "ave_precision_score": 0.7432357069369157,
            "fpr": 0.1163556531284303,
            "logloss": 2.3332738099109234,
            "mae": 0.3200471234156047,
            "precision": 0.7464114832535885,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6334394652866163,
            "auditor_fn_violation": 0.0022733769250008937,
            "auditor_fp_violation": 0.0018752344043005476,
            "ave_precision_score": 0.5739143975171483,
            "fpr": 0.4298245614035088,
            "logloss": 0.7020880270877725,
            "mae": 0.4795172324306087,
            "precision": 0.5489067894131185,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5907762095305658,
            "auditor_fn_violation": 0.0015457819356888343,
            "auditor_fp_violation": 0.006507762270660196,
            "ave_precision_score": 0.5378303777296736,
            "fpr": 0.4566410537870472,
            "logloss": 0.7168514920699623,
            "mae": 0.48835535025230226,
            "precision": 0.5196304849884527,
            "recall": 0.9719222462203023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7101320924345593,
            "auditor_fn_violation": 0.0022465787687140472,
            "auditor_fp_violation": 0.007813476684585582,
            "ave_precision_score": 0.7115182839382967,
            "fpr": 0.40021929824561403,
            "logloss": 0.7372892574332652,
            "mae": 0.47968069666571783,
            "precision": 0.5659928656361475,
            "recall": 0.9694501018329938
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7042657847317197,
            "auditor_fn_violation": 0.0012423155434063639,
            "auditor_fp_violation": 0.008070997334169687,
            "ave_precision_score": 0.7058109723670112,
            "fpr": 0.4281009879253567,
            "logloss": 0.6898485465540024,
            "mae": 0.48149251892066813,
            "precision": 0.5346062052505967,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.5750518207549934,
            "auditor_fn_violation": 0.004160413763533087,
            "auditor_fp_violation": 0.004091657290494645,
            "ave_precision_score": 0.5769222687765891,
            "fpr": 0.013157894736842105,
            "logloss": 0.8623151776861081,
            "mae": 0.5131162956700122,
            "precision": 0.4782608695652174,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5537634218131378,
            "auditor_fn_violation": 0.0011451114646283992,
            "auditor_fp_violation": 0.003190175631174534,
            "ave_precision_score": 0.5552085924942154,
            "fpr": 0.014270032930845226,
            "logloss": 0.831929432863128,
            "mae": 0.4969034350909595,
            "precision": 0.38095238095238093,
            "recall": 0.017278617710583154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.6988047912060995,
            "auditor_fn_violation": 0.004875031264515671,
            "auditor_fp_violation": 0.035389840396716256,
            "ave_precision_score": 0.6832451566020656,
            "fpr": 0.15679824561403508,
            "logloss": 2.2923571935602283,
            "mae": 0.2938613454599909,
            "precision": 0.7270992366412213,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6604051930048191,
            "auditor_fn_violation": 0.007584288975872058,
            "auditor_fp_violation": 0.0389681668496158,
            "ave_precision_score": 0.6359048079042113,
            "fpr": 0.18441273326015367,
            "logloss": 2.8126765819484034,
            "mae": 0.3180954833873041,
            "precision": 0.6824196597353497,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7711442795080752,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.003750468808601074,
            "ave_precision_score": 0.5432285558828273,
            "fpr": 0.4517543859649123,
            "logloss": 15.641276409253674,
            "mae": 0.45285087719298245,
            "precision": 0.5432372505543237,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7549559471365639,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.5099118942731278,
            "fpr": 0.4884742041712404,
            "logloss": 16.87169189527079,
            "mae": 0.4884742041712404,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.7037377972171732,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0019299287410926367,
            "ave_precision_score": 0.7051684029623808,
            "fpr": 0.003289473684210526,
            "logloss": 0.7369169782562437,
            "mae": 0.5032500318790737,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6942478604839579,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005341461502273797,
            "ave_precision_score": 0.695727821749492,
            "fpr": 0.0010976948408342481,
            "logloss": 0.7248085552796061,
            "mae": 0.4958312721467044,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7778287069604048,
            "auditor_fn_violation": 0.005078250616357601,
            "auditor_fp_violation": 0.01891382256115348,
            "ave_precision_score": 0.7788182571969199,
            "fpr": 0.14144736842105263,
            "logloss": 1.0770025919522683,
            "mae": 0.2808647271444262,
            "precision": 0.7430278884462151,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7860091683176311,
            "auditor_fn_violation": 0.00294931399999526,
            "auditor_fp_violation": 0.012280461031833148,
            "ave_precision_score": 0.7865534274791012,
            "fpr": 0.15367727771679474,
            "logloss": 1.055405993837131,
            "mae": 0.2901793791572374,
            "precision": 0.717741935483871,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.703183380439201,
            "auditor_fn_violation": 0.10454184085468254,
            "auditor_fp_violation": 0.0751682501979414,
            "ave_precision_score": 0.7049025849084971,
            "fpr": 0.16337719298245615,
            "logloss": 0.6858031956975276,
            "mae": 0.4922577444660036,
            "precision": 0.595108695652174,
            "recall": 0.4460285132382892
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6965053547848201,
            "auditor_fn_violation": 0.09548522616544136,
            "auditor_fp_violation": 0.07663527128743923,
            "ave_precision_score": 0.697942118138121,
            "fpr": 0.14818880351262348,
            "logloss": 0.6883871382973255,
            "mae": 0.4942945266463492,
            "precision": 0.5700636942675159,
            "recall": 0.38660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7759566218074656,
            "auditor_fn_violation": 0.015165523278665096,
            "auditor_fp_violation": 0.019499833312497397,
            "ave_precision_score": 0.7763755919077648,
            "fpr": 0.12938596491228072,
            "logloss": 1.101577606947266,
            "mae": 0.3129422234152405,
            "precision": 0.739514348785872,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7578271123672551,
            "auditor_fn_violation": 0.009037608495162329,
            "auditor_fp_violation": 0.007340834248079035,
            "ave_precision_score": 0.7586751557678999,
            "fpr": 0.145993413830955,
            "logloss": 1.149887318628258,
            "mae": 0.3173011283897505,
            "precision": 0.7070484581497798,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6955849542569381,
            "auditor_fn_violation": 0.003599885661199842,
            "auditor_fp_violation": 0.037986519148226865,
            "ave_precision_score": 0.6795089444602431,
            "fpr": 0.16228070175438597,
            "logloss": 2.3505383121190166,
            "mae": 0.2945955107370033,
            "precision": 0.7196969696969697,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6559145337560259,
            "auditor_fn_violation": 0.005775344778125768,
            "auditor_fp_violation": 0.037632801474047364,
            "ave_precision_score": 0.6307979383674498,
            "fpr": 0.18990120746432493,
            "logloss": 2.936848560355833,
            "mae": 0.3193186363145504,
            "precision": 0.6772388059701493,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5580517737206192,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5842543350532389,
            "fpr": 0.019736842105263157,
            "logloss": 0.830690383322512,
            "mae": 0.5093018687166796,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5610794723639176,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.59138946557365,
            "fpr": 0.014270032930845226,
            "logloss": 0.8690636361351306,
            "mae": 0.49051569309801224,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.5734452969980383,
            "auditor_fn_violation": 0.011177064351305967,
            "auditor_fp_violation": 0.014759657457182157,
            "ave_precision_score": 0.5751965636340909,
            "fpr": 0.30372807017543857,
            "logloss": 1.1872368647536207,
            "mae": 0.481755661643431,
            "precision": 0.5790273556231003,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5404012161683687,
            "auditor_fn_violation": 0.011666860284547161,
            "auditor_fp_violation": 0.017367100517484718,
            "ave_precision_score": 0.5411146736768617,
            "fpr": 0.31833150384193193,
            "logloss": 1.1068839405168593,
            "mae": 0.4930632646944916,
            "precision": 0.5425867507886435,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 4719,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.618560420066313,
            "auditor_fn_violation": 0.005670043234358819,
            "auditor_fp_violation": 0.0012267158394799352,
            "ave_precision_score": 0.6197330335648497,
            "fpr": 0.021929824561403508,
            "logloss": 6.166867083638083,
            "mae": 0.5059148984565058,
            "precision": 0.6923076923076923,
            "recall": 0.09164969450101833
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5867367714182669,
            "auditor_fn_violation": 0.005343853501599147,
            "auditor_fp_violation": 0.0025041163556531287,
            "ave_precision_score": 0.5883060278816186,
            "fpr": 0.027442371020856202,
            "logloss": 5.709843064391895,
            "mae": 0.48205898757095017,
            "precision": 0.6575342465753424,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7155113336513925,
            "auditor_fn_violation": 0.001777611033694215,
            "auditor_fp_violation": 0.002409155311080554,
            "ave_precision_score": 0.7164701868098058,
            "fpr": 0.4199561403508772,
            "logloss": 1.0903984441360353,
            "mae": 0.3907177122146414,
            "precision": 0.5597701149425287,
            "recall": 0.9918533604887984
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7224150428327186,
            "auditor_fn_violation": 0.0025723518408318773,
            "auditor_fp_violation": 0.008747255762897926,
            "ave_precision_score": 0.7236281659274283,
            "fpr": 0.43798024149286496,
            "logloss": 1.066685052675344,
            "mae": 0.40451687227619726,
            "precision": 0.5338785046728972,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7090543178954094,
            "auditor_fn_violation": 0.021523385857719658,
            "auditor_fp_violation": 0.04618285619035714,
            "ave_precision_score": 0.7103277446429334,
            "fpr": 0.23793859649122806,
            "logloss": 0.7373700928898484,
            "mae": 0.4817729017190766,
            "precision": 0.6604068857589984,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7057172827205711,
            "auditor_fn_violation": 0.019862823707363565,
            "auditor_fp_violation": 0.05143974439391564,
            "ave_precision_score": 0.7072148581021372,
            "fpr": 0.2217343578485181,
            "logloss": 0.6866017176821679,
            "mae": 0.48187193320297383,
            "precision": 0.6576271186440678,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8120435484880345,
            "auditor_fn_violation": 0.004368099474756145,
            "auditor_fp_violation": 0.015715506104929784,
            "ave_precision_score": 0.7831792036336995,
            "fpr": 0.09100877192982457,
            "logloss": 1.9376295070580376,
            "mae": 0.31014980447524687,
            "precision": 0.7945544554455446,
            "recall": 0.6537678207739308
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7817852590777272,
            "auditor_fn_violation": 0.003689013331183784,
            "auditor_fp_violation": 0.007752469813391879,
            "ave_precision_score": 0.7504163473988748,
            "fpr": 0.10757409440175632,
            "logloss": 2.241567118135819,
            "mae": 0.32460278598497444,
            "precision": 0.7487179487179487,
            "recall": 0.6306695464362851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 4719,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5715193680234698,
            "auditor_fn_violation": 0.008968449637331642,
            "auditor_fp_violation": 0.011540505063132893,
            "ave_precision_score": 0.5734410639554129,
            "fpr": 0.06469298245614036,
            "logloss": 0.6956330085576856,
            "mae": 0.49882049829159913,
            "precision": 0.5874125874125874,
            "recall": 0.1710794297352342
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5471588818902473,
            "auditor_fn_violation": 0.007586659807061755,
            "auditor_fp_violation": 0.00424376666143955,
            "ave_precision_score": 0.548990142367463,
            "fpr": 0.0570801317233809,
            "logloss": 0.6895290280364033,
            "mae": 0.4970556363447045,
            "precision": 0.584,
            "recall": 0.15766738660907129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.4169449314903007,
            "auditor_fn_violation": 0.001304176939293253,
            "auditor_fp_violation": 0.006703962995374422,
            "ave_precision_score": 0.5419476006717406,
            "fpr": 0.015350877192982455,
            "logloss": 18.387858877794667,
            "mae": 0.5438645332071342,
            "precision": 0.3,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.4406380611214099,
            "auditor_fn_violation": 0.001970160718646367,
            "auditor_fp_violation": 0.0038076289791437973,
            "ave_precision_score": 0.5118664282650911,
            "fpr": 0.012074643249176729,
            "logloss": 17.268809967353043,
            "mae": 0.5114142958209753,
            "precision": 0.3888888888888889,
            "recall": 0.01511879049676026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7150761192175085,
            "auditor_fn_violation": 0.00822926715975276,
            "auditor_fp_violation": 0.005149081135141893,
            "ave_precision_score": 0.7143479851048904,
            "fpr": 0.03399122807017544,
            "logloss": 0.7714428060620242,
            "mae": 0.49275405606941175,
            "precision": 0.7651515151515151,
            "recall": 0.20570264765784113
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6968371949379477,
            "auditor_fn_violation": 0.011050444175223391,
            "auditor_fp_violation": 0.0040771522659557805,
            "ave_precision_score": 0.6974464488128624,
            "fpr": 0.043907793633369926,
            "logloss": 0.6963403470812557,
            "mae": 0.49026988899799395,
            "precision": 0.7452229299363057,
            "recall": 0.2526997840172786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.6908696889359528,
            "auditor_fn_violation": 0.0014471004394897597,
            "auditor_fp_violation": 0.0020731758136433723,
            "ave_precision_score": 0.6922372462138566,
            "fpr": 0.0043859649122807015,
            "logloss": 0.8863534839066977,
            "mae": 0.5162945678457618,
            "precision": 0.42857142857142855,
            "recall": 0.006109979633401222
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.6599790800484904,
            "auditor_fn_violation": 0.001422498713824088,
            "auditor_fp_violation": 0.0020336757095813078,
            "ave_precision_score": 0.6616574683544005,
            "fpr": 0.006586169045005488,
            "logloss": 0.8622076362769197,
            "mae": 0.5024688319271404,
            "precision": 0.25,
            "recall": 0.004319654427645789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7065136787096854,
            "auditor_fn_violation": 0.10309474041519279,
            "auditor_fp_violation": 0.07356648747760137,
            "ave_precision_score": 0.7078120019518649,
            "fpr": 0.1600877192982456,
            "logloss": 0.7205778546739826,
            "mae": 0.4893439736855119,
            "precision": 0.5966850828729282,
            "recall": 0.439918533604888
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7065394571022776,
            "auditor_fn_violation": 0.09512011816222651,
            "auditor_fp_violation": 0.07432962207934767,
            "ave_precision_score": 0.7080153846739847,
            "fpr": 0.14050493962678376,
            "logloss": 0.6880508820091498,
            "mae": 0.48546556878884034,
            "precision": 0.5816993464052288,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45723684210526316,
            "auc_prc": 0.5587552705301635,
            "auditor_fn_violation": 0.005073784256976459,
            "auditor_fp_violation": 0.007316018669000292,
            "ave_precision_score": 0.5590816658544242,
            "fpr": 0.044956140350877194,
            "logloss": 7.315159938046172,
            "mae": 0.5333820548624932,
            "precision": 0.47435897435897434,
            "recall": 0.07535641547861507
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5477637314534815,
            "auditor_fn_violation": 0.005870178025714048,
            "auditor_fp_violation": 0.0005022933981496011,
            "ave_precision_score": 0.5483869532000754,
            "fpr": 0.036223929747530186,
            "logloss": 6.756037333171735,
            "mae": 0.4958168399061371,
            "precision": 0.5875,
            "recall": 0.10151187904967603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.650960044564795,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.007193607534275118,
            "ave_precision_score": 0.6524197733580772,
            "fpr": 0.020833333333333332,
            "logloss": 0.8961524434937443,
            "mae": 0.512860163666406,
            "precision": 0.36666666666666664,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.6478822558266992,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.6494268742059066,
            "fpr": 0.014270032930845226,
            "logloss": 0.9294329392792767,
            "mae": 0.49125066458868144,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7146942689964829,
            "auditor_fn_violation": 0.001777611033694215,
            "auditor_fp_violation": 0.0025393799224903164,
            "ave_precision_score": 0.7156418953619537,
            "fpr": 0.4276315789473684,
            "logloss": 1.0983358342119074,
            "mae": 0.3932450087904407,
            "precision": 0.5553021664766249,
            "recall": 0.9918533604887984
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.721781679233058,
            "auditor_fn_violation": 0.0025723518408318773,
            "auditor_fp_violation": 0.00529245726830799,
            "ave_precision_score": 0.7229951262004387,
            "fpr": 0.4434687156970362,
            "logloss": 1.076814048337739,
            "mae": 0.40750509013067093,
            "precision": 0.5307781649245064,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.658702111361162,
            "auditor_fn_violation": 0.002751277378783033,
            "auditor_fp_violation": 0.0010678418135600294,
            "ave_precision_score": 0.6575641447679517,
            "fpr": 0.020833333333333332,
            "logloss": 0.6909581063598508,
            "mae": 0.4984991200137557,
            "precision": 0.6346153846153846,
            "recall": 0.06720977596741344
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5784883206212686,
            "auditor_fn_violation": 0.00283077244050992,
            "auditor_fp_violation": 0.005701642621922536,
            "ave_precision_score": 0.5777878004006443,
            "fpr": 0.036223929747530186,
            "logloss": 0.6945110458228401,
            "mae": 0.4986960808087128,
            "precision": 0.45,
            "recall": 0.058315334773218146
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7711442795080752,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.003750468808601074,
            "ave_precision_score": 0.5432285558828273,
            "fpr": 0.4517543859649123,
            "logloss": 15.634292720192041,
            "mae": 0.45285087719305606,
            "precision": 0.5432372505543237,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7549559471365639,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.5099118942731278,
            "fpr": 0.4884742041712404,
            "logloss": 16.87169189527099,
            "mae": 0.4884742041714376,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8115145628373543,
            "auditor_fn_violation": 0.005911226640940441,
            "auditor_fp_violation": 0.01614785181481019,
            "ave_precision_score": 0.782564943810762,
            "fpr": 0.09320175438596491,
            "logloss": 1.9372549001743584,
            "mae": 0.3120908910033232,
            "precision": 0.7980997624703088,
            "recall": 0.6843177189409368
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7787472502483267,
            "auditor_fn_violation": 0.006258994340825958,
            "auditor_fp_violation": 0.00710071350164654,
            "ave_precision_score": 0.7437960860561801,
            "fpr": 0.11525795828759605,
            "logloss": 2.343488522104298,
            "mae": 0.3276660300430234,
            "precision": 0.7457627118644068,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7156858190300687,
            "auditor_fn_violation": 0.007351627541358493,
            "auditor_fp_violation": 0.002620119181564363,
            "ave_precision_score": 0.705730493074324,
            "fpr": 0.03289473684210526,
            "logloss": 3.0854597845406713,
            "mae": 0.4746357479198998,
            "precision": 0.7272727272727273,
            "recall": 0.1629327902240326
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7109164498698279,
            "auditor_fn_violation": 0.008454384022494463,
            "auditor_fp_violation": 0.005552179708326799,
            "ave_precision_score": 0.6996856093619827,
            "fpr": 0.03293084522502744,
            "logloss": 2.858065167946232,
            "mae": 0.4324038129520489,
            "precision": 0.7540983606557377,
            "recall": 0.19870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.715818999771087,
            "auditor_fn_violation": 0.005962589773823585,
            "auditor_fp_violation": 0.00399268658582323,
            "ave_precision_score": 0.7058643989552928,
            "fpr": 0.03399122807017544,
            "logloss": 2.9684062212718354,
            "mae": 0.46678472907566804,
            "precision": 0.7459016393442623,
            "recall": 0.18533604887983707
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7110804594232398,
            "auditor_fn_violation": 0.010969835914773364,
            "auditor_fp_violation": 0.005410067429825939,
            "ave_precision_score": 0.6998479672127459,
            "fpr": 0.03512623490669594,
            "logloss": 2.7515096538057335,
            "mae": 0.42299569632635065,
            "precision": 0.7697841726618705,
            "recall": 0.23110151187904968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7753731771802661,
            "auditor_fn_violation": 0.017823007110444142,
            "auditor_fp_violation": 0.021320373380005843,
            "ave_precision_score": 0.7758097304023072,
            "fpr": 0.13486842105263158,
            "logloss": 1.0968096812071357,
            "mae": 0.3058717267637935,
            "precision": 0.740506329113924,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7530476137413897,
            "auditor_fn_violation": 0.01430085373631142,
            "auditor_fp_violation": 0.008722753645915009,
            "ave_precision_score": 0.7540777138959109,
            "fpr": 0.15697036223929747,
            "logloss": 1.163955151586115,
            "mae": 0.31724076560455344,
            "precision": 0.7020833333333333,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6950057600034444,
            "auditor_fn_violation": 0.10454184085468254,
            "auditor_fp_violation": 0.0751682501979414,
            "ave_precision_score": 0.6963820981783689,
            "fpr": 0.16337719298245615,
            "logloss": 0.6860923215118923,
            "mae": 0.49235154649144725,
            "precision": 0.595108695652174,
            "recall": 0.4460285132382892
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6999182697265871,
            "auditor_fn_violation": 0.09548522616544136,
            "auditor_fp_violation": 0.07548367178924258,
            "ave_precision_score": 0.7015040342936559,
            "fpr": 0.145993413830955,
            "logloss": 0.6883223491709382,
            "mae": 0.49421261373649705,
            "precision": 0.5737179487179487,
            "recall": 0.38660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.41753895728799245,
            "auditor_fn_violation": 0.001304176939293253,
            "auditor_fp_violation": 0.006703962995374422,
            "ave_precision_score": 0.5424567656411907,
            "fpr": 0.015350877192982455,
            "logloss": 18.386951432545253,
            "mae": 0.543640314127531,
            "precision": 0.3,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.4406380611214099,
            "auditor_fn_violation": 0.001970160718646367,
            "auditor_fp_violation": 0.0038076289791437973,
            "ave_precision_score": 0.5118664282650911,
            "fpr": 0.012074643249176729,
            "logloss": 17.26827624700461,
            "mae": 0.5112885506956559,
            "precision": 0.3888888888888889,
            "recall": 0.01511879049676026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0.5463502898371744,
            "auditor_fn_violation": 0.004046521599313964,
            "auditor_fp_violation": 0.006078884860607576,
            "ave_precision_score": 0.5473859285026147,
            "fpr": 0.025219298245614034,
            "logloss": 11.242369722397877,
            "mae": 0.5457476047965886,
            "precision": 0.39473684210526316,
            "recall": 0.03054989816700611
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.5266296986400893,
            "auditor_fn_violation": 0.00388105065755005,
            "auditor_fp_violation": 0.002197839893366787,
            "ave_precision_score": 0.5275546578689954,
            "fpr": 0.027442371020856202,
            "logloss": 10.602858364635328,
            "mae": 0.5220052154767885,
            "precision": 0.3055555555555556,
            "recall": 0.023758099352051837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0.5693934484207719,
            "auditor_fn_violation": 0.0019919962839890022,
            "auditor_fp_violation": 0.007097241321831896,
            "ave_precision_score": 0.5708312423317956,
            "fpr": 0.01425438596491228,
            "logloss": 0.9004717003733609,
            "mae": 0.5181621252058743,
            "precision": 0.23529411764705882,
            "recall": 0.008146639511201629
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5744071633984213,
            "auditor_fn_violation": 0.0003888163151119181,
            "auditor_fp_violation": 0.002633977575662537,
            "ave_precision_score": 0.5763482136633166,
            "fpr": 0.005488474204171241,
            "logloss": 0.8552352945386634,
            "mae": 0.4968447974042427,
            "precision": 0.375,
            "recall": 0.0064794816414686825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.616466666521218,
            "auditor_fn_violation": 0.0012371815485761382,
            "auditor_fp_violation": 0.0013803808809434515,
            "ave_precision_score": 0.618321836217429,
            "fpr": 0.007675438596491228,
            "logloss": 0.8467038054904785,
            "mae": 0.5127927854232359,
            "precision": 0.46153846153846156,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6028048053440639,
            "auditor_fn_violation": 0.0008155659292591416,
            "auditor_fp_violation": 0.0032783832523130005,
            "ave_precision_score": 0.6043950338318669,
            "fpr": 0.006586169045005488,
            "logloss": 0.8212248606849986,
            "mae": 0.49841514051483965,
            "precision": 0.45454545454545453,
            "recall": 0.01079913606911447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7765134847114056,
            "auditor_fn_violation": 0.00983492335727302,
            "auditor_fp_violation": 0.02352637829728716,
            "ave_precision_score": 0.7796505233586833,
            "fpr": 0.21271929824561403,
            "logloss": 1.2884950683456904,
            "mae": 0.28115801811022306,
            "precision": 0.6910828025477707,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7485324271732259,
            "auditor_fn_violation": 0.009077912625387334,
            "auditor_fp_violation": 0.03131370550415557,
            "ave_precision_score": 0.7471388485054831,
            "fpr": 0.24478594950603733,
            "logloss": 1.5254281919600434,
            "mae": 0.3083537932260172,
            "precision": 0.6454689984101749,
            "recall": 0.8768898488120951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7177420107328342,
            "auditor_fn_violation": 0.005408761210562056,
            "auditor_fp_violation": 0.004224486394132602,
            "ave_precision_score": 0.707784204271627,
            "fpr": 0.029605263157894735,
            "logloss": 3.2414044750954396,
            "mae": 0.4815116341843809,
            "precision": 0.7065217391304348,
            "recall": 0.13238289205702647
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.712576556300057,
            "auditor_fn_violation": 0.0015789735723447402,
            "auditor_fp_violation": 0.006350948721969578,
            "ave_precision_score": 0.7013413774885868,
            "fpr": 0.026344676180021953,
            "logloss": 2.998183263637971,
            "mae": 0.43968085796998513,
            "precision": 0.7669902912621359,
            "recall": 0.17062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.542337461934854,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5691813092462868,
            "fpr": 0.019736842105263157,
            "logloss": 1.1972145801178975,
            "mae": 0.5302375185940611,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5445558429611584,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.576909456891453,
            "fpr": 0.014270032930845226,
            "logloss": 1.2079095668298296,
            "mae": 0.5017230155766338,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.7037185428252783,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0009167812643247073,
            "ave_precision_score": 0.7051491618389802,
            "fpr": 0.0021929824561403508,
            "logloss": 0.7569290128506165,
            "mae": 0.5059206489669649,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.6943044324706128,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005341461502273797,
            "ave_precision_score": 0.695784363671008,
            "fpr": 0.0010976948408342481,
            "logloss": 0.7423625086281486,
            "mae": 0.497007446120259,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6323840467922859,
            "auditor_fn_violation": 0.0013555400721763677,
            "auditor_fp_violation": 0.005922615326915871,
            "ave_precision_score": 0.5728952480154603,
            "fpr": 0.43969298245614036,
            "logloss": 0.682302378676995,
            "mae": 0.48839333561951653,
            "precision": 0.5463800904977375,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.592109843841477,
            "auditor_fn_violation": 0.003734059123788209,
            "auditor_fp_violation": 0.004407930845225016,
            "ave_precision_score": 0.5386708932054225,
            "fpr": 0.46871569703622395,
            "logloss": 0.6885202798370047,
            "mae": 0.4922703154524124,
            "precision": 0.5153234960272418,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45723684210526316,
            "auc_prc": 0.5487663082056534,
            "auditor_fn_violation": 0.0010897916889984775,
            "auditor_fp_violation": 0.0032399883318748185,
            "ave_precision_score": 0.5747023439028353,
            "fpr": 0.009868421052631578,
            "logloss": 0.8419039761113815,
            "mae": 0.5098314241571515,
            "precision": 0.35714285714285715,
            "recall": 0.010183299389002037
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5570331492966881,
            "auditor_fn_violation": 0.0029256056880981843,
            "auditor_fp_violation": 0.002707483926611259,
            "ave_precision_score": 0.5871950794636058,
            "fpr": 0.005488474204171241,
            "logloss": 0.8801284726066589,
            "mae": 0.4907448313860417,
            "precision": 0.6666666666666666,
            "recall": 0.02159827213822894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7390846559461137,
            "auditor_fn_violation": 0.003905831278808021,
            "auditor_fp_violation": 0.0173875901154311,
            "ave_precision_score": 0.7402421044187024,
            "fpr": 0.25,
            "logloss": 0.6880041276983635,
            "mae": 0.49737894381478165,
            "precision": 0.6651982378854625,
            "recall": 0.9226069246435845
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7050828573277075,
            "auditor_fn_violation": 0.00358706759002639,
            "auditor_fp_violation": 0.0035724086561079002,
            "ave_precision_score": 0.7058762957208695,
            "fpr": 0.27991218441273324,
            "logloss": 0.6889396781247712,
            "mae": 0.4978480999543036,
            "precision": 0.6244477172312224,
            "recall": 0.9157667386609071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8114457664680312,
            "auditor_fn_violation": 0.004365866295065565,
            "auditor_fp_violation": 0.015746760011668127,
            "ave_precision_score": 0.7817300299965639,
            "fpr": 0.09758771929824561,
            "logloss": 1.97181608756659,
            "mae": 0.3102481160650825,
            "precision": 0.7915690866510539,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7805446381586812,
            "auditor_fn_violation": 0.008466238178442985,
            "auditor_fp_violation": 0.007835777011133771,
            "ave_precision_score": 0.7453193491118709,
            "fpr": 0.1163556531284303,
            "logloss": 2.3690056262028563,
            "mae": 0.3261753969814545,
            "precision": 0.747016706443914,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7134125341696143,
            "auditor_fn_violation": 0.0016145889162825597,
            "auditor_fp_violation": 0.0018491894820185885,
            "ave_precision_score": 0.7143736486248187,
            "fpr": 0.39364035087719296,
            "logloss": 1.0478195902051808,
            "mae": 0.38439720145246964,
            "precision": 0.5731272294887039,
            "recall": 0.9816700610997964
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7208297359905451,
            "auditor_fn_violation": 0.0031484638199306297,
            "auditor_fp_violation": 0.0130620785635879,
            "ave_precision_score": 0.7220529011323886,
            "fpr": 0.411635565312843,
            "logloss": 1.01727372613115,
            "mae": 0.39625987300953935,
            "precision": 0.5465538089480049,
            "recall": 0.9762419006479481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7711479065460083,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.003750468808601074,
            "ave_precision_score": 0.5432321826278962,
            "fpr": 0.4517543859649123,
            "logloss": 15.641276409253674,
            "mae": 0.45285087719298245,
            "precision": 0.5432372505543237,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7549559471365639,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.5099118942731278,
            "fpr": 0.4884742041712404,
            "logloss": 16.87169189527079,
            "mae": 0.4884742041712404,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7046768568776692,
            "auditor_fn_violation": 0.0013466073534140856,
            "auditor_fp_violation": 0.006188273534191779,
            "ave_precision_score": 0.7056387604822119,
            "fpr": 0.3717105263157895,
            "logloss": 1.1585413292543525,
            "mae": 0.3774607806270452,
            "precision": 0.5860805860805861,
            "recall": 0.9775967413441955
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7100190582341058,
            "auditor_fn_violation": 0.0014201278826343731,
            "auditor_fp_violation": 0.015676454445664123,
            "ave_precision_score": 0.7112472034663325,
            "fpr": 0.3940724478594951,
            "logloss": 1.1625284551292696,
            "mae": 0.39142023405606086,
            "precision": 0.5545905707196029,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.724814395737685,
            "auditor_fn_violation": 0.003347536356165387,
            "auditor_fp_violation": 0.0011329541192649103,
            "ave_precision_score": 0.7148469352349259,
            "fpr": 0.03399122807017544,
            "logloss": 2.763213863556588,
            "mae": 0.4498107964862966,
            "precision": 0.7720588235294118,
            "recall": 0.21384928716904278
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7204036672949998,
            "auditor_fn_violation": 0.012560663643066631,
            "auditor_fp_violation": 0.007066410537870474,
            "ave_precision_score": 0.7091513845632903,
            "fpr": 0.03402854006586169,
            "logloss": 2.566760600145118,
            "mae": 0.4045187658001755,
            "precision": 0.7973856209150327,
            "recall": 0.2634989200863931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 4719,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.567665822413858,
            "auditor_fn_violation": 0.002195215635830913,
            "auditor_fp_violation": 0.0034665791557278005,
            "ave_precision_score": 0.56954883355928,
            "fpr": 0.020833333333333332,
            "logloss": 0.7066461686757239,
            "mae": 0.500131719786543,
            "precision": 0.5869565217391305,
            "recall": 0.054989816700611
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5325845514388965,
            "auditor_fn_violation": 0.003508830160766056,
            "auditor_fp_violation": 0.004493688254665204,
            "ave_precision_score": 0.5339275576169824,
            "fpr": 0.024149286498353458,
            "logloss": 0.6989379331723595,
            "mae": 0.4987292613130795,
            "precision": 0.5217391304347826,
            "recall": 0.05183585313174946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7711479065460083,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.003750468808601074,
            "ave_precision_score": 0.5432321826278962,
            "fpr": 0.4517543859649123,
            "logloss": 15.641276409253674,
            "mae": 0.45285087719298245,
            "precision": 0.5432372505543237,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7549559471365639,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.5099118942731278,
            "fpr": 0.4884742041712404,
            "logloss": 16.87169189527079,
            "mae": 0.4884742041712404,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6318751672362364,
            "auditor_fn_violation": 0.0022733769250008937,
            "auditor_fp_violation": 0.0018752344043005476,
            "ave_precision_score": 0.5737153183839139,
            "fpr": 0.4298245614035088,
            "logloss": 0.7033347126159019,
            "mae": 0.47928716376293123,
            "precision": 0.5489067894131185,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5895986057539045,
            "auditor_fn_violation": 0.0015457819356888343,
            "auditor_fp_violation": 0.006507762270660196,
            "ave_precision_score": 0.537794110276377,
            "fpr": 0.4566410537870472,
            "logloss": 0.7184072942747937,
            "mae": 0.48827613109945595,
            "precision": 0.5196304849884527,
            "recall": 0.9719222462203023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6956161881709276,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0033337500520898684,
            "ave_precision_score": 0.6902508779298251,
            "fpr": 0.45285087719298245,
            "logloss": 2.9093716862676544,
            "mae": 0.4471391346305609,
            "precision": 0.543141592920354,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.7134977300701626,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016097890857770189,
            "ave_precision_score": 0.7088980486486642,
            "fpr": 0.4884742041712404,
            "logloss": 2.7841679844870137,
            "mae": 0.47841857129996224,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.5600775415210316,
            "auditor_fn_violation": 0.008457051488190944,
            "auditor_fp_violation": 0.00550329207817644,
            "ave_precision_score": 0.5602057692044857,
            "fpr": 0.049342105263157895,
            "logloss": 6.576205904584081,
            "mae": 0.5252116226118018,
            "precision": 0.5360824742268041,
            "recall": 0.10590631364562118
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.551692825003334,
            "auditor_fn_violation": 0.0022973354228258934,
            "auditor_fp_violation": 0.0029157519209659717,
            "ave_precision_score": 0.5515960033235076,
            "fpr": 0.04061470911086718,
            "logloss": 6.085478667460836,
            "mae": 0.4878707303926536,
            "precision": 0.6145833333333334,
            "recall": 0.12742980561555076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.696628700694518,
            "auditor_fn_violation": 0.003599885661199842,
            "auditor_fp_violation": 0.03732237363003709,
            "ave_precision_score": 0.6805359221468145,
            "fpr": 0.1611842105263158,
            "logloss": 2.3318196556884923,
            "mae": 0.2944208247960525,
            "precision": 0.7210626185958254,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6570325206757756,
            "auditor_fn_violation": 0.0061404527813406105,
            "auditor_fp_violation": 0.03651795515132508,
            "ave_precision_score": 0.6321069655708866,
            "fpr": 0.18880351262349068,
            "logloss": 2.895086009053706,
            "mae": 0.31918345485574223,
            "precision": 0.6779026217228464,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.777646400519142,
            "auditor_fn_violation": 0.007570479151034415,
            "auditor_fp_violation": 0.01891382256115348,
            "ave_precision_score": 0.7789761590254968,
            "fpr": 0.14144736842105263,
            "logloss": 1.075287883786846,
            "mae": 0.2808518472476299,
            "precision": 0.7435387673956262,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7854658213200049,
            "auditor_fn_violation": 0.00294931399999526,
            "auditor_fp_violation": 0.012273110396738274,
            "ave_precision_score": 0.786030348540379,
            "fpr": 0.15477497255762898,
            "logloss": 1.0511417342277014,
            "mae": 0.289947099627541,
            "precision": 0.716297786720322,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8115878467384314,
            "auditor_fn_violation": 0.002157251581091226,
            "auditor_fp_violation": 0.013522523648789432,
            "ave_precision_score": 0.8036498189039976,
            "fpr": 0.09100877192982457,
            "logloss": 1.2039241770063642,
            "mae": 0.3073038401682256,
            "precision": 0.8037825059101655,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7927136447380988,
            "auditor_fn_violation": 0.012423155434063632,
            "auditor_fp_violation": 0.007725517484710681,
            "ave_precision_score": 0.7868755546748802,
            "fpr": 0.11086717892425905,
            "logloss": 1.330512802275224,
            "mae": 0.32314341153522186,
            "precision": 0.754257907542579,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6362905487065978,
            "auditor_fn_violation": 0.09007753599885662,
            "auditor_fp_violation": 0.05900216693753386,
            "ave_precision_score": 0.6380981160013621,
            "fpr": 0.17324561403508773,
            "logloss": 0.679705171453965,
            "mae": 0.48483558718049735,
            "precision": 0.6098765432098765,
            "recall": 0.5030549898167006
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.632865526603629,
            "auditor_fn_violation": 0.0813171389757535,
            "auditor_fp_violation": 0.06764544456641054,
            "ave_precision_score": 0.634042617387605,
            "fpr": 0.16245883644346873,
            "logloss": 0.6805337391051794,
            "mae": 0.4874646805316766,
            "precision": 0.5842696629213483,
            "recall": 0.44924406047516197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.5582840701945208,
            "auditor_fn_violation": 0.004611516061028343,
            "auditor_fp_violation": 0.0062273409176147035,
            "ave_precision_score": 0.5852425358019159,
            "fpr": 0.019736842105263157,
            "logloss": 0.7984860772206137,
            "mae": 0.5058074845818051,
            "precision": 0.3793103448275862,
            "recall": 0.02240325865580448
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5594509727396914,
            "auditor_fn_violation": 0.0027288266993525474,
            "auditor_fp_violation": 0.0018523600439077942,
            "ave_precision_score": 0.5914437899605375,
            "fpr": 0.014270032930845226,
            "logloss": 0.841244417055854,
            "mae": 0.48951541088546013,
            "precision": 0.5,
            "recall": 0.028077753779697623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7130277819614719,
            "auditor_fn_violation": 0.001777611033694215,
            "auditor_fp_violation": 0.005938242280285044,
            "ave_precision_score": 0.7139898331511125,
            "fpr": 0.41885964912280704,
            "logloss": 1.1044174259506987,
            "mae": 0.3905429829957715,
            "precision": 0.5604142692750288,
            "recall": 0.9918533604887984
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7202538880203198,
            "auditor_fn_violation": 0.0025723518408318773,
            "auditor_fp_violation": 0.008747255762897926,
            "ave_precision_score": 0.721436506236119,
            "fpr": 0.43798024149286496,
            "logloss": 1.085455274482359,
            "mae": 0.4043584037429022,
            "precision": 0.5338785046728972,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7251735436881434,
            "auditor_fn_violation": 0.008919319684139077,
            "auditor_fp_violation": 0.002312789098637332,
            "ave_precision_score": 0.7152050201208576,
            "fpr": 0.03728070175438596,
            "logloss": 2.681669471103949,
            "mae": 0.44399588005098184,
            "precision": 0.7748344370860927,
            "recall": 0.23828920570264767
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7203427936985604,
            "auditor_fn_violation": 0.01642511848228872,
            "auditor_fp_violation": 0.004861220009408814,
            "ave_precision_score": 0.7090899976748963,
            "fpr": 0.03512623490669594,
            "logloss": 2.491936855447912,
            "mae": 0.39896451845368164,
            "precision": 0.803680981595092,
            "recall": 0.28293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6517695699521281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6490677248242531,
            "fpr": 0.4616228070175439,
            "logloss": 2.300820559174532,
            "mae": 0.43579654565505815,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6745563768158704,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6717103129087065,
            "fpr": 0.49176728869374314,
            "logloss": 2.2917695647622587,
            "mae": 0.45825107554311156,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8112082878492374,
            "auditor_fn_violation": 0.003461428520384461,
            "auditor_fp_violation": 0.015986373296662085,
            "ave_precision_score": 0.7815245997907503,
            "fpr": 0.09649122807017543,
            "logloss": 1.9675245217391115,
            "mae": 0.31068345140068326,
            "precision": 0.7929411764705883,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7801949906442561,
            "auditor_fn_violation": 0.008466238178442985,
            "auditor_fp_violation": 0.007835777011133771,
            "ave_precision_score": 0.745020423525295,
            "fpr": 0.1163556531284303,
            "logloss": 2.3616574529984393,
            "mae": 0.32652667418211334,
            "precision": 0.747016706443914,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7859020979879151,
            "auditor_fn_violation": 0.005645478257762534,
            "auditor_fp_violation": 0.019208130182939535,
            "ave_precision_score": 0.7873036326672164,
            "fpr": 0.13267543859649122,
            "logloss": 1.086136264172047,
            "mae": 0.2792261462776835,
            "precision": 0.753061224489796,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7552406359231656,
            "auditor_fn_violation": 0.016282868610906304,
            "auditor_fp_violation": 0.015566194919241019,
            "ave_precision_score": 0.7554182371648963,
            "fpr": 0.15477497255762898,
            "logloss": 1.191750698469354,
            "mae": 0.2939008398264602,
            "precision": 0.7116564417177914,
            "recall": 0.7516198704103672
        }
    }
]