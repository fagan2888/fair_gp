[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 22571,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.6546774872256411,
            "auditor_fn_violation": 0.005571420945873823,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.5930193429175568,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6808038092263159,
            "mae": 0.4843441685171504,
            "precision": 0.9,
            "recall": 0.07302231237322515
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6457053256275387,
            "auditor_fn_violation": 0.006919525395801144,
            "auditor_fp_violation": 0.0005464080985486035,
            "ave_precision_score": 0.5621455919603406,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6633003121031935,
            "mae": 0.47698300828263734,
            "precision": 0.9772727272727273,
            "recall": 0.09327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5578370718056238,
            "auditor_fn_violation": 0.010173125511547634,
            "auditor_fp_violation": 0.010661349076749161,
            "ave_precision_score": 0.5438274856714524,
            "fpr": 0.38377192982456143,
            "logloss": 1.9600342103426212,
            "mae": 0.4861324604012464,
            "precision": 0.5394736842105263,
            "recall": 0.8316430020283976
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5181882886927278,
            "auditor_fn_violation": 0.0033978536613242347,
            "auditor_fp_violation": 0.012757653372362489,
            "ave_precision_score": 0.5067539537341625,
            "fpr": 0.4094401756311745,
            "logloss": 1.7952941751805838,
            "mae": 0.498331865449114,
            "precision": 0.5072655217965654,
            "recall": 0.8329718004338394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8498392264577559,
            "auditor_fn_violation": 0.004615049286502257,
            "auditor_fp_violation": 0.010352552024452547,
            "ave_precision_score": 0.8500561484686946,
            "fpr": 0.12609649122807018,
            "logloss": 0.6063042920245625,
            "mae": 0.28065497743720796,
            "precision": 0.7672064777327935,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8382408141731779,
            "auditor_fn_violation": 0.006745703870029124,
            "auditor_fp_violation": 0.014084644468837674,
            "ave_precision_score": 0.8382998227055238,
            "fpr": 0.1394072447859495,
            "logloss": 0.6076729033367899,
            "mae": 0.2844066253011996,
            "precision": 0.7397540983606558,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7782495013731112,
            "auditor_fn_violation": 0.00232420554428668,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6188188943692499,
            "fpr": 0.4331140350877193,
            "logloss": 0.6736508606081378,
            "mae": 0.4595641862404974,
            "precision": 0.5475372279495991,
            "recall": 0.9695740365111561
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7859554893015747,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.618271149449305,
            "fpr": 0.45334796926454446,
            "logloss": 0.670413109302586,
            "mae": 0.4549490607923263,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.7142210232879398,
            "auditor_fn_violation": 0.002442083911604569,
            "auditor_fp_violation": 0.00048413097182096066,
            "ave_precision_score": 0.7053551461896332,
            "fpr": 0.0010964912280701754,
            "logloss": 0.688160534582607,
            "mae": 0.49367514046791355,
            "precision": 0.9285714285714286,
            "recall": 0.02636916835699797
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.6986060391238131,
            "auditor_fn_violation": 0.004895576123113272,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6877688021431393,
            "fpr": 0.0,
            "logloss": 0.6806283657306607,
            "mae": 0.4909292867756832,
            "precision": 1.0,
            "recall": 0.03253796095444685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7839703575458279,
            "auditor_fn_violation": 0.0028691149781146586,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6254379428031391,
            "fpr": 0.4331140350877193,
            "logloss": 0.6620955505278067,
            "mae": 0.45670418565471965,
            "precision": 0.5480549199084668,
            "recall": 0.9716024340770791
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7908614237669835,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.6253484587457282,
            "fpr": 0.45334796926454446,
            "logloss": 0.6566105917124251,
            "mae": 0.4508286575519947,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 22571,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.7750155987574667,
            "auditor_fn_violation": 0.002624461762926609,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5500311975149335,
            "fpr": 0.0,
            "logloss": 0.6900153118585792,
            "mae": 0.4971036068572287,
            "precision": 1.0,
            "recall": 0.014198782961460446
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7616200417761799,
            "auditor_fn_violation": 0.005340844963104606,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5243042634492088,
            "fpr": 0.0,
            "logloss": 0.6825375644469291,
            "mae": 0.4922451706343503,
            "precision": 1.0,
            "recall": 0.03036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 22571,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.7750155987574667,
            "auditor_fn_violation": 0.002624461762926609,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5500311975149335,
            "fpr": 0.0,
            "logloss": 0.6900153118585792,
            "mae": 0.4971036068572287,
            "precision": 1.0,
            "recall": 0.014198782961460446
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7616200417761799,
            "auditor_fn_violation": 0.005340844963104606,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5243042634492088,
            "fpr": 0.0,
            "logloss": 0.6825375644469291,
            "mae": 0.4922451706343503,
            "precision": 1.0,
            "recall": 0.03036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.6157492554184962,
            "auditor_fn_violation": 0.004228052382477515,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5571386219090246,
            "fpr": 0.0,
            "logloss": 0.6885871818423545,
            "mae": 0.4961237977340556,
            "precision": 1.0,
            "recall": 0.018255578093306288
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5971333375227221,
            "auditor_fn_violation": 0.003409759245281232,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5153251872109396,
            "fpr": 0.0,
            "logloss": 0.6844616868014457,
            "mae": 0.4935848321336292,
            "precision": 1.0,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 22571,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5948245990397926,
            "auditor_fn_violation": 0.003080406391231639,
            "auditor_fp_violation": 0.00048413097182096066,
            "ave_precision_score": 0.5959936749153805,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6823709912346891,
            "mae": 0.488919642966306,
            "precision": 0.9583333333333334,
            "recall": 0.04665314401622718
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5787429769287,
            "auditor_fn_violation": 0.005017013079474553,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5797598518582598,
            "fpr": 0.0,
            "logloss": 0.6697474893018168,
            "mae": 0.4827378830258069,
            "precision": 1.0,
            "recall": 0.0650759219088937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8334879948553142,
            "auditor_fn_violation": 0.009843955731112772,
            "auditor_fp_violation": 0.010844533768789516,
            "ave_precision_score": 0.8338067535550252,
            "fpr": 0.11951754385964912,
            "logloss": 0.7476771380366412,
            "mae": 0.27996824670169007,
            "precision": 0.7705263157894737,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8246215747416903,
            "auditor_fn_violation": 0.008205328463155786,
            "auditor_fp_violation": 0.014804244420051226,
            "ave_precision_score": 0.8248311946333307,
            "fpr": 0.1350164654226125,
            "logloss": 0.720613385994952,
            "mae": 0.2748259637410261,
            "precision": 0.7410526315789474,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.6253577874092004,
            "auditor_fn_violation": 0.004228052382477515,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5698522220817785,
            "fpr": 0.0,
            "logloss": 0.6863387543368811,
            "mae": 0.49484879320912195,
            "precision": 1.0,
            "recall": 0.018255578093306288
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.6043100558367188,
            "auditor_fn_violation": 0.003409759245281232,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5251259427355179,
            "fpr": 0.0,
            "logloss": 0.6825977070885485,
            "mae": 0.49252970394004714,
            "precision": 1.0,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 22571,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.5260389013227662,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017507222710714736,
            "ave_precision_score": 0.5277603451463059,
            "fpr": 0.003289473684210526,
            "logloss": 0.6942801611870028,
            "mae": 0.5005399644244135,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5042147765047235,
            "auditor_fn_violation": 0.000502415642984876,
            "auditor_fp_violation": 0.0015587266739846323,
            "ave_precision_score": 0.5058611186799595,
            "fpr": 0.003293084522502744,
            "logloss": 0.6934605857179771,
            "mae": 0.500103100725377,
            "precision": 0.5,
            "recall": 0.006507592190889371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8502972017940531,
            "auditor_fn_violation": 0.004216931781787125,
            "auditor_fp_violation": 0.01069536909098522,
            "ave_precision_score": 0.85051174752513,
            "fpr": 0.12719298245614036,
            "logloss": 0.5993011551080937,
            "mae": 0.2800445998482964,
            "precision": 0.7661290322580645,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8387890964868362,
            "auditor_fn_violation": 0.004824142619371336,
            "auditor_fp_violation": 0.01167215514087084,
            "ave_precision_score": 0.8388465647302893,
            "fpr": 0.141602634467618,
            "logloss": 0.6071323693783852,
            "mae": 0.2849031367476019,
            "precision": 0.7388663967611336,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8303424636601606,
            "auditor_fn_violation": 0.012232660759403578,
            "auditor_fp_violation": 0.013013963907381817,
            "ave_precision_score": 0.8306246476011185,
            "fpr": 0.11403508771929824,
            "logloss": 0.7587408151021819,
            "mae": 0.28238975135930366,
            "precision": 0.7758620689655172,
            "recall": 0.7302231237322515
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8224976973326432,
            "auditor_fn_violation": 0.0069933400163344605,
            "auditor_fp_violation": 0.013611416026344678,
            "ave_precision_score": 0.8226636415993076,
            "fpr": 0.13172338090010977,
            "logloss": 0.7296482437953953,
            "mae": 0.27756138653961754,
            "precision": 0.7430406852248393,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 22571,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.633824100638612,
            "auditor_fn_violation": 0.0028735632183907955,
            "auditor_fp_violation": 0.001428840597914835,
            "ave_precision_score": 0.5635460171358799,
            "fpr": 0.003289473684210526,
            "logloss": 0.6863442480979073,
            "mae": 0.4948484423129182,
            "precision": 0.8125,
            "recall": 0.02636916835699797
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.6485627488501904,
            "auditor_fn_violation": 0.0014691490602922591,
            "auditor_fp_violation": 0.0011513599219417003,
            "ave_precision_score": 0.5499766532673844,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6825331111900345,
            "mae": 0.49249359477887955,
            "precision": 0.8947368421052632,
            "recall": 0.0368763557483731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8273739973641221,
            "auditor_fn_violation": 0.011950197501868267,
            "auditor_fp_violation": 0.012181782020684175,
            "ave_precision_score": 0.8277397842126687,
            "fpr": 0.11951754385964912,
            "logloss": 0.774545543618426,
            "mae": 0.2837082186037462,
            "precision": 0.7690677966101694,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8194868648020921,
            "auditor_fn_violation": 0.006962385498046292,
            "auditor_fp_violation": 0.01519697524088304,
            "ave_precision_score": 0.8196446824280268,
            "fpr": 0.132821075740944,
            "logloss": 0.7452830421192611,
            "mae": 0.2790121597251528,
            "precision": 0.7392241379310345,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7982188697620021,
            "auditor_fn_violation": 0.025890982527312208,
            "auditor_fp_violation": 0.0014262236737428299,
            "ave_precision_score": 0.6337297944280008,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6327507165718079,
            "mae": 0.4500864639943629,
            "precision": 0.9607843137254902,
            "recall": 0.19878296146044624
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7694224277308532,
            "auditor_fn_violation": 0.024942198389888846,
            "auditor_fp_violation": 0.002590559824368826,
            "ave_precision_score": 0.6030543161963873,
            "fpr": 0.008781558726673985,
            "logloss": 0.6394020615962218,
            "mae": 0.4495072438086165,
            "precision": 0.9252336448598131,
            "recall": 0.21475054229934923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7560762583005194,
            "auditor_fn_violation": 0.016892192448667312,
            "auditor_fp_violation": 0.0015701545032031148,
            "ave_precision_score": 0.7578722147719035,
            "fpr": 0.0625,
            "logloss": 0.7637879028207345,
            "mae": 0.37397352421299856,
            "precision": 0.814935064935065,
            "recall": 0.5091277890466531
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.772302483647551,
            "auditor_fn_violation": 0.00594564862811957,
            "auditor_fp_violation": 0.010757409440175635,
            "ave_precision_score": 0.7733964780464326,
            "fpr": 0.06915477497255763,
            "logloss": 0.684546375348766,
            "mae": 0.35007941997001757,
            "precision": 0.803125,
            "recall": 0.5574837310195228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7982188697620021,
            "auditor_fn_violation": 0.025890982527312208,
            "auditor_fp_violation": 0.0014262236737428299,
            "ave_precision_score": 0.6337297944280008,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6327930670423905,
            "mae": 0.4500934688145654,
            "precision": 0.9607843137254902,
            "recall": 0.19878296146044624
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7694224277308532,
            "auditor_fn_violation": 0.024942198389888846,
            "auditor_fp_violation": 0.002590559824368826,
            "ave_precision_score": 0.6030543161963873,
            "fpr": 0.008781558726673985,
            "logloss": 0.6393583304244349,
            "mae": 0.44948117623083156,
            "precision": 0.9252336448598131,
            "recall": 0.21475054229934923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 22571,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.6225732221818067,
            "auditor_fn_violation": 0.004314793067862351,
            "auditor_fp_violation": 0.00048413097182096066,
            "ave_precision_score": 0.5543728597474036,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6894451322319093,
            "mae": 0.49614529880253894,
            "precision": 0.9166666666666666,
            "recall": 0.02231237322515213
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.6505460970598806,
            "auditor_fn_violation": 0.0034454759971521923,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5455658542642584,
            "fpr": 0.0,
            "logloss": 0.6834365107570518,
            "mae": 0.49298433633981237,
            "precision": 1.0,
            "recall": 0.03036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8273739973641221,
            "auditor_fn_violation": 0.011950197501868267,
            "auditor_fp_violation": 0.012181782020684175,
            "ave_precision_score": 0.8277397842126687,
            "fpr": 0.11951754385964912,
            "logloss": 0.7745455634283474,
            "mae": 0.2837082151014576,
            "precision": 0.7690677966101694,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8194868648020921,
            "auditor_fn_violation": 0.006962385498046292,
            "auditor_fp_violation": 0.01519697524088304,
            "ave_precision_score": 0.8196446824280268,
            "fpr": 0.132821075740944,
            "logloss": 0.7452832158423637,
            "mae": 0.2790121750262429,
            "precision": 0.7392241379310345,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8504138396483388,
            "auditor_fn_violation": 0.0024265150706380564,
            "auditor_fp_violation": 0.00803919105639995,
            "ave_precision_score": 0.8507240188643308,
            "fpr": 0.12280701754385964,
            "logloss": 0.6077981061557101,
            "mae": 0.2791204129364719,
            "precision": 0.7714285714285715,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8399781640250092,
            "auditor_fn_violation": 0.00788387769631713,
            "auditor_fp_violation": 0.013328454689596298,
            "ave_precision_score": 0.840100084541819,
            "fpr": 0.13611416026344675,
            "logloss": 0.6072615836334224,
            "mae": 0.2829734215766859,
            "precision": 0.743801652892562,
            "recall": 0.7809110629067245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7658514302734054,
            "auditor_fn_violation": 0.00232420554428668,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6025808396253083,
            "fpr": 0.4331140350877193,
            "logloss": 0.6878751666863634,
            "mae": 0.46610915775231104,
            "precision": 0.5475372279495991,
            "recall": 0.9695740365111561
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7684651995534232,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.5951267067985512,
            "fpr": 0.45334796926454446,
            "logloss": 0.686601988166968,
            "mae": 0.4629009636579047,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.8414837116177811,
            "auditor_fn_violation": 0.010513415892672868,
            "auditor_fp_violation": 0.0023866348448687374,
            "ave_precision_score": 0.8417365617887648,
            "fpr": 0.03728070175438596,
            "logloss": 0.6934862361505014,
            "mae": 0.35780079142217835,
            "precision": 0.8721804511278195,
            "recall": 0.47058823529411764
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8528139715608136,
            "auditor_fn_violation": 0.0050574920649282965,
            "auditor_fp_violation": 0.008635199414562752,
            "ave_precision_score": 0.8530501655439908,
            "fpr": 0.036223929747530186,
            "logloss": 0.6016986414100496,
            "mae": 0.32535438165003455,
            "precision": 0.8817204301075269,
            "recall": 0.5336225596529284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.6560766800548802,
            "auditor_fn_violation": 0.006565602647592606,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.5939512346298542,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6802458441395439,
            "mae": 0.4838501757762411,
            "precision": 0.9024390243902439,
            "recall": 0.07505070993914807
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6427771506478781,
            "auditor_fn_violation": 0.005771827102347547,
            "auditor_fp_violation": 0.001092816197097207,
            "ave_precision_score": 0.5621759294860369,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6643790609625804,
            "mae": 0.476359787514652,
            "precision": 0.9574468085106383,
            "recall": 0.09761388286334056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.7759414604909751,
            "auditor_fn_violation": 0.002015052845094484,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5518829209819501,
            "fpr": 0.0,
            "logloss": 0.6895488956288612,
            "mae": 0.4963941137845579,
            "precision": 1.0,
            "recall": 0.018255578093306288
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7621521317246044,
            "auditor_fn_violation": 0.005645627912403482,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5253684433460578,
            "fpr": 0.0,
            "logloss": 0.6820968992218719,
            "mae": 0.4917132100734439,
            "precision": 1.0,
            "recall": 0.03253796095444685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6547317813765182,
            "auditor_fn_violation": 0.004181345859577969,
            "auditor_fp_violation": 0.0033287275467906046,
            "ave_precision_score": 0.558845599526981,
            "fpr": 0.010964912280701754,
            "logloss": 0.6885396026511058,
            "mae": 0.4897254888425794,
            "precision": 0.7368421052631579,
            "recall": 0.056795131845841784
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6552682651217074,
            "auditor_fn_violation": 0.003350231325496288,
            "auditor_fp_violation": 0.0011172094157824127,
            "ave_precision_score": 0.5270224304603345,
            "fpr": 0.008781558726673985,
            "logloss": 0.6884257887479542,
            "mae": 0.4898213235135921,
            "precision": 0.7714285714285715,
            "recall": 0.05856832971800434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.6157492554184962,
            "auditor_fn_violation": 0.004228052382477515,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5571386219090246,
            "fpr": 0.0,
            "logloss": 0.6885871818423545,
            "mae": 0.4961237977340556,
            "precision": 1.0,
            "recall": 0.018255578093306288
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5971333375227221,
            "auditor_fn_violation": 0.003409759245281232,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5153251872109396,
            "fpr": 0.0,
            "logloss": 0.6844616868014457,
            "mae": 0.4935848321336292,
            "precision": 1.0,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.787919130779708,
            "auditor_fn_violation": 0.009955161738016473,
            "auditor_fp_violation": 0.0006202110287652318,
            "ave_precision_score": 0.7896185769829489,
            "fpr": 0.03179824561403509,
            "logloss": 0.7757891405756022,
            "mae": 0.3688169480397176,
            "precision": 0.8693693693693694,
            "recall": 0.39148073022312374
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7992033444456597,
            "auditor_fn_violation": 0.006338532898700152,
            "auditor_fp_violation": 0.00362971094035858,
            "ave_precision_score": 0.8009550629348727,
            "fpr": 0.036223929747530186,
            "logloss": 0.6804477107845402,
            "mae": 0.3383903504900315,
            "precision": 0.8589743589743589,
            "recall": 0.4360086767895879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8341073007359165,
            "auditor_fn_violation": 0.009861748692217365,
            "auditor_fp_violation": 0.011948875769375705,
            "ave_precision_score": 0.8343988530559976,
            "fpr": 0.12171052631578948,
            "logloss": 0.7520331000868653,
            "mae": 0.27913195306918204,
            "precision": 0.7682672233820459,
            "recall": 0.7464503042596349
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8248719971294645,
            "auditor_fn_violation": 0.011855580504368161,
            "auditor_fp_violation": 0.01758263202829614,
            "ave_precision_score": 0.8250753249397399,
            "fpr": 0.13391877058177826,
            "logloss": 0.7244334584694112,
            "mae": 0.27380406015591635,
            "precision": 0.7420718816067653,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8377083180256755,
            "auditor_fn_violation": 0.009259012134799472,
            "auditor_fp_violation": 0.015944918980027634,
            "ave_precision_score": 0.8381445954363864,
            "fpr": 0.13048245614035087,
            "logloss": 0.8373244773205993,
            "mae": 0.26865668740479665,
            "precision": 0.7638888888888888,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.825418606903999,
            "auditor_fn_violation": 0.004490786268575687,
            "auditor_fp_violation": 0.020612269788998664,
            "ave_precision_score": 0.8257201445076545,
            "fpr": 0.13721185510428102,
            "logloss": 0.796363878565071,
            "mae": 0.2636719130334081,
            "precision": 0.7464503042596349,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6790270831162336,
            "auditor_fn_violation": 0.003373990249457316,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.6114669629754388,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6639982626615594,
            "mae": 0.47455866569489763,
            "precision": 0.9375,
            "recall": 0.12170385395537525
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6737613592264031,
            "auditor_fn_violation": 0.004178859968902617,
            "auditor_fp_violation": 0.001136723990730577,
            "ave_precision_score": 0.6003444378375957,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6461653369195146,
            "mae": 0.46335032991206215,
            "precision": 0.9512195121951219,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 22571,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8338468993494446,
            "auditor_fn_violation": 0.011661061883918728,
            "auditor_fp_violation": 0.011925323451827658,
            "ave_precision_score": 0.8342781452781838,
            "fpr": 0.11403508771929824,
            "logloss": 0.758038648882312,
            "mae": 0.2810632788788006,
            "precision": 0.7773019271948608,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8244575682653564,
            "auditor_fn_violation": 0.005093208816799261,
            "auditor_fp_violation": 0.015509208440053672,
            "ave_precision_score": 0.824728200370576,
            "fpr": 0.12952799121844127,
            "logloss": 0.7276601125662618,
            "mae": 0.27712443969916006,
            "precision": 0.7440347071583514,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.7479305094165065,
            "auditor_fn_violation": 0.005709316394434362,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.5831887261899347,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6773858987320671,
            "mae": 0.48156493908742015,
            "precision": 0.9111111111111111,
            "recall": 0.08316430020283976
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7586072864766827,
            "auditor_fn_violation": 0.003785975698322025,
            "auditor_fp_violation": 0.001092816197097207,
            "ave_precision_score": 0.5597115454798526,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6635492605007659,
            "mae": 0.47557578442779774,
            "precision": 0.9583333333333334,
            "recall": 0.09978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.519908041838987,
            "auditor_fn_violation": 0.002442083911604569,
            "auditor_fp_violation": 0.00048413097182096066,
            "ave_precision_score": 0.4406844095020434,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6879179558551661,
            "mae": 0.4935258396231292,
            "precision": 0.9285714285714286,
            "recall": 0.02636916835699797
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5114457163137966,
            "auditor_fn_violation": 0.004895576123113272,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.41576513717947094,
            "fpr": 0.0,
            "logloss": 0.6806121811737167,
            "mae": 0.4908944235217035,
            "precision": 1.0,
            "recall": 0.03253796095444685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8368414658405519,
            "auditor_fn_violation": 0.00864293085655315,
            "auditor_fp_violation": 0.015484340325754724,
            "ave_precision_score": 0.837279814997965,
            "fpr": 0.13048245614035087,
            "logloss": 0.7966668602232378,
            "mae": 0.2710750747007679,
            "precision": 0.762,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8233097152064046,
            "auditor_fn_violation": 0.004702705663010066,
            "auditor_fp_violation": 0.022217343578485187,
            "ave_precision_score": 0.8236248792945415,
            "fpr": 0.13830954994511527,
            "logloss": 0.7638153344333226,
            "mae": 0.26717572778046406,
            "precision": 0.7449392712550608,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 22571,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7888642445359618,
            "auditor_fn_violation": 0.012546261698871932,
            "auditor_fp_violation": 0.004715697357953357,
            "ave_precision_score": 0.7905582050468222,
            "fpr": 0.039473684210526314,
            "logloss": 0.7623103126333675,
            "mae": 0.3643365988927894,
            "precision": 0.8631178707224335,
            "recall": 0.460446247464503
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8060181537909955,
            "auditor_fn_violation": 0.00414790545061445,
            "auditor_fp_violation": 0.005766556897182585,
            "ave_precision_score": 0.8072121741514913,
            "fpr": 0.04171240395170143,
            "logloss": 0.6646710978690905,
            "mae": 0.3322446514497029,
            "precision": 0.8647686832740213,
            "recall": 0.527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7764618222385252,
            "auditor_fn_violation": 0.0028691149781146586,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6165075199778132,
            "fpr": 0.4331140350877193,
            "logloss": 0.6684031739624416,
            "mae": 0.4605585169373897,
            "precision": 0.5480549199084668,
            "recall": 0.9716024340770791
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.784516889362191,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.6162492874187402,
            "fpr": 0.45334796926454446,
            "logloss": 0.6629801791045127,
            "mae": 0.45458799705285535,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 22571,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.7125155987574667,
            "auditor_fn_violation": 0.002982545105156426,
            "auditor_fp_violation": 0.00048413097182096066,
            "ave_precision_score": 0.5482563496447509,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6932987896495693,
            "mae": 0.4974886152501169,
            "precision": 0.875,
            "recall": 0.014198782961460446
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7600237719309064,
            "auditor_fn_violation": 0.004850334904076709,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5211117237586618,
            "fpr": 0.0,
            "logloss": 0.6847328797280102,
            "mae": 0.4938677841169774,
            "precision": 1.0,
            "recall": 0.02386117136659436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.852528792130832,
            "auditor_fn_violation": 0.00792676417209352,
            "auditor_fp_violation": 0.012150378930620112,
            "ave_precision_score": 0.8528151023414821,
            "fpr": 0.1206140350877193,
            "logloss": 0.5981588095111472,
            "mae": 0.2787288145263151,
            "precision": 0.7736625514403292,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8418972435812773,
            "auditor_fn_violation": 0.007717199520919303,
            "auditor_fp_violation": 0.015953165020124407,
            "ave_precision_score": 0.8419813782361991,
            "fpr": 0.13172338090010977,
            "logloss": 0.5938801735021308,
            "mae": 0.2809861179211462,
            "precision": 0.7478991596638656,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.835881544314089,
            "auditor_fn_violation": 0.010446692288530656,
            "auditor_fp_violation": 0.015944918980027634,
            "ave_precision_score": 0.8362932146317685,
            "fpr": 0.13048245614035087,
            "logloss": 0.8230773459116775,
            "mae": 0.27244873014027476,
            "precision": 0.7610441767068273,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.823612970344413,
            "auditor_fn_violation": 0.005545621007164781,
            "auditor_fp_violation": 0.02250274423710209,
            "ave_precision_score": 0.8239155275758228,
            "fpr": 0.13721185510428102,
            "logloss": 0.7854838460528525,
            "mae": 0.2671134875678591,
            "precision": 0.745417515274949,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8425120150349421,
            "auditor_fn_violation": 0.004657307569125669,
            "auditor_fp_violation": 0.006754281287945399,
            "ave_precision_score": 0.8426121781445082,
            "fpr": 0.10416666666666667,
            "logloss": 0.6080753282466895,
            "mae": 0.33735532676827606,
            "precision": 0.7850678733031674,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8447663118412494,
            "auditor_fn_violation": 0.00575515928480776,
            "auditor_fp_violation": 0.009103549213318702,
            "ave_precision_score": 0.8445399408596284,
            "fpr": 0.10537870472008781,
            "logloss": 0.6520179254396531,
            "mae": 0.33546273684298145,
            "precision": 0.775175644028103,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5150741463361737,
            "auditor_fn_violation": 0.0010520088253087206,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4415439866218521,
            "fpr": 0.0,
            "logloss": 0.686451480481343,
            "mae": 0.49437835953084003,
            "precision": 1.0,
            "recall": 0.02434077079107505
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5198749230809059,
            "auditor_fn_violation": 0.0047693769331691995,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.42494623807293735,
            "fpr": 0.0,
            "logloss": 0.6798711480835921,
            "mae": 0.49033555656704236,
            "precision": 1.0,
            "recall": 0.0455531453362256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.6340587179238812,
            "auditor_fn_violation": 0.09584845735027224,
            "auditor_fp_violation": 0.06802956077544697,
            "ave_precision_score": 0.6347559657743872,
            "fpr": 0.17434210526315788,
            "logloss": 1.244842978819754,
            "mae": 0.49289379910451436,
            "precision": 0.5470085470085471,
            "recall": 0.3894523326572008
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.592633315323048,
            "auditor_fn_violation": 0.09361360665379277,
            "auditor_fp_violation": 0.06922307598487622,
            "ave_precision_score": 0.5934575160461972,
            "fpr": 0.1800219538968167,
            "logloss": 1.2536024420124452,
            "mae": 0.48813320754899714,
            "precision": 0.5,
            "recall": 0.3557483731019523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5690449666916093,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0024075702382447815,
            "ave_precision_score": 0.5716288786030491,
            "fpr": 0.45394736842105265,
            "logloss": 0.7862464109353784,
            "mae": 0.47702962928043124,
            "precision": 0.5435501653803748,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5590023528722259,
            "auditor_fn_violation": 0.0006309959497203379,
            "auditor_fp_violation": 0.0034613977314306714,
            "ave_precision_score": 0.5607788738234648,
            "fpr": 0.4862788144895719,
            "logloss": 0.823110002829152,
            "mae": 0.49374699572962016,
            "precision": 0.5094130675526024,
            "recall": 0.9978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8366901244274818,
            "auditor_fn_violation": 0.009041048361268284,
            "auditor_fp_violation": 0.01655727923627685,
            "ave_precision_score": 0.8370993171909984,
            "fpr": 0.12938596491228072,
            "logloss": 0.8242108990831912,
            "mae": 0.2714696230219211,
            "precision": 0.7635270541082164,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8239919973332969,
            "auditor_fn_violation": 0.00319069650047265,
            "auditor_fp_violation": 0.021668496158068068,
            "ave_precision_score": 0.8242935557491282,
            "fpr": 0.1350164654226125,
            "logloss": 0.7871500375464798,
            "mae": 0.2666089193200707,
            "precision": 0.7484662576687117,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.623668303445551,
            "auditor_fn_violation": 0.07771965410483614,
            "auditor_fp_violation": 0.03983481974626303,
            "ave_precision_score": 0.6243704066254447,
            "fpr": 0.08881578947368421,
            "logloss": 1.356505207533838,
            "mae": 0.5051978363721513,
            "precision": 0.6232558139534884,
            "recall": 0.2718052738336714
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5850168655678438,
            "auditor_fn_violation": 0.06934526431586943,
            "auditor_fp_violation": 0.029835345773874866,
            "ave_precision_score": 0.5858844828471488,
            "fpr": 0.0801317233809001,
            "logloss": 1.3600017134319118,
            "mae": 0.49428417322077095,
            "precision": 0.6217616580310881,
            "recall": 0.2603036876355748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.6115871995730906,
            "auditor_fn_violation": 0.0012833173196683536,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.555635733136516,
            "fpr": 0.0,
            "logloss": 0.6891516791258433,
            "mae": 0.49658796478781786,
            "precision": 1.0,
            "recall": 0.016227180527383367
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5911129108600053,
            "auditor_fn_violation": 0.0011810339285331696,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5120509051658226,
            "fpr": 0.0,
            "logloss": 0.6859434121386181,
            "mae": 0.4946655383748621,
            "precision": 1.0,
            "recall": 0.021691973969631236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 22571,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5357378900171567,
            "auditor_fn_violation": 0.0038054695562435674,
            "auditor_fp_violation": 0.0007719926307415317,
            "ave_precision_score": 0.5445369997856854,
            "fpr": 0.003289473684210526,
            "logloss": 0.6881569479066046,
            "mae": 0.48954632446954127,
            "precision": 0.8846153846153846,
            "recall": 0.04665314401622718
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5349851169438414,
            "auditor_fn_violation": 0.0015905860166535314,
            "auditor_fp_violation": 0.0014928649835345773,
            "ave_precision_score": 0.5416605731321957,
            "fpr": 0.003293084522502744,
            "logloss": 0.6883923885684059,
            "mae": 0.4898161528597286,
            "precision": 0.88,
            "recall": 0.04772234273318872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8464320147446834,
            "auditor_fn_violation": 0.0014679192911284324,
            "auditor_fp_violation": 0.011069589247581967,
            "ave_precision_score": 0.8468415949644994,
            "fpr": 0.11403508771929824,
            "logloss": 0.5876807250388634,
            "mae": 0.2839832844854659,
            "precision": 0.7819706498951782,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8326087242558922,
            "auditor_fn_violation": 0.004995583028351958,
            "auditor_fp_violation": 0.014013904134650564,
            "ave_precision_score": 0.8327004477123203,
            "fpr": 0.1350164654226125,
            "logloss": 0.5838666643831004,
            "mae": 0.29176343545840483,
            "precision": 0.7360515021459227,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 22571,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8407149230699621,
            "auditor_fn_violation": 0.00982616277000819,
            "auditor_fp_violation": 0.014387849097684547,
            "ave_precision_score": 0.840977820569004,
            "fpr": 0.1118421052631579,
            "logloss": 0.71923066641374,
            "mae": 0.27628751912173183,
            "precision": 0.7825159914712153,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8328695476811852,
            "auditor_fn_violation": 0.009488750413719042,
            "auditor_fp_violation": 0.018441273326015372,
            "ave_precision_score": 0.8330665051164983,
            "fpr": 0.13172338090010977,
            "logloss": 0.6852548273031793,
            "mae": 0.26992669456093155,
            "precision": 0.7473684210526316,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8309101324464214,
            "auditor_fn_violation": 0.014708106473079258,
            "auditor_fp_violation": 0.01580098815056735,
            "ave_precision_score": 0.8313312800247274,
            "fpr": 0.1337719298245614,
            "logloss": 0.8776873241839158,
            "mae": 0.2764006821766113,
            "precision": 0.7540322580645161,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.82615464108168,
            "auditor_fn_violation": 0.0071266825566527236,
            "auditor_fp_violation": 0.022239297475301876,
            "ave_precision_score": 0.826410317072963,
            "fpr": 0.1394072447859495,
            "logloss": 0.8302628929262726,
            "mae": 0.26591136511227575,
            "precision": 0.7413441955193483,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.776742486183543,
            "auditor_fn_violation": 0.007915643571403163,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.6167817696957876,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6578461247350332,
            "mae": 0.46729259993554206,
            "precision": 0.9466666666666667,
            "recall": 0.1440162271805274
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7846099062362957,
            "auditor_fn_violation": 7.857685411613199e-05,
            "auditor_fp_violation": 0.001136723990730577,
            "ave_precision_score": 0.6163353067575669,
            "fpr": 0.0043907793633369925,
            "logloss": 0.633936758686472,
            "mae": 0.45274165001187705,
            "precision": 0.9578947368421052,
            "recall": 0.19739696312364424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.5010278922639785,
            "auditor_fn_violation": 0.0015613323369275205,
            "auditor_fp_violation": 0.00825901268684839,
            "ave_precision_score": 0.5311992799906834,
            "fpr": 0.14364035087719298,
            "logloss": 0.6941991017756269,
            "mae": 0.5004404023485748,
            "precision": 0.5,
            "recall": 0.2657200811359026
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.49278283857177324,
            "auditor_fn_violation": 0.002585892835457698,
            "auditor_fp_violation": 0.011906330040248816,
            "ave_precision_score": 0.5045731625678386,
            "fpr": 0.150384193194292,
            "logloss": 0.6943247452676513,
            "mae": 0.5004923591629472,
            "precision": 0.4689922480620155,
            "recall": 0.26247288503253796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.4378456629961755,
            "auditor_fn_violation": 0.000531564712999547,
            "auditor_fp_violation": 0.00543796842942679,
            "ave_precision_score": 0.5340934932997585,
            "fpr": 0.013157894736842105,
            "logloss": 0.7324580858410294,
            "mae": 0.5052557812121353,
            "precision": 0.07692307692307693,
            "recall": 0.002028397565922921
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.532061487425876,
            "auditor_fn_violation": 0.0009405411326020256,
            "auditor_fp_violation": 0.0011391633125990978,
            "ave_precision_score": 0.5083968889797487,
            "fpr": 0.012074643249176729,
            "logloss": 0.7240990229060872,
            "mae": 0.5039648441792058,
            "precision": 0.26666666666666666,
            "recall": 0.008676789587852495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.521342996925595,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0024075702382447815,
            "ave_precision_score": 0.5304454878295767,
            "fpr": 0.45394736842105265,
            "logloss": 0.7880645234899596,
            "mae": 0.4773257746312179,
            "precision": 0.5435501653803748,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5048840392285538,
            "auditor_fn_violation": 0.0006309959497203379,
            "auditor_fp_violation": 0.0034613977314306714,
            "ave_precision_score": 0.5038757756886886,
            "fpr": 0.4862788144895719,
            "logloss": 0.8246682805835029,
            "mae": 0.49399304926460846,
            "precision": 0.5094130675526024,
            "recall": 0.9978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 22571,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.7648861926421167,
            "auditor_fn_violation": 0.003080406391231639,
            "auditor_fp_violation": 0.00048413097182096066,
            "ave_precision_score": 0.5801014478007906,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6821809890108049,
            "mae": 0.48885100302204754,
            "precision": 0.9583333333333334,
            "recall": 0.04665314401622718
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7658916809405111,
            "auditor_fn_violation": 0.005017013079474553,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5475370146735055,
            "fpr": 0.0,
            "logloss": 0.6696832636135598,
            "mae": 0.4827309365657237,
            "precision": 1.0,
            "recall": 0.0650759219088937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.80596504438438,
            "auditor_fn_violation": 0.031135457812889226,
            "auditor_fp_violation": 0.06505935184022109,
            "ave_precision_score": 0.8063616867489243,
            "fpr": 0.2883771929824561,
            "logloss": 0.8443914363415146,
            "mae": 0.3699470040232382,
            "precision": 0.6285310734463276,
            "recall": 0.9026369168356998
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.8006087115901852,
            "auditor_fn_violation": 0.024142143147979266,
            "auditor_fp_violation": 0.07406269057202099,
            "ave_precision_score": 0.8012029308667741,
            "fpr": 0.3205268935236004,
            "logloss": 0.9592851529093326,
            "mae": 0.3968289190904004,
            "precision": 0.5864022662889519,
            "recall": 0.8980477223427332
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8423014490885171,
            "auditor_fn_violation": 0.004657307569125669,
            "auditor_fp_violation": 0.006754281287945399,
            "ave_precision_score": 0.8423908938826025,
            "fpr": 0.10416666666666667,
            "logloss": 0.6082841807143415,
            "mae": 0.33740386064150435,
            "precision": 0.7850678733031674,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8427641906001453,
            "auditor_fn_violation": 0.00575515928480776,
            "auditor_fp_violation": 0.009103549213318702,
            "ave_precision_score": 0.8426003101428896,
            "fpr": 0.10537870472008781,
            "logloss": 0.6520250543289263,
            "mae": 0.3353977329342849,
            "precision": 0.775175644028103,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8265036250547853,
            "auditor_fn_violation": 0.010277659158037085,
            "auditor_fp_violation": 0.015528828036678807,
            "ave_precision_score": 0.8268092565449812,
            "fpr": 0.12171052631578948,
            "logloss": 0.7875560198040594,
            "mae": 0.28261244640189165,
            "precision": 0.7677824267782427,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8165070313901688,
            "auditor_fn_violation": 0.00794816784968486,
            "auditor_fp_violation": 0.015916575192096598,
            "ave_precision_score": 0.8166665637832367,
            "fpr": 0.13721185510428102,
            "logloss": 0.7627308072138708,
            "mae": 0.2780309761472231,
            "precision": 0.7351694915254238,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 22571,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.6555659559050646,
            "auditor_fn_violation": 0.002982545105156426,
            "auditor_fp_violation": 0.002229619394548424,
            "ave_precision_score": 0.650941379984312,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6952091674464551,
            "mae": 0.4983949148537297,
            "precision": 0.6363636363636364,
            "recall": 0.014198782961460446
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6749477591315316,
            "auditor_fn_violation": 0.004676513378304712,
            "auditor_fp_violation": 0.0015587266739846323,
            "ave_precision_score": 0.6600142489012418,
            "fpr": 0.003293084522502744,
            "logloss": 0.6864041219961435,
            "mae": 0.49453793075160585,
            "precision": 0.8235294117647058,
            "recall": 0.03036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8432890836540441,
            "auditor_fn_violation": 0.007675438596491229,
            "auditor_fp_violation": 0.00762048318887912,
            "ave_precision_score": 0.8435504752231126,
            "fpr": 0.09429824561403509,
            "logloss": 0.5331600268479788,
            "mae": 0.3494277849033671,
            "precision": 0.7981220657276995,
            "recall": 0.6896551724137931
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8223594177594173,
            "auditor_fn_violation": 0.0042074333703993865,
            "auditor_fp_violation": 0.003532138065617762,
            "ave_precision_score": 0.8226643727930003,
            "fpr": 0.09659714599341383,
            "logloss": 0.5415542318232764,
            "mae": 0.35003184093189,
            "precision": 0.7869249394673123,
            "recall": 0.7049891540130152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8455543181431553,
            "auditor_fn_violation": 0.00829374399487563,
            "auditor_fp_violation": 0.01304013314910188,
            "ave_precision_score": 0.8459273836303463,
            "fpr": 0.12390350877192982,
            "logloss": 0.7560365035888308,
            "mae": 0.2668152333789274,
            "precision": 0.771255060728745,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8390435007410412,
            "auditor_fn_violation": 0.007186210476437661,
            "auditor_fp_violation": 0.01958287596048299,
            "ave_precision_score": 0.8393158082084096,
            "fpr": 0.12952799121844127,
            "logloss": 0.69089234643989,
            "mae": 0.26029332420530515,
            "precision": 0.7546777546777547,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 22571,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.621363212685598,
            "auditor_fn_violation": 0.005126596918259136,
            "auditor_fp_violation": 0.0033287275467906046,
            "ave_precision_score": 0.5722311759186025,
            "fpr": 0.010964912280701754,
            "logloss": 0.6846634897479508,
            "mae": 0.4869854832558255,
            "precision": 0.7674418604651163,
            "recall": 0.06693711967545639
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5715122909742819,
            "auditor_fn_violation": 0.0003619297522924185,
            "auditor_fp_violation": 0.0011196487376509332,
            "ave_precision_score": 0.518982325653054,
            "fpr": 0.009879253567508232,
            "logloss": 0.6915666015003821,
            "mae": 0.4898116418807619,
            "precision": 0.7567567567567568,
            "recall": 0.06073752711496746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7637638991803447,
            "auditor_fn_violation": 0.003373990249457316,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.5945480292710759,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6639381393302113,
            "mae": 0.4746407938042754,
            "precision": 0.9375,
            "recall": 0.12170385395537525
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7722156474186005,
            "auditor_fn_violation": 0.004178859968902617,
            "auditor_fp_violation": 0.001136723990730577,
            "ave_precision_score": 0.5942690704203073,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6463216134643808,
            "mae": 0.46354433537576384,
            "precision": 0.9512195121951219,
            "recall": 0.16919739696312364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8371914070714626,
            "auditor_fn_violation": 0.007546439628482976,
            "auditor_fp_violation": 0.01655727923627685,
            "ave_precision_score": 0.8375999175019221,
            "fpr": 0.12938596491228072,
            "logloss": 0.8151175651625304,
            "mae": 0.27115784846530505,
            "precision": 0.7635270541082164,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8246319855332178,
            "auditor_fn_violation": 0.005545621007164781,
            "auditor_fp_violation": 0.02133918770581779,
            "ave_precision_score": 0.8249326109377456,
            "fpr": 0.13830954994511527,
            "logloss": 0.7798992547533058,
            "mae": 0.2664963415317508,
            "precision": 0.7439024390243902,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8354258119351426,
            "auditor_fn_violation": 0.004677324650368315,
            "auditor_fp_violation": 0.011286793953858395,
            "ave_precision_score": 0.8356284806903536,
            "fpr": 0.13157894736842105,
            "logloss": 0.7792855659581402,
            "mae": 0.2790649676717153,
            "precision": 0.7565922920892495,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.813652532957843,
            "auditor_fn_violation": 0.005855166190046457,
            "auditor_fp_violation": 0.01868520551286743,
            "ave_precision_score": 0.8138359328897292,
            "fpr": 0.145993413830955,
            "logloss": 0.7869743415991258,
            "mae": 0.2815844638901329,
            "precision": 0.7302231237322515,
            "recall": 0.7809110629067245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 22571,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8383290433822181,
            "auditor_fn_violation": 0.00982616277000819,
            "auditor_fp_violation": 0.014387849097684547,
            "ave_precision_score": 0.838691337641779,
            "fpr": 0.1118421052631579,
            "logloss": 0.7471766655192676,
            "mae": 0.2758765872886933,
            "precision": 0.7825159914712153,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.83133364325201,
            "auditor_fn_violation": 0.008633929485607343,
            "auditor_fp_violation": 0.017594828637638747,
            "ave_precision_score": 0.831612904009976,
            "fpr": 0.13062568605927552,
            "logloss": 0.7107681268176707,
            "mae": 0.26914966143642033,
            "precision": 0.7484143763213531,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8269282506757776,
            "auditor_fn_violation": 0.013286893704850374,
            "auditor_fp_violation": 0.00592995017376377,
            "ave_precision_score": 0.8273365819808076,
            "fpr": 0.08442982456140351,
            "logloss": 0.9915458610241793,
            "mae": 0.2911759917883188,
            "precision": 0.8055555555555556,
            "recall": 0.6470588235294118
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8129989715943589,
            "auditor_fn_violation": 0.0031621230989758876,
            "auditor_fp_violation": 0.014709110867178925,
            "ave_precision_score": 0.8133310778396289,
            "fpr": 0.09769484083424808,
            "logloss": 0.9148850605645841,
            "mae": 0.2790039637219693,
            "precision": 0.7729591836734694,
            "recall": 0.6572668112798264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.833512174599889,
            "auditor_fn_violation": 0.009843955731112772,
            "auditor_fp_violation": 0.011917472679311649,
            "ave_precision_score": 0.8338367275480996,
            "fpr": 0.1206140350877193,
            "logloss": 0.7476580620927163,
            "mae": 0.27996961050183,
            "precision": 0.7689075630252101,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8246225532618456,
            "auditor_fn_violation": 0.008205328463155786,
            "auditor_fp_violation": 0.014804244420051226,
            "ave_precision_score": 0.8248321591329377,
            "fpr": 0.1350164654226125,
            "logloss": 0.720596961551341,
            "mae": 0.2748244786239614,
            "precision": 0.7410526315789474,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8413725660991296,
            "auditor_fn_violation": 0.010809223871036625,
            "auditor_fp_violation": 0.025051815098605705,
            "ave_precision_score": 0.8418334397926874,
            "fpr": 0.14035087719298245,
            "logloss": 0.8517377237251371,
            "mae": 0.2636315018023543,
            "precision": 0.7547892720306514,
            "recall": 0.7991886409736308
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8335605806599392,
            "auditor_fn_violation": 0.013284250579206661,
            "auditor_fp_violation": 0.023354067569215764,
            "ave_precision_score": 0.8338296284666868,
            "fpr": 0.15697036223929747,
            "logloss": 0.8079753606689153,
            "mae": 0.2608832027897798,
            "precision": 0.7244701348747592,
            "recall": 0.8156182212581344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6638734133027365,
            "auditor_fn_violation": 0.0032449912814490594,
            "auditor_fp_violation": 0.009912908763555679,
            "ave_precision_score": 0.6461416455114706,
            "fpr": 0.24451754385964913,
            "logloss": 2.3966453296127135,
            "mae": 0.3466269916501468,
            "precision": 0.6641566265060241,
            "recall": 0.8945233265720081
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6461419652748126,
            "auditor_fn_violation": 0.010729312262037142,
            "auditor_fp_violation": 0.023100378094889622,
            "ave_precision_score": 0.6310462039693054,
            "fpr": 0.2689352360043908,
            "logloss": 2.335460054801081,
            "mae": 0.3556286580098995,
            "precision": 0.6343283582089553,
            "recall": 0.9219088937093276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8096730218588865,
            "auditor_fn_violation": 0.004657307569125669,
            "auditor_fp_violation": 0.007552443160406983,
            "ave_precision_score": 0.8101615993326698,
            "fpr": 0.10307017543859649,
            "logloss": 0.584985708369504,
            "mae": 0.3725893138749566,
            "precision": 0.7868480725623582,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.804000908288021,
            "auditor_fn_violation": 0.005545621007164776,
            "auditor_fp_violation": 0.01005976338577876,
            "ave_precision_score": 0.8045339231003747,
            "fpr": 0.10318331503841932,
            "logloss": 0.5733415657259564,
            "mae": 0.3646941307746078,
            "precision": 0.7783018867924528,
            "recall": 0.7158351409978309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8315860009375606,
            "auditor_fn_violation": 0.014708106473079258,
            "auditor_fp_violation": 0.015329941799606419,
            "ave_precision_score": 0.8318246814152359,
            "fpr": 0.13267543859649122,
            "logloss": 0.8772007880573095,
            "mae": 0.27667510871246,
            "precision": 0.7555555555555555,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.826458213207991,
            "auditor_fn_violation": 0.0071266825566527236,
            "auditor_fp_violation": 0.020353701670935483,
            "ave_precision_score": 0.8267454098864111,
            "fpr": 0.1394072447859495,
            "logloss": 0.8273735424303824,
            "mae": 0.2659406890142716,
            "precision": 0.7413441955193483,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5362554549122202,
            "auditor_fn_violation": 0.004181345859577969,
            "auditor_fp_violation": 0.0033287275467906046,
            "ave_precision_score": 0.5434695433444802,
            "fpr": 0.010964912280701754,
            "logloss": 0.6939106840864268,
            "mae": 0.4912582641107994,
            "precision": 0.7368421052631579,
            "recall": 0.056795131845841784
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5384774054726196,
            "auditor_fn_violation": 0.003350231325496288,
            "auditor_fp_violation": 0.0011172094157824127,
            "ave_precision_score": 0.5447565383850785,
            "fpr": 0.008781558726673985,
            "logloss": 0.6893741219442405,
            "mae": 0.48944701740168584,
            "precision": 0.7714285714285715,
            "recall": 0.05856832971800434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7963151588630215,
            "auditor_fn_violation": 0.004657307569125669,
            "auditor_fp_violation": 0.006754281287945399,
            "ave_precision_score": 0.7967628756328434,
            "fpr": 0.10416666666666667,
            "logloss": 0.6617772665197976,
            "mae": 0.3628811709709202,
            "precision": 0.7850678733031674,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7952951527713888,
            "auditor_fn_violation": 0.00575515928480776,
            "auditor_fp_violation": 0.009103549213318702,
            "ave_precision_score": 0.7956930244537209,
            "fpr": 0.10537870472008781,
            "logloss": 0.7246434196882702,
            "mae": 0.358127034854819,
            "precision": 0.775175644028103,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 22571,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8296593096909965,
            "auditor_fn_violation": 0.008518380128821045,
            "auditor_fp_violation": 0.015662291169451083,
            "ave_precision_score": 0.8299891439412378,
            "fpr": 0.12609649122807018,
            "logloss": 0.803703943688854,
            "mae": 0.2800912762099366,
            "precision": 0.7594142259414226,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.81973443113685,
            "auditor_fn_violation": 0.007055249052910798,
            "auditor_fp_violation": 0.019392608854738386,
            "ave_precision_score": 0.8199660066290451,
            "fpr": 0.13721185510428102,
            "logloss": 0.7763194243414211,
            "mae": 0.27419133744584157,
            "precision": 0.7357293868921776,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6596500469253439,
            "auditor_fn_violation": 0.00346962741539447,
            "auditor_fp_violation": 0.009606728635431067,
            "ave_precision_score": 0.6396202243241591,
            "fpr": 0.2631578947368421,
            "logloss": 2.685852052763958,
            "mae": 0.34783410783366936,
            "precision": 0.6496350364963503,
            "recall": 0.9026369168356998
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6408399128025828,
            "auditor_fn_violation": 0.009903064735422207,
            "auditor_fp_violation": 0.028188803512623498,
            "ave_precision_score": 0.6243937877799686,
            "fpr": 0.2897914379802415,
            "logloss": 2.5916140586706247,
            "mae": 0.36030184027138773,
            "precision": 0.6190476190476191,
            "recall": 0.93058568329718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.769468188685477,
            "auditor_fn_violation": 0.0028691149781146586,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6028763258060734,
            "fpr": 0.4331140350877193,
            "logloss": 0.6838179963330949,
            "mae": 0.4653481416927095,
            "precision": 0.5480549199084668,
            "recall": 0.9716024340770791
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7796106003917384,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.5983343208898488,
            "fpr": 0.45334796926454446,
            "logloss": 0.6814296637999387,
            "mae": 0.46278092327285414,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8189512314609955,
            "auditor_fn_violation": 0.014968328529233839,
            "auditor_fp_violation": 0.004472323409956873,
            "ave_precision_score": 0.8209168770836794,
            "fpr": 0.08442982456140351,
            "logloss": 1.0443937687909963,
            "mae": 0.2968318383520518,
            "precision": 0.8005181347150259,
            "recall": 0.6267748478701826
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8095385826549759,
            "auditor_fn_violation": 0.0067099871181581635,
            "auditor_fp_violation": 0.013611416026344676,
            "ave_precision_score": 0.8098814992977028,
            "fpr": 0.09769484083424808,
            "logloss": 0.9611175138798169,
            "mae": 0.28405185781683884,
            "precision": 0.7700258397932817,
            "recall": 0.6464208242950108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 22571,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.6423275721182008,
            "auditor_fn_violation": 0.002982545105156426,
            "auditor_fp_violation": 0.002229619394548424,
            "ave_precision_score": 0.6245155551466867,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6951805882912118,
            "mae": 0.49838265034843954,
            "precision": 0.6363636363636364,
            "recall": 0.014198782961460446
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6605711895519394,
            "auditor_fn_violation": 0.004676513378304712,
            "auditor_fp_violation": 0.0015587266739846323,
            "ave_precision_score": 0.6294648805448535,
            "fpr": 0.003293084522502744,
            "logloss": 0.6863646302095044,
            "mae": 0.4945249795324847,
            "precision": 0.8235294117647058,
            "recall": 0.03036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7820698484548889,
            "auditor_fn_violation": 0.0034940927369132785,
            "auditor_fp_violation": 0.0006411464221412721,
            "ave_precision_score": 0.6230268034189825,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6525635125853628,
            "mae": 0.4635270464381105,
            "precision": 0.9512195121951219,
            "recall": 0.15821501014198783
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7881744223827989,
            "auditor_fn_violation": 0.00491700617423586,
            "auditor_fp_violation": 0.001136723990730577,
            "ave_precision_score": 0.6213901587325406,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6299157143824751,
            "mae": 0.4498725212889628,
            "precision": 0.96,
            "recall": 0.20824295010845986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.6280585728222872,
            "auditor_fn_violation": 0.004228052382477515,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5533922788336183,
            "fpr": 0.0,
            "logloss": 0.688603055528081,
            "mae": 0.49612493835912463,
            "precision": 1.0,
            "recall": 0.018255578093306288
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.6448451804452016,
            "auditor_fn_violation": 0.003409759245281232,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5423151908944016,
            "fpr": 0.0,
            "logloss": 0.6844046856044124,
            "mae": 0.49354884165832946,
            "precision": 1.0,
            "recall": 0.026030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5497325358941764,
            "auditor_fn_violation": 0.0012833173196683536,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5502571910304568,
            "fpr": 0.0,
            "logloss": 0.6891530836661841,
            "mae": 0.49660292715487775,
            "precision": 1.0,
            "recall": 0.016227180527383367
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5376108923738372,
            "auditor_fn_violation": 0.0011810339285331696,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5376908797168585,
            "fpr": 0.0,
            "logloss": 0.6860202572025013,
            "mae": 0.49471797809642704,
            "precision": 1.0,
            "recall": 0.021691973969631236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8225988094512711,
            "auditor_fn_violation": 0.013996388028895768,
            "auditor_fp_violation": 0.005945651718795801,
            "ave_precision_score": 0.8232066619313866,
            "fpr": 0.08552631578947369,
            "logloss": 1.01887395510576,
            "mae": 0.2949862480527518,
            "precision": 0.8010204081632653,
            "recall": 0.6369168356997972
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8108060743976307,
            "auditor_fn_violation": 0.0025192215652985626,
            "auditor_fp_violation": 0.01295279912184413,
            "ave_precision_score": 0.8111401392967204,
            "fpr": 0.09659714599341383,
            "logloss": 0.9399369558777201,
            "mae": 0.2821657349534176,
            "precision": 0.7731958762886598,
            "recall": 0.6507592190889371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8359635653594258,
            "auditor_fn_violation": 0.0011854560335931138,
            "auditor_fp_violation": 0.01190962190679563,
            "ave_precision_score": 0.8361708740565528,
            "fpr": 0.13157894736842105,
            "logloss": 0.7836487625458561,
            "mae": 0.2785483895557861,
            "precision": 0.7590361445783133,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8139355642517782,
            "auditor_fn_violation": 0.006571882344257107,
            "auditor_fp_violation": 0.01583119892669839,
            "ave_precision_score": 0.8141520873457687,
            "fpr": 0.14270032930845225,
            "logloss": 0.7916285641297615,
            "mae": 0.28153186239775496,
            "precision": 0.7341513292433538,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8285049155319093,
            "auditor_fn_violation": 0.00986619693249351,
            "auditor_fp_violation": 0.013006113134865807,
            "ave_precision_score": 0.8288638227668808,
            "fpr": 0.11732456140350878,
            "logloss": 0.7725126260156234,
            "mae": 0.28261022109491285,
            "precision": 0.7703862660944206,
            "recall": 0.7281947261663286
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.821979208222317,
            "auditor_fn_violation": 0.0069933400163344605,
            "auditor_fp_violation": 0.01444078546164167,
            "ave_precision_score": 0.8221503613808734,
            "fpr": 0.132821075740944,
            "logloss": 0.7402675011915161,
            "mae": 0.2771483426982457,
            "precision": 0.7414529914529915,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7803112933554408,
            "auditor_fn_violation": 0.0028691149781146586,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6209728803776566,
            "fpr": 0.4331140350877193,
            "logloss": 0.6654790206809802,
            "mae": 0.45863706984540875,
            "precision": 0.5480549199084668,
            "recall": 0.9716024340770791
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7873768589768703,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.6202931176576497,
            "fpr": 0.45334796926454446,
            "logloss": 0.6603663492529478,
            "mae": 0.4529551339267245,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8203738033215162,
            "auditor_fn_violation": 0.008625137895448567,
            "auditor_fp_violation": 0.012966859272285726,
            "ave_precision_score": 0.8204913442658881,
            "fpr": 0.12390350877192982,
            "logloss": 0.6601807761939414,
            "mae": 0.3088418081405938,
            "precision": 0.755939524838013,
            "recall": 0.7099391480730223
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8078767369413257,
            "auditor_fn_violation": 0.014229553945391469,
            "auditor_fp_violation": 0.012367361873399194,
            "ave_precision_score": 0.8078077387755844,
            "fpr": 0.13172338090010977,
            "logloss": 0.6455546760631556,
            "mae": 0.3041187907734133,
            "precision": 0.7362637362637363,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8367895608541623,
            "auditor_fn_violation": 0.007352941176470593,
            "auditor_fp_violation": 0.015484340325754724,
            "ave_precision_score": 0.837226717627009,
            "fpr": 0.13048245614035087,
            "logloss": 0.7965412822899551,
            "mae": 0.2710195393931774,
            "precision": 0.7629482071713147,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8233910629449619,
            "auditor_fn_violation": 0.004471737334244508,
            "auditor_fp_violation": 0.02173435784851812,
            "ave_precision_score": 0.8237060870644229,
            "fpr": 0.1394072447859495,
            "logloss": 0.7635958868676809,
            "mae": 0.26712410320069846,
            "precision": 0.744466800804829,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5111417220284762,
            "auditor_fn_violation": 0.002146275933240809,
            "auditor_fp_violation": 0.0009630280952979106,
            "ave_precision_score": 0.44238544971575705,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6883390780234879,
            "mae": 0.4937543238333443,
            "precision": 0.875,
            "recall": 0.028397565922920892
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5180228873325656,
            "auditor_fn_violation": 0.006414728636024874,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4229135683697104,
            "fpr": 0.0,
            "logloss": 0.6805651597459437,
            "mae": 0.49087533842195663,
            "precision": 1.0,
            "recall": 0.0455531453362256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7803112933554408,
            "auditor_fn_violation": 0.0028691149781146586,
            "auditor_fp_violation": 0.0022531717120964764,
            "ave_precision_score": 0.6209728803776566,
            "fpr": 0.4331140350877193,
            "logloss": 0.6654799688256225,
            "mae": 0.4586369431855386,
            "precision": 0.5480549199084668,
            "recall": 0.9716024340770791
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7873768589768703,
            "auditor_fn_violation": 0.0004881289422364878,
            "auditor_fp_violation": 0.004020002439321888,
            "ave_precision_score": 0.6202931176576497,
            "fpr": 0.45334796926454446,
            "logloss": 0.6603675160982707,
            "mae": 0.45295510932590516,
            "precision": 0.5219907407407407,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7129507450357306,
            "auditor_fn_violation": 0.007088270880039865,
            "auditor_fp_violation": 0.005100385211238126,
            "ave_precision_score": 0.7142209905865211,
            "fpr": 0.11513157894736842,
            "logloss": 0.7345668067298304,
            "mae": 0.39833450310004737,
            "precision": 0.7697368421052632,
            "recall": 0.7119675456389453
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7510615065734084,
            "auditor_fn_violation": 0.0013691421550535625,
            "auditor_fp_violation": 0.009635321380656174,
            "ave_precision_score": 0.7521284722477947,
            "fpr": 0.10976948408342481,
            "logloss": 0.6368391510410727,
            "mae": 0.3728486390868212,
            "precision": 0.7722095671981777,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8438341521489847,
            "auditor_fn_violation": 0.009470303547916446,
            "auditor_fp_violation": 0.01110360926181803,
            "ave_precision_score": 0.8442129076105664,
            "fpr": 0.11951754385964912,
            "logloss": 0.7786174189025805,
            "mae": 0.26743878192068726,
            "precision": 0.7770961145194274,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8370517372675257,
            "auditor_fn_violation": 0.007874353229151537,
            "auditor_fp_violation": 0.01793389437736309,
            "ave_precision_score": 0.8373297603605736,
            "fpr": 0.12733260153677278,
            "logloss": 0.7079631578058099,
            "mae": 0.260392192692269,
            "precision": 0.7557894736842106,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.83931626761904,
            "auditor_fn_violation": 0.008531724849649487,
            "auditor_fp_violation": 0.010255725830088358,
            "ave_precision_score": 0.8395154717520315,
            "fpr": 0.12719298245614036,
            "logloss": 0.6120848185082668,
            "mae": 0.34698979607797925,
            "precision": 0.7552742616033755,
            "recall": 0.7261663286004056
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8362129968573122,
            "auditor_fn_violation": 0.008460107959835329,
            "auditor_fp_violation": 0.009564581046469085,
            "ave_precision_score": 0.8362671666829256,
            "fpr": 0.141602634467618,
            "logloss": 0.6717092016394574,
            "mae": 0.35714551103127706,
            "precision": 0.725531914893617,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5873777180169146,
            "auditor_fn_violation": 0.0020283975659229373,
            "auditor_fp_violation": 0.008180504961688229,
            "ave_precision_score": 0.5934248275919223,
            "fpr": 0.046052631578947366,
            "logloss": 0.6813816282327014,
            "mae": 0.48853407283885436,
            "precision": 0.5625,
            "recall": 0.10953346855983773
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5912913133979281,
            "auditor_fn_violation": 0.0036264408732983896,
            "auditor_fp_violation": 0.004610318331503844,
            "ave_precision_score": 0.5827844120208123,
            "fpr": 0.04610318331503842,
            "logloss": 0.6687626086030524,
            "mae": 0.4824121143632087,
            "precision": 0.6347826086956522,
            "recall": 0.15835140997830802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8341143273505183,
            "auditor_fn_violation": 0.009861748692217365,
            "auditor_fp_violation": 0.011948875769375705,
            "ave_precision_score": 0.8344159267263354,
            "fpr": 0.12171052631578948,
            "logloss": 0.752034061237377,
            "mae": 0.2791319864063543,
            "precision": 0.7682672233820459,
            "recall": 0.7464503042596349
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8248730480669259,
            "auditor_fn_violation": 0.011855580504368161,
            "auditor_fp_violation": 0.01758263202829614,
            "ave_precision_score": 0.8250851044477258,
            "fpr": 0.13391877058177826,
            "logloss": 0.7244337943442073,
            "mae": 0.27380406770453364,
            "precision": 0.7420718816067653,
            "recall": 0.7613882863340564
        }
    }
]