[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.852532112561631,
            "auditor_fn_violation": 0.02107199466839584,
            "auditor_fp_violation": 0.018369453044375646,
            "ave_precision_score": 0.8529758729468078,
            "fpr": 0.10855263157894737,
            "logloss": 0.6876552500105981,
            "mae": 0.26345183289526963,
            "precision": 0.7906976744186046,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8494123677999604,
            "auditor_fn_violation": 0.008161020315581394,
            "auditor_fp_violation": 0.017634813737997055,
            "ave_precision_score": 0.8496601396312863,
            "fpr": 0.12403951701427003,
            "logloss": 0.6750012403891499,
            "mae": 0.2597600627001225,
            "precision": 0.7670103092783506,
            "recall": 0.7965738758029979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7977371963882198,
            "auditor_fn_violation": 0.010073309557260705,
            "auditor_fp_violation": 0.002291021671826628,
            "ave_precision_score": 0.7691631309113488,
            "fpr": 0.08333333333333333,
            "logloss": 0.5904072625905447,
            "mae": 0.3548241972825245,
            "precision": 0.8020833333333334,
            "recall": 0.6324435318275154
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8648289388103494,
            "auditor_fn_violation": 0.003304837143924951,
            "auditor_fp_violation": 0.009088122150690756,
            "ave_precision_score": 0.8423151194697915,
            "fpr": 0.07025246981339188,
            "logloss": 0.4776022322758825,
            "mae": 0.306246292676151,
            "precision": 0.8442822384428224,
            "recall": 0.7430406852248393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7234457306751969,
            "auditor_fn_violation": 0.015440938074138119,
            "auditor_fp_violation": 0.033356553147574824,
            "ave_precision_score": 0.6276881589189156,
            "fpr": 0.28618421052631576,
            "logloss": 0.6529708911084541,
            "mae": 0.44588591284200285,
            "precision": 0.6173020527859238,
            "recall": 0.864476386036961
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.706370296529928,
            "auditor_fn_violation": 0.0039042208364575737,
            "auditor_fp_violation": 0.043299611356691484,
            "ave_precision_score": 0.6116326076140945,
            "fpr": 0.2864983534577388,
            "logloss": 0.6235477103921995,
            "mae": 0.43426705198413584,
            "precision": 0.6167400881057269,
            "recall": 0.8993576017130621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7738747099735688,
            "auditor_fn_violation": 0.005959778810475882,
            "auditor_fp_violation": 0.01638028895768834,
            "ave_precision_score": 0.7743862342730988,
            "fpr": 0.20065789473684212,
            "logloss": 0.6087232989397601,
            "mae": 0.3758483370847739,
            "precision": 0.6975206611570248,
            "recall": 0.86652977412731
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8381290775850424,
            "auditor_fn_violation": 0.001107096937972016,
            "auditor_fp_violation": 0.01992167798973507,
            "ave_precision_score": 0.8384105043432444,
            "fpr": 0.20856201975850713,
            "logloss": 0.589950115968103,
            "mae": 0.3509885082440502,
            "precision": 0.6905537459283387,
            "recall": 0.9079229122055674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.821159427755147,
            "auditor_fn_violation": 0.015283331532115719,
            "auditor_fp_violation": 0.0030598555211558322,
            "ave_precision_score": 0.8215936052418892,
            "fpr": 0.0537280701754386,
            "logloss": 0.5837434224165667,
            "mae": 0.35997934296335043,
            "precision": 0.8419354838709677,
            "recall": 0.5359342915811088
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8732526285566582,
            "auditor_fn_violation": 0.015873090492834425,
            "auditor_fp_violation": 0.005532975346367226,
            "ave_precision_score": 0.873445160026805,
            "fpr": 0.050493962678375415,
            "logloss": 0.48097522174693225,
            "mae": 0.31507626025396696,
            "precision": 0.8707865168539326,
            "recall": 0.6638115631691649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8303471809880387,
            "auditor_fn_violation": 0.008467974350661047,
            "auditor_fp_violation": 0.019840041279669766,
            "ave_precision_score": 0.8307403246497347,
            "fpr": 0.17105263157894737,
            "logloss": 0.563539654573928,
            "mae": 0.30252824100845926,
            "precision": 0.7263157894736842,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8359879684140528,
            "auditor_fn_violation": 0.006109012615263835,
            "auditor_fp_violation": 0.02506155991337111,
            "ave_precision_score": 0.8362529797232733,
            "fpr": 0.1986827661909989,
            "logloss": 0.5593874985653049,
            "mae": 0.30034941168271834,
            "precision": 0.6937394247038917,
            "recall": 0.8779443254817987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7417599365426859,
            "auditor_fn_violation": 0.013331261933066755,
            "auditor_fp_violation": 0.0260964912280702,
            "ave_precision_score": 0.7417768491271517,
            "fpr": 0.39144736842105265,
            "logloss": 1.1861405240054674,
            "mae": 0.414320349737351,
            "precision": 0.55980271270037,
            "recall": 0.9322381930184805
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7843188511032706,
            "auditor_fn_violation": 0.011752621422208225,
            "auditor_fp_violation": 0.020786977976879183,
            "ave_precision_score": 0.7842283305275145,
            "fpr": 0.41712403951701427,
            "logloss": 1.1165426182785854,
            "mae": 0.41961243589979164,
            "precision": 0.536019536019536,
            "recall": 0.9400428265524625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6599269118515197,
            "auditor_fn_violation": 0.02724341654958753,
            "auditor_fp_violation": 0.05926212590299279,
            "ave_precision_score": 0.6617818897598213,
            "fpr": 0.2719298245614035,
            "logloss": 0.6938524182765444,
            "mae": 0.4922552147733146,
            "precision": 0.5921052631578947,
            "recall": 0.7392197125256673
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6410908190169677,
            "auditor_fn_violation": 0.010100202850245751,
            "auditor_fp_violation": 0.04598451360251581,
            "ave_precision_score": 0.6423982827156343,
            "fpr": 0.29857299670691545,
            "logloss": 0.6974114167752543,
            "mae": 0.49271500020663117,
            "precision": 0.5729984301412873,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7493876962297952,
            "auditor_fn_violation": 0.015555765697611591,
            "auditor_fp_violation": 0.023596491228070178,
            "ave_precision_score": 0.6996754053033817,
            "fpr": 0.14473684210526316,
            "logloss": 0.6324400151153566,
            "mae": 0.4172906611735622,
            "precision": 0.7079646017699115,
            "recall": 0.6570841889117043
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7512864963672886,
            "auditor_fn_violation": 0.01449803378643607,
            "auditor_fp_violation": 0.02763273701802791,
            "ave_precision_score": 0.6940508844248852,
            "fpr": 0.17233809001097694,
            "logloss": 0.6199367506080345,
            "mae": 0.41404778613380755,
            "precision": 0.6722338204592901,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 31658,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7349675105817237,
            "auditor_fn_violation": 0.011214831225908719,
            "auditor_fp_violation": 0.013795149638802889,
            "ave_precision_score": 0.7356033301673768,
            "fpr": 0.18859649122807018,
            "logloss": 0.747808667963082,
            "mae": 0.36169255423163504,
            "precision": 0.69449378330373,
            "recall": 0.8028747433264887
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8041832725883424,
            "auditor_fn_violation": 0.004534161344687932,
            "auditor_fp_violation": 0.018354248870165447,
            "ave_precision_score": 0.8047379847370729,
            "fpr": 0.1756311745334797,
            "logloss": 0.6420119486894742,
            "mae": 0.3238459196305628,
            "precision": 0.7163120567375887,
            "recall": 0.8650963597430407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7025717885912846,
            "auditor_fn_violation": 0.015909254656147558,
            "auditor_fp_violation": 0.010528895768833861,
            "ave_precision_score": 0.7034951824108551,
            "fpr": 0.18201754385964913,
            "logloss": 0.6484777276696162,
            "mae": 0.43015068488424285,
            "precision": 0.6591375770020534,
            "recall": 0.6591375770020534
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6233596444133603,
            "auditor_fn_violation": 0.007448811457395576,
            "auditor_fp_violation": 0.009787778997438715,
            "ave_precision_score": 0.624632551429867,
            "fpr": 0.2030735455543359,
            "logloss": 0.6633847951320898,
            "mae": 0.4363858299544562,
            "precision": 0.6329365079365079,
            "recall": 0.683083511777302
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8318684999695762,
            "auditor_fn_violation": 0.0017584387045642836,
            "auditor_fp_violation": 0.0070356037151702785,
            "ave_precision_score": 0.8275904508848586,
            "fpr": 0.039473684210526314,
            "logloss": 0.6352912127231384,
            "mae": 0.3336790421172944,
            "precision": 0.8754325259515571,
            "recall": 0.5195071868583162
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8608797726345353,
            "auditor_fn_violation": 0.004336717304794845,
            "auditor_fp_violation": 0.006729561614303657,
            "ave_precision_score": 0.8571398989009784,
            "fpr": 0.04500548847420417,
            "logloss": 0.5091380345069613,
            "mae": 0.2994899244439245,
            "precision": 0.8738461538461538,
            "recall": 0.6081370449678801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7904411005954398,
            "auditor_fn_violation": 0.008675114377319068,
            "auditor_fp_violation": 0.002755417956656347,
            "ave_precision_score": 0.7954581885502113,
            "fpr": 0.08333333333333333,
            "logloss": 0.5517731996465853,
            "mae": 0.3400340042027988,
            "precision": 0.8,
            "recall": 0.6242299794661191
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8527547717144406,
            "auditor_fn_violation": 0.006849427764862953,
            "auditor_fp_violation": 0.008383520732587694,
            "ave_precision_score": 0.8377996629023929,
            "fpr": 0.06695938529088913,
            "logloss": 0.4641757369205434,
            "mae": 0.3006147571177959,
            "precision": 0.849009900990099,
            "recall": 0.734475374732334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8323882691817761,
            "auditor_fn_violation": 0.0102354191433409,
            "auditor_fp_violation": 0.011777605779153766,
            "ave_precision_score": 0.7742265098059289,
            "fpr": 0.09868421052631579,
            "logloss": 0.5860167226369365,
            "mae": 0.3584280887193847,
            "precision": 0.788235294117647,
            "recall": 0.6878850102669405
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.847440379666519,
            "auditor_fn_violation": 0.0007850751110035105,
            "auditor_fp_violation": 0.009997923280030853,
            "ave_precision_score": 0.7870500430407241,
            "fpr": 0.09769484083424808,
            "logloss": 0.507303329825927,
            "mae": 0.32487382884541144,
            "precision": 0.8043956043956044,
            "recall": 0.7837259100642399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7544038550180404,
            "auditor_fn_violation": 0.08838800028819482,
            "auditor_fp_violation": 0.0829747162022704,
            "ave_precision_score": 0.6031398641144063,
            "fpr": 0.23793859649122806,
            "logloss": 0.6983772636342727,
            "mae": 0.4365051998184961,
            "precision": 0.6265060240963856,
            "recall": 0.7474332648870636
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7417074706584976,
            "auditor_fn_violation": 0.08028450745938881,
            "auditor_fp_violation": 0.09159076749636576,
            "ave_precision_score": 0.5804762797563839,
            "fpr": 0.2557628979143798,
            "logloss": 0.7046400438690744,
            "mae": 0.43971035034936556,
            "precision": 0.6023890784982935,
            "recall": 0.7558886509635975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7581759873946774,
            "auditor_fn_violation": 0.003084585179581397,
            "auditor_fp_violation": 0.009801341589267298,
            "ave_precision_score": 0.7599566250486096,
            "fpr": 0.4243421052631579,
            "logloss": 1.5897157731548885,
            "mae": 0.41517199689437684,
            "precision": 0.5546605293440736,
            "recall": 0.9897330595482546
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.8282208254449188,
            "auditor_fn_violation": 0.0011000453651186899,
            "auditor_fp_violation": 0.01833447058474501,
            "ave_precision_score": 0.8286266549342525,
            "fpr": 0.43798024149286496,
            "logloss": 1.6123166010885506,
            "mae": 0.4268763531326481,
            "precision": 0.5381944444444444,
            "recall": 0.9957173447537473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.8242923122998806,
            "auditor_fn_violation": 0.006477628877120935,
            "auditor_fp_violation": 0.023694530443756478,
            "ave_precision_score": 0.8247224933787111,
            "fpr": 0.3881578947368421,
            "logloss": 0.7247575323487221,
            "mae": 0.3725386596154042,
            "precision": 0.5709090909090909,
            "recall": 0.9671457905544147
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.876554559613731,
            "auditor_fn_violation": 0.005422659524206875,
            "auditor_fp_violation": 0.02423828878274544,
            "ave_precision_score": 0.87673259354799,
            "fpr": 0.39846322722283206,
            "logloss": 0.7027957864689861,
            "mae": 0.36336831761673877,
            "precision": 0.5562347188264058,
            "recall": 0.974304068522484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7986694568788432,
            "auditor_fn_violation": 0.007355722468388627,
            "auditor_fp_violation": 0.007763157894736846,
            "ave_precision_score": 0.7836557212358932,
            "fpr": 0.05592105263157895,
            "logloss": 1.1126081568300756,
            "mae": 0.3710066684868299,
            "precision": 0.8118081180811808,
            "recall": 0.4517453798767967
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8165298426559514,
            "auditor_fn_violation": 0.0053521437956736305,
            "auditor_fp_violation": 0.007594861601447774,
            "ave_precision_score": 0.7906666381864783,
            "fpr": 0.04720087815587267,
            "logloss": 0.9327098781878698,
            "mae": 0.3408333316391068,
            "precision": 0.8458781362007168,
            "recall": 0.5053533190578159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7737920472554525,
            "auditor_fn_violation": 0.009053370078172843,
            "auditor_fp_violation": 0.0036764705882352923,
            "ave_precision_score": 0.6622542329232572,
            "fpr": 0.12609649122807018,
            "logloss": 0.6363716380020942,
            "mae": 0.41450723085405405,
            "precision": 0.7248803827751196,
            "recall": 0.62217659137577
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8259076021582421,
            "auditor_fn_violation": 0.010476286735756417,
            "auditor_fp_violation": 0.010873112409885194,
            "ave_precision_score": 0.7216633215664379,
            "fpr": 0.1119648737650933,
            "logloss": 0.5538562677177917,
            "mae": 0.3771118866903329,
            "precision": 0.7718120805369127,
            "recall": 0.7387580299785867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.6442658201973541,
            "auditor_fn_violation": 0.006581198890449948,
            "auditor_fp_violation": 0.029063467492260065,
            "ave_precision_score": 0.6212094621165489,
            "fpr": 0.25548245614035087,
            "logloss": 2.7386050546293257,
            "mae": 0.3730951480336667,
            "precision": 0.6431852986217458,
            "recall": 0.8624229979466119
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6817184066968707,
            "auditor_fn_violation": 0.004788017967407632,
            "auditor_fp_violation": 0.0377864142957447,
            "ave_precision_score": 0.659236423592068,
            "fpr": 0.25905598243688255,
            "logloss": 2.390408962928406,
            "mae": 0.3511590087729068,
            "precision": 0.6445783132530121,
            "recall": 0.9164882226980728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7224453484941116,
            "auditor_fn_violation": 0.00967479015814691,
            "auditor_fp_violation": 0.01033281733746131,
            "ave_precision_score": 0.6204682616952524,
            "fpr": 0.4057017543859649,
            "logloss": 0.6803427445321244,
            "mae": 0.4598672668073784,
            "precision": 0.5509708737864077,
            "recall": 0.9322381930184805
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.742967683384089,
            "auditor_fn_violation": 0.011651548877977232,
            "auditor_fp_violation": 0.01801060116098538,
            "ave_precision_score": 0.6417559710976697,
            "fpr": 0.40065861690450055,
            "logloss": 0.6475080383306772,
            "mae": 0.4444621009046762,
            "precision": 0.5482673267326733,
            "recall": 0.9486081370449678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7454554809965083,
            "auditor_fn_violation": 0.015028909542850981,
            "auditor_fp_violation": 0.010835913312693502,
            "ave_precision_score": 0.7470836987646386,
            "fpr": 0.05482456140350877,
            "logloss": 0.9014831521421978,
            "mae": 0.41627289865394695,
            "precision": 0.8023715415019763,
            "recall": 0.41683778234086244
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8051032645296566,
            "auditor_fn_violation": 0.002084915040299742,
            "auditor_fp_violation": 0.0007713531313970391,
            "ave_precision_score": 0.8066283037865529,
            "fpr": 0.03951701427003293,
            "logloss": 0.7325311106177552,
            "mae": 0.37029380085913854,
            "precision": 0.8582677165354331,
            "recall": 0.4668094218415418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7834786670301125,
            "auditor_fn_violation": 0.006407831694225305,
            "auditor_fp_violation": 0.004909700722394222,
            "ave_precision_score": 0.7688266567800031,
            "fpr": 0.1337719298245614,
            "logloss": 0.5807123774052001,
            "mae": 0.3506714277369738,
            "precision": 0.7409766454352441,
            "recall": 0.7166324435318275
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.84046164870204,
            "auditor_fn_violation": 0.007742626992950779,
            "auditor_fp_violation": 0.009063399293915217,
            "ave_precision_score": 0.817311358578815,
            "fpr": 0.1251372118551043,
            "logloss": 0.5160251518025565,
            "mae": 0.32012382089993563,
            "precision": 0.7706237424547284,
            "recall": 0.8201284796573876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.5963144112264329,
            "auditor_fn_violation": 0.0017516841384776095,
            "auditor_fp_violation": 0.011578947368421052,
            "ave_precision_score": 0.5926293376867658,
            "fpr": 0.18859649122807018,
            "logloss": 0.6924205048889219,
            "mae": 0.45856814224501713,
            "precision": 0.6348195329087049,
            "recall": 0.6139630390143738
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6839973217329293,
            "auditor_fn_violation": 0.011190846118226669,
            "auditor_fp_violation": 0.0009493577001809702,
            "ave_precision_score": 0.6598882889365943,
            "fpr": 0.1756311745334797,
            "logloss": 0.6218102713588219,
            "mae": 0.4248629999883743,
            "precision": 0.6819085487077535,
            "recall": 0.734475374732334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7758600782438788,
            "auditor_fn_violation": 0.009641017327713539,
            "auditor_fp_violation": 0.018495872033023737,
            "ave_precision_score": 0.6535315725543143,
            "fpr": 0.12938596491228072,
            "logloss": 0.6381265346037498,
            "mae": 0.4300638028142745,
            "precision": 0.7230046948356808,
            "recall": 0.6324435318275154
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.76474402143488,
            "auditor_fn_violation": 0.014117248852356521,
            "auditor_fp_violation": 0.018650923151472005,
            "ave_precision_score": 0.6328877012197347,
            "fpr": 0.14928649835345773,
            "logloss": 0.6518155852625687,
            "mae": 0.43395098039530766,
            "precision": 0.6943820224719102,
            "recall": 0.6616702355460385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 31658,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5818975094124065,
            "auditor_fn_violation": 0.011012194243308474,
            "auditor_fp_violation": 0.019166666666666672,
            "ave_precision_score": 0.5839495137321988,
            "fpr": 0.13048245614035087,
            "logloss": 0.7099576135814047,
            "mae": 0.4895703259430695,
            "precision": 0.6148867313915858,
            "recall": 0.39014373716632444
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.573906601360001,
            "auditor_fn_violation": 0.02032968453613579,
            "auditor_fp_violation": 0.0266858516035245,
            "ave_precision_score": 0.5753565586962421,
            "fpr": 0.15477497255762898,
            "logloss": 0.7003944556691171,
            "mae": 0.48551355022630366,
            "precision": 0.5852941176470589,
            "recall": 0.4261241970021413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7365693412324243,
            "auditor_fn_violation": 0.021522299074174148,
            "auditor_fp_violation": 0.012105263157894746,
            "ave_precision_score": 0.5828252871684019,
            "fpr": 0.2565789473684211,
            "logloss": 0.6754099346287207,
            "mae": 0.4791240999965291,
            "precision": 0.6013628620102215,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7465829447152577,
            "auditor_fn_violation": 0.019685640882198773,
            "auditor_fp_violation": 0.012267481532025991,
            "ave_precision_score": 0.5812430054932994,
            "fpr": 0.265642151481888,
            "logloss": 0.6685190569085208,
            "mae": 0.47545968733817895,
            "precision": 0.6006600660066007,
            "recall": 0.7794432548179872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7683515399830283,
            "auditor_fn_violation": 0.0145155625202637,
            "auditor_fp_violation": 0.015505675954592367,
            "ave_precision_score": 0.6699995679440787,
            "fpr": 0.1425438596491228,
            "logloss": 0.6359501080290996,
            "mae": 0.42386944234175117,
            "precision": 0.7011494252873564,
            "recall": 0.6262833675564682
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.769585724259994,
            "auditor_fn_violation": 0.0158260800071456,
            "auditor_fp_violation": 0.016089635189525425,
            "ave_precision_score": 0.6608415693219711,
            "fpr": 0.1602634467618002,
            "logloss": 0.6041837463949529,
            "mae": 0.411788779542946,
            "precision": 0.6791208791208792,
            "recall": 0.6616702355460385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7027249768282182,
            "auditor_fn_violation": 0.0009771605605389364,
            "auditor_fp_violation": 0.012458720330237358,
            "ave_precision_score": 0.7025615765254034,
            "fpr": 0.11074561403508772,
            "logloss": 0.6377722330710905,
            "mae": 0.41556036624273185,
            "precision": 0.7572115384615384,
            "recall": 0.6468172484599589
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7684593263034505,
            "auditor_fn_violation": 0.004985462007300728,
            "auditor_fp_violation": 0.015011718634111612,
            "ave_precision_score": 0.7673170697320768,
            "fpr": 0.1119648737650933,
            "logloss": 0.5708399327976357,
            "mae": 0.3877409577664115,
            "precision": 0.7713004484304933,
            "recall": 0.7366167023554604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7251022730050629,
            "auditor_fn_violation": 0.018734914802406445,
            "auditor_fp_violation": 0.012254901960784314,
            "ave_precision_score": 0.7199385003395214,
            "fpr": 0.049342105263157895,
            "logloss": 0.7408450967388067,
            "mae": 0.4253271805779118,
            "precision": 0.7954545454545454,
            "recall": 0.3593429158110883
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7324883017940038,
            "auditor_fn_violation": 0.020654056887388753,
            "auditor_fp_violation": 0.008672778156861584,
            "ave_precision_score": 0.7289682644749567,
            "fpr": 0.048298572996706916,
            "logloss": 0.6881022288969108,
            "mae": 0.40590032072672383,
            "precision": 0.7990867579908676,
            "recall": 0.3747323340471092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7986900763666342,
            "auditor_fn_violation": 0.00627274037249181,
            "auditor_fp_violation": 0.011547987616099072,
            "ave_precision_score": 0.7830798242061655,
            "fpr": 0.10526315789473684,
            "logloss": 0.5794113010011082,
            "mae": 0.34872756635345387,
            "precision": 0.7730496453900709,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8611343309078753,
            "auditor_fn_violation": 0.004106365924919557,
            "auditor_fp_violation": 0.011619742684506681,
            "ave_precision_score": 0.8504714014574228,
            "fpr": 0.08781558726673985,
            "logloss": 0.4578107248925246,
            "mae": 0.2923854228301315,
            "precision": 0.8210290827740492,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6850245874273223,
            "auditor_fn_violation": 0.00797038798227603,
            "auditor_fp_violation": 0.007249742002063989,
            "ave_precision_score": 0.685926293673891,
            "fpr": 0.07017543859649122,
            "logloss": 0.7018697879844276,
            "mae": 0.45008209758037865,
            "precision": 0.7155555555555555,
            "recall": 0.33059548254620125
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.689066959527525,
            "auditor_fn_violation": 0.010584410852840736,
            "auditor_fp_violation": 0.008966980152490586,
            "ave_precision_score": 0.6896532402371361,
            "fpr": 0.07574094401756312,
            "logloss": 0.673300913126956,
            "mae": 0.43566215681126824,
            "precision": 0.7063829787234043,
            "recall": 0.3554603854389722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7908575889249432,
            "auditor_fn_violation": 0.015179761518786701,
            "auditor_fp_violation": 0.010356037151702788,
            "ave_precision_score": 0.7874451040677114,
            "fpr": 0.051535087719298246,
            "logloss": 0.59098409202822,
            "mae": 0.3665643595444986,
            "precision": 0.8575757575757575,
            "recall": 0.5811088295687885
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7970377288972204,
            "auditor_fn_violation": 0.010953443165498063,
            "auditor_fp_violation": 0.009938588423769545,
            "ave_precision_score": 0.79414075115783,
            "fpr": 0.06586169045005488,
            "logloss": 0.5280444206101094,
            "mae": 0.3463286434460746,
            "precision": 0.8314606741573034,
            "recall": 0.6338329764453962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5770673317245115,
            "auditor_fn_violation": 0.011748441946756009,
            "auditor_fp_violation": 0.01553405572755418,
            "ave_precision_score": 0.521066660096946,
            "fpr": 0.31359649122807015,
            "logloss": 1.2044034240694836,
            "mae": 0.4970602711423692,
            "precision": 0.5565891472868217,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5559153419987447,
            "auditor_fn_violation": 0.0024727515472326134,
            "auditor_fp_violation": 0.023635051077422104,
            "ave_precision_score": 0.499441685200284,
            "fpr": 0.3336992316136114,
            "logloss": 1.2143560119247399,
            "mae": 0.4995075326942472,
            "precision": 0.5257410296411856,
            "recall": 0.721627408993576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6917098822949028,
            "auditor_fn_violation": 0.0038523541914334304,
            "auditor_fp_violation": 0.0016253869969040245,
            "ave_precision_score": 0.6149157259266946,
            "fpr": 0.005482456140350877,
            "logloss": 0.6855928831618678,
            "mae": 0.47188432787416423,
            "precision": 0.9038461538461539,
            "recall": 0.09650924024640657
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7427660853019658,
            "auditor_fn_violation": 0.007039820231902724,
            "auditor_fp_violation": 0.0012311982674221972,
            "ave_precision_score": 0.6379833586294035,
            "fpr": 0.006586169045005488,
            "logloss": 0.6499485186437289,
            "mae": 0.45231030792308563,
            "precision": 0.9142857142857143,
            "recall": 0.13704496788008566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8378944727647858,
            "auditor_fn_violation": 0.0069549515472459396,
            "auditor_fp_violation": 0.004063467492260066,
            "ave_precision_score": 0.7812737006420772,
            "fpr": 0.08223684210526316,
            "logloss": 0.5602417010809192,
            "mae": 0.33902733991935585,
            "precision": 0.8015873015873016,
            "recall": 0.62217659137577
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8723850622235033,
            "auditor_fn_violation": 0.004294407867674885,
            "auditor_fp_violation": 0.008781558726673987,
            "ave_precision_score": 0.8176401199999817,
            "fpr": 0.06586169045005488,
            "logloss": 0.47162068212824,
            "mae": 0.29818441407217283,
            "precision": 0.8503740648379052,
            "recall": 0.7301927194860813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8389501138636364,
            "auditor_fn_violation": 0.009832396700169317,
            "auditor_fp_violation": 0.0189499484004128,
            "ave_precision_score": 0.8391962337930863,
            "fpr": 0.25877192982456143,
            "logloss": 1.0720689181161414,
            "mae": 0.30797650538416,
            "precision": 0.6574746008708273,
            "recall": 0.9301848049281314
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8369439720367013,
            "auditor_fn_violation": 0.004665790704616667,
            "auditor_fp_violation": 0.03411754235025367,
            "ave_precision_score": 0.8371748103932555,
            "fpr": 0.27991218441273324,
            "logloss": 1.1561872578069974,
            "mae": 0.3153431591986476,
            "precision": 0.6336206896551724,
            "recall": 0.9443254817987152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6884945294077484,
            "auditor_fn_violation": 0.004978115205879194,
            "auditor_fp_violation": 0.004749742002063984,
            "ave_precision_score": 0.6119820369686132,
            "fpr": 0.03070175438596491,
            "logloss": 0.674462242078375,
            "mae": 0.44900488180288095,
            "precision": 0.8227848101265823,
            "recall": 0.2669404517453799
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7715526210282209,
            "auditor_fn_violation": 0.007707369128684161,
            "auditor_fp_violation": 0.0030409113833921747,
            "ave_precision_score": 0.6486957041333061,
            "fpr": 0.01646542261251372,
            "logloss": 0.6113212230650583,
            "mae": 0.4216445437770513,
            "precision": 0.9127906976744186,
            "recall": 0.3361884368308351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7848627740628855,
            "auditor_fn_violation": 0.051708454915522895,
            "auditor_fp_violation": 0.020575335397316825,
            "ave_precision_score": 0.7851880083746035,
            "fpr": 0.12719298245614036,
            "logloss": 1.9083469751712514,
            "mae": 0.3808076508503371,
            "precision": 0.7456140350877193,
            "recall": 0.6981519507186859
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8071029967356222,
            "auditor_fn_violation": 0.03705601534422254,
            "auditor_fp_violation": 0.03813747886195746,
            "ave_precision_score": 0.807364197352384,
            "fpr": 0.15916575192096596,
            "logloss": 1.530952958398908,
            "mae": 0.3655308265830627,
            "precision": 0.7128712871287128,
            "recall": 0.7708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7551504126446245,
            "auditor_fn_violation": 0.003719514391728809,
            "auditor_fp_violation": 0.009138286893704866,
            "ave_precision_score": 0.7209904632283324,
            "fpr": 0.4199561403508772,
            "logloss": 2.3243580503072474,
            "mae": 0.401114287181643,
            "precision": 0.5541327124563445,
            "recall": 0.9774127310061602
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7421814979302057,
            "auditor_fn_violation": 0.0038172514379332307,
            "auditor_fp_violation": 0.015946242620227254,
            "ave_precision_score": 0.7022945765209263,
            "fpr": 0.43688254665203075,
            "logloss": 2.6421205148472615,
            "mae": 0.41296884132923334,
            "precision": 0.5339578454332553,
            "recall": 0.9764453961456103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7909085548494043,
            "auditor_fn_violation": 0.00695270002521705,
            "auditor_fp_violation": 0.015663054695562447,
            "ave_precision_score": 0.7913440449709394,
            "fpr": 0.20394736842105263,
            "logloss": 0.6227650391705689,
            "mae": 0.3457715436795792,
            "precision": 0.6915422885572139,
            "recall": 0.8562628336755647
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8552934202845413,
            "auditor_fn_violation": 0.0034646727952669875,
            "auditor_fp_violation": 0.016050078618684557,
            "ave_precision_score": 0.855529223943702,
            "fpr": 0.23380900109769484,
            "logloss": 0.534320722392156,
            "mae": 0.3287495436610983,
            "precision": 0.6650943396226415,
            "recall": 0.9057815845824411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.8070011197022287,
            "auditor_fn_violation": 0.027162361756547453,
            "auditor_fp_violation": 0.0035964912280701763,
            "ave_precision_score": 0.8074831765771068,
            "fpr": 0.025219298245614034,
            "logloss": 0.9386192775199972,
            "mae": 0.3967507351552373,
            "precision": 0.8722222222222222,
            "recall": 0.32238193018480493
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8455792476649392,
            "auditor_fn_violation": 0.02636818142286638,
            "auditor_fp_violation": 0.00452922736128005,
            "ave_precision_score": 0.8460879605106043,
            "fpr": 0.024149286498353458,
            "logloss": 0.7393437618400815,
            "mae": 0.347692012177378,
            "precision": 0.8952380952380953,
            "recall": 0.4025695931477516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5129208343602092,
            "auditor_fn_violation": 0.0210021974855002,
            "auditor_fp_violation": 0.019164086687306518,
            "ave_precision_score": 0.5148959102427504,
            "fpr": 0.30372807017543857,
            "logloss": 1.388971962622598,
            "mae": 0.49736455803712243,
            "precision": 0.5421487603305785,
            "recall": 0.6735112936344969
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5581819882187573,
            "auditor_fn_violation": 0.015414738257368313,
            "auditor_fp_violation": 0.02676990931656135,
            "ave_precision_score": 0.5596869506972972,
            "fpr": 0.29857299670691545,
            "logloss": 1.1932582794583495,
            "mae": 0.4684152059393314,
            "precision": 0.5496688741721855,
            "recall": 0.7109207708779444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7669956140350878,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.46600877192982454,
            "logloss": 0.6920375712733684,
            "mae": 0.4993553318475422,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.756311745334797,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.48737650933040616,
            "logloss": 0.6928481775714567,
            "mae": 0.49976058639626864,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6752400752487365,
            "auditor_fn_violation": 0.012036636766454122,
            "auditor_fp_violation": 0.018660990712074305,
            "ave_precision_score": 0.6808963643113709,
            "fpr": 0.1513157894736842,
            "logloss": 0.6498433472433358,
            "mae": 0.39970860767521355,
            "precision": 0.7142857142857143,
            "recall": 0.7084188911704312
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6200533635373136,
            "auditor_fn_violation": 0.006104311566694951,
            "auditor_fp_violation": 0.0164777840409015,
            "ave_precision_score": 0.6692789888600625,
            "fpr": 0.15916575192096596,
            "logloss": 0.660420652451075,
            "mae": 0.4009134326821232,
            "precision": 0.7134387351778656,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7813750941233887,
            "auditor_fn_violation": 0.007389495298822009,
            "auditor_fp_violation": 0.021039731682146543,
            "ave_precision_score": 0.7335318110510386,
            "fpr": 0.15021929824561403,
            "logloss": 3.1969294530157963,
            "mae": 0.32146077309798304,
            "precision": 0.7145833333333333,
            "recall": 0.704312114989733
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.761643056962958,
            "auditor_fn_violation": 0.011604538392288406,
            "auditor_fp_violation": 0.024653632776574605,
            "ave_precision_score": 0.7085037246900369,
            "fpr": 0.18441273326015367,
            "logloss": 3.4953958759008494,
            "mae": 0.3368151779688042,
            "precision": 0.6679841897233202,
            "recall": 0.7237687366167024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.42421004626211756,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5441609752303018,
            "fpr": 0.46600877192982454,
            "logloss": 1.0173670608359957,
            "mae": 0.48327062089453665,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.3832209970264008,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5133598354310449,
            "fpr": 0.48737650933040616,
            "logloss": 1.0392311700002328,
            "mae": 0.49511940163916995,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8256047964757854,
            "auditor_fn_violation": 0.025498486977196585,
            "auditor_fp_violation": 0.017456140350877194,
            "ave_precision_score": 0.8260586601824237,
            "fpr": 0.10526315789473684,
            "logloss": 0.5405684146915748,
            "mae": 0.3231580253433142,
            "precision": 0.788546255506608,
            "recall": 0.7351129363449692
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8667073458917953,
            "auditor_fn_violation": 0.008132814024168092,
            "auditor_fp_violation": 0.021338297682973864,
            "ave_precision_score": 0.8669261365511102,
            "fpr": 0.11745334796926454,
            "logloss": 0.4681960051286536,
            "mae": 0.29298892660571507,
            "precision": 0.7811860940695297,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8359325515066629,
            "auditor_fn_violation": 0.006914424150725896,
            "auditor_fp_violation": 0.00989422084623323,
            "ave_precision_score": 0.8362241713203972,
            "fpr": 0.1699561403508772,
            "logloss": 0.5348793083109039,
            "mae": 0.3239842654254876,
            "precision": 0.727112676056338,
            "recall": 0.8480492813141683
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8523743979012287,
            "auditor_fn_violation": 0.007620399730159815,
            "auditor_fp_violation": 0.011194509547967288,
            "ave_precision_score": 0.8526714718205791,
            "fpr": 0.1756311745334797,
            "logloss": 0.5115516314828316,
            "mae": 0.3135349162323676,
            "precision": 0.7227036395147314,
            "recall": 0.892933618843683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8423715570835899,
            "auditor_fn_violation": 0.002235761374689295,
            "auditor_fp_violation": 0.019308565531475752,
            "ave_precision_score": 0.8426067447614771,
            "fpr": 0.17324561403508773,
            "logloss": 0.5962582710298767,
            "mae": 0.34023648362582254,
            "precision": 0.7228070175438597,
            "recall": 0.8459958932238193
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8831374200756075,
            "auditor_fn_violation": 0.00461642969464339,
            "auditor_fp_violation": 0.017503782597086667,
            "ave_precision_score": 0.8834872020249656,
            "fpr": 0.16794731064763996,
            "logloss": 0.5327772230620832,
            "mae": 0.31173500579574304,
            "precision": 0.7292035398230089,
            "recall": 0.8822269807280514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7615449096147393,
            "auditor_fn_violation": 0.005592780719766563,
            "auditor_fp_violation": 0.0005417956656346721,
            "ave_precision_score": 0.5317441990674461,
            "fpr": 0.4616228070175439,
            "logloss": 0.6940433442918279,
            "mae": 0.4993928288877533,
            "precision": 0.5317018909899889,
            "recall": 0.9815195071868583
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7562123286043396,
            "auditor_fn_violation": 0.0001574851270575903,
            "auditor_fp_violation": 0.001176807982516,
            "ave_precision_score": 0.5155367200209562,
            "fpr": 0.47859495060373214,
            "logloss": 0.6916302144727589,
            "mae": 0.4983245841954333,
            "precision": 0.5155555555555555,
            "recall": 0.9935760171306209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7323660374810274,
            "auditor_fn_violation": 0.03038203825786232,
            "auditor_fp_violation": 0.003699690402476779,
            "ave_precision_score": 0.7103531036781259,
            "fpr": 0.10526315789473684,
            "logloss": 0.646437511856544,
            "mae": 0.40322008288918015,
            "precision": 0.7249283667621776,
            "recall": 0.5195071868583162
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7938259364087303,
            "auditor_fn_violation": 0.04530400505832826,
            "auditor_fp_violation": 0.012030142106980751,
            "ave_precision_score": 0.7732630102615513,
            "fpr": 0.10867178924259056,
            "logloss": 0.5521316890544248,
            "mae": 0.3666072687963957,
            "precision": 0.7352941176470589,
            "recall": 0.588865096359743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7637007530727135,
            "auditor_fn_violation": 0.012029882200367449,
            "auditor_fp_violation": 0.019618163054695558,
            "ave_precision_score": 0.5538914569885607,
            "fpr": 0.4024122807017544,
            "logloss": 0.6881167235047444,
            "mae": 0.4970343122748952,
            "precision": 0.5551515151515152,
            "recall": 0.9404517453798767
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7508063115436785,
            "auditor_fn_violation": 0.01058911190140961,
            "auditor_fp_violation": 0.01915526942969315,
            "ave_precision_score": 0.5297424698801559,
            "fpr": 0.42590559824368823,
            "logloss": 0.6899385722623324,
            "mae": 0.4979463533695652,
            "precision": 0.5308343409915357,
            "recall": 0.9400428265524625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7488678642916458,
            "auditor_fn_violation": 0.06753665477863036,
            "auditor_fp_violation": 0.09502837977296183,
            "ave_precision_score": 0.6261807420277645,
            "fpr": 0.28289473684210525,
            "logloss": 0.6654427823087468,
            "mae": 0.45438648975993456,
            "precision": 0.6030769230769231,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7623920564261318,
            "auditor_fn_violation": 0.05847869367262369,
            "auditor_fp_violation": 0.10158127391936393,
            "ave_precision_score": 0.634062478233413,
            "fpr": 0.2897914379802415,
            "logloss": 0.6428042797177074,
            "mae": 0.4408530300292958,
            "precision": 0.5925925925925926,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 31658,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7991222724828368,
            "auditor_fn_violation": 0.007362477034475311,
            "auditor_fp_violation": 0.0029540763673890627,
            "ave_precision_score": 0.7699059232770284,
            "fpr": 0.09649122807017543,
            "logloss": 0.5759604575291906,
            "mae": 0.35932922836295084,
            "precision": 0.7894736842105263,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8186742062430522,
            "auditor_fn_violation": 0.010213028015898951,
            "auditor_fp_violation": 0.012272426103381103,
            "ave_precision_score": 0.7932392327280708,
            "fpr": 0.08781558726673985,
            "logloss": 0.4939800750005949,
            "mae": 0.3216773450914382,
            "precision": 0.8202247191011236,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8308571522256766,
            "auditor_fn_violation": 0.008164018876760696,
            "auditor_fp_violation": 0.0045304437564499525,
            "ave_precision_score": 0.8282002526724621,
            "fpr": 0.08662280701754387,
            "logloss": 0.5527066931334366,
            "mae": 0.3278038652834335,
            "precision": 0.7979539641943734,
            "recall": 0.6406570841889117
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8711082073824008,
            "auditor_fn_violation": 0.010351708948681012,
            "auditor_fp_violation": 0.009960838994867539,
            "ave_precision_score": 0.8677864657661315,
            "fpr": 0.06915477497255763,
            "logloss": 0.448050558528878,
            "mae": 0.2836477520306207,
            "precision": 0.8467153284671532,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7399465840210462,
            "auditor_fn_violation": 0.01010257934363632,
            "auditor_fp_violation": 0.00016253869969040286,
            "ave_precision_score": 0.7004969750534723,
            "fpr": 0.02412280701754386,
            "logloss": 0.6348767280698474,
            "mae": 0.4211950896699962,
            "precision": 0.8829787234042553,
            "recall": 0.3408624229979466
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7734955375713357,
            "auditor_fn_violation": 0.00017158827276424185,
            "auditor_fp_violation": 0.002818405672412259,
            "ave_precision_score": 0.7409805189890067,
            "fpr": 0.01646542261251372,
            "logloss": 0.5769795706237655,
            "mae": 0.3943948290841378,
            "precision": 0.9299065420560748,
            "recall": 0.4261241970021413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 31658,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8266241609635745,
            "auditor_fn_violation": 0.008571544363990062,
            "auditor_fp_violation": 0.0022471620227038193,
            "ave_precision_score": 0.8270360378118238,
            "fpr": 0.09758771929824561,
            "logloss": 0.5614435080049283,
            "mae": 0.3309956301604153,
            "precision": 0.7880952380952381,
            "recall": 0.6796714579055442
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8773682670172173,
            "auditor_fn_violation": 0.010213028015898951,
            "auditor_fp_violation": 0.013780520366689412,
            "ave_precision_score": 0.8775265337269058,
            "fpr": 0.09001097694840834,
            "logloss": 0.46651561189937607,
            "mae": 0.28902229287561426,
            "precision": 0.8165548098434005,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7681070825879024,
            "auditor_fn_violation": 0.0034313195720306927,
            "auditor_fp_violation": 0.014801341589267297,
            "ave_precision_score": 0.5539861794472778,
            "fpr": 0.4243421052631579,
            "logloss": 14.790353806898576,
            "mae": 0.44055516771120085,
            "precision": 0.5494761350407451,
            "recall": 0.9691991786447639
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.7672314959799769,
            "auditor_fn_violation": 0.0030956404826096465,
            "auditor_fp_violation": 0.0041583845096468805,
            "ave_precision_score": 0.543514313910311,
            "fpr": 0.43249176728869376,
            "logloss": 14.983556302101313,
            "mae": 0.44239357472473734,
            "precision": 0.5381008206330598,
            "recall": 0.9828693790149893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 31658,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7961548691069678,
            "auditor_fn_violation": 0.03923727439749271,
            "auditor_fp_violation": 0.05385706914344686,
            "ave_precision_score": 0.7471485036287673,
            "fpr": 0.1699561403508772,
            "logloss": 0.593899387695448,
            "mae": 0.39769289591921525,
            "precision": 0.7007722007722008,
            "recall": 0.7453798767967146
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8401711413755909,
            "auditor_fn_violation": 0.022015010448080446,
            "auditor_fp_violation": 0.05724577486377707,
            "ave_precision_score": 0.7841407030777023,
            "fpr": 0.17014270032930845,
            "logloss": 0.5351883214891597,
            "mae": 0.36991082925173635,
            "precision": 0.7041984732824428,
            "recall": 0.7901498929336188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5730018529141317,
            "auditor_fn_violation": 0.0014049497460283155,
            "auditor_fp_violation": 0.0008849329205366359,
            "ave_precision_score": 0.5744591562754339,
            "fpr": 0.009868421052631578,
            "logloss": 1.308823626445412,
            "mae": 0.5135303339741433,
            "precision": 0.6896551724137931,
            "recall": 0.04106776180698152
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5409320483287099,
            "auditor_fn_violation": 0.002583226188601374,
            "auditor_fp_violation": 0.002192917395990942,
            "ave_precision_score": 0.5430381634910262,
            "fpr": 0.014270032930845226,
            "logloss": 1.2234336677415047,
            "mae": 0.4995530356418415,
            "precision": 0.5666666666666667,
            "recall": 0.03640256959314775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 31658,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.619346704427602,
            "auditor_fn_violation": 0.11782665081595159,
            "auditor_fp_violation": 0.08120743034055729,
            "ave_precision_score": 0.5272133982360995,
            "fpr": 0.20065789473684212,
            "logloss": 0.703181514405437,
            "mae": 0.5009043984311191,
            "precision": 0.5171503957783641,
            "recall": 0.4024640657084189
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6337326543324011,
            "auditor_fn_violation": 0.11950065462101322,
            "auditor_fp_violation": 0.07710564571157326,
            "ave_precision_score": 0.5250348170634395,
            "fpr": 0.19099890230515917,
            "logloss": 0.6947164091122703,
            "mae": 0.4966920193542372,
            "precision": 0.5408970976253298,
            "recall": 0.43897216274089934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8104059595238358,
            "auditor_fn_violation": 0.008375661947476501,
            "auditor_fp_violation": 0.008010835913312695,
            "ave_precision_score": 0.811724888261957,
            "fpr": 0.12938596491228072,
            "logloss": 0.5628488945467666,
            "mae": 0.3418962338780004,
            "precision": 0.7521008403361344,
            "recall": 0.7351129363449692
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8737147984340699,
            "auditor_fn_violation": 0.004947853618749661,
            "auditor_fp_violation": 0.0028035719583469347,
            "ave_precision_score": 0.8738813230375824,
            "fpr": 0.12403951701427003,
            "logloss": 0.48625245323012495,
            "mae": 0.30984752816194105,
            "precision": 0.7730923694779116,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8039920340612136,
            "auditor_fn_violation": 0.011716920638351528,
            "auditor_fp_violation": 0.012982456140350882,
            "ave_precision_score": 0.8045391301752357,
            "fpr": 0.09100877192982457,
            "logloss": 0.570331530988671,
            "mae": 0.35834642396749633,
            "precision": 0.7871794871794872,
            "recall": 0.6303901437371663
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8659307417457072,
            "auditor_fn_violation": 0.007669760740133093,
            "auditor_fp_violation": 0.01585724033583529,
            "ave_precision_score": 0.8661521657221922,
            "fpr": 0.08232711306256861,
            "logloss": 0.4770337188317262,
            "mae": 0.3158859003715536,
            "precision": 0.8259860788863109,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7910979327683254,
            "auditor_fn_violation": 0.0049713606397925,
            "auditor_fp_violation": 0.0029540763673890627,
            "ave_precision_score": 0.7511509588184258,
            "fpr": 0.09649122807017543,
            "logloss": 0.5906031416023743,
            "mae": 0.3584686057772814,
            "precision": 0.7879518072289157,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8456088063911433,
            "auditor_fn_violation": 0.007547533477342122,
            "auditor_fp_violation": 0.012272426103381103,
            "ave_precision_score": 0.8140404894852351,
            "fpr": 0.08781558726673985,
            "logloss": 0.4907197552016545,
            "mae": 0.3142431135300616,
            "precision": 0.8198198198198198,
            "recall": 0.7794432548179872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7283920912578762,
            "auditor_fn_violation": 0.008841727007457065,
            "auditor_fp_violation": 0.003970588235294118,
            "ave_precision_score": 0.6870561801704842,
            "fpr": 0.05043859649122807,
            "logloss": 0.622021328677459,
            "mae": 0.40343807340321836,
            "precision": 0.8374558303886925,
            "recall": 0.486652977412731
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7936083099233395,
            "auditor_fn_violation": 0.009670056906192928,
            "auditor_fp_violation": 0.004672619930578218,
            "ave_precision_score": 0.757325536701643,
            "fpr": 0.04171240395170143,
            "logloss": 0.5337113854036315,
            "mae": 0.3603807765454806,
            "precision": 0.88125,
            "recall": 0.6038543897216274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7174526373651713,
            "auditor_fn_violation": 0.011340916459526658,
            "auditor_fp_violation": 0.012628998968008258,
            "ave_precision_score": 0.70801246471205,
            "fpr": 0.0625,
            "logloss": 0.6690910616076983,
            "mae": 0.439349190356504,
            "precision": 0.7625,
            "recall": 0.3757700205338809
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7225647709273719,
            "auditor_fn_violation": 0.023084498997501392,
            "auditor_fp_violation": 0.005453862204685475,
            "ave_precision_score": 0.7115604255645956,
            "fpr": 0.06476399560922064,
            "logloss": 0.6381025320168415,
            "mae": 0.4279620881906979,
            "precision": 0.7591836734693878,
            "recall": 0.39828693790149894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8386093312025124,
            "auditor_fn_violation": 0.011849760438056129,
            "auditor_fp_violation": 0.011264189886480912,
            "ave_precision_score": 0.839042462376636,
            "fpr": 0.09210526315789473,
            "logloss": 0.5378488639858375,
            "mae": 0.3189608257329255,
            "precision": 0.7985611510791367,
            "recall": 0.6837782340862423
        },
        "train": {
            "accuracy": 0.8057080131723381,
            "auc_prc": 0.8891852517726384,
            "auditor_fn_violation": 0.00847128952112769,
            "auditor_fp_violation": 0.006062044481363912,
            "ave_precision_score": 0.8893397126604408,
            "fpr": 0.07683863885839737,
            "logloss": 0.43668011890007746,
            "mae": 0.2780160396462092,
            "precision": 0.8372093023255814,
            "recall": 0.7708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.702016283146653,
            "auditor_fn_violation": 0.011334161893439965,
            "auditor_fp_violation": 0.01688596491228071,
            "ave_precision_score": 0.6770175262762557,
            "fpr": 0.23574561403508773,
            "logloss": 0.6193029086964027,
            "mae": 0.4225796854139812,
            "precision": 0.6570972886762361,
            "recall": 0.8459958932238193
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6632733753172741,
            "auditor_fn_violation": 0.012904378321584635,
            "auditor_fp_violation": 0.016554424896905708,
            "ave_precision_score": 0.6452482008671101,
            "fpr": 0.24588364434687157,
            "logloss": 0.6298931021421128,
            "mae": 0.42824070586625623,
            "precision": 0.6416,
            "recall": 0.8586723768736617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7666984708587146,
            "auditor_fn_violation": 0.015861972693540838,
            "auditor_fp_violation": 0.04472136222910216,
            "ave_precision_score": 0.7604598003092651,
            "fpr": 0.12719298245614036,
            "logloss": 0.6347423238074137,
            "mae": 0.375016377130171,
            "precision": 0.7381489841986456,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8081776191540101,
            "auditor_fn_violation": 0.022148990332293627,
            "auditor_fp_violation": 0.05188833180051622,
            "ave_precision_score": 0.8017401402393559,
            "fpr": 0.13611416026344675,
            "logloss": 0.5454782918768644,
            "mae": 0.33769182038263945,
            "precision": 0.7416666666666667,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8415267275800183,
            "auditor_fn_violation": 0.003706005259555461,
            "auditor_fp_violation": 0.00035345717234262216,
            "ave_precision_score": 0.8392225111266206,
            "fpr": 0.0800438596491228,
            "logloss": 0.5370211087368277,
            "mae": 0.3256585243170297,
            "precision": 0.818407960199005,
            "recall": 0.675564681724846
        },
        "train": {
            "accuracy": 0.8111964873765093,
            "auc_prc": 0.8655663886864534,
            "auditor_fn_violation": 0.00043954804119058946,
            "auditor_fp_violation": 0.009167235292372504,
            "ave_precision_score": 0.8641395390114649,
            "fpr": 0.07903402854006586,
            "logloss": 0.44018072073580305,
            "mae": 0.28296880763224463,
            "precision": 0.835990888382688,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7583826286266192,
            "auditor_fn_violation": 0.007247649411001844,
            "auditor_fp_violation": 0.006911764705882357,
            "ave_precision_score": 0.7332210870054195,
            "fpr": 0.10526315789473684,
            "logloss": 0.6075574716985696,
            "mae": 0.35938948332413767,
            "precision": 0.7714285714285715,
            "recall": 0.6652977412731006
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8059124676997838,
            "auditor_fn_violation": 0.0024774525958014956,
            "auditor_fp_violation": 0.007288298177431002,
            "ave_precision_score": 0.7897412319873682,
            "fpr": 0.08781558726673985,
            "logloss": 0.48455635872692276,
            "mae": 0.3060259599357222,
            "precision": 0.8181818181818182,
            "recall": 0.7708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5963817124642908,
            "auditor_fn_violation": 0.008064951907489475,
            "auditor_fp_violation": 0.011800825593395252,
            "ave_precision_score": 0.612297026746963,
            "fpr": 0.06907894736842106,
            "logloss": 0.7001805367549375,
            "mae": 0.48146503444826394,
            "precision": 0.5882352941176471,
            "recall": 0.18480492813141683
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6071568565354437,
            "auditor_fn_violation": 0.007622750254444255,
            "auditor_fp_violation": 0.012915220379545298,
            "ave_precision_score": 0.613214935982973,
            "fpr": 0.06147091108671789,
            "logloss": 0.6810834621261743,
            "mae": 0.47080751530556203,
            "precision": 0.6363636363636364,
            "recall": 0.20985010706638116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.817975305282302,
            "auditor_fn_violation": 0.015109964335891082,
            "auditor_fp_violation": 0.0016873065015479878,
            "ave_precision_score": 0.818337557386206,
            "fpr": 0.003289473684210526,
            "logloss": 4.639760937340255,
            "mae": 0.48563145390736073,
            "precision": 0.9387755102040817,
            "recall": 0.0944558521560575
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.808388784070444,
            "auditor_fn_violation": 0.008605269405340867,
            "auditor_fp_violation": 0.0005315414206742417,
            "ave_precision_score": 0.8096892613940139,
            "fpr": 0.0010976948408342481,
            "logloss": 4.24706825440783,
            "mae": 0.457407257772869,
            "precision": 0.9803921568627451,
            "recall": 0.10706638115631692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.6170254395135489,
            "auditor_fn_violation": 0.013461850210742473,
            "auditor_fp_violation": 0.008075335397316825,
            "ave_precision_score": 0.550583516255866,
            "fpr": 0.07017543859649122,
            "logloss": 0.7155356175776697,
            "mae": 0.5007160796146644,
            "precision": 0.6049382716049383,
            "recall": 0.20123203285420946
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5744315687480157,
            "auditor_fn_violation": 0.0022588538373484353,
            "auditor_fp_violation": 0.015432007199295897,
            "ave_precision_score": 0.5213601647136864,
            "fpr": 0.09440175631174534,
            "logloss": 0.712434122607975,
            "mae": 0.4988632403992926,
            "precision": 0.5300546448087432,
            "recall": 0.20770877944325483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7701982934778075,
            "auditor_fn_violation": 0.000614665513887388,
            "auditor_fp_violation": 0.0036842105263157994,
            "ave_precision_score": 0.771478873052651,
            "fpr": 0.4594298245614035,
            "logloss": 0.7656136702035222,
            "mae": 0.49463209392617274,
            "precision": 0.5370165745856353,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.8098540982019077,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0024846471059423916,
            "ave_precision_score": 0.8105958707033911,
            "fpr": 0.4818880351262349,
            "logloss": 0.8021128023931103,
            "mae": 0.4960121670502732,
            "precision": 0.5154525386313465,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7203304562478677,
            "auditor_fn_violation": 0.013329010411037887,
            "auditor_fp_violation": 0.008534571723426213,
            "ave_precision_score": 0.722463745953208,
            "fpr": 0.02412280701754386,
            "logloss": 0.8140932151714659,
            "mae": 0.44265222838638646,
            "precision": 0.7777777777777778,
            "recall": 0.15811088295687886
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7328907673661604,
            "auditor_fn_violation": 0.009138838417909136,
            "auditor_fp_violation": 0.003456255377221349,
            "ave_precision_score": 0.7146914778140333,
            "fpr": 0.024149286498353458,
            "logloss": 0.7574486488620595,
            "mae": 0.4269472232822464,
            "precision": 0.8,
            "recall": 0.18843683083511778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6477269613881858,
            "auditor_fn_violation": 0.001031197089232321,
            "auditor_fp_violation": 0.0024561403508771944,
            "ave_precision_score": 0.6495535210227266,
            "fpr": 0.4517543859649123,
            "logloss": 1.0449205161535122,
            "mae": 0.4565878748125805,
            "precision": 0.5406911928651059,
            "recall": 0.9958932238193019
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6222916530601245,
            "auditor_fn_violation": 0.0021530802445485467,
            "auditor_fp_violation": 0.003945767941377166,
            "ave_precision_score": 0.6244012517579786,
            "fpr": 0.4698133918770582,
            "logloss": 1.0759095747273268,
            "mae": 0.47082170078573843,
            "precision": 0.5196408529741863,
            "recall": 0.9914346895074947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8340713561145398,
            "auditor_fn_violation": 0.01004178824885623,
            "auditor_fp_violation": 0.012721878224974201,
            "ave_precision_score": 0.8352746802733673,
            "fpr": 0.09539473684210527,
            "logloss": 0.6948699879627269,
            "mae": 0.29808361219961593,
            "precision": 0.7943262411347518,
            "recall": 0.6899383983572895
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8494211895811276,
            "auditor_fn_violation": 0.006931696114818419,
            "auditor_fp_violation": 0.014413425500143396,
            "ave_precision_score": 0.8496098269657452,
            "fpr": 0.10757409440175632,
            "logloss": 0.633161524179897,
            "mae": 0.27861594495328357,
            "precision": 0.7782805429864253,
            "recall": 0.7366167023554604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 31658,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5407865898718363,
            "auditor_fn_violation": 0.012615277927879247,
            "auditor_fp_violation": 0.017881836945304444,
            "ave_precision_score": 0.5462132863015913,
            "fpr": 0.375,
            "logloss": 0.7404558322878959,
            "mae": 0.4527278163453989,
            "precision": 0.5665399239543726,
            "recall": 0.917864476386037
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5727744231215025,
            "auditor_fn_violation": 0.006496849122196707,
            "auditor_fp_violation": 0.021207266542063483,
            "ave_precision_score": 0.577354233258074,
            "fpr": 0.3765093304061471,
            "logloss": 0.7365342973492031,
            "mae": 0.45103361587623864,
            "precision": 0.5641677255400254,
            "recall": 0.9507494646680942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7750509534961829,
            "auditor_fn_violation": 0.0069549515472459396,
            "auditor_fp_violation": 0.004063467492260066,
            "ave_precision_score": 0.758754745483887,
            "fpr": 0.08223684210526316,
            "logloss": 0.6834541991884655,
            "mae": 0.3808653019695428,
            "precision": 0.8015873015873016,
            "recall": 0.62217659137577
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8134385066805923,
            "auditor_fn_violation": 0.004294407867674885,
            "auditor_fp_violation": 0.008781558726673987,
            "ave_precision_score": 0.8014038921513886,
            "fpr": 0.06586169045005488,
            "logloss": 0.5588813964190531,
            "mae": 0.3309219136719646,
            "precision": 0.8503740648379052,
            "recall": 0.7301927194860813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.839072164646959,
            "auditor_fn_violation": 0.008663856767174622,
            "auditor_fp_violation": 0.012912796697626417,
            "ave_precision_score": 0.8113787071611338,
            "fpr": 0.06578947368421052,
            "logloss": 0.5597565522538092,
            "mae": 0.32841903639532494,
            "precision": 0.8324022346368715,
            "recall": 0.6119096509240246
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8727890759139626,
            "auditor_fn_violation": 0.0017041301062201955,
            "auditor_fp_violation": 0.008277212448452845,
            "ave_precision_score": 0.842150641785602,
            "fpr": 0.059275521405049394,
            "logloss": 0.4624740293971592,
            "mae": 0.28725933331820364,
            "precision": 0.8604651162790697,
            "recall": 0.7130620985010707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8298392635296966,
            "auditor_fn_violation": 0.016458626031197087,
            "auditor_fp_violation": 0.013248194014447885,
            "ave_precision_score": 0.8138993220442018,
            "fpr": 0.07785087719298246,
            "logloss": 0.5686181973840183,
            "mae": 0.32689849733657883,
            "precision": 0.8259803921568627,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.817825853762739,
            "auditor_fn_violation": 0.001807553174735625,
            "auditor_fp_violation": 0.013271229517113162,
            "ave_precision_score": 0.8125408047016384,
            "fpr": 0.09440175631174534,
            "logloss": 0.4899732008596183,
            "mae": 0.30018242632430436,
            "precision": 0.8105726872246696,
            "recall": 0.7880085653104925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6662908868304162,
            "auditor_fn_violation": 0.015123473468064438,
            "auditor_fp_violation": 0.008893188854489167,
            "ave_precision_score": 0.6662294394576158,
            "fpr": 0.07346491228070176,
            "logloss": 0.7080090181807076,
            "mae": 0.4479903733406804,
            "precision": 0.6747572815533981,
            "recall": 0.28542094455852157
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6216341119310556,
            "auditor_fn_violation": 0.007535780855919932,
            "auditor_fp_violation": 0.016425866041672853,
            "ave_precision_score": 0.6310830837828025,
            "fpr": 0.10098792535675083,
            "logloss": 0.6835065798205924,
            "mae": 0.44532329760058387,
            "precision": 0.5929203539823009,
            "recall": 0.28693790149892934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6931324295868713,
            "auditor_fn_violation": 0.007878075579091466,
            "auditor_fp_violation": 0.03210526315789474,
            "ave_precision_score": 0.6946033319093772,
            "fpr": 0.2149122807017544,
            "logloss": 0.9331553842039658,
            "mae": 0.35419869655263364,
            "precision": 0.6802610114192496,
            "recall": 0.8562628336755647
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7638380744059833,
            "auditor_fn_violation": 0.00467049175318555,
            "auditor_fp_violation": 0.02230990595425283,
            "ave_precision_score": 0.7650384502013374,
            "fpr": 0.21734357848518113,
            "logloss": 0.6931696772690763,
            "mae": 0.3302479664018081,
            "precision": 0.6796116504854369,
            "recall": 0.8993576017130621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7669956140350878,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.46600877192982454,
            "logloss": 0.6922997817574892,
            "mae": 0.49952815263940575,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.756311745334797,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.48737650933040616,
            "logloss": 0.6928930500060134,
            "mae": 0.4998247677094327,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6738742665519148,
            "auditor_fn_violation": 0.01803694297345005,
            "auditor_fp_violation": 0.0026805985552115588,
            "ave_precision_score": 0.6665722158077675,
            "fpr": 0.046052631578947366,
            "logloss": 2.4297523050381886,
            "mae": 0.45870661614787983,
            "precision": 0.776595744680851,
            "recall": 0.2997946611909651
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6891743965743822,
            "auditor_fn_violation": 0.012406067173283008,
            "auditor_fp_violation": 0.007782755312941921,
            "ave_precision_score": 0.6884862354634489,
            "fpr": 0.043907793633369926,
            "logloss": 2.3257665647210843,
            "mae": 0.44161751884434103,
            "precision": 0.7927461139896373,
            "recall": 0.32762312633832974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7694144474550335,
            "auditor_fn_violation": 0.04890530998955294,
            "auditor_fp_violation": 0.060438596491228076,
            "ave_precision_score": 0.7699453050299658,
            "fpr": 0.2050438596491228,
            "logloss": 0.5974029796179945,
            "mae": 0.40279360155967114,
            "precision": 0.6742160278745645,
            "recall": 0.7946611909650924
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8165778432488846,
            "auditor_fn_violation": 0.04156902197035049,
            "auditor_fp_violation": 0.0623040713600538,
            "ave_precision_score": 0.8168807655078252,
            "fpr": 0.21624588364434688,
            "logloss": 0.5578992564203838,
            "mae": 0.38063906770686157,
            "precision": 0.671118530884808,
            "recall": 0.860813704496788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 31658,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8432540929140048,
            "auditor_fn_violation": 0.012450916819770168,
            "auditor_fp_violation": 0.003550051599587205,
            "ave_precision_score": 0.8435209658026857,
            "fpr": 0.08991228070175439,
            "logloss": 0.5518190548980626,
            "mae": 0.31715241732278326,
            "precision": 0.8088578088578089,
            "recall": 0.7125256673511293
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8574784963097779,
            "auditor_fn_violation": 0.010382265764378746,
            "auditor_fp_violation": 0.008403299018008131,
            "ave_precision_score": 0.8577632729079273,
            "fpr": 0.10208562019758508,
            "logloss": 0.48159271450227736,
            "mae": 0.28903226459744025,
            "precision": 0.7978260869565217,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 31658,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5734452923799023,
            "auditor_fn_violation": 0.0016661263013797378,
            "auditor_fp_violation": 0.0013931888544891642,
            "ave_precision_score": 0.5719990214550533,
            "fpr": 0.020833333333333332,
            "logloss": 12.804570350265502,
            "mae": 0.5128212145224809,
            "precision": 0.6779661016949152,
            "recall": 0.08213552361396304
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5826631624383379,
            "auditor_fn_violation": 0.006247693548045898,
            "auditor_fp_violation": 0.002225057109799152,
            "ave_precision_score": 0.5815812155828148,
            "fpr": 0.013172338090010977,
            "logloss": 12.596966732158187,
            "mae": 0.4649264493819497,
            "precision": 0.8356164383561644,
            "recall": 0.13062098501070663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7961058259318545,
            "auditor_fn_violation": 0.009643268849742419,
            "auditor_fp_violation": 0.007461300309597524,
            "ave_precision_score": 0.7871213403408147,
            "fpr": 0.04057017543859649,
            "logloss": 0.6765309577884931,
            "mae": 0.37941962451951805,
            "precision": 0.8537549407114624,
            "recall": 0.44353182751540043
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8494853950778793,
            "auditor_fn_violation": 0.008762754532398458,
            "auditor_fp_violation": 0.0009295794147605344,
            "ave_precision_score": 0.8416771300382342,
            "fpr": 0.031833150384193196,
            "logloss": 0.5557117521716377,
            "mae": 0.33128446570375747,
            "precision": 0.8986013986013986,
            "recall": 0.550321199143469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7840017296343449,
            "auditor_fn_violation": 0.009557711012644549,
            "auditor_fp_violation": 0.009638802889576893,
            "ave_precision_score": 0.7612313808683187,
            "fpr": 0.24561403508771928,
            "logloss": 0.5676864684397764,
            "mae": 0.3812766406591165,
            "precision": 0.6590563165905632,
            "recall": 0.8891170431211499
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7680909321407547,
            "auditor_fn_violation": 0.008121061402745884,
            "auditor_fp_violation": 0.007945926167660523,
            "ave_precision_score": 0.7273352588169377,
            "fpr": 0.28210757409440174,
            "logloss": 0.5912018992207942,
            "mae": 0.3915141647319697,
            "precision": 0.6192592592592593,
            "recall": 0.8950749464668094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7472144013083389,
            "auditor_fn_violation": 0.05740030260456068,
            "auditor_fp_violation": 0.013725490196078431,
            "ave_precision_score": 0.7447735648089115,
            "fpr": 0.043859649122807015,
            "logloss": 1.4220777377141534,
            "mae": 0.4003283102711819,
            "precision": 0.8333333333333334,
            "recall": 0.4106776180698152
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7452632592299634,
            "auditor_fn_violation": 0.0660097734799747,
            "auditor_fp_violation": 0.014507372355890471,
            "ave_precision_score": 0.7426713346055961,
            "fpr": 0.03951701427003293,
            "logloss": 1.3016901664298308,
            "mae": 0.3743782033459045,
            "precision": 0.8506224066390041,
            "recall": 0.43897216274089934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6519715427521287,
            "auditor_fn_violation": 0.020695990489570958,
            "auditor_fp_violation": 0.013137254901960792,
            "ave_precision_score": 0.6526265202688835,
            "fpr": 0.14035087719298245,
            "logloss": 0.6778831707785994,
            "mae": 0.4741924138390076,
            "precision": 0.6512261580381471,
            "recall": 0.49075975359342916
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6109032218960773,
            "auditor_fn_violation": 0.01439226019363621,
            "auditor_fp_violation": 0.012143867248148262,
            "ave_precision_score": 0.6120893594849826,
            "fpr": 0.18221734357848518,
            "logloss": 0.6774801994410822,
            "mae": 0.47303487674479344,
            "precision": 0.5808080808080808,
            "recall": 0.4925053533190578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7856024708940524,
            "auditor_fn_violation": 0.03513274973882344,
            "auditor_fp_violation": 0.043893188854489174,
            "ave_precision_score": 0.7860837315558535,
            "fpr": 0.13267543859649122,
            "logloss": 0.6062738428043317,
            "mae": 0.4025117807568198,
            "precision": 0.7192575406032483,
            "recall": 0.6365503080082136
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8094558373977272,
            "auditor_fn_violation": 0.02315971577460353,
            "auditor_fp_violation": 0.03989280169302123,
            "ave_precision_score": 0.809763511671866,
            "fpr": 0.14050493962678376,
            "logloss": 0.5586224857696013,
            "mae": 0.38366235440554003,
            "precision": 0.7235421166306696,
            "recall": 0.7173447537473233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7683311018771841,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005159958720330262,
            "ave_precision_score": 0.5376116686014543,
            "fpr": 0.4594298245614035,
            "logloss": 15.832984714382052,
            "mae": 0.4594542506741147,
            "precision": 0.5375275938189845,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7560098423517674,
            "auditor_fn_violation": 0.0005077132454393953,
            "auditor_fp_violation": 0.0023288931082564583,
            "ave_precision_score": 0.5161667381961289,
            "fpr": 0.47639956092206365,
            "logloss": 16.460981298402956,
            "mae": 0.47775487317811005,
            "precision": 0.5177777777777778,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7360422197889901,
            "auditor_fn_violation": 0.007738481213300199,
            "auditor_fp_violation": 0.008862229102167182,
            "ave_precision_score": 0.7376508135696354,
            "fpr": 0.10416666666666667,
            "logloss": 0.8009507001953594,
            "mae": 0.30734476419635476,
            "precision": 0.7795823665893271,
            "recall": 0.6899383983572895
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.821348507333604,
            "auditor_fn_violation": 0.0019955951174909585,
            "auditor_fp_violation": 0.014675487781964182,
            "ave_precision_score": 0.820638918507157,
            "fpr": 0.09989023051591657,
            "logloss": 0.5874445956583315,
            "mae": 0.24858192611448918,
            "precision": 0.8013100436681223,
            "recall": 0.7858672376873662
        }
    }
]