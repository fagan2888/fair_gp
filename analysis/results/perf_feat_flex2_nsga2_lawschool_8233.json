[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5924390591157966,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5387590077263534,
            "fpr": 0.4692982456140351,
            "logloss": 0.6917281508046229,
            "mae": 0.49917437031603695,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5883918198150175,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5265750455541068,
            "fpr": 0.4840834248079034,
            "logloss": 0.6921302388857006,
            "mae": 0.49937213854261076,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.4848372547630135,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4970842912555021,
            "fpr": 0.4692982456140351,
            "logloss": 0.6957910928640578,
            "mae": 0.4993166954240255,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.48610814718051854,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5005387721524087,
            "fpr": 0.4840834248079034,
            "logloss": 0.6967838791061589,
            "mae": 0.4997122693402053,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.770712638042671,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6983919686646893,
            "fpr": 0.10855263157894737,
            "logloss": 3.3662060721269875,
            "mae": 0.40082401393406225,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7709948216269775,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6943531649554948,
            "fpr": 0.12403951701427003,
            "logloss": 3.5942218613908126,
            "mae": 0.40188969647190836,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.584901821521017,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5758307202819811,
            "fpr": 0.4692982456140351,
            "logloss": 0.6916450229494436,
            "mae": 0.49911914256058243,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.568090355285881,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5518647255343561,
            "fpr": 0.4840834248079034,
            "logloss": 0.6920997303735158,
            "mae": 0.49934315059894263,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.4848372547630135,
            "auditor_fn_violation": 0.0008608815426997265,
            "auditor_fp_violation": 0.004434640924741772,
            "ave_precision_score": 0.4970842912555021,
            "fpr": 0.4375,
            "logloss": 0.6961227944972089,
            "mae": 0.4993303244966164,
            "precision": 0.5311398354876615,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.48610814718051854,
            "auditor_fn_violation": 0.0005978933601139744,
            "auditor_fp_violation": 0.0016353412934877697,
            "ave_precision_score": 0.5005387721524087,
            "fpr": 0.4643249176728869,
            "logloss": 0.6971266227747607,
            "mae": 0.4997226033200286,
            "precision": 0.5149082568807339,
            "recall": 0.9553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.366200478683314,
            "mae": 0.40082539513445736,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7711442236841682,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6953955770815196,
            "fpr": 0.12403951701427003,
            "logloss": 3.5942147100133925,
            "mae": 0.40189162992619787,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7881364414940076,
            "auditor_fn_violation": 0.0032396331738437003,
            "auditor_fp_violation": 0.004506373995737007,
            "ave_precision_score": 0.7304969901453289,
            "fpr": 0.4375,
            "logloss": 3.4061023114554576,
            "mae": 0.4007980596404849,
            "precision": 0.5455580865603644,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7854290002252995,
            "auditor_fn_violation": 0.0006329261741831516,
            "auditor_fp_violation": 0.007081500730552011,
            "ave_precision_score": 0.7222060108767057,
            "fpr": 0.4566410537870472,
            "logloss": 3.6500682526213155,
            "mae": 0.40317342836822817,
            "precision": 0.5288788221970555,
            "recall": 0.9936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7873449436307689,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.729699796560336,
            "fpr": 0.10855263157894737,
            "logloss": 3.3973825710396826,
            "mae": 0.39675049083470776,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7856055989775604,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.7223805037514083,
            "fpr": 0.12403951701427003,
            "logloss": 3.6362365941005654,
            "mae": 0.39760068867817666,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.4613274377030358,
            "auditor_fn_violation": 0.004005364651297671,
            "auditor_fp_violation": 0.005016191178881785,
            "ave_precision_score": 0.5262957063196297,
            "fpr": 0.025219298245614034,
            "logloss": 0.6969612266514308,
            "mae": 0.5015775624727994,
            "precision": 0.3783783783783784,
            "recall": 0.028925619834710745
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5187729172992035,
            "auditor_fn_violation": 0.003419202653151786,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5152054090664923,
            "fpr": 0.02305159165751921,
            "logloss": 0.6948647195510286,
            "mae": 0.5005224861376372,
            "precision": 0.5,
            "recall": 0.04468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.4613274377030358,
            "auditor_fn_violation": 0.004005364651297671,
            "auditor_fp_violation": 0.005016191178881785,
            "ave_precision_score": 0.5262957063196297,
            "fpr": 0.025219298245614034,
            "logloss": 0.6969612266514308,
            "mae": 0.5015775624727994,
            "precision": 0.3783783783783784,
            "recall": 0.028925619834710745
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5187729172992035,
            "auditor_fn_violation": 0.003419202653151786,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5152054090664923,
            "fpr": 0.02305159165751921,
            "logloss": 0.6948647195510286,
            "mae": 0.5005224861376372,
            "precision": 0.5,
            "recall": 0.04468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.530553269771185,
            "auditor_fn_violation": 0.00879005364651298,
            "auditor_fp_violation": 0.009996515822265949,
            "ave_precision_score": 0.5413769168383261,
            "fpr": 0.06359649122807018,
            "logloss": 8.684748770306756,
            "mae": 0.5551840874709582,
            "precision": 0.6054421768707483,
            "recall": 0.18388429752066116
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5176745683160351,
            "auditor_fn_violation": 0.011364644884041384,
            "auditor_fp_violation": 0.010596115504379583,
            "ave_precision_score": 0.5293910296178599,
            "fpr": 0.07903402854006586,
            "logloss": 8.910867286592765,
            "mae": 0.5562171640629041,
            "precision": 0.6,
            "recall": 0.2297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 8233,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6939534844684345,
            "auditor_fn_violation": 0.07103858561693491,
            "auditor_fp_violation": 0.06542056074766356,
            "ave_precision_score": 0.6906936451087814,
            "fpr": 0.2050438596491228,
            "logloss": 0.6560186964109984,
            "mae": 0.4491100691977823,
            "precision": 0.6333333333333333,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.6685836798078155,
            "auditor_fn_violation": 0.05717355256089871,
            "auditor_fp_violation": 0.0629867753907271,
            "ave_precision_score": 0.6667837331039921,
            "fpr": 0.22063666300768386,
            "logloss": 0.6684814535214945,
            "mae": 0.45348488857599567,
            "precision": 0.625,
            "recall": 0.7127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.4613274377030358,
            "auditor_fn_violation": 0.004005364651297671,
            "auditor_fp_violation": 0.005016191178881785,
            "ave_precision_score": 0.5262957063196297,
            "fpr": 0.025219298245614034,
            "logloss": 0.6969612266514308,
            "mae": 0.5015775624727994,
            "precision": 0.3783783783783784,
            "recall": 0.028925619834710745
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5187729172992035,
            "auditor_fn_violation": 0.003419202653151786,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5152054090664923,
            "fpr": 0.02305159165751921,
            "logloss": 0.6948647195510286,
            "mae": 0.5005224861376372,
            "precision": 0.5,
            "recall": 0.04468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 8233,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.754733139509898,
            "auditor_fn_violation": 0.015887795418297813,
            "auditor_fp_violation": 0.011354320380390229,
            "ave_precision_score": 0.697116881840852,
            "fpr": 0.11293859649122807,
            "logloss": 3.3663340834994697,
            "mae": 0.3997888110185924,
            "precision": 0.7345360824742269,
            "recall": 0.5888429752066116
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7546035804785497,
            "auditor_fn_violation": 0.008508302776934398,
            "auditor_fp_violation": 0.013747321101876535,
            "ave_precision_score": 0.6914522314850007,
            "fpr": 0.1350164654226125,
            "logloss": 3.5954333700727235,
            "mae": 0.401043547789692,
            "precision": 0.7071428571428572,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7850311874241495,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7232277560697975,
            "fpr": 0.4692982456140351,
            "logloss": 6.252384948507805,
            "mae": 0.4692495225422215,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7813674320979308,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7148345008453406,
            "fpr": 0.4840834248079034,
            "logloss": 6.513662261442179,
            "mae": 0.4840230208982097,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5924390591157966,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5387590077263534,
            "fpr": 0.4692982456140351,
            "logloss": 0.6917281508046229,
            "mae": 0.49917437031603695,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5883918198150175,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5265750455541068,
            "fpr": 0.4840834248079034,
            "logloss": 0.6921302388857006,
            "mae": 0.49937213854261076,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6931967755748056,
            "auditor_fn_violation": 0.07073501159924606,
            "auditor_fp_violation": 0.06461100180357437,
            "ave_precision_score": 0.6897985218498657,
            "fpr": 0.20833333333333334,
            "logloss": 0.6586995224937684,
            "mae": 0.450385465531757,
            "precision": 0.6310679611650486,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.664830210914404,
            "auditor_fn_violation": 0.05983604643015626,
            "auditor_fp_violation": 0.06477893023290547,
            "ave_precision_score": 0.6629710000223982,
            "fpr": 0.2239297475301866,
            "logloss": 0.6715782074374764,
            "mae": 0.4552690822357142,
            "precision": 0.6222222222222222,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5594832546521733,
            "auditor_fn_violation": 0.003932869363491373,
            "auditor_fp_violation": 0.005974340055746851,
            "ave_precision_score": 0.5409610781772899,
            "fpr": 0.45723684210526316,
            "logloss": 0.6920026269633112,
            "mae": 0.49927416777140216,
            "precision": 0.5330347144456887,
            "recall": 0.9834710743801653
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5542746035527153,
            "auditor_fn_violation": 0.0035967022444356217,
            "auditor_fp_violation": 0.008826362597728454,
            "ave_precision_score": 0.5339426959401333,
            "fpr": 0.4643249176728869,
            "logloss": 0.6920703386766274,
            "mae": 0.49931100445966164,
            "precision": 0.5225733634311512,
            "recall": 0.9851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7627145453831106,
            "auditor_fn_violation": 0.00518341307814992,
            "auditor_fp_violation": 0.010729217904574538,
            "ave_precision_score": 0.7014529109434513,
            "fpr": 0.375,
            "logloss": 3.409389359338178,
            "mae": 0.39179586990209364,
            "precision": 0.5703517587939698,
            "recall": 0.9380165289256198
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7604762057707473,
            "auditor_fn_violation": 0.0007637153467080832,
            "auditor_fp_violation": 0.009177326254321709,
            "ave_precision_score": 0.6944371095644932,
            "fpr": 0.37980241492864986,
            "logloss": 3.6192603860031864,
            "mae": 0.3911072649302242,
            "precision": 0.5614702154626109,
            "recall": 0.9425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 8233,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7075784761490503,
            "auditor_fn_violation": 0.005142634478758878,
            "auditor_fp_violation": 0.009760821446138716,
            "ave_precision_score": 0.5135176526025809,
            "fpr": 0.40899122807017546,
            "logloss": 0.6947503793756866,
            "mae": 0.5006051509265315,
            "precision": 0.5092105263157894,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.7071287723991617,
            "auditor_fn_violation": 0.008071560361538641,
            "auditor_fp_violation": 0.013821994220300643,
            "ave_precision_score": 0.5017158393889268,
            "fpr": 0.4281009879253567,
            "logloss": 0.6947857403145306,
            "mae": 0.5006256303070143,
            "precision": 0.4987146529562982,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7896829228742197,
            "auditor_fn_violation": 0.000598086124401914,
            "auditor_fp_violation": 0.0029205607476635587,
            "ave_precision_score": 0.732060066295104,
            "fpr": 0.4616228070175439,
            "logloss": 4.6760271988052535,
            "mae": 0.46112507889040766,
            "precision": 0.5342920353982301,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7845628918043993,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031238254540747867,
            "ave_precision_score": 0.7213814080286753,
            "fpr": 0.47859495060373214,
            "logloss": 4.956877182944634,
            "mae": 0.4766098002372028,
            "precision": 0.5187637969094923,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7881427919915402,
            "auditor_fn_violation": 0.0032396331738437003,
            "auditor_fp_violation": 0.004506373995737007,
            "ave_precision_score": 0.7304922988647218,
            "fpr": 0.4375,
            "logloss": 3.4061020749203,
            "mae": 0.4007980541996004,
            "precision": 0.5455580865603644,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7854494551010329,
            "auditor_fn_violation": 0.0006329261741831516,
            "auditor_fp_violation": 0.007081500730552011,
            "ave_precision_score": 0.7222364561776922,
            "fpr": 0.4566410537870472,
            "logloss": 3.650067796645941,
            "mae": 0.403173424573421,
            "precision": 0.5288788221970555,
            "recall": 0.9936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7939893813506671,
            "auditor_fn_violation": 0.000598086124401914,
            "auditor_fp_violation": 0.0029205607476635587,
            "ave_precision_score": 0.7363546309307543,
            "fpr": 0.4616228070175439,
            "logloss": 4.675961538807484,
            "mae": 0.46112231692939376,
            "precision": 0.5342920353982301,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7884825130915754,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031238254540747867,
            "ave_precision_score": 0.7252779345809495,
            "fpr": 0.47859495060373214,
            "logloss": 4.957864356201311,
            "mae": 0.4766163656253622,
            "precision": 0.5187637969094923,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7748106636154051,
            "auditor_fn_violation": 0.000598086124401914,
            "auditor_fp_violation": 0.0029205607476635587,
            "ave_precision_score": 0.7171826783380287,
            "fpr": 0.4616228070175439,
            "logloss": 4.619789198644011,
            "mae": 0.4606977013151879,
            "precision": 0.5342920353982301,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7781554319094673,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031238254540747867,
            "ave_precision_score": 0.7149860453564737,
            "fpr": 0.47859495060373214,
            "logloss": 4.9017110329066735,
            "mae": 0.4761490759139387,
            "precision": 0.5187637969094923,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7838209163808229,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7217749456433582,
            "fpr": 0.4692982456140351,
            "logloss": 6.424633703542991,
            "mae": 0.46925659046361323,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7777053143779239,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.710795075410913,
            "fpr": 0.4840834248079034,
            "logloss": 6.695914639448404,
            "mae": 0.4840395419841017,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7849699284408956,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7229539891338574,
            "fpr": 0.4692982456140351,
            "logloss": 6.267282226579427,
            "mae": 0.46925129251260506,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7791059594527099,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7124010102480304,
            "fpr": 0.4840834248079034,
            "logloss": 6.532441135436529,
            "mae": 0.4840286756189935,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7696096602136168,
            "auditor_fn_violation": 0.002745759025663332,
            "auditor_fp_violation": 0.006952984095753417,
            "ave_precision_score": 0.7119910034845174,
            "fpr": 0.4506578947368421,
            "logloss": 3.3858724253520545,
            "mae": 0.40484315225560413,
            "precision": 0.5387205387205387,
            "recall": 0.9917355371900827
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7721829594135817,
            "auditor_fn_violation": 0.0006679589882523297,
            "auditor_fp_violation": 0.006075902735774148,
            "ave_precision_score": 0.7090296023220627,
            "fpr": 0.4588364434687157,
            "logloss": 3.616754119088793,
            "mae": 0.40550003234301124,
            "precision": 0.5287485907553551,
            "recall": 0.997872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5940622304568786,
            "auditor_fn_violation": 0.009707572132811369,
            "auditor_fp_violation": 0.010739465486145272,
            "ave_precision_score": 0.572129447271282,
            "fpr": 0.08333333333333333,
            "logloss": 8.051678802578873,
            "mae": 0.5378707979005157,
            "precision": 0.6398104265402843,
            "recall": 0.27892561983471076
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5853600230188276,
            "auditor_fn_violation": 0.00857136184225893,
            "auditor_fp_violation": 0.011021752279396944,
            "ave_precision_score": 0.562704851280434,
            "fpr": 0.09879253567508232,
            "logloss": 8.205978157491861,
            "mae": 0.5372234956493231,
            "precision": 0.625,
            "recall": 0.3191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7586317046165543,
            "auditor_fn_violation": 0.007967685225460342,
            "auditor_fp_violation": 0.007188678471880638,
            "ave_precision_score": 0.7000114633899002,
            "fpr": 0.17434210526315788,
            "logloss": 3.3718884426440505,
            "mae": 0.3965980777876419,
            "precision": 0.676829268292683,
            "recall": 0.6880165289256198
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7581724294296982,
            "auditor_fn_violation": 0.0027092042880164486,
            "auditor_fp_violation": 0.014556279884804275,
            "ave_precision_score": 0.694333036831925,
            "fpr": 0.21953896816684962,
            "logloss": 3.605672068215409,
            "mae": 0.3983538062787082,
            "precision": 0.6296296296296297,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7844924828021671,
            "auditor_fn_violation": 0.000598086124401914,
            "auditor_fp_violation": 0.0029205607476635587,
            "ave_precision_score": 0.7268703211968035,
            "fpr": 0.4616228070175439,
            "logloss": 4.65243803293193,
            "mae": 0.4610650700345169,
            "precision": 0.5342920353982301,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7837256779184877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031238254540747867,
            "ave_precision_score": 0.7205503095368367,
            "fpr": 0.47859495060373214,
            "logloss": 4.9315447833080865,
            "mae": 0.4765274168265816,
            "precision": 0.5187637969094923,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.666237795517619,
            "auditor_fn_violation": 0.0018894084384515008,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6849708577826943,
            "fpr": 0.4692982456140351,
            "logloss": 1.0253028632003236,
            "mae": 0.4350514281867889,
            "precision": 0.5291529152915292,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6596651322092812,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6820459338934864,
            "fpr": 0.4840834248079034,
            "logloss": 1.0644562304846867,
            "mae": 0.4401672402014455,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8360618382933106,
            "auditor_fn_violation": 0.022618529795563294,
            "auditor_fp_violation": 0.018184333497294647,
            "ave_precision_score": 0.8363215955696934,
            "fpr": 0.13815789473684212,
            "logloss": 0.541932519724051,
            "mae": 0.34163121487424514,
            "precision": 0.7439024390243902,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8411178318593924,
            "auditor_fn_violation": 0.012242800756708786,
            "auditor_fp_violation": 0.013612909488713161,
            "ave_precision_score": 0.8418451522755938,
            "fpr": 0.13172338090010977,
            "logloss": 0.5198708125649948,
            "mae": 0.3353292321419276,
            "precision": 0.7505197505197505,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.4848372547630135,
            "auditor_fn_violation": 0.0008608815426997265,
            "auditor_fp_violation": 0.004434640924741772,
            "ave_precision_score": 0.4970842912555021,
            "fpr": 0.4375,
            "logloss": 0.6927916659947068,
            "mae": 0.49903189430111333,
            "precision": 0.5311398354876615,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.48610814718051854,
            "auditor_fn_violation": 0.0005978933601139744,
            "auditor_fp_violation": 0.0016353412934877697,
            "ave_precision_score": 0.5005387721524087,
            "fpr": 0.4643249176728869,
            "logloss": 0.6937526402104112,
            "mae": 0.49948908285566007,
            "precision": 0.5149082568807339,
            "recall": 0.9553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7970590113486467,
            "auditor_fn_violation": 0.015219479483833554,
            "auditor_fp_violation": 0.025626639613051318,
            "ave_precision_score": 0.7394337637078355,
            "fpr": 0.17653508771929824,
            "logloss": 3.2014313238277374,
            "mae": 0.29263520675375365,
            "precision": 0.7180385288966725,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.799361959093721,
            "auditor_fn_violation": 0.01698157273979961,
            "auditor_fp_violation": 0.016258826984873718,
            "ave_precision_score": 0.7368128554038117,
            "fpr": 0.18551042810098792,
            "logloss": 3.3588629518227155,
            "mae": 0.2930502865527901,
            "precision": 0.7076124567474048,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7725858311648856,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.7042438719448223,
            "fpr": 0.10855263157894737,
            "logloss": 3.366121766584227,
            "mae": 0.40084423320858104,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7719879861293173,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6987020386012797,
            "fpr": 0.12403951701427003,
            "logloss": 3.5941138480329107,
            "mae": 0.40191797514647476,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7603132091270208,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.662155979333807,
            "fpr": 0.4692982456140351,
            "logloss": 9.52824784560184,
            "mae": 0.46929822090947837,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7596360451503125,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6561916985782168,
            "fpr": 0.4840834248079034,
            "logloss": 10.014673301375467,
            "mae": 0.48408339431859004,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.366054156737148,
            "mae": 0.4008600001729894,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7712258521620733,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6954042841191628,
            "fpr": 0.12403951701427003,
            "logloss": 3.594027093523767,
            "mae": 0.40194002778548443,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7611779812279591,
            "auditor_fn_violation": 0.00518341307814992,
            "auditor_fp_violation": 0.010729217904574538,
            "ave_precision_score": 0.7019806779052644,
            "fpr": 0.375,
            "logloss": 3.409234540771735,
            "mae": 0.3917777999074787,
            "precision": 0.5703517587939698,
            "recall": 0.9380165289256198
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.759617722405725,
            "auditor_fn_violation": 0.0007637153467080832,
            "auditor_fp_violation": 0.009177326254321709,
            "ave_precision_score": 0.6952435429444193,
            "fpr": 0.37980241492864986,
            "logloss": 3.6191457770210396,
            "mae": 0.3910940319099581,
            "precision": 0.5614702154626109,
            "recall": 0.9425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7152925034994441,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7168001839079914,
            "fpr": 0.4692982456140351,
            "logloss": 4.083151827584542,
            "mae": 0.4692198786427054,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7075802977905284,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7092410851139042,
            "fpr": 0.4840834248079034,
            "logloss": 4.183126803560952,
            "mae": 0.48399241551609645,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7938146103977977,
            "auditor_fn_violation": 0.010366826156299844,
            "auditor_fp_violation": 0.013152770946056734,
            "ave_precision_score": 0.7374206042152731,
            "fpr": 0.1206140350877193,
            "logloss": 3.392888957370043,
            "mae": 0.2984454931742891,
            "precision": 0.75,
            "recall": 0.6818181818181818
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7949932546338889,
            "auditor_fn_violation": 0.00856669080038303,
            "auditor_fp_violation": 0.015646507413796105,
            "ave_precision_score": 0.7330168607164426,
            "fpr": 0.13062568605927552,
            "logloss": 3.5668678276828345,
            "mae": 0.28958202102895153,
            "precision": 0.7325842696629213,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6833551788954457,
            "auditor_fn_violation": 0.07050166739161955,
            "auditor_fp_violation": 0.07317797999672078,
            "ave_precision_score": 0.6811500139115012,
            "fpr": 0.2236842105263158,
            "logloss": 0.6677509238395491,
            "mae": 0.4490078521827072,
            "precision": 0.6194029850746269,
            "recall": 0.6859504132231405
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6766778143853541,
            "auditor_fn_violation": 0.06149893733797324,
            "auditor_fp_violation": 0.07291332193323727,
            "ave_precision_score": 0.6750057678120505,
            "fpr": 0.24478594950603733,
            "logloss": 0.6773693904463151,
            "mae": 0.45136020583653685,
            "precision": 0.6046099290780141,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7845707355166487,
            "auditor_fn_violation": 0.000598086124401914,
            "auditor_fp_violation": 0.0029205607476635587,
            "ave_precision_score": 0.7269460119035976,
            "fpr": 0.4616228070175439,
            "logloss": 4.650198284648432,
            "mae": 0.4610750073009098,
            "precision": 0.5342920353982301,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7837678211861694,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031238254540747867,
            "ave_precision_score": 0.7205976381225941,
            "fpr": 0.47859495060373214,
            "logloss": 4.9278359230151505,
            "mae": 0.4765402769563666,
            "precision": 0.5187637969094923,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8403911639073295,
            "auditor_fn_violation": 0.015871937074090195,
            "auditor_fp_violation": 0.008982005246761763,
            "ave_precision_score": 0.8411052458915202,
            "fpr": 0.09429824561403509,
            "logloss": 0.5652212737527598,
            "mae": 0.3017651195981224,
            "precision": 0.7917675544794189,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.85050025181407,
            "auditor_fn_violation": 0.018128313520330713,
            "auditor_fp_violation": 0.01427003293084523,
            "ave_precision_score": 0.8507458681153673,
            "fpr": 0.09879253567508232,
            "logloss": 0.5267269727407907,
            "mae": 0.2912585306751088,
            "precision": 0.7867298578199052,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.79653620057471,
            "auditor_fn_violation": 0.01432008481948674,
            "auditor_fp_violation": 0.01218437448762092,
            "ave_precision_score": 0.738909294346917,
            "fpr": 0.13267543859649122,
            "logloss": 3.1970064832973346,
            "mae": 0.3045620708072787,
            "precision": 0.7468619246861925,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7992905731179388,
            "auditor_fn_violation": 0.014905294625966322,
            "auditor_fp_violation": 0.01839945637969788,
            "ave_precision_score": 0.7361366362798578,
            "fpr": 0.14050493962678376,
            "logloss": 3.3634161370930626,
            "mae": 0.2979557357734104,
            "precision": 0.7355371900826446,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7850382120664589,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7233086255938639,
            "fpr": 0.4692982456140351,
            "logloss": 5.332871353357614,
            "mae": 0.46855474988880913,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7787806904622236,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7125934401882904,
            "fpr": 0.4840834248079034,
            "logloss": 5.57187828762509,
            "mae": 0.4833013588065766,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6833551788954457,
            "auditor_fn_violation": 0.07050166739161955,
            "auditor_fp_violation": 0.07317797999672078,
            "ave_precision_score": 0.6811500139115012,
            "fpr": 0.2236842105263158,
            "logloss": 0.6676288421692782,
            "mae": 0.44901699527052413,
            "precision": 0.6194029850746269,
            "recall": 0.6859504132231405
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6766778143853541,
            "auditor_fn_violation": 0.06149893733797324,
            "auditor_fp_violation": 0.07291332193323727,
            "ave_precision_score": 0.6750057678120505,
            "fpr": 0.24478594950603733,
            "logloss": 0.6772338168481747,
            "mae": 0.4513682665305394,
            "precision": 0.6046099290780141,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8148718659269636,
            "auditor_fn_violation": 0.01576772509786864,
            "auditor_fp_violation": 0.009976020659124452,
            "ave_precision_score": 0.8162021198310653,
            "fpr": 0.12938596491228072,
            "logloss": 0.5914546456596526,
            "mae": 0.306825654465795,
            "precision": 0.7526205450733753,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8221604179995737,
            "auditor_fn_violation": 0.01124786883714413,
            "auditor_fp_violation": 0.016134371787500223,
            "ave_precision_score": 0.8224883551230319,
            "fpr": 0.132821075740944,
            "logloss": 0.5811955666884097,
            "mae": 0.2999650695157758,
            "precision": 0.7473903966597077,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7767683231382321,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7768514157410547,
            "fpr": 0.4692982456140351,
            "logloss": 4.038183781415274,
            "mae": 0.46930592448303576,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7352077019743699,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7365466025625205,
            "fpr": 0.4840834248079034,
            "logloss": 4.100350840206177,
            "mae": 0.4840820718282664,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7884267667188379,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7266779380087315,
            "fpr": 0.4692982456140351,
            "logloss": 6.48098247897352,
            "mae": 0.4692645719961116,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7815489339634322,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7152159273491084,
            "fpr": 0.4840834248079034,
            "logloss": 6.744882632089853,
            "mae": 0.48404829274417277,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7831059111733807,
            "auditor_fn_violation": 0.010262614180078294,
            "auditor_fp_violation": 0.0087335013936711,
            "ave_precision_score": 0.7254878130844191,
            "fpr": 0.23574561403508773,
            "logloss": 3.348375139673425,
            "mae": 0.3306802423781176,
            "precision": 0.6692307692307692,
            "recall": 0.8987603305785123
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7868627681720863,
            "auditor_fn_violation": 0.010960599761776867,
            "auditor_fp_violation": 0.022620976674606916,
            "ave_precision_score": 0.723048157024776,
            "fpr": 0.2513721185510428,
            "logloss": 3.5522702701657005,
            "mae": 0.3277333029351605,
            "precision": 0.6530303030303031,
            "recall": 0.9170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7825148698543192,
            "auditor_fn_violation": 0.010262614180078294,
            "auditor_fp_violation": 0.010319314641744567,
            "ave_precision_score": 0.7248971908345654,
            "fpr": 0.23684210526315788,
            "logloss": 3.3479540885208547,
            "mae": 0.33401651669108806,
            "precision": 0.6682027649769585,
            "recall": 0.8987603305785123
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.786005533302321,
            "auditor_fn_violation": 0.010960599761776867,
            "auditor_fp_violation": 0.02130672979034278,
            "ave_precision_score": 0.7221913258970397,
            "fpr": 0.25466520307354557,
            "logloss": 3.555221745756926,
            "mae": 0.33214455208885274,
            "precision": 0.6500754147812972,
            "recall": 0.9170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7822292920471922,
            "auditor_fn_violation": 0.009268069450485718,
            "auditor_fp_violation": 0.010457656992949668,
            "ave_precision_score": 0.7246116917578224,
            "fpr": 0.23355263157894737,
            "logloss": 3.3479136046367723,
            "mae": 0.33308743489135195,
            "precision": 0.6702786377708978,
            "recall": 0.8946280991735537
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7862499755311825,
            "auditor_fn_violation": 0.011876123969451388,
            "auditor_fp_violation": 0.02174481208509749,
            "ave_precision_score": 0.7224356676513768,
            "fpr": 0.2535675082327113,
            "logloss": 3.553003429199328,
            "mae": 0.3299878881727964,
            "precision": 0.6510574018126888,
            "recall": 0.9170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7621965147850022,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5311734783174505,
            "fpr": 0.4692982456140351,
            "logloss": 0.6917670835412063,
            "mae": 0.4990953191330558,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7554717030382795,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5160913504409766,
            "fpr": 0.4840834248079034,
            "logloss": 0.692639973049256,
            "mae": 0.4995309902860095,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.365727626976143,
            "mae": 0.4009334295661303,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7712258521620733,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6954042841191628,
            "fpr": 0.12403951701427003,
            "logloss": 3.5936073656620766,
            "mae": 0.40204278988974285,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.365970843272524,
            "mae": 0.40087915349163505,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7711442236841682,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6953955770815196,
            "fpr": 0.12403951701427003,
            "logloss": 3.5939201140496304,
            "mae": 0.40196682259227784,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 8233,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7547335469900274,
            "auditor_fn_violation": 0.015887795418297813,
            "auditor_fp_violation": 0.011354320380390229,
            "ave_precision_score": 0.6971176968011108,
            "fpr": 0.11293859649122807,
            "logloss": 3.366334082470958,
            "mae": 0.39978881026699875,
            "precision": 0.7345360824742269,
            "recall": 0.5888429752066116
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7546041917831985,
            "auditor_fn_violation": 0.008508302776934398,
            "auditor_fp_violation": 0.013747321101876535,
            "ave_precision_score": 0.6914534540942981,
            "fpr": 0.1350164654226125,
            "logloss": 3.5954333679538637,
            "mae": 0.40104354638299616,
            "precision": 0.7071428571428572,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 8233,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7547313829528874,
            "auditor_fn_violation": 0.015887795418297813,
            "auditor_fp_violation": 0.011354320380390229,
            "ave_precision_score": 0.6971159844788244,
            "fpr": 0.11293859649122807,
            "logloss": 3.366334146113786,
            "mae": 0.3997888077181159,
            "precision": 0.7345360824742269,
            "recall": 0.5888429752066116
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7546035804785497,
            "auditor_fn_violation": 0.008508302776934398,
            "auditor_fp_violation": 0.013747321101876535,
            "ave_precision_score": 0.6914522314850007,
            "fpr": 0.1350164654226125,
            "logloss": 3.5954333974249133,
            "mae": 0.40104354160677325,
            "precision": 0.7071428571428572,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7850334694244169,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7233002484707743,
            "fpr": 0.4692982456140351,
            "logloss": 5.333462283966217,
            "mae": 0.4685558747957673,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7787920499016562,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7126191008836836,
            "fpr": 0.4840834248079034,
            "logloss": 5.572458371914517,
            "mae": 0.48330254350614077,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7838422688083118,
            "auditor_fn_violation": 0.013937219080759755,
            "auditor_fp_violation": 0.014116043613707174,
            "ave_precision_score": 0.7268164979114795,
            "fpr": 0.18201754385964913,
            "logloss": 3.2954710744388893,
            "mae": 0.31648513675998147,
            "precision": 0.6981818181818182,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7831077429550474,
            "auditor_fn_violation": 0.01260247098115235,
            "auditor_fp_violation": 0.015176066767724296,
            "ave_precision_score": 0.719295261822525,
            "fpr": 0.19209659714599342,
            "logloss": 3.526114367425698,
            "mae": 0.3177153193188037,
            "precision": 0.6835443037974683,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6646777657938563,
            "auditor_fn_violation": 0.011991173698709596,
            "auditor_fp_violation": 0.00010247581570749334,
            "ave_precision_score": 0.6596459440427178,
            "fpr": 0.03179824561403509,
            "logloss": 0.6518059248071463,
            "mae": 0.46168489221548825,
            "precision": 0.8273809523809523,
            "recall": 0.2871900826446281
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.642620246335998,
            "auditor_fn_violation": 0.011000303617721955,
            "auditor_fp_violation": 0.006317345818678733,
            "ave_precision_score": 0.6382933388825973,
            "fpr": 0.04500548847420417,
            "logloss": 0.6610910584240752,
            "mae": 0.4648617844124919,
            "precision": 0.7630057803468208,
            "recall": 0.28085106382978725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7842008800408412,
            "auditor_fn_violation": 0.016275192112512687,
            "auditor_fp_violation": 0.01459255615674701,
            "ave_precision_score": 0.7265821854960897,
            "fpr": 0.20394736842105263,
            "logloss": 3.3018480634104375,
            "mae": 0.31489131648713575,
            "precision": 0.6889632107023411,
            "recall": 0.8512396694214877
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7872285335209673,
            "auditor_fn_violation": 0.01040708129948385,
            "auditor_fp_violation": 0.025224579403660484,
            "ave_precision_score": 0.7234800608182044,
            "fpr": 0.21734357848518113,
            "logloss": 3.4945205425915815,
            "mae": 0.31016993290388445,
            "precision": 0.6764705882352942,
            "recall": 0.8808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7984293913752756,
            "auditor_fn_violation": 0.01649267797593157,
            "auditor_fp_violation": 0.01276848663715364,
            "ave_precision_score": 0.7408011599650957,
            "fpr": 0.13157894736842105,
            "logloss": 3.189591804584447,
            "mae": 0.3021963445381404,
            "precision": 0.7560975609756098,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8003694878866466,
            "auditor_fn_violation": 0.007870705560875352,
            "auditor_fp_violation": 0.01770001817045882,
            "ave_precision_score": 0.7372147820225295,
            "fpr": 0.14270032930845225,
            "logloss": 3.356480411788151,
            "mae": 0.29706841862185945,
            "precision": 0.7368421052631579,
            "recall": 0.774468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7831743487518721,
            "auditor_fn_violation": 0.011173336233144848,
            "auditor_fp_violation": 0.009356041974094115,
            "ave_precision_score": 0.7255562745504415,
            "fpr": 0.23355263157894737,
            "logloss": 3.3376278583509666,
            "mae": 0.3311933179977227,
            "precision": 0.6702786377708978,
            "recall": 0.8946280991735537
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.786740335542859,
            "auditor_fn_violation": 0.011056356120232619,
            "auditor_fp_violation": 0.02078899616926904,
            "ave_precision_score": 0.7229257358187361,
            "fpr": 0.2502744237102086,
            "logloss": 3.543776539288968,
            "mae": 0.3288973739741802,
            "precision": 0.6545454545454545,
            "recall": 0.9191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7940545556830777,
            "auditor_fn_violation": 0.011655882992605488,
            "auditor_fp_violation": 0.012025536973274317,
            "ave_precision_score": 0.7376577874398882,
            "fpr": 0.1206140350877193,
            "logloss": 3.39194334858505,
            "mae": 0.2986731238651724,
            "precision": 0.7494305239179955,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7947828439437365,
            "auditor_fn_violation": 0.00856669080038303,
            "auditor_fp_violation": 0.015646507413796105,
            "ave_precision_score": 0.7328065120999336,
            "fpr": 0.13062568605927552,
            "logloss": 3.569543159157569,
            "mae": 0.2902831306452567,
            "precision": 0.7325842696629213,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7850311874241495,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7232277560697975,
            "fpr": 0.4692982456140351,
            "logloss": 6.252384948507805,
            "mae": 0.4692495225422215,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7813674320979308,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7148345008453406,
            "fpr": 0.4840834248079034,
            "logloss": 6.513662261442179,
            "mae": 0.4840230208982097,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7586666534651683,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6970011819072063,
            "fpr": 0.4692982456140351,
            "logloss": 3.7483322496260487,
            "mae": 0.4466187710171206,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.765256738069102,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.698158754225761,
            "fpr": 0.4840834248079034,
            "logloss": 3.998443391655542,
            "mae": 0.45557163137243295,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8167484886654819,
            "auditor_fn_violation": 0.014408438451500655,
            "auditor_fp_violation": 0.014139100672241355,
            "ave_precision_score": 0.8180759486628371,
            "fpr": 0.13048245614035087,
            "logloss": 0.5854778216756653,
            "mae": 0.3050029296489236,
            "precision": 0.7546391752577319,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.824956297827832,
            "auditor_fn_violation": 0.012513721185510428,
            "auditor_fp_violation": 0.01755067193361062,
            "ave_precision_score": 0.8252766752551006,
            "fpr": 0.13391877058177826,
            "logloss": 0.5754896429132865,
            "mae": 0.29930192277675777,
            "precision": 0.75,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7715079833260015,
            "auditor_fn_violation": 0.010928664636798611,
            "auditor_fp_violation": 0.01659595835382851,
            "ave_precision_score": 0.7138682324290606,
            "fpr": 0.12938596491228072,
            "logloss": 3.369853955640894,
            "mae": 0.37765586882205515,
            "precision": 0.7170263788968825,
            "recall": 0.6177685950413223
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7748233511477735,
            "auditor_fn_violation": 0.011682275731601946,
            "auditor_fp_violation": 0.01675664777436771,
            "ave_precision_score": 0.7115923279524696,
            "fpr": 0.14818880351262348,
            "logloss": 3.5670597316832198,
            "mae": 0.37294763224469796,
            "precision": 0.7019867549668874,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6833551788954457,
            "auditor_fn_violation": 0.07050166739161955,
            "auditor_fp_violation": 0.07317797999672078,
            "ave_precision_score": 0.6811500139115012,
            "fpr": 0.2236842105263158,
            "logloss": 0.6676817805547426,
            "mae": 0.4490131228966148,
            "precision": 0.6194029850746269,
            "recall": 0.6859504132231405
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6766778143853541,
            "auditor_fn_violation": 0.06149893733797324,
            "auditor_fp_violation": 0.07291332193323727,
            "ave_precision_score": 0.6750057678120505,
            "fpr": 0.24478594950603733,
            "logloss": 0.6772925868758641,
            "mae": 0.4513648580902887,
            "precision": 0.6046099290780141,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7807498728392799,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7190182805718557,
            "fpr": 0.4692982456140351,
            "logloss": 5.2965819255777165,
            "mae": 0.46851245333489616,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7769484379628215,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7108161342330872,
            "fpr": 0.4840834248079034,
            "logloss": 5.530981309853064,
            "mae": 0.48321782044338474,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7665104797231093,
            "auditor_fn_violation": 0.016782659127156735,
            "auditor_fp_violation": 0.017010985407443845,
            "ave_precision_score": 0.7089647356624442,
            "fpr": 0.2236842105263158,
            "logloss": 3.5349645160442265,
            "mae": 0.3384530441445637,
            "precision": 0.6611295681063123,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7648065002841878,
            "auditor_fn_violation": 0.00872317070322536,
            "auditor_fp_violation": 0.01978090907054369,
            "ave_precision_score": 0.7010029511854946,
            "fpr": 0.2502744237102086,
            "logloss": 3.803971126799405,
            "mae": 0.3504943379626403,
            "precision": 0.6268412438625205,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.4848372547630135,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4970842912555021,
            "fpr": 0.4692982456140351,
            "logloss": 0.6957886255267774,
            "mae": 0.4993165955601031,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.48610814718051854,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5005387721524087,
            "fpr": 0.4840834248079034,
            "logloss": 0.6967813301566829,
            "mae": 0.49971219409833756,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7775409056508327,
            "auditor_fn_violation": 0.01594896331738437,
            "auditor_fp_violation": 0.012153631742908684,
            "ave_precision_score": 0.7199255933669394,
            "fpr": 0.2149122807017544,
            "logloss": 3.3209424116874304,
            "mae": 0.3378204802097651,
            "precision": 0.6786885245901639,
            "recall": 0.8553719008264463
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7845861713120086,
            "auditor_fn_violation": 0.011357638321227551,
            "auditor_fp_violation": 0.017458575087554228,
            "ave_precision_score": 0.7208391172122638,
            "fpr": 0.2261251372118551,
            "logloss": 3.51110085982003,
            "mae": 0.3279158952001903,
            "precision": 0.6672051696284329,
            "recall": 0.8787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7822924316776492,
            "auditor_fn_violation": 0.010366826156299842,
            "auditor_fp_violation": 0.009181833087391391,
            "ave_precision_score": 0.7246748129425602,
            "fpr": 0.23793859649122806,
            "logloss": 3.360264638202841,
            "mae": 0.3334258044686928,
            "precision": 0.667687595712098,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7861360873851285,
            "auditor_fn_violation": 0.012065301165424949,
            "auditor_fp_violation": 0.02174481208509749,
            "ave_precision_score": 0.7223218871556669,
            "fpr": 0.2535675082327113,
            "logloss": 3.565449093800443,
            "mae": 0.3307048687067304,
            "precision": 0.6515837104072398,
            "recall": 0.9191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.789752661153353,
            "auditor_fn_violation": 0.01039174641148326,
            "auditor_fp_violation": 0.013560112313494018,
            "ave_precision_score": 0.7321256698985533,
            "fpr": 0.11513157894736842,
            "logloss": 3.3898023563495654,
            "mae": 0.39737661965518145,
            "precision": 0.7388059701492538,
            "recall": 0.6136363636363636
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7865832757834632,
            "auditor_fn_violation": 0.012018590746666051,
            "auditor_fp_violation": 0.017528269998083403,
            "ave_precision_score": 0.7233945634050987,
            "fpr": 0.13062568605927552,
            "logloss": 3.626476893917035,
            "mae": 0.39830809291840646,
            "precision": 0.7251732101616628,
            "recall": 0.6680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 8233,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7954875738138029,
            "auditor_fn_violation": 0.009374546904451213,
            "auditor_fp_violation": 0.021056218232497138,
            "ave_precision_score": 0.7378622633977165,
            "fpr": 0.18969298245614036,
            "logloss": 3.2191416883230084,
            "mae": 0.31226932365761806,
            "precision": 0.709731543624161,
            "recall": 0.8739669421487604
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7997251014821573,
            "auditor_fn_violation": 0.009225307704883577,
            "auditor_fp_violation": 0.021080221331123007,
            "ave_precision_score": 0.736570876241376,
            "fpr": 0.19758507135016465,
            "logloss": 3.3911387537888786,
            "mae": 0.3080752845051055,
            "precision": 0.7019867549668874,
            "recall": 0.902127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6973113721772675,
            "auditor_fn_violation": 0.011991173698709596,
            "auditor_fp_violation": 0.00010247581570749334,
            "ave_precision_score": 0.6512911449554147,
            "fpr": 0.03179824561403509,
            "logloss": 0.6513924916132702,
            "mae": 0.45857492321285237,
            "precision": 0.8273809523809523,
            "recall": 0.2871900826446281
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6655388607027595,
            "auditor_fn_violation": 0.011000303617721955,
            "auditor_fp_violation": 0.006317345818678733,
            "ave_precision_score": 0.6242766467715763,
            "fpr": 0.04500548847420417,
            "logloss": 0.6575808297699073,
            "mae": 0.45970329635753066,
            "precision": 0.7630057803468208,
            "recall": 0.28085106382978725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8383814199006302,
            "auditor_fn_violation": 0.018203113672611286,
            "auditor_fp_violation": 0.018127971798655523,
            "ave_precision_score": 0.8386397011123616,
            "fpr": 0.1425438596491228,
            "logloss": 0.5350582410196081,
            "mae": 0.33908481352192577,
            "precision": 0.7445972495088409,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8440142698003266,
            "auditor_fn_violation": 0.01148609197281454,
            "auditor_fp_violation": 0.012228967693919868,
            "ave_precision_score": 0.8447419366491326,
            "fpr": 0.14709110867178923,
            "logloss": 0.5171242859011171,
            "mae": 0.3346586627793692,
            "precision": 0.7330677290836654,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7822887618274823,
            "auditor_fn_violation": 0.010366826156299842,
            "auditor_fp_violation": 0.009181833087391391,
            "ave_precision_score": 0.7246711459138211,
            "fpr": 0.23793859649122806,
            "logloss": 3.360264704829156,
            "mae": 0.33342535951452557,
            "precision": 0.667687595712098,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7861336789909287,
            "auditor_fn_violation": 0.012065301165424949,
            "auditor_fp_violation": 0.02174481208509749,
            "ave_precision_score": 0.7223194798203747,
            "fpr": 0.2535675082327113,
            "logloss": 3.5654488917286473,
            "mae": 0.33070459786003087,
            "precision": 0.6515837104072398,
            "recall": 0.9191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7715385364947022,
            "auditor_fn_violation": 0.010928664636798611,
            "auditor_fp_violation": 0.01350631251024759,
            "ave_precision_score": 0.7139441094122801,
            "fpr": 0.12719298245614036,
            "logloss": 3.3704888720669013,
            "mae": 0.3819070106333803,
            "precision": 0.7204819277108434,
            "recall": 0.6177685950413223
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7749300575472706,
            "auditor_fn_violation": 0.011217507064950848,
            "auditor_fp_violation": 0.01675664777436771,
            "ave_precision_score": 0.7117764952568619,
            "fpr": 0.14818880351262348,
            "logloss": 3.5742876287664767,
            "mae": 0.3785981394321801,
            "precision": 0.7013274336283186,
            "recall": 0.674468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 8233,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7831801063311976,
            "auditor_fn_violation": 0.012142960707554006,
            "auditor_fp_violation": 0.011907689785210687,
            "ave_precision_score": 0.7255623062811624,
            "fpr": 0.17763157894736842,
            "logloss": 3.318990329543933,
            "mae": 0.31625394576396276,
            "precision": 0.7,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7830755401218108,
            "auditor_fn_violation": 0.01321671298783194,
            "auditor_fp_violation": 0.013416270276863037,
            "ave_precision_score": 0.7192642097301669,
            "fpr": 0.19209659714599342,
            "logloss": 3.529808917249251,
            "mae": 0.31755494169042237,
            "precision": 0.6829710144927537,
            "recall": 0.8021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.766186743491667,
            "auditor_fn_violation": 0.008944106133101355,
            "auditor_fp_violation": 0.010329562223315296,
            "ave_precision_score": 0.6904907617304099,
            "fpr": 0.10635964912280702,
            "logloss": 3.2317648224260087,
            "mae": 0.40876832385465767,
            "precision": 0.7349726775956285,
            "recall": 0.5557851239669421
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7695218540935639,
            "auditor_fn_violation": 0.010327673587593721,
            "auditor_fp_violation": 0.019223349786310427,
            "ave_precision_score": 0.690567849558166,
            "fpr": 0.11964873765093303,
            "logloss": 3.3912852914954486,
            "mae": 0.4055045396580262,
            "precision": 0.7176165803108808,
            "recall": 0.5893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7820042852728921,
            "auditor_fn_violation": 0.009768740031897928,
            "auditor_fp_violation": 0.011126311690441058,
            "ave_precision_score": 0.724386751584525,
            "fpr": 0.23135964912280702,
            "logloss": 3.3407431093792335,
            "mae": 0.33270528059061655,
            "precision": 0.671850699844479,
            "recall": 0.8925619834710744
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7860333475812609,
            "auditor_fn_violation": 0.00827241516220193,
            "auditor_fp_violation": 0.02305408076146669,
            "ave_precision_score": 0.7222191888161966,
            "fpr": 0.24478594950603733,
            "logloss": 3.54508211833691,
            "mae": 0.3289637216162366,
            "precision": 0.6574500768049155,
            "recall": 0.9106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7959945263838778,
            "auditor_fn_violation": 0.017444178628389154,
            "auditor_fp_violation": 0.017697573372684048,
            "ave_precision_score": 0.7383680650311081,
            "fpr": 0.14692982456140352,
            "logloss": 3.190797709419122,
            "mae": 0.30698076578080774,
            "precision": 0.7423076923076923,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7995400366341233,
            "auditor_fn_violation": 0.016656935329425235,
            "auditor_fp_violation": 0.016980667129640005,
            "ave_precision_score": 0.7363859877289599,
            "fpr": 0.15806805708013172,
            "logloss": 3.3583522749844237,
            "mae": 0.3002015648488442,
            "precision": 0.7272727272727273,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7817238032925319,
            "auditor_fn_violation": 0.005699942003769755,
            "auditor_fp_violation": 0.007908571077225778,
            "ave_precision_score": 0.7241066551741917,
            "fpr": 0.25109649122807015,
            "logloss": 3.3777025488042187,
            "mae": 0.3398697571951504,
            "precision": 0.6607407407407407,
            "recall": 0.9214876033057852
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7840060838662714,
            "auditor_fn_violation": 0.009288366770208095,
            "auditor_fp_violation": 0.01911880742051669,
            "ave_precision_score": 0.7201928713511759,
            "fpr": 0.27442371020856204,
            "logloss": 3.601816215453178,
            "mae": 0.3415181589906812,
            "precision": 0.638205499276411,
            "recall": 0.9382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7825974924960275,
            "auditor_fn_violation": 0.009693979266347687,
            "auditor_fp_violation": 0.008700196753566175,
            "ave_precision_score": 0.7249797062206125,
            "fpr": 0.23684210526315788,
            "logloss": 3.3513279955274786,
            "mae": 0.3330380957841203,
            "precision": 0.669218989280245,
            "recall": 0.9028925619834711
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7863606495247282,
            "auditor_fn_violation": 0.00882826914543289,
            "auditor_fp_violation": 0.02174481208509749,
            "ave_precision_score": 0.7225462913390824,
            "fpr": 0.2535675082327113,
            "logloss": 3.557847110209808,
            "mae": 0.33050119381553356,
            "precision": 0.6521084337349398,
            "recall": 0.9212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8270334224980607,
            "auditor_fn_violation": 0.00937907785993911,
            "auditor_fp_violation": 0.01091367437284801,
            "ave_precision_score": 0.8273427091333827,
            "fpr": 0.10964912280701754,
            "logloss": 0.5375607571631427,
            "mae": 0.3379234333528745,
            "precision": 0.782608695652174,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.838669569682803,
            "auditor_fn_violation": 0.007401265852348366,
            "auditor_fp_violation": 0.01155193142020804,
            "ave_precision_score": 0.8389797549315685,
            "fpr": 0.11525795828759605,
            "logloss": 0.524251616052798,
            "mae": 0.332259989610406,
            "precision": 0.7676991150442478,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7829346586636848,
            "auditor_fn_violation": 0.011288875598086126,
            "auditor_fp_violation": 0.009819745040170528,
            "ave_precision_score": 0.725316714832282,
            "fpr": 0.23574561403508773,
            "logloss": 3.3417869707542316,
            "mae": 0.33249826067798205,
            "precision": 0.6682098765432098,
            "recall": 0.8946280991735537
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7863723529171162,
            "auditor_fn_violation": 0.010960599761776867,
            "auditor_fp_violation": 0.022182894379852196,
            "ave_precision_score": 0.7225579511057234,
            "fpr": 0.2524698133918771,
            "logloss": 3.5481540558718327,
            "mae": 0.3304247554385489,
            "precision": 0.6520423600605144,
            "recall": 0.9170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8167562136606232,
            "auditor_fn_violation": 0.010341905901116433,
            "auditor_fp_violation": 0.014656603541564192,
            "ave_precision_score": 0.8171410869794842,
            "fpr": 0.10635964912280702,
            "logloss": 0.8117054161525301,
            "mae": 0.30052978673535635,
            "precision": 0.7668269230769231,
            "recall": 0.6590909090909091
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8157407359271338,
            "auditor_fn_violation": 0.009486886049933446,
            "auditor_fp_violation": 0.009237064749060987,
            "ave_precision_score": 0.8159757085842005,
            "fpr": 0.10537870472008781,
            "logloss": 0.8161282643452978,
            "mae": 0.29265581363197013,
            "precision": 0.7681159420289855,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7764724040121324,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7143903495718942,
            "fpr": 0.4692982456140351,
            "logloss": 6.142317039529293,
            "mae": 0.46919878997039377,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7743258082275323,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7072423001078364,
            "fpr": 0.4840834248079034,
            "logloss": 6.417737688773257,
            "mae": 0.48397527594205186,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6454364366270093,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6877413057906852,
            "fpr": 0.4692982456140351,
            "logloss": 1.020495720556983,
            "mae": 0.4371410814162932,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6337897837589148,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6961859200716772,
            "fpr": 0.4840834248079034,
            "logloss": 1.0554014399340579,
            "mae": 0.44156477591339766,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7885231825923329,
            "auditor_fn_violation": 0.010176526025808322,
            "auditor_fp_violation": 0.015648057058534184,
            "ave_precision_score": 0.7316142019516751,
            "fpr": 0.15789473684210525,
            "logloss": 3.2952169787601595,
            "mae": 0.2970013493147231,
            "precision": 0.7230769230769231,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7830312175682316,
            "auditor_fn_violation": 0.010365041922600834,
            "auditor_fp_violation": 0.023845615816762127,
            "ave_precision_score": 0.7198211678781058,
            "fpr": 0.18660812294182216,
            "logloss": 3.541379150942629,
            "mae": 0.3097529033137039,
            "precision": 0.6846011131725418,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7098388641090736,
            "auditor_fn_violation": 0.00899847759895607,
            "auditor_fp_violation": 0.01527914412198721,
            "ave_precision_score": 0.7140069218136536,
            "fpr": 0.13267543859649122,
            "logloss": 0.7170112724769696,
            "mae": 0.402449872916597,
            "precision": 0.7125890736342043,
            "recall": 0.6198347107438017
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7052618590411939,
            "auditor_fn_violation": 0.01325641684377701,
            "auditor_fp_violation": 0.018698148853394273,
            "ave_precision_score": 0.7017724159458888,
            "fpr": 0.15148188803512624,
            "logloss": 0.7309711391069034,
            "mae": 0.3996108833835363,
            "precision": 0.7,
            "recall": 0.6851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7937915824109965,
            "auditor_fn_violation": 0.01407314774539655,
            "auditor_fp_violation": 0.016780414822101988,
            "ave_precision_score": 0.73739749217345,
            "fpr": 0.1524122807017544,
            "logloss": 3.2979827788051947,
            "mae": 0.2932631141317567,
            "precision": 0.7300970873786408,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7947551635467781,
            "auditor_fn_violation": 0.01802555059906112,
            "auditor_fp_violation": 0.01954195509158658,
            "ave_precision_score": 0.7327767748229116,
            "fpr": 0.16355653128430298,
            "logloss": 3.5003872577534194,
            "mae": 0.28941379142562224,
            "precision": 0.7140115163147792,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8360657090134777,
            "auditor_fn_violation": 0.018284670871393363,
            "auditor_fp_violation": 0.01771806853582555,
            "ave_precision_score": 0.8363342527332596,
            "fpr": 0.13925438596491227,
            "logloss": 0.5382002491411291,
            "mae": 0.342816201659668,
            "precision": 0.7449799196787149,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8426857697787079,
            "auditor_fn_violation": 0.010743396314547963,
            "auditor_fp_violation": 0.015268163613780677,
            "ave_precision_score": 0.8434126465324258,
            "fpr": 0.13721185510428102,
            "logloss": 0.5198445889339856,
            "mae": 0.33802504877894135,
            "precision": 0.7422680412371134,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.78310834789973,
            "auditor_fn_violation": 0.005088263012904162,
            "auditor_fp_violation": 0.009422651254303988,
            "ave_precision_score": 0.7254904018819833,
            "fpr": 0.25219298245614036,
            "logloss": 3.370054406147525,
            "mae": 0.3383470252758758,
            "precision": 0.6602658788774003,
            "recall": 0.9235537190082644
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7851707241948855,
            "auditor_fn_violation": 0.008258402036574259,
            "auditor_fp_violation": 0.02062720441268349,
            "ave_precision_score": 0.7213567920258243,
            "fpr": 0.28210757409440174,
            "logloss": 3.594509611051428,
            "mae": 0.3403990181647527,
            "precision": 0.6318051575931232,
            "recall": 0.9382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7679159376335664,
            "auditor_fn_violation": 0.015613672611280273,
            "auditor_fp_violation": 0.01367027381537958,
            "ave_precision_score": 0.7110200054782905,
            "fpr": 0.20942982456140352,
            "logloss": 3.5671040143560875,
            "mae": 0.3273634719160519,
            "precision": 0.6751700680272109,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7643555648343181,
            "auditor_fn_violation": 0.013013522666230707,
            "auditor_fp_violation": 0.01901924326261789,
            "ave_precision_score": 0.7011554725829833,
            "fpr": 0.24698133918770582,
            "logloss": 3.8423305747894756,
            "mae": 0.3448715973415573,
            "precision": 0.6305418719211823,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7696135589769675,
            "auditor_fn_violation": 0.002745759025663332,
            "auditor_fp_violation": 0.006952984095753417,
            "ave_precision_score": 0.7119941666233677,
            "fpr": 0.4506578947368421,
            "logloss": 3.3858726004976187,
            "mae": 0.4048431604904564,
            "precision": 0.5387205387205387,
            "recall": 0.9917355371900827
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7721756840567577,
            "auditor_fn_violation": 0.0006679589882523297,
            "auditor_fp_violation": 0.006075902735774148,
            "ave_precision_score": 0.7090240442746275,
            "fpr": 0.4588364434687157,
            "logloss": 3.61675450424765,
            "mae": 0.40550004595197514,
            "precision": 0.5287485907553551,
            "recall": 0.997872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7750279061374463,
            "auditor_fn_violation": 0.008373205741626795,
            "auditor_fp_violation": 0.006917117560255779,
            "ave_precision_score": 0.7053022931042334,
            "fpr": 0.22807017543859648,
            "logloss": 4.006762400209479,
            "mae": 0.33068071140830096,
            "precision": 0.6666666666666666,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7633622546510797,
            "auditor_fn_violation": 0.01038839713198029,
            "auditor_fp_violation": 0.016756647774367712,
            "ave_precision_score": 0.680652140056027,
            "fpr": 0.24698133918770582,
            "logloss": 4.684376966914484,
            "mae": 0.34440834734319997,
            "precision": 0.6445497630331753,
            "recall": 0.8680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7622615506129373,
            "auditor_fn_violation": 0.017140604610700307,
            "auditor_fp_violation": 0.021563473520249222,
            "ave_precision_score": 0.7040669430376996,
            "fpr": 0.24671052631578946,
            "logloss": 3.6015638394458933,
            "mae": 0.35415674983880563,
            "precision": 0.6456692913385826,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7612761768383466,
            "auditor_fn_violation": 0.009117873741738097,
            "auditor_fp_violation": 0.019671388496855024,
            "ave_precision_score": 0.6968747471148573,
            "fpr": 0.27442371020856204,
            "logloss": 3.867583427527415,
            "mae": 0.3663735459188079,
            "precision": 0.6147919876733436,
            "recall": 0.8489361702127659
        }
    }
]