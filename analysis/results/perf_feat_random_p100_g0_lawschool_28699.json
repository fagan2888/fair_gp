[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8429547008774688,
            "auditor_fn_violation": 0.024314692982456143,
            "auditor_fp_violation": 0.03233126218323587,
            "ave_precision_score": 0.8431880286254225,
            "fpr": 0.1425438596491228,
            "logloss": 0.782079513875168,
            "mae": 0.2700323051324801,
            "precision": 0.7445972495088409,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8265474095466377,
            "auditor_fn_violation": 0.017489011472532158,
            "auditor_fp_violation": 0.022486416968302492,
            "ave_precision_score": 0.8270664507349957,
            "fpr": 0.11855104281009879,
            "logloss": 0.8066173731524456,
            "mae": 0.268236479737691,
            "precision": 0.7672413793103449,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6989245971667905,
            "auditor_fn_violation": 0.008390442251462004,
            "auditor_fp_violation": 0.016889010721247568,
            "ave_precision_score": 0.7000784010830946,
            "fpr": 0.06359649122807018,
            "logloss": 2.093114281216173,
            "mae": 0.46344948202879194,
            "precision": 0.6759776536312849,
            "recall": 0.2520833333333333
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7245900576361013,
            "auditor_fn_violation": 0.003881300745228275,
            "auditor_fp_violation": 0.02129075851467068,
            "ave_precision_score": 0.7246017404564051,
            "fpr": 0.05378704720087816,
            "logloss": 2.0621664792726535,
            "mae": 0.44780081403660726,
            "precision": 0.7134502923976608,
            "recall": 0.25738396624472576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8077294005368338,
            "auditor_fn_violation": 0.017872807017543856,
            "auditor_fp_violation": 0.011299951267056532,
            "ave_precision_score": 0.8041554476114112,
            "fpr": 0.07236842105263158,
            "logloss": 0.556435998381385,
            "mae": 0.33799909754541885,
            "precision": 0.8186813186813187,
            "recall": 0.6208333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8479715464844783,
            "auditor_fn_violation": 0.00529394600452973,
            "auditor_fp_violation": 0.007201581484374806,
            "ave_precision_score": 0.8428775965956092,
            "fpr": 0.05817782656421515,
            "logloss": 0.516786545697293,
            "mae": 0.3240406112960089,
            "precision": 0.8523676880222841,
            "recall": 0.6455696202531646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6872360283554902,
            "auditor_fn_violation": 0.00493877923976608,
            "auditor_fp_violation": 0.0032996263807667323,
            "ave_precision_score": 0.6864830001135791,
            "fpr": 0.06798245614035088,
            "logloss": 0.7755941466356265,
            "mae": 0.4439377436831005,
            "precision": 0.6787564766839378,
            "recall": 0.27291666666666664
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7102401820801448,
            "auditor_fn_violation": 0.015117620086426115,
            "auditor_fp_violation": 0.008110884762136814,
            "ave_precision_score": 0.7091983481602507,
            "fpr": 0.059275521405049394,
            "logloss": 0.7347229185696352,
            "mae": 0.42854141829991316,
            "precision": 0.7272727272727273,
            "recall": 0.3037974683544304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8253629964467099,
            "auditor_fn_violation": 0.006304824561403514,
            "auditor_fp_violation": 0.009147579597141001,
            "ave_precision_score": 0.7361813733834834,
            "fpr": 0.17324561403508773,
            "logloss": 0.6075143854847567,
            "mae": 0.3937806876931797,
            "precision": 0.694980694980695,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.824931935817595,
            "auditor_fn_violation": 0.003911406299934696,
            "auditor_fp_violation": 0.01469956569464993,
            "ave_precision_score": 0.7353411565297511,
            "fpr": 0.18111964873765093,
            "logloss": 0.6122792965180329,
            "mae": 0.3963944511702765,
            "precision": 0.6839080459770115,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7939701101442376,
            "auditor_fn_violation": 0.008175712719298242,
            "auditor_fp_violation": 0.009853192007797272,
            "ave_precision_score": 0.7959082443427544,
            "fpr": 0.11951754385964912,
            "logloss": 0.5364614557742091,
            "mae": 0.3518732751213145,
            "precision": 0.7630434782608696,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8247174734546214,
            "auditor_fn_violation": 0.011245582588799813,
            "auditor_fp_violation": 0.008771511176643465,
            "ave_precision_score": 0.793533202646182,
            "fpr": 0.12403951701427003,
            "logloss": 0.5244680678646472,
            "mae": 0.34795890884263325,
            "precision": 0.755939524838013,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8070939630609714,
            "auditor_fn_violation": 0.008682839912280702,
            "auditor_fp_violation": 0.002728537199480183,
            "ave_precision_score": 0.8074462305440181,
            "fpr": 0.0668859649122807,
            "logloss": 0.8052784444910865,
            "mae": 0.35215730405719764,
            "precision": 0.8205882352941176,
            "recall": 0.58125
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8236284168344505,
            "auditor_fn_violation": 0.006975225444288512,
            "auditor_fp_violation": 0.011391409847101408,
            "ave_precision_score": 0.8239457587309005,
            "fpr": 0.06476399560922064,
            "logloss": 0.8005064143496367,
            "mae": 0.33931996473098774,
            "precision": 0.8294797687861272,
            "recall": 0.6054852320675106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7794816586752638,
            "auditor_fn_violation": 0.0015807748538011796,
            "auditor_fp_violation": 0.008205916991552957,
            "ave_precision_score": 0.7679161777338243,
            "fpr": 0.07346491228070176,
            "logloss": 0.5728818525824653,
            "mae": 0.3525286253884827,
            "precision": 0.8320802005012531,
            "recall": 0.6916666666666667
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8144258447520842,
            "auditor_fn_violation": 0.009948727924523065,
            "auditor_fp_violation": 0.012717686451129976,
            "ave_precision_score": 0.7935634048282242,
            "fpr": 0.07244785949506037,
            "logloss": 0.545783093250879,
            "mae": 0.3379216401313322,
            "precision": 0.8345864661654135,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7876288924986102,
            "auditor_fn_violation": 0.016445084064327504,
            "auditor_fp_violation": 0.0069901315789473685,
            "ave_precision_score": 0.7181470468733444,
            "fpr": 0.029605263157894735,
            "logloss": 0.6077469341119377,
            "mae": 0.4187150227085671,
            "precision": 0.8761467889908257,
            "recall": 0.39791666666666664
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.779502854923444,
            "auditor_fn_violation": 0.010879684308521724,
            "auditor_fp_violation": 0.00513429806559543,
            "ave_precision_score": 0.7104238796163375,
            "fpr": 0.02305159165751921,
            "logloss": 0.6014567838094295,
            "mae": 0.4135344006718186,
            "precision": 0.9014084507042254,
            "recall": 0.4050632911392405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 28699,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.5471420706853515,
            "auditor_fn_violation": 0.004555007309941525,
            "auditor_fp_violation": 0.006340358999350228,
            "ave_precision_score": 0.5565918140739123,
            "fpr": 0.02850877192982456,
            "logloss": 0.9111824651897587,
            "mae": 0.5025812027375459,
            "precision": 0.4222222222222222,
            "recall": 0.03958333333333333
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5462502752619028,
            "auditor_fn_violation": 0.0040109862116559465,
            "auditor_fp_violation": 0.008645916801261973,
            "ave_precision_score": 0.5541074223454927,
            "fpr": 0.036223929747530186,
            "logloss": 0.8937268938723854,
            "mae": 0.4958247106489608,
            "precision": 0.4,
            "recall": 0.046413502109704644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7622851810913936,
            "auditor_fn_violation": 0.002176991959064327,
            "auditor_fp_violation": 0.0056956627680312035,
            "ave_precision_score": 0.537099130882442,
            "fpr": 0.4407894736842105,
            "logloss": 0.6897696411679357,
            "mae": 0.4979928971774745,
            "precision": 0.5373993095512083,
            "recall": 0.9729166666666667
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7585048459460417,
            "auditor_fn_violation": 0.004186987916093504,
            "auditor_fp_violation": 0.005063965215381804,
            "ave_precision_score": 0.5308567602309227,
            "fpr": 0.4456641053787047,
            "logloss": 0.6900206229264092,
            "mae": 0.4981072221184405,
            "precision": 0.5311778290993071,
            "recall": 0.9704641350210971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7241059048981167,
            "auditor_fn_violation": 0.0073305007309941534,
            "auditor_fp_violation": 0.0024569525666016984,
            "ave_precision_score": 0.7256551251631087,
            "fpr": 0.11403508771929824,
            "logloss": 0.6982357812991471,
            "mae": 0.29603265665418965,
            "precision": 0.7704194260485652,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7438727380358106,
            "auditor_fn_violation": 0.0021282311365541694,
            "auditor_fp_violation": 0.011984215298902054,
            "ave_precision_score": 0.745291100692988,
            "fpr": 0.1119648737650933,
            "logloss": 0.6833699554505609,
            "mae": 0.28456365622466445,
            "precision": 0.7738359201773836,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8007430188530036,
            "auditor_fn_violation": 0.00764802631578947,
            "auditor_fp_violation": 0.01260964912280703,
            "ave_precision_score": 0.7594574676862567,
            "fpr": 0.14473684210526316,
            "logloss": 3.9287442378958675,
            "mae": 0.2810789276425228,
            "precision": 0.7391304347826086,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7814949774562457,
            "auditor_fn_violation": 0.00938830144460347,
            "auditor_fp_violation": 0.012782995526328353,
            "ave_precision_score": 0.7410477018063616,
            "fpr": 0.13062568605927552,
            "logloss": 4.3415653015614515,
            "mae": 0.29283966951125584,
            "precision": 0.7440860215053764,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.757235259370597,
            "auditor_fn_violation": 0.005640076754385965,
            "auditor_fp_violation": 0.005170260721247567,
            "ave_precision_score": 0.7107143983755474,
            "fpr": 0.10197368421052631,
            "logloss": 0.584803116419529,
            "mae": 0.3885677104260315,
            "precision": 0.7753623188405797,
            "recall": 0.66875
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7454174125417863,
            "auditor_fn_violation": 0.0019313871250121602,
            "auditor_fp_violation": 0.006945368958596559,
            "ave_precision_score": 0.7046759502546137,
            "fpr": 0.09110867178924259,
            "logloss": 0.5803331658599883,
            "mae": 0.3872041706523309,
            "precision": 0.789873417721519,
            "recall": 0.6582278481012658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7782805703290927,
            "auditor_fn_violation": 0.006339089912280707,
            "auditor_fp_violation": 0.008505421539961013,
            "ave_precision_score": 0.7768853381488452,
            "fpr": 0.08223684210526316,
            "logloss": 0.582650776622395,
            "mae": 0.3529320499918979,
            "precision": 0.8076923076923077,
            "recall": 0.65625
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8161587071572327,
            "auditor_fn_violation": 0.009258615978175795,
            "auditor_fp_violation": 0.01370234635412088,
            "ave_precision_score": 0.813376565178119,
            "fpr": 0.07683863885839737,
            "logloss": 0.5464433353157141,
            "mae": 0.3334369488718841,
            "precision": 0.8214285714285714,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8517318608970256,
            "auditor_fn_violation": 0.021594024122807025,
            "auditor_fp_violation": 0.016561586257309944,
            "ave_precision_score": 0.849207954804357,
            "fpr": 0.09539473684210527,
            "logloss": 0.4896959629038303,
            "mae": 0.31593238163265613,
            "precision": 0.8040540540540541,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.868515800198219,
            "auditor_fn_violation": 0.01901281570305734,
            "auditor_fp_violation": 0.014862838382645875,
            "ave_precision_score": 0.8675523679714302,
            "fpr": 0.09330406147091108,
            "logloss": 0.4715343392109987,
            "mae": 0.3083882179565147,
            "precision": 0.8081264108352144,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.47437165702462064,
            "auditor_fn_violation": 0.004166666666666665,
            "auditor_fp_violation": 0.004040773229369727,
            "ave_precision_score": 0.4763217427186658,
            "fpr": 0.3607456140350877,
            "logloss": 0.6960508851988745,
            "mae": 0.4999889854276389,
            "precision": 0.5161764705882353,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5032670713885153,
            "auditor_fn_violation": 0.0057895297512354895,
            "auditor_fp_violation": 0.016862300838719244,
            "ave_precision_score": 0.5047927948464378,
            "fpr": 0.3424807903402854,
            "logloss": 0.6893089088620725,
            "mae": 0.4964939026094556,
            "precision": 0.5329341317365269,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6704770068987591,
            "auditor_fn_violation": 0.03670961257309943,
            "auditor_fp_violation": 0.01978760558804419,
            "ave_precision_score": 0.6357353896304,
            "fpr": 0.09429824561403509,
            "logloss": 0.7852854451018321,
            "mae": 0.4644199695658723,
            "precision": 0.6704980842911877,
            "recall": 0.3645833333333333
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6803382862533506,
            "auditor_fn_violation": 0.03939890786310773,
            "auditor_fp_violation": 0.016560874337803656,
            "ave_precision_score": 0.6408210899464858,
            "fpr": 0.09110867178924259,
            "logloss": 0.7898254391172449,
            "mae": 0.4601185518622595,
            "precision": 0.6732283464566929,
            "recall": 0.36075949367088606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7741433544328759,
            "auditor_fn_violation": 0.006636056286549707,
            "auditor_fp_violation": 0.014124939083820669,
            "ave_precision_score": 0.7412739202800228,
            "fpr": 0.14583333333333334,
            "logloss": 3.580178404041289,
            "mae": 0.2851205894205864,
            "precision": 0.7329317269076305,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7674848750428961,
            "auditor_fn_violation": 0.008649557448345821,
            "auditor_fp_violation": 0.018814037432147643,
            "ave_precision_score": 0.7389044558929501,
            "fpr": 0.1207464324917673,
            "logloss": 3.485229172439465,
            "mae": 0.2884735470294726,
            "precision": 0.7516930022573364,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7541698860892428,
            "auditor_fn_violation": 0.026133040935672508,
            "auditor_fp_violation": 0.0085739522417154,
            "ave_precision_score": 0.6372903793477764,
            "fpr": 0.09429824561403509,
            "logloss": 0.6420582363175257,
            "mae": 0.4405814239657239,
            "precision": 0.7401812688821753,
            "recall": 0.5104166666666666
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7611895249119401,
            "auditor_fn_violation": 0.01850796870874961,
            "auditor_fp_violation": 0.011820942610906117,
            "ave_precision_score": 0.642390191986921,
            "fpr": 0.0801317233809001,
            "logloss": 0.630182619123458,
            "mae": 0.43757125198775665,
            "precision": 0.762987012987013,
            "recall": 0.4957805907172996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.5807785087719298,
            "auditor_fn_violation": 0.002930829678362592,
            "auditor_fp_violation": 0.009360786224821314,
            "ave_precision_score": 0.5309875730994152,
            "fpr": 0.07346491228070176,
            "logloss": 0.7196849363875045,
            "mae": 0.5012283544791373,
            "precision": 0.5533333333333333,
            "recall": 0.17291666666666666
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.6144626317789161,
            "auditor_fn_violation": 0.007433756200586376,
            "auditor_fp_violation": 0.009148294302787945,
            "ave_precision_score": 0.5387696560435212,
            "fpr": 0.06695938529088913,
            "logloss": 0.7072120732418727,
            "mae": 0.49504741794060664,
            "precision": 0.6114649681528662,
            "recall": 0.20253164556962025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 28699,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6958931595518939,
            "auditor_fn_violation": 0.04194307383040935,
            "auditor_fp_violation": 0.01995004873294347,
            "ave_precision_score": 0.6839603507483121,
            "fpr": 0.07675438596491228,
            "logloss": 4.159334601387293,
            "mae": 0.35541895309598,
            "precision": 0.7947214076246334,
            "recall": 0.5645833333333333
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7229389761119444,
            "auditor_fn_violation": 0.03595761137897336,
            "auditor_fp_violation": 0.01771885447882102,
            "ave_precision_score": 0.7125495854440248,
            "fpr": 0.07464324917672886,
            "logloss": 3.727455861856866,
            "mae": 0.35066743722769744,
            "precision": 0.7881619937694704,
            "recall": 0.5337552742616034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 28699,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7466344362290697,
            "auditor_fn_violation": 0.03902823464912283,
            "auditor_fp_violation": 0.013287341617933724,
            "ave_precision_score": 0.7314715204610034,
            "fpr": 0.03618421052631579,
            "logloss": 0.6999598785200907,
            "mae": 0.4484640320174788,
            "precision": 0.8428571428571429,
            "recall": 0.36875
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7950632013039782,
            "auditor_fn_violation": 0.03556160754398886,
            "auditor_fp_violation": 0.012747829101221532,
            "ave_precision_score": 0.7572398708889843,
            "fpr": 0.02854006586169045,
            "logloss": 0.6854193529947868,
            "mae": 0.44101186654030555,
            "precision": 0.8652849740932642,
            "recall": 0.35232067510548526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6785736304687022,
            "auditor_fn_violation": 0.0009914108187134504,
            "auditor_fp_violation": 0.007584064327485379,
            "ave_precision_score": 0.5773350091390312,
            "fpr": 0.36622807017543857,
            "logloss": 0.6473481234066802,
            "mae": 0.46082712041638924,
            "precision": 0.5840597758405978,
            "recall": 0.9770833333333333
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7006440284259069,
            "auditor_fn_violation": 0.003797931516810478,
            "auditor_fp_violation": 0.007631114248179515,
            "ave_precision_score": 0.5932102705135147,
            "fpr": 0.3677277716794731,
            "logloss": 0.644957455658931,
            "mae": 0.45851777392540755,
            "precision": 0.5775535939470365,
            "recall": 0.9662447257383966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5768400613335322,
            "auditor_fn_violation": 0.09041255482456141,
            "auditor_fp_violation": 0.0788306124106563,
            "ave_precision_score": 0.573347533309313,
            "fpr": 0.24780701754385964,
            "logloss": 0.683078101259712,
            "mae": 0.4795864562977824,
            "precision": 0.5868372943327239,
            "recall": 0.66875
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5615741040246451,
            "auditor_fn_violation": 0.08729221377722818,
            "auditor_fp_violation": 0.062304857739251006,
            "ave_precision_score": 0.574355910188408,
            "fpr": 0.24588364434687157,
            "logloss": 0.6789253543647503,
            "mae": 0.4772814630349826,
            "precision": 0.5882352941176471,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7326462549976867,
            "auditor_fn_violation": 0.01555646929824562,
            "auditor_fp_violation": 0.007051047758284601,
            "ave_precision_score": 0.7326854189925609,
            "fpr": 0.08114035087719298,
            "logloss": 3.775462260688664,
            "mae": 0.39559116171471187,
            "precision": 0.7394366197183099,
            "recall": 0.4375
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7417295378513644,
            "auditor_fn_violation": 0.01774375078158652,
            "auditor_fp_violation": 0.012634794163378186,
            "ave_precision_score": 0.74182125021155,
            "fpr": 0.0570801317233809,
            "logloss": 3.7154982221874744,
            "mae": 0.3790720675187577,
            "precision": 0.8059701492537313,
            "recall": 0.45569620253164556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5339235289361847,
            "auditor_fn_violation": 0.08187134502923976,
            "auditor_fp_violation": 0.08665326510721247,
            "ave_precision_score": 0.5704354603479325,
            "fpr": 0.2675438596491228,
            "logloss": 0.6913470769706087,
            "mae": 0.49473609990979495,
            "precision": 0.5696649029982364,
            "recall": 0.6729166666666667
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5109020456603324,
            "auditor_fn_violation": 0.07876539435960854,
            "auditor_fp_violation": 0.08256825426330108,
            "ave_precision_score": 0.5569843424124579,
            "fpr": 0.2535675082327113,
            "logloss": 0.6918018807213987,
            "mae": 0.4948997704964438,
            "precision": 0.5666041275797373,
            "recall": 0.6371308016877637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7546929792092152,
            "auditor_fn_violation": 0.0038377192982456177,
            "auditor_fp_violation": 0.003878330084470434,
            "ave_precision_score": 0.7212940176217174,
            "fpr": 0.06140350877192982,
            "logloss": 0.5717249802245657,
            "mae": 0.35980809687457066,
            "precision": 0.834319526627219,
            "recall": 0.5875
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.793514309116297,
            "auditor_fn_violation": 0.009865358696105277,
            "auditor_fp_violation": 0.008291740662686162,
            "ave_precision_score": 0.7532999476781888,
            "fpr": 0.048298572996706916,
            "logloss": 0.5259764571255748,
            "mae": 0.3407632908431157,
            "precision": 0.8705882352941177,
            "recall": 0.6244725738396625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7558449655189117,
            "auditor_fn_violation": 0.027412280701754384,
            "auditor_fp_violation": 0.03861578135152697,
            "ave_precision_score": 0.7438636010399301,
            "fpr": 0.15679824561403508,
            "logloss": 2.758569407728942,
            "mae": 0.3404830669566905,
            "precision": 0.6911447084233261,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7398132124684837,
            "auditor_fn_violation": 0.022546744663211472,
            "auditor_fp_violation": 0.0267691851688114,
            "ave_precision_score": 0.7216086874861756,
            "fpr": 0.13062568605927552,
            "logloss": 2.8330768084090145,
            "mae": 0.34161660711407893,
            "precision": 0.7186761229314421,
            "recall": 0.6413502109704642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5438060277431254,
            "auditor_fn_violation": 0.023490040204678375,
            "auditor_fp_violation": 0.019932281513970113,
            "ave_precision_score": 0.544104077102973,
            "fpr": 0.16557017543859648,
            "logloss": 4.923313177732599,
            "mae": 0.46467101237923103,
            "precision": 0.5805555555555556,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5705533438852124,
            "auditor_fn_violation": 0.020758937876029965,
            "auditor_fp_violation": 0.01415950988050951,
            "ave_precision_score": 0.5699668430410982,
            "fpr": 0.14818880351262348,
            "logloss": 4.398547768396687,
            "mae": 0.44234163372259405,
            "precision": 0.6164772727272727,
            "recall": 0.4578059071729958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7778774315106314,
            "auditor_fn_violation": 0.008504660087719301,
            "auditor_fp_violation": 0.030732212475633534,
            "ave_precision_score": 0.603094310230879,
            "fpr": 0.29276315789473684,
            "logloss": 0.6571736292628078,
            "mae": 0.4679155870455137,
            "precision": 0.6130434782608696,
            "recall": 0.88125
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7819375004956063,
            "auditor_fn_violation": 0.00854071428902259,
            "auditor_fp_violation": 0.03700010298738781,
            "ave_precision_score": 0.6098379062948166,
            "fpr": 0.27991218441273324,
            "logloss": 0.6492069014957838,
            "mae": 0.4641610690516253,
            "precision": 0.6210995542347697,
            "recall": 0.8818565400843882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.753706787791408,
            "auditor_fn_violation": 0.009528051900584799,
            "auditor_fp_violation": 0.00922372482131254,
            "ave_precision_score": 0.7454391320173,
            "fpr": 0.09429824561403509,
            "logloss": 0.549888075381215,
            "mae": 0.3519190636610514,
            "precision": 0.8022988505747126,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7888940625139457,
            "auditor_fn_violation": 0.006173954526717529,
            "auditor_fp_violation": 0.014842743282584834,
            "ave_precision_score": 0.7766989930806093,
            "fpr": 0.10208562019758508,
            "logloss": 0.5408495533504258,
            "mae": 0.34693111467832527,
            "precision": 0.7910112359550562,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7201089961626185,
            "auditor_fn_violation": 0.010999177631578955,
            "auditor_fp_violation": 0.019919590643274854,
            "ave_precision_score": 0.7209890269317052,
            "fpr": 0.19736842105263158,
            "logloss": 0.8796360903935397,
            "mae": 0.3721437848621776,
            "precision": 0.6571428571428571,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.725009245041562,
            "auditor_fn_violation": 0.012093169744380686,
            "auditor_fp_violation": 0.010132954205778854,
            "ave_precision_score": 0.7257796512105619,
            "fpr": 0.16465422612513722,
            "logloss": 0.737160533212535,
            "mae": 0.3684446402840439,
            "precision": 0.6842105263157895,
            "recall": 0.6856540084388185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5330687356652719,
            "auditor_fn_violation": 0.011691337719298254,
            "auditor_fp_violation": 0.008233836907082522,
            "ave_precision_score": 0.5362114361527731,
            "fpr": 0.0712719298245614,
            "logloss": 2.7472379814984844,
            "mae": 0.5108384233971877,
            "precision": 0.5723684210526315,
            "recall": 0.18125
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5623423742871665,
            "auditor_fn_violation": 0.006739012630438113,
            "auditor_fp_violation": 0.008831796476826581,
            "ave_precision_score": 0.5616214759095972,
            "fpr": 0.07135016465422613,
            "logloss": 2.5760914858931407,
            "mae": 0.4967248367063119,
            "precision": 0.5806451612903226,
            "recall": 0.189873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8096652265165611,
            "auditor_fn_violation": 0.01014254385964912,
            "auditor_fp_violation": 0.00783788174139052,
            "ave_precision_score": 0.8100203012989828,
            "fpr": 0.08771929824561403,
            "logloss": 0.6864118831819738,
            "mae": 0.36782138563822636,
            "precision": 0.786096256684492,
            "recall": 0.6125
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8095313680223386,
            "auditor_fn_violation": 0.00429119945161574,
            "auditor_fp_violation": 0.012951291989339553,
            "ave_precision_score": 0.8100421637577434,
            "fpr": 0.07683863885839737,
            "logloss": 0.6304221487315571,
            "mae": 0.3608523474803346,
            "precision": 0.8113207547169812,
            "recall": 0.6350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7709758269139808,
            "auditor_fn_violation": 0.007456140350877189,
            "auditor_fp_violation": 0.005096653671215075,
            "ave_precision_score": 0.7298212273347966,
            "fpr": 0.06140350877192982,
            "logloss": 0.5746920776039958,
            "mae": 0.38072968754721315,
            "precision": 0.8390804597701149,
            "recall": 0.6083333333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7583172500149038,
            "auditor_fn_violation": 0.005115628488191681,
            "auditor_fp_violation": 0.006237016681444938,
            "ave_precision_score": 0.7317285634913414,
            "fpr": 0.05817782656421515,
            "logloss": 0.564757262364594,
            "mae": 0.37463320119451615,
            "precision": 0.8502824858757062,
            "recall": 0.6350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7534952799329715,
            "auditor_fn_violation": 0.03501005116959065,
            "auditor_fp_violation": 0.033686647173489286,
            "ave_precision_score": 0.75494367639155,
            "fpr": 0.14473684210526316,
            "logloss": 0.8210303295460267,
            "mae": 0.3561687686768946,
            "precision": 0.7092511013215859,
            "recall": 0.6708333333333333
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7382144311636122,
            "auditor_fn_violation": 0.03483444260723367,
            "auditor_fp_violation": 0.032330504110703914,
            "ave_precision_score": 0.7394324963065828,
            "fpr": 0.12733260153677278,
            "logloss": 0.8470773566145839,
            "mae": 0.3645086878133971,
            "precision": 0.7211538461538461,
            "recall": 0.6329113924050633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6912293625981544,
            "auditor_fn_violation": 0.005311129385964913,
            "auditor_fp_violation": 0.01574683235867447,
            "ave_precision_score": 0.6791173507868724,
            "fpr": 0.2324561403508772,
            "logloss": 0.5906589958056445,
            "mae": 0.3981646012122694,
            "precision": 0.6723338485316847,
            "recall": 0.90625
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.6826685927024795,
            "auditor_fn_violation": 0.010414206116522393,
            "auditor_fp_violation": 0.02089388028846517,
            "ave_precision_score": 0.6873155570091541,
            "fpr": 0.21405049396267836,
            "logloss": 0.5735648743578095,
            "mae": 0.389959226962502,
            "precision": 0.6844660194174758,
            "recall": 0.8924050632911392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7854708627731954,
            "auditor_fn_violation": 0.04380254020467836,
            "auditor_fp_violation": 0.014665570175438609,
            "ave_precision_score": 0.7863587343033324,
            "fpr": 0.1337719298245614,
            "logloss": 2.4962124603227367,
            "mae": 0.35591374533798203,
            "precision": 0.7142857142857143,
            "recall": 0.6354166666666666
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7730487534795202,
            "auditor_fn_violation": 0.04676087389477877,
            "auditor_fp_violation": 0.01876631156950267,
            "ave_precision_score": 0.7740647633797384,
            "fpr": 0.10318331503841932,
            "logloss": 2.716250200831283,
            "mae": 0.3616818486206062,
            "precision": 0.7445652173913043,
            "recall": 0.5780590717299579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8189961823739924,
            "auditor_fn_violation": 0.011924342105263167,
            "auditor_fp_violation": 0.006335282651072126,
            "ave_precision_score": 0.7415844428282049,
            "fpr": 0.046052631578947366,
            "logloss": 0.6185411847662434,
            "mae": 0.4193363132353944,
            "precision": 0.86,
            "recall": 0.5375
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8178586051476385,
            "auditor_fn_violation": 0.027277948375921113,
            "auditor_fp_violation": 0.003114740509461027,
            "ave_precision_score": 0.7415607484477936,
            "fpr": 0.04610318331503842,
            "logloss": 0.5952220499535414,
            "mae": 0.412013281971834,
            "precision": 0.8595317725752508,
            "recall": 0.5421940928270043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6859797773441975,
            "auditor_fn_violation": 0.01644736842105263,
            "auditor_fp_violation": 0.004101689408706956,
            "ave_precision_score": 0.6481021252325818,
            "fpr": 0.06140350877192982,
            "logloss": 0.6606736269951419,
            "mae": 0.43084563288772315,
            "precision": 0.7846153846153846,
            "recall": 0.425
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6767012334501082,
            "auditor_fn_violation": 0.0112548458364018,
            "auditor_fp_violation": 0.011210553946552057,
            "ave_precision_score": 0.6504322633289413,
            "fpr": 0.06805708013172337,
            "logloss": 0.6530309361646273,
            "mae": 0.4238492700585157,
            "precision": 0.7816901408450704,
            "recall": 0.46835443037974683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6992736832179063,
            "auditor_fn_violation": 0.008260233918128662,
            "auditor_fp_violation": 0.012548732943469794,
            "ave_precision_score": 0.5815331933287531,
            "fpr": 0.3092105263157895,
            "logloss": 7.808097703677487,
            "mae": 0.4518927159931576,
            "precision": 0.555205047318612,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6804019347689408,
            "auditor_fn_violation": 0.010407258680820914,
            "auditor_fp_violation": 0.0201980874488517,
            "ave_precision_score": 0.5696215524301169,
            "fpr": 0.29418221734357847,
            "logloss": 7.464202785581972,
            "mae": 0.45613449829928043,
            "precision": 0.5562913907284768,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6122986889485761,
            "auditor_fn_violation": 0.018640350877193,
            "auditor_fp_violation": 0.00757898797920728,
            "ave_precision_score": 0.5772999445286682,
            "fpr": 0.08991228070175439,
            "logloss": 0.7850645680732616,
            "mae": 0.4957427665133748,
            "precision": 0.594059405940594,
            "recall": 0.25
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6330074756954978,
            "auditor_fn_violation": 0.020337460110140017,
            "auditor_fp_violation": 0.012353462762523644,
            "ave_precision_score": 0.5953787037879653,
            "fpr": 0.07464324917672886,
            "logloss": 0.7681584508582109,
            "mae": 0.48711007444185955,
            "precision": 0.6530612244897959,
            "recall": 0.270042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8491659366659124,
            "auditor_fn_violation": 0.010336714181286559,
            "auditor_fp_violation": 0.0025584795321637434,
            "ave_precision_score": 0.82118929399915,
            "fpr": 0.03508771929824561,
            "logloss": 0.6220949411660551,
            "mae": 0.33890050023864043,
            "precision": 0.8844765342960289,
            "recall": 0.5104166666666666
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8525550140492034,
            "auditor_fn_violation": 0.0019244396893106925,
            "auditor_fp_violation": 0.004031579449745923,
            "ave_precision_score": 0.8410496736877769,
            "fpr": 0.024149286498353458,
            "logloss": 0.6237102928326299,
            "mae": 0.32973693248240754,
            "precision": 0.914396887159533,
            "recall": 0.4957805907172996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6485149874008368,
            "auditor_fn_violation": 0.025529970760233927,
            "auditor_fp_violation": 0.015706221572449646,
            "ave_precision_score": 0.6504257966501619,
            "fpr": 0.16228070175438597,
            "logloss": 0.6489481183226364,
            "mae": 0.4502931462943946,
            "precision": 0.6666666666666666,
            "recall": 0.6166666666666667
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6889012491436561,
            "auditor_fn_violation": 0.01065968217797478,
            "auditor_fp_violation": 0.029790985840490124,
            "ave_precision_score": 0.6895791102160751,
            "fpr": 0.14928649835345773,
            "logloss": 0.6153031616118371,
            "mae": 0.43422914908955573,
            "precision": 0.6844547563805105,
            "recall": 0.6223628691983122
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7682102249248512,
            "auditor_fn_violation": 0.002352887426900585,
            "auditor_fp_violation": 0.0043453541260558845,
            "ave_precision_score": 0.5689753752743659,
            "fpr": 0.44298245614035087,
            "logloss": 0.7803476478527986,
            "mae": 0.45786867400206493,
            "precision": 0.540386803185438,
            "recall": 0.9895833333333334
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7640530560120231,
            "auditor_fn_violation": 0.0006993751939492465,
            "auditor_fp_violation": 0.006091327206002416,
            "ave_precision_score": 0.5592205869943564,
            "fpr": 0.4445664105378705,
            "logloss": 0.7931913254361076,
            "mae": 0.4631800263400397,
            "precision": 0.5366132723112128,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 28699,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6087916561714025,
            "auditor_fn_violation": 0.008591465643274855,
            "auditor_fp_violation": 0.03365111273554256,
            "ave_precision_score": 0.617475348456917,
            "fpr": 0.2916666666666667,
            "logloss": 0.6458067122141362,
            "mae": 0.4457571782955998,
            "precision": 0.6128093158660844,
            "recall": 0.8770833333333333
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6708176968973043,
            "auditor_fn_violation": 0.009939464676921084,
            "auditor_fp_violation": 0.037570301451619804,
            "ave_precision_score": 0.6732959272637374,
            "fpr": 0.27332601536772777,
            "logloss": 0.624584467748612,
            "mae": 0.435806592899803,
            "precision": 0.6232980332829047,
            "recall": 0.869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6374161391997694,
            "auditor_fn_violation": 0.011197916666666674,
            "auditor_fp_violation": 0.007995248538011694,
            "ave_precision_score": 0.6355721843406177,
            "fpr": 0.047149122807017545,
            "logloss": 9.620537046945804,
            "mae": 0.4632691744856339,
            "precision": 0.73125,
            "recall": 0.24375
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6653266512072411,
            "auditor_fn_violation": 0.010560102266253535,
            "auditor_fp_violation": 0.005764781830010527,
            "ave_precision_score": 0.6604960408272997,
            "fpr": 0.03402854006586169,
            "logloss": 9.197412501861413,
            "mae": 0.4446755660185596,
            "precision": 0.802547770700637,
            "recall": 0.26582278481012656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7033694433256659,
            "auditor_fn_violation": 0.0031935307017543885,
            "auditor_fp_violation": 0.008505421539961021,
            "ave_precision_score": 0.7036361189961808,
            "fpr": 0.17434210526315788,
            "logloss": 0.6654394635824008,
            "mae": 0.470121674750229,
            "precision": 0.5902061855670103,
            "recall": 0.47708333333333336
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7162475408392704,
            "auditor_fn_violation": 0.006803855363651942,
            "auditor_fp_violation": 0.014179604980570557,
            "ave_precision_score": 0.7165590449818354,
            "fpr": 0.15477497255762898,
            "logloss": 0.6562640743260264,
            "mae": 0.4644151555392666,
            "precision": 0.6028169014084507,
            "recall": 0.45147679324894513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7537240920924618,
            "auditor_fn_violation": 0.019679733187134518,
            "auditor_fp_violation": 0.017482943469785576,
            "ave_precision_score": 0.7540317961621127,
            "fpr": 0.06140350877192982,
            "logloss": 1.2747933593448346,
            "mae": 0.38858352461181966,
            "precision": 0.8021201413427562,
            "recall": 0.47291666666666665
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7527506308192421,
            "auditor_fn_violation": 0.017468169165427712,
            "auditor_fp_violation": 0.008347002187854018,
            "ave_precision_score": 0.7530070158979654,
            "fpr": 0.06147091108671789,
            "logloss": 1.3092303056528969,
            "mae": 0.3948023048971471,
            "precision": 0.7933579335793358,
            "recall": 0.45358649789029537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7666231065164447,
            "auditor_fn_violation": 0.006679459064327488,
            "auditor_fp_violation": 0.007434312053281354,
            "ave_precision_score": 0.7681001331739443,
            "fpr": 0.08662280701754387,
            "logloss": 0.6032418955801808,
            "mae": 0.3726535304980516,
            "precision": 0.7853260869565217,
            "recall": 0.6020833333333333
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8334454386118373,
            "auditor_fn_violation": 0.008091446780326717,
            "auditor_fp_violation": 0.012192701962035335,
            "ave_precision_score": 0.830091218529293,
            "fpr": 0.059275521405049394,
            "logloss": 0.575856937517484,
            "mae": 0.3571615632496668,
            "precision": 0.8383233532934131,
            "recall": 0.5907172995780591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8313531589398087,
            "auditor_fn_violation": 0.015200109649122811,
            "auditor_fp_violation": 0.00434027777777778,
            "ave_precision_score": 0.8305806778146938,
            "fpr": 0.04276315789473684,
            "logloss": 0.6148368829840948,
            "mae": 0.356090668486758,
            "precision": 0.8571428571428571,
            "recall": 0.4875
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8515059405234254,
            "auditor_fn_violation": 0.014249190623740781,
            "auditor_fp_violation": 0.004762538714466212,
            "ave_precision_score": 0.8496732879397698,
            "fpr": 0.03293084522502744,
            "logloss": 0.600402689700988,
            "mae": 0.34730884211565216,
            "precision": 0.8901098901098901,
            "recall": 0.5126582278481012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5180703059732663,
            "auditor_fn_violation": 0.0019417032163742782,
            "auditor_fp_violation": 0.0005127111760883692,
            "ave_precision_score": 0.5311753341687553,
            "fpr": 0.0010964912280701754,
            "logloss": 17.958204014875825,
            "mae": 0.5240884422929141,
            "precision": 0.8333333333333334,
            "recall": 0.010416666666666666
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5160277617325096,
            "auditor_fn_violation": 0.0013061179118787456,
            "auditor_fp_violation": 0.001190634678616553,
            "ave_precision_score": 0.5260780269811937,
            "fpr": 0.0021953896816684962,
            "logloss": 17.748207098561267,
            "mae": 0.5168963340157081,
            "precision": 0.75,
            "recall": 0.012658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7993824826614455,
            "auditor_fn_violation": 0.030619517543859654,
            "auditor_fp_violation": 0.0211480669265757,
            "ave_precision_score": 0.7185126355664782,
            "fpr": 0.09978070175438597,
            "logloss": 0.5684046505251726,
            "mae": 0.38529983574622556,
            "precision": 0.7893518518518519,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8212658875662304,
            "auditor_fn_violation": 0.021036835304089258,
            "auditor_fp_violation": 0.017422451752920697,
            "ave_precision_score": 0.747907311269423,
            "fpr": 0.09659714599341383,
            "logloss": 0.5533825432063091,
            "mae": 0.3795513930259238,
            "precision": 0.7934272300469484,
            "recall": 0.7130801687763713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.848133169884655,
            "auditor_fn_violation": 0.0072368421052631604,
            "auditor_fp_violation": 0.0065586419753086425,
            "ave_precision_score": 0.848436172861508,
            "fpr": 0.10416666666666667,
            "logloss": 0.49564552996228345,
            "mae": 0.33084376058178877,
            "precision": 0.7948164146868251,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8387251439219179,
            "auditor_fn_violation": 0.009272510849578754,
            "auditor_fp_violation": 0.015809819973022332,
            "ave_precision_score": 0.8401641293881278,
            "fpr": 0.10976948408342481,
            "logloss": 0.5015359502887373,
            "mae": 0.32720209404550826,
            "precision": 0.7844827586206896,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.8129536156158561,
            "auditor_fn_violation": 0.002352887426900585,
            "auditor_fp_violation": 0.005540834145549078,
            "ave_precision_score": 0.7194532036350106,
            "fpr": 0.44627192982456143,
            "logloss": 8.861385147153403,
            "mae": 0.4506610318887652,
            "precision": 0.5385487528344671,
            "recall": 0.9895833333333334
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.8153256452033947,
            "auditor_fn_violation": 0.0008383239079788985,
            "auditor_fp_violation": 0.005699472754812157,
            "ave_precision_score": 0.7190864316632863,
            "fpr": 0.45334796926454446,
            "logloss": 8.946879189432712,
            "mae": 0.45718323294600854,
            "precision": 0.5317460317460317,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5885428917965304,
            "auditor_fn_violation": 0.013719846491228075,
            "auditor_fp_violation": 0.00848765432098766,
            "ave_precision_score": 0.5318343869450162,
            "fpr": 0.08771929824561403,
            "logloss": 0.7637258823589111,
            "mae": 0.5050852038619811,
            "precision": 0.553072625698324,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5997715083439774,
            "auditor_fn_violation": 0.0073133339817606745,
            "auditor_fp_violation": 0.003011753121648205,
            "ave_precision_score": 0.532486115636761,
            "fpr": 0.0801317233809001,
            "logloss": 0.7554052070021476,
            "mae": 0.5008923624663661,
            "precision": 0.5780346820809249,
            "recall": 0.2109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6844993729898048,
            "auditor_fn_violation": 0.01169133771929825,
            "auditor_fp_violation": 0.01864035087719299,
            "ave_precision_score": 0.6627333589412631,
            "fpr": 0.18421052631578946,
            "logloss": 0.630741339211235,
            "mae": 0.4295004412139717,
            "precision": 0.6781609195402298,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6880944146704094,
            "auditor_fn_violation": 0.01108810737956621,
            "auditor_fp_violation": 0.01956006802191371,
            "ave_precision_score": 0.660352530259676,
            "fpr": 0.15477497255762898,
            "logloss": 0.6296410869061864,
            "mae": 0.4299781761499189,
            "precision": 0.7006369426751592,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8503613857417094,
            "auditor_fn_violation": 0.024444901315789476,
            "auditor_fp_violation": 0.007721125730994152,
            "ave_precision_score": 0.8505959927636257,
            "fpr": 0.06469298245614036,
            "logloss": 0.530811219583277,
            "mae": 0.33186572124638286,
            "precision": 0.8447368421052631,
            "recall": 0.66875
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8538594511065767,
            "auditor_fn_violation": 0.013691079955721679,
            "auditor_fp_violation": 0.00981645637981749,
            "ave_precision_score": 0.8542892132654505,
            "fpr": 0.06476399560922064,
            "logloss": 0.5187097578820533,
            "mae": 0.3287408049300141,
            "precision": 0.8405405405405405,
            "recall": 0.6561181434599156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.805058177552411,
            "auditor_fn_violation": 0.019426169590643277,
            "auditor_fp_violation": 0.008964831059129305,
            "ave_precision_score": 0.8069819165083454,
            "fpr": 0.12390350877192982,
            "logloss": 0.5375410223014847,
            "mae": 0.3618852832893792,
            "precision": 0.7631027253668763,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.843568823964169,
            "auditor_fn_violation": 0.009304932216185675,
            "auditor_fp_violation": 0.02195389681668496,
            "ave_precision_score": 0.8328985657086844,
            "fpr": 0.10098792535675083,
            "logloss": 0.5150023900271713,
            "mae": 0.35198371770712994,
            "precision": 0.7946428571428571,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8426379752455884,
            "auditor_fn_violation": 0.01871573464912281,
            "auditor_fp_violation": 0.007939408706952573,
            "ave_precision_score": 0.8429236771339333,
            "fpr": 0.0668859649122807,
            "logloss": 1.4503585018751313,
            "mae": 0.33902306042811553,
            "precision": 0.8351351351351352,
            "recall": 0.64375
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8415403618811355,
            "auditor_fn_violation": 0.011004738151148412,
            "auditor_fp_violation": 0.010170632518393298,
            "ave_precision_score": 0.8420030670880501,
            "fpr": 0.07025246981339188,
            "logloss": 1.326897946026455,
            "mae": 0.3358023987609732,
            "precision": 0.8306878306878307,
            "recall": 0.6624472573839663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.756384854180044,
            "auditor_fn_violation": 0.007211714181286552,
            "auditor_fp_violation": 0.020457683560753736,
            "ave_precision_score": 0.6153158197397294,
            "fpr": 0.34649122807017546,
            "logloss": 0.6552790429761937,
            "mae": 0.4565579749709159,
            "precision": 0.5836627140974967,
            "recall": 0.9229166666666667
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7541510873425002,
            "auditor_fn_violation": 0.008760716419569537,
            "auditor_fp_violation": 0.011645110485372038,
            "ave_precision_score": 0.6155119131700109,
            "fpr": 0.3336992316136114,
            "logloss": 0.6517902340760826,
            "mae": 0.45458133870369777,
            "precision": 0.587516960651289,
            "recall": 0.9135021097046413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8578153937942408,
            "auditor_fn_violation": 0.015143000730994153,
            "auditor_fp_violation": 0.01388127436647174,
            "ave_precision_score": 0.858021252738961,
            "fpr": 0.20285087719298245,
            "logloss": 0.5332387265342414,
            "mae": 0.33230718557943445,
            "precision": 0.6937086092715232,
            "recall": 0.8729166666666667
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.850632839532647,
            "auditor_fn_violation": 0.009337353582792593,
            "auditor_fp_violation": 0.01962286520960446,
            "ave_precision_score": 0.8509374070986954,
            "fpr": 0.2052689352360044,
            "logloss": 0.5325444348308875,
            "mae": 0.3321636801730723,
            "precision": 0.6903973509933775,
            "recall": 0.879746835443038
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.549008588972671,
            "auditor_fn_violation": 0.013370339912280711,
            "auditor_fp_violation": 0.014863547758284601,
            "ave_precision_score": 0.5504676526022241,
            "fpr": 0.06578947368421052,
            "logloss": 1.2889227443711226,
            "mae": 0.5003712617039252,
            "precision": 0.574468085106383,
            "recall": 0.16875
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5702945882945115,
            "auditor_fn_violation": 0.02220632031383883,
            "auditor_fp_violation": 0.01844227808101842,
            "ave_precision_score": 0.5723761745189526,
            "fpr": 0.05817782656421515,
            "logloss": 1.2548475330663351,
            "mae": 0.4865163633526453,
            "precision": 0.6159420289855072,
            "recall": 0.17932489451476794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8603684792874076,
            "auditor_fn_violation": 0.01193804824561404,
            "auditor_fp_violation": 0.010777087394411956,
            "ave_precision_score": 0.8605779212000702,
            "fpr": 0.08114035087719298,
            "logloss": 0.5529229871068267,
            "mae": 0.30960787371293513,
            "precision": 0.8238095238095238,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8727510712935999,
            "auditor_fn_violation": 0.013744343629433045,
            "auditor_fp_violation": 0.011120125996277383,
            "ave_precision_score": 0.8731277708298311,
            "fpr": 0.07354555433589462,
            "logloss": 0.5125411768006514,
            "mae": 0.2961729299589605,
            "precision": 0.8357843137254902,
            "recall": 0.7194092827004219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.861934586861683,
            "auditor_fn_violation": 0.0007401315789473701,
            "auditor_fp_violation": 0.005657590155945421,
            "ave_precision_score": 0.8621260992128391,
            "fpr": 0.08223684210526316,
            "logloss": 0.4928335484251366,
            "mae": 0.3225289659345882,
            "precision": 0.8201438848920863,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8621406747122491,
            "auditor_fn_violation": 0.004247199025506353,
            "auditor_fp_violation": 0.012695079463561305,
            "ave_precision_score": 0.8624229934014295,
            "fpr": 0.08342480790340286,
            "logloss": 0.48562594791611435,
            "mae": 0.32259762242976187,
            "precision": 0.819047619047619,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8048854693258095,
            "auditor_fn_violation": 0.006716008771929834,
            "auditor_fp_violation": 0.010530884502923976,
            "ave_precision_score": 0.804202110724686,
            "fpr": 0.0581140350877193,
            "logloss": 0.7180875707436915,
            "mae": 0.35928272436732395,
            "precision": 0.8359133126934984,
            "recall": 0.5625
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8016094692605931,
            "auditor_fn_violation": 0.009379038197001489,
            "auditor_fp_violation": 0.0058351146802241615,
            "ave_precision_score": 0.7997387823737054,
            "fpr": 0.050493962678375415,
            "logloss": 0.7106033567515284,
            "mae": 0.361032996839628,
            "precision": 0.8424657534246576,
            "recall": 0.5189873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7947384158656434,
            "auditor_fn_violation": 0.009767909356725144,
            "auditor_fp_violation": 0.0023300438596491253,
            "ave_precision_score": 0.7713349597089302,
            "fpr": 0.08881578947368421,
            "logloss": 0.5466523574719182,
            "mae": 0.3673110715718123,
            "precision": 0.810304449648712,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7891693764693449,
            "auditor_fn_violation": 0.011597585997674928,
            "auditor_fp_violation": 0.013157266764965198,
            "ave_precision_score": 0.7577696498441968,
            "fpr": 0.09879253567508232,
            "logloss": 0.5510108019770324,
            "mae": 0.36980281470897564,
            "precision": 0.792147806004619,
            "recall": 0.7236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.702327117005869,
            "auditor_fn_violation": 0.011033442982456143,
            "auditor_fp_violation": 0.04160321231319039,
            "ave_precision_score": 0.6600658987951578,
            "fpr": 0.09758771929824561,
            "logloss": 0.7259355804050662,
            "mae": 0.44678837253728454,
            "precision": 0.6727941176470589,
            "recall": 0.38125
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7027318870601396,
            "auditor_fn_violation": 0.009920938181717132,
            "auditor_fp_violation": 0.037919453815180346,
            "ave_precision_score": 0.6589654535416288,
            "fpr": 0.09110867178924259,
            "logloss": 0.7213645454561387,
            "mae": 0.44369325146455274,
            "precision": 0.683206106870229,
            "recall": 0.37763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 28699,
        "test": {
            "accuracy": 0.36293859649122806,
            "auc_prc": 0.5329060128157272,
            "auditor_fn_violation": 0.016321728801169586,
            "auditor_fp_violation": 0.021696312540610805,
            "ave_precision_score": 0.4774452013603749,
            "fpr": 0.28728070175438597,
            "logloss": 0.718950042796348,
            "mae": 0.5110323238268233,
            "precision": 0.3806146572104019,
            "recall": 0.33541666666666664
        },
        "train": {
            "accuracy": 0.3545554335894621,
            "auc_prc": 0.5357360032832172,
            "auditor_fn_violation": 0.011903273168540162,
            "auditor_fp_violation": 0.01908029750795641,
            "ave_precision_score": 0.4676699518975662,
            "fpr": 0.3150384193194292,
            "logloss": 0.7207723190597966,
            "mae": 0.5118670055947372,
            "precision": 0.3760869565217391,
            "recall": 0.3649789029535865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7708296160045909,
            "auditor_fn_violation": 0.009799890350877194,
            "auditor_fp_violation": 0.03198860867446395,
            "ave_precision_score": 0.7713967523658379,
            "fpr": 0.3190789473684211,
            "logloss": 1.1021438236179248,
            "mae": 0.3768853397811191,
            "precision": 0.6072874493927125,
            "recall": 0.9375
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.753955831090035,
            "auditor_fn_violation": 0.008283659168067734,
            "auditor_fp_violation": 0.0314212008329419,
            "ave_precision_score": 0.7544957168412015,
            "fpr": 0.31174533479692645,
            "logloss": 1.0617057927805602,
            "mae": 0.3767375368808941,
            "precision": 0.609353507565337,
            "recall": 0.9345991561181435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.763157894736842,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5263157894736842,
            "fpr": 0.47368421052631576,
            "logloss": 0.6922436327371879,
            "mae": 0.4994316948087592,
            "precision": 0.5263157894736842,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7578432187794022,
            "auditor_fn_violation": 0.0015284358543261683,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5187324978944985,
            "fpr": 0.4796926454445664,
            "logloss": 0.6940152422854768,
            "mae": 0.5001807777143598,
            "precision": 0.5187224669603524,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.759843106059681,
            "auditor_fn_violation": 0.02276589912280702,
            "auditor_fp_violation": 0.004256518031189086,
            "ave_precision_score": 0.7336544769780955,
            "fpr": 0.09758771929824561,
            "logloss": 0.6500225894680529,
            "mae": 0.4061104419330756,
            "precision": 0.7920560747663551,
            "recall": 0.70625
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7867680714763352,
            "auditor_fn_violation": 0.012931493652359587,
            "auditor_fp_violation": 0.008914688764578372,
            "ave_precision_score": 0.745203729262103,
            "fpr": 0.09659714599341383,
            "logloss": 0.646330514509224,
            "mae": 0.4043089854239632,
            "precision": 0.7934272300469484,
            "recall": 0.7130801687763713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8354251283807322,
            "auditor_fn_violation": 0.007127192982456145,
            "auditor_fp_violation": 0.00682261208576998,
            "ave_precision_score": 0.821423296809633,
            "fpr": 0.07017543859649122,
            "logloss": 0.5570797744415467,
            "mae": 0.3732590829471551,
            "precision": 0.8083832335329342,
            "recall": 0.5625
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8349169630072574,
            "auditor_fn_violation": 0.005669107532409795,
            "auditor_fp_violation": 0.010788556845270246,
            "ave_precision_score": 0.8266350152725533,
            "fpr": 0.06037321624588365,
            "logloss": 0.5419220643258337,
            "mae": 0.36663402400657324,
            "precision": 0.8291925465838509,
            "recall": 0.5632911392405063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8510961926132034,
            "auditor_fn_violation": 0.015899122807017548,
            "auditor_fp_violation": 0.02578277290448343,
            "ave_precision_score": 0.8512944891768394,
            "fpr": 0.13486842105263158,
            "logloss": 0.5148896067035494,
            "mae": 0.3148980057622682,
            "precision": 0.7515151515151515,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8486949541079762,
            "auditor_fn_violation": 0.015282042731361188,
            "auditor_fp_violation": 0.019077785620448776,
            "ave_precision_score": 0.8489409510362054,
            "fpr": 0.11086717892425905,
            "logloss": 0.5093770498029778,
            "mae": 0.31549451774922654,
            "precision": 0.7775330396475771,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7634382106886902,
            "auditor_fn_violation": 0.005633223684210531,
            "auditor_fp_violation": 0.005891102176738143,
            "ave_precision_score": 0.7533098308458819,
            "fpr": 0.06469298245614036,
            "logloss": 0.5625501660603645,
            "mae": 0.35418117730959986,
            "precision": 0.8383561643835616,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.784115407072994,
            "auditor_fn_violation": 0.007836707471272361,
            "auditor_fp_violation": 0.007015701808810197,
            "ave_precision_score": 0.7782639985714536,
            "fpr": 0.06256860592755215,
            "logloss": 0.5367696020844379,
            "mae": 0.34312789070161326,
            "precision": 0.8455284552845529,
            "recall": 0.6582278481012658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.704719092452539,
            "auditor_fn_violation": 0.013706140350877194,
            "auditor_fp_violation": 0.015051372644574413,
            "ave_precision_score": 0.5274733755209137,
            "fpr": 0.3530701754385965,
            "logloss": 0.7074309622568001,
            "mae": 0.49938259064628365,
            "precision": 0.5278592375366569,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6942003245796381,
            "auditor_fn_violation": 0.005032259259773891,
            "auditor_fp_violation": 0.005938102068037,
            "ave_precision_score": 0.5132670752402326,
            "fpr": 0.37102085620197583,
            "logloss": 0.713663157941631,
            "mae": 0.5026432475326613,
            "precision": 0.5108538350217077,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7677798524405891,
            "auditor_fn_violation": 0.012506853070175447,
            "auditor_fp_violation": 0.02167600714749838,
            "ave_precision_score": 0.7527251333815699,
            "fpr": 0.18201754385964913,
            "logloss": 2.4751569099845168,
            "mae": 0.3205928169705693,
            "precision": 0.6789168278529981,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.745701067127789,
            "auditor_fn_violation": 0.010661997989875271,
            "auditor_fp_violation": 0.01869095494427378,
            "ave_precision_score": 0.7252966549259989,
            "fpr": 0.1525795828759605,
            "logloss": 2.8946851361480133,
            "mae": 0.32506936113378065,
            "precision": 0.7029914529914529,
            "recall": 0.6940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8137202165775393,
            "auditor_fn_violation": 0.010498903508771938,
            "auditor_fp_violation": 0.0036042072774528896,
            "ave_precision_score": 0.7492510885621482,
            "fpr": 0.06798245614035088,
            "logloss": 0.5871197692790971,
            "mae": 0.3605321298206323,
            "precision": 0.8181818181818182,
            "recall": 0.58125
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7894930135657465,
            "auditor_fn_violation": 0.003997091340252984,
            "auditor_fp_violation": 0.0020371407686878198,
            "ave_precision_score": 0.7402373888641267,
            "fpr": 0.07135016465422613,
            "logloss": 0.5757468978131622,
            "mae": 0.3622154010752161,
            "precision": 0.8071216617210683,
            "recall": 0.5738396624472574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8222685167232173,
            "auditor_fn_violation": 0.005436769005847953,
            "auditor_fp_violation": 0.011754284437946724,
            "ave_precision_score": 0.8031580496080283,
            "fpr": 0.10416666666666667,
            "logloss": 0.5607358798663133,
            "mae": 0.37795292285859194,
            "precision": 0.7845804988662132,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8055933227796219,
            "auditor_fn_violation": 0.009198404868762947,
            "auditor_fp_violation": 0.009309055103276257,
            "ave_precision_score": 0.7882568569880937,
            "fpr": 0.10208562019758508,
            "logloss": 0.5565295007664655,
            "mae": 0.37221488411999365,
            "precision": 0.7881548974943052,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7720592860937447,
            "auditor_fn_violation": 0.009767909356725144,
            "auditor_fp_violation": 0.0023300438596491253,
            "ave_precision_score": 0.7631958383600449,
            "fpr": 0.08881578947368421,
            "logloss": 0.545969810610125,
            "mae": 0.365615545886389,
            "precision": 0.810304449648712,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7530360342271376,
            "auditor_fn_violation": 0.011597585997674928,
            "auditor_fp_violation": 0.013157266764965198,
            "ave_precision_score": 0.744725470466431,
            "fpr": 0.09879253567508232,
            "logloss": 0.5498160040221475,
            "mae": 0.36662919533108773,
            "precision": 0.792147806004619,
            "recall": 0.7236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8107612395207946,
            "auditor_fn_violation": 0.0042466191520467815,
            "auditor_fp_violation": 0.00712719298245614,
            "ave_precision_score": 0.7510442312444343,
            "fpr": 0.08881578947368421,
            "logloss": 0.5487590836622359,
            "mae": 0.377100666331356,
            "precision": 0.8107476635514018,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8026854450175069,
            "auditor_fn_violation": 0.009545776653837072,
            "auditor_fp_violation": 0.0104142856066334,
            "ave_precision_score": 0.7441858178803151,
            "fpr": 0.09330406147091108,
            "logloss": 0.5504251222442278,
            "mae": 0.37895064626776426,
            "precision": 0.8014018691588785,
            "recall": 0.7236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.614659600070643,
            "auditor_fn_violation": 0.08565423976608187,
            "auditor_fp_violation": 0.06046692251461989,
            "ave_precision_score": 0.615423659212992,
            "fpr": 0.17653508771929824,
            "logloss": 0.7273155033613196,
            "mae": 0.4713882713664421,
            "precision": 0.5903307888040712,
            "recall": 0.48333333333333334
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6065782047227023,
            "auditor_fn_violation": 0.08208163700111623,
            "auditor_fp_violation": 0.0575423190247848,
            "ave_precision_score": 0.6077723522583001,
            "fpr": 0.14928649835345773,
            "logloss": 0.7007217050549988,
            "mae": 0.46082825703356256,
            "precision": 0.6190476190476191,
            "recall": 0.46624472573839665
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8121273718581028,
            "auditor_fn_violation": 0.009297331871345033,
            "auditor_fp_violation": 0.004751461988304096,
            "ave_precision_score": 0.8053222433591993,
            "fpr": 0.07894736842105263,
            "logloss": 0.5213176623807506,
            "mae": 0.3153965549396449,
            "precision": 0.8230958230958231,
            "recall": 0.6979166666666666
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8610075430810694,
            "auditor_fn_violation": 0.00857313565562951,
            "auditor_fp_violation": 0.010014895492920244,
            "ave_precision_score": 0.8337016742685194,
            "fpr": 0.07025246981339188,
            "logloss": 0.4927170259272841,
            "mae": 0.3009587308283564,
            "precision": 0.8411910669975186,
            "recall": 0.7151898734177216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7749034363983326,
            "auditor_fn_violation": 0.009055190058479538,
            "auditor_fp_violation": 0.004721003898635481,
            "ave_precision_score": 0.7549354801504929,
            "fpr": 0.09210526315789473,
            "logloss": 0.5631883865004488,
            "mae": 0.3688209111753263,
            "precision": 0.8046511627906977,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7836066754504033,
            "auditor_fn_violation": 0.011039475329655827,
            "auditor_fp_violation": 0.007683863885839738,
            "ave_precision_score": 0.7583081420857911,
            "fpr": 0.10098792535675083,
            "logloss": 0.5598217202830913,
            "mae": 0.3663403857356238,
            "precision": 0.7894736842105263,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8353925814450454,
            "auditor_fn_violation": 0.006400767543859653,
            "auditor_fp_violation": 0.005314936647173489,
            "ave_precision_score": 0.8255212496442939,
            "fpr": 0.051535087719298246,
            "logloss": 0.5304737754365424,
            "mae": 0.3453608814610593,
            "precision": 0.8571428571428571,
            "recall": 0.5875
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8503417274063809,
            "auditor_fn_violation": 0.009675462120264747,
            "auditor_fp_violation": 0.005350320391251598,
            "ave_precision_score": 0.8422521203792912,
            "fpr": 0.04610318331503842,
            "logloss": 0.505941871345912,
            "mae": 0.33453139671738924,
            "precision": 0.8753709198813057,
            "recall": 0.6223628691983122
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.844693055159429,
            "auditor_fn_violation": 0.01673976608187135,
            "auditor_fp_violation": 0.020868867771280053,
            "ave_precision_score": 0.8449670921599898,
            "fpr": 0.13706140350877194,
            "logloss": 0.8059647285411046,
            "mae": 0.28659143412982013,
            "precision": 0.7504990019960079,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8498395288030809,
            "auditor_fn_violation": 0.01011315056945815,
            "auditor_fp_violation": 0.015603845197396679,
            "ave_precision_score": 0.8502418114167813,
            "fpr": 0.11086717892425905,
            "logloss": 0.713237982743452,
            "mae": 0.2791072029526357,
            "precision": 0.7755555555555556,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8473274364392629,
            "auditor_fn_violation": 0.007134046052631581,
            "auditor_fp_violation": 0.017919509421702406,
            "ave_precision_score": 0.8475118864515753,
            "fpr": 0.10416666666666667,
            "logloss": 0.660812791165654,
            "mae": 0.2757797022114146,
            "precision": 0.7970085470085471,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.82626758621008,
            "auditor_fn_violation": 0.013867081660159238,
            "auditor_fp_violation": 0.010120394768240705,
            "ave_precision_score": 0.826477085316621,
            "fpr": 0.08781558726673985,
            "logloss": 0.7772180741141254,
            "mae": 0.27980255217285854,
            "precision": 0.8113207547169812,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 28699,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5365889101431379,
            "auditor_fn_violation": 0.012780975877192987,
            "auditor_fp_violation": 0.015513320337881763,
            "ave_precision_score": 0.5412100675244138,
            "fpr": 0.3508771929824561,
            "logloss": 0.6916975432018981,
            "mae": 0.4914189540176538,
            "precision": 0.5524475524475524,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5680758864986922,
            "auditor_fn_violation": 0.006041953248389353,
            "auditor_fp_violation": 0.018427206755972658,
            "ave_precision_score": 0.5708417469970726,
            "fpr": 0.3424807903402854,
            "logloss": 0.6852147913937103,
            "mae": 0.4886235805753819,
            "precision": 0.5636363636363636,
            "recall": 0.8502109704641351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7858038251590067,
            "auditor_fn_violation": 0.006556103801169604,
            "auditor_fp_violation": 0.010551189896036397,
            "ave_precision_score": 0.7312423730313188,
            "fpr": 0.14364035087719298,
            "logloss": 0.6000625156276779,
            "mae": 0.40209504792041945,
            "precision": 0.722457627118644,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7687938314477888,
            "auditor_fn_violation": 0.009976517667328995,
            "auditor_fp_violation": 0.01361694217886147,
            "ave_precision_score": 0.7109915997020166,
            "fpr": 0.15477497255762898,
            "logloss": 0.6096534492245061,
            "mae": 0.406498919644942,
            "precision": 0.7080745341614907,
            "recall": 0.7215189873417721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 28699,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7978379741214645,
            "auditor_fn_violation": 0.015268640350877195,
            "auditor_fp_violation": 0.007919103313840159,
            "ave_precision_score": 0.7949316048046469,
            "fpr": 0.07017543859649122,
            "logloss": 0.5964196412262663,
            "mae": 0.34626570962644654,
            "precision": 0.8341968911917098,
            "recall": 0.6708333333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8018317508137545,
            "auditor_fn_violation": 0.00666953827342328,
            "auditor_fp_violation": 0.010891544233083071,
            "ave_precision_score": 0.7981378711306256,
            "fpr": 0.06805708013172337,
            "logloss": 0.572135361390359,
            "mae": 0.3365528824001563,
            "precision": 0.8385416666666666,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.81724959381625,
            "auditor_fn_violation": 0.02366593567251462,
            "auditor_fp_violation": 0.02960526315789474,
            "ave_precision_score": 0.7960267754343404,
            "fpr": 0.17763157894736842,
            "logloss": 0.5574877104695475,
            "mae": 0.36776132881845625,
            "precision": 0.7075812274368231,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.804102910907811,
            "auditor_fn_violation": 0.015024987610406333,
            "auditor_fp_violation": 0.019811256772676693,
            "ave_precision_score": 0.7802023752578344,
            "fpr": 0.18331503841931943,
            "logloss": 0.5660640006004791,
            "mae": 0.3767431226444485,
            "precision": 0.697463768115942,
            "recall": 0.8122362869198312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.740654363257978,
            "auditor_fn_violation": 0.020812774122807028,
            "auditor_fp_violation": 0.00872116634178038,
            "ave_precision_score": 0.7412766900673206,
            "fpr": 0.12719298245614036,
            "logloss": 0.6383640646438989,
            "mae": 0.46413090011399044,
            "precision": 0.7135802469135802,
            "recall": 0.6020833333333333
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7463359928947852,
            "auditor_fn_violation": 0.020230932762717285,
            "auditor_fp_violation": 0.008017944924354509,
            "ave_precision_score": 0.7477684528518508,
            "fpr": 0.12294182217343579,
            "logloss": 0.636461008131522,
            "mae": 0.46071988355642357,
            "precision": 0.7268292682926829,
            "recall": 0.6286919831223629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.689396903702631,
            "auditor_fn_violation": 0.008406432748538011,
            "auditor_fp_violation": 0.00693429174788824,
            "ave_precision_score": 0.7279766161255877,
            "fpr": 0.22587719298245615,
            "logloss": 0.617400134513592,
            "mae": 0.37971840910368454,
            "precision": 0.652027027027027,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6992590925594526,
            "auditor_fn_violation": 0.00746849337909378,
            "auditor_fp_violation": 0.019771066572554622,
            "ave_precision_score": 0.7145838658720005,
            "fpr": 0.2030735455543359,
            "logloss": 0.6252428206121855,
            "mae": 0.38827353760469235,
            "precision": 0.6611721611721612,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7878202859070856,
            "auditor_fn_violation": 0.0049342105263157935,
            "auditor_fp_violation": 0.01397011046133854,
            "ave_precision_score": 0.787990877825768,
            "fpr": 0.19188596491228072,
            "logloss": 0.9521288066729068,
            "mae": 0.3209724717920548,
            "precision": 0.6956521739130435,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.770373755865152,
            "auditor_fn_violation": 0.016775741407179943,
            "auditor_fp_violation": 0.015970580773510646,
            "ave_precision_score": 0.7705184736432444,
            "fpr": 0.1756311745334797,
            "logloss": 0.9646176730820134,
            "mae": 0.3263267654062757,
            "precision": 0.708029197080292,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8507383623827076,
            "auditor_fn_violation": 0.0051580774853801185,
            "auditor_fp_violation": 0.005901254873294349,
            "ave_precision_score": 0.7944281479693719,
            "fpr": 0.09100877192982457,
            "logloss": 0.5264733600217761,
            "mae": 0.3470836155639406,
            "precision": 0.8065268065268065,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8328146597080198,
            "auditor_fn_violation": 0.0097356732296776,
            "auditor_fp_violation": 0.01106737635861716,
            "ave_precision_score": 0.7694466586578906,
            "fpr": 0.09440175631174534,
            "logloss": 0.5323050505994512,
            "mae": 0.34914286627662167,
            "precision": 0.8009259259259259,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7860349862405865,
            "auditor_fn_violation": 0.008927266081871348,
            "auditor_fp_violation": 0.00712719298245614,
            "ave_precision_score": 0.7698548737275861,
            "fpr": 0.08881578947368421,
            "logloss": 0.5398442664261079,
            "mae": 0.35123974233538957,
            "precision": 0.8116279069767441,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.806888156218195,
            "auditor_fn_violation": 0.009205352304464424,
            "auditor_fp_violation": 0.00909805655263535,
            "ave_precision_score": 0.7898275945870152,
            "fpr": 0.09220636663007684,
            "logloss": 0.5245558629570182,
            "mae": 0.34349344033670215,
            "precision": 0.8068965517241379,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8111613454490824,
            "auditor_fn_violation": 0.012438322368421052,
            "auditor_fp_violation": 0.02512792397660819,
            "ave_precision_score": 0.7957945453792038,
            "fpr": 0.18201754385964913,
            "logloss": 1.4325643651394886,
            "mae": 0.30675713077608524,
            "precision": 0.7009009009009008,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8033788614063048,
            "auditor_fn_violation": 0.011129791993775099,
            "auditor_fp_violation": 0.01789719849186274,
            "ave_precision_score": 0.7895874749555943,
            "fpr": 0.145993413830955,
            "logloss": 1.3517455781650463,
            "mae": 0.3051691404076111,
            "precision": 0.7350597609561753,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7687787726765393,
            "auditor_fn_violation": 0.03267543859649123,
            "auditor_fp_violation": 0.038646239441195586,
            "ave_precision_score": 0.7536764165013599,
            "fpr": 0.30043859649122806,
            "logloss": 0.6045248843984539,
            "mae": 0.40101056584369454,
            "precision": 0.6,
            "recall": 0.85625
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7753160307091468,
            "auditor_fn_violation": 0.033630220418976696,
            "auditor_fp_violation": 0.027472513670947767,
            "ave_precision_score": 0.7545392941751506,
            "fpr": 0.29747530186608123,
            "logloss": 0.61276929735883,
            "mae": 0.40814495140852247,
            "precision": 0.594311377245509,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8385238743399424,
            "auditor_fn_violation": 0.0061266447368421096,
            "auditor_fp_violation": 0.014985380116959074,
            "ave_precision_score": 0.8387603711114335,
            "fpr": 0.14912280701754385,
            "logloss": 0.6532276157807264,
            "mae": 0.2735993019607089,
            "precision": 0.7394636015325671,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8218656357793791,
            "auditor_fn_violation": 0.009953359548324051,
            "auditor_fp_violation": 0.005822555242686013,
            "ave_precision_score": 0.8227534761873541,
            "fpr": 0.1251372118551043,
            "logloss": 0.6543037086290743,
            "mae": 0.2736200860903395,
            "precision": 0.7615062761506276,
            "recall": 0.7679324894514767
        }
    }
]