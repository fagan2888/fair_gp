[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8495241899738453,
            "auditor_fn_violation": 0.01976980276342158,
            "auditor_fp_violation": 0.009480799456267792,
            "ave_precision_score": 0.8491841834531378,
            "fpr": 0.12719298245614036,
            "logloss": 1.0881644860411772,
            "mae": 0.2549372223689348,
            "precision": 0.7777777777777778,
            "recall": 0.8136272545090181
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8090251810358111,
            "auditor_fn_violation": 0.011830979119672862,
            "auditor_fp_violation": 0.021340054307007927,
            "ave_precision_score": 0.8083919560302657,
            "fpr": 0.15697036223929747,
            "logloss": 0.9190010144419539,
            "mae": 0.2777266193897544,
            "precision": 0.7168316831683168,
            "recall": 0.7956043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.843693832962496,
            "auditor_fn_violation": 0.02731999085891081,
            "auditor_fp_violation": 0.01617656429208615,
            "ave_precision_score": 0.843294264248897,
            "fpr": 0.11074561403508772,
            "logloss": 1.1330375128354204,
            "mae": 0.24884988389912543,
            "precision": 0.795959595959596,
            "recall": 0.7895791583166333
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8049960815148011,
            "auditor_fn_violation": 0.021227729460440773,
            "auditor_fp_violation": 0.021361719336761228,
            "ave_precision_score": 0.8047429707986961,
            "fpr": 0.14270032930845225,
            "logloss": 0.9405214474798315,
            "mae": 0.2727644130922013,
            "precision": 0.7308488612836439,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7960526315789473,
            "auc_prc": 0.8540890515521025,
            "auditor_fn_violation": 0.024078859473332638,
            "auditor_fp_violation": 0.014174737691686845,
            "ave_precision_score": 0.8534496192741102,
            "fpr": 0.09320175438596491,
            "logloss": 1.0819217904509753,
            "mae": 0.2620438258980041,
            "precision": 0.8240165631469979,
            "recall": 0.7975951903807615
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8011879021638626,
            "auditor_fn_violation": 0.017949120034740234,
            "auditor_fp_violation": 0.016725402969553417,
            "ave_precision_score": 0.8002761588963021,
            "fpr": 0.12952799121844127,
            "logloss": 0.8981313758325228,
            "mae": 0.2909957859265067,
            "precision": 0.7526205450733753,
            "recall": 0.789010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8366140380423406,
            "auditor_fn_violation": 0.02558626023977781,
            "auditor_fp_violation": 0.017812008835648444,
            "ave_precision_score": 0.8368592278354642,
            "fpr": 0.10307017543859649,
            "logloss": 1.5294981265503023,
            "mae": 0.25778939147163693,
            "precision": 0.8037578288100209,
            "recall": 0.7715430861723447
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8134118352659796,
            "auditor_fn_violation": 0.02170299513877999,
            "auditor_fp_violation": 0.02388930614131377,
            "ave_precision_score": 0.8138106603183197,
            "fpr": 0.132821075740944,
            "logloss": 1.0759584657223165,
            "mae": 0.26574467883077435,
            "precision": 0.7494824016563147,
            "recall": 0.7956043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8526347528973319,
            "auditor_fn_violation": 0.01796355869634006,
            "auditor_fp_violation": 0.0085940486810246,
            "ave_precision_score": 0.8528362994635963,
            "fpr": 0.10307017543859649,
            "logloss": 0.8377718862281496,
            "mae": 0.27667079573839953,
            "precision": 0.7868480725623582,
            "recall": 0.6953907815631263
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8095398069885685,
            "auditor_fn_violation": 0.011871991893945798,
            "auditor_fp_violation": 0.019816280547691953,
            "ave_precision_score": 0.8109319356302644,
            "fpr": 0.11525795828759605,
            "logloss": 0.8381567929812295,
            "mae": 0.282802667425299,
            "precision": 0.7540983606557377,
            "recall": 0.7076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.702626845043012,
            "auditor_fn_violation": 0.011738389058819392,
            "auditor_fp_violation": 0.013736672188946948,
            "ave_precision_score": 0.6641103259038021,
            "fpr": 0.17434210526315788,
            "logloss": 5.234610941614653,
            "mae": 0.38438545177315103,
            "precision": 0.6794354838709677,
            "recall": 0.6753507014028056
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6404598849563838,
            "auditor_fn_violation": 0.009401575373035306,
            "auditor_fp_violation": 0.02132801817936719,
            "ave_precision_score": 0.5862094430915448,
            "fpr": 0.2414928649835346,
            "logloss": 5.674773932542544,
            "mae": 0.4120776268400173,
            "precision": 0.5910780669144982,
            "recall": 0.6989010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8447535155696191,
            "auditor_fn_violation": 0.017245016348486453,
            "auditor_fp_violation": 0.010099401044985343,
            "ave_precision_score": 0.8448427458905884,
            "fpr": 0.09868421052631579,
            "logloss": 1.1525607474376445,
            "mae": 0.2795198385676384,
            "precision": 0.7940503432494279,
            "recall": 0.6953907815631263
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.78964405439397,
            "auditor_fn_violation": 0.01669461164521538,
            "auditor_fp_violation": 0.01686983650124213,
            "ave_precision_score": 0.7900550308331227,
            "fpr": 0.12733260153677278,
            "logloss": 1.0985531712279692,
            "mae": 0.29767535039347964,
            "precision": 0.7276995305164319,
            "recall": 0.6813186813186813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8020443157557351,
            "auditor_fn_violation": 0.020365291987483745,
            "auditor_fp_violation": 0.034007157724820526,
            "ave_precision_score": 0.8023916715560743,
            "fpr": 0.14473684210526316,
            "logloss": 1.3533191090940813,
            "mae": 0.28553257999976384,
            "precision": 0.7436893203883496,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7388726417889583,
            "auditor_fn_violation": 0.020991302879338012,
            "auditor_fp_violation": 0.0377765902131839,
            "ave_precision_score": 0.739282671874919,
            "fpr": 0.17453347969264543,
            "logloss": 1.249454336827095,
            "mae": 0.3094340474740989,
            "precision": 0.6832669322709163,
            "recall": 0.7538461538461538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8230964559803813,
            "auditor_fn_violation": 0.020846517596596705,
            "auditor_fp_violation": 0.017076589779533576,
            "ave_precision_score": 0.8233604390563087,
            "fpr": 0.11074561403508772,
            "logloss": 1.1462036932890591,
            "mae": 0.2961552330631914,
            "precision": 0.7926078028747433,
            "recall": 0.7735470941883767
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.749531459804395,
            "auditor_fn_violation": 0.019413517327897135,
            "auditor_fp_violation": 0.02615450536329848,
            "ave_precision_score": 0.7503066649328103,
            "fpr": 0.15916575192096596,
            "logloss": 1.0630046337689827,
            "mae": 0.32387751326652237,
            "precision": 0.7064777327935222,
            "recall": 0.7670329670329671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8198895751086186,
            "auditor_fn_violation": 0.014331294167281934,
            "auditor_fp_violation": 0.01053746654772525,
            "ave_precision_score": 0.8083604044709753,
            "fpr": 0.12828947368421054,
            "logloss": 1.899353215569846,
            "mae": 0.2838439189906193,
            "precision": 0.7678571428571429,
            "recall": 0.7755511022044088
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7916562728416578,
            "auditor_fn_violation": 0.013736866865297164,
            "auditor_fp_violation": 0.018810060276927228,
            "ave_precision_score": 0.7806866537840603,
            "fpr": 0.1437980241492865,
            "logloss": 1.6698729929755254,
            "mae": 0.3057914314792961,
            "precision": 0.720682302771855,
            "recall": 0.7428571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8388786734961515,
            "auditor_fn_violation": 0.017387845867172944,
            "auditor_fp_violation": 0.012449025105135724,
            "ave_precision_score": 0.8382939422779507,
            "fpr": 0.12390350877192982,
            "logloss": 1.136350269240456,
            "mae": 0.25728288055913795,
            "precision": 0.7749003984063745,
            "recall": 0.779559118236473
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7752896033784787,
            "auditor_fn_violation": 0.011859929313277283,
            "auditor_fp_violation": 0.02345600554624763,
            "ave_precision_score": 0.7758924291135942,
            "fpr": 0.15806805708013172,
            "logloss": 1.081458553789735,
            "mae": 0.28869649227940253,
            "precision": 0.7079107505070994,
            "recall": 0.7670329670329671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.820465669033525,
            "auditor_fn_violation": 0.026608040642688888,
            "auditor_fp_violation": 0.01676330657151353,
            "ave_precision_score": 0.8218396474328851,
            "fpr": 0.08442982456140351,
            "logloss": 1.2789882668148354,
            "mae": 0.3170844279014778,
            "precision": 0.80306905370844,
            "recall": 0.6292585170340681
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7725992400621999,
            "auditor_fn_violation": 0.019794694877021995,
            "auditor_fp_violation": 0.018718585706857707,
            "ave_precision_score": 0.7730977447235182,
            "fpr": 0.10537870472008781,
            "logloss": 1.385061624547244,
            "mae": 0.3373059110866527,
            "precision": 0.7340720221606648,
            "recall": 0.5824175824175825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8234797157691824,
            "auditor_fn_violation": 0.015342087684140212,
            "auditor_fp_violation": 0.020153668068476276,
            "ave_precision_score": 0.8226138251296033,
            "fpr": 0.20285087719298245,
            "logloss": 1.4038647847704664,
            "mae": 0.29022511621723796,
            "precision": 0.6962233169129721,
            "recall": 0.8496993987975952
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7875324282128047,
            "auditor_fn_violation": 0.008619920145715975,
            "auditor_fp_violation": 0.027716794731064764,
            "ave_precision_score": 0.7857817175394326,
            "fpr": 0.22941822173435786,
            "logloss": 1.3044208361655063,
            "mae": 0.30966351393092484,
            "precision": 0.6516666666666666,
            "recall": 0.8593406593406593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 4866,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8364523337023867,
            "auditor_fn_violation": 0.032888144710473584,
            "auditor_fp_violation": 0.016811095535448795,
            "ave_precision_score": 0.8355587564204157,
            "fpr": 0.11842105263157894,
            "logloss": 1.300001601420096,
            "mae": 0.2631342587718743,
            "precision": 0.7809330628803245,
            "recall": 0.7715430861723447
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7971389380880723,
            "auditor_fn_violation": 0.021360417847794362,
            "auditor_fp_violation": 0.02556714233443103,
            "ave_precision_score": 0.7953857888253238,
            "fpr": 0.145993413830955,
            "logloss": 1.092341104284949,
            "mae": 0.2810694820590581,
            "precision": 0.7263374485596708,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8490286197441149,
            "auditor_fn_violation": 0.014061016770382871,
            "auditor_fp_violation": 0.009695849793976473,
            "ave_precision_score": 0.8486745734241673,
            "fpr": 0.17763157894736842,
            "logloss": 1.0645407870013226,
            "mae": 0.2793601533675128,
            "precision": 0.7263513513513513,
            "recall": 0.8617234468937875
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8011915601668886,
            "auditor_fn_violation": 0.00837866853234581,
            "auditor_fp_violation": 0.016176555549136287,
            "ave_precision_score": 0.8009113015231349,
            "fpr": 0.21734357848518113,
            "logloss": 0.9376850821984597,
            "mae": 0.31173867355693513,
            "precision": 0.6655405405405406,
            "recall": 0.865934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8440391826312275,
            "auditor_fn_violation": 0.013030446858629547,
            "auditor_fp_violation": 0.013872074253430192,
            "ave_precision_score": 0.8421753865319257,
            "fpr": 0.15021929824561403,
            "logloss": 1.1515046718661948,
            "mae": 0.28506048349881763,
            "precision": 0.7553571428571428,
            "recall": 0.8476953907815631
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7942294523570517,
            "auditor_fn_violation": 0.005404036139491685,
            "auditor_fp_violation": 0.024633138829510667,
            "ave_precision_score": 0.7915930063336553,
            "fpr": 0.1942919868276619,
            "logloss": 1.0327123707711474,
            "mae": 0.3130518061176449,
            "precision": 0.6905594405594405,
            "recall": 0.8681318681318682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8294675621118883,
            "auditor_fn_violation": 0.022934025946630108,
            "auditor_fp_violation": 0.013511002081474875,
            "ave_precision_score": 0.8235865738294323,
            "fpr": 0.12171052631578948,
            "logloss": 1.6265101674619469,
            "mae": 0.26305111668534137,
            "precision": 0.7827788649706457,
            "recall": 0.8016032064128257
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7916540050112331,
            "auditor_fn_violation": 0.011150649569968996,
            "auditor_fp_violation": 0.022059814739923363,
            "ave_precision_score": 0.7844852294131182,
            "fpr": 0.150384193194292,
            "logloss": 1.511939017452775,
            "mae": 0.29243960292827553,
            "precision": 0.7209775967413442,
            "recall": 0.778021978021978
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7408646193904812,
            "auditor_fn_violation": 0.017535070140280558,
            "auditor_fp_violation": 0.006358587145830689,
            "ave_precision_score": 0.7257524413685162,
            "fpr": 0.18201754385964913,
            "logloss": 2.928226484248714,
            "mae": 0.30693368543666577,
            "precision": 0.710801393728223,
            "recall": 0.8176352705410822
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.700980343529011,
            "auditor_fn_violation": 0.016368921967165655,
            "auditor_fp_violation": 0.00983592350800162,
            "ave_precision_score": 0.686047936561319,
            "fpr": 0.21295279912184412,
            "logloss": 2.685404169696109,
            "mae": 0.3413857377020906,
            "precision": 0.6529516994633273,
            "recall": 0.8021978021978022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.799354519837145,
            "auditor_fn_violation": 0.02333175122174173,
            "auditor_fp_violation": 0.01543583535108959,
            "ave_precision_score": 0.7998350560148155,
            "fpr": 0.09539473684210527,
            "logloss": 1.3724510798703566,
            "mae": 0.3076001153741755,
            "precision": 0.7948113207547169,
            "recall": 0.6753507014028056
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.721500011702314,
            "auditor_fn_violation": 0.014851449319067326,
            "auditor_fp_violation": 0.02089471758430104,
            "ave_precision_score": 0.7220071720344282,
            "fpr": 0.1207464324917673,
            "logloss": 1.346230537939682,
            "mae": 0.3421019401063015,
            "precision": 0.7150259067357513,
            "recall": 0.6065934065934065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8357133902408345,
            "auditor_fn_violation": 0.008695021622191752,
            "auditor_fp_violation": 0.024112187247780466,
            "ave_precision_score": 0.8322502890355692,
            "fpr": 0.2949561403508772,
            "logloss": 1.3811372479557842,
            "mae": 0.319407859944077,
            "precision": 0.6310013717421125,
            "recall": 0.9218436873747495
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7922331782224372,
            "auditor_fn_violation": 0.008342480790340286,
            "auditor_fp_violation": 0.02393745065187668,
            "ave_precision_score": 0.7894601100228451,
            "fpr": 0.3205268935236004,
            "logloss": 1.2663272585425478,
            "mae": 0.3480493636292037,
            "precision": 0.5921787709497207,
            "recall": 0.9318681318681319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7664575142149752,
            "auditor_fn_violation": 0.01250747108251591,
            "auditor_fp_violation": 0.011129518712034329,
            "ave_precision_score": 0.7631646295333138,
            "fpr": 0.13596491228070176,
            "logloss": 1.3416355754543043,
            "mae": 0.2840907220645511,
            "precision": 0.75,
            "recall": 0.7454909819639278
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7428292826392806,
            "auditor_fn_violation": 0.01576579293374025,
            "auditor_fp_violation": 0.018935236004390784,
            "ave_precision_score": 0.7431774807322056,
            "fpr": 0.13830954994511527,
            "logloss": 1.1960180629097508,
            "mae": 0.2909511024746382,
            "precision": 0.7236842105263158,
            "recall": 0.7252747252747253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8529026448696778,
            "auditor_fn_violation": 0.023375698765952958,
            "auditor_fp_violation": 0.01788103733911049,
            "ave_precision_score": 0.8525856853566113,
            "fpr": 0.11074561403508772,
            "logloss": 1.2435918298740667,
            "mae": 0.24719443478736594,
            "precision": 0.7963709677419355,
            "recall": 0.7915831663326653
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.809223454082224,
            "auditor_fn_violation": 0.01524710196499439,
            "auditor_fp_violation": 0.023441562193078743,
            "ave_precision_score": 0.8090442830694837,
            "fpr": 0.141602634467618,
            "logloss": 1.0009114586499817,
            "mae": 0.2709423541443322,
            "precision": 0.7351129363449692,
            "recall": 0.7868131868131868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7058494650675129,
            "auditor_fn_violation": 0.011468111661920336,
            "auditor_fp_violation": 0.01651108703963298,
            "ave_precision_score": 0.6723768200263261,
            "fpr": 0.1699561403508772,
            "logloss": 4.442933203818352,
            "mae": 0.37809812419266225,
            "precision": 0.6849593495934959,
            "recall": 0.6753507014028056
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6444790610200778,
            "auditor_fn_violation": 0.011203724924910443,
            "auditor_fp_violation": 0.020430123057369007,
            "ave_precision_score": 0.6035493067396998,
            "fpr": 0.23380900109769484,
            "logloss": 4.517761341439866,
            "mae": 0.40586520221004224,
            "precision": 0.5973534971644613,
            "recall": 0.6945054945054945
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8309900369673683,
            "auditor_fn_violation": 0.012531642231832082,
            "auditor_fp_violation": 0.007778981351684303,
            "ave_precision_score": 0.8309970778411636,
            "fpr": 0.12609649122807018,
            "logloss": 1.1660608701528425,
            "mae": 0.2729651884493418,
            "precision": 0.7775628626692457,
            "recall": 0.8056112224448898
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7893846978778745,
            "auditor_fn_violation": 0.009073473178851885,
            "auditor_fp_violation": 0.012247963487203197,
            "ave_precision_score": 0.7887922361164286,
            "fpr": 0.16245883644346873,
            "logloss": 1.0611394523102382,
            "mae": 0.30333707774774704,
            "precision": 0.7051792828685259,
            "recall": 0.778021978021978
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8486168647099211,
            "auditor_fn_violation": 0.018631561368350737,
            "auditor_fp_violation": 0.0034885943672741198,
            "ave_precision_score": 0.8486978044709299,
            "fpr": 0.09539473684210527,
            "logloss": 1.121699702108378,
            "mae": 0.2531378045949779,
            "precision": 0.8133047210300429,
            "recall": 0.7595190380761523
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7902937955961127,
            "auditor_fn_violation": 0.009650064534806579,
            "auditor_fp_violation": 0.024524813680744124,
            "ave_precision_score": 0.7909013033410175,
            "fpr": 0.1350164654226125,
            "logloss": 1.025240480272555,
            "mae": 0.28335762919968766,
            "precision": 0.7314410480349345,
            "recall": 0.7362637362637363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8399542675446672,
            "auditor_fn_violation": 0.028820799493724295,
            "auditor_fp_violation": 0.024438745168004764,
            "ave_precision_score": 0.840170058148252,
            "fpr": 0.12280701754385964,
            "logloss": 1.1119412444421013,
            "mae": 0.2617546935715623,
            "precision": 0.7837837837837838,
            "recall": 0.8136272545090181
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7908474409939271,
            "auditor_fn_violation": 0.020279610619896023,
            "auditor_fp_violation": 0.02806584243264583,
            "ave_precision_score": 0.7907656945785339,
            "fpr": 0.16355653128430298,
            "logloss": 1.0388807089536143,
            "mae": 0.2878049610660094,
            "precision": 0.7112403100775194,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7772581064092212,
            "auditor_fn_violation": 0.02275384101536406,
            "auditor_fp_violation": 0.02833089078628775,
            "ave_precision_score": 0.757062349669221,
            "fpr": 0.17763157894736842,
            "logloss": 1.8592739826929423,
            "mae": 0.29346625190130277,
            "precision": 0.7240204429301533,
            "recall": 0.8517034068136272
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7521639014398392,
            "auditor_fn_violation": 0.023616120432805397,
            "auditor_fp_violation": 0.02286864251738017,
            "ave_precision_score": 0.732087385731328,
            "fpr": 0.20856201975850713,
            "logloss": 1.7623747504383804,
            "mae": 0.3162614295944232,
            "precision": 0.6740994854202401,
            "recall": 0.8637362637362638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8275517869037787,
            "auditor_fn_violation": 0.02325484301937208,
            "auditor_fp_violation": 0.017342084023618372,
            "ave_precision_score": 0.8280272771060934,
            "fpr": 0.11403508771929824,
            "logloss": 0.9016582418132579,
            "mae": 0.27092334728092643,
            "precision": 0.7796610169491526,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8093713361157886,
            "auditor_fn_violation": 0.020547399910736903,
            "auditor_fp_violation": 0.022936044832168236,
            "ave_precision_score": 0.8100347613399628,
            "fpr": 0.13172338090010977,
            "logloss": 0.8210344985020995,
            "mae": 0.2770078544230115,
            "precision": 0.738562091503268,
            "recall": 0.7450549450549451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8673848963562792,
            "auditor_fn_violation": 0.01589582674120171,
            "auditor_fp_violation": 0.01228441867380315,
            "ave_precision_score": 0.8674783740361858,
            "fpr": 0.09978070175438597,
            "logloss": 1.020048648928384,
            "mae": 0.23124259184668447,
            "precision": 0.8123711340206186,
            "recall": 0.7895791583166333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.808233037757257,
            "auditor_fn_violation": 0.007652501176101622,
            "auditor_fp_violation": 0.009872031890923802,
            "ave_precision_score": 0.8098591747336321,
            "fpr": 0.12843029637760703,
            "logloss": 0.9841102601506779,
            "mae": 0.26298223527316433,
            "precision": 0.75,
            "recall": 0.7714285714285715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.82874729435335,
            "auditor_fn_violation": 0.012707432408677005,
            "auditor_fp_violation": 0.016558876003568253,
            "ave_precision_score": 0.8206664216644519,
            "fpr": 0.1337719298245614,
            "logloss": 1.1966920337151972,
            "mae": 0.2666562981752594,
            "precision": 0.7644787644787645,
            "recall": 0.7935871743486974
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7799539876970625,
            "auditor_fn_violation": 0.012202506604262921,
            "auditor_fp_violation": 0.025362528164538684,
            "ave_precision_score": 0.7685829773588843,
            "fpr": 0.16245883644346873,
            "logloss": 1.3973676461378404,
            "mae": 0.29203711190658693,
            "precision": 0.7022132796780685,
            "recall": 0.7670329670329671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8347773688467202,
            "auditor_fn_violation": 0.00944872200541434,
            "auditor_fp_violation": 0.0049620874219446975,
            "ave_precision_score": 0.8319581478479352,
            "fpr": 0.26096491228070173,
            "logloss": 1.2924652208669918,
            "mae": 0.31806915582966155,
            "precision": 0.6530612244897959,
            "recall": 0.8977955911823647
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7870554894479858,
            "auditor_fn_violation": 0.006132616011869578,
            "auditor_fp_violation": 0.01920965971459936,
            "ave_precision_score": 0.7844290184742628,
            "fpr": 0.28869374313940727,
            "logloss": 1.1884851478103422,
            "mae": 0.3397244992740357,
            "precision": 0.6103703703703703,
            "recall": 0.9054945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8239026665071918,
            "auditor_fn_violation": 0.015342087684140212,
            "auditor_fp_violation": 0.020153668068476276,
            "ave_precision_score": 0.8230515583482345,
            "fpr": 0.20285087719298245,
            "logloss": 1.3971185594854096,
            "mae": 0.28994252928199116,
            "precision": 0.6962233169129721,
            "recall": 0.8496993987975952
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7874698741201223,
            "auditor_fn_violation": 0.008619920145715975,
            "auditor_fp_violation": 0.026768347872975544,
            "ave_precision_score": 0.7856966188688888,
            "fpr": 0.2283205268935236,
            "logloss": 1.2989566132230441,
            "mae": 0.30959867752165926,
            "precision": 0.6527545909849749,
            "recall": 0.8593406593406593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8543864828180876,
            "auditor_fn_violation": 0.014937770277396898,
            "auditor_fp_violation": 0.010335690922220812,
            "ave_precision_score": 0.8545917178540559,
            "fpr": 0.10964912280701754,
            "logloss": 0.8138113495656102,
            "mae": 0.26872804707699544,
            "precision": 0.7858672376873662,
            "recall": 0.7354709418837675
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8147037102689614,
            "auditor_fn_violation": 0.017372528678785536,
            "auditor_fp_violation": 0.027095730544803277,
            "ave_precision_score": 0.8153694886553917,
            "fpr": 0.11855104281009879,
            "logloss": 0.8116722376185969,
            "mae": 0.2784576160970589,
            "precision": 0.7545454545454545,
            "recall": 0.7296703296703296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6634604452813837,
            "auditor_fn_violation": 0.058085469183982004,
            "auditor_fp_violation": 0.042739263412769214,
            "ave_precision_score": 0.5945434929263882,
            "fpr": 0.1962719298245614,
            "logloss": 8.072384792203348,
            "mae": 0.3861809528010932,
            "precision": 0.6629001883239172,
            "recall": 0.7054108216432866
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6373379304813739,
            "auditor_fn_violation": 0.045789556217657214,
            "auditor_fp_violation": 0.04886908544687736,
            "ave_precision_score": 0.5617472522183802,
            "fpr": 0.22722283205268934,
            "logloss": 7.43661701538469,
            "mae": 0.3887370322357628,
            "precision": 0.6145251396648045,
            "recall": 0.7252747252747253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6019253438448733,
            "auditor_fn_violation": 0.040009844249903316,
            "auditor_fp_violation": 0.043766726137377344,
            "ave_precision_score": 0.5622658425013132,
            "fpr": 0.13048245614035087,
            "logloss": 10.248302823452995,
            "mae": 0.46620636959600215,
            "precision": 0.6371951219512195,
            "recall": 0.4188376753507014
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5254789273221367,
            "auditor_fn_violation": 0.02664865321286837,
            "auditor_fp_violation": 0.04514992200589289,
            "ave_precision_score": 0.49244417404342966,
            "fpr": 0.14489571899012074,
            "logloss": 10.424876419354433,
            "mae": 0.4698465958166385,
            "precision": 0.5741935483870968,
            "recall": 0.3912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 4866,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8459410151716931,
            "auditor_fn_violation": 0.012395404844777278,
            "auditor_fp_violation": 0.01605974682468884,
            "ave_precision_score": 0.846223699132149,
            "fpr": 0.13925438596491227,
            "logloss": 0.7814514097149186,
            "mae": 0.2636606912567203,
            "precision": 0.7608286252354048,
            "recall": 0.8096192384769539
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8182917764453548,
            "auditor_fn_violation": 0.009840653309369009,
            "auditor_fp_violation": 0.025752498700098214,
            "ave_precision_score": 0.8186285432790693,
            "fpr": 0.16136114160263446,
            "logloss": 0.7723530096683079,
            "mae": 0.28259398764787114,
            "precision": 0.711764705882353,
            "recall": 0.7978021978021979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7998569387152097,
            "auditor_fn_violation": 0.021758429138979712,
            "auditor_fp_violation": 0.0336567053226286,
            "ave_precision_score": 0.8001842420693721,
            "fpr": 0.14473684210526316,
            "logloss": 1.37538840122561,
            "mae": 0.2875224840310566,
            "precision": 0.7421875,
            "recall": 0.7615230460921844
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7390516770039393,
            "auditor_fn_violation": 0.021857396171336897,
            "auditor_fp_violation": 0.03691480347410788,
            "ave_precision_score": 0.7395509762929712,
            "fpr": 0.17233809001097694,
            "logloss": 1.2786622100547593,
            "mae": 0.3103469766960638,
            "precision": 0.6847389558232931,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8549338411894116,
            "auditor_fn_violation": 0.008073163871602857,
            "auditor_fp_violation": 0.04161622276029056,
            "ave_precision_score": 0.8483918607205483,
            "fpr": 0.14692982456140352,
            "logloss": 1.6302566418144961,
            "mae": 0.2735114476507049,
            "precision": 0.7481203007518797,
            "recall": 0.7975951903807615
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8270502274094038,
            "auditor_fn_violation": 0.010564408149479503,
            "auditor_fp_violation": 0.033017505344040673,
            "ave_precision_score": 0.8228763812921479,
            "fpr": 0.1712403951701427,
            "logloss": 1.3524461127136038,
            "mae": 0.28816559022724536,
            "precision": 0.7017208413001912,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8404078817570648,
            "auditor_fn_violation": 0.026898094434483003,
            "auditor_fp_violation": 0.03413459496198123,
            "ave_precision_score": 0.8394477610196209,
            "fpr": 0.15679824561403508,
            "logloss": 1.150156878378034,
            "mae": 0.2740661272357462,
            "precision": 0.7437275985663082,
            "recall": 0.8316633266533067
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7979453782708339,
            "auditor_fn_violation": 0.03207198948142966,
            "auditor_fp_violation": 0.03758160494540413,
            "ave_precision_score": 0.7969503947630796,
            "fpr": 0.19538968166849616,
            "logloss": 0.9800157891409845,
            "mae": 0.2957028902756298,
            "precision": 0.6821428571428572,
            "recall": 0.8395604395604396
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7826559690594811,
            "auditor_fn_violation": 0.026491579650529135,
            "auditor_fp_violation": 0.016550911176245707,
            "ave_precision_score": 0.7709651806923294,
            "fpr": 0.14144736842105263,
            "logloss": 2.486856712351149,
            "mae": 0.2870443563338075,
            "precision": 0.7579737335834896,
            "recall": 0.8096192384769539
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7411131137206324,
            "auditor_fn_violation": 0.02536760714587279,
            "auditor_fp_violation": 0.027271458008357886,
            "ave_precision_score": 0.7291919749865917,
            "fpr": 0.17014270032930845,
            "logloss": 2.186071577253826,
            "mae": 0.3083432850071043,
            "precision": 0.696078431372549,
            "recall": 0.7802197802197802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8745531557281812,
            "auditor_fn_violation": 0.01468946665260346,
            "auditor_fp_violation": 0.012074678220976168,
            "ave_precision_score": 0.8745982389950226,
            "fpr": 0.09758771929824561,
            "logloss": 1.0732310715125832,
            "mae": 0.22807416439004813,
            "precision": 0.814968814968815,
            "recall": 0.7855711422845691
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8301686487354007,
            "auditor_fn_violation": 0.007408837046597752,
            "auditor_fp_violation": 0.013978758641939648,
            "ave_precision_score": 0.8308994216072412,
            "fpr": 0.12623490669593854,
            "logloss": 0.9849624116892366,
            "mae": 0.2536755777851118,
            "precision": 0.7510822510822511,
            "recall": 0.7626373626373626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 4866,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6936818911823581,
            "auditor_fn_violation": 0.017027476004640857,
            "auditor_fp_violation": 0.016893398751115077,
            "ave_precision_score": 0.6438519520815632,
            "fpr": 0.16666666666666666,
            "logloss": 6.025211399712597,
            "mae": 0.3813453697962039,
            "precision": 0.6820083682008368,
            "recall": 0.6533066132264529
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6328947122801997,
            "auditor_fn_violation": 0.015570379126910413,
            "auditor_fp_violation": 0.02700907042579007,
            "ave_precision_score": 0.5679673177439621,
            "fpr": 0.2305159165751921,
            "logloss": 6.531057062469288,
            "mae": 0.41050317788079843,
            "precision": 0.5945945945945946,
            "recall": 0.676923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8414159085806293,
            "auditor_fn_violation": 0.02212319375593292,
            "auditor_fp_violation": 0.012642835903317617,
            "ave_precision_score": 0.8405219101635586,
            "fpr": 0.11074561403508772,
            "logloss": 1.1494995422644747,
            "mae": 0.24604469631251438,
            "precision": 0.7967806841046278,
            "recall": 0.7935871743486974
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.801618397033993,
            "auditor_fn_violation": 0.020822426749978896,
            "auditor_fp_violation": 0.02230053729273788,
            "ave_precision_score": 0.8011110028521851,
            "fpr": 0.14270032930845225,
            "logloss": 0.9568250005939042,
            "mae": 0.27242198803635975,
            "precision": 0.7302904564315352,
            "recall": 0.7736263736263737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8543813321092428,
            "auditor_fn_violation": 0.028339573884611325,
            "auditor_fp_violation": 0.021576717216770746,
            "ave_precision_score": 0.8545108129615331,
            "fpr": 0.10526315789473684,
            "logloss": 1.1237144989964059,
            "mae": 0.25395001068008893,
            "precision": 0.806841046277666,
            "recall": 0.8036072144288577
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8081321148215257,
            "auditor_fn_violation": 0.030226414639147905,
            "auditor_fp_violation": 0.027037957132127796,
            "ave_precision_score": 0.8087555103586972,
            "fpr": 0.14489571899012074,
            "logloss": 0.8666943534583397,
            "mae": 0.2815029150965929,
            "precision": 0.7354709418837675,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 4866,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8273312550414548,
            "auditor_fn_violation": 0.03171694265724432,
            "auditor_fp_violation": 0.02651491015674781,
            "ave_precision_score": 0.8280435051058015,
            "fpr": 0.10197368421052631,
            "logloss": 1.226933100963172,
            "mae": 0.3105094551701458,
            "precision": 0.7769784172661871,
            "recall": 0.6492985971943888
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7797993879340467,
            "auditor_fn_violation": 0.023401406496905953,
            "auditor_fp_violation": 0.030966549194060895,
            "ave_precision_score": 0.7800925649662172,
            "fpr": 0.13172338090010977,
            "logloss": 1.21226941649136,
            "mae": 0.3353755672189083,
            "precision": 0.7037037037037037,
            "recall": 0.6263736263736264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8300017663934443,
            "auditor_fn_violation": 0.01636826284147242,
            "auditor_fp_violation": 0.009940104498534478,
            "ave_precision_score": 0.8251043463267338,
            "fpr": 0.10855263157894737,
            "logloss": 1.5829852214506324,
            "mae": 0.26360716129055517,
            "precision": 0.7946058091286307,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7917979937717916,
            "auditor_fn_violation": 0.011845454216475076,
            "auditor_fp_violation": 0.018025304754751864,
            "ave_precision_score": 0.7856392842184741,
            "fpr": 0.14050493962678376,
            "logloss": 1.46243822377035,
            "mae": 0.2907683446745101,
            "precision": 0.7235421166306696,
            "recall": 0.7362637362637363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8101025622259818,
            "auditor_fn_violation": 0.0305940829026474,
            "auditor_fp_violation": 0.028203453549127063,
            "ave_precision_score": 0.810790375075152,
            "fpr": 0.14144736842105263,
            "logloss": 1.1719819496177268,
            "mae": 0.30664364853430137,
            "precision": 0.7334710743801653,
            "recall": 0.7114228456913828
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7630412660468544,
            "auditor_fn_violation": 0.023862197078442962,
            "auditor_fp_violation": 0.031890923796868684,
            "ave_precision_score": 0.763498701710287,
            "fpr": 0.1778265642151482,
            "logloss": 1.1772834544656026,
            "mae": 0.33254771590727705,
            "precision": 0.6625,
            "recall": 0.6989010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8480754872450181,
            "auditor_fn_violation": 0.018308546918398203,
            "auditor_fp_violation": 0.009002909816915178,
            "ave_precision_score": 0.8476466724051478,
            "fpr": 0.19078947368421054,
            "logloss": 1.0796672435992936,
            "mae": 0.2841692890272347,
            "precision": 0.7128712871287128,
            "recall": 0.8657314629258517
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8015490195646628,
            "auditor_fn_violation": 0.010458257439596629,
            "auditor_fp_violation": 0.021542261251372118,
            "ave_precision_score": 0.8012117029877923,
            "fpr": 0.22941822173435786,
            "logloss": 0.9553296837874734,
            "mae": 0.3151928890468521,
            "precision": 0.6579378068739771,
            "recall": 0.8835164835164835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8195919514080378,
            "auditor_fn_violation": 0.018104190837815986,
            "auditor_fp_violation": 0.018640350877192995,
            "ave_precision_score": 0.8196848067962329,
            "fpr": 0.19407894736842105,
            "logloss": 1.3419594531369676,
            "mae": 0.2814880400002511,
            "precision": 0.7010135135135135,
            "recall": 0.8316633266533067
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7798674890000394,
            "auditor_fn_violation": 0.010853910085523697,
            "auditor_fp_violation": 0.02800806901997035,
            "ave_precision_score": 0.7801100655071309,
            "fpr": 0.21624588364434688,
            "logloss": 1.2479353482773023,
            "mae": 0.30059346149087784,
            "precision": 0.6591695501730104,
            "recall": 0.8373626373626374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7410946576142297,
            "auditor_fn_violation": 0.01933252469851985,
            "auditor_fp_violation": 0.01383490505925832,
            "ave_precision_score": 0.7160710956838916,
            "fpr": 0.1787280701754386,
            "logloss": 2.7155713997842956,
            "mae": 0.32882801793051897,
            "precision": 0.7047101449275363,
            "recall": 0.779559118236473
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6999683947943509,
            "auditor_fn_violation": 0.016890025452045217,
            "auditor_fp_violation": 0.0123490669593853,
            "ave_precision_score": 0.6733044798703236,
            "fpr": 0.1877058177826564,
            "logloss": 2.4445615155884766,
            "mae": 0.343660119199264,
            "precision": 0.6730401529636711,
            "recall": 0.7736263736263737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6004798890855216,
            "auditor_fn_violation": 0.04366408255106705,
            "auditor_fp_violation": 0.04912970986789007,
            "ave_precision_score": 0.5603658484342962,
            "fpr": 0.12828947368421054,
            "logloss": 10.441418052167577,
            "mae": 0.47038383185825916,
            "precision": 0.6355140186915887,
            "recall": 0.4088176352705411
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5260549059387357,
            "auditor_fn_violation": 0.026766866503419747,
            "auditor_fp_violation": 0.04587449688986462,
            "ave_precision_score": 0.49155577282347507,
            "fpr": 0.145993413830955,
            "logloss": 10.608285530162732,
            "mae": 0.47162635900686417,
            "precision": 0.5681818181818182,
            "recall": 0.38461538461538464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.7756920743868494,
            "auditor_fn_violation": 0.026019143550258413,
            "auditor_fp_violation": 0.020785544369398078,
            "ave_precision_score": 0.7657966208371739,
            "fpr": 0.12609649122807018,
            "logloss": 1.646941907331564,
            "mae": 0.2701886180429294,
            "precision": 0.7813688212927756,
            "recall": 0.8236472945891784
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7241459008813029,
            "auditor_fn_violation": 0.01942557990856564,
            "auditor_fp_violation": 0.02726905078282975,
            "ave_precision_score": 0.7124772022522009,
            "fpr": 0.1712403951701427,
            "logloss": 1.5846496846282079,
            "mae": 0.3023556714031861,
            "precision": 0.7017208413001912,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8301473312764961,
            "auditor_fn_violation": 0.0155024962205112,
            "auditor_fp_violation": 0.013380909901873331,
            "ave_precision_score": 0.8284046431039103,
            "fpr": 0.13815789473684212,
            "logloss": 1.3119115980919407,
            "mae": 0.26867063217298787,
            "precision": 0.7604562737642585,
            "recall": 0.8016032064128257
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7849059019719922,
            "auditor_fn_violation": 0.009761040276956854,
            "auditor_fp_violation": 0.01883413253220868,
            "ave_precision_score": 0.7822554802271203,
            "fpr": 0.16136114160263446,
            "logloss": 1.165016321676675,
            "mae": 0.29503658528064325,
            "precision": 0.7083333333333334,
            "recall": 0.7846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8398546032553624,
            "auditor_fn_violation": 0.029572302499736313,
            "auditor_fp_violation": 0.030616796227857783,
            "ave_precision_score": 0.8389569204491505,
            "fpr": 0.14364035087719298,
            "logloss": 1.1842653045186424,
            "mae": 0.2705001888389189,
            "precision": 0.7551401869158878,
            "recall": 0.8096192384769539
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7960858672276256,
            "auditor_fn_violation": 0.022187910881654022,
            "auditor_fp_violation": 0.030952105840892023,
            "ave_precision_score": 0.7942683569941497,
            "fpr": 0.17672886937431395,
            "logloss": 1.0505298270100165,
            "mae": 0.2922096071757971,
            "precision": 0.7001862197392924,
            "recall": 0.8263736263736263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8402813032871876,
            "auditor_fn_violation": 0.02869994374714341,
            "auditor_fp_violation": 0.030547767724395738,
            "ave_precision_score": 0.8393235354597606,
            "fpr": 0.14692982456140352,
            "logloss": 1.1477218729720702,
            "mae": 0.27400335657992736,
            "precision": 0.7527675276752768,
            "recall": 0.8176352705410822
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7958564503188477,
            "auditor_fn_violation": 0.0214207307511369,
            "auditor_fp_violation": 0.03078841450497815,
            "ave_precision_score": 0.7949578668892817,
            "fpr": 0.17892425905598244,
            "logloss": 0.9955384599072465,
            "mae": 0.2985914464796935,
            "precision": 0.6981481481481482,
            "recall": 0.8285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.828443731815247,
            "auditor_fn_violation": 0.021442006820658863,
            "auditor_fp_violation": 0.015510173739433334,
            "ave_precision_score": 0.8289274532823809,
            "fpr": 0.11293859649122807,
            "logloss": 0.9258694230550687,
            "mae": 0.2689514903589136,
            "precision": 0.7803837953091685,
            "recall": 0.7334669338677354
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8089501611528913,
            "auditor_fn_violation": 0.020916514879193257,
            "auditor_fp_violation": 0.025998035703969042,
            "ave_precision_score": 0.8096147135363236,
            "fpr": 0.12952799121844127,
            "logloss": 0.8405818183435544,
            "mae": 0.27545811822985067,
            "precision": 0.74235807860262,
            "recall": 0.7472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 4866,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8428851801935573,
            "auditor_fn_violation": 0.01310735506099919,
            "auditor_fp_violation": 0.009791427721846992,
            "ave_precision_score": 0.8426874486759293,
            "fpr": 0.09868421052631579,
            "logloss": 1.1708264590653075,
            "mae": 0.27398233487826984,
            "precision": 0.8167006109979633,
            "recall": 0.8036072144288577
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7781602796146789,
            "auditor_fn_violation": 0.007141047755756865,
            "auditor_fp_violation": 0.013957093612186344,
            "ave_precision_score": 0.7801117930298545,
            "fpr": 0.14270032930845225,
            "logloss": 0.9839696608991619,
            "mae": 0.30882277255784474,
            "precision": 0.7263157894736842,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8701842800512886,
            "auditor_fn_violation": 0.016341894314945683,
            "auditor_fp_violation": 0.01246229981733996,
            "ave_precision_score": 0.8702544980112374,
            "fpr": 0.09758771929824561,
            "logloss": 1.0897006588909286,
            "mae": 0.23177198555819323,
            "precision": 0.8153526970954357,
            "recall": 0.7875751503006012
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8245170271293915,
            "auditor_fn_violation": 0.013406352154980039,
            "auditor_fp_violation": 0.013316771621699695,
            "ave_precision_score": 0.8247292777939754,
            "fpr": 0.12733260153677278,
            "logloss": 1.0066447994104755,
            "mae": 0.2582643992039428,
            "precision": 0.7489177489177489,
            "recall": 0.7604395604395604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8436195420305231,
            "auditor_fn_violation": 0.020787188411911548,
            "auditor_fp_violation": 0.007359500446030338,
            "ave_precision_score": 0.8431433351162487,
            "fpr": 0.12390350877192982,
            "logloss": 1.2253197357124888,
            "mae": 0.2572136171099111,
            "precision": 0.7784313725490196,
            "recall": 0.7955911823647295
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8067694857037658,
            "auditor_fn_violation": 0.013391877058177829,
            "auditor_fp_violation": 0.018846168659849408,
            "ave_precision_score": 0.8058989120526884,
            "fpr": 0.1525795828759605,
            "logloss": 1.0377729043868733,
            "mae": 0.2779739783576357,
            "precision": 0.717479674796748,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8488458527118586,
            "auditor_fn_violation": 0.021272808775445635,
            "auditor_fp_violation": 0.008639182702519017,
            "ave_precision_score": 0.8485969159927375,
            "fpr": 0.11293859649122807,
            "logloss": 1.1171356992591261,
            "mae": 0.254090161030353,
            "precision": 0.7931726907630522,
            "recall": 0.7915831663326653
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.80643625915415,
            "auditor_fn_violation": 0.011196487376509334,
            "auditor_fp_violation": 0.018578966626225286,
            "ave_precision_score": 0.8067617982317729,
            "fpr": 0.1437980241492865,
            "logloss": 0.9493632893196964,
            "mae": 0.27677404020089363,
            "precision": 0.7265135699373695,
            "recall": 0.7648351648351648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8461759630475836,
            "auditor_fn_violation": 0.017187884541011843,
            "auditor_fp_violation": 0.012398581198759612,
            "ave_precision_score": 0.8463114698883829,
            "fpr": 0.1337719298245614,
            "logloss": 1.086548462475289,
            "mae": 0.2546829133565119,
            "precision": 0.7676190476190476,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7984891172771336,
            "auditor_fn_violation": 0.009271299501815426,
            "auditor_fp_violation": 0.020668438384655385,
            "ave_precision_score": 0.7991818759118019,
            "fpr": 0.16465422612513722,
            "logloss": 0.9994620414217625,
            "mae": 0.28016519945877155,
            "precision": 0.7041420118343196,
            "recall": 0.7846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8160417312861576,
            "auditor_fn_violation": 0.01545635129908941,
            "auditor_fp_violation": 0.022673208444840918,
            "ave_precision_score": 0.8163844558432384,
            "fpr": 0.19188596491228072,
            "logloss": 1.3744361926041693,
            "mae": 0.278698345050991,
            "precision": 0.7053872053872053,
            "recall": 0.8396793587174348
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.77025087961203,
            "auditor_fn_violation": 0.008537894597170118,
            "auditor_fp_violation": 0.0325505035915805,
            "ave_precision_score": 0.7700790199718912,
            "fpr": 0.21185510428100987,
            "logloss": 1.3706763406341929,
            "mae": 0.3009074996347174,
            "precision": 0.6596119929453262,
            "recall": 0.8219780219780219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8234581203962676,
            "auditor_fn_violation": 0.008457704883451114,
            "auditor_fp_violation": 0.020153668068476276,
            "ave_precision_score": 0.8225911353337364,
            "fpr": 0.20285087719298245,
            "logloss": 1.4078685195781153,
            "mae": 0.2903649396905681,
            "precision": 0.6967213114754098,
            "recall": 0.8517034068136272
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7875511688206571,
            "auditor_fn_violation": 0.009541501308790005,
            "auditor_fp_violation": 0.028930036397249996,
            "ave_precision_score": 0.7857809524548341,
            "fpr": 0.2305159165751921,
            "logloss": 1.3088487904600934,
            "mae": 0.309870378368288,
            "precision": 0.6511627906976745,
            "recall": 0.8615384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8465885683341028,
            "auditor_fn_violation": 0.017603188833807966,
            "auditor_fp_violation": 0.008047130538209936,
            "ave_precision_score": 0.8466754918063852,
            "fpr": 0.12280701754385964,
            "logloss": 1.1313200773810141,
            "mae": 0.25606385106203766,
            "precision": 0.7782178217821782,
            "recall": 0.7875751503006012
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7978001134262638,
            "auditor_fn_violation": 0.012733260153677282,
            "auditor_fp_violation": 0.02067566006123983,
            "ave_precision_score": 0.7981871589794917,
            "fpr": 0.14818880351262348,
            "logloss": 1.0072301927786356,
            "mae": 0.2826886330252214,
            "precision": 0.7210743801652892,
            "recall": 0.7670329670329671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 4866,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.854383263050537,
            "auditor_fn_violation": 0.01978298702668495,
            "auditor_fp_violation": 0.009114417399430785,
            "ave_precision_score": 0.854610195367343,
            "fpr": 0.08991228070175439,
            "logloss": 0.6618056724320592,
            "mae": 0.2816812243972215,
            "precision": 0.8114942528735632,
            "recall": 0.7074148296593187
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8220400035397528,
            "auditor_fn_violation": 0.014419608931134725,
            "auditor_fp_violation": 0.011918173589847293,
            "ave_precision_score": 0.82341394130064,
            "fpr": 0.11306256860592755,
            "logloss": 0.6409108708249022,
            "mae": 0.27651316273930765,
            "precision": 0.7695749440715883,
            "recall": 0.756043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8328439677314474,
            "auditor_fn_violation": 0.014522465984600786,
            "auditor_fp_violation": 0.019359840278662763,
            "ave_precision_score": 0.8331365579552139,
            "fpr": 0.16666666666666666,
            "logloss": 1.2273777066735445,
            "mae": 0.2682939823673538,
            "precision": 0.7285714285714285,
            "recall": 0.8176352705410822
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7920904904077442,
            "auditor_fn_violation": 0.007399186982062943,
            "auditor_fp_violation": 0.023359716525121813,
            "ave_precision_score": 0.7923884143818456,
            "fpr": 0.19319429198682767,
            "logloss": 1.120777993664721,
            "mae": 0.28526857785909476,
            "precision": 0.6794171220400729,
            "recall": 0.8197802197802198
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8186646253002425,
            "auditor_fn_violation": 0.018418415778926278,
            "auditor_fp_violation": 0.013641094261076422,
            "ave_precision_score": 0.818858953920188,
            "fpr": 0.12171052631578948,
            "logloss": 1.3451837358253587,
            "mae": 0.2792280602019408,
            "precision": 0.7677824267782427,
            "recall": 0.7354709418837675
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7668406431514057,
            "auditor_fn_violation": 0.012231456797867335,
            "auditor_fp_violation": 0.01712259518169738,
            "ave_precision_score": 0.7675109117276369,
            "fpr": 0.141602634467618,
            "logloss": 1.2239521685340997,
            "mae": 0.30329192822358897,
            "precision": 0.7158590308370044,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8354742578426515,
            "auditor_fn_violation": 0.01818769117181732,
            "auditor_fp_violation": 0.010463128159381508,
            "ave_precision_score": 0.835604184209832,
            "fpr": 0.11513157894736842,
            "logloss": 1.1346288157479243,
            "mae": 0.2685916768050922,
            "precision": 0.7830578512396694,
            "recall": 0.7595190380761523
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7854071316366025,
            "auditor_fn_violation": 0.01140637628014138,
            "auditor_fp_violation": 0.019002638319178852,
            "ave_precision_score": 0.7857372164200233,
            "fpr": 0.14270032930845225,
            "logloss": 1.0346935412011757,
            "mae": 0.29253467224018376,
            "precision": 0.721627408993576,
            "recall": 0.7406593406593407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6002809524222237,
            "auditor_fn_violation": 0.041943536195197424,
            "auditor_fp_violation": 0.045797757104625976,
            "ave_precision_score": 0.5608654848129782,
            "fpr": 0.125,
            "logloss": 10.800666231040713,
            "mae": 0.4701182083114378,
            "precision": 0.6392405063291139,
            "recall": 0.40480961923847697
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.523620172449243,
            "auditor_fn_violation": 0.03504179684201639,
            "auditor_fp_violation": 0.05600410191229996,
            "ave_precision_score": 0.4911677230224143,
            "fpr": 0.141602634467618,
            "logloss": 10.825696143970527,
            "mae": 0.4738082409658215,
            "precision": 0.5656565656565656,
            "recall": 0.36923076923076925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8460091417107721,
            "auditor_fn_violation": 0.02452492704707662,
            "auditor_fp_violation": 0.009573722441697463,
            "ave_precision_score": 0.8462846573514928,
            "fpr": 0.08991228070175439,
            "logloss": 0.9390779194474054,
            "mae": 0.2677382896692428,
            "precision": 0.8236559139784946,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.787138488610248,
            "auditor_fn_violation": 0.0156934174497292,
            "auditor_fp_violation": 0.01646542261251372,
            "ave_precision_score": 0.7874819096268849,
            "fpr": 0.1251372118551043,
            "logloss": 0.8335057489685793,
            "mae": 0.29634510449372276,
            "precision": 0.75,
            "recall": 0.7516483516483516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8394410057073616,
            "auditor_fn_violation": 0.008237967162394966,
            "auditor_fp_violation": 0.01168174673973069,
            "ave_precision_score": 0.8397069992011095,
            "fpr": 0.125,
            "logloss": 0.947039527870331,
            "mae": 0.2659581061882023,
            "precision": 0.7729083665338645,
            "recall": 0.7775551102204409
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8020049713474666,
            "auditor_fn_violation": 0.014675335641307104,
            "auditor_fp_violation": 0.02792381612648526,
            "ave_precision_score": 0.8025882651217641,
            "fpr": 0.14270032930845225,
            "logloss": 0.9565913624946044,
            "mae": 0.28244388451374225,
            "precision": 0.7245762711864406,
            "recall": 0.7516483516483516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8297613449697072,
            "auditor_fn_violation": 0.01636826284147242,
            "auditor_fp_violation": 0.009940104498534478,
            "ave_precision_score": 0.824867936481056,
            "fpr": 0.10855263157894737,
            "logloss": 1.5883993860245118,
            "mae": 0.2638483588170826,
            "precision": 0.7946058091286307,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7921813926376065,
            "auditor_fn_violation": 0.011804441442202152,
            "auditor_fp_violation": 0.018278063435207128,
            "ave_precision_score": 0.7860475191279537,
            "fpr": 0.1394072447859495,
            "logloss": 1.4672021023514386,
            "mae": 0.2906827569889308,
            "precision": 0.7257019438444925,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 4866,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8413687741170854,
            "auditor_fn_violation": 0.013718225925535277,
            "auditor_fp_violation": 0.014519880208997072,
            "ave_precision_score": 0.8414693061809086,
            "fpr": 0.14035087719298245,
            "logloss": 1.2469744389187418,
            "mae": 0.26020815735696634,
            "precision": 0.7571157495256167,
            "recall": 0.7995991983967936
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7939328598997847,
            "auditor_fn_violation": 0.01155595228043088,
            "auditor_fp_violation": 0.023350087623009233,
            "ave_precision_score": 0.7943876694857888,
            "fpr": 0.17233809001097694,
            "logloss": 1.179319097945983,
            "mae": 0.2890201143353153,
            "precision": 0.692156862745098,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8560930838894663,
            "auditor_fn_violation": 0.015634338853144893,
            "auditor_fp_violation": 0.014278280446879914,
            "ave_precision_score": 0.8563038919114505,
            "fpr": 0.11951754385964912,
            "logloss": 0.8287632870594505,
            "mae": 0.2567173014371236,
            "precision": 0.782435129740519,
            "recall": 0.7855711422845691
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8196553949064747,
            "auditor_fn_violation": 0.012870773573298274,
            "auditor_fp_violation": 0.023687099196949564,
            "ave_precision_score": 0.8200410564837564,
            "fpr": 0.14270032930845225,
            "logloss": 0.8368825423676411,
            "mae": 0.2729396327420231,
            "precision": 0.7263157894736842,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8350627140734441,
            "auditor_fn_violation": 0.011766954962556697,
            "auditor_fp_violation": 0.014140223439955829,
            "ave_precision_score": 0.8350674230442119,
            "fpr": 0.11951754385964912,
            "logloss": 1.1235141807514253,
            "mae": 0.2692676379378467,
            "precision": 0.7806841046277666,
            "recall": 0.7775551102204409
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7872612537255594,
            "auditor_fn_violation": 0.009384687760099398,
            "auditor_fp_violation": 0.019065226182910632,
            "ave_precision_score": 0.7876607273386584,
            "fpr": 0.14709110867178923,
            "logloss": 1.0073215520912435,
            "mae": 0.295533727139548,
            "precision": 0.7142857142857143,
            "recall": 0.7362637362637363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7663389288526472,
            "auditor_fn_violation": 0.010995675561649619,
            "auditor_fp_violation": 0.007471008028545943,
            "ave_precision_score": 0.7630280891957254,
            "fpr": 0.13815789473684212,
            "logloss": 1.337893433927677,
            "mae": 0.2832558124560125,
            "precision": 0.7485029940119761,
            "recall": 0.751503006012024
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7421473046650922,
            "auditor_fn_violation": 0.014964837577351299,
            "auditor_fp_violation": 0.01993182737304293,
            "ave_precision_score": 0.7425998560425875,
            "fpr": 0.14050493962678376,
            "logloss": 1.1931884333303469,
            "mae": 0.29057383289665395,
            "precision": 0.7229437229437229,
            "recall": 0.734065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 4866,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6926522471646728,
            "auditor_fn_violation": 0.01626278873536547,
            "auditor_fp_violation": 0.015406630984240274,
            "ave_precision_score": 0.6428230973717843,
            "fpr": 0.1699561403508772,
            "logloss": 6.109746943442932,
            "mae": 0.38331206001754564,
            "precision": 0.6797520661157025,
            "recall": 0.6593186372745491
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6313712063120157,
            "auditor_fn_violation": 0.015570379126910413,
            "auditor_fp_violation": 0.024043368575115073,
            "ave_precision_score": 0.5664444338999388,
            "fpr": 0.2349066959385291,
            "logloss": 6.619412256564557,
            "mae": 0.41346531442608975,
            "precision": 0.5900383141762452,
            "recall": 0.676923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8425897248503038,
            "auditor_fn_violation": 0.01621224905952256,
            "auditor_fp_violation": 0.013739327131387794,
            "ave_precision_score": 0.842810455557666,
            "fpr": 0.14144736842105263,
            "logloss": 0.9443934009070744,
            "mae": 0.27413614602466485,
            "precision": 0.7495145631067961,
            "recall": 0.7735470941883767
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8113619280268549,
            "auditor_fn_violation": 0.016103545192458473,
            "auditor_fp_violation": 0.025795828759604834,
            "ave_precision_score": 0.8117997032748117,
            "fpr": 0.14489571899012074,
            "logloss": 0.847504418501934,
            "mae": 0.2810720893799992,
            "precision": 0.725,
            "recall": 0.7648351648351648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7971491228070176,
            "auc_prc": 0.8928835574886456,
            "auditor_fn_violation": 0.010903385718806032,
            "auditor_fp_violation": 0.01115872307888365,
            "ave_precision_score": 0.8919003825441986,
            "fpr": 0.09758771929824561,
            "logloss": 1.2822562271737832,
            "mae": 0.2091501234449952,
            "precision": 0.8191056910569106,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8629184080893513,
            "auditor_fn_violation": 0.0065716939482032815,
            "auditor_fp_violation": 0.008184566795693963,
            "ave_precision_score": 0.8590956992388971,
            "fpr": 0.1141602634467618,
            "logloss": 1.1638025859537169,
            "mae": 0.22350014067049778,
            "precision": 0.7773019271948608,
            "recall": 0.7978021978021979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8031652639156015,
            "auditor_fn_violation": 0.0209497943254931,
            "auditor_fp_violation": 0.008360413746229981,
            "ave_precision_score": 0.7984739324167798,
            "fpr": 0.13157894736842105,
            "logloss": 1.2840568359070483,
            "mae": 0.28326141139183647,
            "precision": 0.7628458498023716,
            "recall": 0.7735470941883767
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7848481445479841,
            "auditor_fn_violation": 0.011196487376509332,
            "auditor_fp_violation": 0.020153292121632294,
            "ave_precision_score": 0.7798908157628901,
            "fpr": 0.14709110867178923,
            "logloss": 1.2204907602025739,
            "mae": 0.2957646523374796,
            "precision": 0.7248459958932238,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8349997306682955,
            "auditor_fn_violation": 0.02749358365854516,
            "auditor_fp_violation": 0.026889257040907357,
            "ave_precision_score": 0.8138733935809448,
            "fpr": 0.13486842105263158,
            "logloss": 1.7785533541419634,
            "mae": 0.26051499675049217,
            "precision": 0.768361581920904,
            "recall": 0.8176352705410822
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7877445479617045,
            "auditor_fn_violation": 0.02046778687832475,
            "auditor_fp_violation": 0.02484978912704374,
            "ave_precision_score": 0.7632605302566169,
            "fpr": 0.16575192096597147,
            "logloss": 1.7358461361485589,
            "mae": 0.2861506835286673,
            "precision": 0.710727969348659,
            "recall": 0.8153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8532238519938259,
            "auditor_fn_violation": 0.02487870477797701,
            "auditor_fp_violation": 0.0021186440677966123,
            "ave_precision_score": 0.8532260318028533,
            "fpr": 0.04057017543859649,
            "logloss": 1.1198240345297827,
            "mae": 0.27797438768268523,
            "precision": 0.8954802259887006,
            "recall": 0.6352705410821643
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7958692786885924,
            "auditor_fn_violation": 0.013768229575035288,
            "auditor_fp_violation": 0.003437518054191463,
            "ave_precision_score": 0.7978843593388771,
            "fpr": 0.07244785949506037,
            "logloss": 0.9206917908654931,
            "mae": 0.29700744568921844,
            "precision": 0.8125,
            "recall": 0.6285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6637288968106191,
            "auditor_fn_violation": 0.06372174172907219,
            "auditor_fp_violation": 0.06184157427466974,
            "ave_precision_score": 0.581143704994506,
            "fpr": 0.23903508771929824,
            "logloss": 8.978103729773313,
            "mae": 0.40791763846480245,
            "precision": 0.6254295532646048,
            "recall": 0.7294589178356713
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6430328657682347,
            "auditor_fn_violation": 0.049803983064136734,
            "auditor_fp_violation": 0.06296820536522425,
            "ave_precision_score": 0.5509001412171686,
            "fpr": 0.265642151481888,
            "logloss": 8.339989164110422,
            "mae": 0.40609849237754786,
            "precision": 0.5898305084745763,
            "recall": 0.7648351648351648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8525387243901024,
            "auditor_fn_violation": 0.02793086172344689,
            "auditor_fp_violation": 0.018552737776645005,
            "ave_precision_score": 0.8522666046491385,
            "fpr": 0.10964912280701754,
            "logloss": 1.1461185450666365,
            "mae": 0.24786077684407484,
            "precision": 0.7967479674796748,
            "recall": 0.7855711422845691
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8101484442130327,
            "auditor_fn_violation": 0.018918951520488298,
            "auditor_fp_violation": 0.021816684961580686,
            "ave_precision_score": 0.8100399273734609,
            "fpr": 0.13721185510428102,
            "logloss": 0.9625043895754397,
            "mae": 0.27096890996113493,
            "precision": 0.7384937238493724,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8781593430140668,
            "auditor_fn_violation": 0.014577400414864817,
            "auditor_fp_violation": 0.007003738158956723,
            "ave_precision_score": 0.8783261108731214,
            "fpr": 0.10197368421052631,
            "logloss": 0.8709049095673388,
            "mae": 0.23503417733473822,
            "precision": 0.80625,
            "recall": 0.7755511022044088
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8453159587569351,
            "auditor_fn_violation": 0.012142193700920376,
            "auditor_fp_violation": 0.014570936121863387,
            "ave_precision_score": 0.8456604445842384,
            "fpr": 0.11306256860592755,
            "logloss": 0.8832599157830706,
            "mae": 0.24445541163689977,
            "precision": 0.7741228070175439,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7399327768083237,
            "auditor_fn_violation": 0.026324578982526454,
            "auditor_fp_violation": 0.01632524106877363,
            "ave_precision_score": 0.7143997798823558,
            "fpr": 0.18092105263157895,
            "logloss": 2.7449504351167406,
            "mae": 0.3285852383645521,
            "precision": 0.7021660649819494,
            "recall": 0.779559118236473
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.69890908192096,
            "auditor_fn_violation": 0.01708061422660764,
            "auditor_fp_violation": 0.011983168679107217,
            "ave_precision_score": 0.6718019498506332,
            "fpr": 0.18990120746432493,
            "logloss": 2.4752336903334813,
            "mae": 0.3437247452343059,
            "precision": 0.6711026615969582,
            "recall": 0.7758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8345491337659029,
            "auditor_fn_violation": 0.01750870161375383,
            "auditor_fp_violation": 0.0205041204706682,
            "ave_precision_score": 0.834698998711366,
            "fpr": 0.17105263157894737,
            "logloss": 1.2290105282919455,
            "mae": 0.26968471014761797,
            "precision": 0.723404255319149,
            "recall": 0.8176352705410822
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7940877650748266,
            "auditor_fn_violation": 0.008687470597459621,
            "auditor_fp_violation": 0.024178173204691213,
            "ave_precision_score": 0.7941764123708018,
            "fpr": 0.1942919868276619,
            "logloss": 1.124131621128213,
            "mae": 0.2866059739599647,
            "precision": 0.6805054151624549,
            "recall": 0.8285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8537597256516007,
            "auditor_fn_violation": 0.02218472031782864,
            "auditor_fp_violation": 0.013818975404613236,
            "ave_precision_score": 0.8531777779119372,
            "fpr": 0.12171052631578948,
            "logloss": 1.0745797131142836,
            "mae": 0.2530789715039601,
            "precision": 0.7893738140417458,
            "recall": 0.8336673346693386
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8136740183907669,
            "auditor_fn_violation": 0.01309996260599993,
            "auditor_fp_violation": 0.018704142353688835,
            "ave_precision_score": 0.8128677712915853,
            "fpr": 0.15148188803512624,
            "logloss": 0.8746606591169571,
            "mae": 0.27589026772791125,
            "precision": 0.7330754352030948,
            "recall": 0.832967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7628099979235099,
            "auditor_fn_violation": 0.025425851703406825,
            "auditor_fp_violation": 0.013218958412981608,
            "ave_precision_score": 0.7539473072701083,
            "fpr": 0.09758771929824561,
            "logloss": 2.430421520910779,
            "mae": 0.2790532432221812,
            "precision": 0.806941431670282,
            "recall": 0.7454909819639278
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7086099593060573,
            "auditor_fn_violation": 0.025647459017382187,
            "auditor_fp_violation": 0.004525583992913132,
            "ave_precision_score": 0.6995512723948705,
            "fpr": 0.12294182217343579,
            "logloss": 2.2290120840978,
            "mae": 0.3055986649689545,
            "precision": 0.7454545454545455,
            "recall": 0.7208791208791209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8569956118514971,
            "auditor_fn_violation": 0.02030816018000915,
            "auditor_fp_violation": 0.006249734505755916,
            "ave_precision_score": 0.8573383680892215,
            "fpr": 0.0712719298245614,
            "logloss": 0.9333090335777985,
            "mae": 0.2365281058376415,
            "precision": 0.8505747126436781,
            "recall": 0.7414829659318637
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8086360278233953,
            "auditor_fn_violation": 0.017908107260467303,
            "auditor_fp_violation": 0.013258998209024214,
            "ave_precision_score": 0.8091244003202626,
            "fpr": 0.11306256860592755,
            "logloss": 0.831450060916305,
            "mae": 0.26743400606050843,
            "precision": 0.7632183908045977,
            "recall": 0.7296703296703296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.833781057601751,
            "auditor_fn_violation": 0.016906620258059984,
            "auditor_fp_violation": 0.019532411537317874,
            "ave_precision_score": 0.83396757033784,
            "fpr": 0.16447368421052633,
            "logloss": 1.2330357076852296,
            "mae": 0.26816951643019665,
            "precision": 0.7316636851520573,
            "recall": 0.8196392785571143
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7926513953431195,
            "auditor_fn_violation": 0.00979481550282868,
            "auditor_fp_violation": 0.024019296319833617,
            "ave_precision_score": 0.79299709842625,
            "fpr": 0.19099890230515917,
            "logloss": 1.128336520951384,
            "mae": 0.2851888611740262,
            "precision": 0.6807339449541284,
            "recall": 0.8153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8372890355220393,
            "auditor_fn_violation": 0.03700163484864466,
            "auditor_fp_violation": 0.019051866955524407,
            "ave_precision_score": 0.8361023297218938,
            "fpr": 0.10526315789473684,
            "logloss": 2.502595065385788,
            "mae": 0.26232132803900765,
            "precision": 0.7931034482758621,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7822974164325238,
            "auditor_fn_violation": 0.028528003281021955,
            "auditor_fp_violation": 0.028085100236870993,
            "ave_precision_score": 0.7818370304827399,
            "fpr": 0.1350164654226125,
            "logloss": 2.157996154666076,
            "mae": 0.2854411668359543,
            "precision": 0.7284768211920529,
            "recall": 0.7252747252747253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8431809594953407,
            "auditor_fn_violation": 0.017844900326969733,
            "auditor_fp_violation": 0.006148846693003699,
            "ave_precision_score": 0.8432707814332263,
            "fpr": 0.11403508771929824,
            "logloss": 1.194741501228108,
            "mae": 0.2589991190245547,
            "precision": 0.7877551020408163,
            "recall": 0.7735470941883767
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7937394438185689,
            "auditor_fn_violation": 0.012038455507171208,
            "auditor_fp_violation": 0.019825909449804537,
            "ave_precision_score": 0.7942657493822712,
            "fpr": 0.14709110867178923,
            "logloss": 1.0702273427916522,
            "mae": 0.2852856337097829,
            "precision": 0.7202505219206681,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8513326558908183,
            "auditor_fn_violation": 0.02949539429736667,
            "auditor_fp_violation": 0.016784546111040317,
            "ave_precision_score": 0.8513346621741735,
            "fpr": 0.11074561403508772,
            "logloss": 1.187677874472583,
            "mae": 0.24802814560808475,
            "precision": 0.795131845841785,
            "recall": 0.7855711422845691
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8094131445422563,
            "auditor_fn_violation": 0.01711921448474687,
            "auditor_fp_violation": 0.020856201975850728,
            "ave_precision_score": 0.8093872406013506,
            "fpr": 0.14050493962678376,
            "logloss": 0.9597971887816473,
            "mae": 0.2712537582750854,
            "precision": 0.7344398340248963,
            "recall": 0.778021978021978
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8476311428310557,
            "auditor_fn_violation": 0.01815253313644834,
            "auditor_fp_violation": 0.006132917038358605,
            "ave_precision_score": 0.8477584474335087,
            "fpr": 0.11513157894736842,
            "logloss": 1.102539807151492,
            "mae": 0.25669964111991495,
            "precision": 0.7848360655737705,
            "recall": 0.7675350701402806
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8015358608444705,
            "auditor_fn_violation": 0.010492032665468451,
            "auditor_fp_violation": 0.018169738286440584,
            "ave_precision_score": 0.8019118029113912,
            "fpr": 0.13830954994511527,
            "logloss": 0.9551930508421728,
            "mae": 0.2790748578525308,
            "precision": 0.7307692307692307,
            "recall": 0.7516483516483516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8433220251053521,
            "auditor_fn_violation": 0.01156040150476392,
            "auditor_fp_violation": 0.010723312518584603,
            "ave_precision_score": 0.8435754109769809,
            "fpr": 0.13267543859649122,
            "logloss": 0.8440884783370686,
            "mae": 0.2644138027417733,
            "precision": 0.7659574468085106,
            "recall": 0.7935871743486974
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8142740323289532,
            "auditor_fn_violation": 0.005068696396907153,
            "auditor_fp_violation": 0.020625108325148776,
            "ave_precision_score": 0.8146246948709697,
            "fpr": 0.14818880351262348,
            "logloss": 0.8264831690096494,
            "mae": 0.28120723764319766,
            "precision": 0.7204968944099379,
            "recall": 0.7648351648351648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8483423892183048,
            "auditor_fn_violation": 0.01947315683999578,
            "auditor_fp_violation": 0.009579032326579166,
            "ave_precision_score": 0.8479535330727987,
            "fpr": 0.18640350877192982,
            "logloss": 1.0715116138693506,
            "mae": 0.2822282278299495,
            "precision": 0.7166666666666667,
            "recall": 0.8617234468937875
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8017584585068108,
            "auditor_fn_violation": 0.009464300792511551,
            "auditor_fp_violation": 0.01790975792940089,
            "ave_precision_score": 0.801471489894523,
            "fpr": 0.22722283205268934,
            "logloss": 0.9472151674205556,
            "mae": 0.31374000197796315,
            "precision": 0.6595394736842105,
            "recall": 0.8813186813186813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8020589941422087,
            "auditor_fn_violation": 0.029306419857258386,
            "auditor_fp_violation": 0.023488275774181222,
            "ave_precision_score": 0.8026702804019328,
            "fpr": 0.1337719298245614,
            "logloss": 1.3247521487074392,
            "mae": 0.3151157450648918,
            "precision": 0.7376344086021506,
            "recall": 0.687374749498998
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.737434424963418,
            "auditor_fn_violation": 0.024021423143267273,
            "auditor_fp_violation": 0.02673946116663778,
            "ave_precision_score": 0.7391000228669857,
            "fpr": 0.1602634467618002,
            "logloss": 1.3279588440092898,
            "mae": 0.3404807872223006,
            "precision": 0.6755555555555556,
            "recall": 0.6681318681318681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8521410135606653,
            "auditor_fn_violation": 0.014403807615230472,
            "auditor_fp_violation": 0.0085940486810246,
            "ave_precision_score": 0.8523437783794483,
            "fpr": 0.10307017543859649,
            "logloss": 0.8453396532964971,
            "mae": 0.2763081510166476,
            "precision": 0.7892376681614349,
            "recall": 0.7054108216432866
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8084610222491049,
            "auditor_fn_violation": 0.009946804019251881,
            "auditor_fp_violation": 0.018855797561961995,
            "ave_precision_score": 0.8098650681074793,
            "fpr": 0.11964873765093303,
            "logloss": 0.8464120819509279,
            "mae": 0.2831274189313264,
            "precision": 0.7470997679814385,
            "recall": 0.7076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8713207105184455,
            "auditor_fn_violation": 0.0157705762401997,
            "auditor_fp_violation": 0.011373773416592329,
            "ave_precision_score": 0.8713860182163434,
            "fpr": 0.1074561403508772,
            "logloss": 1.1122084553874818,
            "mae": 0.2307632392960907,
            "precision": 0.8016194331983806,
            "recall": 0.7935871743486974
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8297402587207326,
            "auditor_fn_violation": 0.010344869181312655,
            "auditor_fp_violation": 0.015541048009705944,
            "ave_precision_score": 0.8296718130062575,
            "fpr": 0.1394072447859495,
            "logloss": 1.010752864138574,
            "mae": 0.2564369610732969,
            "precision": 0.7354166666666667,
            "recall": 0.7758241758241758
        }
    }
]