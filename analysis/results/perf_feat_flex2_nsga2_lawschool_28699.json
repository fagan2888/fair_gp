[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5300515687184139,
            "auditor_fn_violation": 0.0028234649122807244,
            "auditor_fp_violation": 0.0035483674463937637,
            "ave_precision_score": 0.5322630133513783,
            "fpr": 0.03728070175438596,
            "logloss": 0.702095670062783,
            "mae": 0.5015746070758292,
            "precision": 0.5142857142857142,
            "recall": 0.075
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5509211997750835,
            "auditor_fn_violation": 0.0025821302690510295,
            "auditor_fp_violation": 0.0036547963236014443,
            "ave_precision_score": 0.5527975292884143,
            "fpr": 0.027442371020856202,
            "logloss": 0.697197836710156,
            "mae": 0.49910738730535287,
            "precision": 0.5833333333333334,
            "recall": 0.07383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6508838395115358,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6437755102403823,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7293539303914074,
            "mae": 0.4685138765918581,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6459585086334924,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6367541903075955,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7274242593126694,
            "mae": 0.467403502531685,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6514810111158927,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6450640798157723,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7244240862842413,
            "mae": 0.46664028748739184,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6466315064099796,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6381313599747057,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7234771249632845,
            "mae": 0.4668015476181269,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6515584928770793,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6438947901389144,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7263737696034307,
            "mae": 0.4676108991955979,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6456744231924969,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6380126097366997,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7253462311776846,
            "mae": 0.4672947825964144,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6514810111158927,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6450640798157723,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7244210883598615,
            "mae": 0.46663965629577114,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6466315064099796,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6381313599747057,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7234737937542917,
            "mae": 0.466800808268635,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.618347579725269,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.619956646037505,
            "fpr": 0.3048245614035088,
            "logloss": 0.6838956268918951,
            "mae": 0.4899349940058432,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6020651460869224,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6036396418374568,
            "fpr": 0.29418221734357847,
            "logloss": 0.6847581949210048,
            "mae": 0.4904921083955419,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5468500973399081,
            "auditor_fn_violation": 0.029970760233918134,
            "auditor_fp_violation": 0.05340826023391813,
            "ave_precision_score": 0.5397005012609358,
            "fpr": 0.3355263157894737,
            "logloss": 0.8899169849330316,
            "mae": 0.49122913389362194,
            "precision": 0.5590778097982709,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5063183474314514,
            "auditor_fn_violation": 0.028878174399162605,
            "auditor_fp_violation": 0.040981444686981144,
            "ave_precision_score": 0.5312376646612325,
            "fpr": 0.36223929747530187,
            "logloss": 0.8447945158171961,
            "mae": 0.49084726673913337,
            "precision": 0.541029207232267,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5201120367225174,
            "auditor_fn_violation": 0.04848547149122807,
            "auditor_fp_violation": 0.053636695906432746,
            "ave_precision_score": 0.5497736352951936,
            "fpr": 0.18859649122807018,
            "logloss": 0.7689201335850341,
            "mae": 0.5096860910324674,
            "precision": 0.5437665782493368,
            "recall": 0.4270833333333333
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5563807323663384,
            "auditor_fn_violation": 0.04273599281171987,
            "auditor_fp_violation": 0.059164998354713685,
            "ave_precision_score": 0.5649433722341952,
            "fpr": 0.1712403951701427,
            "logloss": 0.7551194728795945,
            "mae": 0.5014702680834562,
            "precision": 0.5617977528089888,
            "recall": 0.4219409282700422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 28699,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.970779375617635,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7691872287090499,
            "auditor_fn_violation": 0.006784539473684213,
            "auditor_fp_violation": 0.014975227420402868,
            "ave_precision_score": 0.7694937577571042,
            "fpr": 0.17324561403508773,
            "logloss": 1.0613728286420736,
            "mae": 0.2868914793106337,
            "precision": 0.7116788321167883,
            "recall": 0.8125
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7452511249506512,
            "auditor_fn_violation": 0.010821789011009376,
            "auditor_fp_violation": 0.011903834898657904,
            "ave_precision_score": 0.745754721417038,
            "fpr": 0.15697036223929747,
            "logloss": 1.0318881511696885,
            "mae": 0.28663554684605164,
            "precision": 0.718503937007874,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.639955510933759,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.6419065134925541,
            "fpr": 0.3048245614035088,
            "logloss": 0.6837889591470314,
            "mae": 0.48950637226695554,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.620356357504035,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6220900923286856,
            "fpr": 0.29418221734357847,
            "logloss": 0.6846665321496105,
            "mae": 0.49009982327205814,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6408793279893112,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6442386207370345,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7207236579432138,
            "mae": 0.46673820842580316,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6436949992663369,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6398136632868113,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7189541745527896,
            "mae": 0.46575192742368654,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6654005698908996,
            "auditor_fn_violation": 0.007161458333333334,
            "auditor_fp_violation": 0.0033376989928525064,
            "ave_precision_score": 0.5345854572134692,
            "fpr": 0.4331140350877193,
            "logloss": 0.69274319428043,
            "mae": 0.4975393363519719,
            "precision": 0.5240963855421686,
            "recall": 0.90625
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.668692665621694,
            "auditor_fn_violation": 0.007693127133441714,
            "auditor_fp_violation": 0.008249038575056466,
            "ave_precision_score": 0.5415160856289387,
            "fpr": 0.424807903402854,
            "logloss": 0.6893770680616679,
            "mae": 0.4959478732914092,
            "precision": 0.532043530834341,
            "recall": 0.9282700421940928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 28699,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.535372121488404,
            "auditor_fn_violation": 0.003700657894736858,
            "auditor_fp_violation": 0.002649853801169591,
            "ave_precision_score": 0.5302360476141069,
            "fpr": 0.039473684210526314,
            "logloss": 0.6955908030377403,
            "mae": 0.5007891824240225,
            "precision": 0.5,
            "recall": 0.075
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.5122903162368538,
            "auditor_fn_violation": 0.005502369075574219,
            "auditor_fp_violation": 0.011843549598474787,
            "ave_precision_score": 0.5141581266497125,
            "fpr": 0.050493962678375415,
            "logloss": 0.6959248769134835,
            "mae": 0.5008892896212024,
            "precision": 0.46511627906976744,
            "recall": 0.08438818565400844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6435260591535119,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.6455418089958262,
            "fpr": 0.3048245614035088,
            "logloss": 0.6837634080938259,
            "mae": 0.48944157375055447,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.623953587867637,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6257509783414656,
            "fpr": 0.29418221734357847,
            "logloss": 0.6846432644572982,
            "mae": 0.49004070246520604,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.716421819110884,
            "auditor_fn_violation": 0.06672149122807018,
            "auditor_fp_violation": 0.08442982456140352,
            "ave_precision_score": 0.5529892692897291,
            "fpr": 0.29605263157894735,
            "logloss": 0.6906279279394575,
            "mae": 0.49855615982883855,
            "precision": 0.5631067961165048,
            "recall": 0.725
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7062042555871523,
            "auditor_fn_violation": 0.08075236097023256,
            "auditor_fp_violation": 0.07972730949217172,
            "ave_precision_score": 0.5453870466081545,
            "fpr": 0.29088913282107576,
            "logloss": 0.691011062824724,
            "mae": 0.49875370286298765,
            "precision": 0.5561139028475712,
            "recall": 0.70042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6508659746564812,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.6535091534649158,
            "fpr": 0.3048245614035088,
            "logloss": 0.6836395946667273,
            "mae": 0.489958587020897,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6313584394688867,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6333888077263107,
            "fpr": 0.29418221734357847,
            "logloss": 0.6844844216361379,
            "mae": 0.49054585647504495,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6515584928770793,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6438947901389144,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7263732557320286,
            "mae": 0.4676107903615686,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6456744231924969,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6380126097366997,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7253456647781968,
            "mae": 0.467294655879295,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6497583882629538,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.6519798711824585,
            "fpr": 0.3048245614035088,
            "logloss": 0.6836875465254013,
            "mae": 0.4893000042882928,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6301307797442506,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6321840619918181,
            "fpr": 0.29418221734357847,
            "logloss": 0.6845737175075629,
            "mae": 0.48991242967112525,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.6261362666651107,
            "auditor_fn_violation": 0.03614309210526316,
            "auditor_fp_violation": 0.027884381091617946,
            "ave_precision_score": 0.6049434590407811,
            "fpr": 0.23135964912280702,
            "logloss": 0.954416732794289,
            "mae": 0.47196778168405507,
            "precision": 0.5352422907488987,
            "recall": 0.50625
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6504859724044187,
            "auditor_fn_violation": 0.035376342591949314,
            "auditor_fp_violation": 0.041624487888934386,
            "ave_precision_score": 0.6275644148333418,
            "fpr": 0.22502744237102085,
            "logloss": 0.9263481934069471,
            "mae": 0.46142533824203535,
            "precision": 0.5572354211663066,
            "recall": 0.5443037974683544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5404593603078222,
            "auditor_fn_violation": 0.01349597953216374,
            "auditor_fp_violation": 0.011063901072124774,
            "ave_precision_score": 0.5971938954007412,
            "fpr": 0.4309210526315789,
            "logloss": 0.6856191304266703,
            "mae": 0.49431028458894344,
            "precision": 0.5381903642773208,
            "recall": 0.9541666666666667
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5458964427422816,
            "auditor_fn_violation": 0.004904889605246704,
            "auditor_fp_violation": 0.0012057060036623475,
            "ave_precision_score": 0.5913751586338698,
            "fpr": 0.43907793633369924,
            "logloss": 0.6832778221558312,
            "mae": 0.492017660081452,
            "precision": 0.5310668229777257,
            "recall": 0.9556962025316456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5468500973399081,
            "auditor_fn_violation": 0.029970760233918134,
            "auditor_fp_violation": 0.05340826023391813,
            "ave_precision_score": 0.5397005012609358,
            "fpr": 0.3355263157894737,
            "logloss": 0.8899739841068759,
            "mae": 0.49122807991554385,
            "precision": 0.5590778097982709,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5063183474314514,
            "auditor_fn_violation": 0.028878174399162605,
            "auditor_fp_violation": 0.040981444686981144,
            "ave_precision_score": 0.5312376646612325,
            "fpr": 0.36223929747530187,
            "logloss": 0.8448470814825974,
            "mae": 0.49084713480411557,
            "precision": 0.541029207232267,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7398442454026632,
            "auditor_fn_violation": 0.007161458333333334,
            "auditor_fp_violation": 0.0033376989928525064,
            "ave_precision_score": 0.5243044546607483,
            "fpr": 0.4331140350877193,
            "logloss": 0.6935684227988198,
            "mae": 0.49918948244630246,
            "precision": 0.5240963855421686,
            "recall": 0.90625
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.748817598808399,
            "auditor_fn_violation": 0.007693127133441714,
            "auditor_fp_violation": 0.008249038575056466,
            "ave_precision_score": 0.5312016954050522,
            "fpr": 0.424807903402854,
            "logloss": 0.6899535259490426,
            "mae": 0.49738321234967914,
            "precision": 0.532043530834341,
            "recall": 0.9282700421940928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6907551900744541,
            "auditor_fn_violation": 0.00019188596491228005,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6857824103712968,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6355243092476338,
            "mae": 0.4563367813988997,
            "precision": 0.9587628865979382,
            "recall": 0.19375
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.677713416426952,
            "auditor_fn_violation": 0.009559671525240038,
            "auditor_fp_violation": 0.0019416890433978805,
            "ave_precision_score": 0.675402842660876,
            "fpr": 0.005488474204171241,
            "logloss": 0.63906532258241,
            "mae": 0.45844776340393284,
            "precision": 0.9438202247191011,
            "recall": 0.17721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6381286795522579,
            "auditor_fn_violation": 0.005505299707602355,
            "auditor_fp_violation": 0.0012792397660818717,
            "ave_precision_score": 0.6215842895948318,
            "fpr": 0.021929824561403508,
            "logloss": 0.7249894883439248,
            "mae": 0.46613786688989456,
            "precision": 0.8461538461538461,
            "recall": 0.22916666666666666
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6442214091473599,
            "auditor_fn_violation": 0.01659047645514042,
            "auditor_fp_violation": 0.0004295327638047066,
            "ave_precision_score": 0.6266699607193307,
            "fpr": 0.019758507135016465,
            "logloss": 0.724159647874552,
            "mae": 0.4651943328744363,
            "precision": 0.8524590163934426,
            "recall": 0.21940928270042195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6508838395115358,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6437755102403823,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7293536148222758,
            "mae": 0.46851381149731186,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6459585086334924,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6367541903075955,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7274239106303448,
            "mae": 0.4674034259649061,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6508838395115358,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6437755102403823,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7293530383078803,
            "mae": 0.4685136936441587,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6459585086334924,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6367541903075955,
            "fpr": 0.0043907793633369925,
            "logloss": 0.727423273722612,
            "mae": 0.4674032877979373,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8104048575888814,
            "auditor_fn_violation": 0.008630299707602344,
            "auditor_fp_violation": 0.02798590805717999,
            "ave_precision_score": 0.8107742846801275,
            "fpr": 0.18640350877192982,
            "logloss": 0.8610825221041106,
            "mae": 0.29013534986713446,
            "precision": 0.696969696969697,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8084887194384718,
            "auditor_fn_violation": 0.01661363457414535,
            "auditor_fp_violation": 0.019062714295403006,
            "ave_precision_score": 0.8089954405008748,
            "fpr": 0.1690450054884742,
            "logloss": 0.8383608784699439,
            "mae": 0.28409482390081003,
            "precision": 0.7083333333333334,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6514354920601637,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6480511537058227,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7286378080803884,
            "mae": 0.46606522887585716,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6471148828616031,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6432043972005236,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7273725309427876,
            "mae": 0.4650320919756047,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8032774482330196,
            "auditor_fn_violation": 0.015385142543859651,
            "auditor_fp_violation": 0.028800661955815463,
            "ave_precision_score": 0.8038052169556862,
            "fpr": 0.13048245614035087,
            "logloss": 1.0097296107070313,
            "mae": 0.2839035061198588,
            "precision": 0.7531120331950207,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8372599738139771,
            "auditor_fn_violation": 0.016013839291917353,
            "auditor_fp_violation": 0.02423217878610524,
            "ave_precision_score": 0.8375110836549735,
            "fpr": 0.10757409440175632,
            "logloss": 0.8927403291946744,
            "mae": 0.26505256843155744,
            "precision": 0.7836644591611479,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7186351035236201,
            "auditor_fn_violation": 0.0069353070175438595,
            "auditor_fp_violation": 0.018107334307992204,
            "ave_precision_score": 0.7192216672761091,
            "fpr": 0.046052631578947366,
            "logloss": 0.6345265294462675,
            "mae": 0.4539478600613381,
            "precision": 0.7439024390243902,
            "recall": 0.25416666666666665
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7148573077925682,
            "auditor_fn_violation": 0.010467469790233781,
            "auditor_fp_violation": 0.007935052636602723,
            "ave_precision_score": 0.7148363966414307,
            "fpr": 0.043907793633369926,
            "logloss": 0.6362415258941916,
            "mae": 0.45609331979906,
            "precision": 0.7468354430379747,
            "recall": 0.2489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6549047467372934,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.656482429341346,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6356187604004213,
            "mae": 0.45483155362308025,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.663349519861576,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6617686263477653,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6389054014222416,
            "mae": 0.45774964984960276,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5468500973399081,
            "auditor_fn_violation": 0.029970760233918134,
            "auditor_fp_violation": 0.05340826023391813,
            "ave_precision_score": 0.5397005012609358,
            "fpr": 0.3355263157894737,
            "logloss": 0.8882567114521394,
            "mae": 0.491259981686967,
            "precision": 0.5590778097982709,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5063183474314514,
            "auditor_fn_violation": 0.028878174399162605,
            "auditor_fp_violation": 0.040981444686981144,
            "ave_precision_score": 0.5312376646612325,
            "fpr": 0.36223929747530187,
            "logloss": 0.8432629688405447,
            "mae": 0.4908510986003724,
            "precision": 0.541029207232267,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5468500973399081,
            "auditor_fn_violation": 0.029970760233918134,
            "auditor_fp_violation": 0.05340826023391813,
            "ave_precision_score": 0.5397005012609358,
            "fpr": 0.3355263157894737,
            "logloss": 0.8883226989129044,
            "mae": 0.49125874793173196,
            "precision": 0.5590778097982709,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5063183474314514,
            "auditor_fn_violation": 0.028878174399162605,
            "auditor_fp_violation": 0.040981444686981144,
            "ave_precision_score": 0.5312376646612325,
            "fpr": 0.36223929747530187,
            "logloss": 0.843323833480248,
            "mae": 0.49085094222604325,
            "precision": 0.541029207232267,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.62956916452163,
            "auditor_fn_violation": 0.018188048245614038,
            "auditor_fp_violation": 0.028173732943469792,
            "ave_precision_score": 0.618788059395963,
            "fpr": 0.23026315789473684,
            "logloss": 0.9438268664303546,
            "mae": 0.47269672766815984,
            "precision": 0.5652173913043478,
            "recall": 0.56875
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6535805664940266,
            "auditor_fn_violation": 0.026849523174329697,
            "auditor_fp_violation": 0.039511990495017676,
            "ave_precision_score": 0.640105609752121,
            "fpr": 0.2217343578485181,
            "logloss": 0.913435500887734,
            "mae": 0.4614113797525682,
            "precision": 0.5738396624472574,
            "recall": 0.5738396624472574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.650425670485997,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6510150612911785,
            "fpr": 0.0043859649122807015,
            "logloss": 0.635928363503247,
            "mae": 0.4548588888556288,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6611719031387576,
            "auditor_fn_violation": 0.01213022273478859,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6616034821135826,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6387823860984214,
            "mae": 0.45755556408974263,
            "precision": 0.9574468085106383,
            "recall": 0.189873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6504407229180176,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.6529260189137832,
            "fpr": 0.3048245614035088,
            "logloss": 0.6836757209554748,
            "mae": 0.48928317774021834,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6309339311009576,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6330329997703796,
            "fpr": 0.29418221734357847,
            "logloss": 0.6845629772198706,
            "mae": 0.4898973634031026,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5463828232919377,
            "auditor_fn_violation": 0.016013340643274854,
            "auditor_fp_violation": 0.022074500487329438,
            "ave_precision_score": 0.5392406557461868,
            "fpr": 0.19846491228070176,
            "logloss": 0.6930180788536549,
            "mae": 0.49992297429656773,
            "precision": 0.5429292929292929,
            "recall": 0.4479166666666667
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5055521207141309,
            "auditor_fn_violation": 0.025246981339187718,
            "auditor_fp_violation": 0.036427392635648204,
            "ave_precision_score": 0.5304769944375435,
            "fpr": 0.2217343578485181,
            "logloss": 0.6930605980815794,
            "mae": 0.4999434717334848,
            "precision": 0.5167464114832536,
            "recall": 0.45569620253164556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7979913336029342,
            "auditor_fn_violation": 0.016228070175438602,
            "auditor_fp_violation": 0.02315576267056531,
            "ave_precision_score": 0.7984916047026049,
            "fpr": 0.1699561403508772,
            "logloss": 0.8977250495012097,
            "mae": 0.2963068709381245,
            "precision": 0.712430426716141,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8239977450822601,
            "auditor_fn_violation": 0.010620313375666377,
            "auditor_fp_violation": 0.019002428995219877,
            "ave_precision_score": 0.8242876718239506,
            "fpr": 0.1394072447859495,
            "logloss": 0.7592928948605183,
            "mae": 0.27108390026814083,
            "precision": 0.744466800804829,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6175002288918305,
            "auditor_fn_violation": 0.01305509868421054,
            "auditor_fp_violation": 0.001606664230019493,
            "ave_precision_score": 0.6114723776206715,
            "fpr": 0.005482456140350877,
            "logloss": 1.0244333039611686,
            "mae": 0.4859971011041157,
            "precision": 0.9375,
            "recall": 0.15625
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6309713486869915,
            "auditor_fn_violation": 0.011926431287545126,
            "auditor_fp_violation": 0.0004697229639267835,
            "ave_precision_score": 0.6226367802019801,
            "fpr": 0.003293084522502744,
            "logloss": 0.9888266857362135,
            "mae": 0.4728608991455953,
            "precision": 0.9620253164556962,
            "recall": 0.16033755274261605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8192252265603333,
            "auditor_fn_violation": 0.009443530701754384,
            "auditor_fp_violation": 0.027686403508771933,
            "ave_precision_score": 0.8195444059547271,
            "fpr": 0.17763157894736842,
            "logloss": 0.7869422755633073,
            "mae": 0.2863622086504313,
            "precision": 0.7070524412296564,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8166500719534264,
            "auditor_fn_violation": 0.022342953215967985,
            "auditor_fp_violation": 0.017844448854202517,
            "ave_precision_score": 0.8171375000383132,
            "fpr": 0.15806805708013172,
            "logloss": 0.771276141538348,
            "mae": 0.28367835475447317,
            "precision": 0.7192982456140351,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7931546840528905,
            "auditor_fn_violation": 0.014775219298245617,
            "auditor_fp_violation": 0.02642239278752437,
            "ave_precision_score": 0.7937270684379654,
            "fpr": 0.1425438596491228,
            "logloss": 1.0898970800888863,
            "mae": 0.2864976983732152,
            "precision": 0.7363083164300203,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.82906762219677,
            "auditor_fn_violation": 0.017929015733626052,
            "auditor_fp_violation": 0.023945823610235437,
            "ave_precision_score": 0.8293475129895823,
            "fpr": 0.11525795828759605,
            "logloss": 0.9579899224302907,
            "mae": 0.26815605423134864,
            "precision": 0.7702407002188184,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6507296372823742,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.647032136986503,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7274929479248118,
            "mae": 0.4677072393528202,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6456832152787016,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6412094760747511,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7264082993651242,
            "mae": 0.467322644561889,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7895284320851007,
            "auditor_fn_violation": 0.010197368421052632,
            "auditor_fp_violation": 0.022904483430799226,
            "ave_precision_score": 0.7902348289802904,
            "fpr": 0.17105263157894737,
            "logloss": 0.9669536227563738,
            "mae": 0.28179066946723447,
            "precision": 0.717391304347826,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8198238003246736,
            "auditor_fn_violation": 0.007600494657421949,
            "auditor_fp_violation": 0.014219795180692637,
            "ave_precision_score": 0.8211429188632082,
            "fpr": 0.14489571899012074,
            "logloss": 0.8340692583432805,
            "mae": 0.26931203905638557,
            "precision": 0.7416829745596869,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 28699,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8212867526812001,
            "auditor_fn_violation": 0.009923245614035089,
            "auditor_fp_violation": 0.019729227582846006,
            "ave_precision_score": 0.821581257171133,
            "fpr": 0.15460526315789475,
            "logloss": 0.8381847654713434,
            "mae": 0.28032136124753765,
            "precision": 0.7329545454545454,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.819480545869002,
            "auditor_fn_violation": 0.017625644374661315,
            "auditor_fp_violation": 0.015425501184354973,
            "ave_precision_score": 0.8199275541526532,
            "fpr": 0.1437980241492865,
            "logloss": 0.8154607499182103,
            "mae": 0.2764712448403706,
            "precision": 0.7326530612244898,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.633145506941714,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6351815358021898,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6383335848922647,
            "mae": 0.4562974446044679,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6405492896454301,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6405370931505618,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6418921757571763,
            "mae": 0.45937808667658186,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.804751991340921,
            "auditor_fn_violation": 0.01723318713450293,
            "auditor_fp_violation": 0.02888188352826511,
            "ave_precision_score": 0.8052588368704937,
            "fpr": 0.15460526315789475,
            "logloss": 1.072545684595341,
            "mae": 0.28490608657381694,
            "precision": 0.7272727272727273,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.832742106287808,
            "auditor_fn_violation": 0.015981417925310434,
            "auditor_fp_violation": 0.024950578613287387,
            "ave_precision_score": 0.8329871390522734,
            "fpr": 0.13062568605927552,
            "logloss": 0.9433528637596614,
            "mae": 0.26409771369203006,
            "precision": 0.7551440329218106,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6654005698908996,
            "auditor_fn_violation": 0.007161458333333334,
            "auditor_fp_violation": 0.0033376989928525064,
            "ave_precision_score": 0.5345854572134692,
            "fpr": 0.4331140350877193,
            "logloss": 0.69274319428043,
            "mae": 0.4975393363519719,
            "precision": 0.5240963855421686,
            "recall": 0.90625
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.668692665621694,
            "auditor_fn_violation": 0.007693127133441714,
            "auditor_fp_violation": 0.008249038575056466,
            "ave_precision_score": 0.5415160856289387,
            "fpr": 0.424807903402854,
            "logloss": 0.6893770680616679,
            "mae": 0.4959478732914092,
            "precision": 0.532043530834341,
            "recall": 0.9282700421940928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8254976212555465,
            "auditor_fn_violation": 0.007293951023391815,
            "auditor_fp_violation": 0.024871568388564004,
            "ave_precision_score": 0.8257916969674464,
            "fpr": 0.1699561403508772,
            "logloss": 0.7550891869989006,
            "mae": 0.2865695109432338,
            "precision": 0.7150735294117647,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8233690031761763,
            "auditor_fn_violation": 0.019647348163792752,
            "auditor_fp_violation": 0.015294883033958212,
            "ave_precision_score": 0.8238005676383549,
            "fpr": 0.1525795828759605,
            "logloss": 0.734904707240576,
            "mae": 0.28191418745762514,
            "precision": 0.7263779527559056,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6507296372823742,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.647032136986503,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7274919726590453,
            "mae": 0.4677070433175878,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6456832152787016,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6412094760747511,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7264072135264644,
            "mae": 0.46732241105038824,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6507296372823742,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.647032136986503,
            "fpr": 0.0043859649122807015,
            "logloss": 0.7274923813097218,
            "mae": 0.46770712578048307,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6456832152787016,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6412094760747511,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7264076669342786,
            "mae": 0.46732250891388705,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5999119641183821,
            "auditor_fn_violation": 0.004166666666666665,
            "auditor_fp_violation": 0.004040773229369727,
            "ave_precision_score": 0.5174801299925447,
            "fpr": 0.3607456140350877,
            "logloss": 0.6986812147374482,
            "mae": 0.5006381354637837,
            "precision": 0.5161764705882353,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6206124695940263,
            "auditor_fn_violation": 0.0057895297512354895,
            "auditor_fp_violation": 0.016862300838719244,
            "ave_precision_score": 0.5325777002681802,
            "fpr": 0.3424807903402854,
            "logloss": 0.6901355110314523,
            "mae": 0.4962896002961566,
            "precision": 0.5329341317365269,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5468500973399081,
            "auditor_fn_violation": 0.029970760233918134,
            "auditor_fp_violation": 0.05340826023391813,
            "ave_precision_score": 0.5397005012609358,
            "fpr": 0.3355263157894737,
            "logloss": 0.889859722363538,
            "mae": 0.49123019112834476,
            "precision": 0.5590778097982709,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5063183474314514,
            "auditor_fn_violation": 0.028878174399162605,
            "auditor_fp_violation": 0.040981444686981144,
            "ave_precision_score": 0.5312376646612325,
            "fpr": 0.36223929747530187,
            "logloss": 0.8447416866801335,
            "mae": 0.4908474000683553,
            "precision": 0.541029207232267,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.805909135596919,
            "auditor_fn_violation": 0.010101425438596493,
            "auditor_fp_violation": 0.02156432748538013,
            "ave_precision_score": 0.8064485730772577,
            "fpr": 0.15789473684210525,
            "logloss": 0.893390908746075,
            "mae": 0.2778058911941801,
            "precision": 0.7288135593220338,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.833996220586923,
            "auditor_fn_violation": 0.00930956383998666,
            "auditor_fp_violation": 0.017173774889665344,
            "ave_precision_score": 0.8342673098726163,
            "fpr": 0.13062568605927552,
            "logloss": 0.7985173959648425,
            "mae": 0.264197754691315,
            "precision": 0.7566462167689162,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.81754407577506,
            "auditor_fn_violation": 0.009523483187134507,
            "auditor_fp_violation": 0.026346247563352836,
            "ave_precision_score": 0.8178760991697074,
            "fpr": 0.17982456140350878,
            "logloss": 0.7964472915400782,
            "mae": 0.2875248132402927,
            "precision": 0.7045045045045045,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8141766867187537,
            "auditor_fn_violation": 0.02210674040211759,
            "auditor_fp_violation": 0.021845885653856877,
            "ave_precision_score": 0.8146702660193098,
            "fpr": 0.15697036223929747,
            "logloss": 0.7804940381739525,
            "mae": 0.28478369404239207,
            "precision": 0.720703125,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7931509859523849,
            "auditor_fn_violation": 0.014775219298245617,
            "auditor_fp_violation": 0.02642239278752437,
            "ave_precision_score": 0.7937233715560366,
            "fpr": 0.1425438596491228,
            "logloss": 1.0898879489685205,
            "mae": 0.286505742051106,
            "precision": 0.7363083164300203,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8290621370578922,
            "auditor_fn_violation": 0.017929015733626052,
            "auditor_fp_violation": 0.023945823610235437,
            "ave_precision_score": 0.8293393392145254,
            "fpr": 0.11525795828759605,
            "logloss": 0.957953956865716,
            "mae": 0.2681607395248618,
            "precision": 0.7702407002188184,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7984447800055363,
            "auditor_fn_violation": 0.015350877192982459,
            "auditor_fp_violation": 0.022584673489278752,
            "ave_precision_score": 0.7989419748939297,
            "fpr": 0.17214912280701755,
            "logloss": 0.8876544654585438,
            "mae": 0.2973958124026525,
            "precision": 0.7097966728280961,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8235931014182458,
            "auditor_fn_violation": 0.010814841575307892,
            "auditor_fp_violation": 0.01738728532781389,
            "ave_precision_score": 0.8238849070335126,
            "fpr": 0.141602634467618,
            "logloss": 0.7473044695724057,
            "mae": 0.27189819894614,
            "precision": 0.7445544554455445,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8021739587388032,
            "auditor_fn_violation": 0.015510782163742695,
            "auditor_fp_violation": 0.0238029970760234,
            "ave_precision_score": 0.8026997383662723,
            "fpr": 0.13815789473684212,
            "logloss": 1.0610237732527812,
            "mae": 0.28350417867396754,
            "precision": 0.7418032786885246,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.834138593562274,
            "auditor_fn_violation": 0.01683132089279181,
            "auditor_fp_violation": 0.025043518451069693,
            "ave_precision_score": 0.8343977953184484,
            "fpr": 0.11525795828759605,
            "logloss": 0.9410713917300324,
            "mae": 0.2660608107699263,
            "precision": 0.7702407002188184,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7996888229804073,
            "auditor_fn_violation": 0.015853435672514623,
            "auditor_fp_violation": 0.025257370857699808,
            "ave_precision_score": 0.8002269560313211,
            "fpr": 0.14144736842105263,
            "logloss": 1.0555083212803957,
            "mae": 0.28419466873541327,
            "precision": 0.7383367139959433,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8324839318515257,
            "auditor_fn_violation": 0.017929015733626052,
            "auditor_fp_violation": 0.023945823610235437,
            "ave_precision_score": 0.8327470578622844,
            "fpr": 0.11525795828759605,
            "logloss": 0.9411227704981072,
            "mae": 0.2662595674029829,
            "precision": 0.7702407002188184,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 28699,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5250708439182074,
            "auditor_fn_violation": 0.03251096491228071,
            "auditor_fp_violation": 0.029564652371669917,
            "ave_precision_score": 0.5531008752744926,
            "fpr": 0.32456140350877194,
            "logloss": 0.786299575789464,
            "mae": 0.5125518381562933,
            "precision": 0.5083056478405316,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5501756809193726,
            "auditor_fn_violation": 0.04047576039683753,
            "auditor_fp_violation": 0.041968616477479674,
            "ave_precision_score": 0.5644703330203925,
            "fpr": 0.31394072447859495,
            "logloss": 0.7722791335336489,
            "mae": 0.5043314900147012,
            "precision": 0.5168918918918919,
            "recall": 0.6455696202531646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5201120367225174,
            "auditor_fn_violation": 0.04848547149122807,
            "auditor_fp_violation": 0.053636695906432746,
            "ave_precision_score": 0.5497736352951936,
            "fpr": 0.18859649122807018,
            "logloss": 0.7689200627255225,
            "mae": 0.5096860711479134,
            "precision": 0.5437665782493368,
            "recall": 0.4270833333333333
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5563807323663384,
            "auditor_fn_violation": 0.04273599281171987,
            "auditor_fp_violation": 0.059164998354713685,
            "ave_precision_score": 0.5649433722341952,
            "fpr": 0.1712403951701427,
            "logloss": 0.7551194025650747,
            "mae": 0.5014702482915736,
            "precision": 0.5617977528089888,
            "recall": 0.4219409282700422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8056163280872979,
            "auditor_fn_violation": 0.017852247807017548,
            "auditor_fp_violation": 0.030496162280701764,
            "ave_precision_score": 0.8061211953847982,
            "fpr": 0.1524122807017544,
            "logloss": 1.0751941000946923,
            "mae": 0.2840817032283763,
            "precision": 0.7295719844357976,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8334685062883547,
            "auditor_fn_violation": 0.017468169165427715,
            "auditor_fp_violation": 0.024330142398902813,
            "ave_precision_score": 0.83373923953406,
            "fpr": 0.12952799121844127,
            "logloss": 0.9471590419569504,
            "mae": 0.2639104385640087,
            "precision": 0.756701030927835,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8235295757814313,
            "auditor_fn_violation": 0.01194718567251462,
            "auditor_fp_violation": 0.021823221247563356,
            "ave_precision_score": 0.8238212405261802,
            "fpr": 0.1600877192982456,
            "logloss": 0.746393941012337,
            "mae": 0.28491849292596544,
            "precision": 0.7250470809792844,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8221461270913173,
            "auditor_fn_violation": 0.022905695507788083,
            "auditor_fp_violation": 0.017000454651638883,
            "ave_precision_score": 0.8226191057058417,
            "fpr": 0.14709110867178923,
            "logloss": 0.7319544222741966,
            "mae": 0.28279216348837,
            "precision": 0.7303822937625755,
            "recall": 0.7658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8038004976087282,
            "auditor_fn_violation": 0.017854532163742692,
            "auditor_fp_violation": 0.02561525341130605,
            "ave_precision_score": 0.8043135750327856,
            "fpr": 0.15460526315789475,
            "logloss": 1.0653763211654999,
            "mae": 0.2847045939629786,
            "precision": 0.7272727272727273,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8329093810195408,
            "auditor_fn_violation": 0.015270463671858718,
            "auditor_fp_violation": 0.024689342312493884,
            "ave_precision_score": 0.8331799841782539,
            "fpr": 0.12843029637760703,
            "logloss": 0.935389484211517,
            "mae": 0.263917966406288,
            "precision": 0.7577639751552795,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6422076180468397,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6434273484160957,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6380853413441906,
            "mae": 0.45540384846951876,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6570935708679829,
            "auditor_fn_violation": 0.01213022273478859,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6576426885693011,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6385559187392429,
            "mae": 0.4569616680218543,
            "precision": 0.9574468085106383,
            "recall": 0.189873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5206806784588205,
            "auditor_fn_violation": 0.03698145102339182,
            "auditor_fp_violation": 0.04516934697855752,
            "ave_precision_score": 0.5498740162366346,
            "fpr": 0.20614035087719298,
            "logloss": 0.7822683205785392,
            "mae": 0.510987278286433,
            "precision": 0.5425790754257908,
            "recall": 0.46458333333333335
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5408572822149857,
            "auditor_fn_violation": 0.036691723751430025,
            "auditor_fp_violation": 0.04355864126980938,
            "ave_precision_score": 0.5544392481209779,
            "fpr": 0.1964873765093304,
            "logloss": 0.7695086793001699,
            "mae": 0.5033923981283943,
            "precision": 0.537467700258398,
            "recall": 0.4388185654008439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.795282788655223,
            "auditor_fn_violation": 0.013395467836257316,
            "auditor_fp_violation": 0.028326023391812866,
            "ave_precision_score": 0.7958453296143153,
            "fpr": 0.16776315789473684,
            "logloss": 1.2049716163111355,
            "mae": 0.29543428143654366,
            "precision": 0.7107750472589792,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8186838880186609,
            "auditor_fn_violation": 0.017178692677865943,
            "auditor_fp_violation": 0.02431507107385703,
            "ave_precision_score": 0.8189762283415127,
            "fpr": 0.13830954994511527,
            "logloss": 1.0396284135377416,
            "mae": 0.2709109978260235,
            "precision": 0.7459677419354839,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7991178296063692,
            "auditor_fn_violation": 0.015853435672514623,
            "auditor_fp_violation": 0.025257370857699808,
            "ave_precision_score": 0.7996590131677979,
            "fpr": 0.14144736842105263,
            "logloss": 1.0503131221968711,
            "mae": 0.2846405635053716,
            "precision": 0.7383367139959433,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.832471145716375,
            "auditor_fn_violation": 0.017197219173069888,
            "auditor_fp_violation": 0.02444568922425379,
            "ave_precision_score": 0.8327344528326146,
            "fpr": 0.1163556531284303,
            "logloss": 0.9337880808953283,
            "mae": 0.26640700031938125,
            "precision": 0.7690631808278867,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8258268144015319,
            "auditor_fn_violation": 0.010615405701754387,
            "auditor_fp_violation": 0.02617872807017544,
            "ave_precision_score": 0.8261154448287589,
            "fpr": 0.17763157894736842,
            "logloss": 0.7769701316072567,
            "mae": 0.2849520246901405,
            "precision": 0.7081081081081081,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8210280068510757,
            "auditor_fn_violation": 0.022384637830176888,
            "auditor_fp_violation": 0.019444521196562734,
            "ave_precision_score": 0.8214016504653024,
            "fpr": 0.15587266739846323,
            "logloss": 0.7617540516602559,
            "mae": 0.2826026586661074,
            "precision": 0.7237354085603113,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8094140984468567,
            "auditor_fn_violation": 0.00885416666666667,
            "auditor_fp_violation": 0.01958201348278103,
            "ave_precision_score": 0.809999609687689,
            "fpr": 0.16557017543859648,
            "logloss": 0.8971843509364714,
            "mae": 0.27607163318369754,
            "precision": 0.7229357798165138,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8362315216526538,
            "auditor_fn_violation": 0.008619451893639388,
            "auditor_fp_violation": 0.016636230963032562,
            "ave_precision_score": 0.8364962799648076,
            "fpr": 0.1437980241492865,
            "logloss": 0.7983067856976981,
            "mae": 0.26319288493343657,
            "precision": 0.7416173570019724,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7992907734750074,
            "auditor_fn_violation": 0.015533625730994155,
            "auditor_fp_violation": 0.023960363872644583,
            "ave_precision_score": 0.7998320805888575,
            "fpr": 0.14035087719298245,
            "logloss": 1.057164737897851,
            "mae": 0.2843973009503804,
            "precision": 0.7403651115618661,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8321138848988962,
            "auditor_fn_violation": 0.017197219173069888,
            "auditor_fp_violation": 0.02454365283705135,
            "ave_precision_score": 0.8323819573643203,
            "fpr": 0.1141602634467618,
            "logloss": 0.939337001088406,
            "mae": 0.2660461521410515,
            "precision": 0.7724288840262582,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6527552607938633,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6601731836493568,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6411271534263949,
            "mae": 0.4544200866172711,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6370175229967749,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0019416890433978805,
            "ave_precision_score": 0.6404187279811169,
            "fpr": 0.005488474204171241,
            "logloss": 0.6464155324705275,
            "mae": 0.4577673226329125,
            "precision": 0.9468085106382979,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6171089655669877,
            "auditor_fn_violation": 0.03698145102339182,
            "auditor_fp_violation": 0.04516934697855752,
            "ave_precision_score": 0.5364382823671777,
            "fpr": 0.20614035087719298,
            "logloss": 0.7872693243792772,
            "mae": 0.5112112152896691,
            "precision": 0.5425790754257908,
            "recall": 0.46458333333333335
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.6074292926081617,
            "auditor_fn_violation": 0.036691723751430025,
            "auditor_fp_violation": 0.046515132866289714,
            "ave_precision_score": 0.5363219199556187,
            "fpr": 0.19758507135016465,
            "logloss": 0.7755345468424427,
            "mae": 0.5042076272119151,
            "precision": 0.5360824742268041,
            "recall": 0.4388185654008439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8048414555833122,
            "auditor_fn_violation": 0.01723318713450293,
            "auditor_fp_violation": 0.02888188352826511,
            "ave_precision_score": 0.8053509129901074,
            "fpr": 0.15460526315789475,
            "logloss": 1.0721849425354741,
            "mae": 0.28493487238184695,
            "precision": 0.7272727272727273,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8327992237970518,
            "auditor_fn_violation": 0.015981417925310434,
            "auditor_fp_violation": 0.024950578613287387,
            "ave_precision_score": 0.8330674541633671,
            "fpr": 0.13062568605927552,
            "logloss": 0.942912543109447,
            "mae": 0.264116280442779,
            "precision": 0.7551440329218106,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6422082673355044,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6434155558463135,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6380853377783794,
            "mae": 0.4554038471623994,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6571597810584838,
            "auditor_fn_violation": 0.01213022273478859,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6576378324716611,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6385559163518626,
            "mae": 0.45696166759657414,
            "precision": 0.9574468085106383,
            "recall": 0.189873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.805909135596919,
            "auditor_fn_violation": 0.010101425438596493,
            "auditor_fp_violation": 0.02156432748538013,
            "ave_precision_score": 0.8064485730772577,
            "fpr": 0.15789473684210525,
            "logloss": 0.8933841899137867,
            "mae": 0.27780601756906004,
            "precision": 0.7288135593220338,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.833996220586923,
            "auditor_fn_violation": 0.00930956383998666,
            "auditor_fp_violation": 0.017173774889665344,
            "ave_precision_score": 0.8342673098726163,
            "fpr": 0.13062568605927552,
            "logloss": 0.798511208434486,
            "mae": 0.26419771814160015,
            "precision": 0.7566462167689162,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8204408647753951,
            "auditor_fn_violation": 0.011622807017543861,
            "auditor_fp_violation": 0.020219095191682915,
            "ave_precision_score": 0.8207390673397942,
            "fpr": 0.15570175438596492,
            "logloss": 0.839468817841057,
            "mae": 0.28112294512584046,
            "precision": 0.7300380228136882,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8189329847012763,
            "auditor_fn_violation": 0.018558916570560476,
            "auditor_fp_violation": 0.015425501184354973,
            "ave_precision_score": 0.8192238480644427,
            "fpr": 0.1437980241492865,
            "logloss": 0.8157830983936807,
            "mae": 0.27703192978560154,
            "precision": 0.7358870967741935,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8008539781336523,
            "auditor_fn_violation": 0.010743329678362577,
            "auditor_fp_violation": 0.024533991228070175,
            "ave_precision_score": 0.8013411720691186,
            "fpr": 0.17763157894736842,
            "logloss": 0.9958185511133094,
            "mae": 0.2911717655305643,
            "precision": 0.7070524412296564,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8210800854054399,
            "auditor_fn_violation": 0.01177127189021199,
            "auditor_fp_violation": 0.014732220232249115,
            "ave_precision_score": 0.8213708758878585,
            "fpr": 0.14928649835345773,
            "logloss": 0.8679760240940978,
            "mae": 0.27067423873232044,
            "precision": 0.7359223300970874,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8196863596658972,
            "auditor_fn_violation": 0.010485197368421056,
            "auditor_fp_violation": 0.027686403508771933,
            "ave_precision_score": 0.8200011245549059,
            "fpr": 0.17763157894736842,
            "logloss": 0.785399409628662,
            "mae": 0.2861475848985954,
            "precision": 0.7065217391304348,
            "recall": 0.8125
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8170266247159186,
            "auditor_fn_violation": 0.022342953215967985,
            "auditor_fp_violation": 0.01699543087662362,
            "ave_precision_score": 0.817513374714453,
            "fpr": 0.15697036223929747,
            "logloss": 0.7690108745157855,
            "mae": 0.2834617339139541,
            "precision": 0.720703125,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8058395419721469,
            "auditor_fn_violation": 0.008317342836257308,
            "auditor_fp_violation": 0.02156432748538013,
            "ave_precision_score": 0.8063784206263848,
            "fpr": 0.15789473684210525,
            "logloss": 0.8922972795962251,
            "mae": 0.2778330282692855,
            "precision": 0.7298311444652908,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8339970903053219,
            "auditor_fn_violation": 0.009467039049220272,
            "auditor_fp_violation": 0.016678933050662266,
            "ave_precision_score": 0.8342668273294754,
            "fpr": 0.12952799121844127,
            "logloss": 0.7977107980335193,
            "mae": 0.26415164161028265,
            "precision": 0.7586912065439673,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7929545110864171,
            "auditor_fn_violation": 0.014446271929824565,
            "auditor_fp_violation": 0.0266609811565952,
            "ave_precision_score": 0.7935169577834102,
            "fpr": 0.14692982456140352,
            "logloss": 1.096631804968956,
            "mae": 0.28676620256938107,
            "precision": 0.7309236947791165,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8279189759696801,
            "auditor_fn_violation": 0.021222100256128806,
            "auditor_fp_violation": 0.021047105426430592,
            "ave_precision_score": 0.8281890776974673,
            "fpr": 0.11745334796926454,
            "logloss": 0.9722287878059483,
            "mae": 0.2692573687097684,
            "precision": 0.7668845315904139,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7951204719251832,
            "auditor_fn_violation": 0.01408305921052632,
            "auditor_fp_violation": 0.030057058154645877,
            "ave_precision_score": 0.7956789534987847,
            "fpr": 0.16557017543859648,
            "logloss": 1.2320178966641497,
            "mae": 0.2955023353193578,
            "precision": 0.7129277566539924,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8163012859319172,
            "auditor_fn_violation": 0.019663558847096203,
            "auditor_fp_violation": 0.02487522198805849,
            "ave_precision_score": 0.8165997803783199,
            "fpr": 0.1394072447859495,
            "logloss": 1.0744661255810464,
            "mae": 0.27192901904365885,
            "precision": 0.742914979757085,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.816213042333028,
            "auditor_fn_violation": 0.009678819444444443,
            "auditor_fp_violation": 0.026346247563352836,
            "ave_precision_score": 0.8165597420005379,
            "fpr": 0.17982456140350878,
            "logloss": 0.8015674811223743,
            "mae": 0.2880568460090214,
            "precision": 0.7034358047016275,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8130035418105289,
            "auditor_fn_violation": 0.022083582283112645,
            "auditor_fp_violation": 0.022227692555016623,
            "ave_precision_score": 0.8134971154524807,
            "fpr": 0.16136114160263446,
            "logloss": 0.7866188929843242,
            "mae": 0.2854648942034195,
            "precision": 0.7156673114119922,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6822229171293428,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.10082642949967512,
            "ave_precision_score": 0.6869442264411918,
            "fpr": 0.3048245614035088,
            "logloss": 0.6840819331124005,
            "mae": 0.48944433804666787,
            "precision": 0.5663026521060842,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6734888278825627,
            "auditor_fn_violation": 0.09573566396643,
            "auditor_fp_violation": 0.1050898376567104,
            "ave_precision_score": 0.6774447158663837,
            "fpr": 0.29418221734357847,
            "logloss": 0.6852503665506545,
            "mae": 0.49021236096333987,
            "precision": 0.5620915032679739,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8058948510910717,
            "auditor_fn_violation": 0.01723318713450293,
            "auditor_fp_violation": 0.030577383853151403,
            "ave_precision_score": 0.8064010759359623,
            "fpr": 0.15679824561403508,
            "logloss": 1.0484700586794904,
            "mae": 0.2846370148704668,
            "precision": 0.7244701348747592,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8341774558887775,
            "auditor_fn_violation": 0.016020786727618835,
            "auditor_fp_violation": 0.025103803751252807,
            "ave_precision_score": 0.8344431430395116,
            "fpr": 0.132821075740944,
            "logloss": 0.9191469479052173,
            "mae": 0.26309576169452464,
            "precision": 0.7515400410677618,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.795887202123962,
            "auditor_fn_violation": 0.01419270833333334,
            "auditor_fp_violation": 0.024848724821312545,
            "ave_precision_score": 0.796391346748961,
            "fpr": 0.16885964912280702,
            "logloss": 0.9112641027624451,
            "mae": 0.2984272827765078,
            "precision": 0.7121495327102804,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8221382952113492,
            "auditor_fn_violation": 0.00917061512595701,
            "auditor_fp_violation": 0.0161690198866134,
            "ave_precision_score": 0.822431132744988,
            "fpr": 0.1394072447859495,
            "logloss": 0.7671768851114498,
            "mae": 0.27213431412622896,
            "precision": 0.7454909819639278,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.766077248459341,
            "auditor_fn_violation": 0.007775950292397659,
            "auditor_fp_violation": 0.017391569200779743,
            "ave_precision_score": 0.7655597637914792,
            "fpr": 0.17434210526315788,
            "logloss": 1.101099831762,
            "mae": 0.2879846924709568,
            "precision": 0.7124773960216998,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7380340633003479,
            "auditor_fn_violation": 0.010821789011009376,
            "auditor_fp_violation": 0.011037233708525607,
            "ave_precision_score": 0.7385000800450727,
            "fpr": 0.16245883644346873,
            "logloss": 1.0624600183974662,
            "mae": 0.2875064817950957,
            "precision": 0.7115009746588694,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7952496175461081,
            "auditor_fn_violation": 0.013395467836257316,
            "auditor_fp_violation": 0.026955409356725153,
            "ave_precision_score": 0.795742854310409,
            "fpr": 0.16776315789473684,
            "logloss": 1.18907525007169,
            "mae": 0.2959661255583163,
            "precision": 0.7107750472589792,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8191994475724742,
            "auditor_fn_violation": 0.017178692677865943,
            "auditor_fp_violation": 0.02431507107385703,
            "ave_precision_score": 0.8194892455277052,
            "fpr": 0.13830954994511527,
            "logloss": 1.0245087348842041,
            "mae": 0.2712554193872319,
            "precision": 0.7459677419354839,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6381286795522579,
            "auditor_fn_violation": 0.005505299707602355,
            "auditor_fp_violation": 0.0012792397660818717,
            "ave_precision_score": 0.6215842895948318,
            "fpr": 0.021929824561403508,
            "logloss": 0.7249781065339279,
            "mae": 0.46613689782424717,
            "precision": 0.8461538461538461,
            "recall": 0.22916666666666666
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6442218667021034,
            "auditor_fn_violation": 0.01659047645514042,
            "auditor_fp_violation": 0.0004295327638047066,
            "ave_precision_score": 0.626659532594877,
            "fpr": 0.019758507135016465,
            "logloss": 0.7241475688498117,
            "mae": 0.46519292819055064,
            "precision": 0.8524590163934426,
            "recall": 0.21940928270042195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8165804561226859,
            "auditor_fn_violation": 0.00849780701754386,
            "auditor_fp_violation": 0.025965521442495126,
            "ave_precision_score": 0.8169197771357847,
            "fpr": 0.18092105263157895,
            "logloss": 0.7971321519035631,
            "mae": 0.28810239432549223,
            "precision": 0.7027027027027027,
            "recall": 0.8125
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8133920254763781,
            "auditor_fn_violation": 0.02157410366500392,
            "auditor_fp_violation": 0.02165247031576938,
            "ave_precision_score": 0.8138844124851308,
            "fpr": 0.15916575192096596,
            "logloss": 0.7815354868920411,
            "mae": 0.28557542437828376,
            "precision": 0.7184466019417476,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7922688458339021,
            "auditor_fn_violation": 0.014288651315789472,
            "auditor_fp_violation": 0.023574561403508776,
            "ave_precision_score": 0.7927807645536586,
            "fpr": 0.17105263157894737,
            "logloss": 0.9320714168741886,
            "mae": 0.30049388872015426,
            "precision": 0.7062146892655368,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8188200703543318,
            "auditor_fn_violation": 0.012074643249176726,
            "auditor_fp_violation": 0.014365484656135161,
            "ave_precision_score": 0.8191189535868287,
            "fpr": 0.14050493962678376,
            "logloss": 0.7837312421749412,
            "mae": 0.27346939909675305,
            "precision": 0.7455268389662028,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6692528907743361,
            "auditor_fn_violation": 0.001973684210526328,
            "auditor_fp_violation": 0.0025889376218323585,
            "ave_precision_score": 0.6646351100111919,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6330229111678969,
            "mae": 0.4532135362295728,
            "precision": 0.9611650485436893,
            "recall": 0.20625
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6447501329895622,
            "auditor_fn_violation": 0.010590207820959947,
            "auditor_fp_violation": 0.0013940975667345713,
            "ave_precision_score": 0.6445673332522233,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6382641666760474,
            "mae": 0.45761283209831605,
            "precision": 0.956989247311828,
            "recall": 0.1877637130801688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8077722697388385,
            "auditor_fn_violation": 0.007538377192982456,
            "auditor_fp_violation": 0.02176738141650423,
            "ave_precision_score": 0.8083037870709411,
            "fpr": 0.15679824561403508,
            "logloss": 0.872482184707407,
            "mae": 0.27799191126685524,
            "precision": 0.7317073170731707,
            "recall": 0.8125
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8356370803737125,
            "auditor_fn_violation": 0.008369344208386021,
            "auditor_fp_violation": 0.017173774889665344,
            "ave_precision_score": 0.83590227078731,
            "fpr": 0.13062568605927552,
            "logloss": 0.7780797707454733,
            "mae": 0.2641486356994016,
            "precision": 0.7571428571428571,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.6052441833946897,
            "auditor_fn_violation": 0.041906524122807015,
            "auditor_fp_violation": 0.024899488304093585,
            "ave_precision_score": 0.5976533173556184,
            "fpr": 0.24342105263157895,
            "logloss": 1.0280800341403178,
            "mae": 0.48773069989769474,
            "precision": 0.5033557046979866,
            "recall": 0.46875
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.6207061783274382,
            "auditor_fn_violation": 0.03839847712209423,
            "auditor_fp_violation": 0.03751755181395957,
            "ave_precision_score": 0.6132041903724532,
            "fpr": 0.23710208562019758,
            "logloss": 0.9941314338909376,
            "mae": 0.4757709469662572,
            "precision": 0.5294117647058824,
            "recall": 0.5126582278481012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7946901437301794,
            "auditor_fn_violation": 0.013660453216374272,
            "auditor_fp_violation": 0.024000974658869398,
            "ave_precision_score": 0.7951958901732344,
            "fpr": 0.17105263157894737,
            "logloss": 0.8911070236137726,
            "mae": 0.3009637793137423,
            "precision": 0.7089552238805971,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.821500324337409,
            "auditor_fn_violation": 0.011576743690570483,
            "auditor_fp_violation": 0.01635489956217801,
            "ave_precision_score": 0.8217964195038465,
            "fpr": 0.13830954994511527,
            "logloss": 0.7472476269280851,
            "mae": 0.2742317602847355,
            "precision": 0.7474949899799599,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8262135885604782,
            "auditor_fn_violation": 0.010615405701754387,
            "auditor_fp_violation": 0.026754893599740096,
            "ave_precision_score": 0.8265000270997276,
            "fpr": 0.17653508771929824,
            "logloss": 0.774562056096216,
            "mae": 0.2847361768800828,
            "precision": 0.7093862815884476,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.821355139917975,
            "auditor_fn_violation": 0.022384637830176888,
            "auditor_fp_violation": 0.017605819540977678,
            "ave_precision_score": 0.8217345453900456,
            "fpr": 0.15587266739846323,
            "logloss": 0.7589532362696205,
            "mae": 0.28235248869547697,
            "precision": 0.7237354085603113,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6454226335291069,
            "auditor_fn_violation": 0.005105537280701763,
            "auditor_fp_violation": 0.009086663417803769,
            "ave_precision_score": 0.6463762488671914,
            "fpr": 0.02412280701754386,
            "logloss": 0.6376345364464371,
            "mae": 0.4551151124270339,
            "precision": 0.8267716535433071,
            "recall": 0.21875
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6651180833737202,
            "auditor_fn_violation": 0.007385124150675996,
            "auditor_fp_violation": 0.012584556413225591,
            "ave_precision_score": 0.6655513542811774,
            "fpr": 0.03402854006586169,
            "logloss": 0.6384283618169757,
            "mae": 0.4568377600903045,
            "precision": 0.7753623188405797,
            "recall": 0.22573839662447256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.6614191299642086,
            "auditor_fn_violation": 0.03529102704678362,
            "auditor_fp_violation": 0.023993360136452258,
            "ave_precision_score": 0.6027183911201847,
            "fpr": 0.24013157894736842,
            "logloss": 1.0210678447809125,
            "mae": 0.4856732849403399,
            "precision": 0.5239130434782608,
            "recall": 0.5020833333333333
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.6911392319777282,
            "auditor_fn_violation": 0.03828963396277102,
            "auditor_fp_violation": 0.037721014702077595,
            "ave_precision_score": 0.6336305874907753,
            "fpr": 0.22502744237102085,
            "logloss": 0.9894505460055555,
            "mae": 0.47428313727591814,
            "precision": 0.5474613686534217,
            "recall": 0.5232067510548524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6229538310968771,
            "auditor_fn_violation": 0.006469298245614037,
            "auditor_fp_violation": 0.01841699155295647,
            "ave_precision_score": 0.6173751706567085,
            "fpr": 0.15350877192982457,
            "logloss": 1.0345519771587914,
            "mae": 0.48790643726508215,
            "precision": 0.573170731707317,
            "recall": 0.39166666666666666
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6390357971156337,
            "auditor_fn_violation": 0.0021953896816684984,
            "auditor_fp_violation": 0.01846237318107946,
            "ave_precision_score": 0.6310680315498783,
            "fpr": 0.1350164654226125,
            "logloss": 1.001182136585595,
            "mae": 0.47562393693521243,
            "precision": 0.5993485342019544,
            "recall": 0.3881856540084388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7902678929195848,
            "auditor_fn_violation": 0.015385142543859651,
            "auditor_fp_violation": 0.03023473034437947,
            "ave_precision_score": 0.7908330393947243,
            "fpr": 0.14583333333333334,
            "logloss": 1.1388692458449206,
            "mae": 0.2877511770583791,
            "precision": 0.7318548387096774,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8258052128783415,
            "auditor_fn_violation": 0.021752421181341967,
            "auditor_fp_violation": 0.02159720879060153,
            "ave_precision_score": 0.8260773699360351,
            "fpr": 0.11855104281009879,
            "logloss": 1.0073752001053047,
            "mae": 0.27067335237647117,
            "precision": 0.7647058823529411,
            "recall": 0.740506329113924
        }
    }
]