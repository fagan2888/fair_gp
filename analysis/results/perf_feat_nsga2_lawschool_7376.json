[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7911452951031721,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7311259282381084,
            "fpr": 0.10197368421052631,
            "logloss": 2.9992271073269317,
            "mae": 0.3888434922289953,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7565259448544344,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6815898782878544,
            "fpr": 0.1251372118551043,
            "logloss": 3.8012938404512586,
            "mae": 0.41360000446520573,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7877423992670005,
            "auditor_fn_violation": 0.000622753638660546,
            "auditor_fp_violation": 0.0027817903948415355,
            "ave_precision_score": 0.726347845889334,
            "fpr": 0.45285087719298245,
            "logloss": 3.131828860220321,
            "mae": 0.4098897281658362,
            "precision": 0.543646408839779,
            "recall": 0.9979716024340771
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7543652331640438,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0029857299670691694,
            "ave_precision_score": 0.677169703527488,
            "fpr": 0.48737650933040616,
            "logloss": 3.9093466100084955,
            "mae": 0.4358381175576136,
            "precision": 0.5093922651933702,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7868311544871333,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7223407118903418,
            "fpr": 0.10197368421052631,
            "logloss": 2.959552809543576,
            "mae": 0.3966727645969705,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7531931333608044,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6727852338388047,
            "fpr": 0.1251372118551043,
            "logloss": 3.7574889881389244,
            "mae": 0.4187335609146583,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7595495935189255,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7055759591963033,
            "fpr": 0.10197368421052631,
            "logloss": 2.9577290528542455,
            "mae": 0.39757659678396423,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7304704227770907,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6608219528381654,
            "fpr": 0.1251372118551043,
            "logloss": 3.755236157374695,
            "mae": 0.4192933809220725,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.5997014158376166,
            "auditor_fn_violation": 0.01041777872673571,
            "auditor_fp_violation": 0.014442804505296662,
            "ave_precision_score": 0.6003591717882971,
            "fpr": 0.19846491228070176,
            "logloss": 0.685334586134559,
            "mae": 0.4877624005712916,
            "precision": 0.559610705596107,
            "recall": 0.4665314401622718
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5766298442150188,
            "auditor_fn_violation": 0.00958637620216635,
            "auditor_fp_violation": 0.020129284059031593,
            "ave_precision_score": 0.5771826455896142,
            "fpr": 0.2261251372118551,
            "logloss": 0.6778885722523329,
            "mae": 0.48712917099861197,
            "precision": 0.5130023640661938,
            "recall": 0.47071583514099785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 7376,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6330583595326065,
            "auditor_fn_violation": 0.07657868047400448,
            "auditor_fp_violation": 0.0772620692542813,
            "ave_precision_score": 0.6338783452852674,
            "fpr": 0.26864035087719296,
            "logloss": 0.6684645945393723,
            "mae": 0.4793384252851339,
            "precision": 0.6073717948717948,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5884397936648252,
            "auditor_fn_violation": 0.08502968062080478,
            "auditor_fp_violation": 0.10129527991218443,
            "ave_precision_score": 0.5893397285729549,
            "fpr": 0.2864983534577388,
            "logloss": 0.6703611744524405,
            "mae": 0.48191237936264597,
            "precision": 0.5620805369127517,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7853630067698818,
            "auditor_fn_violation": 0.018195526849578317,
            "auditor_fp_violation": 0.01628511912238831,
            "ave_precision_score": 0.7218137138625343,
            "fpr": 0.10416666666666667,
            "logloss": 2.9564017410621006,
            "mae": 0.3974911743742332,
            "precision": 0.7513089005235603,
            "recall": 0.5821501014198783
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.750091474365326,
            "auditor_fn_violation": 0.00010953137240428896,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6704637826035668,
            "fpr": 0.1251372118551043,
            "logloss": 3.7535683419210293,
            "mae": 0.4189885893323419,
            "precision": 0.6976127320954907,
            "recall": 0.5704989154013015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 7376,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6329511996989904,
            "auditor_fn_violation": 0.07657868047400448,
            "auditor_fp_violation": 0.0772620692542813,
            "ave_precision_score": 0.6337693947362777,
            "fpr": 0.26864035087719296,
            "logloss": 0.6698163253617198,
            "mae": 0.480213475340095,
            "precision": 0.6073717948717948,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5884335618263625,
            "auditor_fn_violation": 0.08502968062080478,
            "auditor_fp_violation": 0.10342724722527138,
            "ave_precision_score": 0.5893306341682416,
            "fpr": 0.2854006586169045,
            "logloss": 0.6704936409364077,
            "mae": 0.48214262389423557,
            "precision": 0.5630252100840336,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5758734594870016,
            "auditor_fn_violation": 0.00831820931639445,
            "auditor_fp_violation": 0.016842523971025425,
            "ave_precision_score": 0.5768522771851387,
            "fpr": 0.21162280701754385,
            "logloss": 0.688407036476579,
            "mae": 0.4893146904469815,
            "precision": 0.5404761904761904,
            "recall": 0.460446247464503
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5749303705765918,
            "auditor_fn_violation": 0.010138795297770564,
            "auditor_fp_violation": 0.020221978290035372,
            "ave_precision_score": 0.5755315672752765,
            "fpr": 0.2261251372118551,
            "logloss": 0.6779361032233902,
            "mae": 0.4871283498460797,
            "precision": 0.5152941176470588,
            "recall": 0.4750542299349241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7787102371032939,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7233039374079141,
            "fpr": 0.10197368421052631,
            "logloss": 2.9564965218213044,
            "mae": 0.39792283634214026,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7478789749557769,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6767501621780813,
            "fpr": 0.1251372118551043,
            "logloss": 3.753697694188197,
            "mae": 0.4194091712865819,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.8141133121932609,
            "auditor_fn_violation": 0.01788415003024804,
            "auditor_fp_violation": 0.0074582338902147985,
            "ave_precision_score": 0.758774641517233,
            "fpr": 0.0712719298245614,
            "logloss": 2.882893762185658,
            "mae": 0.40154901731824666,
            "precision": 0.796875,
            "recall": 0.5172413793103449
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7799803425599655,
            "auditor_fn_violation": 0.00015477259144083374,
            "auditor_fp_violation": 0.01268935236004391,
            "ave_precision_score": 0.7119202829382295,
            "fpr": 0.09440175631174534,
            "logloss": 3.4634144170432215,
            "mae": 0.42053852430682803,
            "precision": 0.7378048780487805,
            "recall": 0.5249457700650759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 7376,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.524834518639772,
            "auditor_fn_violation": 0.021794153232981037,
            "auditor_fp_violation": 0.024724699577105054,
            "ave_precision_score": 0.5257653665687448,
            "fpr": 0.04057017543859649,
            "logloss": 0.6895377260476406,
            "mae": 0.49348299930754463,
            "precision": 0.5375,
            "recall": 0.0872210953346856
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.48868993885557804,
            "auditor_fn_violation": 0.018036959694836065,
            "auditor_fp_violation": 0.029813391877058178,
            "ave_precision_score": 0.4906859728774834,
            "fpr": 0.048298572996706916,
            "logloss": 0.6860264931108074,
            "mae": 0.4923748448245743,
            "precision": 0.5111111111111111,
            "recall": 0.09978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5437960068423123,
            "auditor_fn_violation": 0.02531938365182734,
            "auditor_fp_violation": 0.026860109701461292,
            "ave_precision_score": 0.5446422979038079,
            "fpr": 0.044956140350877194,
            "logloss": 0.6883187944886842,
            "mae": 0.49284747272337737,
            "precision": 0.5444444444444444,
            "recall": 0.09939148073022312
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.49557781278270396,
            "auditor_fn_violation": 0.024787425798447987,
            "auditor_fp_violation": 0.03332601536772777,
            "ave_precision_score": 0.49756905334983137,
            "fpr": 0.05378704720087816,
            "logloss": 0.686141543082802,
            "mae": 0.49240924177525724,
            "precision": 0.5288461538461539,
            "recall": 0.1193058568329718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8444703573232817,
            "auditor_fn_violation": 0.011634372442261842,
            "auditor_fp_violation": 0.03246294435372442,
            "ave_precision_score": 0.8446984811550116,
            "fpr": 0.26864035087719296,
            "logloss": 1.7497359042690424,
            "mae": 0.3159445162143625,
            "precision": 0.6489971346704871,
            "recall": 0.9188640973630832
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8600378764308252,
            "auditor_fn_violation": 0.005857547306837855,
            "auditor_fp_violation": 0.027069154774972563,
            "ave_precision_score": 0.8602369753230457,
            "fpr": 0.28210757409440174,
            "logloss": 1.656451671827942,
            "mae": 0.3177979740300897,
            "precision": 0.6226138032305433,
            "recall": 0.9197396963123644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 7376,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.617038780671636,
            "auditor_fn_violation": 0.009029927760577943,
            "auditor_fp_violation": 0.013385567139806558,
            "ave_precision_score": 0.6178800377729335,
            "fpr": 0.03618421052631579,
            "logloss": 0.680894619017617,
            "mae": 0.4879298078370068,
            "precision": 0.6526315789473685,
            "recall": 0.1257606490872211
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5787625220724941,
            "auditor_fn_violation": 0.010503106166854374,
            "auditor_fp_violation": 0.015004268813269914,
            "ave_precision_score": 0.5796648447258047,
            "fpr": 0.04500548847420417,
            "logloss": 0.6770884727819413,
            "mae": 0.4873104614055379,
            "precision": 0.5287356321839081,
            "recall": 0.09978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7853082010736666,
            "auditor_fn_violation": 0.01929201807764849,
            "auditor_fp_violation": 0.01887325712850144,
            "ave_precision_score": 0.713964172680694,
            "fpr": 0.10416666666666667,
            "logloss": 2.9596156133134333,
            "mae": 0.39886024042048995,
            "precision": 0.7513089005235603,
            "recall": 0.5821501014198783
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.754143809213627,
            "auditor_fn_violation": 0.004219338954356377,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6680139862614966,
            "fpr": 0.1251372118551043,
            "logloss": 3.7457257833350086,
            "mae": 0.4166417717933655,
            "precision": 0.7007874015748031,
            "recall": 0.579175704989154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8114741404882442,
            "auditor_fn_violation": 0.026057791537667695,
            "auditor_fp_violation": 0.01494787087049366,
            "ave_precision_score": 0.808938112350447,
            "fpr": 0.12828947368421054,
            "logloss": 0.9475404352359026,
            "mae": 0.27884685968430795,
            "precision": 0.7631578947368421,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7881925061965356,
            "auditor_fn_violation": 0.0028501967993028138,
            "auditor_fp_violation": 0.022188071716062935,
            "ave_precision_score": 0.7858707545730135,
            "fpr": 0.13611416026344675,
            "logloss": 1.041190247546157,
            "mae": 0.28395294963201234,
            "precision": 0.7389473684210527,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8444663761486516,
            "auditor_fn_violation": 0.011634372442261842,
            "auditor_fp_violation": 0.03246294435372442,
            "ave_precision_score": 0.8446943352572296,
            "fpr": 0.26864035087719296,
            "logloss": 1.749867861308446,
            "mae": 0.3159650511255391,
            "precision": 0.6489971346704871,
            "recall": 0.9188640973630832
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8600718001831389,
            "auditor_fn_violation": 0.005857547306837855,
            "auditor_fp_violation": 0.027069154774972563,
            "ave_precision_score": 0.8602710008615888,
            "fpr": 0.28210757409440174,
            "logloss": 1.6566122220219661,
            "mae": 0.31783330994203257,
            "precision": 0.6226138032305433,
            "recall": 0.9197396963123644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7911925674875415,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7310733984500959,
            "fpr": 0.10197368421052631,
            "logloss": 2.977088355002328,
            "mae": 0.39002595969328757,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7565358730517548,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6814561715722466,
            "fpr": 0.1251372118551043,
            "logloss": 3.7788567031105726,
            "mae": 0.4145188444466805,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6897211734578421,
            "auditor_fn_violation": 0.0023709120671862216,
            "auditor_fp_violation": 0.006170707197588259,
            "ave_precision_score": 0.5276539621207114,
            "fpr": 0.44298245614035087,
            "logloss": 12.580586332634853,
            "mae": 0.4521952453315225,
            "precision": 0.545045045045045,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.679958958171182,
            "auditor_fn_violation": 0.002995444923578057,
            "auditor_fp_violation": 0.005820221978290057,
            "ave_precision_score": 0.5016484578357991,
            "fpr": 0.47310647639956094,
            "logloss": 13.49475979356674,
            "mae": 0.4835146159488568,
            "precision": 0.5118912797281994,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7550680881395034,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.022602374073608843,
            "ave_precision_score": 0.7412829399810593,
            "fpr": 0.3081140350877193,
            "logloss": 1.05636162625211,
            "mae": 0.3498516093665003,
            "precision": 0.6207827260458839,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7635038597909579,
            "auditor_fn_violation": 0.004119332049117677,
            "auditor_fp_violation": 0.023524820100012202,
            "ave_precision_score": 0.7443295021043441,
            "fpr": 0.3336992316136114,
            "logloss": 1.1125146556469832,
            "mae": 0.3707831968808398,
            "precision": 0.5858310626702997,
            "recall": 0.9327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8193364837495942,
            "auditor_fn_violation": 0.012855414398064126,
            "auditor_fp_violation": 0.020665850186325004,
            "ave_precision_score": 0.7668719387181046,
            "fpr": 0.2236842105263158,
            "logloss": 3.0365915915368675,
            "mae": 0.2839246561805866,
            "precision": 0.6851851851851852,
            "recall": 0.9006085192697769
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.782884062434233,
            "auditor_fn_violation": 0.004550314188360627,
            "auditor_fp_violation": 0.02742041712403953,
            "ave_precision_score": 0.7147391538179338,
            "fpr": 0.23380900109769484,
            "logloss": 3.7824395278197893,
            "mae": 0.2952430717580541,
            "precision": 0.660828025477707,
            "recall": 0.9002169197396963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 7376,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8528794281303292,
            "auditor_fn_violation": 0.008582879612825169,
            "auditor_fp_violation": 0.02611690323661183,
            "ave_precision_score": 0.8531199333587123,
            "fpr": 0.2817982456140351,
            "logloss": 1.8061505402703388,
            "mae": 0.31108979467433273,
            "precision": 0.6410614525139665,
            "recall": 0.9310344827586207
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.869137817758048,
            "auditor_fn_violation": 0.005771827102347544,
            "auditor_fp_violation": 0.029725576289791448,
            "ave_precision_score": 0.8693204687455125,
            "fpr": 0.29198682766191,
            "logloss": 1.7200027478946869,
            "mae": 0.3160875249085653,
            "precision": 0.6150506512301013,
            "recall": 0.9219088937093276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.609972787282114,
            "auditor_fn_violation": 0.0975810469378314,
            "auditor_fp_violation": 0.07825388351547125,
            "ave_precision_score": 0.6108250865198381,
            "fpr": 0.22478070175438597,
            "logloss": 0.6847170324383305,
            "mae": 0.48727517113334134,
            "precision": 0.599609375,
            "recall": 0.6227180527383367
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5807795622173076,
            "auditor_fn_violation": 0.08943474668489015,
            "auditor_fp_violation": 0.08963288205878767,
            "ave_precision_score": 0.5816761085217895,
            "fpr": 0.23600439077936333,
            "logloss": 0.6757017977700106,
            "mae": 0.486274901938136,
            "precision": 0.5708582834331337,
            "recall": 0.6203904555314533
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8339334165799968,
            "auditor_fn_violation": 0.012254901960784322,
            "auditor_fp_violation": 0.009645982498011137,
            "ave_precision_score": 0.7914557410800624,
            "fpr": 0.09100877192982457,
            "logloss": 0.5359937075114031,
            "mae": 0.36390450243887146,
            "precision": 0.8087557603686636,
            "recall": 0.7119675456389453
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8372069641175462,
            "auditor_fn_violation": 0.005876596241169044,
            "auditor_fp_violation": 0.0115965361629467,
            "ave_precision_score": 0.7900893739513646,
            "fpr": 0.07025246981339188,
            "logloss": 0.5191804695270478,
            "mae": 0.35667579524161785,
            "precision": 0.8367346938775511,
            "recall": 0.7114967462039046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 7376,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6170694349867758,
            "auditor_fn_violation": 0.020201683214120525,
            "auditor_fp_violation": 0.02531089059163422,
            "ave_precision_score": 0.6179074597911041,
            "fpr": 0.05701754385964912,
            "logloss": 0.6804807603088663,
            "mae": 0.48766169512415664,
            "precision": 0.6090225563909775,
            "recall": 0.1643002028397566
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5788351914965639,
            "auditor_fn_violation": 0.017863138169064065,
            "auditor_fp_violation": 0.023490669593852914,
            "ave_precision_score": 0.5797374613576455,
            "fpr": 0.06915477497255763,
            "logloss": 0.6765495799063023,
            "mae": 0.4869927529298775,
            "precision": 0.5190839694656488,
            "recall": 0.1475054229934924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.6169743027977886,
            "auditor_fn_violation": 0.021551724137931064,
            "auditor_fp_violation": 0.028534941171544613,
            "ave_precision_score": 0.6178148530898612,
            "fpr": 0.06359649122807018,
            "logloss": 0.6865396911737611,
            "mae": 0.4889310559681913,
            "precision": 0.5972222222222222,
            "recall": 0.1744421906693712
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5792735336882111,
            "auditor_fn_violation": 0.020822866340771157,
            "auditor_fp_violation": 0.023490669593852914,
            "ave_precision_score": 0.5801755666695476,
            "fpr": 0.06915477497255763,
            "logloss": 0.6765202356117042,
            "mae": 0.4867278606366084,
            "precision": 0.5367647058823529,
            "recall": 0.15835140997830802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.815410176574624,
            "auditor_fn_violation": 0.019069606063841144,
            "auditor_fp_violation": 0.013278273248754344,
            "ave_precision_score": 0.7629492633364554,
            "fpr": 0.13157894736842105,
            "logloss": 2.916433912802416,
            "mae": 0.2795219717936242,
            "precision": 0.7614314115308151,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7815128199217248,
            "auditor_fn_violation": 0.0030740217776941744,
            "auditor_fp_violation": 0.022724722527137458,
            "ave_precision_score": 0.7133691914051297,
            "fpr": 0.1394072447859495,
            "logloss": 3.6802545392724064,
            "mae": 0.28498328584537697,
            "precision": 0.7348643006263048,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7984106016790247,
            "auditor_fn_violation": 0.018633678516778777,
            "auditor_fp_violation": 0.016033894401875814,
            "ave_precision_score": 0.7445835859103151,
            "fpr": 0.11513157894736842,
            "logloss": 3.1924748793072086,
            "mae": 0.31639295658602146,
            "precision": 0.7569444444444444,
            "recall": 0.6632860040567952
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7584287925791433,
            "auditor_fn_violation": 0.0004738422414881102,
            "auditor_fp_violation": 0.016758141236736183,
            "ave_precision_score": 0.6887994365171528,
            "fpr": 0.12733260153677278,
            "logloss": 3.96393096906534,
            "mae": 0.33293340704631874,
            "precision": 0.722488038277512,
            "recall": 0.6550976138828634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.78217473952066,
            "auditor_fn_violation": 0.03952039073342586,
            "auditor_fp_violation": 0.06189810744043881,
            "ave_precision_score": 0.7310821163828792,
            "fpr": 0.2598684210526316,
            "logloss": 2.8707587858109096,
            "mae": 0.38626683205783546,
            "precision": 0.6319875776397516,
            "recall": 0.8255578093306288
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7457722649422036,
            "auditor_fn_violation": 0.04681037500208349,
            "auditor_fp_violation": 0.07227710696426394,
            "ave_precision_score": 0.6825275456915063,
            "fpr": 0.2843029637760702,
            "logloss": 3.445382468310951,
            "mae": 0.404864012334574,
            "precision": 0.594679186228482,
            "recall": 0.824295010845987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8339544550986225,
            "auditor_fn_violation": 0.012254901960784322,
            "auditor_fp_violation": 0.009645982498011137,
            "ave_precision_score": 0.791476741782462,
            "fpr": 0.09100877192982457,
            "logloss": 0.5387967878001413,
            "mae": 0.3640768456414726,
            "precision": 0.8087557603686636,
            "recall": 0.7119675456389453
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8372461110931003,
            "auditor_fn_violation": 0.005876596241169044,
            "auditor_fp_violation": 0.009062080741553851,
            "ave_precision_score": 0.7901280863323985,
            "fpr": 0.07135016465422613,
            "logloss": 0.5189467392108478,
            "mae": 0.3567050126402687,
            "precision": 0.8346055979643766,
            "recall": 0.7114967462039046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8156072676395297,
            "auditor_fn_violation": 0.02236130386818974,
            "auditor_fp_violation": 0.013278273248754344,
            "ave_precision_score": 0.7631462601713848,
            "fpr": 0.13157894736842105,
            "logloss": 2.9113733430523636,
            "mae": 0.28011888765251025,
            "precision": 0.7609561752988048,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7817766874359702,
            "auditor_fn_violation": 0.003835979150941373,
            "auditor_fp_violation": 0.022724722527137458,
            "ave_precision_score": 0.713632911467569,
            "fpr": 0.1394072447859495,
            "logloss": 3.675353037825077,
            "mae": 0.28549020055887975,
            "precision": 0.7365145228215768,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8576577235419872,
            "auditor_fn_violation": 0.010095281306715064,
            "auditor_fp_violation": 0.024374031738056363,
            "ave_precision_score": 0.8578891608503572,
            "fpr": 0.27631578947368424,
            "logloss": 1.7809883274162595,
            "mae": 0.30614105081022325,
            "precision": 0.6455696202531646,
            "recall": 0.9310344827586207
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8644595227996007,
            "auditor_fn_violation": 0.005093208816799257,
            "auditor_fp_violation": 0.028920600073179654,
            "ave_precision_score": 0.8647130594040087,
            "fpr": 0.2810098792535675,
            "logloss": 1.7060002036177673,
            "mae": 0.3114871050176979,
            "precision": 0.6229749631811488,
            "recall": 0.9175704989154013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6926474744695895,
            "auditor_fn_violation": 0.0023709120671862216,
            "auditor_fp_violation": 0.006170707197588259,
            "ave_precision_score": 0.5296210458231372,
            "fpr": 0.44298245614035087,
            "logloss": 12.59596035756935,
            "mae": 0.452193311121651,
            "precision": 0.545045045045045,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6810393288919894,
            "auditor_fn_violation": 0.002995444923578057,
            "auditor_fp_violation": 0.005820221978290057,
            "ave_precision_score": 0.5016395040864376,
            "fpr": 0.47310647639956094,
            "logloss": 13.548197830177948,
            "mae": 0.4834600372358415,
            "precision": 0.5118912797281994,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7261586146140845,
            "auditor_fn_violation": 0.005482456140350881,
            "auditor_fp_violation": 0.00877978059707742,
            "ave_precision_score": 0.7204598206846344,
            "fpr": 0.044956140350877194,
            "logloss": 1.3187105016362406,
            "mae": 0.4291791157501693,
            "precision": 0.788659793814433,
            "recall": 0.3103448275862069
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7321162673928199,
            "auditor_fn_violation": 0.006779039505108686,
            "auditor_fp_violation": 0.006139773143066228,
            "ave_precision_score": 0.7202960775295827,
            "fpr": 0.042810098792535674,
            "logloss": 1.2361808882017291,
            "mae": 0.4030592114625494,
            "precision": 0.7891891891891892,
            "recall": 0.31670281995661603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8504166975670482,
            "auditor_fn_violation": 0.008476121846197645,
            "auditor_fp_violation": 0.028438114977180424,
            "ave_precision_score": 0.8506665316175412,
            "fpr": 0.26535087719298245,
            "logloss": 1.7786527314022917,
            "mae": 0.30720022049520107,
            "precision": 0.6542857142857142,
            "recall": 0.9290060851926978
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.8642198297250026,
            "auditor_fn_violation": 0.005467044153048664,
            "auditor_fp_violation": 0.03365532381997805,
            "ave_precision_score": 0.8644784224959362,
            "fpr": 0.28210757409440174,
            "logloss": 1.6949015103143095,
            "mae": 0.3117615062371305,
            "precision": 0.623718887262079,
            "recall": 0.9240780911062907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8113373138466586,
            "auditor_fn_violation": 0.026438116081278253,
            "auditor_fp_violation": 0.014814407737721394,
            "ave_precision_score": 0.8087586585383155,
            "fpr": 0.12719298245614036,
            "logloss": 0.9493213428669086,
            "mae": 0.27907266517413837,
            "precision": 0.7642276422764228,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7878893146132747,
            "auditor_fn_violation": 0.0017382152577201757,
            "auditor_fp_violation": 0.022188071716062935,
            "ave_precision_score": 0.7855827128353476,
            "fpr": 0.13611416026344675,
            "logloss": 1.0430450149056787,
            "mae": 0.2842350690278023,
            "precision": 0.7383966244725738,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.6689691232273804,
            "auditor_fn_violation": 0.008233692751147652,
            "auditor_fp_violation": 0.010938743038981702,
            "ave_precision_score": 0.676801896420384,
            "fpr": 0.03070175438596491,
            "logloss": 4.599803479108221,
            "mae": 0.547098615446939,
            "precision": 0.4166666666666667,
            "recall": 0.04056795131845842
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.68297860630459,
            "auditor_fn_violation": 0.010960280590802701,
            "auditor_fp_violation": 0.006147091108671791,
            "ave_precision_score": 0.6807684872521167,
            "fpr": 0.021953896816684963,
            "logloss": 4.259167504557268,
            "mae": 0.5032524350966033,
            "precision": 0.5121951219512195,
            "recall": 0.0455531453362256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8449937112339464,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.0265042080140686,
            "ave_precision_score": 0.8452355754294351,
            "fpr": 0.30153508771929827,
            "logloss": 1.8890348216717996,
            "mae": 0.3214082448955691,
            "precision": 0.6258503401360545,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.861298219658765,
            "auditor_fn_violation": 0.004119332049117677,
            "auditor_fp_violation": 0.024461519697524088,
            "ave_precision_score": 0.8615330297311825,
            "fpr": 0.32711306256860595,
            "logloss": 1.7962655185303689,
            "mae": 0.33021002206399336,
            "precision": 0.5906593406593407,
            "recall": 0.9327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8028378806000558,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.022602374073608843,
            "ave_precision_score": 0.8041507645789349,
            "fpr": 0.3081140350877193,
            "logloss": 2.3320087445870166,
            "mae": 0.34005404361769176,
            "precision": 0.6207827260458839,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.8414034626718507,
            "auditor_fn_violation": 0.0047479468820466175,
            "auditor_fp_violation": 0.023524820100012202,
            "ave_precision_score": 0.8420785292292393,
            "fpr": 0.3336992316136114,
            "logloss": 2.279813034239336,
            "mae": 0.3610021209612164,
            "precision": 0.5852660300136425,
            "recall": 0.93058568329718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7260808735806655,
            "auditor_fn_violation": 0.007337372335504094,
            "auditor_fp_violation": 0.0070787798852740445,
            "ave_precision_score": 0.7274059637046566,
            "fpr": 0.04057017543859649,
            "logloss": 0.6268500660517058,
            "mae": 0.44640293240285756,
            "precision": 0.8294930875576036,
            "recall": 0.36511156186612576
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6853878962891177,
            "auditor_fn_violation": 0.00929587995361586,
            "auditor_fp_violation": 0.008649835345773878,
            "ave_precision_score": 0.6869363738945233,
            "fpr": 0.048298572996706916,
            "logloss": 0.6321728768314135,
            "mae": 0.4498993589672639,
            "precision": 0.7777777777777778,
            "recall": 0.33405639913232105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.6681768144386047,
            "auditor_fn_violation": 0.008233692751147652,
            "auditor_fp_violation": 0.010938743038981702,
            "ave_precision_score": 0.6760755398916404,
            "fpr": 0.03070175438596491,
            "logloss": 3.922658604476486,
            "mae": 0.546399373866271,
            "precision": 0.4166666666666667,
            "recall": 0.04056795131845842
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.6828694090681886,
            "auditor_fn_violation": 0.010829319167275838,
            "auditor_fp_violation": 0.006156848396145872,
            "ave_precision_score": 0.6806596280594631,
            "fpr": 0.024149286498353458,
            "logloss": 3.63075065357508,
            "mae": 0.5024174345596453,
            "precision": 0.5111111111111111,
            "recall": 0.049891540130151846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7885896469244251,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7232172659693114,
            "fpr": 0.10197368421052631,
            "logloss": 2.9567655809657576,
            "mae": 0.3983548138159932,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.752731684253867,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6706661160550382,
            "fpr": 0.1251372118551043,
            "logloss": 3.7539590356486725,
            "mae": 0.41981423454017724,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8104149931862447,
            "auditor_fn_violation": 0.026057791537667695,
            "auditor_fp_violation": 0.013170979357702143,
            "ave_precision_score": 0.8079020549745224,
            "fpr": 0.12609649122807018,
            "logloss": 0.9591241823773711,
            "mae": 0.2795409198003829,
            "precision": 0.766260162601626,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7878175171306969,
            "auditor_fn_violation": 0.0028501967993028138,
            "auditor_fp_violation": 0.0229906086108062,
            "ave_precision_score": 0.7854289242635176,
            "fpr": 0.13721185510428102,
            "logloss": 1.0541785935606525,
            "mae": 0.28441612982793285,
            "precision": 0.7373949579831933,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7873203316469286,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.022602374073608843,
            "ave_precision_score": 0.7201751982144806,
            "fpr": 0.3081140350877193,
            "logloss": 3.0595891037694196,
            "mae": 0.3438771934745825,
            "precision": 0.6207827260458839,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7559211691639265,
            "auditor_fn_violation": 0.004119332049117677,
            "auditor_fp_violation": 0.023524820100012202,
            "ave_precision_score": 0.6738612569461057,
            "fpr": 0.3336992316136114,
            "logloss": 3.8222169156597006,
            "mae": 0.3564649900619828,
            "precision": 0.5858310626702997,
            "recall": 0.9327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.8404453286948116,
            "auditor_fn_violation": 0.008582879612825169,
            "auditor_fp_violation": 0.023007997320269653,
            "ave_precision_score": 0.8407053406125755,
            "fpr": 0.28289473684210525,
            "logloss": 1.8682634425150177,
            "mae": 0.31652905586126606,
            "precision": 0.6401673640167364,
            "recall": 0.9310344827586207
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8641040300038878,
            "auditor_fn_violation": 0.0038074057494446065,
            "auditor_fp_violation": 0.027420417124039517,
            "ave_precision_score": 0.8642836405448188,
            "fpr": 0.29747530186608123,
            "logloss": 1.7663551559958566,
            "mae": 0.31805820525935663,
            "precision": 0.6123032904148784,
            "recall": 0.928416485900217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7583922184612443,
            "auditor_fn_violation": 0.006690153375324724,
            "auditor_fp_violation": 0.0034752753004228952,
            "ave_precision_score": 0.7592314522420385,
            "fpr": 0.01206140350877193,
            "logloss": 0.7637198531643251,
            "mae": 0.3970112322717988,
            "precision": 0.9185185185185185,
            "recall": 0.2515212981744422
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7545900683596849,
            "auditor_fn_violation": 0.003438332646777991,
            "auditor_fp_violation": 0.001980729357238688,
            "ave_precision_score": 0.7553912874518706,
            "fpr": 0.008781558726673985,
            "logloss": 0.7334407490227941,
            "mae": 0.3885727145675109,
            "precision": 0.9354838709677419,
            "recall": 0.25162689804772237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7896398579107369,
            "auditor_fn_violation": 0.01702563965695171,
            "auditor_fp_violation": 0.010428442825440695,
            "ave_precision_score": 0.7371528057086854,
            "fpr": 0.13267543859649122,
            "logloss": 2.967486877268153,
            "mae": 0.36454501481759444,
            "precision": 0.7425531914893617,
            "recall": 0.7079107505070994
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7601941403830532,
            "auditor_fn_violation": 0.0012524674322750946,
            "auditor_fp_violation": 0.015367727771679473,
            "ave_precision_score": 0.6919940815213471,
            "fpr": 0.13721185510428102,
            "logloss": 3.7298826086269083,
            "mae": 0.37553407395775834,
            "precision": 0.7184684684684685,
            "recall": 0.6919739696312365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.859887516609067,
            "auditor_fn_violation": 0.009650457279100388,
            "auditor_fp_violation": 0.029495352342670523,
            "ave_precision_score": 0.8602558647009111,
            "fpr": 0.26096491228070173,
            "logloss": 1.8992505792577665,
            "mae": 0.29721053764877614,
            "precision": 0.6580459770114943,
            "recall": 0.9290060851926978
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8622876065540653,
            "auditor_fn_violation": 0.005676582430691642,
            "auditor_fp_violation": 0.028957189901207474,
            "ave_precision_score": 0.8625510148630997,
            "fpr": 0.2623490669593853,
            "logloss": 1.8426552661370204,
            "mae": 0.306331211155123,
            "precision": 0.6406015037593985,
            "recall": 0.9240780911062907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7776674528723286,
            "auditor_fn_violation": 0.020715454966015446,
            "auditor_fp_violation": 0.018535673910312776,
            "ave_precision_score": 0.7177217505575181,
            "fpr": 0.1118421052631579,
            "logloss": 2.956319099762688,
            "mae": 0.3972766024893836,
            "precision": 0.745,
            "recall": 0.6044624746450304
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7411395638154094,
            "auditor_fn_violation": 0.001681068454726646,
            "auditor_fp_violation": 0.017460665934870105,
            "ave_precision_score": 0.6664054587735122,
            "fpr": 0.13611416026344675,
            "logloss": 3.7554517655389734,
            "mae": 0.41994843439788904,
            "precision": 0.6828644501278772,
            "recall": 0.579175704989154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.719308921678239,
            "auditor_fn_violation": 0.005629248069463735,
            "auditor_fp_violation": 0.008476217393124819,
            "ave_precision_score": 0.7150573992313389,
            "fpr": 0.043859649122807015,
            "logloss": 1.3919857200347077,
            "mae": 0.4426938615126815,
            "precision": 0.7530864197530864,
            "recall": 0.24746450304259635
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7122765573700565,
            "auditor_fn_violation": 0.009762578844729773,
            "auditor_fp_violation": 0.0034101719721917304,
            "ave_precision_score": 0.6998120662159454,
            "fpr": 0.036223929747530186,
            "logloss": 1.3049697251317063,
            "mae": 0.4173561932034004,
            "precision": 0.7659574468085106,
            "recall": 0.23427331887201736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6040688415217448,
            "auditor_fn_violation": 0.0723750934130458,
            "auditor_fp_violation": 0.07977955030775029,
            "ave_precision_score": 0.604965258764915,
            "fpr": 0.2883771929824561,
            "logloss": 0.6801778757026193,
            "mae": 0.48341460911691875,
            "precision": 0.5941358024691358,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.588880839012294,
            "auditor_fn_violation": 0.07895783280274114,
            "auditor_fp_violation": 0.10167093547993661,
            "ave_precision_score": 0.5897647915588454,
            "fpr": 0.29527991218441274,
            "logloss": 0.6712119106891999,
            "mae": 0.4824044059051669,
            "precision": 0.5611745513866232,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8612493593306205,
            "auditor_fn_violation": 0.01989030639479022,
            "auditor_fp_violation": 0.005621153121467155,
            "ave_precision_score": 0.8614551596665142,
            "fpr": 0.0625,
            "logloss": 1.6626243741779172,
            "mae": 0.3093100039231215,
            "precision": 0.8523316062176166,
            "recall": 0.6673427991886409
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8709068539476676,
            "auditor_fn_violation": 0.002676375273530793,
            "auditor_fp_violation": 0.009137699719477987,
            "ave_precision_score": 0.8712033741365399,
            "fpr": 0.048298572996706916,
            "logloss": 1.558617821752441,
            "mae": 0.2917719516416543,
            "precision": 0.8735632183908046,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8094235866464132,
            "auditor_fn_violation": 0.02579089712109889,
            "auditor_fp_violation": 0.016164740610476076,
            "ave_precision_score": 0.8068754077558601,
            "fpr": 0.1162280701754386,
            "logloss": 0.9724769449735509,
            "mae": 0.2814506258658009,
            "precision": 0.7730192719486081,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7863280264251649,
            "auditor_fn_violation": 0.006509973307680765,
            "auditor_fp_violation": 0.021880717160629344,
            "ave_precision_score": 0.7838552185574895,
            "fpr": 0.13172338090010977,
            "logloss": 1.0649152357717993,
            "mae": 0.28601991768791435,
            "precision": 0.7391304347826086,
            "recall": 0.737527114967462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7191639060697421,
            "auditor_fn_violation": 0.013996388028895773,
            "auditor_fp_violation": 0.008476217393124819,
            "ave_precision_score": 0.7189696873908551,
            "fpr": 0.043859649122807015,
            "logloss": 1.3738410277806017,
            "mae": 0.43876013752243365,
            "precision": 0.7837837837837838,
            "recall": 0.29411764705882354
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7268777288214938,
            "auditor_fn_violation": 0.010017358341409287,
            "auditor_fp_violation": 0.005439687766800831,
            "ave_precision_score": 0.7157927266413978,
            "fpr": 0.038419319429198684,
            "logloss": 1.2875803169310183,
            "mae": 0.41239431837815815,
            "precision": 0.7904191616766467,
            "recall": 0.28633405639913234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5995718895699389,
            "auditor_fn_violation": 0.012061403508771934,
            "auditor_fp_violation": 0.014442804505296662,
            "ave_precision_score": 0.6003618523330643,
            "fpr": 0.19846491228070176,
            "logloss": 0.6853738382889878,
            "mae": 0.48778600944461414,
            "precision": 0.5617433414043583,
            "recall": 0.47058823529411764
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5766083694141628,
            "auditor_fn_violation": 0.00958637620216635,
            "auditor_fp_violation": 0.020129284059031593,
            "ave_precision_score": 0.5772024449992398,
            "fpr": 0.2261251372118551,
            "logloss": 0.6778780540707641,
            "mae": 0.48712578294267134,
            "precision": 0.5130023640661938,
            "recall": 0.47071583514099785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8339519709804327,
            "auditor_fn_violation": 0.012254901960784322,
            "auditor_fp_violation": 0.009645982498011137,
            "ave_precision_score": 0.7914742954804984,
            "fpr": 0.09100877192982457,
            "logloss": 0.5368547543678485,
            "mae": 0.3647479567300986,
            "precision": 0.8087557603686636,
            "recall": 0.7119675456389453
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8372019018893723,
            "auditor_fn_violation": 0.005876596241169044,
            "auditor_fp_violation": 0.009062080741553851,
            "ave_precision_score": 0.7900843247842122,
            "fpr": 0.07135016465422613,
            "logloss": 0.5197138223060831,
            "mae": 0.3572341042124021,
            "precision": 0.8346055979643766,
            "recall": 0.7114967462039046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8095137030814092,
            "auditor_fn_violation": 0.025766431799580096,
            "auditor_fp_violation": 0.014869363145333506,
            "ave_precision_score": 0.8069698712110502,
            "fpr": 0.11842105263157894,
            "logloss": 0.9716835222047175,
            "mae": 0.2811954487002814,
            "precision": 0.7711864406779662,
            "recall": 0.7383367139959433
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7864183579169236,
            "auditor_fn_violation": 0.007407654338037631,
            "auditor_fp_violation": 0.021788022929625568,
            "ave_precision_score": 0.7839525134393358,
            "fpr": 0.13391877058177826,
            "logloss": 1.0656601033340933,
            "mae": 0.28581295648546795,
            "precision": 0.735357917570499,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8578034566649522,
            "auditor_fn_violation": 0.009501441229849472,
            "auditor_fp_violation": 0.027299752962358162,
            "ave_precision_score": 0.8580347675354203,
            "fpr": 0.2543859649122807,
            "logloss": 1.747634176401928,
            "mae": 0.3024385938126794,
            "precision": 0.6627906976744186,
            "recall": 0.9249492900608519
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8646946056039211,
            "auditor_fn_violation": 0.005093208816799257,
            "auditor_fp_violation": 0.028703500426881325,
            "ave_precision_score": 0.8649468228677031,
            "fpr": 0.2645444566410538,
            "logloss": 1.6703618456412124,
            "mae": 0.30517676920843767,
            "precision": 0.6370481927710844,
            "recall": 0.9175704989154013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8093922730892145,
            "auditor_fn_violation": 0.02687404362834063,
            "auditor_fp_violation": 0.014657392287401082,
            "ave_precision_score": 0.8068642708484987,
            "fpr": 0.1206140350877193,
            "logloss": 0.9624392071121539,
            "mae": 0.2804397726233634,
            "precision": 0.7689075630252101,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7865926324534805,
            "auditor_fn_violation": 0.00041907655528596364,
            "auditor_fp_violation": 0.02578363215026223,
            "ave_precision_score": 0.784201369273311,
            "fpr": 0.13611416026344675,
            "logloss": 1.0535483772129897,
            "mae": 0.28501692297842873,
            "precision": 0.7367303609341825,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.6679028089415591,
            "auditor_fn_violation": 0.008233692751147652,
            "auditor_fp_violation": 0.010938743038981702,
            "ave_precision_score": 0.6759437422913112,
            "fpr": 0.03070175438596491,
            "logloss": 3.705458657706938,
            "mae": 0.5460549856667151,
            "precision": 0.4166666666666667,
            "recall": 0.04056795131845842
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.6842568162445402,
            "auditor_fn_violation": 0.010829319167275838,
            "auditor_fp_violation": 0.006156848396145872,
            "ave_precision_score": 0.6826603603528233,
            "fpr": 0.024149286498353458,
            "logloss": 3.4290203924844094,
            "mae": 0.5019765159114189,
            "precision": 0.5111111111111111,
            "recall": 0.049891540130151846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7223654916609233,
            "auditor_fn_violation": 0.008331554037222886,
            "auditor_fp_violation": 0.01005160574467194,
            "ave_precision_score": 0.7263617153167563,
            "fpr": 0.046052631578947366,
            "logloss": 1.333076283875517,
            "mae": 0.43516391246479935,
            "precision": 0.7485029940119761,
            "recall": 0.2535496957403651
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7529747060459095,
            "auditor_fn_violation": 0.00959113843574915,
            "auditor_fp_violation": 0.006439809732894256,
            "ave_precision_score": 0.7252574335363472,
            "fpr": 0.038419319429198684,
            "logloss": 1.238430415727249,
            "mae": 0.40728010517614227,
            "precision": 0.7619047619047619,
            "recall": 0.24295010845986983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8191750061396985,
            "auditor_fn_violation": 0.013224618340984304,
            "auditor_fp_violation": 0.021419524347862498,
            "ave_precision_score": 0.7667105043117033,
            "fpr": 0.18530701754385964,
            "logloss": 2.984112472409338,
            "mae": 0.2723244134441002,
            "precision": 0.7135593220338983,
            "recall": 0.8539553752535497
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7826257474616789,
            "auditor_fn_violation": 0.004081234180455321,
            "auditor_fp_violation": 0.02925234784729846,
            "ave_precision_score": 0.714480978395041,
            "fpr": 0.19319429198682767,
            "logloss": 3.733819364429786,
            "mae": 0.28137643780696314,
            "precision": 0.6901408450704225,
            "recall": 0.8503253796095445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7408037944262925,
            "auditor_fn_violation": 0.004434895555318331,
            "auditor_fp_violation": 0.009099045346062052,
            "ave_precision_score": 0.7468687629308456,
            "fpr": 0.04824561403508772,
            "logloss": 1.1159530842714829,
            "mae": 0.40003986519300594,
            "precision": 0.8127659574468085,
            "recall": 0.38742393509127787
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7628554477288068,
            "auditor_fn_violation": 0.005736110350476594,
            "auditor_fp_violation": 0.007805829979265765,
            "ave_precision_score": 0.7377252550443653,
            "fpr": 0.043907793633369926,
            "logloss": 1.041390310459453,
            "mae": 0.37925095864219144,
            "precision": 0.8198198198198198,
            "recall": 0.3947939262472885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7845189348292533,
            "auditor_fn_violation": 0.019763531546920045,
            "auditor_fp_violation": 0.01675616547334925,
            "ave_precision_score": 0.7144682995851601,
            "fpr": 0.10197368421052631,
            "logloss": 2.9560041191109727,
            "mae": 0.39881621382869126,
            "precision": 0.7546174142480211,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.751700769266469,
            "auditor_fn_violation": 0.0058480228396722705,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6655427648044453,
            "fpr": 0.1251372118551043,
            "logloss": 3.752864778868299,
            "mae": 0.4200353530837728,
            "precision": 0.6968085106382979,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8059975717290904,
            "auditor_fn_violation": 0.017904167111490697,
            "auditor_fp_violation": 0.009774211782439394,
            "ave_precision_score": 0.736150557811347,
            "fpr": 0.08662280701754387,
            "logloss": 3.1540523431391345,
            "mae": 0.3102472595021282,
            "precision": 0.8039702233250621,
            "recall": 0.6572008113590264
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7682702703694448,
            "auditor_fn_violation": 0.004719373480549849,
            "auditor_fp_violation": 0.01380168313208928,
            "ave_precision_score": 0.6828769945795636,
            "fpr": 0.10208562019758508,
            "logloss": 3.9042023743157315,
            "mae": 0.32577851181767176,
            "precision": 0.7609254498714653,
            "recall": 0.6420824295010846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7329794835199224,
            "auditor_fn_violation": 0.014948311447991178,
            "auditor_fp_violation": 0.011582506385294985,
            "ave_precision_score": 0.7151530379944014,
            "fpr": 0.15460526315789475,
            "logloss": 1.867709993900872,
            "mae": 0.40454468530496296,
            "precision": 0.6954643628509719,
            "recall": 0.6531440162271805
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6844757302167433,
            "auditor_fn_violation": 0.004719373480549849,
            "auditor_fp_violation": 0.005037199658494943,
            "ave_precision_score": 0.6570000739931288,
            "fpr": 0.1525795828759605,
            "logloss": 2.0930357827297397,
            "mae": 0.4120473021235134,
            "precision": 0.6804597701149425,
            "recall": 0.6420824295010846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.802023376769357,
            "auditor_fn_violation": 0.015924700188605388,
            "auditor_fp_violation": 0.02312837583218189,
            "ave_precision_score": 0.7494243962250873,
            "fpr": 0.16776315789473684,
            "logloss": 2.909170764395537,
            "mae": 0.35133633376997814,
            "precision": 0.7161410018552876,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7777537892595232,
            "auditor_fn_violation": 0.002621609587328653,
            "auditor_fp_violation": 0.012611294060251247,
            "ave_precision_score": 0.709475354470262,
            "fpr": 0.15367727771679474,
            "logloss": 3.670476176990752,
            "mae": 0.3592941962861334,
            "precision": 0.7265625,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6096992193626549,
            "auditor_fn_violation": 0.06192617700437707,
            "auditor_fp_violation": 0.07626502114474733,
            "ave_precision_score": 0.610579539733719,
            "fpr": 0.30372807017543857,
            "logloss": 0.6766838107781623,
            "mae": 0.48191862432909066,
            "precision": 0.593245227606461,
            "recall": 0.8194726166328601
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.5902993651984721,
            "auditor_fn_violation": 0.06734988844467832,
            "auditor_fp_violation": 0.10233443102817417,
            "ave_precision_score": 0.591182731653271,
            "fpr": 0.305159165751921,
            "logloss": 0.6706022356173877,
            "mae": 0.4821904756549979,
            "precision": 0.5642633228840125,
            "recall": 0.7809110629067245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8249476382045566,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.022602374073608843,
            "ave_precision_score": 0.8252761773657545,
            "fpr": 0.3081140350877193,
            "logloss": 2.077573484299445,
            "mae": 0.33237805452785996,
            "precision": 0.6207827260458839,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.8454624354797118,
            "auditor_fn_violation": 0.004119332049117677,
            "auditor_fp_violation": 0.023524820100012202,
            "ave_precision_score": 0.8460366543049785,
            "fpr": 0.3336992316136114,
            "logloss": 1.9869517435349606,
            "mae": 0.3453578374519306,
            "precision": 0.5858310626702997,
            "recall": 0.9327548806941431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8083478970195921,
            "auditor_fn_violation": 0.025673018753781012,
            "auditor_fp_violation": 0.01021123811916426,
            "ave_precision_score": 0.8079993637393394,
            "fpr": 0.12280701754385964,
            "logloss": 0.8588088445021775,
            "mae": 0.2853549414578817,
            "precision": 0.7695473251028807,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7938080844815296,
            "auditor_fn_violation": 0.007931500032145078,
            "auditor_fp_violation": 0.024002927186242223,
            "ave_precision_score": 0.7942091808565699,
            "fpr": 0.13611416026344675,
            "logloss": 0.9053359102718403,
            "mae": 0.2904235258408128,
            "precision": 0.740041928721174,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.6519255658996503,
            "auditor_fn_violation": 0.0034273691327710927,
            "auditor_fp_violation": 0.0027294519114014156,
            "ave_precision_score": 0.5582270871384973,
            "fpr": 0.009868421052631578,
            "logloss": 0.6884728515300025,
            "mae": 0.49280721445878345,
            "precision": 0.7352941176470589,
            "recall": 0.05070993914807302
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6619506185338098,
            "auditor_fn_violation": 0.005381323948558364,
            "auditor_fp_violation": 0.004020002439321869,
            "ave_precision_score": 0.5310308460360724,
            "fpr": 0.008781558726673985,
            "logloss": 0.6836226175055988,
            "mae": 0.49103677989230066,
            "precision": 0.7837837837837838,
            "recall": 0.06290672451193059
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8060783386680965,
            "auditor_fn_violation": 0.012995533966762752,
            "auditor_fp_violation": 0.009331951597370514,
            "ave_precision_score": 0.7534876764195946,
            "fpr": 0.125,
            "logloss": 2.9090827594687076,
            "mae": 0.35186578385662615,
            "precision": 0.7659137577002053,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7742360984548463,
            "auditor_fn_violation": 0.005221789123534721,
            "auditor_fp_violation": 0.014416392242956457,
            "ave_precision_score": 0.7059525702923538,
            "fpr": 0.1350164654226125,
            "logloss": 3.6804622508966007,
            "mae": 0.36503578449316265,
            "precision": 0.7426778242677824,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.840707096121061,
            "auditor_fn_violation": 0.009565940713853612,
            "auditor_fp_violation": 0.010342084327764524,
            "ave_precision_score": 0.800625315354856,
            "fpr": 0.07785087719298246,
            "logloss": 0.5399870481943696,
            "mae": 0.3529966897976122,
            "precision": 0.8251231527093597,
            "recall": 0.6795131845841785
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8305542191155463,
            "auditor_fn_violation": 0.002331113338778157,
            "auditor_fp_violation": 0.010140261007439935,
            "ave_precision_score": 0.7874252129534819,
            "fpr": 0.06476399560922064,
            "logloss": 0.532338205212248,
            "mae": 0.3478236422720943,
            "precision": 0.8422459893048129,
            "recall": 0.6832971800433839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.808152554305761,
            "auditor_fn_violation": 0.012234884879541654,
            "auditor_fp_violation": 0.009151383829502157,
            "ave_precision_score": 0.7555687969089433,
            "fpr": 0.13048245614035087,
            "logloss": 2.9125029287705253,
            "mae": 0.3508256348013355,
            "precision": 0.7615230460921844,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7727229453107629,
            "auditor_fn_violation": 0.007231451695474212,
            "auditor_fp_violation": 0.0132455177460666,
            "ave_precision_score": 0.704455989621706,
            "fpr": 0.141602634467618,
            "logloss": 3.691272261382212,
            "mae": 0.36773156279004887,
            "precision": 0.735655737704918,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7180671657872073,
            "auditor_fn_violation": 0.008331554037222886,
            "auditor_fp_violation": 0.01005160574467194,
            "ave_precision_score": 0.720341461886249,
            "fpr": 0.046052631578947366,
            "logloss": 1.3476683302808845,
            "mae": 0.436155718605045,
            "precision": 0.7485029940119761,
            "recall": 0.2535496957403651
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7399168458315284,
            "auditor_fn_violation": 0.00959113843574915,
            "auditor_fp_violation": 0.006439809732894256,
            "ave_precision_score": 0.7277056482859897,
            "fpr": 0.038419319429198684,
            "logloss": 1.2473211867792418,
            "mae": 0.4075434817001525,
            "precision": 0.7619047619047619,
            "recall": 0.24295010845986983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7990545468233944,
            "auditor_fn_violation": 0.015186292302765027,
            "auditor_fp_violation": 0.018208558388812128,
            "ave_precision_score": 0.7458446327377872,
            "fpr": 0.11732456140350878,
            "logloss": 3.2271925784357207,
            "mae": 0.31359284318439107,
            "precision": 0.7551487414187643,
            "recall": 0.6693711967545639
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7616639782489122,
            "auditor_fn_violation": 0.003971702808051034,
            "auditor_fp_violation": 0.01896084888401025,
            "ave_precision_score": 0.6928220051426912,
            "fpr": 0.132821075740944,
            "logloss": 3.995848757502273,
            "mae": 0.32912441212254906,
            "precision": 0.717948717948718,
            "recall": 0.6681127982646421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7819836531495554,
            "auditor_fn_violation": 0.018195526849578317,
            "auditor_fp_violation": 0.01628511912238831,
            "ave_precision_score": 0.7142981621223732,
            "fpr": 0.10416666666666667,
            "logloss": 2.9556494103980477,
            "mae": 0.39791782994411495,
            "precision": 0.7513089005235603,
            "recall": 0.5821501014198783
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7477757649730551,
            "auditor_fn_violation": 0.00010953137240428896,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6651292643472387,
            "fpr": 0.1251372118551043,
            "logloss": 3.752546140248044,
            "mae": 0.4192137396950622,
            "precision": 0.6976127320954907,
            "recall": 0.5704989154013015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7789246862474531,
            "auditor_fn_violation": 0.01929201807764849,
            "auditor_fp_violation": 0.01887325712850144,
            "ave_precision_score": 0.6921383402251056,
            "fpr": 0.10416666666666667,
            "logloss": 2.9601246868173443,
            "mae": 0.40102826866010827,
            "precision": 0.7513089005235603,
            "recall": 0.5821501014198783
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7469333177893145,
            "auditor_fn_violation": 0.004219338954356377,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6452066090320786,
            "fpr": 0.1251372118551043,
            "logloss": 3.7443531050695786,
            "mae": 0.4177219719512533,
            "precision": 0.7007874015748031,
            "recall": 0.579175704989154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.6689691232273804,
            "auditor_fn_violation": 0.008233692751147652,
            "auditor_fp_violation": 0.010938743038981702,
            "ave_precision_score": 0.676801896420384,
            "fpr": 0.03070175438596491,
            "logloss": 4.599799328846544,
            "mae": 0.547098611536747,
            "precision": 0.4166666666666667,
            "recall": 0.04056795131845842
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.68297860630459,
            "auditor_fn_violation": 0.010960280590802701,
            "auditor_fp_violation": 0.006147091108671791,
            "ave_precision_score": 0.6807684872521167,
            "fpr": 0.021953896816684963,
            "logloss": 4.259163664800942,
            "mae": 0.5032524311849449,
            "precision": 0.5121951219512195,
            "recall": 0.0455531453362256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8327731578422201,
            "auditor_fn_violation": 0.009990747660225617,
            "auditor_fp_violation": 0.00668624125947327,
            "ave_precision_score": 0.8036105530670528,
            "fpr": 0.08991228070175439,
            "logloss": 0.5338398778912381,
            "mae": 0.36205587538138945,
            "precision": 0.8097447795823666,
            "recall": 0.7079107505070994
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8293747286407841,
            "auditor_fn_violation": 0.0035050039169371248,
            "auditor_fp_violation": 0.010384193194291992,
            "ave_precision_score": 0.8023145860837917,
            "fpr": 0.06915477497255763,
            "logloss": 0.5187701324618939,
            "mae": 0.3555563467827704,
            "precision": 0.8384615384615385,
            "recall": 0.7093275488069414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.839909361290702,
            "auditor_fn_violation": 0.0108359133126935,
            "auditor_fp_violation": 0.028291567223548135,
            "ave_precision_score": 0.840207111715769,
            "fpr": 0.20394736842105263,
            "logloss": 1.8478577383282877,
            "mae": 0.28556888825219257,
            "precision": 0.7004830917874396,
            "recall": 0.8823529411764706
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8382712544471378,
            "auditor_fn_violation": 0.005164642320541186,
            "auditor_fp_violation": 0.03207708257104527,
            "ave_precision_score": 0.8385561156283505,
            "fpr": 0.21514818880351264,
            "logloss": 1.8050512505683318,
            "mae": 0.29230684229672677,
            "precision": 0.672787979966611,
            "recall": 0.8741865509761388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8085279641332446,
            "auditor_fn_violation": 0.014828208960535215,
            "auditor_fp_violation": 0.008109848009044095,
            "ave_precision_score": 0.8077021557932397,
            "fpr": 0.16228070175438597,
            "logloss": 0.8999742603345267,
            "mae": 0.29160784074950863,
            "precision": 0.7342908438061041,
            "recall": 0.8296146044624746
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7939424509647823,
            "auditor_fn_violation": 0.003926461589014484,
            "auditor_fp_violation": 0.026959385290889138,
            "ave_precision_score": 0.7943851123126022,
            "fpr": 0.16355653128430298,
            "logloss": 0.9590142059860703,
            "mae": 0.29563156920807226,
            "precision": 0.7209737827715356,
            "recall": 0.8351409978308026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7914682411818176,
            "auditor_fn_violation": 0.025802017721789267,
            "auditor_fp_violation": 0.04598720847464725,
            "ave_precision_score": 0.7944045481456772,
            "fpr": 0.34868421052631576,
            "logloss": 5.731248337499542,
            "mae": 0.46567019967257695,
            "precision": 0.5295857988165681,
            "recall": 0.7261663286004056
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.7401856926069701,
            "auditor_fn_violation": 0.0271661614730541,
            "auditor_fp_violation": 0.06516648371752656,
            "ave_precision_score": 0.7454614634046111,
            "fpr": 0.3633369923161361,
            "logloss": 5.835706324847808,
            "mae": 0.47998776467645854,
            "precision": 0.4954268292682927,
            "recall": 0.7049891540130152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7576971973982214,
            "auditor_fn_violation": 0.006690153375324724,
            "auditor_fp_violation": 0.0034752753004228952,
            "ave_precision_score": 0.7585430440114496,
            "fpr": 0.01206140350877193,
            "logloss": 0.7650507458186343,
            "mae": 0.3973857473474577,
            "precision": 0.9185185185185185,
            "recall": 0.2515212981744422
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7531630001294711,
            "auditor_fn_violation": 0.003438332646777991,
            "auditor_fp_violation": 0.001980729357238688,
            "ave_precision_score": 0.7539758984120807,
            "fpr": 0.008781558726673985,
            "logloss": 0.7354864569745239,
            "mae": 0.3890292860213917,
            "precision": 0.9354838709677419,
            "recall": 0.25162689804772237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8125366429323309,
            "auditor_fn_violation": 0.026438116081278253,
            "auditor_fp_violation": 0.014814407737721394,
            "ave_precision_score": 0.8106625665516202,
            "fpr": 0.12719298245614036,
            "logloss": 0.9278334729018146,
            "mae": 0.2791268675793075,
            "precision": 0.7642276422764228,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7879012298935474,
            "auditor_fn_violation": 0.0017382152577201757,
            "auditor_fp_violation": 0.022188071716062935,
            "ave_precision_score": 0.7856016044489205,
            "fpr": 0.13611416026344675,
            "logloss": 1.0413961777715943,
            "mae": 0.2842683001670835,
            "precision": 0.7383966244725738,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8612630284497428,
            "auditor_fn_violation": 0.01989030639479022,
            "auditor_fp_violation": 0.005621153121467155,
            "ave_precision_score": 0.8614688068830575,
            "fpr": 0.0625,
            "logloss": 1.662632366382133,
            "mae": 0.3093114056616303,
            "precision": 0.8523316062176166,
            "recall": 0.6673427991886409
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8709138668982397,
            "auditor_fn_violation": 0.002676375273530793,
            "auditor_fp_violation": 0.009137699719477987,
            "ave_precision_score": 0.871210386245519,
            "fpr": 0.048298572996706916,
            "logloss": 1.558619537243578,
            "mae": 0.2917711922058551,
            "precision": 0.8735632183908046,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8501238670883274,
            "auditor_fn_violation": 0.008829756948151312,
            "auditor_fp_violation": 0.02849307038479253,
            "ave_precision_score": 0.8503761498921854,
            "fpr": 0.2631578947368421,
            "logloss": 1.7835855978772621,
            "mae": 0.3065421350398346,
            "precision": 0.6556671449067432,
            "recall": 0.9269776876267748
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8637232446156594,
            "auditor_fn_violation": 0.004400303830502582,
            "auditor_fp_violation": 0.0345993413830955,
            "ave_precision_score": 0.8639799630705878,
            "fpr": 0.278814489571899,
            "logloss": 1.7005516333806168,
            "mae": 0.31125268950224183,
            "precision": 0.625920471281296,
            "recall": 0.9219088937093276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5282144897666237,
            "auditor_fn_violation": 0.024943507348492953,
            "auditor_fp_violation": 0.02770537620901897,
            "ave_precision_score": 0.5291411050518415,
            "fpr": 0.046052631578947366,
            "logloss": 0.68964014600512,
            "mae": 0.4935141042724513,
            "precision": 0.5280898876404494,
            "recall": 0.09533468559837728
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.4885781152135734,
            "auditor_fn_violation": 0.023651633088951386,
            "auditor_fp_violation": 0.034028540065861694,
            "ave_precision_score": 0.49057050529531265,
            "fpr": 0.054884742041712405,
            "logloss": 0.6863210735849957,
            "mae": 0.4925026053851051,
            "precision": 0.5098039215686274,
            "recall": 0.11279826464208242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8592829880699245,
            "auditor_fn_violation": 0.011269616739617808,
            "auditor_fp_violation": 0.027286668341498142,
            "ave_precision_score": 0.8595030610106144,
            "fpr": 0.24232456140350878,
            "logloss": 1.743647715528321,
            "mae": 0.30131663332219477,
            "precision": 0.6730769230769231,
            "recall": 0.922920892494929
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8637305982334517,
            "auditor_fn_violation": 0.004547933071569227,
            "auditor_fp_violation": 0.03140870837907062,
            "ave_precision_score": 0.8640022776917976,
            "fpr": 0.26125137211855104,
            "logloss": 1.6668611146738925,
            "mae": 0.3036833718239155,
            "precision": 0.6382978723404256,
            "recall": 0.911062906724512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8175272817385412,
            "auditor_fn_violation": 0.014454556777338886,
            "auditor_fp_violation": 0.022437507850772524,
            "ave_precision_score": 0.7650638242979214,
            "fpr": 0.2138157894736842,
            "logloss": 3.021205220222197,
            "mae": 0.2836334560960913,
            "precision": 0.6909667194928685,
            "recall": 0.8843813387423936
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7817459017623871,
            "auditor_fn_violation": 0.004959866276480997,
            "auditor_fp_violation": 0.022627149652396646,
            "ave_precision_score": 0.7136015432463723,
            "fpr": 0.22283205268935236,
            "logloss": 3.7699657180871746,
            "mae": 0.2914246645131093,
            "precision": 0.6672131147540984,
            "recall": 0.8828633405639913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7835455357876144,
            "auditor_fn_violation": 0.000622753638660546,
            "auditor_fp_violation": 0.0027817903948415355,
            "ave_precision_score": 0.7228132727210448,
            "fpr": 0.45285087719298245,
            "logloss": 3.1558158745851945,
            "mae": 0.41225562518331826,
            "precision": 0.543646408839779,
            "recall": 0.9979716024340771
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7512394037206336,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0029857299670691694,
            "ave_precision_score": 0.674793409303324,
            "fpr": 0.48737650933040616,
            "logloss": 3.933045749493249,
            "mae": 0.43728129766088153,
            "precision": 0.5093922651933702,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7845342387000317,
            "auditor_fn_violation": 0.021169175474182414,
            "auditor_fp_violation": 0.018263513796424234,
            "ave_precision_score": 0.7093386136559365,
            "fpr": 0.10855263157894737,
            "logloss": 3.007413506974317,
            "mae": 0.38319884315786656,
            "precision": 0.753731343283582,
            "recall": 0.6146044624746451
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.753284467858363,
            "auditor_fn_violation": 0.001864414447664255,
            "auditor_fp_violation": 0.015499451152579585,
            "ave_precision_score": 0.6632718140246995,
            "fpr": 0.1251372118551043,
            "logloss": 3.7992647439842915,
            "mae": 0.40534021616243765,
            "precision": 0.7128463476070529,
            "recall": 0.613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6255691545415464,
            "auditor_fn_violation": 0.06192617700437707,
            "auditor_fp_violation": 0.07870399447305615,
            "ave_precision_score": 0.6264020960945402,
            "fpr": 0.2993421052631579,
            "logloss": 0.6752096176812794,
            "mae": 0.4811580822746404,
            "precision": 0.5967503692762186,
            "recall": 0.8194726166328601
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.5905126654576167,
            "auditor_fn_violation": 0.06981672544056612,
            "auditor_fp_violation": 0.10262227100865959,
            "ave_precision_score": 0.5914020493643891,
            "fpr": 0.3040614709110867,
            "logloss": 0.6703024476964364,
            "mae": 0.48200651068515404,
            "precision": 0.5637795275590551,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.840707096121061,
            "auditor_fn_violation": 0.009565940713853612,
            "auditor_fp_violation": 0.010342084327764524,
            "ave_precision_score": 0.800625315354856,
            "fpr": 0.07785087719298246,
            "logloss": 0.5399865691075669,
            "mae": 0.3529965578886173,
            "precision": 0.8251231527093597,
            "recall": 0.6795131845841785
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8305542191155463,
            "auditor_fn_violation": 0.002331113338778157,
            "auditor_fp_violation": 0.010140261007439935,
            "ave_precision_score": 0.7874252129534819,
            "fpr": 0.06476399560922064,
            "logloss": 0.5323379735498274,
            "mae": 0.34782372647730286,
            "precision": 0.8422459893048129,
            "recall": 0.6832971800433839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7101947961446691,
            "auditor_fn_violation": 0.014948311447991178,
            "auditor_fp_violation": 0.011582506385294985,
            "ave_precision_score": 0.7068004950744693,
            "fpr": 0.15460526315789475,
            "logloss": 1.89735639222075,
            "mae": 0.40419194757614924,
            "precision": 0.6954643628509719,
            "recall": 0.6531440162271805
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6737874802411727,
            "auditor_fn_violation": 0.004719373480549849,
            "auditor_fp_violation": 0.005037199658494943,
            "ave_precision_score": 0.6588478876267755,
            "fpr": 0.1525795828759605,
            "logloss": 2.094979326390578,
            "mae": 0.4110787019514889,
            "precision": 0.6804597701149425,
            "recall": 0.6420824295010846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.8465393250629015,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.023798308420215224,
            "ave_precision_score": 0.8467606447798173,
            "fpr": 0.30701754385964913,
            "logloss": 1.8723961391952526,
            "mae": 0.3240847426482986,
            "precision": 0.6216216216216216,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8611334061442715,
            "auditor_fn_violation": 0.0047479468820466175,
            "auditor_fp_violation": 0.02507622880839127,
            "ave_precision_score": 0.8613171799888875,
            "fpr": 0.33040614709110866,
            "logloss": 1.79351036952603,
            "mae": 0.33487785376125884,
            "precision": 0.5876712328767123,
            "recall": 0.93058568329718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8249442649382833,
            "auditor_fn_violation": 0.009154478488310025,
            "auditor_fp_violation": 0.022602374073608843,
            "ave_precision_score": 0.8252746498493837,
            "fpr": 0.3081140350877193,
            "logloss": 2.0778731054467796,
            "mae": 0.33235988589493853,
            "precision": 0.6207827260458839,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.845426878289357,
            "auditor_fn_violation": 0.004119332049117677,
            "auditor_fp_violation": 0.023524820100012202,
            "ave_precision_score": 0.8460012303075608,
            "fpr": 0.3336992316136114,
            "logloss": 1.9871766798719268,
            "mae": 0.34533926697384515,
            "precision": 0.5858310626702997,
            "recall": 0.9327548806941431
        }
    }
]