[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6011525357411005,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5605835854578218,
            "fpr": 0.15460526315789475,
            "logloss": 3.3988021114234033,
            "mae": 0.4725338926114011,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6234454470631328,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5782682936204562,
            "fpr": 0.14270032930845225,
            "logloss": 3.2148478139774896,
            "mae": 0.4605605996793502,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8428435879916565,
            "auditor_fn_violation": 0.011643911032812157,
            "auditor_fp_violation": 0.0009777467863206412,
            "ave_precision_score": 0.7874427720572074,
            "fpr": 0.09539473684210527,
            "logloss": 5.525906323521538,
            "mae": 0.2472048166755138,
            "precision": 0.7981438515081206,
            "recall": 0.7196652719665272
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8553865480936896,
            "auditor_fn_violation": 0.009330406147091104,
            "auditor_fp_violation": 0.01563016515891341,
            "ave_precision_score": 0.7994118439969753,
            "fpr": 0.09440175631174534,
            "logloss": 5.065845405381902,
            "mae": 0.23331723742819735,
            "precision": 0.8022988505747126,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.623361516813588,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5572113547956113,
            "fpr": 0.15460526315789475,
            "logloss": 4.103738088997617,
            "mae": 0.47296243451797126,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.648165697655513,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5784477613689091,
            "fpr": 0.14270032930845225,
            "logloss": 3.8027386580725198,
            "mae": 0.46110248788128044,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6322186496891065,
            "auditor_fn_violation": 0.09015543566028042,
            "auditor_fp_violation": 0.07291919314415071,
            "ave_precision_score": 0.6324818096633376,
            "fpr": 0.2730263157894737,
            "logloss": 0.6765522415722048,
            "mae": 0.48301030447085697,
            "precision": 0.5699481865284974,
            "recall": 0.6903765690376569
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6723887822055228,
            "auditor_fn_violation": 0.07903633462166425,
            "auditor_fp_violation": 0.07305853110766242,
            "ave_precision_score": 0.6739636057165499,
            "fpr": 0.2623490669593853,
            "logloss": 0.6660844716533668,
            "mae": 0.47756487677849085,
            "precision": 0.6016666666666667,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6002140743823021,
            "auditor_fn_violation": 0.0004519011965059091,
            "auditor_fp_violation": 0.007857344975341598,
            "ave_precision_score": 0.5610274782164979,
            "fpr": 0.45614035087719296,
            "logloss": 3.302846122190203,
            "mae": 0.4699720992265563,
            "precision": 0.5341545352743561,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6245513502914766,
            "auditor_fn_violation": 0.0022922451088009297,
            "auditor_fp_violation": 0.004123295103271638,
            "ave_precision_score": 0.5795041671365895,
            "fpr": 0.4621295279912184,
            "logloss": 3.142242833806204,
            "mae": 0.461256389691199,
            "precision": 0.5274971941638609,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6319604125719371,
            "auditor_fn_violation": 0.054989723262130225,
            "auditor_fp_violation": 0.019741895060231236,
            "ave_precision_score": 0.6329846727355743,
            "fpr": 0.39364035087719296,
            "logloss": 0.6821785636058346,
            "mae": 0.48033027226317737,
            "precision": 0.5213333333333333,
            "recall": 0.8179916317991632
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6722649419696378,
            "auditor_fn_violation": 0.049493123264673596,
            "auditor_fp_violation": 0.013159720907932437,
            "ave_precision_score": 0.6737595406182221,
            "fpr": 0.4061470911086718,
            "logloss": 0.6735393090943987,
            "mae": 0.475322156359414,
            "precision": 0.5231958762886598,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.623361516813588,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5572113547956113,
            "fpr": 0.15460526315789475,
            "logloss": 4.10356519318186,
            "mae": 0.4729627493050015,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.648165697655513,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5784477613689091,
            "fpr": 0.14270032930845225,
            "logloss": 3.802899989110155,
            "mae": 0.4612694133060824,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 13352,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5724699214912671,
            "auditor_fn_violation": 0.05033766424429274,
            "auditor_fp_violation": 0.04466559544021344,
            "ave_precision_score": 0.5424462978296596,
            "fpr": 0.09100877192982457,
            "logloss": 4.002474246030181,
            "mae": 0.500175221545393,
            "precision": 0.5561497326203209,
            "recall": 0.2175732217573222
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5691820902214396,
            "auditor_fn_violation": 0.05324281194365783,
            "auditor_fp_violation": 0.04070807625824849,
            "ave_precision_score": 0.5431132298561622,
            "fpr": 0.08122941822173436,
            "logloss": 4.479856750236821,
            "mae": 0.5053683023094215,
            "precision": 0.6,
            "recall": 0.23319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 13352,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8432559198183143,
            "auditor_fn_violation": 0.007955296190266475,
            "auditor_fp_violation": 0.004032258064516131,
            "ave_precision_score": 0.7883254889748127,
            "fpr": 0.09210526315789473,
            "logloss": 5.479304131460662,
            "mae": 0.24296825474648837,
            "precision": 0.8018867924528302,
            "recall": 0.7112970711297071
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8561004897238282,
            "auditor_fn_violation": 0.007840677434530346,
            "auditor_fp_violation": 0.010179542500977832,
            "ave_precision_score": 0.8021554923784338,
            "fpr": 0.09440175631174534,
            "logloss": 5.013409104603834,
            "mae": 0.23087569582714146,
            "precision": 0.8036529680365296,
            "recall": 0.7394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5941647071793648,
            "auditor_fn_violation": 0.004523599794465265,
            "auditor_fp_violation": 0.01012106880103485,
            "ave_precision_score": 0.5948835063264608,
            "fpr": 0.05043859649122807,
            "logloss": 0.9434097655957491,
            "mae": 0.49144574437747923,
            "precision": 0.5740740740740741,
            "recall": 0.1297071129707113
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6172246277210727,
            "auditor_fn_violation": 0.0064662528018891606,
            "auditor_fp_violation": 3.785154623566494e-05,
            "ave_precision_score": 0.6191300547276413,
            "fpr": 0.03951701427003293,
            "logloss": 0.9352592273596785,
            "mae": 0.4853235781744826,
            "precision": 0.64,
            "recall": 0.13445378151260504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 13352,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6384833922719048,
            "auditor_fn_violation": 0.03660858474638479,
            "auditor_fp_violation": 0.008461173094025389,
            "ave_precision_score": 0.6395811736265837,
            "fpr": 0.3826754385964912,
            "logloss": 0.6751563766943136,
            "mae": 0.4817318938174203,
            "precision": 0.5407894736842105,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6723493162154728,
            "auditor_fn_violation": 0.03374258594766117,
            "auditor_fp_violation": 0.009553730269881532,
            "ave_precision_score": 0.6736872846390491,
            "fpr": 0.40285400658616904,
            "logloss": 0.6705256384082215,
            "mae": 0.4794802094362962,
            "precision": 0.5360303413400759,
            "recall": 0.8907563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8433788486180407,
            "auditor_fn_violation": 0.008340673860383178,
            "auditor_fp_violation": 0.0028852372867652996,
            "ave_precision_score": 0.7883181026340051,
            "fpr": 0.08771929824561403,
            "logloss": 5.504177868058084,
            "mae": 0.24363511921761377,
            "precision": 0.8081534772182254,
            "recall": 0.7050209205020921
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8554438441657896,
            "auditor_fn_violation": 0.006786798144065533,
            "auditor_fp_violation": 0.015761383852530383,
            "ave_precision_score": 0.8005637284477055,
            "fpr": 0.09110867178924259,
            "logloss": 5.060035184139444,
            "mae": 0.23203140493580957,
            "precision": 0.8069767441860465,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6010712148667041,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.542713347340987,
            "fpr": 0.15460526315789475,
            "logloss": 4.103142355363621,
            "mae": 0.47299681077792977,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6235337401658504,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5655800241939323,
            "fpr": 0.14270032930845225,
            "logloss": 3.801826679256715,
            "mae": 0.4610130918078313,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 13352,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5728059678329345,
            "auditor_fn_violation": 0.010221683916905257,
            "auditor_fp_violation": 0.010393928369310376,
            "ave_precision_score": 0.5754051100853551,
            "fpr": 0.0756578947368421,
            "logloss": 1.15889143915785,
            "mae": 0.5069086095399893,
            "precision": 0.6101694915254238,
            "recall": 0.22594142259414227
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5681815352074855,
            "auditor_fn_violation": 0.014613639089005545,
            "auditor_fp_violation": 0.00594521619541492,
            "ave_precision_score": 0.5716522140933201,
            "fpr": 0.0801317233809001,
            "logloss": 1.171253325501963,
            "mae": 0.5062338976203806,
            "precision": 0.5654761904761905,
            "recall": 0.19957983193277312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5728527317719386,
            "auditor_fn_violation": 0.0074185201497467546,
            "auditor_fp_violation": 0.006720430107526881,
            "ave_precision_score": 0.5754523718739954,
            "fpr": 0.07675438596491228,
            "logloss": 1.1576300360037886,
            "mae": 0.5068235736107454,
            "precision": 0.6153846153846154,
            "recall": 0.23430962343096234
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5682654450362423,
            "auditor_fn_violation": 0.012895608298204042,
            "auditor_fp_violation": 0.00594521619541492,
            "ave_precision_score": 0.571733452356795,
            "fpr": 0.0801317233809001,
            "logloss": 1.1699660836545915,
            "mae": 0.5061736299127798,
            "precision": 0.5680473372781065,
            "recall": 0.20168067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7141753360444977,
            "auditor_fn_violation": 0.027774719224840348,
            "auditor_fp_violation": 0.026912038159915923,
            "ave_precision_score": 0.6938633146973077,
            "fpr": 0.16228070175438597,
            "logloss": 2.9990638664123366,
            "mae": 0.35616907089354766,
            "precision": 0.6768558951965066,
            "recall": 0.6485355648535565
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7592365983656061,
            "auditor_fn_violation": 0.01666374562997537,
            "auditor_fp_violation": 0.014421439115787887,
            "ave_precision_score": 0.7407038171916251,
            "fpr": 0.14270032930845225,
            "logloss": 2.584300497616237,
            "mae": 0.31995693063078623,
            "precision": 0.7180043383947939,
            "recall": 0.6953781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 13352,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8431337690815626,
            "auditor_fn_violation": 0.007955296190266475,
            "auditor_fp_violation": 0.004032258064516131,
            "ave_precision_score": 0.7882034404585851,
            "fpr": 0.09210526315789473,
            "logloss": 5.483858370719982,
            "mae": 0.24308964537316874,
            "precision": 0.8018867924528302,
            "recall": 0.7112970711297071
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8569079364852502,
            "auditor_fn_violation": 0.008832292521838593,
            "auditor_fp_violation": 0.010179542500977832,
            "ave_precision_score": 0.8036831726161707,
            "fpr": 0.09440175631174534,
            "logloss": 4.999240044502042,
            "mae": 0.23098519693835823,
            "precision": 0.8032036613272311,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.601028475474779,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5583328932063859,
            "fpr": 0.15460526315789475,
            "logloss": 3.3966560565110147,
            "mae": 0.47286738684041457,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6234664986897163,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5771446202576105,
            "fpr": 0.14270032930845225,
            "logloss": 3.212109203158326,
            "mae": 0.4607476564584265,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8058333959419506,
            "auditor_fn_violation": 0.017002495779196946,
            "auditor_fp_violation": 0.025183927560837583,
            "ave_precision_score": 0.8062206506350691,
            "fpr": 0.1513157894736842,
            "logloss": 0.9273113155957184,
            "mae": 0.2891220645785207,
            "precision": 0.7272727272727273,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8483234154242727,
            "auditor_fn_violation": 0.015203995978193698,
            "auditor_fp_violation": 0.015960735329371544,
            "ave_precision_score": 0.8487804303344455,
            "fpr": 0.14270032930845225,
            "logloss": 0.7842152363447341,
            "mae": 0.2578780564670777,
            "precision": 0.7435897435897436,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 13352,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5863565720085759,
            "auditor_fn_violation": 0.08014249798135506,
            "auditor_fp_violation": 0.06657773465922871,
            "ave_precision_score": 0.5551686637197927,
            "fpr": 0.1337719298245614,
            "logloss": 3.395137070413516,
            "mae": 0.4806037914138614,
            "precision": 0.568904593639576,
            "recall": 0.3368200836820084
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6081714314949812,
            "auditor_fn_violation": 0.08883026317003201,
            "auditor_fp_violation": 0.0627427230402362,
            "ave_precision_score": 0.5738061295300323,
            "fpr": 0.12184412733260154,
            "logloss": 3.3288991174024503,
            "mae": 0.47031618417552484,
            "precision": 0.6185567010309279,
            "recall": 0.37815126050420167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 13352,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5864495435281049,
            "auditor_fn_violation": 0.0021677493944065413,
            "auditor_fp_violation": 0.0121826744280055,
            "ave_precision_score": 0.5880981468541875,
            "fpr": 0.05482456140350877,
            "logloss": 0.9104390105010183,
            "mae": 0.48757392843049674,
            "precision": 0.5726495726495726,
            "recall": 0.1401673640167364
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6291626276086194,
            "auditor_fn_violation": 0.00025828113901982995,
            "auditor_fp_violation": 0.0034066391612097356,
            "ave_precision_score": 0.6299374659041804,
            "fpr": 0.03732162458836443,
            "logloss": 0.8837054649651866,
            "mae": 0.47803933600538323,
            "precision": 0.6730769230769231,
            "recall": 0.14705882352941177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6002140743823021,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5610274782164979,
            "fpr": 0.15460526315789475,
            "logloss": 3.3322771430904505,
            "mae": 0.47210226413842876,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6234343102708149,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5786847098624782,
            "fpr": 0.14270032930845225,
            "logloss": 3.1586540441414446,
            "mae": 0.4600667665609282,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6203715047189874,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5581694323914566,
            "fpr": 0.15460526315789475,
            "logloss": 4.103088130934,
            "mae": 0.4728928425659736,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.643079228315087,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5794103193467003,
            "fpr": 0.14270032930845225,
            "logloss": 3.801796818950028,
            "mae": 0.4609339329793346,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6010950211512194,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5427269321056549,
            "fpr": 0.15460526315789475,
            "logloss": 4.103108619948223,
            "mae": 0.47299717918953355,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.623551234421244,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.565543202342139,
            "fpr": 0.14270032930845225,
            "logloss": 3.8017564866111506,
            "mae": 0.46099756800382513,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5328930065250465,
            "auditor_fn_violation": 0.004051053365631661,
            "auditor_fp_violation": 0.00752384994744927,
            "ave_precision_score": 0.5313618039315783,
            "fpr": 0.03289473684210526,
            "logloss": 1.2462262812624862,
            "mae": 0.5168143722081655,
            "precision": 0.5588235294117647,
            "recall": 0.0794979079497908
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5263840026594448,
            "auditor_fn_violation": 0.0060880554197529765,
            "auditor_fp_violation": 0.009213066353760551,
            "ave_precision_score": 0.5335150701501761,
            "fpr": 0.03402854006586169,
            "logloss": 1.2629728076474287,
            "mae": 0.5165340418873189,
            "precision": 0.5,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8059512989272218,
            "auditor_fn_violation": 0.01303402334287602,
            "auditor_fp_violation": 0.024827694235588976,
            "ave_precision_score": 0.8063455160641448,
            "fpr": 0.1524122807017544,
            "logloss": 0.9250791747721167,
            "mae": 0.2889770737324137,
            "precision": 0.7258382642998028,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8482650404233573,
            "auditor_fn_violation": 0.015203995978193698,
            "auditor_fp_violation": 0.015960735329371544,
            "ave_precision_score": 0.8487227067585232,
            "fpr": 0.14270032930845225,
            "logloss": 0.7826587277817674,
            "mae": 0.2578838091002528,
            "precision": 0.7435897435897436,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6351255813574801,
            "auditor_fn_violation": 0.07480455846729794,
            "auditor_fp_violation": 0.03031772980839196,
            "ave_precision_score": 0.6355677798897229,
            "fpr": 0.30043859649122806,
            "logloss": 0.6745182951531956,
            "mae": 0.48314038175566676,
            "precision": 0.5594855305466238,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6706889792560792,
            "auditor_fn_violation": 0.06614072632346023,
            "auditor_fp_violation": 0.03849502252167001,
            "ave_precision_score": 0.672115336222303,
            "fpr": 0.2897914379802415,
            "logloss": 0.6685639296234491,
            "mae": 0.48046724862213586,
            "precision": 0.5802861685214626,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6278765126642685,
            "auditor_fn_violation": 0.09514699405417311,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5615752754396656,
            "fpr": 0.15460526315789475,
            "logloss": 4.103428432790019,
            "mae": 0.4724976971680135,
            "precision": 0.5688073394495413,
            "recall": 0.3891213389121339
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6499593753645807,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5806398496322821,
            "fpr": 0.14270032930845225,
            "logloss": 3.8027160720548694,
            "mae": 0.4608873529308583,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6308529632740973,
            "auditor_fn_violation": 0.07124899067753065,
            "auditor_fp_violation": 0.0666156318214892,
            "ave_precision_score": 0.5968147187589512,
            "fpr": 0.1787280701754386,
            "logloss": 3.3480946567285383,
            "mae": 0.4398611965456471,
            "precision": 0.5955334987593052,
            "recall": 0.502092050209205
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.655691639172583,
            "auditor_fn_violation": 0.07567867981440655,
            "auditor_fp_violation": 0.05924524016806086,
            "ave_precision_score": 0.6199288078050667,
            "fpr": 0.1712403951701427,
            "logloss": 3.1612551784808516,
            "mae": 0.42523000518761733,
            "precision": 0.6070528967254408,
            "recall": 0.5063025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6545742784929763,
            "auditor_fn_violation": 0.07651352492108934,
            "auditor_fp_violation": 0.051482031692133556,
            "ave_precision_score": 0.6467933962011054,
            "fpr": 0.19188596491228072,
            "logloss": 0.6930870210501557,
            "mae": 0.44005957292921966,
            "precision": 0.6428571428571429,
            "recall": 0.6589958158995816
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6755161577217323,
            "auditor_fn_violation": 0.06460718206053004,
            "auditor_fp_violation": 0.047541542071993646,
            "ave_precision_score": 0.677229447687495,
            "fpr": 0.1778265642151482,
            "logloss": 0.6713724673087615,
            "mae": 0.43005398675200185,
            "precision": 0.6772908366533864,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 13352,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5797347275733246,
            "auditor_fn_violation": 0.05033766424429274,
            "auditor_fp_violation": 0.04466559544021344,
            "ave_precision_score": 0.559074656119761,
            "fpr": 0.09100877192982457,
            "logloss": 3.9816828298790243,
            "mae": 0.5003927384682915,
            "precision": 0.5561497326203209,
            "recall": 0.2175732217573222
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5802030789302899,
            "auditor_fn_violation": 0.05324281194365783,
            "auditor_fp_violation": 0.04070807625824849,
            "ave_precision_score": 0.5616642279100098,
            "fpr": 0.08122941822173436,
            "logloss": 4.462795511771441,
            "mae": 0.5054930777633491,
            "precision": 0.6,
            "recall": 0.23319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 13352,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.532912993528711,
            "auditor_fn_violation": 0.004051053365631661,
            "auditor_fp_violation": 0.00752384994744927,
            "ave_precision_score": 0.5313761761608333,
            "fpr": 0.03289473684210526,
            "logloss": 1.2460478463697588,
            "mae": 0.5168095709584457,
            "precision": 0.5588235294117647,
            "recall": 0.0794979079497908
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5263860716069972,
            "auditor_fn_violation": 0.0060880554197529765,
            "auditor_fp_violation": 0.009213066353760551,
            "ave_precision_score": 0.533511194133933,
            "fpr": 0.03402854006586169,
            "logloss": 1.2627878594227893,
            "mae": 0.5165303628257876,
            "precision": 0.5,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6993850704514144,
            "auditor_fn_violation": 0.09040317844821259,
            "auditor_fp_violation": 0.08198924731182797,
            "ave_precision_score": 0.5498407960487967,
            "fpr": 0.2774122807017544,
            "logloss": 0.6882056811566535,
            "mae": 0.49651139170715686,
            "precision": 0.5576923076923077,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7300941383495857,
            "auditor_fn_violation": 0.07401599498196644,
            "auditor_fp_violation": 0.09178242931223742,
            "ave_precision_score": 0.5752621836006415,
            "fpr": 0.270032930845225,
            "logloss": 0.6835584497222469,
            "mae": 0.49417606091002075,
            "precision": 0.5858585858585859,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7020776094165786,
            "auditor_fn_violation": 0.016128514277325114,
            "auditor_fp_violation": 0.04059291373595279,
            "ave_precision_score": 0.6393328277194352,
            "fpr": 0.26644736842105265,
            "logloss": 4.543676256904918,
            "mae": 0.34285748409758604,
            "precision": 0.6306990881458967,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7360203519584104,
            "auditor_fn_violation": 0.006447804149102012,
            "auditor_fp_violation": 0.029766455959725963,
            "ave_precision_score": 0.6774426615699279,
            "fpr": 0.2502744237102086,
            "logloss": 4.055068582367407,
            "mae": 0.3121661724875687,
            "precision": 0.6503067484662577,
            "recall": 0.8907563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8090426532844364,
            "auditor_fn_violation": 0.015772957498348384,
            "auditor_fp_violation": 0.025037391866763688,
            "ave_precision_score": 0.8094127336119938,
            "fpr": 0.15570175438596492,
            "logloss": 0.8830827074935895,
            "mae": 0.2886785001800723,
            "precision": 0.7242718446601941,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8500636204849987,
            "auditor_fn_violation": 0.007042773201486962,
            "auditor_fp_violation": 0.015239032514478222,
            "ave_precision_score": 0.8505948612027288,
            "fpr": 0.14489571899012074,
            "logloss": 0.7524677181844399,
            "mae": 0.2591356847585127,
            "precision": 0.7431906614785992,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.623361516813588,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5572113547956113,
            "fpr": 0.15460526315789475,
            "logloss": 4.103732387482831,
            "mae": 0.47296205424425897,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.648165697655513,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5784477613689091,
            "fpr": 0.14270032930845225,
            "logloss": 3.802853871692758,
            "mae": 0.4611598637637925,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8150570181614594,
            "auditor_fn_violation": 0.014841628128899656,
            "auditor_fp_violation": 0.025466893039049233,
            "ave_precision_score": 0.8154124734416595,
            "fpr": 0.16447368421052633,
            "logloss": 0.8359879755845694,
            "mae": 0.28516969049778357,
            "precision": 0.714828897338403,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8546619378332467,
            "auditor_fn_violation": 0.007351788135671396,
            "auditor_fp_violation": 0.01505986852896275,
            "ave_precision_score": 0.8553536888707973,
            "fpr": 0.14928649835345773,
            "logloss": 0.7218929712179761,
            "mae": 0.2580133257949171,
            "precision": 0.7394636015325671,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8431829054169221,
            "auditor_fn_violation": 0.007955296190266475,
            "auditor_fp_violation": 0.0015613630851321887,
            "ave_precision_score": 0.7882525491529477,
            "fpr": 0.09429824561403509,
            "logloss": 5.484646209868009,
            "mae": 0.24295644787379808,
            "precision": 0.7981220657276995,
            "recall": 0.7112970711297071
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8559651746600647,
            "auditor_fn_violation": 0.008652418157164075,
            "auditor_fp_violation": 0.010179542500977832,
            "ave_precision_score": 0.8020211662995824,
            "fpr": 0.09440175631174534,
            "logloss": 5.024344651873082,
            "mae": 0.2312295266327751,
            "precision": 0.8036529680365296,
            "recall": 0.7394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6936343459984644,
            "auditor_fn_violation": 0.004665822506055936,
            "auditor_fp_violation": 0.04041858678955453,
            "ave_precision_score": 0.6399050145310774,
            "fpr": 0.24342105263157895,
            "logloss": 4.6026382403717285,
            "mae": 0.3435065208037252,
            "precision": 0.6396103896103896,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7250261054369046,
            "auditor_fn_violation": 0.0047044064607182105,
            "auditor_fp_violation": 0.030621900904651965,
            "ave_precision_score": 0.6746951447544237,
            "fpr": 0.2305159165751921,
            "logloss": 4.1670271312304115,
            "mae": 0.31446806066219574,
            "precision": 0.6601941747572816,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6995029727955653,
            "auditor_fn_violation": 0.09040317844821259,
            "auditor_fp_violation": 0.08198924731182797,
            "ave_precision_score": 0.5471012703137066,
            "fpr": 0.2774122807017544,
            "logloss": 0.6887139352866993,
            "mae": 0.4968085997786961,
            "precision": 0.5576923076923077,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7286384672369242,
            "auditor_fn_violation": 0.07401599498196644,
            "auditor_fp_violation": 0.09178242931223742,
            "ave_precision_score": 0.5692965878839034,
            "fpr": 0.270032930845225,
            "logloss": 0.6841557614184968,
            "mae": 0.4945019875478273,
            "precision": 0.5858585858585859,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6474817577836218,
            "auditor_fn_violation": 0.08640029729134552,
            "auditor_fp_violation": 0.05833636510631419,
            "ave_precision_score": 0.648283645990026,
            "fpr": 0.25109649122807015,
            "logloss": 0.6719437095345189,
            "mae": 0.48223919303180945,
            "precision": 0.5910714285714286,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6811078752307002,
            "auditor_fn_violation": 0.07217343578485182,
            "auditor_fp_violation": 0.05262121957681973,
            "ave_precision_score": 0.6827893038341772,
            "fpr": 0.23710208562019758,
            "logloss": 0.6657530504027893,
            "mae": 0.47941599193342954,
            "precision": 0.6230366492146597,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.4443818928613751,
            "auditor_fn_violation": 0.10801126770902152,
            "auditor_fp_violation": 0.10054369795456385,
            "ave_precision_score": 0.53938783073396,
            "fpr": 0.2905701754385965,
            "logloss": 0.6928862350886926,
            "mae": 0.4997210050361198,
            "precision": 0.5477815699658704,
            "recall": 0.6715481171548117
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.3585293437678057,
            "auditor_fn_violation": 0.09320489996218027,
            "auditor_fp_violation": 0.10071287078743836,
            "ave_precision_score": 0.5611052613890334,
            "fpr": 0.2810098792535675,
            "logloss": 0.6913773372085333,
            "mae": 0.4989721323603725,
            "precision": 0.5754560530679934,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6299388103166481,
            "auditor_fn_violation": 0.057779123541070246,
            "auditor_fp_violation": 0.05590589376667477,
            "ave_precision_score": 0.5958978759550968,
            "fpr": 0.23464912280701755,
            "logloss": 3.3441061132187317,
            "mae": 0.4353364368700504,
            "precision": 0.5787401574803149,
            "recall": 0.6150627615062761
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6530650886915466,
            "auditor_fn_violation": 0.06482856589397559,
            "auditor_fp_violation": 0.0467668470923704,
            "ave_precision_score": 0.6170661166781495,
            "fpr": 0.2261251372118551,
            "logloss": 3.1697039859767946,
            "mae": 0.4262988942968695,
            "precision": 0.5821501014198783,
            "recall": 0.6029411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6002134507911672,
            "auditor_fn_violation": 0.0004519011965059091,
            "auditor_fp_violation": 0.007857344975341598,
            "ave_precision_score": 0.5610274782164979,
            "fpr": 0.45614035087719296,
            "logloss": 3.249731482386303,
            "mae": 0.46998449359415917,
            "precision": 0.5341545352743561,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6245513502914766,
            "auditor_fn_violation": 0.0022922451088009297,
            "auditor_fp_violation": 0.004123295103271638,
            "ave_precision_score": 0.5795041671365895,
            "fpr": 0.4621295279912184,
            "logloss": 3.0972850396862253,
            "mae": 0.46115364162118455,
            "precision": 0.5274971941638609,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8126582594092451,
            "auditor_fn_violation": 0.013979116200543203,
            "auditor_fp_violation": 0.02580796749939365,
            "ave_precision_score": 0.8130214095695654,
            "fpr": 0.16557017543859648,
            "logloss": 0.8406305074949308,
            "mae": 0.2868444226031843,
            "precision": 0.713472485768501,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8538844489589686,
            "auditor_fn_violation": 0.006909020468780272,
            "auditor_fp_violation": 0.016720289690500535,
            "ave_precision_score": 0.8544071102167156,
            "fpr": 0.150384193194292,
            "logloss": 0.7217445904090121,
            "mae": 0.25827130309816215,
            "precision": 0.7375478927203065,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6925796326750604,
            "auditor_fn_violation": 0.08852216839169054,
            "auditor_fp_violation": 0.07826016654539576,
            "ave_precision_score": 0.5593157053002047,
            "fpr": 0.2631578947368421,
            "logloss": 0.6868513684204793,
            "mae": 0.49546855776325655,
            "precision": 0.5667870036101083,
            "recall": 0.6569037656903766
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7191733957243251,
            "auditor_fn_violation": 0.07230488243596012,
            "auditor_fp_violation": 0.08524168212271473,
            "ave_precision_score": 0.5801980171366563,
            "fpr": 0.2524698133918771,
            "logloss": 0.6817923617872901,
            "mae": 0.4929148464184561,
            "precision": 0.5979020979020979,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.840835038165265,
            "auditor_fn_violation": 0.009547272994200983,
            "auditor_fp_violation": 0.0089184655186353,
            "ave_precision_score": 0.7941380942583083,
            "fpr": 0.08662280701754387,
            "logloss": 4.705270178495865,
            "mae": 0.24741293095593853,
            "precision": 0.8127962085308057,
            "recall": 0.7175732217573222
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8540852040631312,
            "auditor_fn_violation": 0.005795183056757281,
            "auditor_fp_violation": 0.016028868112595736,
            "ave_precision_score": 0.8094848123293267,
            "fpr": 0.09001097694840834,
            "logloss": 4.354997562829704,
            "mae": 0.23474675537903397,
            "precision": 0.8070588235294117,
            "recall": 0.7205882352941176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6971387774290004,
            "auditor_fn_violation": 0.021232474491668502,
            "auditor_fp_violation": 0.045413432775487116,
            "ave_precision_score": 0.6384348279838183,
            "fpr": 0.24451754385964913,
            "logloss": 4.394627587399618,
            "mae": 0.3341116552041728,
            "precision": 0.6432,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7331821763114409,
            "auditor_fn_violation": 0.011110701141049175,
            "auditor_fp_violation": 0.035989250160869075,
            "ave_precision_score": 0.6780850858417306,
            "fpr": 0.22722283205268934,
            "logloss": 3.8867042717990627,
            "mae": 0.3018257424044019,
            "precision": 0.6688,
            "recall": 0.8781512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8428213895561484,
            "auditor_fn_violation": 0.01243301769067019,
            "auditor_fp_violation": 0.0021929824561403547,
            "ave_precision_score": 0.7874218005692888,
            "fpr": 0.09429824561403509,
            "logloss": 5.5280791623584165,
            "mae": 0.24704816448266942,
            "precision": 0.8,
            "recall": 0.7196652719665272
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8550954128330278,
            "auditor_fn_violation": 0.004612163196782554,
            "auditor_fp_violation": 0.018880351262349073,
            "ave_precision_score": 0.7991220708177569,
            "fpr": 0.09549945115257959,
            "logloss": 5.068335335808383,
            "mae": 0.23422109165577668,
            "precision": 0.8,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8574812676619988,
            "auditor_fn_violation": 0.0060077626073552146,
            "auditor_fp_violation": 0.009767361953270279,
            "ave_precision_score": 0.8292711994596675,
            "fpr": 0.08991228070175439,
            "logloss": 3.3535441705240334,
            "mae": 0.22314034370011454,
            "precision": 0.8140589569160998,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8699371178162276,
            "auditor_fn_violation": 0.011262902526543005,
            "auditor_fp_violation": 0.015392962135836581,
            "ave_precision_score": 0.8427380985116498,
            "fpr": 0.09110867178924259,
            "logloss": 3.2432677864254376,
            "mae": 0.20949051167972388,
            "precision": 0.8175824175824176,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6009549096937339,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5426265042824434,
            "fpr": 0.15460526315789475,
            "logloss": 4.1032366797284485,
            "mae": 0.472995698157894,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6235678735086585,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5655707609114966,
            "fpr": 0.14270032930845225,
            "logloss": 3.802054274159094,
            "mae": 0.46107134697335217,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6925796326750604,
            "auditor_fn_violation": 0.08852216839169054,
            "auditor_fp_violation": 0.07826016654539576,
            "ave_precision_score": 0.5593157053002047,
            "fpr": 0.2631578947368421,
            "logloss": 0.6868569782690229,
            "mae": 0.49547214018540425,
            "precision": 0.5667870036101083,
            "recall": 0.6569037656903766
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7191733957243251,
            "auditor_fn_violation": 0.07230488243596012,
            "auditor_fp_violation": 0.08524168212271473,
            "ave_precision_score": 0.5801980171366563,
            "fpr": 0.2524698133918771,
            "logloss": 0.6817971958819301,
            "mae": 0.4929180875436927,
            "precision": 0.5979020979020979,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 13352,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8434189345435757,
            "auditor_fn_violation": 0.007464398443808267,
            "auditor_fp_violation": 0.0039413048750909525,
            "ave_precision_score": 0.7884608640639639,
            "fpr": 0.09429824561403509,
            "logloss": 5.464344549283745,
            "mae": 0.2431010044308637,
            "precision": 0.7990654205607477,
            "recall": 0.7154811715481172
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8550371781332092,
            "auditor_fn_violation": 0.008311118080602167,
            "auditor_fp_violation": 0.01635439141022244,
            "ave_precision_score": 0.8003377710997974,
            "fpr": 0.09659714599341383,
            "logloss": 5.029960619033039,
            "mae": 0.23186681036449633,
            "precision": 0.7995444191343963,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 13352,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6945453633594557,
            "auditor_fn_violation": 0.024856859722528078,
            "auditor_fp_violation": 0.048705432937181665,
            "ave_precision_score": 0.6348732236646871,
            "fpr": 0.24342105263157895,
            "logloss": 4.4857822868838815,
            "mae": 0.33636808203051,
            "precision": 0.6419354838709678,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7300334825216259,
            "auditor_fn_violation": 0.012651163648774551,
            "auditor_fp_violation": 0.03543661758582839,
            "ave_precision_score": 0.6717402805549779,
            "fpr": 0.2283205268935236,
            "logloss": 4.045762837155187,
            "mae": 0.30513008389931195,
            "precision": 0.6634304207119741,
            "recall": 0.8613445378151261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5743936247492599,
            "auditor_fn_violation": 0.007744256037583519,
            "auditor_fp_violation": 0.0061393402861993724,
            "ave_precision_score": 0.5769044512517943,
            "fpr": 0.06578947368421052,
            "logloss": 1.1581020711525511,
            "mae": 0.5067955075810141,
            "precision": 0.6273291925465838,
            "recall": 0.2112970711297071
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5702310864275273,
            "auditor_fn_violation": 0.014565211375439315,
            "auditor_fp_violation": 0.0057029662995066715,
            "ave_precision_score": 0.5736560509417323,
            "fpr": 0.07354555433589462,
            "logloss": 1.1696662414642915,
            "mae": 0.5060900496758529,
            "precision": 0.567741935483871,
            "recall": 0.18487394957983194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6418203034382298,
            "auditor_fn_violation": 0.08470738824047566,
            "auditor_fp_violation": 0.04614863772334063,
            "ave_precision_score": 0.6428499088282884,
            "fpr": 0.25548245614035087,
            "logloss": 0.6735503551717649,
            "mae": 0.48342281900419803,
            "precision": 0.5809352517985612,
            "recall": 0.6757322175732218
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6721176955325568,
            "auditor_fn_violation": 0.06959062439465359,
            "auditor_fp_violation": 0.04555812104924487,
            "ave_precision_score": 0.6734817086692171,
            "fpr": 0.2239297475301866,
            "logloss": 0.6679458183558153,
            "mae": 0.4808668799731067,
            "precision": 0.6324324324324324,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6995029727955653,
            "auditor_fn_violation": 0.09040317844821259,
            "auditor_fp_violation": 0.08198924731182797,
            "ave_precision_score": 0.5471012703137066,
            "fpr": 0.2774122807017544,
            "logloss": 0.6887139354802704,
            "mae": 0.49680859987673004,
            "precision": 0.5576923076923077,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7286384672369242,
            "auditor_fn_violation": 0.07401599498196644,
            "auditor_fp_violation": 0.09178242931223742,
            "ave_precision_score": 0.5692965878839034,
            "fpr": 0.270032930845225,
            "logloss": 0.6841557615476858,
            "mae": 0.49450198761325503,
            "precision": 0.5858585858585859,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5954793881558599,
            "auditor_fn_violation": 0.03027967408059899,
            "auditor_fp_violation": 0.025507316678793763,
            "ave_precision_score": 0.5233097713303416,
            "fpr": 0.36293859649122806,
            "logloss": 6.5897445675148,
            "mae": 0.4761500225091974,
            "precision": 0.5357643758765779,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6199234291516154,
            "auditor_fn_violation": 0.02989142967834774,
            "auditor_fp_violation": 0.028360901876174977,
            "ave_precision_score": 0.5467717309079154,
            "fpr": 0.3600439077936334,
            "logloss": 6.183459867931636,
            "mae": 0.4651850458933807,
            "precision": 0.5425383542538355,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 13352,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5750741887318465,
            "auditor_fn_violation": 0.09040317844821259,
            "auditor_fp_violation": 0.08342933947772659,
            "ave_precision_score": 0.5714620997917412,
            "fpr": 0.2817982456140351,
            "logloss": 0.6890083692789655,
            "mae": 0.4971954503929929,
            "precision": 0.5538194444444444,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.584005386953512,
            "auditor_fn_violation": 0.07401599498196644,
            "auditor_fp_violation": 0.08996050822009412,
            "ave_precision_score": 0.5851514795206714,
            "fpr": 0.27442371020856204,
            "logloss": 0.6855002474890404,
            "mae": 0.49543897773248563,
            "precision": 0.5819397993311036,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5621673989174945,
            "auditor_fn_violation": 0.002507248770461711,
            "auditor_fp_violation": 0.007410158460667799,
            "ave_precision_score": 0.5649630855494867,
            "fpr": 0.025219298245614034,
            "logloss": 1.2173270188786063,
            "mae": 0.5107073663956518,
            "precision": 0.5576923076923077,
            "recall": 0.060669456066945605
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5642586780592191,
            "auditor_fn_violation": 0.0001291405695099279,
            "auditor_fp_violation": 0.0023972645949253703,
            "ave_precision_score": 0.5667614817580492,
            "fpr": 0.018660812294182216,
            "logloss": 1.2257489328618492,
            "mae": 0.509227960583121,
            "precision": 0.6222222222222222,
            "recall": 0.058823529411764705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5806280003099088,
            "auditor_fn_violation": 0.0022962086177787736,
            "auditor_fp_violation": 0.004881154499151106,
            "ave_precision_score": 0.5826194233042865,
            "fpr": 0.09210526315789473,
            "logloss": 1.082273068386911,
            "mae": 0.503444099451595,
            "precision": 0.5902439024390244,
            "recall": 0.25313807531380755
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5697328024681716,
            "auditor_fn_violation": 0.014786595208884866,
            "auditor_fp_violation": 0.006601309663499757,
            "ave_precision_score": 0.5715216573704835,
            "fpr": 0.08562019758507135,
            "logloss": 1.0921993586369758,
            "mae": 0.5031437515500937,
            "precision": 0.5714285714285714,
            "recall": 0.2184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6034926413466462,
            "auditor_fn_violation": 0.09383028701460765,
            "auditor_fp_violation": 0.0767644918748484,
            "ave_precision_score": 0.5644193861579261,
            "fpr": 0.1600877192982456,
            "logloss": 3.2374765720495837,
            "mae": 0.4728626953928094,
            "precision": 0.5680473372781065,
            "recall": 0.401673640167364
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6283971333209049,
            "auditor_fn_violation": 0.10603363189403095,
            "auditor_fp_violation": 0.07384836670577993,
            "ave_precision_score": 0.5835568384784249,
            "fpr": 0.14489571899012074,
            "logloss": 3.0783691181777315,
            "mae": 0.46069072692375934,
            "precision": 0.6129032258064516,
            "recall": 0.43907563025210083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7139190686158885,
            "auditor_fn_violation": 0.0286280554943845,
            "auditor_fp_violation": 0.03415292262915353,
            "ave_precision_score": 0.6980405010628441,
            "fpr": 0.15570175438596492,
            "logloss": 2.6436410344368992,
            "mae": 0.35349050130638043,
            "precision": 0.6830357142857143,
            "recall": 0.6401673640167364
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7596579143979204,
            "auditor_fn_violation": 0.014445295132322967,
            "auditor_fp_violation": 0.01315972090793243,
            "ave_precision_score": 0.7438246555587381,
            "fpr": 0.13721185510428102,
            "logloss": 2.2935429106967278,
            "mae": 0.32345794267475697,
            "precision": 0.7264770240700219,
            "recall": 0.6974789915966386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8090426532844364,
            "auditor_fn_violation": 0.015772957498348384,
            "auditor_fp_violation": 0.025037391866763688,
            "ave_precision_score": 0.8094127336119938,
            "fpr": 0.15570175438596492,
            "logloss": 0.8830826398178824,
            "mae": 0.28867847139700936,
            "precision": 0.7242718446601941,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8500636204849987,
            "auditor_fn_violation": 0.007042773201486962,
            "auditor_fp_violation": 0.015239032514478222,
            "ave_precision_score": 0.8505948612027288,
            "fpr": 0.14489571899012074,
            "logloss": 0.7524678582879452,
            "mae": 0.2591356579868505,
            "precision": 0.7431906614785992,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5325332941029814,
            "auditor_fn_violation": 0.0010001468105410173,
            "auditor_fp_violation": 0.00760975018190638,
            "ave_precision_score": 0.5337482192149765,
            "fpr": 0.029605263157894735,
            "logloss": 1.2258349929521,
            "mae": 0.5165246785904297,
            "precision": 0.55,
            "recall": 0.06903765690376569
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.519233092732923,
            "auditor_fn_violation": 0.006364785211559929,
            "auditor_fp_violation": 0.011166206139520799,
            "ave_precision_score": 0.5231138776459016,
            "fpr": 0.03293084522502744,
            "logloss": 1.2425714376718702,
            "mae": 0.5163040606777309,
            "precision": 0.47368421052631576,
            "recall": 0.05672268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5741362907845622,
            "auditor_fn_violation": 0.00834067386038319,
            "auditor_fp_violation": 0.0061393402861993724,
            "ave_precision_score": 0.5766483123404564,
            "fpr": 0.06578947368421052,
            "logloss": 1.1589892238300215,
            "mae": 0.5068857501385521,
            "precision": 0.625,
            "recall": 0.20920502092050208
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5701162743665554,
            "auditor_fn_violation": 0.014565211375439315,
            "auditor_fp_violation": 0.007237215640258907,
            "ave_precision_score": 0.5735439833445664,
            "fpr": 0.07244785949506037,
            "logloss": 1.170563537706183,
            "mae": 0.5061533104701931,
            "precision": 0.5714285714285714,
            "recall": 0.18487394957983194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.815091509794442,
            "auditor_fn_violation": 0.018484364677383836,
            "auditor_fp_violation": 0.023981324278438035,
            "ave_precision_score": 0.8154059425357307,
            "fpr": 0.1600877192982456,
            "logloss": 0.8264287193929807,
            "mae": 0.286724452174235,
            "precision": 0.7213740458015268,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8573991588287101,
            "auditor_fn_violation": 0.010921602449981091,
            "auditor_fp_violation": 0.014421439115787887,
            "ave_precision_score": 0.8579200567869907,
            "fpr": 0.14270032930845225,
            "logloss": 0.7005010575137025,
            "mae": 0.25701034187760596,
            "precision": 0.7470817120622568,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7192883322810555,
            "auditor_fn_violation": 0.016949735741026213,
            "auditor_fp_violation": 0.029991814212951735,
            "ave_precision_score": 0.7034519737098393,
            "fpr": 0.15460526315789475,
            "logloss": 2.62433999502218,
            "mae": 0.3480862354437374,
            "precision": 0.6934782608695652,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7632264284965157,
            "auditor_fn_violation": 0.00975933732439189,
            "auditor_fp_violation": 0.004201521632158676,
            "ave_precision_score": 0.7473829971728314,
            "fpr": 0.14818880351262348,
            "logloss": 2.2868772355766094,
            "mae": 0.31726147337247845,
            "precision": 0.7163865546218487,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6413521532820828,
            "auditor_fn_violation": 0.08830195258019526,
            "auditor_fp_violation": 0.04924104616379659,
            "ave_precision_score": 0.6416633949343095,
            "fpr": 0.26206140350877194,
            "logloss": 0.6735475642523601,
            "mae": 0.4833068487504007,
            "precision": 0.5769911504424778,
            "recall": 0.6820083682008368
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6717547723771825,
            "auditor_fn_violation": 0.07073213478585727,
            "auditor_fp_violation": 0.04754406550840935,
            "ave_precision_score": 0.6731862826912344,
            "fpr": 0.23819978046103182,
            "logloss": 0.6679782032955346,
            "mae": 0.48075824416560475,
            "precision": 0.6212914485165794,
            "recall": 0.7478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6971652518763043,
            "auditor_fn_violation": 0.021232474491668502,
            "auditor_fp_violation": 0.045413432775487116,
            "ave_precision_score": 0.6384554386193104,
            "fpr": 0.24451754385964913,
            "logloss": 4.3935483861808065,
            "mae": 0.33404892246611106,
            "precision": 0.6432,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7332459403854569,
            "auditor_fn_violation": 0.011110701141049175,
            "auditor_fp_violation": 0.035989250160869075,
            "ave_precision_score": 0.6781516675151005,
            "fpr": 0.22722283205268934,
            "logloss": 3.88584601373673,
            "mae": 0.3017391322261769,
            "precision": 0.6688,
            "recall": 0.8781512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7149321650109807,
            "auditor_fn_violation": 0.030068633927916023,
            "auditor_fp_violation": 0.03281136308513219,
            "ave_precision_score": 0.6987086285137272,
            "fpr": 0.15021929824561403,
            "logloss": 2.656258465575314,
            "mae": 0.35298558319681417,
            "precision": 0.6886363636363636,
            "recall": 0.6338912133891214
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7601015561676882,
            "auditor_fn_violation": 0.01838869466557206,
            "auditor_fp_violation": 0.016657203780107762,
            "ave_precision_score": 0.7439867519974585,
            "fpr": 0.132821075740944,
            "logloss": 2.306809033019693,
            "mae": 0.32121541392359076,
            "precision": 0.7317073170731707,
            "recall": 0.6932773109243697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6993850704514144,
            "auditor_fn_violation": 0.09040317844821259,
            "auditor_fp_violation": 0.08198924731182797,
            "ave_precision_score": 0.5498407960487967,
            "fpr": 0.2774122807017544,
            "logloss": 0.6881162592316422,
            "mae": 0.49635155201611814,
            "precision": 0.5576923076923077,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7300941383495857,
            "auditor_fn_violation": 0.07401599498196644,
            "auditor_fp_violation": 0.09178242931223742,
            "ave_precision_score": 0.5752621836006415,
            "fpr": 0.270032930845225,
            "logloss": 0.6835061022269687,
            "mae": 0.49402724715148055,
            "precision": 0.5858585858585859,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.623361516813588,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.0783713315546932,
            "ave_precision_score": 0.5572113547956113,
            "fpr": 0.15460526315789475,
            "logloss": 4.1037065945238265,
            "mae": 0.4729620512378843,
            "precision": 0.5701219512195121,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.648165697655513,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.5784477613689091,
            "fpr": 0.14270032930845225,
            "logloss": 3.8028907536108707,
            "mae": 0.4611908101878496,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6330236795381892,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.07892715660118038,
            "ave_precision_score": 0.5981347012700746,
            "fpr": 0.15570175438596492,
            "logloss": 3.370972245949627,
            "mae": 0.4728993022847071,
            "precision": 0.5683890577507599,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6521408851525556,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.6156352622788037,
            "fpr": 0.14270032930845225,
            "logloss": 3.1907646344801552,
            "mae": 0.4606072403466008,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7020881171199052,
            "auditor_fn_violation": 0.016128514277325114,
            "auditor_fp_violation": 0.04059291373595279,
            "ave_precision_score": 0.6393433302404868,
            "fpr": 0.26644736842105265,
            "logloss": 4.543622693909602,
            "mae": 0.3428494341598191,
            "precision": 0.6306990881458967,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7360228641152367,
            "auditor_fn_violation": 0.006447804149102012,
            "auditor_fp_violation": 0.029766455959725963,
            "ave_precision_score": 0.6774451724958326,
            "fpr": 0.2502744237102086,
            "logloss": 4.055064770173882,
            "mae": 0.3121644665269755,
            "precision": 0.6503067484662577,
            "recall": 0.8907563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6756242117463918,
            "auditor_fn_violation": 0.018640350877192985,
            "auditor_fp_violation": 0.03660865874363328,
            "ave_precision_score": 0.6284001950170115,
            "fpr": 0.29714912280701755,
            "logloss": 3.861213085223215,
            "mae": 0.37714291850633136,
            "precision": 0.6032210834553441,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7171810020475997,
            "auditor_fn_violation": 0.014018670036620579,
            "auditor_fp_violation": 0.027000769648106805,
            "ave_precision_score": 0.6722051377882103,
            "fpr": 0.2678375411635565,
            "logloss": 3.4471365818029898,
            "mae": 0.3428841154426505,
            "precision": 0.6330827067669172,
            "recall": 0.884453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7161216677248811,
            "auditor_fn_violation": 0.00929494237686267,
            "auditor_fp_violation": 0.029822540221521542,
            "ave_precision_score": 0.6999348638092409,
            "fpr": 0.20614035087719298,
            "logloss": 2.6488324035741053,
            "mae": 0.3525126315823298,
            "precision": 0.6459510357815442,
            "recall": 0.7175732217573222
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7608615223279604,
            "auditor_fn_violation": 0.007783025394570564,
            "auditor_fp_violation": 0.02361431797822274,
            "ave_precision_score": 0.7447666586877854,
            "fpr": 0.1986827661909989,
            "logloss": 2.303803925228967,
            "mae": 0.32807439540878214,
            "precision": 0.6660516605166051,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6291600231151873,
            "auditor_fn_violation": 0.07095307568083388,
            "auditor_fp_violation": 0.06020090548953028,
            "ave_precision_score": 0.5945412772763895,
            "fpr": 0.16337719298245615,
            "logloss": 3.4172425879419204,
            "mae": 0.4444180401241235,
            "precision": 0.6058201058201058,
            "recall": 0.4790794979079498
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6537519005194109,
            "auditor_fn_violation": 0.0714954477949248,
            "auditor_fp_violation": 0.05134436075046999,
            "ave_precision_score": 0.6175270592600004,
            "fpr": 0.15587266739846323,
            "logloss": 3.2406822672542184,
            "mae": 0.43051400907546217,
            "precision": 0.6172506738544474,
            "recall": 0.4810924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6991388214600784,
            "auditor_fn_violation": 0.016020700286280557,
            "auditor_fp_violation": 0.03993350311262027,
            "ave_precision_score": 0.6361027353231932,
            "fpr": 0.26864035087719296,
            "logloss": 4.560303155152919,
            "mae": 0.3437701955954409,
            "precision": 0.6293494704992436,
            "recall": 0.8702928870292888
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7345106744664387,
            "auditor_fn_violation": 0.005292457268307982,
            "auditor_fp_violation": 0.02929709678640373,
            "ave_precision_score": 0.6757382606060356,
            "fpr": 0.2502744237102086,
            "logloss": 4.051343912524976,
            "mae": 0.31279474069755053,
            "precision": 0.6508422664624809,
            "recall": 0.8928571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.633475333407296,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.07892715660118038,
            "ave_precision_score": 0.5985847712374004,
            "fpr": 0.15570175438596492,
            "logloss": 3.398960698692308,
            "mae": 0.47289486628091126,
            "precision": 0.5683890577507599,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6523336054774717,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07381051515954427,
            "ave_precision_score": 0.615857517356141,
            "fpr": 0.14270032930845225,
            "logloss": 3.214445815414947,
            "mae": 0.46068354809716033,
            "precision": 0.6153846153846154,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 13352,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5447455272405514,
            "auditor_fn_violation": 0.009606914776480948,
            "auditor_fp_violation": 0.01580816961759237,
            "ave_precision_score": 0.5467496126435414,
            "fpr": 0.051535087719298246,
            "logloss": 1.1960547392420033,
            "mae": 0.5105651279180229,
            "precision": 0.5607476635514018,
            "recall": 0.12552301255230125
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.55349605162424,
            "auditor_fn_violation": 0.008251159959043988,
            "auditor_fp_violation": 0.016283735190582536,
            "ave_precision_score": 0.5553020385122143,
            "fpr": 0.052689352360043906,
            "logloss": 1.194427877326883,
            "mae": 0.5083434385575689,
            "precision": 0.5294117647058824,
            "recall": 0.1134453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6899431448876482,
            "auditor_fn_violation": 0.016786867797107835,
            "auditor_fp_violation": 0.042957696661007364,
            "ave_precision_score": 0.6397862746504326,
            "fpr": 0.24890350877192982,
            "logloss": 4.650399574725918,
            "mae": 0.3530706085245977,
            "precision": 0.6344605475040258,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7266907734922909,
            "auditor_fn_violation": 0.004794343643055468,
            "auditor_fp_violation": 0.022771490215375303,
            "ave_precision_score": 0.6787504090077531,
            "fpr": 0.24039517014270034,
            "logloss": 4.172723872800209,
            "mae": 0.3226307081180749,
            "precision": 0.6512738853503185,
            "recall": 0.8592436974789915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6021085439505046,
            "auditor_fn_violation": 0.003349115466490503,
            "auditor_fp_violation": 0.016209879537553568,
            "ave_precision_score": 0.6042369385334816,
            "fpr": 0.11074561403508772,
            "logloss": 0.8073758907744351,
            "mae": 0.4693382752580793,
            "precision": 0.6023622047244095,
            "recall": 0.3200836820083682
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6150164976585061,
            "auditor_fn_violation": 0.016571502366039745,
            "auditor_fp_violation": 0.004552279293942492,
            "ave_precision_score": 0.6212859769795256,
            "fpr": 0.11745334796926454,
            "logloss": 0.7898273515586225,
            "mae": 0.46166509537875344,
            "precision": 0.5685483870967742,
            "recall": 0.296218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6067783308690272,
            "auditor_fn_violation": 0.09565853703295898,
            "auditor_fp_violation": 0.07948298164766757,
            "ave_precision_score": 0.5720509627751305,
            "fpr": 0.15679824561403508,
            "logloss": 3.3973845087563714,
            "mae": 0.4725174912692685,
            "precision": 0.5666666666666667,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6296063630279967,
            "auditor_fn_violation": 0.10552629394238486,
            "auditor_fp_violation": 0.07470885852353737,
            "ave_precision_score": 0.5933286254093888,
            "fpr": 0.1437980241492865,
            "logloss": 3.2129022489273504,
            "mae": 0.46039422423988746,
            "precision": 0.6135693215339233,
            "recall": 0.4369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6980925553111575,
            "auditor_fn_violation": 0.09040317844821259,
            "auditor_fp_violation": 0.08205998868138087,
            "ave_precision_score": 0.5472931919215357,
            "fpr": 0.2807017543859649,
            "logloss": 0.688771053175245,
            "mae": 0.4966844176514107,
            "precision": 0.5547826086956522,
            "recall": 0.6673640167364017
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.72917317700165,
            "auditor_fn_violation": 0.07401599498196644,
            "auditor_fp_violation": 0.09150232787009349,
            "ave_precision_score": 0.573324110523561,
            "fpr": 0.2722283205268935,
            "logloss": 0.6839265007187724,
            "mae": 0.4942493830305554,
            "precision": 0.5838926174496645,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6391961623212441,
            "auditor_fn_violation": 0.08644846950011012,
            "auditor_fp_violation": 0.05095399789797074,
            "ave_precision_score": 0.6395518236377028,
            "fpr": 0.2576754385964912,
            "logloss": 0.6741509980544544,
            "mae": 0.48368831530719864,
            "precision": 0.5796064400715564,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.671639730086717,
            "auditor_fn_violation": 0.07045540499405031,
            "auditor_fp_violation": 0.049878244192941956,
            "ave_precision_score": 0.673068283524047,
            "fpr": 0.2327113062568606,
            "logloss": 0.6684950276876888,
            "mae": 0.48115742466648637,
            "precision": 0.624113475177305,
            "recall": 0.7394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6731437954723493,
            "auditor_fn_violation": 0.018640350877192985,
            "auditor_fp_violation": 0.03660865874363328,
            "ave_precision_score": 0.6291359599245698,
            "fpr": 0.29714912280701755,
            "logloss": 3.738922523464817,
            "mae": 0.37723835494232427,
            "precision": 0.6032210834553441,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7166081567402204,
            "auditor_fn_violation": 0.014542150559455397,
            "auditor_fp_violation": 0.026942730610545442,
            "ave_precision_score": 0.6724918414433741,
            "fpr": 0.2667398463227223,
            "logloss": 3.401063071705622,
            "mae": 0.3428364629020483,
            "precision": 0.6345864661654136,
            "recall": 0.8865546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5954751309459312,
            "auditor_fn_violation": 0.029715371063642377,
            "auditor_fp_violation": 0.025507316678793763,
            "ave_precision_score": 0.5238812757725889,
            "fpr": 0.36293859649122806,
            "logloss": 6.540709340145251,
            "mae": 0.4750621909144939,
            "precision": 0.5344585091420534,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6206093361760793,
            "auditor_fn_violation": 0.031007573171969123,
            "auditor_fp_violation": 0.028678854864554553,
            "ave_precision_score": 0.547878313345233,
            "fpr": 0.3578485181119649,
            "logloss": 6.133004655638049,
            "mae": 0.4649693960759433,
            "precision": 0.5427769985974754,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8149562211932984,
            "auditor_fn_violation": 0.018484364677383836,
            "auditor_fp_violation": 0.023981324278438035,
            "ave_precision_score": 0.8152749061934388,
            "fpr": 0.1600877192982456,
            "logloss": 0.8282118289931089,
            "mae": 0.28661694224873885,
            "precision": 0.7213740458015268,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8572040066426372,
            "auditor_fn_violation": 0.007015100222306267,
            "auditor_fp_violation": 0.014421439115787887,
            "ave_precision_score": 0.8577175326016808,
            "fpr": 0.14270032930845225,
            "logloss": 0.7028221208770513,
            "mae": 0.2570566923723596,
            "precision": 0.74609375,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 13352,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7792955085462205,
            "auditor_fn_violation": 0.013079901636937535,
            "auditor_fp_violation": 0.01964588891583799,
            "ave_precision_score": 0.7775544190955346,
            "fpr": 0.125,
            "logloss": 1.0936828155412281,
            "mae": 0.2968217108222869,
            "precision": 0.7527114967462039,
            "recall": 0.7259414225941423
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8317131948991445,
            "auditor_fn_violation": 0.010441937477515706,
            "auditor_fp_violation": 0.011938377682728344,
            "ave_precision_score": 0.8320622100698054,
            "fpr": 0.11964873765093303,
            "logloss": 0.8713998174567891,
            "mae": 0.2635121920508821,
            "precision": 0.7680851063829788,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6474817577836218,
            "auditor_fn_violation": 0.08640029729134552,
            "auditor_fp_violation": 0.05833636510631419,
            "ave_precision_score": 0.648283645990026,
            "fpr": 0.25109649122807015,
            "logloss": 0.6719437078860467,
            "mae": 0.4822391926212923,
            "precision": 0.5910714285714286,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6811078752307002,
            "auditor_fn_violation": 0.07217343578485182,
            "auditor_fp_violation": 0.05262121957681973,
            "ave_precision_score": 0.6827893038341772,
            "fpr": 0.23710208562019758,
            "logloss": 0.6657530487547322,
            "mae": 0.47941599102562005,
            "precision": 0.6230366492146597,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8575009425890917,
            "auditor_fn_violation": 0.0060077626073552146,
            "auditor_fp_violation": 0.008562232193386693,
            "ave_precision_score": 0.8292892852774019,
            "fpr": 0.08881578947368421,
            "logloss": 3.3494736513092906,
            "mae": 0.22301588677373416,
            "precision": 0.8159090909090909,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8697559225200443,
            "auditor_fn_violation": 0.011262902526543005,
            "auditor_fp_violation": 0.015392962135836581,
            "ave_precision_score": 0.8425708304980328,
            "fpr": 0.09110867178924259,
            "logloss": 3.238334153933627,
            "mae": 0.20955162297739988,
            "precision": 0.8175824175824176,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7188017443426213,
            "auditor_fn_violation": 0.00879945680099831,
            "auditor_fp_violation": 0.013900679117147706,
            "ave_precision_score": 0.7012258160350271,
            "fpr": 0.17653508771929824,
            "logloss": 2.8068324927717145,
            "mae": 0.3511825225356678,
            "precision": 0.6747474747474748,
            "recall": 0.698744769874477
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7641566369061401,
            "auditor_fn_violation": 0.0057698161591749775,
            "auditor_fp_violation": 0.0116507059313373,
            "ave_precision_score": 0.7473027828730865,
            "fpr": 0.17233809001097694,
            "logloss": 2.4358044839486945,
            "mae": 0.3202058589983778,
            "precision": 0.6884920634920635,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6929934429263513,
            "auditor_fn_violation": 0.005324176025838662,
            "auditor_fp_violation": 0.044860134206483965,
            "ave_precision_score": 0.6382683162492515,
            "fpr": 0.2565789473684211,
            "logloss": 4.70239642499648,
            "mae": 0.3507798179572238,
            "precision": 0.6303317535545023,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7261141546571234,
            "auditor_fn_violation": 0.0031454953002057026,
            "auditor_fp_violation": 0.02599644195465385,
            "ave_precision_score": 0.6752043247613134,
            "fpr": 0.24368825466520308,
            "logloss": 4.246818051425011,
            "mae": 0.3225989926753593,
            "precision": 0.6498422712933754,
            "recall": 0.865546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8058970122029359,
            "auditor_fn_violation": 0.013809366512515603,
            "auditor_fp_violation": 0.024827694235588976,
            "ave_precision_score": 0.806296873487387,
            "fpr": 0.1524122807017544,
            "logloss": 0.924266476573992,
            "mae": 0.28899188362895634,
            "precision": 0.7252964426877471,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8481866459739231,
            "auditor_fn_violation": 0.015203995978193698,
            "auditor_fp_violation": 0.015960735329371544,
            "ave_precision_score": 0.8486447782727529,
            "fpr": 0.14270032930845225,
            "logloss": 0.7823088826285836,
            "mae": 0.25799489725849545,
            "precision": 0.7435897435897436,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7181049444251103,
            "auditor_fn_violation": 0.011813660720839751,
            "auditor_fp_violation": 0.021217357910906308,
            "ave_precision_score": 0.6977541368828282,
            "fpr": 0.18640350877192982,
            "logloss": 3.041335382893506,
            "mae": 0.3556049133649452,
            "precision": 0.6593186372745491,
            "recall": 0.6882845188284519
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7632857178884019,
            "auditor_fn_violation": 0.003431449418406225,
            "auditor_fp_violation": 0.011140971775363696,
            "ave_precision_score": 0.7444658992417611,
            "fpr": 0.1756311745334797,
            "logloss": 2.625044596029546,
            "mae": 0.32475941602968567,
            "precision": 0.6868884540117417,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7769020617828333,
            "auditor_fn_violation": 0.013440046245320416,
            "auditor_fp_violation": 0.01878183361629882,
            "ave_precision_score": 0.7746621293665402,
            "fpr": 0.1206140350877193,
            "logloss": 1.1441400665780224,
            "mae": 0.29765948382259355,
            "precision": 0.7560975609756098,
            "recall": 0.7133891213389121
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8267920422479669,
            "auditor_fn_violation": 0.01178407696777943,
            "auditor_fp_violation": 0.01129490139672206,
            "ave_precision_score": 0.8272044987691205,
            "fpr": 0.1163556531284303,
            "logloss": 0.9011142949135758,
            "mae": 0.26379738517719503,
            "precision": 0.7700650759219089,
            "recall": 0.7457983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6976601338182015,
            "auditor_fn_violation": 0.015841774939440653,
            "auditor_fp_violation": 0.04232102433503114,
            "ave_precision_score": 0.6353640369201026,
            "fpr": 0.26864035087719296,
            "logloss": 4.563074839397031,
            "mae": 0.3467020834365073,
            "precision": 0.6270928462709284,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7331529563687993,
            "auditor_fn_violation": 0.006959754263944877,
            "auditor_fp_violation": 0.02966047163026611,
            "ave_precision_score": 0.6748420572801375,
            "fpr": 0.2502744237102086,
            "logloss": 4.059803068723131,
            "mae": 0.3147623613775238,
            "precision": 0.6492307692307693,
            "recall": 0.8865546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7029951862709859,
            "auditor_fn_violation": 0.016020700286280557,
            "auditor_fp_violation": 0.04059291373595279,
            "ave_precision_score": 0.6405026909484677,
            "fpr": 0.26644736842105265,
            "logloss": 4.525886131295471,
            "mae": 0.3432184607953442,
            "precision": 0.6312594840667678,
            "recall": 0.8702928870292888
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7358526148221901,
            "auditor_fn_violation": 0.005292457268307982,
            "auditor_fp_violation": 0.029766455959725963,
            "ave_precision_score": 0.6778451317731017,
            "fpr": 0.2502744237102086,
            "logloss": 4.034658391353295,
            "mae": 0.3121883562373216,
            "precision": 0.6508422664624809,
            "recall": 0.8928571428571429
        }
    }
]