[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8489770687175617,
            "auditor_fn_violation": 0.015276335026161898,
            "auditor_fp_violation": 0.019823407202216075,
            "ave_precision_score": 0.849243042542352,
            "fpr": 0.23464912280701755,
            "logloss": 0.8209091910736861,
            "mae": 0.2986893129815959,
            "precision": 0.6586921850079744,
            "recall": 0.9057017543859649
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8607006121639721,
            "auditor_fn_violation": 0.006850673825929404,
            "auditor_fp_violation": 0.025717421985259534,
            "ave_precision_score": 0.8609661805695051,
            "fpr": 0.20856201975850713,
            "logloss": 0.7123797763282743,
            "mae": 0.27479171461002094,
            "precision": 0.7072419106317411,
            "recall": 0.9216867469879518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8428102743298079,
            "auditor_fn_violation": 0.014297668513388737,
            "auditor_fp_violation": 0.018375846414281322,
            "ave_precision_score": 0.8431000647257942,
            "fpr": 0.23574561403508773,
            "logloss": 0.8288703142705722,
            "mae": 0.30052282838788397,
            "precision": 0.6565495207667732,
            "recall": 0.9013157894736842
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8577813277052542,
            "auditor_fn_violation": 0.004694959861399496,
            "auditor_fp_violation": 0.027572606001972134,
            "ave_precision_score": 0.8580771454753161,
            "fpr": 0.20417124039517015,
            "logloss": 0.7151063750207755,
            "mae": 0.27502049422454494,
            "precision": 0.7129629629629629,
            "recall": 0.927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7038859433910907,
            "auditor_fn_violation": 0.015254693751923669,
            "auditor_fp_violation": 0.02523372576177286,
            "ave_precision_score": 0.6899734494696343,
            "fpr": 0.2565789473684211,
            "logloss": 2.1496314359278137,
            "mae": 0.3175182183693706,
            "precision": 0.64,
            "recall": 0.9122807017543859
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7499974856741618,
            "auditor_fn_violation": 0.008146747252456586,
            "auditor_fp_violation": 0.024811092830962972,
            "ave_precision_score": 0.7364655909366266,
            "fpr": 0.2414928649835346,
            "logloss": 1.8416340736606092,
            "mae": 0.30306095140527856,
            "precision": 0.6726190476190477,
            "recall": 0.9076305220883534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8085990727661717,
            "auditor_fn_violation": 0.013561865189289014,
            "auditor_fp_violation": 0.020828524161280393,
            "ave_precision_score": 0.8089184948034014,
            "fpr": 0.18201754385964913,
            "logloss": 0.8681487821413019,
            "mae": 0.2790911598249694,
            "precision": 0.6992753623188406,
            "recall": 0.8464912280701754
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8248768118838302,
            "auditor_fn_violation": 0.014283258169891427,
            "auditor_fp_violation": 0.020845570548820847,
            "ave_precision_score": 0.8257461153987529,
            "fpr": 0.1668496158068057,
            "logloss": 0.849154623751591,
            "mae": 0.27720003332281096,
            "precision": 0.7271095152603232,
            "recall": 0.8132530120481928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8391117682034746,
            "auditor_fn_violation": 0.012422091412742383,
            "auditor_fp_violation": 0.0165844298245614,
            "ave_precision_score": 0.8393458079921052,
            "fpr": 0.1875,
            "logloss": 0.7188157100594735,
            "mae": 0.2814528023660006,
            "precision": 0.6907775768535263,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8508131267204814,
            "auditor_fn_violation": 0.008204056621656772,
            "auditor_fp_violation": 0.019774454275561272,
            "ave_precision_score": 0.851187082263769,
            "fpr": 0.15477497255762898,
            "logloss": 0.6563814819409963,
            "mae": 0.26908846842968737,
            "precision": 0.7454873646209387,
            "recall": 0.8293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8213000947817573,
            "auditor_fn_violation": 0.014930074638350263,
            "auditor_fp_violation": 0.020631348107109884,
            "ave_precision_score": 0.8216301332834602,
            "fpr": 0.2138157894736842,
            "logloss": 0.9033871602092771,
            "mae": 0.28647883085685494,
            "precision": 0.6728187919463087,
            "recall": 0.8793859649122807
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8476680647475343,
            "auditor_fn_violation": 0.009028429855536304,
            "auditor_fp_violation": 0.027686893842543265,
            "ave_precision_score": 0.8479725365614434,
            "fpr": 0.1877058177826564,
            "logloss": 0.7667128050992873,
            "mae": 0.26699652007845043,
            "precision": 0.719672131147541,
            "recall": 0.8815261044176707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 19863,
        "test": {
            "accuracy": 0.8004385964912281,
            "auc_prc": 0.8796512050651163,
            "auditor_fn_violation": 0.007752385349338264,
            "auditor_fp_violation": 0.005424746075715608,
            "ave_precision_score": 0.8798345137171202,
            "fpr": 0.08552631578947369,
            "logloss": 0.8765358565740361,
            "mae": 0.20829552596349132,
            "precision": 0.8186046511627907,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8651349454608122,
            "auditor_fn_violation": 0.012566181300393671,
            "auditor_fp_violation": 0.013148417379193766,
            "ave_precision_score": 0.8654674649802,
            "fpr": 0.0867178924259056,
            "logloss": 1.0046184758711674,
            "mae": 0.24507679094896415,
            "precision": 0.8204545454545454,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8100017529736249,
            "auditor_fn_violation": 0.019501192674669134,
            "auditor_fp_violation": 0.025911819021237303,
            "ave_precision_score": 0.8103386709319325,
            "fpr": 0.19956140350877194,
            "logloss": 0.9980319168563968,
            "mae": 0.2852294731312946,
            "precision": 0.681260945709282,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.830506178427489,
            "auditor_fn_violation": 0.01694153121817677,
            "auditor_fp_violation": 0.028999875080732405,
            "ave_precision_score": 0.8309923983716262,
            "fpr": 0.19099890230515917,
            "logloss": 0.8912225269068109,
            "mae": 0.277157957995485,
            "precision": 0.7070707070707071,
            "recall": 0.8433734939759037
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7780697410977896,
            "auditor_fn_violation": 0.021698984302862424,
            "auditor_fp_violation": 0.01903951215758696,
            "ave_precision_score": 0.7785107640667897,
            "fpr": 0.15679824561403508,
            "logloss": 0.8919502275638189,
            "mae": 0.29956366849468913,
            "precision": 0.7063655030800822,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8223080743311149,
            "auditor_fn_violation": 0.0049925277399388976,
            "auditor_fp_violation": 0.019915320683707074,
            "ave_precision_score": 0.8227463263467054,
            "fpr": 0.12843029637760703,
            "logloss": 0.791577241342333,
            "mae": 0.28993344218585326,
            "precision": 0.7582644628099173,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7813180740691131,
            "auditor_fn_violation": 0.019919590643274858,
            "auditor_fp_violation": 0.02280990304709141,
            "ave_precision_score": 0.7817459991782151,
            "fpr": 0.16776315789473684,
            "logloss": 1.1250118702812282,
            "mae": 0.28813841377982713,
            "precision": 0.7023346303501945,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.813321346659051,
            "auditor_fn_violation": 0.010150370967955248,
            "auditor_fp_violation": 0.03064243055684757,
            "ave_precision_score": 0.8170981918855696,
            "fpr": 0.14050493962678376,
            "logloss": 1.0504634760663996,
            "mae": 0.2815001255462962,
            "precision": 0.7485265225933202,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8310770638225987,
            "auditor_fn_violation": 0.015052708525700216,
            "auditor_fp_violation": 0.02275219298245615,
            "ave_precision_score": 0.8313687950434826,
            "fpr": 0.20833333333333334,
            "logloss": 0.8544067891993401,
            "mae": 0.2823509652765578,
            "precision": 0.6801346801346801,
            "recall": 0.8859649122807017
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8509532106988639,
            "auditor_fn_violation": 0.007035827172576145,
            "auditor_fp_violation": 0.0294384214457146,
            "ave_precision_score": 0.8512639391709387,
            "fpr": 0.18221734357848518,
            "logloss": 0.736474163180862,
            "mae": 0.265621416378662,
            "precision": 0.7256198347107438,
            "recall": 0.8815261044176707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8135282797796392,
            "auditor_fn_violation": 0.010993767313019393,
            "auditor_fp_violation": 0.020371652816251175,
            "ave_precision_score": 0.8138603094499606,
            "fpr": 0.23684210526315788,
            "logloss": 1.013334617982219,
            "mae": 0.3072563868720178,
            "precision": 0.6504854368932039,
            "recall": 0.881578947368421
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.846805776588692,
            "auditor_fn_violation": 0.005867597723495521,
            "auditor_fp_violation": 0.017260121782996626,
            "ave_precision_score": 0.847174259683871,
            "fpr": 0.19099890230515917,
            "logloss": 0.7283608111990092,
            "mae": 0.28272849282280893,
            "precision": 0.7147540983606557,
            "recall": 0.8755020080321285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8123547202576628,
            "auditor_fn_violation": 0.024168494152046787,
            "auditor_fp_violation": 0.03275046168051708,
            "ave_precision_score": 0.8123607368485436,
            "fpr": 0.1513157894736842,
            "logloss": 1.7721262640014697,
            "mae": 0.2733681638929825,
            "precision": 0.7234468937875751,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8153477329072664,
            "auditor_fn_violation": 0.03548992898046632,
            "auditor_fp_violation": 0.0333321815954051,
            "ave_precision_score": 0.8157166994201295,
            "fpr": 0.14050493962678376,
            "logloss": 2.177347557668026,
            "mae": 0.28970387216177584,
            "precision": 0.7424547283702213,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8505747869889225,
            "auditor_fn_violation": 0.013855224684518313,
            "auditor_fp_violation": 0.025421283471837496,
            "ave_precision_score": 0.8508247727525324,
            "fpr": 0.23464912280701755,
            "logloss": 0.8275894146354582,
            "mae": 0.2984918749802963,
            "precision": 0.6597774244833068,
            "recall": 0.9100877192982456
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8612166870125362,
            "auditor_fn_violation": 0.00723861417128448,
            "auditor_fp_violation": 0.024776540693115884,
            "ave_precision_score": 0.8614776890939,
            "fpr": 0.20636663007683864,
            "logloss": 0.7146876297873075,
            "mae": 0.2749319054644201,
            "precision": 0.7098765432098766,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8358155935803203,
            "auditor_fn_violation": 0.018034395198522624,
            "auditor_fp_violation": 0.0190515350877193,
            "ave_precision_score": 0.8360846341026025,
            "fpr": 0.1611842105263158,
            "logloss": 0.7450142582299556,
            "mae": 0.2741299767866575,
            "precision": 0.7134502923976608,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.841928224696916,
            "auditor_fn_violation": 0.008957895247289932,
            "auditor_fp_violation": 0.023612399433344942,
            "ave_precision_score": 0.8422227268280207,
            "fpr": 0.13391877058177826,
            "logloss": 0.7061395058633547,
            "mae": 0.2756416778009327,
            "precision": 0.7607843137254902,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8365550246443193,
            "auditor_fn_violation": 0.024295937211449688,
            "auditor_fp_violation": 0.010705216989843032,
            "ave_precision_score": 0.8368186529025596,
            "fpr": 0.07456140350877193,
            "logloss": 0.7838399054687456,
            "mae": 0.28118278333453356,
            "precision": 0.8152173913043478,
            "recall": 0.6578947368421053
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8509324891044909,
            "auditor_fn_violation": 0.009718346492446189,
            "auditor_fp_violation": 0.010961001267797671,
            "ave_precision_score": 0.8512769191500039,
            "fpr": 0.06366630076838639,
            "logloss": 0.7610940867333603,
            "mae": 0.2899753362570687,
            "precision": 0.8453333333333334,
            "recall": 0.6365461847389559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7855147337615456,
            "auditor_fn_violation": 0.0168224838411819,
            "auditor_fp_violation": 0.016735918744229,
            "ave_precision_score": 0.7859549513925792,
            "fpr": 0.15570175438596492,
            "logloss": 0.8891965883039745,
            "mae": 0.2909684697088542,
            "precision": 0.7131313131313132,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8169735366361832,
            "auditor_fn_violation": 0.010137145728909048,
            "auditor_fp_violation": 0.020409682040596108,
            "ave_precision_score": 0.8174148559286708,
            "fpr": 0.13062568605927552,
            "logloss": 0.8565714164416346,
            "mae": 0.28600493316468534,
            "precision": 0.7561475409836066,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.8634020224625942,
            "auditor_fn_violation": 0.006538069405971069,
            "auditor_fp_violation": 0.018476839027393062,
            "ave_precision_score": 0.8637813051161518,
            "fpr": 0.2905701754385965,
            "logloss": 0.7389634286666763,
            "mae": 0.32811858307890857,
            "precision": 0.6203438395415473,
            "recall": 0.9495614035087719
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8668207739004167,
            "auditor_fn_violation": 0.004351103646198405,
            "auditor_fp_violation": 0.01769601029122138,
            "ave_precision_score": 0.8671221910371253,
            "fpr": 0.2502744237102086,
            "logloss": 0.6269735858761651,
            "mae": 0.30560473993968673,
            "precision": 0.6756756756756757,
            "recall": 0.9538152610441767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8470971837662182,
            "auditor_fn_violation": 0.015988092489996924,
            "auditor_fp_violation": 0.023199445983379502,
            "ave_precision_score": 0.847341948324549,
            "fpr": 0.21052631578947367,
            "logloss": 0.8044633881926031,
            "mae": 0.28518859202308516,
            "precision": 0.6805324459234608,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8570021936704678,
            "auditor_fn_violation": 0.006967496770837465,
            "auditor_fp_violation": 0.030687614121724528,
            "ave_precision_score": 0.8573006386000697,
            "fpr": 0.18880351262349068,
            "logloss": 0.6858825001720639,
            "mae": 0.2665252762156737,
            "precision": 0.7203252032520325,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8080979526271781,
            "auditor_fn_violation": 0.021136311172668513,
            "auditor_fp_violation": 0.02849674899969222,
            "ave_precision_score": 0.8084501138221533,
            "fpr": 0.19846491228070176,
            "logloss": 1.0307349180435792,
            "mae": 0.2851420250639769,
            "precision": 0.6830122591943958,
            "recall": 0.8552631578947368
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8276999601552,
            "auditor_fn_violation": 0.018616728164028234,
            "auditor_fp_violation": 0.030031123502629955,
            "ave_precision_score": 0.8287726930441277,
            "fpr": 0.18990120746432493,
            "logloss": 0.9193066003609157,
            "mae": 0.2779618723862161,
            "precision": 0.7072758037225042,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8003863404565064,
            "auditor_fn_violation": 0.00918070944906125,
            "auditor_fp_violation": 0.023182613881194223,
            "ave_precision_score": 0.8006264290795061,
            "fpr": 0.3826754385964912,
            "logloss": 2.3371853645175116,
            "mae": 0.4159404936071532,
            "precision": 0.5490956072351422,
            "recall": 0.9320175438596491
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.8144207588578805,
            "auditor_fn_violation": 0.01332442833904223,
            "auditor_fp_violation": 0.03293350308178491,
            "ave_precision_score": 0.8144341151399739,
            "fpr": 0.35236004390779363,
            "logloss": 2.1162404499760905,
            "mae": 0.3941132060140043,
            "precision": 0.5841968911917098,
            "recall": 0.9056224899598394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8289431297082523,
            "auditor_fn_violation": 0.013677285318559556,
            "auditor_fp_violation": 0.021487380732533097,
            "ave_precision_score": 0.829228686667497,
            "fpr": 0.20614035087719298,
            "logloss": 0.7771759019431661,
            "mae": 0.28713571362475737,
            "precision": 0.6813559322033899,
            "recall": 0.881578947368421
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.847129535490682,
            "auditor_fn_violation": 0.009475883776599267,
            "auditor_fp_violation": 0.030336777029738762,
            "ave_precision_score": 0.847460210206685,
            "fpr": 0.18331503841931943,
            "logloss": 0.7195559295279557,
            "mae": 0.2721704758814774,
            "precision": 0.7216666666666667,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8354871149732075,
            "auditor_fn_violation": 0.023514446752847036,
            "auditor_fp_violation": 0.009680863342566945,
            "ave_precision_score": 0.8357532892518851,
            "fpr": 0.07236842105263158,
            "logloss": 0.7877762613279012,
            "mae": 0.28370494903771276,
            "precision": 0.8161559888579387,
            "recall": 0.6425438596491229
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8498798239781128,
            "auditor_fn_violation": 0.007961593905809854,
            "auditor_fp_violation": 0.010961001267797671,
            "ave_precision_score": 0.8502261383686784,
            "fpr": 0.06366630076838639,
            "logloss": 0.7739311636686121,
            "mae": 0.29335334194641266,
            "precision": 0.842391304347826,
            "recall": 0.6224899598393574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8300519560603457,
            "auditor_fn_violation": 0.012349953831948294,
            "auditor_fp_violation": 0.024988457987072943,
            "ave_precision_score": 0.8303192389698214,
            "fpr": 0.19736842105263158,
            "logloss": 0.7565690870243217,
            "mae": 0.2838925595747416,
            "precision": 0.6875,
            "recall": 0.868421052631579
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8454548227905601,
            "auditor_fn_violation": 0.013463293349027284,
            "auditor_fp_violation": 0.0326198759844037,
            "ave_precision_score": 0.8458175803057738,
            "fpr": 0.1756311745334797,
            "logloss": 0.7155019865606228,
            "mae": 0.2734191890808153,
            "precision": 0.7227036395147314,
            "recall": 0.8373493975903614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.809653512692412,
            "auditor_fn_violation": 0.016699849953831954,
            "auditor_fp_violation": 0.019520429362880887,
            "ave_precision_score": 0.8099963625891656,
            "fpr": 0.2050438596491228,
            "logloss": 0.8888067356439545,
            "mae": 0.28213425952056836,
            "precision": 0.6775862068965517,
            "recall": 0.8618421052631579
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8394603274506778,
            "auditor_fn_violation": 0.009240033680275444,
            "auditor_fp_violation": 0.032199934616723776,
            "ave_precision_score": 0.8398945995224048,
            "fpr": 0.1778265642151482,
            "logloss": 0.7960205112532219,
            "mae": 0.26816340477147915,
            "precision": 0.7235494880546075,
            "recall": 0.8514056224899599
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8396112352474076,
            "auditor_fn_violation": 0.01495412049861496,
            "auditor_fp_violation": 0.02231455832563867,
            "ave_precision_score": 0.8398777150582557,
            "fpr": 0.21929824561403508,
            "logloss": 0.9449967900783217,
            "mae": 0.29311444772757145,
            "precision": 0.6683250414593698,
            "recall": 0.8837719298245614
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8509071717490416,
            "auditor_fn_violation": 0.008058578992148619,
            "auditor_fp_violation": 0.031033135500195347,
            "ave_precision_score": 0.851218372028606,
            "fpr": 0.19978046103183314,
            "logloss": 0.8619854373934172,
            "mae": 0.27357570290269106,
            "precision": 0.7088,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8324133523097978,
            "auditor_fn_violation": 0.00887292243767313,
            "auditor_fp_violation": 0.020636157279162827,
            "ave_precision_score": 0.832663259797854,
            "fpr": 0.15570175438596492,
            "logloss": 0.7199571671136618,
            "mae": 0.27182460317242707,
            "precision": 0.723196881091618,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8400069851919956,
            "auditor_fn_violation": 0.009579481482461127,
            "auditor_fp_violation": 0.02027944705948018,
            "ave_precision_score": 0.8404783378425937,
            "fpr": 0.13062568605927552,
            "logloss": 0.7249289243027817,
            "mae": 0.27863394040336453,
            "precision": 0.7638888888888888,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8236165896079342,
            "auditor_fn_violation": 0.018147410741766696,
            "auditor_fp_violation": 0.029509079716835956,
            "ave_precision_score": 0.8237469094634016,
            "fpr": 0.22807017543859648,
            "logloss": 1.2716924277376236,
            "mae": 0.29132821129012537,
            "precision": 0.6628849270664505,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8390043621318769,
            "auditor_fn_violation": 0.011660252425729262,
            "auditor_fp_violation": 0.021063514802933215,
            "ave_precision_score": 0.8394809576697697,
            "fpr": 0.20856201975850713,
            "logloss": 1.0151874178711393,
            "mae": 0.27699075219938785,
            "precision": 0.7012578616352201,
            "recall": 0.8955823293172691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.824876584533022,
            "auditor_fn_violation": 0.01617324561403509,
            "auditor_fp_violation": 0.02244681055709449,
            "ave_precision_score": 0.8251829209525129,
            "fpr": 0.20285087719298245,
            "logloss": 0.8749755352142287,
            "mae": 0.2809958483675826,
            "precision": 0.6832191780821918,
            "recall": 0.875
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8474819223940938,
            "auditor_fn_violation": 0.010101878424785863,
            "auditor_fp_violation": 0.028242385904854055,
            "ave_precision_score": 0.847806884433033,
            "fpr": 0.17672886937431395,
            "logloss": 0.7386992708689788,
            "mae": 0.26473172269235107,
            "precision": 0.7261904761904762,
            "recall": 0.857429718875502
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8508750360196177,
            "auditor_fn_violation": 0.016310307017543862,
            "auditor_fp_violation": 0.02241074176669745,
            "ave_precision_score": 0.851088577100378,
            "fpr": 0.19846491228070176,
            "logloss": 0.7319896663571032,
            "mae": 0.2794730933237047,
            "precision": 0.6879310344827586,
            "recall": 0.875
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8606809251828791,
            "auditor_fn_violation": 0.007692680711870537,
            "auditor_fp_violation": 0.02502637922831787,
            "ave_precision_score": 0.8610325990204611,
            "fpr": 0.16465422612513722,
            "logloss": 0.6326967050109208,
            "mae": 0.26066173406247284,
            "precision": 0.7457627118644068,
            "recall": 0.8835341365461847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8270227961998448,
            "auditor_fn_violation": 0.013239650661742076,
            "auditor_fp_violation": 0.021232494613727303,
            "ave_precision_score": 0.8272769708973086,
            "fpr": 0.15679824561403508,
            "logloss": 0.7509981209159877,
            "mae": 0.27538625849517234,
            "precision": 0.718503937007874,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8383474970564054,
            "auditor_fn_violation": 0.006678745718328859,
            "auditor_fp_violation": 0.023200431635937418,
            "ave_precision_score": 0.8387199203340483,
            "fpr": 0.13830954994511527,
            "logloss": 0.7448611377495905,
            "mae": 0.27976328703856307,
            "precision": 0.7509881422924901,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8235218445432615,
            "auditor_fn_violation": 0.012609649122807019,
            "auditor_fp_violation": 0.02185768698060942,
            "ave_precision_score": 0.8238072899232346,
            "fpr": 0.20285087719298245,
            "logloss": 0.7932900214818022,
            "mae": 0.2902838929733865,
            "precision": 0.6810344827586207,
            "recall": 0.8662280701754386
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8390744458907888,
            "auditor_fn_violation": 0.007994657003425337,
            "auditor_fp_violation": 0.028651695845504102,
            "ave_precision_score": 0.839436355377474,
            "fpr": 0.18331503841931943,
            "logloss": 0.749881103492002,
            "mae": 0.2780361005857964,
            "precision": 0.7159863945578231,
            "recall": 0.8453815261044176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7973997979347882,
            "auditor_fn_violation": 0.018450388581101877,
            "auditor_fp_violation": 0.01940500923361034,
            "ave_precision_score": 0.797762663979195,
            "fpr": 0.1513157894736842,
            "logloss": 0.9276445293072824,
            "mae": 0.2790843636191235,
            "precision": 0.7189409368635438,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8283440379456296,
            "auditor_fn_violation": 0.004179175538597859,
            "auditor_fp_violation": 0.01797774310751297,
            "ave_precision_score": 0.8288067374933523,
            "fpr": 0.1141602634467618,
            "logloss": 0.9138396907896057,
            "mae": 0.27836861142949226,
            "precision": 0.7787234042553192,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5231037221379913,
            "auditor_fn_violation": 0.004563904278239461,
            "auditor_fp_violation": 0.008512234533702678,
            "ave_precision_score": 0.5141703220319682,
            "fpr": 0.0756578947368421,
            "logloss": 14.42624126932498,
            "mae": 0.49240155483665643,
            "precision": 0.5174825174825175,
            "recall": 0.16228070175438597
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5571552490537249,
            "auditor_fn_violation": 0.002750849721608744,
            "auditor_fp_violation": 0.008101147396762199,
            "ave_precision_score": 0.5596971731225107,
            "fpr": 0.048298572996706916,
            "logloss": 15.391507298457435,
            "mae": 0.508757407580755,
            "precision": 0.6507936507936508,
            "recall": 0.1646586345381526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8525683809798219,
            "auditor_fn_violation": 0.014297668513388737,
            "auditor_fp_violation": 0.025075023084025854,
            "ave_precision_score": 0.8528280500224898,
            "fpr": 0.2236842105263158,
            "logloss": 0.7595081015681878,
            "mae": 0.2935178767924107,
            "precision": 0.6682926829268293,
            "recall": 0.9013157894736842
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8620175542579497,
            "auditor_fn_violation": 0.0059271112992034004,
            "auditor_fp_violation": 0.029465000013289288,
            "ave_precision_score": 0.8622838774034196,
            "fpr": 0.1986827661909989,
            "logloss": 0.6615737280215739,
            "mae": 0.27141037781862304,
            "precision": 0.7154088050314465,
            "recall": 0.9136546184738956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8414552192115596,
            "auditor_fn_violation": 0.014694425207756235,
            "auditor_fp_violation": 0.018337373037857818,
            "ave_precision_score": 0.8416977933278548,
            "fpr": 0.22039473684210525,
            "logloss": 0.7595362552424556,
            "mae": 0.2892321593451291,
            "precision": 0.6694078947368421,
            "recall": 0.8925438596491229
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.853716071519711,
            "auditor_fn_violation": 0.008702207292396813,
            "auditor_fp_violation": 0.02741313459652406,
            "ave_precision_score": 0.8539952794967898,
            "fpr": 0.18660812294182216,
            "logloss": 0.6993037942521407,
            "mae": 0.2731317409485747,
            "precision": 0.7231270358306189,
            "recall": 0.891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.796342392060338,
            "auditor_fn_violation": 0.01878462603878117,
            "auditor_fp_violation": 0.02326196522006771,
            "ave_precision_score": 0.7973614243667306,
            "fpr": 0.1787280701754386,
            "logloss": 0.8768754489828335,
            "mae": 0.2790448131310516,
            "precision": 0.6953271028037383,
            "recall": 0.8157894736842105
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8325297720592495,
            "auditor_fn_violation": 0.011237044776250997,
            "auditor_fp_violation": 0.025850314823132926,
            "ave_precision_score": 0.8329480685505382,
            "fpr": 0.15477497255762898,
            "logloss": 0.7827857450917464,
            "mae": 0.2728532937663852,
            "precision": 0.7422303473491774,
            "recall": 0.8152610441767069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8258417306452569,
            "auditor_fn_violation": 0.013109803016312715,
            "auditor_fp_violation": 0.021439289012003697,
            "ave_precision_score": 0.8260949164373369,
            "fpr": 0.15460526315789475,
            "logloss": 0.7551708985611161,
            "mae": 0.2765690521573991,
            "precision": 0.7196819085487077,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8362977206467759,
            "auditor_fn_violation": 0.005849964071433932,
            "auditor_fp_violation": 0.019397038616000832,
            "ave_precision_score": 0.8366856788999593,
            "fpr": 0.1350164654226125,
            "logloss": 0.7550003048909343,
            "mae": 0.2814826438117847,
            "precision": 0.7535070140280561,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8008998112549481,
            "auditor_fn_violation": 0.020232186826715914,
            "auditor_fp_violation": 0.017096606648199442,
            "ave_precision_score": 0.801286458419574,
            "fpr": 0.17763157894736842,
            "logloss": 0.903683526335378,
            "mae": 0.2831008095322276,
            "precision": 0.6977611940298507,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.827626635679273,
            "auditor_fn_violation": 0.012325922791054449,
            "auditor_fp_violation": 0.026544015436832057,
            "ave_precision_score": 0.8282261420163224,
            "fpr": 0.14818880351262348,
            "logloss": 0.8176906140741708,
            "mae": 0.2767092803806483,
            "precision": 0.7467166979362101,
            "recall": 0.7991967871485943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.824082539006396,
            "auditor_fn_violation": 0.003890620190827947,
            "auditor_fp_violation": 0.030430036164973855,
            "ave_precision_score": 0.8243527598039233,
            "fpr": 0.37390350877192985,
            "logloss": 1.710489138859203,
            "mae": 0.38267219682174636,
            "precision": 0.5661577608142494,
            "recall": 0.9758771929824561
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8432573420988578,
            "auditor_fn_violation": 0.003901445518627749,
            "auditor_fp_violation": 0.020898727683970206,
            "ave_precision_score": 0.8436445768737404,
            "fpr": 0.33479692645444564,
            "logloss": 1.4869482749364777,
            "mae": 0.34237175008654946,
            "precision": 0.6144121365360303,
            "recall": 0.9759036144578314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 19863,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5874473612844573,
            "auditor_fn_violation": 0.008887349953831954,
            "auditor_fp_violation": 0.002921572022160666,
            "ave_precision_score": 0.5928565486389936,
            "fpr": 0.03618421052631579,
            "logloss": 12.943137544618814,
            "mae": 0.43592450652483267,
            "precision": 0.7441860465116279,
            "recall": 0.21052631578947367
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6130736723691264,
            "auditor_fn_violation": 0.007683863885839741,
            "auditor_fp_violation": 0.005990809131332676,
            "ave_precision_score": 0.6263474878462699,
            "fpr": 0.02854006586169045,
            "logloss": 14.148620538824701,
            "mae": 0.46357709836514294,
            "precision": 0.803030303030303,
            "recall": 0.21285140562248997
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.5906127715402949,
            "auditor_fn_violation": 0.011166897506925233,
            "auditor_fp_violation": 0.0017024469067405364,
            "ave_precision_score": 0.5960283512017858,
            "fpr": 0.039473684210526314,
            "logloss": 12.897593559631208,
            "mae": 0.4342117780358633,
            "precision": 0.7391304347826086,
            "recall": 0.2236842105263158
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6178169923120828,
            "auditor_fn_violation": 0.008858705954443458,
            "auditor_fp_violation": 0.007423393923607882,
            "ave_precision_score": 0.6303823961466868,
            "fpr": 0.030735455543358946,
            "logloss": 14.129622267502269,
            "mae": 0.4666511795173255,
            "precision": 0.7925925925925926,
            "recall": 0.21485943775100402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8004067136300448,
            "auditor_fn_violation": 0.00918070944906125,
            "auditor_fp_violation": 0.023182613881194223,
            "ave_precision_score": 0.8006587213107008,
            "fpr": 0.3826754385964912,
            "logloss": 2.3327549254171576,
            "mae": 0.41570669019628825,
            "precision": 0.5490956072351422,
            "recall": 0.9320175438596491
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.814390525098378,
            "auditor_fn_violation": 0.01332442833904223,
            "auditor_fp_violation": 0.03293350308178491,
            "ave_precision_score": 0.8145128554261349,
            "fpr": 0.35236004390779363,
            "logloss": 2.111884480431223,
            "mae": 0.39384285590876134,
            "precision": 0.5841968911917098,
            "recall": 0.9056224899598394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8458730978194894,
            "auditor_fn_violation": 0.016887407663896584,
            "auditor_fp_violation": 0.022391505078485686,
            "ave_precision_score": 0.846125990532157,
            "fpr": 0.21052631578947367,
            "logloss": 0.8108150553381404,
            "mae": 0.28541606864811586,
            "precision": 0.679465776293823,
            "recall": 0.8925438596491229
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8562222108749467,
            "auditor_fn_violation": 0.006967496770837465,
            "auditor_fp_violation": 0.0312617111813376,
            "ave_precision_score": 0.8565277105650921,
            "fpr": 0.18990120746432493,
            "logloss": 0.6877167419837086,
            "mae": 0.2665356920716651,
            "precision": 0.7191558441558441,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8454021902470414,
            "auditor_fn_violation": 0.017276950600184676,
            "auditor_fp_violation": 0.024762426900584795,
            "ave_precision_score": 0.8456684926990402,
            "fpr": 0.20833333333333334,
            "logloss": 0.8013954356002639,
            "mae": 0.28674513646169114,
            "precision": 0.680672268907563,
            "recall": 0.8881578947368421
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.856075689796315,
            "auditor_fn_violation": 0.007822728895824792,
            "auditor_fp_violation": 0.0287606679725603,
            "ave_precision_score": 0.8563950605159649,
            "fpr": 0.18660812294182216,
            "logloss": 0.6689269102779973,
            "mae": 0.2656157483393335,
            "precision": 0.7226753670473083,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8356911332102575,
            "auditor_fn_violation": 0.013092970914127427,
            "auditor_fp_violation": 0.016418513388735,
            "ave_precision_score": 0.8359396067755354,
            "fpr": 0.16447368421052633,
            "logloss": 0.6876559103339448,
            "mae": 0.2730106071357559,
            "precision": 0.7175141242937854,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8498314436976653,
            "auditor_fn_violation": 0.010064406914154975,
            "auditor_fp_violation": 0.020912016967757543,
            "ave_precision_score": 0.8501437328621422,
            "fpr": 0.13830954994511527,
            "logloss": 0.6706072630464881,
            "mae": 0.26788926242990785,
            "precision": 0.7586206896551724,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8312618124801353,
            "auditor_fn_violation": 0.009223991997537706,
            "auditor_fp_violation": 0.022641582025238534,
            "ave_precision_score": 0.831521322530203,
            "fpr": 0.1524122807017544,
            "logloss": 0.6712353343475217,
            "mae": 0.27506909537388846,
            "precision": 0.7225548902195609,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8420452875695605,
            "auditor_fn_violation": 0.006579556425482395,
            "auditor_fp_violation": 0.01618900550973706,
            "ave_precision_score": 0.8423929483862858,
            "fpr": 0.12733260153677278,
            "logloss": 0.6863271062262732,
            "mae": 0.2766498741862619,
            "precision": 0.7637474541751528,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8015580336415825,
            "auditor_fn_violation": 0.010416666666666668,
            "auditor_fp_violation": 0.013273314866112659,
            "ave_precision_score": 0.8019158808690736,
            "fpr": 0.18201754385964913,
            "logloss": 0.8958495181673459,
            "mae": 0.2822034838007959,
            "precision": 0.6959706959706959,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8263354943717494,
            "auditor_fn_violation": 0.003107931175856008,
            "auditor_fp_violation": 0.02334129804408322,
            "ave_precision_score": 0.826811859342394,
            "fpr": 0.15587266739846323,
            "logloss": 0.871782545170462,
            "mae": 0.28067694947290694,
            "precision": 0.7340823970037453,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.82970252887021,
            "auditor_fn_violation": 0.006396198830409356,
            "auditor_fp_violation": 0.02736899815327794,
            "ave_precision_score": 0.8299299228225433,
            "fpr": 0.3848684210526316,
            "logloss": 1.9697523550154405,
            "mae": 0.38980260936012706,
            "precision": 0.5595984943538268,
            "recall": 0.9780701754385965
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.8470991378839927,
            "auditor_fn_violation": 0.004787536534722865,
            "auditor_fp_violation": 0.01714849179918298,
            "ave_precision_score": 0.8470275231509085,
            "fpr": 0.3402854006586169,
            "logloss": 1.715264753780355,
            "mae": 0.3507344995416348,
            "precision": 0.6110414052697616,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8422019197796569,
            "auditor_fn_violation": 0.014636715143120961,
            "auditor_fp_violation": 0.021494594490612497,
            "ave_precision_score": 0.8424877544349303,
            "fpr": 0.18969298245614036,
            "logloss": 0.6827520227285532,
            "mae": 0.27943018822237387,
            "precision": 0.6932624113475178,
            "recall": 0.8574561403508771
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.85682498210332,
            "auditor_fn_violation": 0.007994657003425337,
            "auditor_fp_violation": 0.0307806391082359,
            "ave_precision_score": 0.857113434772883,
            "fpr": 0.16355653128430298,
            "logloss": 0.6258368192110272,
            "mae": 0.26464629614841473,
            "precision": 0.7385964912280701,
            "recall": 0.8453815261044176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8205121297902089,
            "auditor_fn_violation": 0.02096799015081564,
            "auditor_fp_violation": 0.02938163665743306,
            "ave_precision_score": 0.8192498034862751,
            "fpr": 0.16776315789473684,
            "logloss": 2.573436754582133,
            "mae": 0.2802714006406748,
            "precision": 0.7040618955512572,
            "recall": 0.7982456140350878
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8151572035488281,
            "auditor_fn_violation": 0.02569663946675836,
            "auditor_fp_violation": 0.028359331602182635,
            "ave_precision_score": 0.8146707730996061,
            "fpr": 0.14928649835345773,
            "logloss": 3.2137172105511995,
            "mae": 0.2964955744598707,
            "precision": 0.7354085603112841,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.86721953954621,
            "auditor_fn_violation": 0.0150382810095414,
            "auditor_fp_violation": 0.029893813481071098,
            "ave_precision_score": 0.8674537671911212,
            "fpr": 0.19736842105263158,
            "logloss": 0.5747073103026932,
            "mae": 0.28253074203902395,
            "precision": 0.6943972835314092,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.863930488001143,
            "auditor_fn_violation": 0.014018753388967504,
            "auditor_fp_violation": 0.03246306243571309,
            "ave_precision_score": 0.8643464330513626,
            "fpr": 0.1734357848518112,
            "logloss": 0.5672425808921905,
            "mae": 0.2776275844186957,
            "precision": 0.7362270450751253,
            "recall": 0.8855421686746988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8066611342359202,
            "auditor_fn_violation": 0.017178362573099414,
            "auditor_fp_violation": 0.018743748076331185,
            "ave_precision_score": 0.8069976726758372,
            "fpr": 0.18530701754385964,
            "logloss": 0.9228792656395445,
            "mae": 0.2827802036000755,
            "precision": 0.692167577413479,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8294245517924197,
            "auditor_fn_violation": 0.014051816486583001,
            "auditor_fp_violation": 0.023208405206209815,
            "ave_precision_score": 0.8299662119252067,
            "fpr": 0.1668496158068057,
            "logloss": 0.8362226141948085,
            "mae": 0.27541280109289495,
            "precision": 0.7261261261261261,
            "recall": 0.8092369477911646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8148008647284071,
            "auditor_fn_violation": 0.015769275161588183,
            "auditor_fp_violation": 0.021381578947368418,
            "ave_precision_score": 0.8151552393503865,
            "fpr": 0.18092105263157895,
            "logloss": 1.0440218191358432,
            "mae": 0.2777843472828737,
            "precision": 0.6983546617915904,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8399216622373626,
            "auditor_fn_violation": 0.011768258544606527,
            "auditor_fp_violation": 0.02152598187873263,
            "ave_precision_score": 0.8402879563764152,
            "fpr": 0.15367727771679474,
            "logloss": 0.806326817306478,
            "mae": 0.2702781062446216,
            "precision": 0.7449908925318761,
            "recall": 0.821285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 19863,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8347508147217603,
            "auditor_fn_violation": 0.011154874576792859,
            "auditor_fp_violation": 0.03692722760849494,
            "ave_precision_score": 0.8350002108214047,
            "fpr": 0.30372807017543857,
            "logloss": 1.2240523340740113,
            "mae": 0.33526372479843397,
            "precision": 0.6087570621468926,
            "recall": 0.9451754385964912
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8443894518984749,
            "auditor_fn_violation": 0.005356221813709283,
            "auditor_fp_violation": 0.027043692507236036,
            "ave_precision_score": 0.8448023452031709,
            "fpr": 0.2491767288693743,
            "logloss": 1.0808216671119737,
            "mae": 0.3000151703701885,
            "precision": 0.6743185078909613,
            "recall": 0.9437751004016064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.826904311022636,
            "auditor_fn_violation": 0.015437442289935365,
            "auditor_fp_violation": 0.024584487534626043,
            "ave_precision_score": 0.8271930132838505,
            "fpr": 0.22697368421052633,
            "logloss": 0.8451456517908168,
            "mae": 0.30085664054772077,
            "precision": 0.6612111292962357,
            "recall": 0.8859649122807017
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8441252913242245,
            "auditor_fn_violation": 0.007207755280176691,
            "auditor_fp_violation": 0.03240724744380628,
            "ave_precision_score": 0.8444803760670523,
            "fpr": 0.20417124039517015,
            "logloss": 0.7207900709640555,
            "mae": 0.27747942316930624,
            "precision": 0.7070866141732284,
            "recall": 0.9016064257028112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8223947768897407,
            "auditor_fn_violation": 0.025204870729455216,
            "auditor_fp_violation": 0.023834256694367503,
            "ave_precision_score": 0.8226415146434407,
            "fpr": 0.13157894736842105,
            "logloss": 1.3543248465047673,
            "mae": 0.268296237826784,
            "precision": 0.7424892703862661,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8228386799251556,
            "auditor_fn_violation": 0.02958485974633992,
            "auditor_fp_violation": 0.028768641542832693,
            "ave_precision_score": 0.8232495092742597,
            "fpr": 0.11855104281009879,
            "logloss": 1.5778831155160413,
            "mae": 0.28801750245575886,
            "precision": 0.7647058823529411,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 19863,
        "test": {
            "accuracy": 0.41118421052631576,
            "auc_prc": 0.41943880574202275,
            "auditor_fn_violation": 0.015194579101261933,
            "auditor_fp_violation": 0.013157894736842118,
            "ave_precision_score": 0.3980845066463855,
            "fpr": 0.32456140350877194,
            "logloss": 14.452475812180047,
            "mae": 0.598136565374974,
            "precision": 0.4207436399217221,
            "recall": 0.47149122807017546
        },
        "train": {
            "accuracy": 0.3929747530186608,
            "auc_prc": 0.4605353680072847,
            "auditor_fn_violation": 0.015103222990755573,
            "auditor_fp_violation": 0.01481223570936869,
            "ave_precision_score": 0.4409484373031842,
            "fpr": 0.3040614709110867,
            "logloss": 15.079375499864506,
            "mae": 0.6107117059319815,
            "precision": 0.44488977955911824,
            "recall": 0.4457831325301205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7699376407238745,
            "auditor_fn_violation": 0.02310807171437366,
            "auditor_fp_violation": 0.024031432748538015,
            "ave_precision_score": 0.7704463091927912,
            "fpr": 0.14583333333333334,
            "logloss": 1.050004106331809,
            "mae": 0.2968475788281238,
            "precision": 0.7158119658119658,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.798983255704184,
            "auditor_fn_violation": 0.02022800312115641,
            "auditor_fp_violation": 0.02779586596959944,
            "ave_precision_score": 0.7994715643359163,
            "fpr": 0.13721185510428102,
            "logloss": 1.1635900900468494,
            "mae": 0.3152704298378025,
            "precision": 0.7351694915254238,
            "recall": 0.6967871485943775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8086758109480169,
            "auditor_fn_violation": 0.012518274853801175,
            "auditor_fp_violation": 0.021189212065250845,
            "ave_precision_score": 0.8090260999274453,
            "fpr": 0.17982456140350878,
            "logloss": 0.8583950858412615,
            "mae": 0.2791843347862291,
            "precision": 0.7012750455373407,
            "recall": 0.8442982456140351
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8254610469280123,
            "auditor_fn_violation": 0.012319310171531353,
            "auditor_fp_violation": 0.023447612314381926,
            "ave_precision_score": 0.8261812942816885,
            "fpr": 0.15697036223929747,
            "logloss": 0.8414101887379541,
            "mae": 0.2769912253537173,
            "precision": 0.7361623616236163,
            "recall": 0.8012048192771084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8280056880519027,
            "auditor_fn_violation": 0.015011830563250231,
            "auditor_fp_violation": 0.02038367574638351,
            "ave_precision_score": 0.8282985476106269,
            "fpr": 0.21820175438596492,
            "logloss": 0.8982789297170124,
            "mae": 0.288346666761825,
            "precision": 0.6716171617161716,
            "recall": 0.8925438596491229
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8500514992015745,
            "auditor_fn_violation": 0.007049052411622341,
            "auditor_fp_violation": 0.029010506507762275,
            "ave_precision_score": 0.8503468928478441,
            "fpr": 0.1942919868276619,
            "logloss": 0.7834750395780579,
            "mae": 0.2699821092176091,
            "precision": 0.714975845410628,
            "recall": 0.891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8359312858974384,
            "auditor_fn_violation": 0.024295937211449688,
            "auditor_fp_violation": 0.010705216989843032,
            "ave_precision_score": 0.8361963106265811,
            "fpr": 0.07456140350877193,
            "logloss": 0.7868610405010699,
            "mae": 0.2813602966754831,
            "precision": 0.8152173913043478,
            "recall": 0.6578947368421053
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8507363904287382,
            "auditor_fn_violation": 0.0103200948690481,
            "auditor_fp_violation": 0.010961001267797671,
            "ave_precision_score": 0.8510802463648616,
            "fpr": 0.06366630076838639,
            "logloss": 0.7643726314133145,
            "mae": 0.29007075548282235,
            "precision": 0.8453333333333334,
            "recall": 0.6365461847389559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8127573585915491,
            "auditor_fn_violation": 0.005468028624192063,
            "auditor_fp_violation": 0.018676419667590035,
            "ave_precision_score": 0.8130381072121963,
            "fpr": 0.13706140350877194,
            "logloss": 1.2500380479469677,
            "mae": 0.279697683995318,
            "precision": 0.7340425531914894,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8205298125596716,
            "auditor_fn_violation": 0.004946239403277223,
            "auditor_fp_violation": 0.022434968889786657,
            "ave_precision_score": 0.821035196447548,
            "fpr": 0.1163556531284303,
            "logloss": 1.4292352858250872,
            "mae": 0.2952349191648196,
            "precision": 0.7654867256637168,
            "recall": 0.6947791164658634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5944935650489089,
            "auditor_fn_violation": 0.010618651892890128,
            "auditor_fp_violation": 0.0017817982456140363,
            "ave_precision_score": 0.5998363389087691,
            "fpr": 0.051535087719298246,
            "logloss": 12.961759552445544,
            "mae": 0.44262539508827,
            "precision": 0.6802721088435374,
            "recall": 0.21929824561403508
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6162633533665927,
            "auditor_fn_violation": 0.010566965997910438,
            "auditor_fp_violation": 0.0055123949149884525,
            "ave_precision_score": 0.6290301163884633,
            "fpr": 0.04061470911086718,
            "logloss": 14.134750441316646,
            "mae": 0.465073945811722,
            "precision": 0.7549668874172185,
            "recall": 0.2289156626506024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8081155127604023,
            "auditor_fn_violation": 0.0131506809787627,
            "auditor_fp_violation": 0.023964104339796857,
            "ave_precision_score": 0.8084693771968002,
            "fpr": 0.20394736842105263,
            "logloss": 0.9275007388801719,
            "mae": 0.2850787773070395,
            "precision": 0.6809605488850772,
            "recall": 0.8706140350877193
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8338199219570096,
            "auditor_fn_violation": 0.01056035337838732,
            "auditor_fp_violation": 0.02967497069712926,
            "ave_precision_score": 0.8342373457311402,
            "fpr": 0.18221734357848518,
            "logloss": 0.8487129666941723,
            "mae": 0.27604805639829827,
            "precision": 0.7181663837011885,
            "recall": 0.8493975903614458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8067183946286864,
            "auditor_fn_violation": 0.013297360726377348,
            "auditor_fp_violation": 0.02102089104339797,
            "ave_precision_score": 0.8070475925163675,
            "fpr": 0.17214912280701755,
            "logloss": 0.877661168054107,
            "mae": 0.2784930333831827,
            "precision": 0.704331450094162,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8212122206072182,
            "auditor_fn_violation": 0.009513355287230157,
            "auditor_fp_violation": 0.02152598187873263,
            "ave_precision_score": 0.8218368692977138,
            "fpr": 0.15367727771679474,
            "logloss": 0.8753688935475521,
            "mae": 0.28004863129495844,
            "precision": 0.7368421052631579,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8596528667977171,
            "auditor_fn_violation": 0.013573888119421361,
            "auditor_fp_violation": 0.019881117266851343,
            "ave_precision_score": 0.8598677020764957,
            "fpr": 0.20723684210526316,
            "logloss": 0.6956730640083402,
            "mae": 0.28466939323031426,
            "precision": 0.6796610169491526,
            "recall": 0.8793859649122807
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8603843973363713,
            "auditor_fn_violation": 0.006008666939988277,
            "auditor_fp_violation": 0.027453002447886076,
            "ave_precision_score": 0.8606880453887424,
            "fpr": 0.16355653128430298,
            "logloss": 0.590380517177031,
            "mae": 0.26587197708405946,
            "precision": 0.7470288624787776,
            "recall": 0.8835341365461847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8520603161245179,
            "auditor_fn_violation": 0.01616362726992921,
            "auditor_fp_violation": 0.02360341643582641,
            "ave_precision_score": 0.8523059154573693,
            "fpr": 0.21052631578947367,
            "logloss": 0.7707859436232719,
            "mae": 0.2856411678745034,
            "precision": 0.6810631229235881,
            "recall": 0.8991228070175439
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8592192917110741,
            "auditor_fn_violation": 0.006967496770837465,
            "auditor_fp_violation": 0.028415146594089464,
            "ave_precision_score": 0.8595162577613158,
            "fpr": 0.1877058177826564,
            "logloss": 0.656838594031451,
            "mae": 0.26669197768991176,
            "precision": 0.7214983713355049,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8367052052009996,
            "auditor_fn_violation": 0.024295937211449688,
            "auditor_fp_violation": 0.010705216989843032,
            "ave_precision_score": 0.8369686969283453,
            "fpr": 0.07456140350877193,
            "logloss": 0.7827619904487946,
            "mae": 0.2810444327339691,
            "precision": 0.8152173913043478,
            "recall": 0.6578947368421053
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8509415676150348,
            "auditor_fn_violation": 0.009718346492446189,
            "auditor_fp_violation": 0.010961001267797671,
            "ave_precision_score": 0.8512860139010335,
            "fpr": 0.06366630076838639,
            "logloss": 0.760065484162383,
            "mae": 0.28989529125284685,
            "precision": 0.8453333333333334,
            "recall": 0.6365461847389559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 19863,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.8045101325549993,
            "auditor_fn_violation": 0.008305440135426286,
            "auditor_fp_violation": 0.01862111418898124,
            "ave_precision_score": 0.8045725971733795,
            "fpr": 0.3991228070175439,
            "logloss": 2.6494223002095385,
            "mae": 0.42986892431166646,
            "precision": 0.5398230088495575,
            "recall": 0.9364035087719298
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.8142850969014964,
            "auditor_fn_violation": 0.014012140769444409,
            "auditor_fp_violation": 0.03498536849855015,
            "ave_precision_score": 0.8153144474622276,
            "fpr": 0.36553238199780463,
            "logloss": 2.4072597689248427,
            "mae": 0.4048690905042019,
            "precision": 0.5774111675126904,
            "recall": 0.9136546184738956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8208171464458894,
            "auditor_fn_violation": 0.016995614035087717,
            "auditor_fp_violation": 0.027551746691289628,
            "ave_precision_score": 0.8211070388074425,
            "fpr": 0.23793859649122806,
            "logloss": 1.118639681473413,
            "mae": 0.2948447661462551,
            "precision": 0.6505636070853462,
            "recall": 0.8859649122807017
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8367467367433123,
            "auditor_fn_violation": 0.010946089517234692,
            "auditor_fp_violation": 0.03182783467067826,
            "ave_precision_score": 0.8369980477812557,
            "fpr": 0.21185510428100987,
            "logloss": 1.0107319227209348,
            "mae": 0.2807750805318283,
            "precision": 0.6960629921259842,
            "recall": 0.8875502008032129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.806309663201295,
            "auditor_fn_violation": 0.01312903970452447,
            "auditor_fp_violation": 0.019671918282548474,
            "ave_precision_score": 0.8066565921010673,
            "fpr": 0.18092105263157895,
            "logloss": 0.887247719460464,
            "mae": 0.2794583921560156,
            "precision": 0.6961325966850829,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8219986329231883,
            "auditor_fn_violation": 0.0090504719206133,
            "auditor_fp_violation": 0.021616349008486545,
            "ave_precision_score": 0.8226068750178619,
            "fpr": 0.16355653128430298,
            "logloss": 0.8766253232735856,
            "mae": 0.28097940741407795,
            "precision": 0.7255985267034991,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8295886767969605,
            "auditor_fn_violation": 0.01906355801785165,
            "auditor_fp_violation": 0.01911164973838104,
            "ave_precision_score": 0.8298521370828013,
            "fpr": 0.16228070175438597,
            "logloss": 0.7062187865904754,
            "mae": 0.2740986536891448,
            "precision": 0.7131782945736435,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.839435072921594,
            "auditor_fn_violation": 0.01118855223308161,
            "auditor_fp_violation": 0.022581151011447396,
            "ave_precision_score": 0.8401883673494688,
            "fpr": 0.12952799121844127,
            "logloss": 0.7299119090124686,
            "mae": 0.2739095058207415,
            "precision": 0.7663366336633664,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8508134676633043,
            "auditor_fn_violation": 0.01616362726992921,
            "auditor_fp_violation": 0.02162684672206833,
            "ave_precision_score": 0.8510523970801869,
            "fpr": 0.21600877192982457,
            "logloss": 0.7927119424440892,
            "mae": 0.2878678205657511,
            "precision": 0.6754530477759473,
            "recall": 0.8991228070175439
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8584220423746296,
            "auditor_fn_violation": 0.006810998108790819,
            "auditor_fp_violation": 0.028986585796945075,
            "ave_precision_score": 0.8587164503103644,
            "fpr": 0.19209659714599342,
            "logloss": 0.6812897322236747,
            "mae": 0.2689905064881447,
            "precision": 0.717741935483871,
            "recall": 0.893574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8215440710080134,
            "auditor_fn_violation": 0.015591335795629423,
            "auditor_fp_violation": 0.02284356725146199,
            "ave_precision_score": 0.8218670489155966,
            "fpr": 0.22916666666666666,
            "logloss": 0.8331241505390923,
            "mae": 0.2995506976764253,
            "precision": 0.6601626016260163,
            "recall": 0.8903508771929824
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8391773079067957,
            "auditor_fn_violation": 0.007626554516639555,
            "auditor_fp_violation": 0.03141586687327074,
            "ave_precision_score": 0.8395452138871642,
            "fpr": 0.20087815587266739,
            "logloss": 0.7720549314006632,
            "mae": 0.2809781567624155,
            "precision": 0.7085987261146497,
            "recall": 0.893574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8105269413979153,
            "auditor_fn_violation": 0.01224415204678363,
            "auditor_fp_violation": 0.020083102493074795,
            "ave_precision_score": 0.8108533150286615,
            "fpr": 0.17434210526315788,
            "logloss": 0.8306953715593262,
            "mae": 0.27718520679088693,
            "precision": 0.7060998151571165,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8243510653678536,
            "auditor_fn_violation": 0.012125339998853814,
            "auditor_fp_violation": 0.020457523462230537,
            "ave_precision_score": 0.8250745504722417,
            "fpr": 0.15587266739846323,
            "logloss": 0.8279425340780956,
            "mae": 0.2762009333058293,
            "precision": 0.7355679702048417,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8313786702252584,
            "auditor_fn_violation": 0.012191251154201296,
            "auditor_fp_violation": 0.022694482917820873,
            "ave_precision_score": 0.831625450856721,
            "fpr": 0.15021929824561403,
            "logloss": 0.7374821398113003,
            "mae": 0.2712472573240302,
            "precision": 0.7215447154471545,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8398990552544272,
            "auditor_fn_violation": 0.008415660446395905,
            "auditor_fp_violation": 0.023907421533423876,
            "ave_precision_score": 0.8402822919947366,
            "fpr": 0.12294182217343579,
            "logloss": 0.7454789849754143,
            "mae": 0.27995104895938966,
            "precision": 0.7695473251028807,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5231087592694852,
            "auditor_fn_violation": 0.004198407202216061,
            "auditor_fp_violation": 0.007848568790397047,
            "ave_precision_score": 0.5141856317786382,
            "fpr": 0.07456140350877193,
            "logloss": 14.424099309443882,
            "mae": 0.4913024893800397,
            "precision": 0.5244755244755245,
            "recall": 0.16447368421052633
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5570535346602029,
            "auditor_fn_violation": 0.002750849721608744,
            "auditor_fp_violation": 0.008101147396762199,
            "ave_precision_score": 0.5594376245956512,
            "fpr": 0.048298572996706916,
            "logloss": 15.412321756011503,
            "mae": 0.508713423104623,
            "precision": 0.6507936507936508,
            "recall": 0.1646586345381526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 19863,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.798921710303406,
            "auditor_fn_violation": 0.0016230955678670361,
            "auditor_fp_violation": 0.01610591720529394,
            "ave_precision_score": 0.7986002684575096,
            "fpr": 0.45285087719298245,
            "logloss": 2.6960687713743354,
            "mae": 0.4502018710925939,
            "precision": 0.523094688221709,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.8330696626254313,
            "auditor_fn_violation": 0.000833190059910333,
            "auditor_fp_violation": 0.01864752301039489,
            "ave_precision_score": 0.833135854270187,
            "fpr": 0.40175631174533477,
            "logloss": 2.3396937121185055,
            "mae": 0.4003091835220475,
            "precision": 0.5749128919860628,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8202305304314701,
            "auditor_fn_violation": 0.015370113881194214,
            "auditor_fp_violation": 0.021987534626038783,
            "ave_precision_score": 0.8205377325507328,
            "fpr": 0.1513157894736842,
            "logloss": 0.7048186960119321,
            "mae": 0.2788855051969531,
            "precision": 0.7206477732793523,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8371700604890512,
            "auditor_fn_violation": 0.003438562152010908,
            "auditor_fp_violation": 0.020242237064875625,
            "ave_precision_score": 0.8375301127874066,
            "fpr": 0.1251372118551043,
            "logloss": 0.7212677481027993,
            "mae": 0.2811913553140864,
            "precision": 0.7634854771784232,
            "recall": 0.7389558232931727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8381551429782497,
            "auditor_fn_violation": 0.016173245614035086,
            "auditor_fp_violation": 0.01715431671283472,
            "ave_precision_score": 0.8385096684760893,
            "fpr": 0.10855263157894737,
            "logloss": 0.49386795739389955,
            "mae": 0.30305988398156425,
            "precision": 0.7755102040816326,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.823555417827294,
            "auditor_fn_violation": 0.027508497216087183,
            "auditor_fp_violation": 0.019476774318724875,
            "ave_precision_score": 0.8238269770942866,
            "fpr": 0.11745334796926454,
            "logloss": 0.5709321436423798,
            "mae": 0.3396304235952108,
            "precision": 0.76431718061674,
            "recall": 0.6967871485943775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8063287116052476,
            "auditor_fn_violation": 0.015249884579870731,
            "auditor_fp_violation": 0.01765927977839335,
            "ave_precision_score": 0.8066914344600016,
            "fpr": 0.20285087719298245,
            "logloss": 0.8974998873794333,
            "mae": 0.29087261925216956,
            "precision": 0.6782608695652174,
            "recall": 0.8552631578947368
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8251979165087617,
            "auditor_fn_violation": 0.009328201940583411,
            "auditor_fp_violation": 0.030568010567638474,
            "ave_precision_score": 0.8256637526085187,
            "fpr": 0.1877058177826564,
            "logloss": 0.8226956784236449,
            "mae": 0.28270481668624114,
            "precision": 0.7071917808219178,
            "recall": 0.8293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8415219708173732,
            "auditor_fn_violation": 0.02119161665127732,
            "auditor_fp_violation": 0.02123730378578024,
            "ave_precision_score": 0.8417542965013768,
            "fpr": 0.13157894736842105,
            "logloss": 0.648973297998621,
            "mae": 0.26554292197604806,
            "precision": 0.7494780793319415,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8424140491802484,
            "auditor_fn_violation": 0.017364738867655036,
            "auditor_fp_violation": 0.025573897720356266,
            "ave_precision_score": 0.8428779267362962,
            "fpr": 0.11745334796926454,
            "logloss": 0.6894256806473376,
            "mae": 0.27217381119954315,
            "precision": 0.7807377049180327,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8196366119155174,
            "auditor_fn_violation": 0.01692347645429363,
            "auditor_fp_violation": 0.021441693598030165,
            "ave_precision_score": 0.8199276065428757,
            "fpr": 0.21820175438596492,
            "logloss": 1.030055292813214,
            "mae": 0.28857065312453517,
            "precision": 0.6666666666666666,
            "recall": 0.8728070175438597
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8417749236970488,
            "auditor_fn_violation": 0.009425187026922181,
            "auditor_fp_violation": 0.03188896537610003,
            "ave_precision_score": 0.8421312043328503,
            "fpr": 0.1964873765093304,
            "logloss": 0.8627820719617609,
            "mae": 0.2716033953658686,
            "precision": 0.711755233494364,
            "recall": 0.8875502008032129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8114641610077358,
            "auditor_fn_violation": 0.01644736842105263,
            "auditor_fp_violation": 0.02122287626962142,
            "ave_precision_score": 0.8118181243267267,
            "fpr": 0.1787280701754386,
            "logloss": 0.8626210940579715,
            "mae": 0.27599441587406226,
            "precision": 0.7020109689213894,
            "recall": 0.8421052631578947
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8365619744429702,
            "auditor_fn_violation": 0.014093696410229284,
            "auditor_fp_violation": 0.022578493154689926,
            "ave_precision_score": 0.8370540942160777,
            "fpr": 0.15916575192096596,
            "logloss": 0.7854685172790464,
            "mae": 0.27009167767992714,
            "precision": 0.7373188405797102,
            "recall": 0.8172690763052208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.8364080100930058,
            "auditor_fn_violation": 0.0039026431209602955,
            "auditor_fp_violation": 0.027494036626654367,
            "ave_precision_score": 0.8366702703334968,
            "fpr": 0.3925438596491228,
            "logloss": 1.6985846056660152,
            "mae": 0.3911100900121717,
            "precision": 0.55527950310559,
            "recall": 0.9802631578947368
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8504092593999368,
            "auditor_fn_violation": 0.004437067699998677,
            "auditor_fp_violation": 0.024186496492958013,
            "ave_precision_score": 0.8506614839836053,
            "fpr": 0.34577387486278816,
            "logloss": 1.4900920560992694,
            "mae": 0.3513212453008734,
            "precision": 0.6082089552238806,
            "recall": 0.9819277108433735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8213360374864775,
            "auditor_fn_violation": 0.01789012003693444,
            "auditor_fp_violation": 0.022374672976300407,
            "ave_precision_score": 0.8216614809279836,
            "fpr": 0.20942982456140352,
            "logloss": 0.8726867976549627,
            "mae": 0.28566238536685384,
            "precision": 0.676818950930626,
            "recall": 0.8771929824561403
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.847468381529694,
            "auditor_fn_violation": 0.009028429855536304,
            "auditor_fp_violation": 0.031009214789378153,
            "ave_precision_score": 0.8478022957926891,
            "fpr": 0.18551042810098792,
            "logloss": 0.7502318819707814,
            "mae": 0.26642300472027036,
            "precision": 0.7220394736842105,
            "recall": 0.8815261044176707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8117464621447228,
            "auditor_fn_violation": 0.014095683287165288,
            "auditor_fp_violation": 0.021797572329947678,
            "ave_precision_score": 0.8120673100174112,
            "fpr": 0.18311403508771928,
            "logloss": 0.8814900775237257,
            "mae": 0.2756623907195655,
            "precision": 0.6935779816513762,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8303158741642384,
            "auditor_fn_violation": 0.011748420686037233,
            "auditor_fp_violation": 0.027248347477561042,
            "ave_precision_score": 0.8311288815676334,
            "fpr": 0.15148188803512624,
            "logloss": 0.8590369070450914,
            "mae": 0.2757878008347841,
            "precision": 0.7410881801125704,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8249187167984562,
            "auditor_fn_violation": 0.004804362880886427,
            "auditor_fp_violation": 0.01918859649122807,
            "ave_precision_score": 0.825175171655707,
            "fpr": 0.1875,
            "logloss": 0.731348359772492,
            "mae": 0.2919734405559331,
            "precision": 0.6913357400722022,
            "recall": 0.8399122807017544
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.830662929673404,
            "auditor_fn_violation": 0.017743862386979312,
            "auditor_fp_violation": 0.035463782714894365,
            "ave_precision_score": 0.8312042354034246,
            "fpr": 0.17453347969264543,
            "logloss": 0.7263040759873318,
            "mae": 0.299676677716694,
            "precision": 0.7124773960216998,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8414103358352419,
            "auditor_fn_violation": 0.015487938596491226,
            "auditor_fp_violation": 0.019558902739304402,
            "ave_precision_score": 0.8416584447086175,
            "fpr": 0.1600877192982456,
            "logloss": 0.7203108479409234,
            "mae": 0.26993447015918104,
            "precision": 0.7176015473887815,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8561988238043492,
            "auditor_fn_violation": 0.01246478780103951,
            "auditor_fp_violation": 0.021539271162519972,
            "ave_precision_score": 0.8565465578939274,
            "fpr": 0.1251372118551043,
            "logloss": 0.6271692321906376,
            "mae": 0.26314647143338615,
            "precision": 0.7786407766990291,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8242377692972271,
            "auditor_fn_violation": 0.0197416512773161,
            "auditor_fp_violation": 0.027414685287780856,
            "ave_precision_score": 0.8245452240323621,
            "fpr": 0.20942982456140352,
            "logloss": 0.8847785215845864,
            "mae": 0.2875697106662599,
            "precision": 0.6751700680272109,
            "recall": 0.8706140350877193
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8360593632016531,
            "auditor_fn_violation": 0.01634639546109796,
            "auditor_fp_violation": 0.029228450761874646,
            "ave_precision_score": 0.8368741946009703,
            "fpr": 0.19099890230515917,
            "logloss": 0.8014477866806284,
            "mae": 0.2778519651732631,
            "precision": 0.7114427860696517,
            "recall": 0.8614457831325302
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7851383905410568,
            "auditor_fn_violation": 0.012590412434595261,
            "auditor_fp_violation": 0.01835180055401663,
            "ave_precision_score": 0.7855246788940089,
            "fpr": 0.17653508771929824,
            "logloss": 0.9692410998312951,
            "mae": 0.28708446160277135,
            "precision": 0.6939163498098859,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8160498417794071,
            "auditor_fn_violation": 0.007974819144856047,
            "auditor_fp_violation": 0.025034352798590277,
            "ave_precision_score": 0.8164670791441263,
            "fpr": 0.14270032930845225,
            "logloss": 0.96207010782948,
            "mae": 0.2847393178421777,
            "precision": 0.7440944881889764,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8036110217267761,
            "auditor_fn_violation": 0.011513157894736843,
            "auditor_fp_violation": 0.02092951677439213,
            "ave_precision_score": 0.803968632979923,
            "fpr": 0.17543859649122806,
            "logloss": 0.8674724645753245,
            "mae": 0.2819273995697898,
            "precision": 0.7037037037037037,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8182593224482461,
            "auditor_fn_violation": 0.006171778221558023,
            "auditor_fp_violation": 0.021783793984207017,
            "ave_precision_score": 0.8189695999834421,
            "fpr": 0.16245883644346873,
            "logloss": 0.8778830526940801,
            "mae": 0.28446142705656763,
            "precision": 0.725925925925926,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8117563822969747,
            "auditor_fn_violation": 0.014095683287165288,
            "auditor_fp_violation": 0.021797572329947678,
            "ave_precision_score": 0.8120621733796851,
            "fpr": 0.18311403508771928,
            "logloss": 0.8813608568942617,
            "mae": 0.27566685666008595,
            "precision": 0.6935779816513762,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8303058023683259,
            "auditor_fn_violation": 0.011748420686037233,
            "auditor_fp_violation": 0.027248347477561042,
            "ave_precision_score": 0.8311291065326779,
            "fpr": 0.15148188803512624,
            "logloss": 0.8589928187241778,
            "mae": 0.275786188367691,
            "precision": 0.7410881801125704,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8096082227667646,
            "auditor_fn_violation": 0.019501192674669134,
            "auditor_fp_violation": 0.025911819021237303,
            "ave_precision_score": 0.8099462822020952,
            "fpr": 0.19956140350877194,
            "logloss": 1.0012981032828585,
            "mae": 0.2851462442276679,
            "precision": 0.681260945709282,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8304541583418761,
            "auditor_fn_violation": 0.015402995075802664,
            "auditor_fp_violation": 0.028893560810433688,
            "ave_precision_score": 0.8310193707085423,
            "fpr": 0.19209659714599342,
            "logloss": 0.8945950381341635,
            "mae": 0.2771313266501298,
            "precision": 0.7048903878583473,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8370456925168164,
            "auditor_fn_violation": 0.012321098799630654,
            "auditor_fp_violation": 0.034736649738381045,
            "ave_precision_score": 0.8372927881043919,
            "fpr": 0.2949561403508772,
            "logloss": 1.147212107701607,
            "mae": 0.33049995752625416,
            "precision": 0.6140602582496413,
            "recall": 0.9385964912280702
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8455612442075972,
            "auditor_fn_violation": 0.005197518945154933,
            "auditor_fp_violation": 0.02658122543143661,
            "ave_precision_score": 0.8459423131762018,
            "fpr": 0.24807903402854006,
            "logloss": 1.0175202292836272,
            "mae": 0.29640939240518854,
            "precision": 0.6743515850144092,
            "recall": 0.9397590361445783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8266378956318378,
            "auditor_fn_violation": 0.012927054478301024,
            "auditor_fp_violation": 0.007487880886426592,
            "ave_precision_score": 0.8269150531885532,
            "fpr": 0.05592105263157895,
            "logloss": 0.9073577489144612,
            "mae": 0.3036045199341868,
            "precision": 0.8271186440677966,
            "recall": 0.5350877192982456
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8394706338944711,
            "auditor_fn_violation": 0.01170654076239096,
            "auditor_fp_violation": 0.009531074332279935,
            "ave_precision_score": 0.8398012478951843,
            "fpr": 0.04939626783754116,
            "logloss": 0.9504421433415671,
            "mae": 0.3222359618544607,
            "precision": 0.8548387096774194,
            "recall": 0.5321285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8482220404337114,
            "auditor_fn_violation": 0.015988092489996924,
            "auditor_fp_violation": 0.023338911972914742,
            "ave_precision_score": 0.8484682462392831,
            "fpr": 0.20942982456140352,
            "logloss": 0.7927067250475586,
            "mae": 0.28575790365287124,
            "precision": 0.6816666666666666,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8570475432429991,
            "auditor_fn_violation": 0.006555310153897698,
            "auditor_fp_violation": 0.030687614121724528,
            "ave_precision_score": 0.8573484390074682,
            "fpr": 0.18880351262349068,
            "logloss": 0.6773301653643459,
            "mae": 0.2675336076448451,
            "precision": 0.7198697068403909,
            "recall": 0.8875502008032129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8356146468667641,
            "auditor_fn_violation": 0.012775565558633425,
            "auditor_fp_violation": 0.023172995537088344,
            "ave_precision_score": 0.8358542489027142,
            "fpr": 0.18311403508771928,
            "logloss": 0.7218601973207293,
            "mae": 0.27753117848363384,
            "precision": 0.6985559566787004,
            "recall": 0.8486842105263158
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8481954024727825,
            "auditor_fn_violation": 0.011131242863881436,
            "auditor_fp_violation": 0.028369963029212512,
            "ave_precision_score": 0.8486746096077415,
            "fpr": 0.15806805708013172,
            "logloss": 0.6861047680951551,
            "mae": 0.26871227711246976,
            "precision": 0.7381818181818182,
            "recall": 0.8152610441767069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8082888138099226,
            "auditor_fn_violation": 0.011967624653739612,
            "auditor_fp_violation": 0.020828524161280393,
            "ave_precision_score": 0.8086335091932999,
            "fpr": 0.18201754385964913,
            "logloss": 0.8703421572967165,
            "mae": 0.27895898587087337,
            "precision": 0.6998191681735986,
            "recall": 0.8486842105263158
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8241726860865584,
            "auditor_fn_violation": 0.0131194371338262,
            "auditor_fp_violation": 0.022676833854716232,
            "ave_precision_score": 0.825054064375625,
            "fpr": 0.16465422612513722,
            "logloss": 0.8545708689731706,
            "mae": 0.277589886547453,
            "precision": 0.72875226039783,
            "recall": 0.8092369477911646
        }
    }
]