[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7862683117950671,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7870252233929238,
            "fpr": 0.46271929824561403,
            "logloss": 1.0325711523559127,
            "mae": 0.46399329491613206,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7407952946225684,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7417102050531255,
            "fpr": 0.49066959385290887,
            "logloss": 1.1327298103418517,
            "mae": 0.4833332809868026,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7811946171060972,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7793933766179524,
            "fpr": 0.46271929824561403,
            "logloss": 1.1929658363406115,
            "mae": 0.4603055071804607,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7421552717876772,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7402432765895038,
            "fpr": 0.49066959385290887,
            "logloss": 1.3202371422861625,
            "mae": 0.48246786590465207,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7874414276606949,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7883966022006921,
            "fpr": 0.46271929824561403,
            "logloss": 1.011027833430885,
            "mae": 0.463234066636416,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7436081562743894,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7453431747592918,
            "fpr": 0.49066959385290887,
            "logloss": 1.108376946562843,
            "mae": 0.4821542591085549,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 9540,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5715587976379584,
            "auditor_fn_violation": 0.02051109917651271,
            "auditor_fp_violation": 0.03365864305313046,
            "ave_precision_score": 0.570385859012114,
            "fpr": 0.14912280701754385,
            "logloss": 0.734613527396986,
            "mae": 0.5016932346050836,
            "precision": 0.5496688741721855,
            "recall": 0.33877551020408164
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5094021285815971,
            "auditor_fn_violation": 0.009273628827737631,
            "auditor_fp_violation": 0.05485772941699389,
            "ave_precision_score": 0.5181992994411999,
            "fpr": 0.16245883644346873,
            "logloss": 0.7463932222038702,
            "mae": 0.5015437862778064,
            "precision": 0.5241157556270096,
            "recall": 0.35129310344827586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7451254275186426,
            "auditor_fn_violation": 0.013354815610454708,
            "auditor_fp_violation": 0.013924399268312961,
            "ave_precision_score": 0.7391962894553025,
            "fpr": 0.18969298245614036,
            "logloss": 1.6300403006528115,
            "mae": 0.32865871584752937,
            "precision": 0.6802218114602587,
            "recall": 0.7510204081632653
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7727912933304668,
            "auditor_fn_violation": 0.010910708202430074,
            "auditor_fp_violation": 0.017700636270096774,
            "ave_precision_score": 0.7709752291363176,
            "fpr": 0.17672886937431395,
            "logloss": 1.1825614160378004,
            "mae": 0.2897952208162119,
            "precision": 0.7012987012987013,
            "recall": 0.8146551724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 9540,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5496722781157884,
            "auditor_fn_violation": 0.017948890082348738,
            "auditor_fp_violation": 0.029984617942961672,
            "ave_precision_score": 0.555168003857282,
            "fpr": 0.15021929824561403,
            "logloss": 0.7367822597881759,
            "mae": 0.5016483599331543,
            "precision": 0.5493421052631579,
            "recall": 0.3408163265306122
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.488133249698955,
            "auditor_fn_violation": 0.009273628827737631,
            "auditor_fp_violation": 0.0544648185119973,
            "ave_precision_score": 0.5030504023913767,
            "fpr": 0.16136114160263446,
            "logloss": 0.7495911105001661,
            "mae": 0.5015182439337508,
            "precision": 0.5258064516129032,
            "recall": 0.35129310344827586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.78485166736104,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.781662295061722,
            "fpr": 0.46271929824561403,
            "logloss": 1.2982095261622781,
            "mae": 0.4595061445183921,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.751874513592266,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7468497488439321,
            "fpr": 0.49066959385290887,
            "logloss": 1.4341497325075696,
            "mae": 0.48235211859157656,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7811946171060972,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7793933766179524,
            "fpr": 0.46271929824561403,
            "logloss": 1.1929652433380102,
            "mae": 0.4603055126703622,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7421552717876772,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7402432765895038,
            "fpr": 0.49066959385290887,
            "logloss": 1.3202365184814417,
            "mae": 0.48246786394182073,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7441943435731162,
            "auditor_fn_violation": 0.01405746509129968,
            "auditor_fp_violation": 0.015475596574374325,
            "ave_precision_score": 0.7382292453523932,
            "fpr": 0.18859649122807018,
            "logloss": 1.6436988381298687,
            "mae": 0.33030749903056356,
            "precision": 0.6808905380333952,
            "recall": 0.7489795918367347
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7716134509193706,
            "auditor_fn_violation": 0.010910708202430074,
            "auditor_fp_violation": 0.015713980506707734,
            "ave_precision_score": 0.7689550010356727,
            "fpr": 0.1778265642151482,
            "logloss": 1.206429211396524,
            "mae": 0.28821216791855175,
            "precision": 0.7,
            "recall": 0.8146551724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7305170449389249,
            "auditor_fn_violation": 0.012710347296813465,
            "auditor_fp_violation": 0.017034588841772676,
            "ave_precision_score": 0.7224534441331767,
            "fpr": 0.20065789473684212,
            "logloss": 1.929901979607189,
            "mae": 0.33728379079865767,
            "precision": 0.6690777576853526,
            "recall": 0.7551020408163265
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7525586959892945,
            "auditor_fn_violation": 0.011355463870699122,
            "auditor_fp_violation": 0.023149819383768366,
            "ave_precision_score": 0.7474027380351005,
            "fpr": 0.19978046103183314,
            "logloss": 1.4919499629900046,
            "mae": 0.30164758961586047,
            "precision": 0.675,
            "recall": 0.8146551724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7814510839417014,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.780593789083527,
            "fpr": 0.46271929824561403,
            "logloss": 1.1903707375835095,
            "mae": 0.46029147322763475,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7384363229310924,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7378264029058008,
            "fpr": 0.49066959385290887,
            "logloss": 1.3169089129063747,
            "mae": 0.4824013988744022,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.760900144832108,
            "auditor_fn_violation": 0.004567221625492304,
            "auditor_fp_violation": 0.023260164629583437,
            "ave_precision_score": 0.7551738354704838,
            "fpr": 0.2949561403508772,
            "logloss": 1.5677460591398074,
            "mae": 0.34128371118699374,
            "precision": 0.6243016759776536,
            "recall": 0.9122448979591836
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7655604414589405,
            "auditor_fn_violation": 0.0036952572012566736,
            "auditor_fp_violation": 0.03006505131170851,
            "ave_precision_score": 0.7593524545854222,
            "fpr": 0.2864983534577388,
            "logloss": 1.3881172304420777,
            "mae": 0.3201606447951685,
            "precision": 0.6239193083573487,
            "recall": 0.9331896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7354504887745223,
            "auditor_fn_violation": 0.015075635517364842,
            "auditor_fp_violation": 0.016891681217261173,
            "ave_precision_score": 0.7281006934124408,
            "fpr": 0.17214912280701755,
            "logloss": 1.8469013367098297,
            "mae": 0.33012263557495053,
            "precision": 0.6957364341085271,
            "recall": 0.7326530612244898
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7602376134982167,
            "auditor_fn_violation": 0.012580907680078735,
            "auditor_fp_violation": 0.022115972564996058,
            "ave_precision_score": 0.7551666060763372,
            "fpr": 0.16794731064763996,
            "logloss": 1.4035859764549852,
            "mae": 0.2914733865272934,
            "precision": 0.7057692307692308,
            "recall": 0.790948275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7814510839417014,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.780593789083527,
            "fpr": 0.46271929824561403,
            "logloss": 1.1903702225378667,
            "mae": 0.4602914786521803,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7384363229310924,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7378264029058007,
            "fpr": 0.49066959385290887,
            "logloss": 1.3169083637131245,
            "mae": 0.48240139638814916,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7863212964290163,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7872603015063795,
            "fpr": 0.46271929824561403,
            "logloss": 1.1939622191628168,
            "mae": 0.4517755260070165,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7496018487891098,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7514489924106932,
            "fpr": 0.49066959385290887,
            "logloss": 1.2843890788897596,
            "mae": 0.4728475188842589,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 9540,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.551078358565209,
            "auditor_fn_violation": 0.027792696025778753,
            "auditor_fp_violation": 0.03661033507940468,
            "ave_precision_score": 0.5508857476753843,
            "fpr": 0.12280701754385964,
            "logloss": 0.6934305378682618,
            "mae": 0.5000842193697106,
            "precision": 0.5371900826446281,
            "recall": 0.2653061224489796
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5049165736417633,
            "auditor_fn_violation": 0.04048932586396154,
            "auditor_fp_violation": 0.03841686373604246,
            "ave_precision_score": 0.5052573950568566,
            "fpr": 0.14270032930845225,
            "logloss": 0.6933449977302959,
            "mae": 0.5000386299273054,
            "precision": 0.4779116465863454,
            "recall": 0.25646551724137934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5531567555303583,
            "auditor_fn_violation": 0.0336421410669531,
            "auditor_fp_violation": 0.01808950694271223,
            "ave_precision_score": 0.5546678859335559,
            "fpr": 0.24780701754385964,
            "logloss": 1.8450251970673055,
            "mae": 0.4695081770953811,
            "precision": 0.577570093457944,
            "recall": 0.6306122448979592
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5286981003439976,
            "auditor_fn_violation": 0.0014951360763087184,
            "auditor_fp_violation": 0.009930823123789038,
            "ave_precision_score": 0.5308102709520218,
            "fpr": 0.26344676180021953,
            "logloss": 1.5901797362707792,
            "mae": 0.45830226554381437,
            "precision": 0.55637707948244,
            "recall": 0.6487068965517241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5816792444173731,
            "auditor_fn_violation": 0.015355352667382768,
            "auditor_fp_violation": 0.01793880435686373,
            "ave_precision_score": 0.5691615340509115,
            "fpr": 0.08991228070175439,
            "logloss": 0.6929170620363905,
            "mae": 0.4998406401851721,
            "precision": 0.5858585858585859,
            "recall": 0.23673469387755103
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5068259300376923,
            "auditor_fn_violation": 0.01317706953329043,
            "auditor_fp_violation": 0.0027749332665384825,
            "ave_precision_score": 0.5049965718239843,
            "fpr": 0.12733260153677278,
            "logloss": 0.6933575756619428,
            "mae": 0.5000625766331226,
            "precision": 0.45023696682464454,
            "recall": 0.20474137931034483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 9540,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5806382776840889,
            "auditor_fn_violation": 0.005867346938775523,
            "auditor_fp_violation": 0.021160721709486997,
            "ave_precision_score": 0.5688971850017885,
            "fpr": 0.17105263157894737,
            "logloss": 0.6977528313331508,
            "mae": 0.49913186534193527,
            "precision": 0.5465116279069767,
            "recall": 0.3836734693877551
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5020294490480607,
            "auditor_fn_violation": 0.009330406147091125,
            "auditor_fp_violation": 0.03542582947175584,
            "ave_precision_score": 0.529533296351062,
            "fpr": 0.18551042810098792,
            "logloss": 0.6952962901145017,
            "mae": 0.4980771348256573,
            "precision": 0.5212464589235127,
            "recall": 0.39655172413793105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.850574171072427,
            "auditor_fn_violation": 0.011222252058718225,
            "auditor_fp_violation": 0.008948615614866554,
            "ave_precision_score": 0.8504863728243466,
            "fpr": 0.09210526315789473,
            "logloss": 0.6652692954174558,
            "mae": 0.4853517335365739,
            "precision": 0.8112359550561797,
            "recall": 0.736734693877551
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8362368412694198,
            "auditor_fn_violation": 0.0023089443203754972,
            "auditor_fp_violation": 0.012214617759081767,
            "ave_precision_score": 0.8361552513909953,
            "fpr": 0.09001097694840834,
            "logloss": 0.6643007675690166,
            "mae": 0.4847781042824985,
            "precision": 0.8,
            "recall": 0.7068965517241379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 9540,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.7062184543444304,
            "auditor_fn_violation": 0.006019513068385264,
            "auditor_fp_violation": 0.0010393281782655696,
            "ave_precision_score": 0.6742923153907794,
            "fpr": 0.009868421052631578,
            "logloss": 0.6928718165804237,
            "mae": 0.4997716549326453,
            "precision": 0.7857142857142857,
            "recall": 0.0673469387755102
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6912444887127563,
            "auditor_fn_violation": 0.00206290926984368,
            "auditor_fp_violation": 0.004543032339023175,
            "ave_precision_score": 0.657645333295231,
            "fpr": 0.010976948408342482,
            "logloss": 0.6921462484203837,
            "mae": 0.49941999315561236,
            "precision": 0.7222222222222222,
            "recall": 0.05603448275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5807333670875616,
            "auditor_fn_violation": 0.019815162907268202,
            "auditor_fp_violation": 0.0314370790720878,
            "ave_precision_score": 0.5689892454070874,
            "fpr": 0.15021929824561403,
            "logloss": 0.6981995013337269,
            "mae": 0.49933533939091784,
            "precision": 0.5608974358974359,
            "recall": 0.35714285714285715
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5023297228053127,
            "auditor_fn_violation": 0.002096029372799889,
            "auditor_fp_violation": 0.042530149772725595,
            "ave_precision_score": 0.5298200466642687,
            "fpr": 0.15697036223929747,
            "logloss": 0.6953693796977733,
            "mae": 0.49809650872332073,
            "precision": 0.5431309904153354,
            "recall": 0.36637931034482757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5806954217800668,
            "auditor_fn_violation": 0.019815162907268202,
            "auditor_fp_violation": 0.0314370790720878,
            "ave_precision_score": 0.5689515519353799,
            "fpr": 0.15021929824561403,
            "logloss": 0.6983292839243798,
            "mae": 0.4993577804743198,
            "precision": 0.5608974358974359,
            "recall": 0.35714285714285715
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5022739915242606,
            "auditor_fn_violation": 0.002096029372799889,
            "auditor_fp_violation": 0.042530149772725595,
            "ave_precision_score": 0.5297674626024621,
            "fpr": 0.15697036223929747,
            "logloss": 0.6954736419712956,
            "mae": 0.49811021782433296,
            "precision": 0.5431309904153354,
            "recall": 0.36637931034482757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.571836679090944,
            "auditor_fn_violation": 0.0048245614035087704,
            "auditor_fp_violation": 0.031948948199883594,
            "ave_precision_score": 0.5696700174515129,
            "fpr": 0.15789473684210525,
            "logloss": 0.7412507461346691,
            "mae": 0.500546379403156,
            "precision": 0.556923076923077,
            "recall": 0.3693877551020408
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5176104066196904,
            "auditor_fn_violation": 0.009907642227184994,
            "auditor_fp_violation": 0.04977935596991285,
            "ave_precision_score": 0.5202251943274085,
            "fpr": 0.17672886937431395,
            "logloss": 0.7725915723201782,
            "mae": 0.4985236532358256,
            "precision": 0.5236686390532544,
            "recall": 0.38146551724137934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8302180542384083,
            "auditor_fn_violation": 0.012226996061582533,
            "auditor_fp_violation": 0.008278248939885262,
            "ave_precision_score": 0.8306347924840825,
            "fpr": 0.08991228070175439,
            "logloss": 0.6632349840322384,
            "mae": 0.48365824359158677,
            "precision": 0.8136363636363636,
            "recall": 0.7306122448979592
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8060865775896657,
            "auditor_fn_violation": 0.0019256974147394002,
            "auditor_fp_violation": 0.011168492474528328,
            "ave_precision_score": 0.8069545570253971,
            "fpr": 0.09769484083424808,
            "logloss": 0.6672926683918591,
            "mae": 0.48439494423102075,
            "precision": 0.7839805825242718,
            "recall": 0.6961206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 9540,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.7064336434668156,
            "auditor_fn_violation": 0.007478517722878634,
            "auditor_fp_violation": 0.0010393281782655696,
            "ave_precision_score": 0.6745093156824432,
            "fpr": 0.009868421052631578,
            "logloss": 0.6927501349930294,
            "mae": 0.49972157092078734,
            "precision": 0.8043478260869565,
            "recall": 0.07551020408163266
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6918129279744751,
            "auditor_fn_violation": 0.007272228320526896,
            "auditor_fp_violation": 0.0040887291051208575,
            "ave_precision_score": 0.6582079462295485,
            "fpr": 0.009879253567508232,
            "logloss": 0.6920841510537407,
            "mae": 0.49939968815619284,
            "precision": 0.7631578947368421,
            "recall": 0.0625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7802710693379902,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7797543287225592,
            "fpr": 0.46271929824561403,
            "logloss": 1.1864059776838856,
            "mae": 0.4603068965830301,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7357328628999533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7351126240092907,
            "fpr": 0.49066959385290887,
            "logloss": 1.3125362021463158,
            "mae": 0.4823910106550064,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7863779857714197,
            "auditor_fn_violation": 0.0006109022556390979,
            "auditor_fp_violation": 0.0020682630747484985,
            "ave_precision_score": 0.7873736801911868,
            "fpr": 0.4583333333333333,
            "logloss": 1.0692275949524623,
            "mae": 0.44905915356796694,
            "precision": 0.5391400220507166,
            "recall": 0.9979591836734694
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7495741167911383,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026177689045398566,
            "ave_precision_score": 0.7514489924106932,
            "fpr": 0.4818880351262349,
            "logloss": 1.133070581997362,
            "mae": 0.46465477658973436,
            "precision": 0.5138427464008859,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.549838100496808,
            "auditor_fn_violation": 0.03126566416040101,
            "auditor_fp_violation": 0.019185998170782412,
            "ave_precision_score": 0.5513412802564988,
            "fpr": 0.24671052631578946,
            "logloss": 1.842795841460582,
            "mae": 0.4725501066616314,
            "precision": 0.5778611632270169,
            "recall": 0.6285714285714286
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5238969628308064,
            "auditor_fn_violation": 0.00477166054733336,
            "auditor_fp_violation": 0.007624927250090265,
            "ave_precision_score": 0.5260004735792811,
            "fpr": 0.2502744237102086,
            "logloss": 1.587163094185507,
            "mae": 0.46275939435011654,
            "precision": 0.5640535372848948,
            "recall": 0.6357758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7683849657407996,
            "auditor_fn_violation": 0.0019110275689223058,
            "auditor_fp_violation": 0.005815041157395878,
            "ave_precision_score": 0.5433042448492965,
            "fpr": 0.4451754385964912,
            "logloss": 15.500022798774625,
            "mae": 0.4528508778798367,
            "precision": 0.5433070866141733,
            "recall": 0.9857142857142858
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7555302740646127,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.008631761444144051,
            "ave_precision_score": 0.5193588461341188,
            "fpr": 0.4632272228320527,
            "logloss": 16.14131039520883,
            "mae": 0.4720087830151359,
            "precision": 0.5193621867881549,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 9540,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.7069503122909678,
            "auditor_fn_violation": 0.0031641604010025203,
            "auditor_fp_violation": 0.0006339901887419978,
            "ave_precision_score": 0.6698923998249848,
            "fpr": 0.01206140350877193,
            "logloss": 0.6931679488013277,
            "mae": 0.49989931229828743,
            "precision": 0.717948717948718,
            "recall": 0.05714285714285714
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7126865696462551,
            "auditor_fn_violation": 0.0019824747340928955,
            "auditor_fp_violation": 0.0022027567611371825,
            "ave_precision_score": 0.6727671340756511,
            "fpr": 0.006586169045005488,
            "logloss": 0.6919582875340594,
            "mae": 0.4993042617741845,
            "precision": 0.7931034482758621,
            "recall": 0.04956896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5530737844730633,
            "auditor_fn_violation": 0.0312544754744003,
            "auditor_fp_violation": 0.019479608381142446,
            "ave_precision_score": 0.5545849056947754,
            "fpr": 0.24013157894736842,
            "logloss": 1.8445669386734813,
            "mae": 0.47071522229180934,
            "precision": 0.5804597701149425,
            "recall": 0.6183673469387755
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5288559594655557,
            "auditor_fn_violation": 0.005282656421514824,
            "auditor_fp_violation": 0.006033638084854029,
            "ave_precision_score": 0.5309700964700702,
            "fpr": 0.2502744237102086,
            "logloss": 1.5879273710067259,
            "mae": 0.4594593891597642,
            "precision": 0.5623800383877159,
            "recall": 0.6314655172413793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8520865139191156,
            "auditor_fn_violation": 0.0019110275689223058,
            "auditor_fp_violation": 0.005815041157395878,
            "ave_precision_score": 0.8519616312514782,
            "fpr": 0.4451754385964912,
            "logloss": 2.952531804447378,
            "mae": 0.4526873164169892,
            "precision": 0.5433070866141733,
            "recall": 0.9857142857142858
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.839378920063397,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.008631761444144051,
            "ave_precision_score": 0.839339241748476,
            "fpr": 0.4632272228320527,
            "logloss": 3.060410796144341,
            "mae": 0.47177003181646693,
            "precision": 0.5193621867881549,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5551733583576038,
            "auditor_fn_violation": 0.03581274615109202,
            "auditor_fp_violation": 0.02339527729275796,
            "ave_precision_score": 0.5574430454257278,
            "fpr": 0.19846491228070176,
            "logloss": 1.666133533305543,
            "mae": 0.4669414836275351,
            "precision": 0.5995575221238938,
            "recall": 0.5530612244897959
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5212004845371431,
            "auditor_fn_violation": 0.036995155002081836,
            "auditor_fp_violation": 0.030882797132732676,
            "ave_precision_score": 0.5234392175786607,
            "fpr": 0.19099890230515917,
            "logloss": 1.7201326493120632,
            "mae": 0.4760903498885823,
            "precision": 0.5660847880299252,
            "recall": 0.4892241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 9540,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.8436963315406893,
            "auditor_fn_violation": 0.001418725384890799,
            "auditor_fp_violation": 0.0036012721376902095,
            "ave_precision_score": 0.8450707057946347,
            "fpr": 0.44956140350877194,
            "logloss": 4.229710506144692,
            "mae": 0.45795065475006896,
            "precision": 0.5413870246085011,
            "recall": 0.9877551020408163
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.8227689251452563,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.00580771431448098,
            "ave_precision_score": 0.8241447412616206,
            "fpr": 0.47200878155872666,
            "logloss": 4.434338653059873,
            "mae": 0.4838382562154211,
            "precision": 0.5146726862302483,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5499140644561751,
            "auditor_fn_violation": 0.03571428571428572,
            "auditor_fp_violation": 0.022787270308472603,
            "ave_precision_score": 0.551416687011312,
            "fpr": 0.20065789473684212,
            "logloss": 1.8815268120015682,
            "mae": 0.47162503871229705,
            "precision": 0.5859728506787331,
            "recall": 0.5285714285714286
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5154110870541875,
            "auditor_fn_violation": 0.04128657405655021,
            "auditor_fp_violation": 0.02709611828582795,
            "ave_precision_score": 0.5177670530277958,
            "fpr": 0.19099890230515917,
            "logloss": 1.932982014687106,
            "mae": 0.4787237588189079,
            "precision": 0.5561224489795918,
            "recall": 0.4698275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5438436952066336,
            "auditor_fn_violation": 0.001908789831722162,
            "auditor_fp_violation": 0.019752432027937156,
            "ave_precision_score": 0.5453756377971464,
            "fpr": 0.23355263157894737,
            "logloss": 1.5906310896309501,
            "mae": 0.478270790531882,
            "precision": 0.5705645161290323,
            "recall": 0.5775510204081633
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.512822412336594,
            "auditor_fn_violation": 0.016966955600136276,
            "auditor_fp_violation": 0.006691763850723324,
            "ave_precision_score": 0.5142088761534571,
            "fpr": 0.24259055982436883,
            "logloss": 1.6230529001487564,
            "mae": 0.4780553740975977,
            "precision": 0.5498981670061099,
            "recall": 0.5818965517241379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7866515580675134,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7876419544590291,
            "fpr": 0.46271929824561403,
            "logloss": 0.7106082914880756,
            "mae": 0.4607002388751298,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7485717070732671,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7505042090097197,
            "fpr": 0.49066959385290887,
            "logloss": 0.7373878801228697,
            "mae": 0.47192239440756756,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7892717577442021,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.790144475774285,
            "fpr": 0.46271929824561403,
            "logloss": 1.0261294903775904,
            "mae": 0.46299635115684123,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7493748257184716,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7513786219796822,
            "fpr": 0.49066959385290887,
            "logloss": 1.1240840518242226,
            "mae": 0.4821437486701949,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8501459217363656,
            "auditor_fn_violation": 0.0019110275689223058,
            "auditor_fp_violation": 0.005815041157395878,
            "ave_precision_score": 0.8500605020693686,
            "fpr": 0.4451754385964912,
            "logloss": 2.170729860991649,
            "mae": 0.45193175443572486,
            "precision": 0.5433070866141733,
            "recall": 0.9857142857142858
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8373670572731745,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.008631761444144051,
            "ave_precision_score": 0.837285924888238,
            "fpr": 0.4632272228320527,
            "logloss": 2.260033958221488,
            "mae": 0.47056090643377574,
            "precision": 0.5193621867881549,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7538769085812496,
            "auditor_fn_violation": 0.003954081632653062,
            "auditor_fp_violation": 0.0205838945705496,
            "ave_precision_score": 0.7428489587960162,
            "fpr": 0.26644736842105265,
            "logloss": 1.9083190949894306,
            "mae": 0.3320694777928975,
            "precision": 0.6426470588235295,
            "recall": 0.8918367346938776
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7572518166580181,
            "auditor_fn_violation": 0.008559180892539462,
            "auditor_fp_violation": 0.025794600913026725,
            "ave_precision_score": 0.7455671546845674,
            "fpr": 0.26125137211855104,
            "logloss": 1.7019860361527501,
            "mae": 0.30941787218006156,
            "precision": 0.6388467374810318,
            "recall": 0.9073275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 9540,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5583286165204402,
            "auditor_fn_violation": 0.03483485499462943,
            "auditor_fp_violation": 0.018915772844433354,
            "ave_precision_score": 0.5598411306380847,
            "fpr": 0.27850877192982454,
            "logloss": 1.8190378530456153,
            "mae": 0.46337902391420216,
            "precision": 0.5716694772344013,
            "recall": 0.6918367346938775
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5318229392609257,
            "auditor_fn_violation": 0.013583973655323833,
            "auditor_fp_violation": 0.016590662963481387,
            "ave_precision_score": 0.533930937757793,
            "fpr": 0.28210757409440174,
            "logloss": 1.566405757984127,
            "mae": 0.4530623598065828,
            "precision": 0.5553633217993079,
            "recall": 0.6918103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.550479194720277,
            "auditor_fn_violation": 0.031055316863587548,
            "auditor_fp_violation": 0.02204415066101272,
            "ave_precision_score": 0.5519815308950682,
            "fpr": 0.23574561403508773,
            "logloss": 1.8384515502049894,
            "mae": 0.47314431816006725,
            "precision": 0.5841392649903289,
            "recall": 0.6163265306122448
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5242780655671642,
            "auditor_fn_violation": 0.002405938907604378,
            "auditor_fp_violation": 0.007337611150811493,
            "ave_precision_score": 0.5263725836333366,
            "fpr": 0.24368825466520308,
            "logloss": 1.5828094109766404,
            "mae": 0.4633981342921322,
            "precision": 0.5638506876227898,
            "recall": 0.6185344827586207
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6117958342964226,
            "auditor_fn_violation": 0.010215270318653786,
            "auditor_fp_violation": 0.01792841107508107,
            "ave_precision_score": 0.6132756481556294,
            "fpr": 0.22149122807017543,
            "logloss": 1.3745333491811125,
            "mae": 0.4208112962374446,
            "precision": 0.6152380952380953,
            "recall": 0.6591836734693878
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.5858831307190558,
            "auditor_fn_violation": 0.0010787690677164182,
            "auditor_fp_violation": 0.0031678441715350773,
            "ave_precision_score": 0.5874813149452066,
            "fpr": 0.22722283205268934,
            "logloss": 1.366888268301299,
            "mae": 0.415494913591633,
            "precision": 0.6011560693641619,
            "recall": 0.6724137931034483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7864161749485787,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7870508843066054,
            "fpr": 0.46271929824561403,
            "logloss": 1.3524759925973122,
            "mae": 0.4555768588263738,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7488499899956444,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7516325672121654,
            "fpr": 0.49066959385290887,
            "logloss": 1.4709269001767793,
            "mae": 0.4788990080945447,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 9540,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5760880106623038,
            "auditor_fn_violation": 0.0035356247762263,
            "auditor_fp_violation": 0.026832855242371334,
            "ave_precision_score": 0.5649575386960398,
            "fpr": 0.16776315789473684,
            "logloss": 0.7086586572080418,
            "mae": 0.49865347568072793,
            "precision": 0.5459940652818991,
            "recall": 0.37551020408163266
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.49622659713448125,
            "auditor_fn_violation": 0.011142548923123519,
            "auditor_fp_violation": 0.023626223856076746,
            "ave_precision_score": 0.5228924497858154,
            "fpr": 0.18331503841931943,
            "logloss": 0.7043328294777764,
            "mae": 0.49682015723299133,
            "precision": 0.5159420289855072,
            "recall": 0.38362068965517243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5772496544969462,
            "auditor_fn_violation": 0.020405925528105995,
            "auditor_fp_violation": 0.03460962833624346,
            "ave_precision_score": 0.5660067057881253,
            "fpr": 0.14912280701754385,
            "logloss": 0.7088067833047622,
            "mae": 0.498607118019723,
            "precision": 0.5598705501618123,
            "recall": 0.35306122448979593
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.4970510155075901,
            "auditor_fn_violation": 0.008951890684734502,
            "auditor_fp_violation": 0.043365085445843374,
            "ave_precision_score": 0.5235695378024932,
            "fpr": 0.1602634467618002,
            "logloss": 0.704514024089806,
            "mae": 0.49678859700599903,
            "precision": 0.535031847133758,
            "recall": 0.3620689655172414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5555686812094787,
            "auditor_fn_violation": 0.03513247404224848,
            "auditor_fp_violation": 0.018778061860813183,
            "ave_precision_score": 0.5570710363063038,
            "fpr": 0.24451754385964913,
            "logloss": 1.8294092833431195,
            "mae": 0.4671099104264446,
            "precision": 0.5784499054820416,
            "recall": 0.6244897959183674
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5300471536009093,
            "auditor_fn_violation": 0.01282694273061055,
            "auditor_fp_violation": 0.0073326997644990385,
            "ave_precision_score": 0.5321611100141035,
            "fpr": 0.24807903402854006,
            "logloss": 1.5733491006600318,
            "mae": 0.45673062471249765,
            "precision": 0.571157495256167,
            "recall": 0.6487068965517241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7533162943291242,
            "auditor_fn_violation": 0.015776047261009667,
            "auditor_fp_violation": 0.016359025525900062,
            "ave_precision_score": 0.7544832475385124,
            "fpr": 0.1425438596491228,
            "logloss": 1.3473814056385307,
            "mae": 0.3110953791232955,
            "precision": 0.7274633123689728,
            "recall": 0.7081632653061225
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7876328466338793,
            "auditor_fn_violation": 0.016337673643968355,
            "auditor_fp_violation": 0.020318405174636626,
            "ave_precision_score": 0.7866319116186323,
            "fpr": 0.141602634467618,
            "logloss": 1.1474946087784021,
            "mae": 0.28027819931507986,
            "precision": 0.7306889352818372,
            "recall": 0.7543103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.850566597409287,
            "auditor_fn_violation": 0.0019110275689223058,
            "auditor_fp_violation": 0.005815041157395878,
            "ave_precision_score": 0.8504925883167588,
            "fpr": 0.4451754385964912,
            "logloss": 1.5767425256763747,
            "mae": 0.4498620398608067,
            "precision": 0.5433070866141733,
            "recall": 0.9857142857142858
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8376901890383499,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.008631761444144051,
            "ave_precision_score": 0.83761067097439,
            "fpr": 0.4632272228320527,
            "logloss": 1.6404076775069187,
            "mae": 0.4670336917083068,
            "precision": 0.5193621867881549,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5499033573746008,
            "auditor_fn_violation": 0.034586466165413554,
            "auditor_fp_violation": 0.02003564895651452,
            "ave_precision_score": 0.5514068295096203,
            "fpr": 0.2225877192982456,
            "logloss": 1.846530403313942,
            "mae": 0.47551133176515986,
            "precision": 0.5857142857142857,
            "recall": 0.5857142857142857
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5238501601832293,
            "auditor_fn_violation": 0.002900374730307737,
            "auditor_fp_violation": 0.007860673793088205,
            "ave_precision_score": 0.5259440483776003,
            "fpr": 0.2305159165751921,
            "logloss": 1.5873344779293772,
            "mae": 0.465227835218377,
            "precision": 0.569672131147541,
            "recall": 0.5991379310344828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8514944323421656,
            "auditor_fn_violation": 0.0019110275689223058,
            "auditor_fp_violation": 0.005815041157395878,
            "ave_precision_score": 0.8513822419315782,
            "fpr": 0.4451754385964912,
            "logloss": 1.9691633530654478,
            "mae": 0.4515410876713424,
            "precision": 0.5433070866141733,
            "recall": 0.9857142857142858
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8390244037485288,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.008631761444144051,
            "ave_precision_score": 0.8389871947069723,
            "fpr": 0.4632272228320527,
            "logloss": 2.0316012830886243,
            "mae": 0.4702081555801185,
            "precision": 0.5193621867881549,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.78485166736104,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.781662295061722,
            "fpr": 0.46271929824561403,
            "logloss": 1.298204244543854,
            "mae": 0.4595061839280421,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.751874513592266,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7468497488439321,
            "fpr": 0.49066959385290887,
            "logloss": 1.4341441554659737,
            "mae": 0.4823520907847994,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7498457993160188,
            "auditor_fn_violation": 0.01138560687432868,
            "auditor_fp_violation": 0.011513157894736845,
            "ave_precision_score": 0.7510557389860846,
            "fpr": 0.14802631578947367,
            "logloss": 1.311998848334936,
            "mae": 0.31529441306532285,
            "precision": 0.7210743801652892,
            "recall": 0.7122448979591837
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.77867103962698,
            "auditor_fn_violation": 0.013915174684885881,
            "auditor_fp_violation": 0.0153186139085549,
            "ave_precision_score": 0.7782701661524496,
            "fpr": 0.1437980241492865,
            "logloss": 1.1310580545160742,
            "mae": 0.2837189791082328,
            "precision": 0.7298969072164948,
            "recall": 0.7629310344827587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5806233435335387,
            "auditor_fn_violation": 0.07681704260651628,
            "auditor_fp_violation": 0.056040575372079494,
            "ave_precision_score": 0.5702845227062907,
            "fpr": 0.23464912280701755,
            "logloss": 0.7523190334636357,
            "mae": 0.49825494977148754,
            "precision": 0.5900383141762452,
            "recall": 0.6285714285714286
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5146587053101048,
            "auditor_fn_violation": 0.05017695597865173,
            "auditor_fp_violation": 0.06562594390705692,
            "ave_precision_score": 0.528193965821077,
            "fpr": 0.2667398463227223,
            "logloss": 0.7871596176000922,
            "mae": 0.4959616576961692,
            "precision": 0.5573770491803278,
            "recall": 0.6594827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7383832060349385,
            "auditor_fn_violation": 0.014196204797708554,
            "auditor_fp_violation": 0.01826619273301739,
            "ave_precision_score": 0.7311098866863099,
            "fpr": 0.17982456140350878,
            "logloss": 1.8394274581610301,
            "mae": 0.32983458782845937,
            "precision": 0.6864244741873805,
            "recall": 0.7326530612244898
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7645163605210773,
            "auditor_fn_violation": 0.013508270562852497,
            "auditor_fp_violation": 0.02342976840357844,
            "ave_precision_score": 0.7600881490143334,
            "fpr": 0.16575192096597147,
            "logloss": 1.375855920155495,
            "mae": 0.29057365254914896,
            "precision": 0.7079303675048356,
            "recall": 0.7887931034482759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7359460282214566,
            "auditor_fn_violation": 0.015075635517364842,
            "auditor_fp_violation": 0.016891681217261173,
            "ave_precision_score": 0.7285934027460487,
            "fpr": 0.17214912280701755,
            "logloss": 1.844664228469696,
            "mae": 0.32972607637604356,
            "precision": 0.6957364341085271,
            "recall": 0.7326530612244898
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7607660641342502,
            "auditor_fn_violation": 0.013508270562852497,
            "auditor_fp_violation": 0.022115972564996058,
            "ave_precision_score": 0.755702238477612,
            "fpr": 0.16794731064763996,
            "logloss": 1.4003725336035449,
            "mae": 0.29108694118108874,
            "precision": 0.7052023121387283,
            "recall": 0.7887931034482759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5729207029182751,
            "auditor_fn_violation": 0.020405925528105995,
            "auditor_fp_violation": 0.03460962833624346,
            "ave_precision_score": 0.5618737235040501,
            "fpr": 0.14912280701754385,
            "logloss": 0.7092977677547807,
            "mae": 0.4986971464388238,
            "precision": 0.5598705501618123,
            "recall": 0.35306122448979593
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.49288766869258305,
            "auditor_fn_violation": 0.008951890684734502,
            "auditor_fp_violation": 0.043365085445843374,
            "ave_precision_score": 0.5198906644363609,
            "fpr": 0.1602634467618002,
            "logloss": 0.7049797789126323,
            "mae": 0.4968588968235139,
            "precision": 0.535031847133758,
            "recall": 0.3620689655172414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7533103746322329,
            "auditor_fn_violation": 0.015776047261009667,
            "auditor_fp_violation": 0.016359025525900062,
            "ave_precision_score": 0.7544773329793912,
            "fpr": 0.1425438596491228,
            "logloss": 1.347485963525247,
            "mae": 0.31109817257034184,
            "precision": 0.7274633123689728,
            "recall": 0.7081632653061225
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7876224558923204,
            "auditor_fn_violation": 0.016337673643968355,
            "auditor_fp_violation": 0.020318405174636626,
            "ave_precision_score": 0.7866215221114727,
            "fpr": 0.141602634467618,
            "logloss": 1.1475868713037796,
            "mae": 0.2802841184667344,
            "precision": 0.7306889352818372,
            "recall": 0.7543103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5530936769173825,
            "auditor_fn_violation": 0.0312544754744003,
            "auditor_fp_violation": 0.019479608381142446,
            "ave_precision_score": 0.5546047928447915,
            "fpr": 0.24013157894736842,
            "logloss": 1.8444081708638085,
            "mae": 0.47065113111557727,
            "precision": 0.5804597701149425,
            "recall": 0.6183673469387755
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5289211057400578,
            "auditor_fn_violation": 0.005282656421514824,
            "auditor_fp_violation": 0.006033638084854029,
            "ave_precision_score": 0.531035270550108,
            "fpr": 0.2502744237102086,
            "logloss": 1.587809409373242,
            "mae": 0.4593898620598924,
            "precision": 0.5623800383877159,
            "recall": 0.6314655172413793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7876646603074935,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7886637840103333,
            "fpr": 0.46271929824561403,
            "logloss": 1.0041964202322873,
            "mae": 0.4490272313879247,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7518093578884972,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7537096933094735,
            "fpr": 0.49066959385290887,
            "logloss": 1.0716105858032285,
            "mae": 0.4666346411673612,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7525739458622795,
            "auditor_fn_violation": 0.0041666666666666675,
            "auditor_fp_violation": 0.021282842770433196,
            "ave_precision_score": 0.7454531838200624,
            "fpr": 0.2817982456140351,
            "logloss": 1.6640167222559132,
            "mae": 0.33995456831579607,
            "precision": 0.6318051575931232,
            "recall": 0.9
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.754552613977018,
            "auditor_fn_violation": 0.00881941027290965,
            "auditor_fp_violation": 0.024340830564539312,
            "ave_precision_score": 0.7462247112706734,
            "fpr": 0.27332601536772777,
            "logloss": 1.5103078578941251,
            "mae": 0.31997923517943444,
            "precision": 0.6300148588410104,
            "recall": 0.9137931034482759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7872429382851117,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7881715917580375,
            "fpr": 0.46271929824561403,
            "logloss": 1.63242062847811,
            "mae": 0.45949601094450865,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7453100276524178,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7461062178258245,
            "fpr": 0.49066959385290887,
            "logloss": 1.7649494121509328,
            "mae": 0.4847098161700528,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 9540,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.8537197771569164,
            "auditor_fn_violation": 0.001418725384890799,
            "auditor_fp_violation": 0.0036012721376902095,
            "ave_precision_score": 0.8535590841242582,
            "fpr": 0.44956140350877194,
            "logloss": 3.888751521376813,
            "mae": 0.45791641753493695,
            "precision": 0.5413870246085011,
            "recall": 0.9877551020408163
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.8383269838281853,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.00580771431448098,
            "ave_precision_score": 0.8382740505873906,
            "fpr": 0.47200878155872666,
            "logloss": 4.0805297334299,
            "mae": 0.48380000897479764,
            "precision": 0.5146726862302483,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7611356327740659,
            "auditor_fn_violation": 0.004567221625492304,
            "auditor_fp_violation": 0.020105803608547444,
            "ave_precision_score": 0.7551944940986854,
            "fpr": 0.2905701754385965,
            "logloss": 1.5696648999235863,
            "mae": 0.340752153851744,
            "precision": 0.6278089887640449,
            "recall": 0.9122448979591836
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7657061129929934,
            "auditor_fn_violation": 0.0036952572012566736,
            "auditor_fp_violation": 0.029939810960740828,
            "ave_precision_score": 0.7594529212593045,
            "fpr": 0.2843029637760702,
            "logloss": 1.3897530380751235,
            "mae": 0.3197022666059739,
            "precision": 0.6257225433526011,
            "recall": 0.9331896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7311394737868151,
            "auditor_fn_violation": 0.014164876476906554,
            "auditor_fp_violation": 0.015298910784069178,
            "ave_precision_score": 0.7236305677287125,
            "fpr": 0.19517543859649122,
            "logloss": 1.9061401918828924,
            "mae": 0.33658869860072094,
            "precision": 0.673992673992674,
            "recall": 0.7510204081632653
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.752395100377228,
            "auditor_fn_violation": 0.011031360006056255,
            "auditor_fp_violation": 0.02141118862915841,
            "ave_precision_score": 0.747221514708339,
            "fpr": 0.1964873765093304,
            "logloss": 1.4856856204729836,
            "mae": 0.30096423880724954,
            "precision": 0.6768953068592057,
            "recall": 0.8081896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.750327853662843,
            "auditor_fn_violation": 0.01427005012531328,
            "auditor_fp_violation": 0.011097426623430613,
            "ave_precision_score": 0.7511186883920622,
            "fpr": 0.14364035087719298,
            "logloss": 1.3133761085024154,
            "mae": 0.3149529402034192,
            "precision": 0.7259414225941423,
            "recall": 0.7081632653061225
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7805018900413447,
            "auditor_fn_violation": 0.017951095802263527,
            "auditor_fp_violation": 0.013803451231161772,
            "ave_precision_score": 0.7801513117019354,
            "fpr": 0.1394072447859495,
            "logloss": 1.129495038758474,
            "mae": 0.28381520435911683,
            "precision": 0.7331932773109243,
            "recall": 0.7521551724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7850704352664389,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7857528037581744,
            "fpr": 0.46271929824561403,
            "logloss": 1.339609436359907,
            "mae": 0.45500019244980394,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7488617437682065,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7497647786660034,
            "fpr": 0.49066959385290887,
            "logloss": 1.4571867498999067,
            "mae": 0.478310943631257,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8520939377594925,
            "auditor_fn_violation": 0.0019110275689223058,
            "auditor_fp_violation": 0.005815041157395878,
            "ave_precision_score": 0.8519690544260488,
            "fpr": 0.4451754385964912,
            "logloss": 2.199627851297416,
            "mae": 0.45194842686115616,
            "precision": 0.5433070866141733,
            "recall": 0.9857142857142858
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8393340720269711,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.008631761444144051,
            "ave_precision_score": 0.8392944051293099,
            "fpr": 0.4632272228320527,
            "logloss": 2.2773547469937587,
            "mae": 0.4706779015787535,
            "precision": 0.5193621867881549,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7866526504911768,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7875724262567187,
            "fpr": 0.46271929824561403,
            "logloss": 0.8762645843774801,
            "mae": 0.4555525490197173,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7500306805018928,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7518591366197693,
            "fpr": 0.49066959385290887,
            "logloss": 0.9391321704273301,
            "mae": 0.4697777250726451,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7358700270402687,
            "auditor_fn_violation": 0.006968313641245973,
            "auditor_fp_violation": 0.010362101937307737,
            "ave_precision_score": 0.7323652541863741,
            "fpr": 0.3399122807017544,
            "logloss": 1.471647769877655,
            "mae": 0.3756190546952218,
            "precision": 0.5958279009126467,
            "recall": 0.9326530612244898
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7338117747622831,
            "auditor_fn_violation": 0.0044333623528521144,
            "auditor_fp_violation": 0.022128251030777216,
            "ave_precision_score": 0.731748287727621,
            "fpr": 0.33040614709110866,
            "logloss": 1.3261284590765667,
            "mae": 0.3459660248082411,
            "precision": 0.5970548862115127,
            "recall": 0.9612068965517241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.565040325236017,
            "auditor_fn_violation": 0.012218045112781954,
            "auditor_fp_violation": 0.011133803109669911,
            "ave_precision_score": 0.5626239013887031,
            "fpr": 0.3826754385964912,
            "logloss": 2.119255004449848,
            "mae": 0.45340712515277515,
            "precision": 0.5502577319587629,
            "recall": 0.8714285714285714
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5487241027676398,
            "auditor_fn_violation": 0.008947159241455015,
            "auditor_fp_violation": 0.007524243830684872,
            "ave_precision_score": 0.5456304716199103,
            "fpr": 0.3940724478594951,
            "logloss": 2.168712270482119,
            "mae": 0.43346706584176203,
            "precision": 0.5403329065300896,
            "recall": 0.9094827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7496024459352661,
            "auditor_fn_violation": 0.01138560687432868,
            "auditor_fp_violation": 0.011513157894736845,
            "ave_precision_score": 0.7507800359578649,
            "fpr": 0.14802631578947367,
            "logloss": 1.314360328254103,
            "mae": 0.3153660242487312,
            "precision": 0.7210743801652892,
            "recall": 0.7122448979591837
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7785367716899887,
            "auditor_fn_violation": 0.015112229834588747,
            "auditor_fp_violation": 0.0153186139085549,
            "ave_precision_score": 0.7781707076357984,
            "fpr": 0.1437980241492865,
            "logloss": 1.132546362411875,
            "mae": 0.28374890877472686,
            "precision": 0.7293388429752066,
            "recall": 0.7607758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7866526504911768,
            "auditor_fn_violation": 0.0006109022556390979,
            "auditor_fp_violation": 0.0020682630747484985,
            "ave_precision_score": 0.7875724262567187,
            "fpr": 0.4583333333333333,
            "logloss": 1.0253947602111502,
            "mae": 0.45041828760784747,
            "precision": 0.5391400220507166,
            "recall": 0.9979591836734694
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7500306805018928,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026177689045398566,
            "ave_precision_score": 0.7518591366197693,
            "fpr": 0.4818880351262349,
            "logloss": 1.088807433385889,
            "mae": 0.46470941551084977,
            "precision": 0.5138427464008859,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5625817170659181,
            "auditor_fn_violation": 0.011457214464733268,
            "auditor_fp_violation": 0.02470223247692693,
            "ave_precision_score": 0.5641090064407442,
            "fpr": 0.23355263157894737,
            "logloss": 1.3682581710443136,
            "mae": 0.46247806218841003,
            "precision": 0.5888030888030888,
            "recall": 0.6224489795918368
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5304196459261689,
            "auditor_fn_violation": 0.006654774972557635,
            "auditor_fp_violation": 0.011242163269215184,
            "ave_precision_score": 0.5314878931615145,
            "fpr": 0.24588364434687157,
            "logloss": 1.3705382796385568,
            "mae": 0.46078350105454635,
            "precision": 0.5700575815738963,
            "recall": 0.6400862068965517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7866526504911768,
            "auditor_fn_violation": 0.0006109022556390979,
            "auditor_fp_violation": 0.0020682630747484985,
            "ave_precision_score": 0.7875724262567187,
            "fpr": 0.4583333333333333,
            "logloss": 1.1324113933020057,
            "mae": 0.4522099103137806,
            "precision": 0.5391400220507166,
            "recall": 0.9979591836734694
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7500306805018928,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026177689045398566,
            "ave_precision_score": 0.7518591366197693,
            "fpr": 0.4818880351262349,
            "logloss": 1.209290444157002,
            "mae": 0.4685380145987653,
            "precision": 0.5138427464008859,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 9540,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5802965892541442,
            "auditor_fn_violation": 0.015695488721804516,
            "auditor_fp_violation": 0.017278830963665094,
            "ave_precision_score": 0.5684576509068494,
            "fpr": 0.08771929824561403,
            "logloss": 0.6929538907274263,
            "mae": 0.4998571393325141,
            "precision": 0.5833333333333334,
            "recall": 0.22857142857142856
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5074076676628061,
            "auditor_fn_violation": 0.0029476891631023258,
            "auditor_fp_violation": 0.003445337498188927,
            "ave_precision_score": 0.5053050188241757,
            "fpr": 0.12623490669593854,
            "logloss": 0.6933131235924455,
            "mae": 0.5000374003443315,
            "precision": 0.44976076555023925,
            "recall": 0.2025862068965517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5094475451629692,
            "auditor_fn_violation": 0.008404940923737917,
            "auditor_fp_violation": 0.016270682630747494,
            "ave_precision_score": 0.5025365190143443,
            "fpr": 0.38596491228070173,
            "logloss": 4.190520722379264,
            "mae": 0.4906536252428385,
            "precision": 0.5243243243243243,
            "recall": 0.7918367346938775
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.4812671102203357,
            "auditor_fn_violation": 0.002318407206934407,
            "auditor_fp_violation": 0.003936476129434691,
            "ave_precision_score": 0.47728060882189893,
            "fpr": 0.3940724478594951,
            "logloss": 4.112708417148053,
            "mae": 0.48315742556881874,
            "precision": 0.5155195681511471,
            "recall": 0.8232758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7865495789595338,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7873662831934329,
            "fpr": 0.46271929824561403,
            "logloss": 1.3522354721419252,
            "mae": 0.45555294925967854,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7509309714543198,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7513931036106328,
            "fpr": 0.49066959385290887,
            "logloss": 1.4705447915545269,
            "mae": 0.4788687152606072,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7845526659767058,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.782480513117852,
            "fpr": 0.46271929824561403,
            "logloss": 4.664722532092066,
            "mae": 0.46270693681742014,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7530923719436002,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7492521384098881,
            "fpr": 0.49066959385290887,
            "logloss": 5.044591676561293,
            "mae": 0.4906518440346032,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7707581635610993,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7718925718237435,
            "fpr": 0.46271929824561403,
            "logloss": 1.178045378961793,
            "mae": 0.45333403884841683,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.747885350079776,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.749772323809953,
            "fpr": 0.49066959385290887,
            "logloss": 1.2679512106572717,
            "mae": 0.4735505236752339,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7875787099666176,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7885027066400556,
            "fpr": 0.46271929824561403,
            "logloss": 1.110245970899435,
            "mae": 0.4534473421803692,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7514616142447017,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7533156460034259,
            "fpr": 0.49066959385290887,
            "logloss": 1.203065512316484,
            "mae": 0.47381631799377544,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7437938985262156,
            "auditor_fn_violation": 0.012947547440028653,
            "auditor_fp_violation": 0.02403966076328261,
            "ave_precision_score": 0.7384943164927555,
            "fpr": 0.16228070175438597,
            "logloss": 1.5995464020664496,
            "mae": 0.32349215956727273,
            "precision": 0.7098039215686275,
            "recall": 0.7387755102040816
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7709323478344767,
            "auditor_fn_violation": 0.01239164994890041,
            "auditor_fp_violation": 0.019095469982834706,
            "ave_precision_score": 0.7692018940685672,
            "fpr": 0.16245883644346873,
            "logloss": 1.1626611429846385,
            "mae": 0.28698914398980424,
            "precision": 0.7098039215686275,
            "recall": 0.7801724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7866526504911768,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7875724262567187,
            "fpr": 0.46271929824561403,
            "logloss": 0.9894975488383791,
            "mae": 0.45424563803693707,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7500306805018928,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7518591366197693,
            "fpr": 0.49066959385290887,
            "logloss": 1.0690887402543725,
            "mae": 0.47184980622238176,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.78639187951612,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7870508843066054,
            "fpr": 0.46271929824561403,
            "logloss": 1.3528028276633413,
            "mae": 0.45556118208588214,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7487261958659235,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.751447838148126,
            "fpr": 0.49066959385290887,
            "logloss": 1.4717325663036531,
            "mae": 0.4788877618561461,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5535198412972466,
            "auditor_fn_violation": 0.03325277479412818,
            "auditor_fp_violation": 0.018598777750062374,
            "ave_precision_score": 0.5550386959125481,
            "fpr": 0.24561403508771928,
            "logloss": 1.8484504814140092,
            "mae": 0.46992953158389594,
            "precision": 0.5765595463137996,
            "recall": 0.6224489795918368
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5285002053339393,
            "auditor_fn_violation": 0.00019162345281805218,
            "auditor_fp_violation": 0.016367194886264567,
            "ave_precision_score": 0.5306054970481665,
            "fpr": 0.2557628979143798,
            "logloss": 1.595120054279816,
            "mae": 0.4586255238383586,
            "precision": 0.560377358490566,
            "recall": 0.6400862068965517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7533162943291242,
            "auditor_fn_violation": 0.015776047261009667,
            "auditor_fp_violation": 0.016359025525900062,
            "ave_precision_score": 0.7544832475385124,
            "fpr": 0.1425438596491228,
            "logloss": 1.3473812208085056,
            "mae": 0.31109536368457813,
            "precision": 0.7274633123689728,
            "recall": 0.7081632653061225
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7876328466338793,
            "auditor_fn_violation": 0.016337673643968355,
            "auditor_fp_violation": 0.020318405174636626,
            "ave_precision_score": 0.7866319116186323,
            "fpr": 0.141602634467618,
            "logloss": 1.1474943211354796,
            "mae": 0.28027818131845067,
            "precision": 0.7306889352818372,
            "recall": 0.7543103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7125643368101148,
            "auditor_fn_violation": 0.034353741496598644,
            "auditor_fp_violation": 0.010107466533632661,
            "ave_precision_score": 0.7131451751275708,
            "fpr": 0.21271929824561403,
            "logloss": 1.026281842649883,
            "mae": 0.394461126771299,
            "precision": 0.6541889483065954,
            "recall": 0.7489795918367347
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.721137458021522,
            "auditor_fn_violation": 0.022668344751883115,
            "auditor_fp_violation": 0.019702026192423207,
            "ave_precision_score": 0.7217957566756317,
            "fpr": 0.20636663007683864,
            "logloss": 0.901951825428463,
            "mae": 0.36621046827600406,
            "precision": 0.6624775583482945,
            "recall": 0.7952586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7611356327740659,
            "auditor_fn_violation": 0.004567221625492304,
            "auditor_fp_violation": 0.020105803608547444,
            "ave_precision_score": 0.7551944940986854,
            "fpr": 0.2905701754385965,
            "logloss": 1.5696653135662688,
            "mae": 0.3407521655313728,
            "precision": 0.6278089887640449,
            "recall": 0.9122448979591836
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7657061129929934,
            "auditor_fn_violation": 0.0036952572012566736,
            "auditor_fp_violation": 0.029939810960740828,
            "ave_precision_score": 0.7594529212593045,
            "fpr": 0.2843029637760702,
            "logloss": 1.3897533428960718,
            "mae": 0.319702281883978,
            "precision": 0.6257225433526011,
            "recall": 0.9331896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.8506926866587426,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.850631369027234,
            "fpr": 0.46271929824561403,
            "logloss": 3.804510585412043,
            "mae": 0.4626921948633696,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.8373167186787849,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8371056719789973,
            "fpr": 0.49066959385290887,
            "logloss": 4.019742541110996,
            "mae": 0.4906204768122224,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 9540,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5814877912760184,
            "auditor_fn_violation": 0.005068474758324396,
            "auditor_fp_violation": 0.027838405254843275,
            "ave_precision_score": 0.5706973372523989,
            "fpr": 0.16666666666666666,
            "logloss": 0.752816252545483,
            "mae": 0.4977367939506198,
            "precision": 0.5489614243323442,
            "recall": 0.37755102040816324
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5154741469320383,
            "auditor_fn_violation": 0.01438358756955222,
            "auditor_fp_violation": 0.0240240461473858,
            "ave_precision_score": 0.5290503427059658,
            "fpr": 0.18441273326015367,
            "logloss": 0.7875314400032996,
            "mae": 0.4953047371844419,
            "precision": 0.5172413793103449,
            "recall": 0.3879310344827586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.8506434241042986,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8505141005374184,
            "fpr": 0.46271929824561403,
            "logloss": 3.8478492712857246,
            "mae": 0.46269030574905246,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.8379883079771661,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8376821419636136,
            "fpr": 0.49066959385290887,
            "logloss": 4.062220394481124,
            "mae": 0.49062026842496265,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7329650626770987,
            "auditor_fn_violation": 0.013979144289294669,
            "auditor_fp_violation": 0.017413943626839613,
            "ave_precision_score": 0.7254619414859929,
            "fpr": 0.20614035087719298,
            "logloss": 1.8755255520887826,
            "mae": 0.33713603471431236,
            "precision": 0.6624775583482945,
            "recall": 0.753061224489796
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7555231438199824,
            "auditor_fn_violation": 0.010527461296793975,
            "auditor_fp_violation": 0.02141118862915841,
            "ave_precision_score": 0.7504089790248609,
            "fpr": 0.1964873765093304,
            "logloss": 1.4566693891028293,
            "mae": 0.3010106974518879,
            "precision": 0.6792114695340502,
            "recall": 0.8168103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5816792444173731,
            "auditor_fn_violation": 0.015355352667382768,
            "auditor_fp_violation": 0.01793880435686373,
            "ave_precision_score": 0.5691615340509115,
            "fpr": 0.08991228070175439,
            "logloss": 0.6929170650968817,
            "mae": 0.4998406413289016,
            "precision": 0.5858585858585859,
            "recall": 0.23673469387755103
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5068259300376923,
            "auditor_fn_violation": 0.01317706953329043,
            "auditor_fp_violation": 0.0027749332665384825,
            "ave_precision_score": 0.5049965718239843,
            "fpr": 0.12733260153677278,
            "logloss": 0.6933575782320631,
            "mae": 0.5000625775491105,
            "precision": 0.45023696682464454,
            "recall": 0.20474137931034483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7876646603074935,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7886637840103333,
            "fpr": 0.46271929824561403,
            "logloss": 1.002323195328082,
            "mae": 0.44899773656537656,
            "precision": 0.5372807017543859,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7518043585766199,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7537046874549389,
            "fpr": 0.49066959385290887,
            "logloss": 1.0690689102752704,
            "mae": 0.4665525647209452,
            "precision": 0.5093304061470911,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 9540,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.7004611916594193,
            "auditor_fn_violation": 0.004802184031507365,
            "auditor_fp_violation": 0.0018759873617693527,
            "ave_precision_score": 0.6732954088874035,
            "fpr": 0.013157894736842105,
            "logloss": 0.6926674792127374,
            "mae": 0.49968485978611726,
            "precision": 0.76,
            "recall": 0.07755102040816327
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6951234713953222,
            "auditor_fn_violation": 0.004871020856201981,
            "auditor_fp_violation": 0.000503417097026893,
            "ave_precision_score": 0.666433524236237,
            "fpr": 0.010976948408342482,
            "logloss": 0.6920317165754069,
            "mae": 0.4993793760905805,
            "precision": 0.7560975609756098,
            "recall": 0.0668103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 9540,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6268577302173793,
            "auditor_fn_violation": 0.001418725384890799,
            "auditor_fp_violation": 0.0036012721376902095,
            "ave_precision_score": 0.6876224146949518,
            "fpr": 0.44956140350877194,
            "logloss": 7.19972884307441,
            "mae": 0.45802295158960316,
            "precision": 0.5413870246085011,
            "recall": 0.9877551020408163
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.8096597791496234,
            "auditor_fn_violation": 0.0033877133880919038,
            "auditor_fp_violation": 0.00580771431448098,
            "ave_precision_score": 0.6798164355532762,
            "fpr": 0.47200878155872666,
            "logloss": 7.533365810240868,
            "mae": 0.4838529146398069,
            "precision": 0.5146726862302483,
            "recall": 0.9827586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5434548094454277,
            "auditor_fn_violation": 0.0036564625850340183,
            "auditor_fp_violation": 0.01920938305479338,
            "ave_precision_score": 0.5449867571446682,
            "fpr": 0.23574561403508773,
            "logloss": 1.5882737504284823,
            "mae": 0.47820930851765053,
            "precision": 0.5708582834331337,
            "recall": 0.5836734693877551
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5126461102637324,
            "auditor_fn_violation": 0.016966955600136276,
            "auditor_fp_violation": 0.006691763850723324,
            "ave_precision_score": 0.5140902253361156,
            "fpr": 0.24259055982436883,
            "logloss": 1.6206083468867094,
            "mae": 0.47802007117501083,
            "precision": 0.5498981670061099,
            "recall": 0.5818965517241379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7420334795804242,
            "auditor_fn_violation": 0.010439044038668101,
            "auditor_fp_violation": 0.014389498628086805,
            "ave_precision_score": 0.744127322302124,
            "fpr": 0.14912280701754385,
            "logloss": 1.2559459635607213,
            "mae": 0.3182991638333869,
            "precision": 0.7195876288659794,
            "recall": 0.7122448979591837
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7703821204769065,
            "auditor_fn_violation": 0.013077709224421814,
            "auditor_fp_violation": 0.014638386904279538,
            "ave_precision_score": 0.7703154241727739,
            "fpr": 0.145993413830955,
            "logloss": 1.0918698810159528,
            "mae": 0.28825349241007925,
            "precision": 0.7268993839835729,
            "recall": 0.7629310344827587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7482468653704517,
            "auditor_fn_violation": 0.01308181167203724,
            "auditor_fp_violation": 0.010515402843601897,
            "ave_precision_score": 0.7498230272185323,
            "fpr": 0.15021929824561403,
            "logloss": 1.3211731589729911,
            "mae": 0.3159142442464631,
            "precision": 0.7181069958847737,
            "recall": 0.7122448979591837
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7764525926560175,
            "auditor_fn_violation": 0.014083140921306636,
            "auditor_fp_violation": 0.01760731993016009,
            "ave_precision_score": 0.7764595480924545,
            "fpr": 0.14709110867178923,
            "logloss": 1.1428222087706668,
            "mae": 0.28459993567988884,
            "precision": 0.7259713701431493,
            "recall": 0.7650862068965517
        }
    }
]