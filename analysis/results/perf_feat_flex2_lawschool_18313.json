[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517469670902422,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5356967210815051,
            "fpr": 0.42105263157894735,
            "logloss": 14.81725829271301,
            "mae": 0.45656158110639616,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.766976780872874,
            "auditor_fn_violation": 0.012423701022831137,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5571680462423708,
            "fpr": 0.3951701427003293,
            "logloss": 13.817942090727032,
            "mae": 0.4209023806160881,
            "precision": 0.5577395577395577,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7530896034234001,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5385555951267302,
            "fpr": 0.42105263157894735,
            "logloss": 14.877198820919586,
            "mae": 0.45759735664041873,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7674694191073856,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.559497301348755,
            "fpr": 0.3951701427003293,
            "logloss": 13.88083421335807,
            "mae": 0.42261357223885393,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7842158981136494,
            "auditor_fn_violation": 0.007574082264484739,
            "auditor_fp_violation": 0.014324802832770003,
            "ave_precision_score": 0.7495504553159393,
            "fpr": 0.15350877192982457,
            "logloss": 3.7607561283762156,
            "mae": 0.2859684883905236,
            "precision": 0.7244094488188977,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.779184629454666,
            "auditor_fn_violation": 0.013670663990557073,
            "auditor_fp_violation": 0.024004786253717082,
            "ave_precision_score": 0.743954385825019,
            "fpr": 0.15367727771679474,
            "logloss": 3.610790883529686,
            "mae": 0.2829687684639246,
            "precision": 0.726027397260274,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.6838296485292215,
            "auditor_fn_violation": 0.010050401739643248,
            "auditor_fp_violation": 0.009124014163849994,
            "ave_precision_score": 0.6851149844291351,
            "fpr": 0.02412280701754386,
            "logloss": 7.5546803269553,
            "mae": 0.5153359751869386,
            "precision": 0.5686274509803921,
            "recall": 0.06092436974789916
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.629019257011279,
            "auditor_fn_violation": 0.012331843713974722,
            "auditor_fp_violation": 0.011691844355490881,
            "ave_precision_score": 0.6302122190492927,
            "fpr": 0.029637760702524697,
            "logloss": 7.719180951282934,
            "mae": 0.5340472523422239,
            "precision": 0.4489795918367347,
            "recall": 0.04602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7931729152735224,
            "auditor_fn_violation": 0.007868937048503616,
            "auditor_fp_violation": 0.024273700305810397,
            "ave_precision_score": 0.7217219253108588,
            "fpr": 0.2138157894736842,
            "logloss": 5.652044141545118,
            "mae": 0.30383047149184456,
            "precision": 0.6700507614213198,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7902325258923399,
            "auditor_fn_violation": 0.01276816593104272,
            "auditor_fp_violation": 0.02251668724316349,
            "ave_precision_score": 0.719759037768861,
            "fpr": 0.2052689352360044,
            "logloss": 5.438918344410274,
            "mae": 0.2922289556135068,
            "precision": 0.6808873720136519,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517616896994672,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5357114424186993,
            "fpr": 0.42105263157894735,
            "logloss": 14.786405788090525,
            "mae": 0.45597481199680917,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7670028277856694,
            "auditor_fn_violation": 0.01162454243578026,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.557194090050061,
            "fpr": 0.3951701427003293,
            "logloss": 13.797346787782365,
            "mae": 0.42020287901029413,
            "precision": 0.558282208588957,
            "recall": 0.9518828451882845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7783030862382744,
            "auditor_fn_violation": 0.009545923632610942,
            "auditor_fp_violation": 0.018084560598744564,
            "ave_precision_score": 0.7294494738276456,
            "fpr": 0.15899122807017543,
            "logloss": 5.068452546107178,
            "mae": 0.30220345999556164,
            "precision": 0.7028688524590164,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7718687474570388,
            "auditor_fn_violation": 0.01562263180375605,
            "auditor_fp_violation": 0.023467346747350196,
            "ave_precision_score": 0.7211524810699725,
            "fpr": 0.1690450054884742,
            "logloss": 5.141382289668978,
            "mae": 0.3167388047626285,
            "precision": 0.6901408450704225,
            "recall": 0.7175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7857111872161866,
            "auditor_fn_violation": 0.013286893704850361,
            "auditor_fp_violation": 0.011689200064381145,
            "ave_precision_score": 0.7820154077225431,
            "fpr": 0.15789473684210525,
            "logloss": 2.10357720653105,
            "mae": 0.3010152643623588,
            "precision": 0.708502024291498,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7994627871359596,
            "auditor_fn_violation": 0.015358542040793831,
            "auditor_fp_violation": 0.013937935877382679,
            "ave_precision_score": 0.7969460373638272,
            "fpr": 0.150384193194292,
            "logloss": 1.9230446641761092,
            "mae": 0.30037738705981987,
            "precision": 0.7163561076604554,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7787140663539426,
            "auditor_fn_violation": 0.0009997420020639847,
            "auditor_fp_violation": 0.018562389344921944,
            "ave_precision_score": 0.7020704441448398,
            "fpr": 0.1611842105263158,
            "logloss": 7.758325807194421,
            "mae": 0.32118387648455643,
            "precision": 0.6911764705882353,
            "recall": 0.6911764705882353
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7662008560887071,
            "auditor_fn_violation": 0.023391463700287968,
            "auditor_fp_violation": 0.02030101682540568,
            "ave_precision_score": 0.686927199446376,
            "fpr": 0.1734357848518112,
            "logloss": 7.992768298634298,
            "mae": 0.33978041717405894,
            "precision": 0.6735537190082644,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.8277682825788768,
            "auditor_fn_violation": 0.004427428866283357,
            "auditor_fp_violation": 0.0172772815065186,
            "ave_precision_score": 0.8272293576143048,
            "fpr": 0.3442982456140351,
            "logloss": 1.9311152826425595,
            "mae": 0.3631336811128458,
            "precision": 0.5932642487046632,
            "recall": 0.9621848739495799
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.8337827417333772,
            "auditor_fn_violation": 0.004859251638504747,
            "auditor_fp_violation": 0.019712875478815513,
            "ave_precision_score": 0.8335590755939302,
            "fpr": 0.34357848518111966,
            "logloss": 1.8870550698493207,
            "mae": 0.3513977223456734,
            "precision": 0.5982028241335045,
            "recall": 0.9748953974895398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.36999637256002293,
            "auditor_fn_violation": 0.0017138434321097018,
            "auditor_fp_violation": 0.001858502333816192,
            "ave_precision_score": 0.37119889368591674,
            "fpr": 0.005482456140350877,
            "logloss": 17.94883726618079,
            "mae": 0.5247196600558917,
            "precision": 0.375,
            "recall": 0.0063025210084033615
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.3720491748877418,
            "auditor_fn_violation": 0.0010701376481773298,
            "auditor_fp_violation": 0.0025705832993208493,
            "ave_precision_score": 0.37307017655520314,
            "fpr": 0.008781558726673985,
            "logloss": 18.054187565356482,
            "mae": 0.531447747847188,
            "precision": 0.2,
            "recall": 0.0041841004184100415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 18313,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.792998838432873,
            "auditor_fn_violation": 0.009822349992628633,
            "auditor_fp_violation": 0.021834258812168036,
            "ave_precision_score": 0.6949200139489342,
            "fpr": 0.21710526315789475,
            "logloss": 7.576254284997625,
            "mae": 0.31810967831355635,
            "precision": 0.6592082616179001,
            "recall": 0.8046218487394958
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.787466303014133,
            "auditor_fn_violation": 0.012455851080930886,
            "auditor_fp_violation": 0.02267893313187803,
            "ave_precision_score": 0.6860898909164729,
            "fpr": 0.19978046103183314,
            "logloss": 7.574660929594134,
            "mae": 0.2962868804176459,
            "precision": 0.6851211072664359,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.751454730028064,
            "auditor_fn_violation": 0.004072681704260652,
            "auditor_fp_violation": 0.005170610011266696,
            "ave_precision_score": 0.5354045052360327,
            "fpr": 0.4451754385964912,
            "logloss": 14.630377446342225,
            "mae": 0.46344916444892686,
            "precision": 0.5344036697247706,
            "recall": 0.9789915966386554
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7668137093487072,
            "auditor_fn_violation": 0.00470768707889165,
            "auditor_fp_violation": 0.011717195275602525,
            "ave_precision_score": 0.5570049932595418,
            "fpr": 0.41602634467618005,
            "logloss": 13.710887770693533,
            "mae": 0.43093430403718147,
            "precision": 0.5535924617196702,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7515594802762704,
            "auditor_fn_violation": 0.01174812030075188,
            "auditor_fp_violation": 0.015597336230484466,
            "ave_precision_score": 0.5355092480719422,
            "fpr": 0.4232456140350877,
            "logloss": 14.803697124167215,
            "mae": 0.456735599398431,
            "precision": 0.5354993983152828,
            "recall": 0.9348739495798319
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7667635684268758,
            "auditor_fn_violation": 0.01162454243578026,
            "auditor_fp_violation": 0.0185847595338473,
            "ave_precision_score": 0.5569548582587143,
            "fpr": 0.39846322722283206,
            "logloss": 13.817334277040654,
            "mae": 0.4232585731017391,
            "precision": 0.5562347188264058,
            "recall": 0.9518828451882845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7735141654883335,
            "auditor_fn_violation": 0.015288681261978479,
            "auditor_fp_violation": 0.016291445356510545,
            "ave_precision_score": 0.7464562625398061,
            "fpr": 0.1425438596491228,
            "logloss": 3.8744159920850554,
            "mae": 0.30460465867962433,
            "precision": 0.7180043383947939,
            "recall": 0.6953781512605042
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7712657792160906,
            "auditor_fn_violation": 0.020782716128765578,
            "auditor_fp_violation": 0.023971830057571943,
            "ave_precision_score": 0.742018941450038,
            "fpr": 0.14818880351262348,
            "logloss": 3.7879182889531657,
            "mae": 0.3118582116303816,
            "precision": 0.7096774193548387,
            "recall": 0.6903765690376569
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517926529185205,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5357424031779113,
            "fpr": 0.42105263157894735,
            "logloss": 14.827554844872648,
            "mae": 0.4564959691190661,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7669638346661047,
            "auditor_fn_violation": 0.012423701022831137,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5571551017263456,
            "fpr": 0.3951701427003293,
            "logloss": 13.835686987275357,
            "mae": 0.4213786909885129,
            "precision": 0.5577395577395577,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.852954228767198,
            "auditor_fn_violation": 0.006896837682441406,
            "auditor_fp_violation": 0.010854257202639628,
            "ave_precision_score": 0.8224166880802161,
            "fpr": 0.09539473684210527,
            "logloss": 4.117298158505188,
            "mae": 0.24797650436063068,
            "precision": 0.795774647887324,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.858967442799341,
            "auditor_fn_violation": 0.0028016479201208836,
            "auditor_fp_violation": 0.015573070224583803,
            "ave_precision_score": 0.8370183215251774,
            "fpr": 0.10757409440175632,
            "logloss": 3.9867378895994543,
            "mae": 0.25881669146546593,
            "precision": 0.7752293577981652,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 18313,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.6832467641088136,
            "auditor_fn_violation": 0.010172490048651055,
            "auditor_fp_violation": 0.009843272171253824,
            "ave_precision_score": 0.6845297141974929,
            "fpr": 0.029605263157894735,
            "logloss": 12.6862985930672,
            "mae": 0.5197431903790668,
            "precision": 0.5263157894736842,
            "recall": 0.06302521008403361
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.6263535587542075,
            "auditor_fn_violation": 0.012331843713974722,
            "auditor_fp_violation": 0.013664145940176899,
            "ave_precision_score": 0.6275442825352695,
            "fpr": 0.04171240395170143,
            "logloss": 12.998004488536504,
            "mae": 0.5409020565598688,
            "precision": 0.36666666666666664,
            "recall": 0.04602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7917110257994484,
            "auditor_fn_violation": 0.010181704260651634,
            "auditor_fp_violation": 0.023451331884757773,
            "ave_precision_score": 0.6899712084615769,
            "fpr": 0.22478070175438597,
            "logloss": 7.674275382553472,
            "mae": 0.3138953111681226,
            "precision": 0.6583333333333333,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7859956613063379,
            "auditor_fn_violation": 0.013677553288721302,
            "auditor_fp_violation": 0.020389745045796444,
            "ave_precision_score": 0.6796103361450468,
            "fpr": 0.21734357848518113,
            "logloss": 7.70041930271195,
            "mae": 0.30151033679574174,
            "precision": 0.669449081803005,
            "recall": 0.8389121338912134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7946827856143136,
            "auditor_fn_violation": 0.008352683178534577,
            "auditor_fp_violation": 0.021929824561403504,
            "ave_precision_score": 0.6840730143704339,
            "fpr": 0.23903508771929824,
            "logloss": 7.934901564398974,
            "mae": 0.31662165388314334,
            "precision": 0.6512,
            "recall": 0.8550420168067226
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7927150437529227,
            "auditor_fn_violation": 0.012382365233845748,
            "auditor_fp_violation": 0.02046579780613138,
            "ave_precision_score": 0.6785918168822755,
            "fpr": 0.23600439077936333,
            "logloss": 7.796982028401987,
            "mae": 0.3084397472715412,
            "precision": 0.6570972886762361,
            "recall": 0.8619246861924686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7530934002859746,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.538559391749065,
            "fpr": 0.42105263157894735,
            "logloss": 14.863000181583706,
            "mae": 0.45759312448609607,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7674830814605286,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5595109621987733,
            "fpr": 0.3951701427003293,
            "logloss": 13.871557602931349,
            "mae": 0.4226173418938186,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517443664634506,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5356941205819437,
            "fpr": 0.42105263157894735,
            "logloss": 14.826628801775037,
            "mae": 0.4564761434785493,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7669404709160426,
            "auditor_fn_violation": 0.012423701022831137,
            "auditor_fp_violation": 0.01764677548971641,
            "ave_precision_score": 0.557131740691606,
            "fpr": 0.39626783754116357,
            "logloss": 13.837121781715268,
            "mae": 0.4224619160515639,
            "precision": 0.5570552147239264,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7517349158883063,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.016688797682279093,
            "ave_precision_score": 0.5356846714876455,
            "fpr": 0.42214912280701755,
            "logloss": 14.850321795019777,
            "mae": 0.45783062570265437,
            "precision": 0.535024154589372,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7669054477492445,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5570967225252395,
            "fpr": 0.3951701427003293,
            "logloss": 13.865051326555585,
            "mae": 0.4227008804083076,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.751705639213226,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.53565539643878,
            "fpr": 0.42105263157894735,
            "logloss": 14.922253518691925,
            "mae": 0.4573361903780078,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7668994392395639,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5570907138958511,
            "fpr": 0.3951701427003293,
            "logloss": 13.909663710969335,
            "mae": 0.42241853839427873,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7905679337351993,
            "auditor_fn_violation": 0.00867057349255492,
            "auditor_fp_violation": 0.024932600997907613,
            "ave_precision_score": 0.6848627795173244,
            "fpr": 0.24780701754385964,
            "logloss": 7.73110615157715,
            "mae": 0.31751051817087667,
            "precision": 0.646875,
            "recall": 0.8697478991596639
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7885780224080964,
            "auditor_fn_violation": 0.010655447827345003,
            "auditor_fp_violation": 0.022965398529139616,
            "ave_precision_score": 0.6799908914446546,
            "fpr": 0.24259055982436883,
            "logloss": 7.6308080980454225,
            "mae": 0.31064367322359304,
            "precision": 0.6530612244897959,
            "recall": 0.8702928870292888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7624035281146637,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013027120553677869,
            "ave_precision_score": 0.5248070562293274,
            "fpr": 0.4725877192982456,
            "logloss": 16.32297967559481,
            "mae": 0.47258795113048757,
            "precision": 0.5248070562293274,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7636266735694339,
            "auditor_fn_violation": 0.0006475940274377781,
            "auditor_fp_violation": 0.0044009197313816485,
            "ave_precision_score": 0.5282402944136423,
            "fpr": 0.4676180021953897,
            "logloss": 16.16470211018255,
            "mae": 0.46871569210084846,
            "precision": 0.5282392026578073,
            "recall": 0.997907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.752640524223614,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.018280721873491067,
            "ave_precision_score": 0.5374978054330849,
            "fpr": 0.4199561403508772,
            "logloss": 14.695086731293548,
            "mae": 0.4559986487346009,
            "precision": 0.5363196125907991,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7670829152710948,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5572741672725806,
            "fpr": 0.3951701427003293,
            "logloss": 13.807918858468357,
            "mae": 0.421899730590722,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 18313,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7746103962618301,
            "auditor_fn_violation": 0.01102941176470589,
            "auditor_fp_violation": 0.012835989055206828,
            "ave_precision_score": 0.7416447404163933,
            "fpr": 0.13486842105263158,
            "logloss": 4.776413295905784,
            "mae": 0.31629821707404665,
            "precision": 0.7146171693735499,
            "recall": 0.6470588235294118
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7674508441215682,
            "auditor_fn_violation": 0.021306302789247184,
            "auditor_fp_violation": 0.022392467734616426,
            "ave_precision_score": 0.7328421719709958,
            "fpr": 0.13830954994511527,
            "logloss": 4.862002589472249,
            "mae": 0.32395694155073107,
            "precision": 0.7103448275862069,
            "recall": 0.6464435146443515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.7065862212802673,
            "auditor_fn_violation": 0.013480392156862748,
            "auditor_fp_violation": 0.013869608079832613,
            "ave_precision_score": 0.5111046287661682,
            "fpr": 0.40460526315789475,
            "logloss": 16.491670818178463,
            "mae": 0.5024869453556001,
            "precision": 0.5112582781456954,
            "recall": 0.8109243697478992
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7101110553460012,
            "auditor_fn_violation": 0.020040968359749962,
            "auditor_fp_violation": 0.014556498328106815,
            "ave_precision_score": 0.523029163805745,
            "fpr": 0.38309549945115257,
            "logloss": 16.0181022153187,
            "mae": 0.48714455581505384,
            "precision": 0.523224043715847,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 18313,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8083168695786483,
            "auditor_fn_violation": 0.006894534129441254,
            "auditor_fp_violation": 0.018957226782552714,
            "ave_precision_score": 0.8087842188356571,
            "fpr": 0.18640350877192982,
            "logloss": 0.7638850251528211,
            "mae": 0.29463082217862074,
            "precision": 0.702276707530648,
            "recall": 0.842436974789916
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.819932419907638,
            "auditor_fn_violation": 0.010777158761579761,
            "auditor_fp_violation": 0.017636635121671743,
            "ave_precision_score": 0.8202560355369088,
            "fpr": 0.1800219538968167,
            "logloss": 0.749304101772973,
            "mae": 0.29116110201581547,
            "precision": 0.712784588441331,
            "recall": 0.8514644351464435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 18313,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.6821232585547166,
            "auditor_fn_violation": 0.012222652218782252,
            "auditor_fp_violation": 0.009848301947529376,
            "ave_precision_score": 0.6831209678615935,
            "fpr": 0.02850877192982456,
            "logloss": 2.5226282456819193,
            "mae": 0.5144045249126219,
            "precision": 0.543859649122807,
            "recall": 0.06512605042016807
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.6473328713321155,
            "auditor_fn_violation": 0.01114918086244827,
            "auditor_fp_violation": 0.01692680935854567,
            "ave_precision_score": 0.6483088462971839,
            "fpr": 0.038419319429198684,
            "logloss": 2.53547459412521,
            "mae": 0.5315814157597443,
            "precision": 0.39655172413793105,
            "recall": 0.04811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7519742706241036,
            "auditor_fn_violation": 0.002262089046144774,
            "auditor_fp_violation": 0.010884435860292961,
            "ave_precision_score": 0.5359240070247435,
            "fpr": 0.43640350877192985,
            "logloss": 14.607606813106546,
            "mae": 0.4459342428687043,
            "precision": 0.5414746543778802,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7669262200043782,
            "auditor_fn_violation": 0.002360732837610057,
            "auditor_fp_violation": 0.010386271969741153,
            "ave_precision_score": 0.5571174912980785,
            "fpr": 0.41822173435784854,
            "logloss": 13.740916910154803,
            "mae": 0.425724291763539,
            "precision": 0.5543859649122806,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7519473759861289,
            "auditor_fn_violation": 0.007472725932478256,
            "auditor_fp_violation": 0.014533538548205388,
            "ave_precision_score": 0.535897114427759,
            "fpr": 0.4243421052631579,
            "logloss": 14.634007605070416,
            "mae": 0.44993029765225917,
            "precision": 0.5387365911799762,
            "recall": 0.9495798319327731
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7669396506106747,
            "auditor_fn_violation": 0.009603681640938966,
            "auditor_fp_violation": 0.01773550371010717,
            "ave_precision_score": 0.5571309215858988,
            "fpr": 0.3995609220636663,
            "logloss": 13.72132530515646,
            "mae": 0.4198182420445314,
            "precision": 0.558252427184466,
            "recall": 0.9623430962343096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7863877053819567,
            "auditor_fn_violation": 0.010762199616688782,
            "auditor_fp_violation": 0.02137654917109288,
            "ave_precision_score": 0.7510268385977972,
            "fpr": 0.14802631578947367,
            "logloss": 4.265398827395312,
            "mae": 0.29662712733400265,
            "precision": 0.7163865546218487,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.777115154123323,
            "auditor_fn_violation": 0.01812803990281497,
            "auditor_fp_violation": 0.02066353498300221,
            "ave_precision_score": 0.7394343792624558,
            "fpr": 0.15806805708013172,
            "logloss": 4.329996471952539,
            "mae": 0.3115344988369448,
            "precision": 0.7018633540372671,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7518537873816821,
            "auditor_fn_violation": 0.008691305469556243,
            "auditor_fp_violation": 0.017727446483180424,
            "ave_precision_score": 0.5358035329723017,
            "fpr": 0.42214912280701755,
            "logloss": 14.689230622880665,
            "mae": 0.4530753699324613,
            "precision": 0.5372596153846154,
            "recall": 0.9390756302521008
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.766955212801844,
            "auditor_fn_violation": 0.012235393539675468,
            "auditor_fp_violation": 0.017411011932678105,
            "ave_precision_score": 0.5571464810608174,
            "fpr": 0.3973655323819978,
            "logloss": 13.74972797303399,
            "mae": 0.42010808307499564,
            "precision": 0.557997557997558,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7809889812107631,
            "auditor_fn_violation": 0.015076754385964916,
            "auditor_fp_violation": 0.022772312087558363,
            "ave_precision_score": 0.6115574596697977,
            "fpr": 0.3125,
            "logloss": 11.350310135700969,
            "mae": 0.36654982403479275,
            "precision": 0.5997191011235955,
            "recall": 0.8970588235294118
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7948357630814361,
            "auditor_fn_violation": 0.009844807076687074,
            "auditor_fp_violation": 0.024334348215168486,
            "ave_precision_score": 0.6277603431992735,
            "fpr": 0.29418221734357847,
            "logloss": 10.513017018930825,
            "mae": 0.3366577990754989,
            "precision": 0.620933521923621,
            "recall": 0.9184100418410042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 18313,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.7157848174244285,
            "auditor_fn_violation": 0.005406438891346016,
            "auditor_fp_violation": 0.0013982778046032632,
            "ave_precision_score": 0.5103959649086486,
            "fpr": 0.4309210526315789,
            "logloss": 16.447054426045327,
            "mae": 0.5079001789281388,
            "precision": 0.5075187969924813,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7444212467207973,
            "auditor_fn_violation": 0.0018624069370639681,
            "auditor_fp_violation": 0.006096896286850735,
            "ave_precision_score": 0.5394620743884214,
            "fpr": 0.40175631174533477,
            "logloss": 14.972564337841098,
            "mae": 0.45425647850267015,
            "precision": 0.5407779171894604,
            "recall": 0.9016736401673641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 18313,
        "test": {
            "accuracy": 0.43859649122807015,
            "auc_prc": 0.44437846130402314,
            "auditor_fn_violation": 0.004266180156273052,
            "auditor_fp_violation": 0.007605021728633514,
            "ave_precision_score": 0.44592505418320655,
            "fpr": 0.29385964912280704,
            "logloss": 2.717475061976038,
            "mae": 0.5679697846594413,
            "precision": 0.464,
            "recall": 0.48739495798319327
        },
        "train": {
            "accuracy": 0.43468715697036225,
            "auc_prc": 0.45994753414638706,
            "auditor_fn_violation": 0.02270253388386481,
            "auditor_fp_violation": 0.024907279009691655,
            "ave_precision_score": 0.46168056851810646,
            "fpr": 0.27771679473106475,
            "logloss": 2.640380599261911,
            "mae": 0.5640975843787691,
            "precision": 0.4605543710021322,
            "recall": 0.45188284518828453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8240081997608109,
            "auditor_fn_violation": 0.009815439333628188,
            "auditor_fp_violation": 0.019183566714952516,
            "ave_precision_score": 0.824423178733912,
            "fpr": 0.2412280701754386,
            "logloss": 1.0049231436016983,
            "mae": 0.30192310212039236,
            "precision": 0.663093415007657,
            "recall": 0.9096638655462185
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.829750268519799,
            "auditor_fn_violation": 0.0077206068093823065,
            "auditor_fp_violation": 0.028499504389511824,
            "ave_precision_score": 0.8301554797712529,
            "fpr": 0.2414928649835346,
            "logloss": 0.9980058444029445,
            "mae": 0.2902670765589331,
            "precision": 0.6676737160120846,
            "recall": 0.9246861924686193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7365467833205559,
            "auditor_fn_violation": 0.020464764853309746,
            "auditor_fp_violation": 0.00879707870593916,
            "ave_precision_score": 0.6071856181014343,
            "fpr": 0.18969298245614036,
            "logloss": 12.371286630927008,
            "mae": 0.37031787594257964,
            "precision": 0.643298969072165,
            "recall": 0.6554621848739496
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7352150887845611,
            "auditor_fn_violation": 0.02016267929398472,
            "auditor_fp_violation": 0.01105553626068859,
            "ave_precision_score": 0.6090782889564095,
            "fpr": 0.19538968166849616,
            "logloss": 12.525905402773292,
            "mae": 0.3773408305576835,
            "precision": 0.6359918200408998,
            "recall": 0.6506276150627615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7521098750032497,
            "auditor_fn_violation": 0.010232382426654873,
            "auditor_fp_violation": 0.01450084500241429,
            "ave_precision_score": 0.5355311691934568,
            "fpr": 0.4232456140350877,
            "logloss": 14.794627587110316,
            "mae": 0.4558182420900259,
            "precision": 0.5360576923076923,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7669506666384975,
            "auditor_fn_violation": 0.013333088380509717,
            "auditor_fp_violation": 0.01705102886709273,
            "ave_precision_score": 0.5571419351650905,
            "fpr": 0.3973655323819978,
            "logloss": 13.766679425473214,
            "mae": 0.420473063841487,
            "precision": 0.557997557997558,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517137147152088,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.535663471477726,
            "fpr": 0.42105263157894735,
            "logloss": 14.836532938482675,
            "mae": 0.45644656956425794,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7669484650121041,
            "auditor_fn_violation": 0.012423701022831137,
            "auditor_fp_violation": 0.01764677548971641,
            "ave_precision_score": 0.5571397339733491,
            "fpr": 0.39626783754116357,
            "logloss": 13.837429934224353,
            "mae": 0.4221964146546486,
            "precision": 0.5570552147239264,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.6250927675257434,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017538829872847255,
            "ave_precision_score": 0.5769161627557414,
            "fpr": 0.05482456140350877,
            "logloss": 17.302266542977208,
            "mae": 0.5397455037872485,
            "precision": 0.39759036144578314,
            "recall": 0.06932773109243698
        },
        "train": {
            "accuracy": 0.4270032930845225,
            "auc_prc": 0.5826963536402365,
            "auditor_fn_violation": 0.010685301452723353,
            "auditor_fp_violation": 0.016706256353574356,
            "ave_precision_score": 0.5414849001866633,
            "fpr": 0.07354555433589462,
            "logloss": 17.92875341350835,
            "mae": 0.5721002415783036,
            "precision": 0.25555555555555554,
            "recall": 0.04811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7516865070040737,
            "auditor_fn_violation": 0.01222265221878225,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5356362663529718,
            "fpr": 0.42105263157894735,
            "logloss": 14.775958917781596,
            "mae": 0.4549638299274159,
            "precision": 0.5367913148371531,
            "recall": 0.9348739495798319
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7667689011631041,
            "auditor_fn_violation": 0.012671715756743474,
            "auditor_fp_violation": 0.01764677548971641,
            "ave_precision_score": 0.5569601910030907,
            "fpr": 0.39626783754116357,
            "logloss": 13.806631010199183,
            "mae": 0.42091168423651437,
            "precision": 0.5581395348837209,
            "recall": 0.9539748953974896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.751284406593209,
            "auditor_fn_violation": 0.011029411764705885,
            "auditor_fp_violation": 0.015652663769515542,
            "ave_precision_score": 0.5349331253961743,
            "fpr": 0.4232456140350877,
            "logloss": 14.88558971206663,
            "mae": 0.45798410926303423,
            "precision": 0.5354993983152828,
            "recall": 0.9348739495798319
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7669197408027613,
            "auditor_fn_violation": 0.012754387334714255,
            "auditor_fp_violation": 0.01868869830630503,
            "ave_precision_score": 0.5562564178362333,
            "fpr": 0.3973655323819978,
            "logloss": 13.893606079622193,
            "mae": 0.42350112974973214,
            "precision": 0.5563725490196079,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7781852904063392,
            "auditor_fn_violation": 0.009545923632610942,
            "auditor_fp_violation": 0.018416525832930953,
            "ave_precision_score": 0.7286620652195578,
            "fpr": 0.15679824561403508,
            "logloss": 5.1211561045678655,
            "mae": 0.3024560362243713,
            "precision": 0.7057613168724279,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7719996135947952,
            "auditor_fn_violation": 0.01562263180375605,
            "auditor_fp_violation": 0.02244063448282856,
            "ave_precision_score": 0.7213330179496762,
            "fpr": 0.16794731064763996,
            "logloss": 5.176337408953341,
            "mae": 0.31681668968421167,
            "precision": 0.6915322580645161,
            "recall": 0.7175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7730072963906256,
            "auditor_fn_violation": 0.018414602683178537,
            "auditor_fp_violation": 0.015308124094640265,
            "ave_precision_score": 0.5950440461610748,
            "fpr": 0.3475877192982456,
            "logloss": 12.255085787199162,
            "mae": 0.3962432876583608,
            "precision": 0.5762032085561497,
            "recall": 0.9054621848739496
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7929437220690573,
            "auditor_fn_violation": 0.014977334209039678,
            "auditor_fp_violation": 0.021091965532889015,
            "ave_precision_score": 0.621334733439516,
            "fpr": 0.3150384193194292,
            "logloss": 11.006131166213443,
            "mae": 0.3472208003213567,
            "precision": 0.6095238095238096,
            "recall": 0.9372384937238494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8816144819700338,
            "auditor_fn_violation": 0.013144073418841223,
            "auditor_fp_violation": 0.01141759214550137,
            "ave_precision_score": 0.8817868831259914,
            "fpr": 0.10087719298245613,
            "logloss": 0.45298597126215767,
            "mae": 0.2979300471141183,
            "precision": 0.8046709129511678,
            "recall": 0.7962184873949579
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8695873416035255,
            "auditor_fn_violation": 0.017455185115441682,
            "auditor_fp_violation": 0.01272869698805718,
            "ave_precision_score": 0.8700257139741205,
            "fpr": 0.10318331503841932,
            "logloss": 0.4700779886712032,
            "mae": 0.30179874939357393,
            "precision": 0.796976241900648,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7894196518534248,
            "auditor_fn_violation": 0.005666740380362671,
            "auditor_fp_violation": 0.023715395139224212,
            "ave_precision_score": 0.7001037673180651,
            "fpr": 0.23026315789473684,
            "logloss": 7.016002889664785,
            "mae": 0.31365301933946144,
            "precision": 0.6579804560260586,
            "recall": 0.8487394957983193
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7889388286439506,
            "auditor_fn_violation": 0.012722237276614508,
            "auditor_fp_violation": 0.02046833289814255,
            "ave_precision_score": 0.6991160606936745,
            "fpr": 0.22722283205268934,
            "logloss": 6.870987188046573,
            "mae": 0.30587813965632993,
            "precision": 0.6628664495114006,
            "recall": 0.8514644351464435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517436952165709,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5356934496698655,
            "fpr": 0.42105263157894735,
            "logloss": 14.78792615782464,
            "mae": 0.4559456792395826,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7669984984972066,
            "auditor_fn_violation": 0.012423701022831137,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5571897613378356,
            "fpr": 0.3951701427003293,
            "logloss": 13.794275964119858,
            "mae": 0.4203135405106306,
            "precision": 0.5577395577395577,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8315383734329522,
            "auditor_fn_violation": 0.0004699248120300765,
            "auditor_fp_violation": 0.007474247545469179,
            "ave_precision_score": 0.8317799123407505,
            "fpr": 0.09649122807017543,
            "logloss": 0.556553876808493,
            "mae": 0.3278594997107958,
            "precision": 0.794392523364486,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8577789011579255,
            "auditor_fn_violation": 0.005309352451901218,
            "auditor_fp_violation": 0.013131776617832344,
            "ave_precision_score": 0.8580193883223555,
            "fpr": 0.09110867178924259,
            "logloss": 0.5136033275909613,
            "mae": 0.31240515886426673,
            "precision": 0.8083140877598153,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7537467113460585,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.539824366415115,
            "fpr": 0.42105263157894735,
            "logloss": 14.817031156097103,
            "mae": 0.4575250220350238,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7674867373731458,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5595146174841464,
            "fpr": 0.3951701427003293,
            "logloss": 13.864660156540676,
            "mae": 0.42261489215626746,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 18313,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.6841391767153886,
            "auditor_fn_violation": 0.010050401739643248,
            "auditor_fp_violation": 0.009606872686302914,
            "ave_precision_score": 0.685248304047251,
            "fpr": 0.02631578947368421,
            "logloss": 8.31698708317238,
            "mae": 0.5163658590153898,
            "precision": 0.5471698113207547,
            "recall": 0.06092436974789916
        },
        "train": {
            "accuracy": 0.4654226125137212,
            "auc_prc": 0.6281022793037042,
            "auditor_fn_violation": 0.012331843713974722,
            "auditor_fp_violation": 0.010469930006109572,
            "ave_precision_score": 0.6292911428832706,
            "fpr": 0.03402854006586169,
            "logloss": 8.499876899708163,
            "mae": 0.5355120209812945,
            "precision": 0.41509433962264153,
            "recall": 0.04602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 18313,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7824170181951915,
            "auditor_fn_violation": 0.01087277016069586,
            "auditor_fp_violation": 0.017860735554482535,
            "ave_precision_score": 0.7561332972112511,
            "fpr": 0.13815789473684212,
            "logloss": 4.097000193552965,
            "mae": 0.3018572922861422,
            "precision": 0.7260869565217392,
            "recall": 0.7016806722689075
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.77341280202826,
            "auditor_fn_violation": 0.017756017801946456,
            "auditor_fp_violation": 0.018896575851220523,
            "ave_precision_score": 0.7452269621441903,
            "fpr": 0.14818880351262348,
            "logloss": 4.072451401894694,
            "mae": 0.3151510411426659,
            "precision": 0.7071583514099783,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.752651740972209,
            "auditor_fn_violation": 0.010448916408668733,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5363746955953455,
            "fpr": 0.42105263157894735,
            "logloss": 14.672725228893569,
            "mae": 0.45331556907881043,
            "precision": 0.5373493975903615,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7673733497015094,
            "auditor_fn_violation": 0.012235393539675468,
            "auditor_fp_violation": 0.017527626165191677,
            "ave_precision_score": 0.5578897621941353,
            "fpr": 0.3951701427003293,
            "logloss": 13.698806804393318,
            "mae": 0.41854584891871477,
            "precision": 0.5593635250917993,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7514153095315577,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5353650879420205,
            "fpr": 0.42105263157894735,
            "logloss": 14.95535114011122,
            "mae": 0.4583521270189362,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7667456679871966,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5569369602532485,
            "fpr": 0.3951701427003293,
            "logloss": 13.935827205986078,
            "mae": 0.4236321487476298,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.754256895248363,
            "auditor_fn_violation": 0.016594795813062068,
            "auditor_fp_violation": 0.03511789795589893,
            "ave_precision_score": 0.5469960700625205,
            "fpr": 0.39473684210526316,
            "logloss": 14.321994898196738,
            "mae": 0.43808261931254394,
            "precision": 0.5477386934673367,
            "recall": 0.9159663865546218
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7692631766508169,
            "auditor_fn_violation": 0.014766062398669908,
            "auditor_fp_violation": 0.0395778564783009,
            "ave_precision_score": 0.5663109959213604,
            "fpr": 0.3754116355653128,
            "logloss": 13.410596758310735,
            "mae": 0.4061085459446546,
            "precision": 0.5681818181818182,
            "recall": 0.9414225941422594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7786948603460364,
            "auditor_fn_violation": 0.015378519828984229,
            "auditor_fp_violation": 0.01848191292451313,
            "ave_precision_score": 0.7227335115589604,
            "fpr": 0.1787280701754386,
            "logloss": 5.409736356098565,
            "mae": 0.3010009038613195,
            "precision": 0.6941838649155723,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7790644847425251,
            "auditor_fn_violation": 0.015374617069843707,
            "auditor_fp_violation": 0.022073046141209703,
            "ave_precision_score": 0.7237846145913833,
            "fpr": 0.18221734357848518,
            "logloss": 5.281460963178693,
            "mae": 0.30256269139228326,
            "precision": 0.6908752327746741,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 18313,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.7152356576866259,
            "auditor_fn_violation": 0.005406438891346016,
            "auditor_fp_violation": 0.0013982778046032632,
            "ave_precision_score": 0.5093027178521002,
            "fpr": 0.4309210526315789,
            "logloss": 16.475013721232393,
            "mae": 0.5080386243667213,
            "precision": 0.5075187969924813,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7444142488487673,
            "auditor_fn_violation": 0.0018624069370639681,
            "auditor_fp_violation": 0.005780009785455186,
            "ave_precision_score": 0.5394550771715061,
            "fpr": 0.40285400658616904,
            "logloss": 14.962614299258474,
            "mae": 0.4546374054381768,
            "precision": 0.5401002506265664,
            "recall": 0.9016736401673641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7855923509007938,
            "auditor_fn_violation": 0.013286893704850361,
            "auditor_fp_violation": 0.011689200064381145,
            "ave_precision_score": 0.7821311177815501,
            "fpr": 0.15789473684210525,
            "logloss": 2.063464336852281,
            "mae": 0.3009823977165728,
            "precision": 0.708502024291498,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7993981231127908,
            "auditor_fn_violation": 0.016107179107973674,
            "auditor_fp_violation": 0.014384112071347627,
            "ave_precision_score": 0.7970704291536757,
            "fpr": 0.15148188803512624,
            "logloss": 1.886490697502445,
            "mae": 0.30031415049677346,
            "precision": 0.7166324435318275,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7531102335414434,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5385762237416363,
            "fpr": 0.42105263157894735,
            "logloss": 14.867491839240978,
            "mae": 0.45752421701452556,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7674845330377081,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5595124135872276,
            "fpr": 0.3951701427003293,
            "logloss": 13.875717508267753,
            "mae": 0.42261674345341604,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8074867937493924,
            "auditor_fn_violation": 0.007832080200501253,
            "auditor_fp_violation": 0.0184743682600998,
            "ave_precision_score": 0.7300904281056017,
            "fpr": 0.3168859649122807,
            "logloss": 6.908945743566452,
            "mae": 0.35525679503522517,
            "precision": 0.6046511627906976,
            "recall": 0.9285714285714286
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.8110600576878878,
            "auditor_fn_violation": 0.006861740971574756,
            "auditor_fp_violation": 0.02297807398919545,
            "ave_precision_score": 0.7368403369718984,
            "fpr": 0.3194291986827662,
            "logloss": 6.50862061956037,
            "mae": 0.34793557903835615,
            "precision": 0.6078167115902965,
            "recall": 0.9435146443514645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.789940971313842,
            "auditor_fn_violation": 0.009785493144626274,
            "auditor_fp_violation": 0.014694491389023028,
            "ave_precision_score": 0.7560443143197701,
            "fpr": 0.14364035087719298,
            "logloss": 3.6221269043559032,
            "mae": 0.27937871715372986,
            "precision": 0.7348178137651822,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7848107382781283,
            "auditor_fn_violation": 0.011888632198742482,
            "auditor_fp_violation": 0.022605415463554258,
            "ave_precision_score": 0.7508653710491964,
            "fpr": 0.13611416026344675,
            "logloss": 3.4791954242207197,
            "mae": 0.27757202011392357,
            "precision": 0.7453798767967146,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.75165265986679,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5356024223428255,
            "fpr": 0.42105263157894735,
            "logloss": 14.798229082929536,
            "mae": 0.45750443414208986,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7668333859577544,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5570246670823605,
            "fpr": 0.3951701427003293,
            "logloss": 13.827942841447184,
            "mae": 0.42260459689004853,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7517333378509891,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5356830936586138,
            "fpr": 0.42105263157894735,
            "logloss": 14.854517614394696,
            "mae": 0.4578249705346052,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7668973095778567,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5570885852767563,
            "fpr": 0.3951701427003293,
            "logloss": 13.867553094391422,
            "mae": 0.42268648977440476,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.797291069887867,
            "auditor_fn_violation": 0.01078753869969041,
            "auditor_fp_violation": 0.004154595203605347,
            "ave_precision_score": 0.6813634502222301,
            "fpr": 0.1118421052631579,
            "logloss": 9.667975920234037,
            "mae": 0.2860976006746856,
            "precision": 0.7565632458233891,
            "recall": 0.6659663865546218
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8096811366571283,
            "auditor_fn_violation": 0.007605785173311776,
            "auditor_fp_violation": 0.006124782298973541,
            "ave_precision_score": 0.6927216238591525,
            "fpr": 0.1119648737650933,
            "logloss": 9.29140295385753,
            "mae": 0.2704955324289465,
            "precision": 0.7660550458715596,
            "recall": 0.698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 18313,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7798438322284077,
            "auditor_fn_violation": 0.009555137844611532,
            "auditor_fp_violation": 0.015899122807017555,
            "ave_precision_score": 0.7364864244077243,
            "fpr": 0.15679824561403508,
            "logloss": 4.83555769158536,
            "mae": 0.3043253498726561,
            "precision": 0.7039337474120083,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7731757382328692,
            "auditor_fn_violation": 0.018153300662750484,
            "auditor_fp_violation": 0.022572459267409115,
            "ave_precision_score": 0.7291071366520879,
            "fpr": 0.16245883644346873,
            "logloss": 4.77075086927919,
            "mae": 0.31563677295339004,
            "precision": 0.6973415132924335,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7888078756919609,
            "auditor_fn_violation": 0.00751418988648091,
            "auditor_fp_violation": 0.023705335586673103,
            "ave_precision_score": 0.7030196823875688,
            "fpr": 0.23464912280701755,
            "logloss": 6.772124472899547,
            "mae": 0.3124056067408254,
            "precision": 0.654281098546042,
            "recall": 0.8508403361344538
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7899166974794419,
            "auditor_fn_violation": 0.013144780897354054,
            "auditor_fp_violation": 0.018095486775692518,
            "ave_precision_score": 0.7057458091025777,
            "fpr": 0.2283205268935236,
            "logloss": 6.569161427901353,
            "mae": 0.30359400929725133,
            "precision": 0.6628849270664505,
            "recall": 0.8556485355648535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7524489806544052,
            "auditor_fn_violation": 0.011655978180745983,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5370030109431597,
            "fpr": 0.42105263157894735,
            "logloss": 14.68683263994865,
            "mae": 0.45497485257607717,
            "precision": 0.5362318840579711,
            "recall": 0.9327731092436975
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7669953397505976,
            "auditor_fn_violation": 0.012235393539675468,
            "auditor_fp_violation": 0.01764677548971641,
            "ave_precision_score": 0.5571866031600785,
            "fpr": 0.39626783754116357,
            "logloss": 13.769122275953793,
            "mae": 0.41965931148591484,
            "precision": 0.558679706601467,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7778571898526447,
            "auditor_fn_violation": 0.008744287188559638,
            "auditor_fp_violation": 0.01528046032512474,
            "ave_precision_score": 0.7276187937206195,
            "fpr": 0.16447368421052633,
            "logloss": 5.128932904620909,
            "mae": 0.30384727475615186,
            "precision": 0.6963562753036437,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7723291888451254,
            "auditor_fn_violation": 0.016084214780759568,
            "auditor_fp_violation": 0.021454483690485558,
            "ave_precision_score": 0.7214508866136807,
            "fpr": 0.17672886937431395,
            "logloss": 5.062238901480441,
            "mae": 0.31537795912084937,
            "precision": 0.6811881188118812,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7624035281146637,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013027120553677869,
            "ave_precision_score": 0.5248070562293274,
            "fpr": 0.4725877192982456,
            "logloss": 16.32309592551551,
            "mae": 0.4727017041238664,
            "precision": 0.5248070562293274,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7636266735694339,
            "auditor_fn_violation": 0.0006475940274377781,
            "auditor_fp_violation": 0.0044009197313816485,
            "ave_precision_score": 0.5282402944136423,
            "fpr": 0.4676180021953897,
            "logloss": 16.157396294065983,
            "mae": 0.46871282833901984,
            "precision": 0.5282392026578073,
            "recall": 0.997907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7855100857385166,
            "auditor_fn_violation": 0.009509066784608581,
            "auditor_fp_violation": 0.021074762594559798,
            "ave_precision_score": 0.7571115152590788,
            "fpr": 0.2324561403508772,
            "logloss": 3.497474323422543,
            "mae": 0.3024617490758199,
            "precision": 0.6602564102564102,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7815480478396357,
            "auditor_fn_violation": 0.010542922623995888,
            "auditor_fp_violation": 0.023799443800812753,
            "ave_precision_score": 0.7520076188020124,
            "fpr": 0.23380900109769484,
            "logloss": 3.2980805406783373,
            "mae": 0.2979524160792473,
            "precision": 0.6619047619047619,
            "recall": 0.8723849372384938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7518847646281295,
            "auditor_fn_violation": 0.008117720772519535,
            "auditor_fp_violation": 0.01572308063737325,
            "ave_precision_score": 0.5358345078333254,
            "fpr": 0.4232456140350877,
            "logloss": 14.660142878012186,
            "mae": 0.4513630349095768,
            "precision": 0.5382775119617225,
            "recall": 0.9453781512605042
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7669552736784484,
            "auditor_fn_violation": 0.011450013548953057,
            "auditor_fp_violation": 0.01773550371010717,
            "ave_precision_score": 0.5571465419273313,
            "fpr": 0.3995609220636663,
            "logloss": 13.732274742298724,
            "mae": 0.4194927177308584,
            "precision": 0.5571776155717761,
            "recall": 0.9581589958158996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.76059712451687,
            "auditor_fn_violation": 0.0016631652661064423,
            "auditor_fp_violation": 0.0026582367616288347,
            "ave_precision_score": 0.6349485525190827,
            "fpr": 0.46381578947368424,
            "logloss": 11.983953152435223,
            "mae": 0.5218597190591835,
            "precision": 0.49940828402366866,
            "recall": 0.8865546218487395
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7818688812390504,
            "auditor_fn_violation": 0.0045423439229500895,
            "auditor_fp_violation": 0.0009810806083206838,
            "ave_precision_score": 0.6511053385450315,
            "fpr": 0.4588364434687157,
            "logloss": 11.406608715439646,
            "mae": 0.4991964867017239,
            "precision": 0.5128205128205128,
            "recall": 0.9205020920502092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7566417364233811,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5466639467965164,
            "fpr": 0.42105263157894735,
            "logloss": 14.894191760191358,
            "mae": 0.45787083805664625,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7696301764946266,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5636409572061779,
            "fpr": 0.3951701427003293,
            "logloss": 13.944170403345984,
            "mae": 0.42259956630251516,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7525882312509256,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5374455174187406,
            "fpr": 0.42105263157894735,
            "logloss": 14.691965779321745,
            "mae": 0.45717665174209,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7670694105129763,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.017411011932678105,
            "ave_precision_score": 0.5575858610525325,
            "fpr": 0.3973655323819978,
            "logloss": 13.802683915952962,
            "mae": 0.424883867415403,
            "precision": 0.5558282208588957,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.6964827684084871,
            "auditor_fn_violation": 0.009497549019607868,
            "auditor_fp_violation": 0.0077961532271044595,
            "ave_precision_score": 0.6977492481639765,
            "fpr": 0.021929824561403508,
            "logloss": 13.199254148181696,
            "mae": 0.5139144925687514,
            "precision": 0.574468085106383,
            "recall": 0.05672268907563025
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.6503858024769215,
            "auditor_fn_violation": 0.012331843713974722,
            "auditor_fp_violation": 0.012515749259119361,
            "ave_precision_score": 0.6515765034726412,
            "fpr": 0.029637760702524697,
            "logloss": 13.457733388651913,
            "mae": 0.531384724332536,
            "precision": 0.4489795918367347,
            "recall": 0.04602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7821130508901288,
            "auditor_fn_violation": 0.006542090520418692,
            "auditor_fp_violation": 0.014463121680347659,
            "ave_precision_score": 0.7575349765255691,
            "fpr": 0.14802631578947367,
            "logloss": 3.1014963107351208,
            "mae": 0.2854870312069938,
            "precision": 0.73,
            "recall": 0.7668067226890757
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7765606788888816,
            "auditor_fn_violation": 0.01676625529901851,
            "auditor_fp_violation": 0.019134874500269988,
            "ave_precision_score": 0.7493510656912672,
            "fpr": 0.15477497255762898,
            "logloss": 2.976984470334406,
            "mae": 0.29010611602267594,
            "precision": 0.7202380952380952,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.7129918237576112,
            "auditor_fn_violation": 0.00766161727849035,
            "auditor_fp_violation": 0.01930428134556577,
            "ave_precision_score": 0.510759359906096,
            "fpr": 0.4155701754385965,
            "logloss": 16.25406333886492,
            "mae": 0.5036918348693618,
            "precision": 0.5103359173126615,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7441383974609743,
            "auditor_fn_violation": 0.009883846432951053,
            "auditor_fp_violation": 0.017948451439044995,
            "ave_precision_score": 0.5425181089904858,
            "fpr": 0.3896816684961581,
            "logloss": 14.704818137599206,
            "mae": 0.4488326928048434,
            "precision": 0.5442875481386393,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8159638517037429,
            "auditor_fn_violation": 0.015037593984962403,
            "auditor_fp_violation": 0.015270400772573639,
            "ave_precision_score": 0.8157795689052334,
            "fpr": 0.13706140350877194,
            "logloss": 0.9050480659888687,
            "mae": 0.27247638308252436,
            "precision": 0.749498997995992,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8081163971845093,
            "auditor_fn_violation": 0.015464177945978718,
            "auditor_fp_violation": 0.023667619016232194,
            "ave_precision_score": 0.8081538625334257,
            "fpr": 0.13172338090010977,
            "logloss": 0.8974307337594306,
            "mae": 0.2779269172621269,
            "precision": 0.7505197505197505,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 18313,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4145079346466357,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.016884958957025593,
            "ave_precision_score": 0.3977879506191563,
            "fpr": 0.051535087719298246,
            "logloss": 18.176911587570167,
            "mae": 0.5379126138845253,
            "precision": 0.4125,
            "recall": 0.06932773109243698
        },
        "train": {
            "accuracy": 0.429198682766191,
            "auc_prc": 0.3949736110491279,
            "auditor_fn_violation": 0.01209301471094803,
            "auditor_fp_violation": 0.01827547830848521,
            "ave_precision_score": 0.37968264543562513,
            "fpr": 0.07244785949506037,
            "logloss": 19.13260230291332,
            "mae": 0.5707848321121431,
            "precision": 0.26666666666666666,
            "recall": 0.0502092050209205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7517861117051676,
            "auditor_fn_violation": 0.011655978180745983,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5357358625648814,
            "fpr": 0.42105263157894735,
            "logloss": 14.779634443549691,
            "mae": 0.4556026497030076,
            "precision": 0.5362318840579711,
            "recall": 0.9327731092436975
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7669363772518621,
            "auditor_fn_violation": 0.012423701022831137,
            "auditor_fp_violation": 0.01764677548971641,
            "ave_precision_score": 0.5571276475439229,
            "fpr": 0.39626783754116357,
            "logloss": 13.807133693628,
            "mae": 0.4220998414588985,
            "precision": 0.5570552147239264,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7518262746002885,
            "auditor_fn_violation": 0.009619637328615658,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5357760224466872,
            "fpr": 0.42105263157894735,
            "logloss": 14.712424080628288,
            "mae": 0.454192391009848,
            "precision": 0.5373493975903615,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7669706282987765,
            "auditor_fn_violation": 0.012235393539675468,
            "auditor_fp_violation": 0.01764677548971641,
            "ave_precision_score": 0.5571618946414061,
            "fpr": 0.39626783754116357,
            "logloss": 13.760616336429914,
            "mae": 0.4199796346338148,
            "precision": 0.558679706601467,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7735001842609897,
            "auditor_fn_violation": 0.005537741412354416,
            "auditor_fp_violation": 0.01775511025269598,
            "ave_precision_score": 0.6527647339494003,
            "fpr": 0.26096491228070173,
            "logloss": 8.687086383190668,
            "mae": 0.3490521534821388,
            "precision": 0.6246056782334385,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7642770381558562,
            "auditor_fn_violation": 0.010386765198939966,
            "auditor_fp_violation": 0.011316650737838534,
            "ave_precision_score": 0.6411796621714296,
            "fpr": 0.2579582875960483,
            "logloss": 8.821430510830199,
            "mae": 0.33848087762484497,
            "precision": 0.6316614420062696,
            "recall": 0.8430962343096234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7521018612789441,
            "auditor_fn_violation": 0.010232382426654873,
            "auditor_fp_violation": 0.01450084500241429,
            "ave_precision_score": 0.5355231561742051,
            "fpr": 0.4232456140350877,
            "logloss": 14.806973403833,
            "mae": 0.45590380892256294,
            "precision": 0.5360576923076923,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.766944966667542,
            "auditor_fn_violation": 0.013333088380509717,
            "auditor_fp_violation": 0.01705102886709273,
            "ave_precision_score": 0.5571362359503246,
            "fpr": 0.3973655323819978,
            "logloss": 13.77339883888112,
            "mae": 0.42074289761702305,
            "precision": 0.557997557997558,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.75207740402395,
            "auditor_fn_violation": 0.009142801857585139,
            "auditor_fp_violation": 0.01450084500241429,
            "ave_precision_score": 0.5354987007635514,
            "fpr": 0.4232456140350877,
            "logloss": 14.803156926440657,
            "mae": 0.4553845623238356,
            "precision": 0.5366146458583433,
            "recall": 0.9390756302521008
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7669102747752532,
            "auditor_fn_violation": 0.012547708389787304,
            "auditor_fp_violation": 0.01705102886709273,
            "ave_precision_score": 0.5571015476601326,
            "fpr": 0.3973655323819978,
            "logloss": 13.766233581454989,
            "mae": 0.41997434747203444,
            "precision": 0.5585365853658537,
            "recall": 0.9581589958158996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 18313,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7521035573900523,
            "auditor_fn_violation": 0.010232382426654873,
            "auditor_fp_violation": 0.01450084500241429,
            "ave_precision_score": 0.5355248520522884,
            "fpr": 0.4232456140350877,
            "logloss": 14.789581255099181,
            "mae": 0.45552875244060487,
            "precision": 0.5360576923076923,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7669542983269617,
            "auditor_fn_violation": 0.012547708389787304,
            "auditor_fp_violation": 0.01705102886709273,
            "ave_precision_score": 0.557145566659684,
            "fpr": 0.3973655323819978,
            "logloss": 13.761574827844195,
            "mae": 0.4198276304384949,
            "precision": 0.5585365853658537,
            "recall": 0.9581589958158996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7930033148168709,
            "auditor_fn_violation": 0.009287925696594429,
            "auditor_fp_violation": 0.0117445276034122,
            "ave_precision_score": 0.7559561939752786,
            "fpr": 0.13815789473684212,
            "logloss": 3.940155185230406,
            "mae": 0.27891586166811483,
            "precision": 0.7428571428571429,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7880942617884064,
            "auditor_fn_violation": 0.012903655461605943,
            "auditor_fp_violation": 0.021330264181938487,
            "ave_precision_score": 0.7515654742603831,
            "fpr": 0.13062568605927552,
            "logloss": 3.88173338577514,
            "mae": 0.2794134352063432,
            "precision": 0.7531120331950207,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7767848898092045,
            "auditor_fn_violation": 0.011844869526758072,
            "auditor_fp_violation": 0.016399585546434906,
            "ave_precision_score": 0.7748539394055864,
            "fpr": 0.13048245614035087,
            "logloss": 1.9486972798853182,
            "mae": 0.291738335025937,
            "precision": 0.734966592427617,
            "recall": 0.6932773109243697
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7790649408871557,
            "auditor_fn_violation": 0.01728065622861447,
            "auditor_fp_violation": 0.021822072032104407,
            "ave_precision_score": 0.775630485600879,
            "fpr": 0.13611416026344675,
            "logloss": 1.9959121337181105,
            "mae": 0.304397433872478,
            "precision": 0.7238307349665924,
            "recall": 0.6799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7518561377301713,
            "auditor_fn_violation": 0.008691305469556243,
            "auditor_fp_violation": 0.017727446483180424,
            "ave_precision_score": 0.5358058832127219,
            "fpr": 0.42214912280701755,
            "logloss": 14.686908341955753,
            "mae": 0.4531957391543,
            "precision": 0.5372596153846154,
            "recall": 0.9390756302521008
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.766962333402373,
            "auditor_fn_violation": 0.012235393539675468,
            "auditor_fp_violation": 0.017411011932678105,
            "ave_precision_score": 0.557153600727318,
            "fpr": 0.3973655323819978,
            "logloss": 13.747295324386346,
            "mae": 0.4199192266931462,
            "precision": 0.557997557997558,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8221374454163337,
            "auditor_fn_violation": 0.006975158484446411,
            "auditor_fp_violation": 0.017523740544020613,
            "ave_precision_score": 0.8226769831265717,
            "fpr": 0.16228070175438597,
            "logloss": 0.7743911474646108,
            "mae": 0.27855709776807824,
            "precision": 0.7238805970149254,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.830410273759997,
            "auditor_fn_violation": 0.01153727799236666,
            "auditor_fp_violation": 0.021046333876688056,
            "ave_precision_score": 0.8307044185658085,
            "fpr": 0.16465422612513722,
            "logloss": 0.7575837896841696,
            "mae": 0.28285694466312106,
            "precision": 0.7169811320754716,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7859707980569866,
            "auditor_fn_violation": 0.013286893704850361,
            "auditor_fp_violation": 0.01406828424271688,
            "ave_precision_score": 0.7824443975103146,
            "fpr": 0.15899122807017543,
            "logloss": 2.070376810317012,
            "mae": 0.30089869215924425,
            "precision": 0.7070707070707071,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.799365244507948,
            "auditor_fn_violation": 0.014876291169297617,
            "auditor_fp_violation": 0.014384112071347627,
            "ave_precision_score": 0.7969410260930565,
            "fpr": 0.15148188803512624,
            "logloss": 1.8939602574816334,
            "mae": 0.3001698175431189,
            "precision": 0.7154639175257732,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.46850621144707144,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.01714399243521648,
            "ave_precision_score": 0.5266815613089146,
            "fpr": 0.05592105263157895,
            "logloss": 17.600750589929596,
            "mae": 0.5415920017352491,
            "precision": 0.39285714285714285,
            "recall": 0.06932773109243698
        },
        "train": {
            "accuracy": 0.4226125137211855,
            "auc_prc": 0.38970743419348913,
            "auditor_fn_violation": 0.012825576749077992,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5133431236972281,
            "fpr": 0.0801317233809001,
            "logloss": 18.562241521187683,
            "mae": 0.5760078845641746,
            "precision": 0.25510204081632654,
            "recall": 0.05230125523012552
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7531351402728361,
            "auditor_fn_violation": 0.012708701901813358,
            "auditor_fp_violation": 0.017010703363914383,
            "ave_precision_score": 0.5386011285247282,
            "fpr": 0.42105263157894735,
            "logloss": 14.872669639761074,
            "mae": 0.4574085404914175,
            "precision": 0.535671100362757,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7675000372293238,
            "auditor_fn_violation": 0.012825576749077982,
            "auditor_fp_violation": 0.01824252211234007,
            "ave_precision_score": 0.5595279159629902,
            "fpr": 0.3951701427003293,
            "logloss": 13.870793257757123,
            "mae": 0.4226200827664378,
            "precision": 0.5571955719557196,
            "recall": 0.9476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7782987619174546,
            "auditor_fn_violation": 0.009545923632610942,
            "auditor_fp_violation": 0.018084560598744564,
            "ave_precision_score": 0.7294502596957121,
            "fpr": 0.15899122807017543,
            "logloss": 5.060057553063925,
            "mae": 0.30218369833829123,
            "precision": 0.7028688524590164,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7718418090719442,
            "auditor_fn_violation": 0.01562263180375605,
            "auditor_fp_violation": 0.022075581233220863,
            "ave_precision_score": 0.7211236137587116,
            "fpr": 0.17014270032930845,
            "logloss": 5.132673185787656,
            "mae": 0.3166920322243517,
            "precision": 0.6887550200803213,
            "recall": 0.7175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7810917354848217,
            "auditor_fn_violation": 0.010762199616688782,
            "auditor_fp_violation": 0.019565829711894422,
            "ave_precision_score": 0.7349917575017864,
            "fpr": 0.15021929824561403,
            "logloss": 4.9438942880604335,
            "mae": 0.29805513602838063,
            "precision": 0.7133891213389121,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7733439190380428,
            "auditor_fn_violation": 0.01812803990281497,
            "auditor_fp_violation": 0.020947465288252646,
            "ave_precision_score": 0.7253844261577811,
            "fpr": 0.16136114160263446,
            "logloss": 5.037448241119714,
            "mae": 0.3149544056815123,
            "precision": 0.6975308641975309,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7524746796480489,
            "auditor_fn_violation": 0.007438172637476043,
            "auditor_fp_violation": 0.017727446483180424,
            "ave_precision_score": 0.5370287079785884,
            "fpr": 0.42214912280701755,
            "logloss": 14.633163356615855,
            "mae": 0.4515998230902478,
            "precision": 0.5383693045563549,
            "recall": 0.9432773109243697
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7669708925261971,
            "auditor_fn_violation": 0.009266106030891614,
            "auditor_fp_violation": 0.017411011932678105,
            "ave_precision_score": 0.5571621587706129,
            "fpr": 0.3973655323819978,
            "logloss": 13.738770417259392,
            "mae": 0.4188443044884136,
            "precision": 0.559074299634592,
            "recall": 0.9602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7783328349742373,
            "auditor_fn_violation": 0.011794191360754845,
            "auditor_fp_violation": 0.003913165942378888,
            "ave_precision_score": 0.7589750979702514,
            "fpr": 0.07456140350877193,
            "logloss": 3.7150438302195354,
            "mae": 0.3507141126467355,
            "precision": 0.7622377622377622,
            "recall": 0.4579831932773109
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7757815671725772,
            "auditor_fn_violation": 0.020318836719040646,
            "auditor_fp_violation": 0.01218618729766797,
            "ave_precision_score": 0.7535648476881724,
            "fpr": 0.07574094401756312,
            "logloss": 3.709222079728957,
            "mae": 0.35777441939093935,
            "precision": 0.7553191489361702,
            "recall": 0.4456066945606695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7522318353072031,
            "auditor_fn_violation": 0.009914492112634529,
            "auditor_fp_violation": 0.017727446483180424,
            "ave_precision_score": 0.5364833510577629,
            "fpr": 0.42214912280701755,
            "logloss": 14.647148035991226,
            "mae": 0.45123235015291213,
            "precision": 0.5389221556886228,
            "recall": 0.9453781512605042
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7669542885344768,
            "auditor_fn_violation": 0.009266106030891614,
            "auditor_fp_violation": 0.017411011932678105,
            "ave_precision_score": 0.5571455568286034,
            "fpr": 0.3973655323819978,
            "logloss": 13.73754425516173,
            "mae": 0.41869953775465635,
            "precision": 0.559074299634592,
            "recall": 0.9602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8515532854088996,
            "auditor_fn_violation": 0.006210378888397465,
            "auditor_fp_violation": 0.009969016578142604,
            "ave_precision_score": 0.8158234845679712,
            "fpr": 0.09758771929824561,
            "logloss": 4.536261615930894,
            "mae": 0.2511503592078616,
            "precision": 0.7915690866510539,
            "recall": 0.7100840336134454
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8557426584193554,
            "auditor_fn_violation": 0.0035456921218579075,
            "auditor_fp_violation": 0.01503816581022808,
            "ave_precision_score": 0.8293011136229995,
            "fpr": 0.10867178924259056,
            "logloss": 4.437998299309835,
            "mae": 0.26156106048155014,
            "precision": 0.7744874715261959,
            "recall": 0.7112970711297071
        }
    }
]