[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7566230664383802,
            "auditor_fn_violation": 0.011608847580964735,
            "auditor_fp_violation": 0.010510835913312703,
            "ave_precision_score": 0.7157503786797306,
            "fpr": 0.25,
            "logloss": 3.989725990651348,
            "mae": 0.3144774226733851,
            "precision": 0.6555891238670695,
            "recall": 0.891170431211499
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.783221738548235,
            "auditor_fn_violation": 0.016178658649811845,
            "auditor_fp_violation": 0.02115287625715728,
            "ave_precision_score": 0.7483011503742268,
            "fpr": 0.23380900109769484,
            "logloss": 3.4084047219470346,
            "mae": 0.3002167151562582,
            "precision": 0.660828025477707,
            "recall": 0.8886509635974305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7966900782629343,
            "auditor_fn_violation": 0.008121239958211755,
            "auditor_fp_violation": 0.013937048503611972,
            "ave_precision_score": 0.7634658879029846,
            "fpr": 0.12828947368421054,
            "logloss": 3.5632549135700713,
            "mae": 0.2775390936895995,
            "precision": 0.7602459016393442,
            "recall": 0.7618069815195072
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7799241361651176,
            "auditor_fn_violation": 0.007498172467368852,
            "auditor_fp_violation": 0.02017385112884564,
            "ave_precision_score": 0.7417119997793636,
            "fpr": 0.13830954994511527,
            "logloss": 3.8240774059141285,
            "mae": 0.27907680201821106,
            "precision": 0.7375,
            "recall": 0.7580299785867237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8495630025150176,
            "auditor_fn_violation": 0.0033345041247883605,
            "auditor_fp_violation": 0.00646542827657379,
            "ave_precision_score": 0.8499359271927516,
            "fpr": 0.14692982456140352,
            "logloss": 0.49766262701287883,
            "mae": 0.3238051839360738,
            "precision": 0.7545787545787546,
            "recall": 0.8459958932238193
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8556492542820496,
            "auditor_fn_violation": 0.008358464355474488,
            "auditor_fp_violation": 0.010878056981240294,
            "ave_precision_score": 0.8559074267945982,
            "fpr": 0.145993413830955,
            "logloss": 0.49233702939694146,
            "mae": 0.3223581699425463,
            "precision": 0.7432432432432432,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7871776398366064,
            "auditor_fn_violation": 0.01193531827515401,
            "auditor_fp_violation": 0.0013467492260061972,
            "ave_precision_score": 0.7125989755301559,
            "fpr": 0.19956140350877194,
            "logloss": 5.410498854677366,
            "mae": 0.28697951521314574,
            "precision": 0.6956521739130435,
            "recall": 0.8542094455852156
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7847368909753935,
            "auditor_fn_violation": 0.007789637478639611,
            "auditor_fp_violation": 0.02366471850555276,
            "ave_precision_score": 0.7094995728571932,
            "fpr": 0.19209659714599342,
            "logloss": 5.536750406964981,
            "mae": 0.2843868234756027,
            "precision": 0.6897163120567376,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5023199453041304,
            "auditor_fn_violation": 0.013187164523217701,
            "auditor_fp_violation": 0.0023761609907120753,
            "ave_precision_score": 0.500361597838364,
            "fpr": 0.20723684210526316,
            "logloss": 4.789121952613228,
            "mae": 0.4805475743404248,
            "precision": 0.591792656587473,
            "recall": 0.5626283367556468
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.47674147047094934,
            "auditor_fn_violation": 0.02076218100447306,
            "auditor_fp_violation": 0.015802850050929095,
            "ave_precision_score": 0.4700140016989098,
            "fpr": 0.21953896816684962,
            "logloss": 5.431641507219794,
            "mae": 0.487547896685765,
            "precision": 0.5555555555555556,
            "recall": 0.5353319057815846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8345732440066672,
            "auditor_fn_violation": 0.00713732483158615,
            "auditor_fp_violation": 0.021465428276573797,
            "ave_precision_score": 0.8348092175397894,
            "fpr": 0.20065789473684212,
            "logloss": 1.026946351746287,
            "mae": 0.27267236271296097,
            "precision": 0.7024390243902439,
            "recall": 0.8870636550308009
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8272108416104438,
            "auditor_fn_violation": 0.0030956404826096473,
            "auditor_fp_violation": 0.021862422246615443,
            "ave_precision_score": 0.8272272105970544,
            "fpr": 0.2030735455543359,
            "logloss": 1.0834908731348605,
            "mae": 0.2798962329652105,
            "precision": 0.685374149659864,
            "recall": 0.8629550321199143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8489500057734513,
            "auditor_fn_violation": 0.008621077848625673,
            "auditor_fp_violation": 0.02044633642930857,
            "ave_precision_score": 0.8423003089596665,
            "fpr": 0.16447368421052633,
            "logloss": 1.9629537664797287,
            "mae": 0.2761241679639819,
            "precision": 0.7242647058823529,
            "recall": 0.8090349075975359
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8385078433406826,
            "auditor_fn_violation": 0.0065626638021610735,
            "auditor_fp_violation": 0.010442934701990692,
            "ave_precision_score": 0.8335048593923038,
            "fpr": 0.15477497255762898,
            "logloss": 1.8967864705100022,
            "mae": 0.2711231413588708,
            "precision": 0.7283236994219653,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7827615266693573,
            "auditor_fn_violation": 0.020396538059728377,
            "auditor_fp_violation": 0.02083075335397317,
            "ave_precision_score": 0.7574532043242124,
            "fpr": 0.09649122807017543,
            "logloss": 4.052464157991997,
            "mae": 0.2916022941528036,
            "precision": 0.7889688249400479,
            "recall": 0.675564681724846
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7800837756060948,
            "auditor_fn_violation": 0.01697313585795312,
            "auditor_fp_violation": 0.022124484528436236,
            "ave_precision_score": 0.7552340616175952,
            "fpr": 0.10428100987925357,
            "logloss": 3.6312722759506704,
            "mae": 0.2847494925211439,
            "precision": 0.7705314009661836,
            "recall": 0.683083511777302
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8276976922629758,
            "auditor_fn_violation": 0.012320328542094455,
            "auditor_fp_violation": 0.025892672858617127,
            "ave_precision_score": 0.8281187661259437,
            "fpr": 0.2149122807017544,
            "logloss": 0.8986695293417986,
            "mae": 0.2889792221971367,
            "precision": 0.6853932584269663,
            "recall": 0.8767967145790554
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8119609778910184,
            "auditor_fn_violation": 0.005248720727158193,
            "auditor_fp_violation": 0.0247574687750319,
            "ave_precision_score": 0.8123552312499341,
            "fpr": 0.21734357848518113,
            "logloss": 0.9640865411519113,
            "mae": 0.2909502474126242,
            "precision": 0.6743421052631579,
            "recall": 0.8779443254817987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.848757951918564,
            "auditor_fn_violation": 0.006583450412478837,
            "auditor_fp_violation": 0.023320433436532513,
            "ave_precision_score": 0.8487797291440033,
            "fpr": 0.29714912280701755,
            "logloss": 1.3683859071562972,
            "mae": 0.3221746996254408,
            "precision": 0.6317934782608695,
            "recall": 0.9548254620123203
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.8366765875376241,
            "auditor_fn_violation": 0.004788017967407631,
            "auditor_fp_violation": 0.022215959098505763,
            "ave_precision_score": 0.8365714710608363,
            "fpr": 0.300768386388584,
            "logloss": 1.404617020682035,
            "mae": 0.3290127990676722,
            "precision": 0.6167832167832168,
            "recall": 0.9443254817987152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.8736244746658611,
            "auditor_fn_violation": 0.0031723945387081673,
            "auditor_fp_violation": 0.01710526315789473,
            "ave_precision_score": 0.8739866144130023,
            "fpr": 0.3782894736842105,
            "logloss": 1.6060844913409322,
            "mae": 0.3777164504490588,
            "precision": 0.5802919708029197,
            "recall": 0.9794661190965093
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.870555532406587,
            "auditor_fn_violation": 0.005084184027247277,
            "auditor_fp_violation": 0.027563513019056383,
            "ave_precision_score": 0.8707424990414464,
            "fpr": 0.3896816684961581,
            "logloss": 1.6463083009738881,
            "mae": 0.39007018564593726,
            "precision": 0.5617283950617284,
            "recall": 0.974304068522484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7976008550484377,
            "auditor_fn_violation": 0.020500108073057393,
            "auditor_fp_violation": 0.02016511867905057,
            "ave_precision_score": 0.7891800343805246,
            "fpr": 0.13596491228070176,
            "logloss": 1.6577426638571149,
            "mae": 0.27447014955743493,
            "precision": 0.7494949494949495,
            "recall": 0.7618069815195072
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7881427913690422,
            "auditor_fn_violation": 0.009420901332042115,
            "auditor_fp_violation": 0.02171655739163973,
            "ave_precision_score": 0.7774499063049589,
            "fpr": 0.14489571899012074,
            "logloss": 1.8472504186465373,
            "mae": 0.2727368524017522,
            "precision": 0.7327935222672065,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8407684596278298,
            "auditor_fn_violation": 0.01720613134478908,
            "auditor_fp_violation": 0.017141382868937047,
            "ave_precision_score": 0.8414745683499034,
            "fpr": 0.14144736842105263,
            "logloss": 0.7099460585586642,
            "mae": 0.27336807411184216,
            "precision": 0.7470588235294118,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8337349728090374,
            "auditor_fn_violation": 0.006579117472152167,
            "auditor_fp_violation": 0.023504019936511703,
            "ave_precision_score": 0.8340381578997172,
            "fpr": 0.14818880351262348,
            "logloss": 0.7319544902144577,
            "mae": 0.2714105009113673,
            "precision": 0.731610337972167,
            "recall": 0.7880085653104925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8569434181806451,
            "auditor_fn_violation": 0.0014252134442883403,
            "auditor_fp_violation": 0.00923374613003096,
            "ave_precision_score": 0.8572542102717329,
            "fpr": 0.09758771929824561,
            "logloss": 0.4838815824631695,
            "mae": 0.3166082807951362,
            "precision": 0.806941431670282,
            "recall": 0.7638603696098563
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8653655329470946,
            "auditor_fn_violation": 0.009427952904895438,
            "auditor_fp_violation": 0.009508410715875042,
            "ave_precision_score": 0.865572831625552,
            "fpr": 0.09879253567508232,
            "logloss": 0.47525604989323955,
            "mae": 0.31205317179409686,
            "precision": 0.7972972972972973,
            "recall": 0.7580299785867237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.828578108485726,
            "auditor_fn_violation": 0.005793166180337909,
            "auditor_fp_violation": 0.007262641898864817,
            "ave_precision_score": 0.8289931271246822,
            "fpr": 0.3618421052631579,
            "logloss": 1.9730417117468344,
            "mae": 0.37692015812623986,
            "precision": 0.5880149812734082,
            "recall": 0.9671457905544147
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.8225836504978739,
            "auditor_fn_violation": 0.003986489186413029,
            "auditor_fp_violation": 0.008628277014665599,
            "ave_precision_score": 0.8224017940116306,
            "fpr": 0.38748627881448955,
            "logloss": 1.9977094670618476,
            "mae": 0.3927945905221463,
            "precision": 0.5641975308641975,
            "recall": 0.9785867237687366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7848359713363595,
            "auditor_fn_violation": 0.018667369141539682,
            "auditor_fp_violation": 0.02670278637770898,
            "ave_precision_score": 0.7522368715757226,
            "fpr": 0.15460526315789475,
            "logloss": 4.272060557339562,
            "mae": 0.2910767999183876,
            "precision": 0.7235294117647059,
            "recall": 0.757700205338809
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7750255850568648,
            "auditor_fn_violation": 0.017553715356210208,
            "auditor_fp_violation": 0.033909870353339075,
            "ave_precision_score": 0.7414363594652539,
            "fpr": 0.16136114160263446,
            "logloss": 3.9663969071965055,
            "mae": 0.28727107230316506,
            "precision": 0.7134502923976608,
            "recall": 0.7837259100642399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7526278857775942,
            "auditor_fn_violation": 0.010021524550596201,
            "auditor_fp_violation": 0.00937822497420021,
            "ave_precision_score": 0.6969950478416652,
            "fpr": 0.2532894736842105,
            "logloss": 4.5988644431289725,
            "mae": 0.31723993773700376,
            "precision": 0.6515837104072398,
            "recall": 0.8870636550308009
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7694631930027618,
            "auditor_fn_violation": 0.016890867507997658,
            "auditor_fp_violation": 0.022594218807171603,
            "ave_precision_score": 0.7178577860366482,
            "fpr": 0.23600439077936333,
            "logloss": 4.065329865609951,
            "mae": 0.30188537523790326,
            "precision": 0.6581875993640699,
            "recall": 0.8865096359743041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8376982745983161,
            "auditor_fn_violation": 0.020504611117115174,
            "auditor_fp_violation": 0.016852425180598558,
            "ave_precision_score": 0.8382285927282702,
            "fpr": 0.08662280701754387,
            "logloss": 0.6146504245409048,
            "mae": 0.3228927120437458,
            "precision": 0.8073170731707318,
            "recall": 0.6796714579055442
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8404706239260522,
            "auditor_fn_violation": 0.02036259187611798,
            "auditor_fp_violation": 0.009434242145548402,
            "ave_precision_score": 0.8407004277016334,
            "fpr": 0.07683863885839737,
            "logloss": 0.5908324891384981,
            "mae": 0.31373853341896046,
            "precision": 0.8162729658792651,
            "recall": 0.6659528907922913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7734710333297401,
            "auditor_fn_violation": 0.009046615512086171,
            "auditor_fp_violation": 0.01152992776057792,
            "ave_precision_score": 0.7201766669777727,
            "fpr": 0.2543859649122807,
            "logloss": 3.801157963824799,
            "mae": 0.31168146248535933,
            "precision": 0.6573116691285081,
            "recall": 0.9137577002053389
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7637628509292467,
            "auditor_fn_violation": 0.006518003840756682,
            "auditor_fp_violation": 0.011807636396000827,
            "ave_precision_score": 0.71136911563861,
            "fpr": 0.27661909989023054,
            "logloss": 3.764576372923222,
            "mae": 0.3325414278293562,
            "precision": 0.6266666666666667,
            "recall": 0.9057815845824411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8366837418234792,
            "auditor_fn_violation": 0.016071364242227753,
            "auditor_fp_violation": 0.02112745098039216,
            "ave_precision_score": 0.8368938315150769,
            "fpr": 0.13267543859649122,
            "logloss": 0.7756374027043929,
            "mae": 0.27029049280557865,
            "precision": 0.7565392354124748,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8253307450462413,
            "auditor_fn_violation": 0.00622653882948592,
            "auditor_fp_violation": 0.018893207147872355,
            "ave_precision_score": 0.8256930898529825,
            "fpr": 0.1394072447859495,
            "logloss": 0.7959484147819708,
            "mae": 0.26890371252812595,
            "precision": 0.741869918699187,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8393170965499674,
            "auditor_fn_violation": 0.02316140711120718,
            "auditor_fp_violation": 0.01594169246646027,
            "ave_precision_score": 0.8395738011114349,
            "fpr": 0.11074561403508772,
            "logloss": 0.8478807217404899,
            "mae": 0.26793687889468043,
            "precision": 0.7775330396475771,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8276253355711873,
            "auditor_fn_violation": 0.01830823365151598,
            "auditor_fp_violation": 0.024255594782488312,
            "ave_precision_score": 0.8280906216405594,
            "fpr": 0.12623490669593854,
            "logloss": 0.9012334837707477,
            "mae": 0.27374010266173626,
            "precision": 0.7466960352422908,
            "recall": 0.7259100642398287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8274661119279523,
            "auditor_fn_violation": 0.004872293670521274,
            "auditor_fp_violation": 0.01629772961816306,
            "ave_precision_score": 0.828101699784567,
            "fpr": 0.15679824561403508,
            "logloss": 0.9334757316502378,
            "mae": 0.26477634923662974,
            "precision": 0.7409420289855072,
            "recall": 0.839835728952772
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8198903299908311,
            "auditor_fn_violation": 0.008786259775242871,
            "auditor_fp_violation": 0.02174869710544793,
            "ave_precision_score": 0.8201147775685583,
            "fpr": 0.17014270032930845,
            "logloss": 0.9977094388086086,
            "mae": 0.2762439727552123,
            "precision": 0.7134935304990758,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8567550124906315,
            "auditor_fn_violation": 0.010692478115205881,
            "auditor_fp_violation": 0.011320949432404541,
            "ave_precision_score": 0.8572725284560322,
            "fpr": 0.12171052631578948,
            "logloss": 0.7578398806544452,
            "mae": 0.25118957131991204,
            "precision": 0.7766599597585513,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8493327608680326,
            "auditor_fn_violation": 0.009578386459099706,
            "auditor_fp_violation": 0.013330564373374479,
            "ave_precision_score": 0.8495796911424822,
            "fpr": 0.12733260153677278,
            "logloss": 0.7962236983885717,
            "mae": 0.25484580550878105,
            "precision": 0.7603305785123967,
            "recall": 0.7880085653104925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6769175670120304,
            "auditor_fn_violation": 0.012959760798299655,
            "auditor_fp_violation": 0.031710526315789474,
            "ave_precision_score": 0.6110625579313725,
            "fpr": 0.3168859649122807,
            "logloss": 7.0256286492333855,
            "mae": 0.3972843675213124,
            "precision": 0.5877318116975749,
            "recall": 0.8459958932238193
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6591018831080617,
            "auditor_fn_violation": 0.024396091548219836,
            "auditor_fp_violation": 0.03732162458836445,
            "ave_precision_score": 0.5845314509907282,
            "fpr": 0.32930845225027444,
            "logloss": 7.243520224410167,
            "mae": 0.40830680007816983,
            "precision": 0.5732574679943101,
            "recall": 0.8629550321199143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8571110371051135,
            "auditor_fn_violation": 0.02109225836665586,
            "auditor_fp_violation": 0.013157894736842108,
            "ave_precision_score": 0.856361537503363,
            "fpr": 0.08223684210526316,
            "logloss": 0.8373229616009898,
            "mae": 0.26352815007736263,
            "precision": 0.8197115384615384,
            "recall": 0.7002053388090349
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8526397774040289,
            "auditor_fn_violation": 0.00799883413995492,
            "auditor_fp_violation": 0.01037371070301916,
            "ave_precision_score": 0.8509754389905231,
            "fpr": 0.0867178924259056,
            "logloss": 0.828013197189654,
            "mae": 0.2549558465883632,
            "precision": 0.8068459657701712,
            "recall": 0.7066381156316917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8601842112497022,
            "auditor_fn_violation": 0.009440631867142191,
            "auditor_fp_violation": 0.021349329205366356,
            "ave_precision_score": 0.8604153035504438,
            "fpr": 0.16447368421052633,
            "logloss": 0.5164431013436342,
            "mae": 0.32107192188452344,
            "precision": 0.7391304347826086,
            "recall": 0.8726899383983573
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8677648044004906,
            "auditor_fn_violation": 0.007592193438746516,
            "auditor_fp_violation": 0.015434479484973448,
            "ave_precision_score": 0.8679504265441426,
            "fpr": 0.16794731064763996,
            "logloss": 0.5025242601693898,
            "mae": 0.31833870938757247,
            "precision": 0.725314183123878,
            "recall": 0.8650963597430407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8492744715114551,
            "auditor_fn_violation": 0.012860693829028422,
            "auditor_fp_violation": 0.020381836945304443,
            "ave_precision_score": 0.8499707280702418,
            "fpr": 0.13157894736842105,
            "logloss": 0.6825236490687598,
            "mae": 0.2671335832413082,
            "precision": 0.7585513078470825,
            "recall": 0.7741273100616016
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8422443753893177,
            "auditor_fn_violation": 0.005805794982570865,
            "auditor_fp_violation": 0.019357996855252625,
            "ave_precision_score": 0.8425532618524723,
            "fpr": 0.13721185510428102,
            "logloss": 0.6931191493700407,
            "mae": 0.2655372816344489,
            "precision": 0.7474747474747475,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7374979998553122,
            "auditor_fn_violation": 0.006533916927843221,
            "auditor_fp_violation": 0.01604747162022705,
            "ave_precision_score": 0.6644206389683482,
            "fpr": 0.3366228070175439,
            "logloss": 5.325093591839927,
            "mae": 0.3599294478511535,
            "precision": 0.5992167101827677,
            "recall": 0.9425051334702259
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.741447546541727,
            "auditor_fn_violation": 0.008132814024168093,
            "auditor_fp_violation": 0.01719721917306989,
            "ave_precision_score": 0.6725260278883336,
            "fpr": 0.3336992316136114,
            "logloss": 4.970526864211577,
            "mae": 0.36944760114733155,
            "precision": 0.5891891891891892,
            "recall": 0.9336188436830836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.837866925614136,
            "auditor_fn_violation": 0.006259231240318454,
            "auditor_fp_violation": 0.022074303405572766,
            "ave_precision_score": 0.8380746912237376,
            "fpr": 0.1962719298245614,
            "logloss": 0.9802840889573552,
            "mae": 0.27046715664974774,
            "precision": 0.7060755336617406,
            "recall": 0.8829568788501027
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8291317384962822,
            "auditor_fn_violation": 0.005963280109628455,
            "auditor_fp_violation": 0.023630106506066985,
            "ave_precision_score": 0.8292839617217299,
            "fpr": 0.20417124039517015,
            "logloss": 1.0423642756153215,
            "mae": 0.27783376800041004,
            "precision": 0.6863406408094435,
            "recall": 0.8715203426124197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7801809042466457,
            "auditor_fn_violation": 0.012124446125580897,
            "auditor_fp_violation": 0.0015479876160990754,
            "ave_precision_score": 0.7340975160595545,
            "fpr": 0.17543859649122806,
            "logloss": 4.170005195144473,
            "mae": 0.2819974914816061,
            "precision": 0.7122302158273381,
            "recall": 0.813141683778234
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7916298322184961,
            "auditor_fn_violation": 0.008964899620860434,
            "auditor_fp_violation": 0.02500469734278736,
            "ave_precision_score": 0.7487617696823988,
            "fpr": 0.16575192096597147,
            "logloss": 3.83086931823514,
            "mae": 0.2689988922984823,
            "precision": 0.7150943396226415,
            "recall": 0.8115631691648822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7691356928322441,
            "auditor_fn_violation": 0.016003818581361004,
            "auditor_fp_violation": 0.00866615067079463,
            "ave_precision_score": 0.7085553747963204,
            "fpr": 0.24342105263157895,
            "logloss": 4.261252623339821,
            "mae": 0.30713791887391345,
            "precision": 0.6610687022900763,
            "recall": 0.8891170431211499
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7670674390802386,
            "auditor_fn_violation": 0.01507391223612427,
            "auditor_fp_violation": 0.02775882358758319,
            "ave_precision_score": 0.7081904922454547,
            "fpr": 0.23929747530186607,
            "logloss": 4.22510993861517,
            "mae": 0.30634443225031116,
            "precision": 0.6517571884984026,
            "recall": 0.8736616702355461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6657213282492342,
            "auditor_fn_violation": 0.004363449691991788,
            "auditor_fp_violation": 0.001181630546955625,
            "ave_precision_score": 0.6595348206415604,
            "fpr": 0.38596491228070173,
            "logloss": 3.248089064181694,
            "mae": 0.3933998127842699,
            "precision": 0.5748792270531401,
            "recall": 0.9774127310061602
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.657739484375639,
            "auditor_fn_violation": 0.0029287532584142888,
            "auditor_fp_violation": 0.014069777790963306,
            "ave_precision_score": 0.6511710491641074,
            "fpr": 0.4094401756311745,
            "logloss": 3.2708330326185444,
            "mae": 0.4125648471662357,
            "precision": 0.5506024096385542,
            "recall": 0.9785867237687366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7540224081993214,
            "auditor_fn_violation": 0.013295237580604491,
            "auditor_fp_violation": 0.005580495356037165,
            "ave_precision_score": 0.7226593531367869,
            "fpr": 0.20394736842105263,
            "logloss": 3.3798215398146487,
            "mae": 0.2984405486893061,
            "precision": 0.6868686868686869,
            "recall": 0.837782340862423
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7737280686071527,
            "auditor_fn_violation": 0.0182306663501294,
            "auditor_fp_violation": 0.021716557391639718,
            "ave_precision_score": 0.7482555787387108,
            "fpr": 0.20087815587266739,
            "logloss": 2.8910744007015823,
            "mae": 0.2882406980707028,
            "precision": 0.6800699300699301,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8617881375389083,
            "auditor_fn_violation": 0.013308746712777838,
            "auditor_fp_violation": 0.009938080495356041,
            "ave_precision_score": 0.862054846591658,
            "fpr": 0.11951754385964912,
            "logloss": 0.6642255781522746,
            "mae": 0.25256748923305516,
            "precision": 0.780241935483871,
            "recall": 0.7946611909650924
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8541094482831565,
            "auditor_fn_violation": 0.0067083963077964595,
            "auditor_fp_violation": 0.015877018621255727,
            "ave_precision_score": 0.8543818835946498,
            "fpr": 0.12403951701427003,
            "logloss": 0.6650084131774524,
            "mae": 0.25129548320357786,
            "precision": 0.7670103092783506,
            "recall": 0.7965738758029979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7996074767423735,
            "auditor_fn_violation": 0.009114161172952915,
            "auditor_fp_violation": 0.013771929824561407,
            "ave_precision_score": 0.7998962787846929,
            "fpr": 0.24232456140350878,
            "logloss": 1.0562679575339848,
            "mae": 0.3037259793391125,
            "precision": 0.661042944785276,
            "recall": 0.8850102669404517
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7811331801390193,
            "auditor_fn_violation": 0.006153672576668229,
            "auditor_fp_violation": 0.011303290117779696,
            "ave_precision_score": 0.780768631741002,
            "fpr": 0.23710208562019758,
            "logloss": 1.182981649667731,
            "mae": 0.3072591962294055,
            "precision": 0.6571428571428571,
            "recall": 0.8865096359743041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 5740,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8365962848293227,
            "auditor_fn_violation": 0.019971000396267882,
            "auditor_fp_violation": 0.01970846233230135,
            "ave_precision_score": 0.8369773669870828,
            "fpr": 0.13596491228070176,
            "logloss": 0.7797845714292677,
            "mae": 0.27010089821718203,
            "precision": 0.7524950099800399,
            "recall": 0.7741273100616016
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8258639973285258,
            "auditor_fn_violation": 0.006931696114818412,
            "auditor_fp_violation": 0.019773340849081805,
            "ave_precision_score": 0.8262195094968479,
            "fpr": 0.141602634467618,
            "logloss": 0.8004246250049871,
            "mae": 0.268649013630196,
            "precision": 0.7399193548387096,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 5740,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8374088755655875,
            "auditor_fn_violation": 0.018514265643575056,
            "auditor_fp_violation": 0.01975490196078432,
            "ave_precision_score": 0.8377228635872526,
            "fpr": 0.13486842105263158,
            "logloss": 0.8062969468073706,
            "mae": 0.27059674652373267,
            "precision": 0.7535070140280561,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8259098416735677,
            "auditor_fn_violation": 0.008438382181145504,
            "auditor_fp_violation": 0.01981289741992267,
            "ave_precision_score": 0.82624785720285,
            "fpr": 0.14270032930845225,
            "logloss": 0.8144368759475249,
            "mae": 0.26959019173572635,
            "precision": 0.7363083164300203,
            "recall": 0.7773019271948608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 5740,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8339839922698599,
            "auditor_fn_violation": 0.0069639576353615045,
            "auditor_fp_violation": 0.019894220846233227,
            "ave_precision_score": 0.8339162054255778,
            "fpr": 0.2598684210526316,
            "logloss": 1.2485261083157717,
            "mae": 0.2948154569452277,
            "precision": 0.658008658008658,
            "recall": 0.9363449691991786
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8314578560811973,
            "auditor_fn_violation": 0.006165425198090435,
            "auditor_fp_violation": 0.0249206396297505,
            "ave_precision_score": 0.8311272762706595,
            "fpr": 0.2535675082327113,
            "logloss": 1.2936883482716723,
            "mae": 0.3042441405925437,
            "precision": 0.6484018264840182,
            "recall": 0.9122055674518201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 5740,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7564759728225597,
            "auditor_fn_violation": 0.005941766634244754,
            "auditor_fp_violation": 0.005242518059855528,
            "ave_precision_score": 0.6945749690868974,
            "fpr": 0.22149122807017543,
            "logloss": 4.675336248771726,
            "mae": 0.30602782665695016,
            "precision": 0.6757624398073836,
            "recall": 0.864476386036961
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7746586024900877,
            "auditor_fn_violation": 0.010821813805569333,
            "auditor_fp_violation": 0.02050019283828286,
            "ave_precision_score": 0.7199408248393845,
            "fpr": 0.21075740944017562,
            "logloss": 4.117337905739307,
            "mae": 0.2922350781970646,
            "precision": 0.6751269035532995,
            "recall": 0.854389721627409
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.8449560378120243,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.0017363261093911316,
            "ave_precision_score": 0.7706353800250366,
            "fpr": 0.4594298245614035,
            "logloss": 7.852654629974064,
            "mae": 0.45973496103910616,
            "precision": 0.5370165745856353,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.8319313597805253,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0023733942504524275,
            "ave_precision_score": 0.7466244427070571,
            "fpr": 0.47859495060373214,
            "logloss": 8.312884341795252,
            "mae": 0.4777024464566953,
            "precision": 0.5171650055370985,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.524649387676698,
            "auditor_fn_violation": 0.00958472927699125,
            "auditor_fp_violation": 0.0023348813209494407,
            "ave_precision_score": 0.5226904172700851,
            "fpr": 0.44956140350877194,
            "logloss": 4.754562334056044,
            "mae": 0.5053601211813971,
            "precision": 0.5107398568019093,
            "recall": 0.8788501026694046
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.49295456446964586,
            "auditor_fn_violation": 0.004002942856404124,
            "auditor_fp_violation": 0.002150888539472521,
            "ave_precision_score": 0.4880217314497999,
            "fpr": 0.4676180021953897,
            "logloss": 5.304347937247175,
            "mae": 0.5257202581723793,
            "precision": 0.48612786489746684,
            "recall": 0.8629550321199143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8592668821336369,
            "auditor_fn_violation": 0.0132659677942289,
            "auditor_fp_violation": 0.02441692466460269,
            "ave_precision_score": 0.8595718554756697,
            "fpr": 0.2324561403508772,
            "logloss": 0.7458508977886851,
            "mae": 0.2868268687480937,
            "precision": 0.6778115501519757,
            "recall": 0.9158110882956879
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.861059137107341,
            "auditor_fn_violation": 0.00801528780994601,
            "auditor_fp_violation": 0.02537059562306544,
            "ave_precision_score": 0.8613118344381455,
            "fpr": 0.22502744237102085,
            "logloss": 0.7507230453389887,
            "mae": 0.28564729133935995,
            "precision": 0.6761453396524486,
            "recall": 0.9164882226980728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6302008538480546,
            "auditor_fn_violation": 0.0006169170359162794,
            "auditor_fp_violation": 0.0017905056759545972,
            "ave_precision_score": 0.6038711350924947,
            "fpr": 0.45723684210526316,
            "logloss": 5.917022153428477,
            "mae": 0.4522296969467278,
            "precision": 0.5382059800664452,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6066449791930583,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.007263575320655465,
            "ave_precision_score": 0.5818159974268713,
            "fpr": 0.4665203073545554,
            "logloss": 6.226949273237944,
            "mae": 0.46611911656004057,
            "precision": 0.523542600896861,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7523916048020038,
            "auditor_fn_violation": 0.015776414856442954,
            "auditor_fp_violation": 0.015180598555211552,
            "ave_precision_score": 0.7055726451826543,
            "fpr": 0.22587719298245615,
            "logloss": 4.163871627914418,
            "mae": 0.3115454330906813,
            "precision": 0.6682769726247987,
            "recall": 0.8521560574948666
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7715046192096268,
            "auditor_fn_violation": 0.012514191290367316,
            "auditor_fp_violation": 0.02413445278428814,
            "ave_precision_score": 0.7292966268017241,
            "fpr": 0.2217343578485181,
            "logloss": 3.6724559473314966,
            "mae": 0.30151836910611923,
            "precision": 0.6622073578595318,
            "recall": 0.8479657387580299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7513065765192698,
            "auditor_fn_violation": 0.006333531467271882,
            "auditor_fp_violation": 0.009602683178534573,
            "ave_precision_score": 0.6911537289671402,
            "fpr": 0.21600877192982457,
            "logloss": 4.689816768386207,
            "mae": 0.30851570671569706,
            "precision": 0.6770491803278689,
            "recall": 0.8480492813141683
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7684367816225721,
            "auditor_fn_violation": 0.010925236874084764,
            "auditor_fp_violation": 0.017288693743139415,
            "ave_precision_score": 0.7152170338243417,
            "fpr": 0.2030735455543359,
            "logloss": 4.082994186494715,
            "mae": 0.2949631607180541,
            "precision": 0.6771378708551483,
            "recall": 0.8308351177730193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8373646775520195,
            "auditor_fn_violation": 0.021441244281134048,
            "auditor_fp_violation": 0.017497420020639847,
            "ave_precision_score": 0.837731994597201,
            "fpr": 0.13815789473684212,
            "logloss": 0.8417917895307474,
            "mae": 0.27241761362250033,
            "precision": 0.748,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8325805213522244,
            "auditor_fn_violation": 0.014103145706649875,
            "auditor_fp_violation": 0.021049040258699983,
            "ave_precision_score": 0.8329139484614868,
            "fpr": 0.141602634467618,
            "logloss": 0.8172482050339651,
            "mae": 0.27038217860513625,
            "precision": 0.7372708757637475,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8046399554352837,
            "auditor_fn_violation": 0.02023442847364819,
            "auditor_fp_violation": 0.02272445820433437,
            "ave_precision_score": 0.8002778771004248,
            "fpr": 0.13596491228070176,
            "logloss": 1.3436269139189347,
            "mae": 0.2740318689933838,
            "precision": 0.751503006012024,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7925909711722579,
            "auditor_fn_violation": 0.009420901332042115,
            "auditor_fp_violation": 0.021081179972508184,
            "ave_precision_score": 0.7865506462994596,
            "fpr": 0.1437980241492865,
            "logloss": 1.4657005253514803,
            "mae": 0.27229428858940735,
            "precision": 0.7342799188640974,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7528538309879629,
            "auditor_fn_violation": 0.00944288338917108,
            "auditor_fp_violation": 0.011184210526315807,
            "ave_precision_score": 0.6655234163930259,
            "fpr": 0.27960526315789475,
            "logloss": 6.044296424591572,
            "mae": 0.32736427133572576,
            "precision": 0.6367521367521367,
            "recall": 0.917864476386037
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7557079062947893,
            "auditor_fn_violation": 0.012457778707540716,
            "auditor_fp_violation": 0.02900485556907074,
            "ave_precision_score": 0.6723028391189678,
            "fpr": 0.2722283205268935,
            "logloss": 5.684031522199529,
            "mae": 0.3298505907361166,
            "precision": 0.6281859070464768,
            "recall": 0.8972162740899358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.834766834455715,
            "auditor_fn_violation": 0.0067973450052235315,
            "auditor_fp_violation": 0.012012383900928804,
            "ave_precision_score": 0.8349514787669778,
            "fpr": 0.3201754385964912,
            "logloss": 1.4397718875018932,
            "mae": 0.3393205073980146,
            "precision": 0.6162943495400789,
            "recall": 0.9630390143737166
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.8267053366092137,
            "auditor_fn_violation": 0.0035257864266624674,
            "auditor_fp_violation": 0.013533291798933979,
            "ave_precision_score": 0.8270061690142397,
            "fpr": 0.33150384193194293,
            "logloss": 1.482198793668228,
            "mae": 0.34955252545593385,
            "precision": 0.5978695073235686,
            "recall": 0.961456102783726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8578802467384785,
            "auditor_fn_violation": 0.0038005691847689095,
            "auditor_fp_violation": 0.015170278637770903,
            "ave_precision_score": 0.8581326221001944,
            "fpr": 0.10416666666666667,
            "logloss": 0.4866399913271786,
            "mae": 0.31833228682118814,
            "precision": 0.8,
            "recall": 0.7802874743326489
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8604761458389444,
            "auditor_fn_violation": 0.004994864104438501,
            "auditor_fp_violation": 0.009538078144005695,
            "ave_precision_score": 0.8607060828009094,
            "fpr": 0.11086717892425905,
            "logloss": 0.47707372578109003,
            "mae": 0.3133611724753869,
            "precision": 0.7799564270152506,
            "recall": 0.7665952890792291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.8610903897022798,
            "auditor_fn_violation": 0.0006394322562051948,
            "auditor_fp_violation": 0.005015479876161003,
            "ave_precision_score": 0.8253316849756583,
            "fpr": 0.45614035087719296,
            "logloss": 5.554870123109528,
            "mae": 0.45284385917853287,
            "precision": 0.5388026607538803,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8460245178335585,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.006353774191315368,
            "ave_precision_score": 0.8055389913485344,
            "fpr": 0.47200878155872666,
            "logloss": 5.790582758055712,
            "mae": 0.4701603267773266,
            "precision": 0.5206243032329989,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7989174428486749,
            "auditor_fn_violation": 0.013029557981195289,
            "auditor_fp_violation": 0.01446852425180599,
            "ave_precision_score": 0.7652950061301804,
            "fpr": 0.12938596491228072,
            "logloss": 3.6502944484321556,
            "mae": 0.27881594255876047,
            "precision": 0.7591836734693878,
            "recall": 0.7638603696098563
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7826900917799691,
            "auditor_fn_violation": 0.004550615014679028,
            "auditor_fp_violation": 0.017273860029074082,
            "ave_precision_score": 0.7432044947977455,
            "fpr": 0.141602634467618,
            "logloss": 3.922970594522302,
            "mae": 0.28099697720659467,
            "precision": 0.7323651452282157,
            "recall": 0.7558886509635975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7499011254326355,
            "auditor_fn_violation": 0.013403310637991283,
            "auditor_fp_violation": 0.012180082559339528,
            "ave_precision_score": 0.6789148783051362,
            "fpr": 0.22149122807017543,
            "logloss": 5.164889326261071,
            "mae": 0.311727868771796,
            "precision": 0.6677631578947368,
            "recall": 0.8336755646817249
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7638597198669503,
            "auditor_fn_violation": 0.013889247996765679,
            "auditor_fp_violation": 0.022277766240444623,
            "ave_precision_score": 0.6981776369175274,
            "fpr": 0.21624588364434688,
            "logloss": 4.678639150704134,
            "mae": 0.30507418983040774,
            "precision": 0.6615120274914089,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.4973649331305493,
            "auditor_fn_violation": 0.012000612413991854,
            "auditor_fp_violation": 0.01647058823529413,
            "ave_precision_score": 0.49443983837295186,
            "fpr": 0.2543859649122807,
            "logloss": 4.848356403380965,
            "mae": 0.4866059973796314,
            "precision": 0.5679702048417132,
            "recall": 0.6262833675564682
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.4708471946629058,
            "auditor_fn_violation": 0.0069340466391028645,
            "auditor_fp_violation": 0.012848468666251335,
            "ave_precision_score": 0.4641133818218186,
            "fpr": 0.2711306256860593,
            "logloss": 5.42856773730804,
            "mae": 0.49978805303188845,
            "precision": 0.5339622641509434,
            "recall": 0.6059957173447538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.8098419724841102,
            "auditor_fn_violation": 0.0010942397060412997,
            "auditor_fp_violation": 0.001818885448916409,
            "ave_precision_score": 0.8107933861861369,
            "fpr": 0.005482456140350877,
            "logloss": 4.788037733676868,
            "mae": 0.5367083952107192,
            "precision": 0.2857142857142857,
            "recall": 0.004106776180698152
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.8255297806815547,
            "auditor_fn_violation": 0.0013609535606917264,
            "auditor_fp_violation": 0.002086609111856094,
            "ave_precision_score": 0.8261561574697974,
            "fpr": 0.007683863885839737,
            "logloss": 4.560289724340592,
            "mae": 0.5088324111036702,
            "precision": 0.5882352941176471,
            "recall": 0.021413276231263382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7574145192984916,
            "auditor_fn_violation": 0.012277549623545518,
            "auditor_fp_violation": 0.005389576883384941,
            "ave_precision_score": 0.6890825726420208,
            "fpr": 0.20942982456140352,
            "logloss": 4.934514923000442,
            "mae": 0.3078446156165612,
            "precision": 0.6795302013422819,
            "recall": 0.8316221765913757
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7643629371324087,
            "auditor_fn_violation": 0.015379480393101686,
            "auditor_fp_violation": 0.01416619693238793,
            "ave_precision_score": 0.6979146247284761,
            "fpr": 0.20417124039517015,
            "logloss": 4.649865365154059,
            "mae": 0.3025677351999704,
            "precision": 0.6731107205623902,
            "recall": 0.8201284796573876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7510237267020807,
            "auditor_fn_violation": 0.016001567059332113,
            "auditor_fp_violation": 0.0018601651186790531,
            "ave_precision_score": 0.707560168606091,
            "fpr": 0.19846491228070176,
            "logloss": 3.977472351193257,
            "mae": 0.3074203065351196,
            "precision": 0.6841186736474695,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7747375785357202,
            "auditor_fn_violation": 0.018804194275533162,
            "auditor_fp_violation": 0.018304803156614355,
            "ave_precision_score": 0.7384272047562306,
            "fpr": 0.18880351262349068,
            "logloss": 3.411307898602166,
            "mae": 0.2934932703959336,
            "precision": 0.6861313868613139,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7953787510085608,
            "auditor_fn_violation": 0.020759033106379915,
            "auditor_fp_violation": 0.020307017543859655,
            "ave_precision_score": 0.7859029674571896,
            "fpr": 0.13048245614035087,
            "logloss": 1.7398208480701425,
            "mae": 0.2751636999194765,
            "precision": 0.7561475409836066,
            "recall": 0.757700205338809
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7865119573185709,
            "auditor_fn_violation": 0.007209057980382528,
            "auditor_fp_violation": 0.01931349571305664,
            "ave_precision_score": 0.7743964020810701,
            "fpr": 0.14050493962678376,
            "logloss": 1.9272804443293678,
            "mae": 0.2733129833656423,
            "precision": 0.7382413087934561,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.754587617497659,
            "auditor_fn_violation": 0.01281791491047949,
            "auditor_fp_violation": 0.011824045407636735,
            "ave_precision_score": 0.7061358520035693,
            "fpr": 0.22587719298245615,
            "logloss": 4.232326972753339,
            "mae": 0.3112903333678025,
            "precision": 0.6661264181523501,
            "recall": 0.8439425051334702
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7707004175986268,
            "auditor_fn_violation": 0.013682401859734815,
            "auditor_fp_violation": 0.022962589373127246,
            "ave_precision_score": 0.7250427627751796,
            "fpr": 0.22063666300768386,
            "logloss": 3.794455682023197,
            "mae": 0.298292335764675,
            "precision": 0.662751677852349,
            "recall": 0.8458244111349036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7503144240927957,
            "auditor_fn_violation": 0.012725602507294934,
            "auditor_fp_violation": 0.008539731682146548,
            "ave_precision_score": 0.6921207704588926,
            "fpr": 0.2324561403508772,
            "logloss": 4.635543309749854,
            "mae": 0.31199356691512803,
            "precision": 0.665086887835703,
            "recall": 0.864476386036961
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7625083244972757,
            "auditor_fn_violation": 0.013017203487237833,
            "auditor_fp_violation": 0.021498996252014922,
            "ave_precision_score": 0.7086398599053821,
            "fpr": 0.2327113062568606,
            "logloss": 4.220227374943903,
            "mae": 0.30625262339739917,
            "precision": 0.6530278232405892,
            "recall": 0.854389721627409
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8559973275236052,
            "auditor_fn_violation": 0.01247793508411687,
            "auditor_fp_violation": 0.019290505675954594,
            "ave_precision_score": 0.8552026173395152,
            "fpr": 0.10635964912280702,
            "logloss": 0.8944524091839606,
            "mae": 0.2676264737335761,
            "precision": 0.7853982300884956,
            "recall": 0.728952772073922
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8496286891735576,
            "auditor_fn_violation": 0.004646986510341138,
            "auditor_fp_violation": 0.018502586010818726,
            "ave_precision_score": 0.8478476113212222,
            "fpr": 0.11086717892425905,
            "logloss": 0.8474348841530936,
            "mae": 0.26116087092021634,
            "precision": 0.7750556792873051,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.8713804524481792,
            "auditor_fn_violation": 0.0025059440181562738,
            "auditor_fp_violation": 0.011803405572755419,
            "ave_precision_score": 0.8719385781706915,
            "fpr": 0.40021929824561403,
            "logloss": 2.0061783134180082,
            "mae": 0.39945427130550615,
            "precision": 0.5690672963400236,
            "recall": 0.9897330595482546
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.8731805111174181,
            "auditor_fn_violation": 0.003673869456582291,
            "auditor_fp_violation": 0.022191236241730212,
            "ave_precision_score": 0.8733628933502335,
            "fpr": 0.4138309549945115,
            "logloss": 2.0362535107206288,
            "mae": 0.41126230809109127,
            "precision": 0.5495818399044206,
            "recall": 0.9850107066381156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8412977704918084,
            "auditor_fn_violation": 0.011642620411398113,
            "auditor_fp_violation": 0.018072755417956658,
            "ave_precision_score": 0.8418349713997599,
            "fpr": 0.1206140350877193,
            "logloss": 0.7588243601101073,
            "mae": 0.27038715811945907,
            "precision": 0.7698744769874477,
            "recall": 0.75564681724846
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8309855096941648,
            "auditor_fn_violation": 0.009378591894922166,
            "auditor_fp_violation": 0.015555621483173623,
            "ave_precision_score": 0.8313237029679154,
            "fpr": 0.12733260153677278,
            "logloss": 0.7759215137074992,
            "mae": 0.26921052396915773,
            "precision": 0.7547568710359408,
            "recall": 0.7644539614561028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8601835036281256,
            "auditor_fn_violation": 0.00142746496631723,
            "auditor_fp_violation": 0.015389576883384937,
            "ave_precision_score": 0.860419632905245,
            "fpr": 0.09100877192982457,
            "logloss": 0.49118875506211596,
            "mae": 0.321651641028247,
            "precision": 0.8134831460674158,
            "recall": 0.7433264887063655
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8533762948183218,
            "auditor_fn_violation": 0.0034858275138269636,
            "auditor_fp_violation": 0.013127836947814997,
            "ave_precision_score": 0.8536943214171513,
            "fpr": 0.09879253567508232,
            "logloss": 0.48551610754876384,
            "mae": 0.31750166645574124,
            "precision": 0.7945205479452054,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8331891664175399,
            "auditor_fn_violation": 0.007371483122590879,
            "auditor_fp_violation": 0.027319401444788442,
            "ave_precision_score": 0.8335146006382743,
            "fpr": 0.1513157894736842,
            "logloss": 0.8047895146420287,
            "mae": 0.2723369191276648,
            "precision": 0.7381404174573055,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8249946935425331,
            "auditor_fn_violation": 0.00608785789670386,
            "auditor_fp_violation": 0.01963983742249385,
            "ave_precision_score": 0.8253563739782841,
            "fpr": 0.15806805708013172,
            "logloss": 0.825247120242873,
            "mae": 0.2716944249906655,
            "precision": 0.7230769230769231,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7188295959163035,
            "auditor_fn_violation": 0.011057224683886308,
            "auditor_fp_violation": 0.015165118679050568,
            "ave_precision_score": 0.7040689180303501,
            "fpr": 0.15570175438596492,
            "logloss": 2.620180229928411,
            "mae": 0.28395704986402936,
            "precision": 0.7305502846299811,
            "recall": 0.7905544147843943
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7430417798519962,
            "auditor_fn_violation": 0.012236829424803202,
            "auditor_fp_violation": 0.016996964033187966,
            "ave_precision_score": 0.7326663836789984,
            "fpr": 0.1437980241492865,
            "logloss": 1.997077850733711,
            "mae": 0.2757479387784727,
            "precision": 0.7326530612244898,
            "recall": 0.7687366167023555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7943103269502605,
            "auditor_fn_violation": 0.007855560358802553,
            "auditor_fp_violation": 0.0071929824561403535,
            "ave_precision_score": 0.755884168494489,
            "fpr": 0.19078947368421054,
            "logloss": 2.9066166522274193,
            "mae": 0.27214330252766117,
            "precision": 0.7109634551495017,
            "recall": 0.8788501026694046
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7841841779097389,
            "auditor_fn_violation": 0.008285598102656801,
            "auditor_fp_violation": 0.012104310677307394,
            "ave_precision_score": 0.7461581327442699,
            "fpr": 0.20197585071350166,
            "logloss": 2.910171374950351,
            "mae": 0.2871954773938116,
            "precision": 0.6854700854700855,
            "recall": 0.8586723768736617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8306497700266966,
            "auditor_fn_violation": 0.0115908354047336,
            "auditor_fp_violation": 0.02071981424148607,
            "ave_precision_score": 0.8309308686933903,
            "fpr": 0.1875,
            "logloss": 0.8640520995493938,
            "mae": 0.28053606706832407,
            "precision": 0.7076923076923077,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8131824332104306,
            "auditor_fn_violation": 0.00878861029952731,
            "auditor_fp_violation": 0.026829244172822654,
            "ave_precision_score": 0.8134905119636224,
            "fpr": 0.19978046103183314,
            "logloss": 0.9161982292109202,
            "mae": 0.2818222672037841,
            "precision": 0.6872852233676976,
            "recall": 0.8565310492505354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8223348564693753,
            "auditor_fn_violation": 0.014243128354767823,
            "auditor_fp_violation": 0.028740970072239438,
            "ave_precision_score": 0.8229035713872216,
            "fpr": 0.22587719298245615,
            "logloss": 0.960006862893572,
            "mae": 0.29179016212027725,
            "precision": 0.6755905511811023,
            "recall": 0.8809034907597536
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8078658565603911,
            "auditor_fn_violation": 0.009733521061872853,
            "auditor_fp_violation": 0.025899664758062126,
            "ave_precision_score": 0.8082428150946142,
            "fpr": 0.2239297475301866,
            "logloss": 1.0317635830030973,
            "mae": 0.29515841918113994,
            "precision": 0.6693679092382496,
            "recall": 0.8843683083511777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8249181789078196,
            "auditor_fn_violation": 0.011228340358082064,
            "auditor_fp_violation": 0.02991228070175438,
            "ave_precision_score": 0.8253205511889812,
            "fpr": 0.2236842105263158,
            "logloss": 0.928869445838701,
            "mae": 0.29199217732296967,
            "precision": 0.6782334384858044,
            "recall": 0.8829568788501027
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8107007488196465,
            "auditor_fn_violation": 0.007462914603102225,
            "auditor_fp_violation": 0.024089951642092152,
            "ave_precision_score": 0.8110696039827701,
            "fpr": 0.2239297475301866,
            "logloss": 0.9992649076666731,
            "mae": 0.29513296015870244,
            "precision": 0.6699029126213593,
            "recall": 0.8865096359743041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 5740,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8346101116256699,
            "auditor_fn_violation": 0.013475359342915813,
            "auditor_fp_violation": 0.020265737874097012,
            "ave_precision_score": 0.8349209905960534,
            "fpr": 0.14692982456140352,
            "logloss": 0.7733404385700681,
            "mae": 0.27343210419768343,
            "precision": 0.7428023032629558,
            "recall": 0.7946611909650924
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8205798581542025,
            "auditor_fn_violation": 0.007230212698942502,
            "auditor_fp_violation": 0.0212221002561288,
            "ave_precision_score": 0.82093992209332,
            "fpr": 0.16245883644346873,
            "logloss": 0.8204458418839775,
            "mae": 0.27479197781701364,
            "precision": 0.7175572519083969,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 5740,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7927001542592251,
            "auditor_fn_violation": 0.002373104218451674,
            "auditor_fp_violation": 0.006189370485036131,
            "ave_precision_score": 0.7522400048818916,
            "fpr": 0.20614035087719298,
            "logloss": 3.001492328959948,
            "mae": 0.27531000821378254,
            "precision": 0.6957928802588996,
            "recall": 0.8829568788501027
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7815843167267398,
            "auditor_fn_violation": 0.007260769514640241,
            "auditor_fp_violation": 0.011948556679621448,
            "ave_precision_score": 0.7407331218899509,
            "fpr": 0.20965971459934138,
            "logloss": 3.0292830282420242,
            "mae": 0.2910538845237056,
            "precision": 0.6795302013422819,
            "recall": 0.867237687366167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7607620242279158,
            "auditor_fn_violation": 0.013202925177419937,
            "auditor_fp_violation": 0.003245614035087718,
            "ave_precision_score": 0.7071414448388107,
            "fpr": 0.24232456140350878,
            "logloss": 4.461121184229862,
            "mae": 0.3217505259509101,
            "precision": 0.656298600311042,
            "recall": 0.86652977412731
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.777039573131054,
            "auditor_fn_violation": 0.012046436957763432,
            "auditor_fp_violation": 0.02650784703474056,
            "ave_precision_score": 0.726795472466196,
            "fpr": 0.23380900109769484,
            "logloss": 4.0400421025489175,
            "mae": 0.3061257612206547,
            "precision": 0.6570048309178744,
            "recall": 0.8736616702355461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8619859194649951,
            "auditor_fn_violation": 0.01885649699196657,
            "auditor_fp_violation": 0.024509803921568638,
            "ave_precision_score": 0.8610983718718992,
            "fpr": 0.19188596491228072,
            "logloss": 0.9198346201548815,
            "mae": 0.2765871540583621,
            "precision": 0.7048903878583473,
            "recall": 0.8583162217659137
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8570290006952743,
            "auditor_fn_violation": 0.008090504587048143,
            "auditor_fp_violation": 0.026065307898458283,
            "ave_precision_score": 0.8552337409491225,
            "fpr": 0.18990120746432493,
            "logloss": 0.8990956395602123,
            "mae": 0.2701106507199766,
            "precision": 0.7027491408934707,
            "recall": 0.8758029978586723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8331195891820575,
            "auditor_fn_violation": 0.00960499297525127,
            "auditor_fp_violation": 0.02900412796697627,
            "ave_precision_score": 0.8334969261189032,
            "fpr": 0.26973684210526316,
            "logloss": 1.2392299948441923,
            "mae": 0.31069845168796667,
            "precision": 0.6495726495726496,
            "recall": 0.9363449691991786
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8226880146130213,
            "auditor_fn_violation": 0.008243288665536848,
            "auditor_fp_violation": 0.025988667042454092,
            "ave_precision_score": 0.8230279532508473,
            "fpr": 0.27661909989023054,
            "logloss": 1.300533927064868,
            "mae": 0.31547490031014835,
            "precision": 0.6310395314787701,
            "recall": 0.9229122055674518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8048683406074975,
            "auditor_fn_violation": 0.009591483843077921,
            "auditor_fp_violation": 0.026101651186790514,
            "ave_precision_score": 0.7719629596863502,
            "fpr": 0.2324561403508772,
            "logloss": 2.277818420331439,
            "mae": 0.2905423675752928,
            "precision": 0.6753445635528331,
            "recall": 0.9055441478439425
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7887650369360226,
            "auditor_fn_violation": 0.0035774979609201835,
            "auditor_fp_violation": 0.021073763115475524,
            "ave_precision_score": 0.7517815865324727,
            "fpr": 0.2327113062568606,
            "logloss": 2.4973678706423232,
            "mae": 0.29683931585677176,
            "precision": 0.6656151419558359,
            "recall": 0.9036402569593148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7024339535289992,
            "auditor_fn_violation": 0.011901545444720631,
            "auditor_fp_violation": 0.016031991744066054,
            "ave_precision_score": 0.6894628670094611,
            "fpr": 0.19298245614035087,
            "logloss": 2.5748038940014357,
            "mae": 0.3030605151434114,
            "precision": 0.6928446771378709,
            "recall": 0.8151950718685832
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7290769670534238,
            "auditor_fn_violation": 0.014714282020604697,
            "auditor_fp_violation": 0.028322504722065652,
            "ave_precision_score": 0.7205677321901673,
            "fpr": 0.18880351262349068,
            "logloss": 1.9689986445821068,
            "mae": 0.2950297496395563,
            "precision": 0.6889692585895117,
            "recall": 0.815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7518224573887531,
            "auditor_fn_violation": 0.01840844410821716,
            "auditor_fp_violation": 0.00018317853457172796,
            "ave_precision_score": 0.7076507018680949,
            "fpr": 0.19298245614035087,
            "logloss": 4.006687609089917,
            "mae": 0.30205313973943515,
            "precision": 0.6901408450704225,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7761115814697592,
            "auditor_fn_violation": 0.01748319962767696,
            "auditor_fp_violation": 0.01999584656006171,
            "ave_precision_score": 0.7375177738995526,
            "fpr": 0.18551042810098792,
            "logloss": 3.4642559187419453,
            "mae": 0.289241840860586,
            "precision": 0.686456400742115,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8354651112339329,
            "auditor_fn_violation": 0.008789942000792536,
            "auditor_fp_violation": 0.019143446852425184,
            "ave_precision_score": 0.8357239086151738,
            "fpr": 0.20833333333333334,
            "logloss": 0.9966968967363672,
            "mae": 0.27491906746557526,
            "precision": 0.6955128205128205,
            "recall": 0.891170431211499
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8290463958198306,
            "auditor_fn_violation": 0.0029052480155698796,
            "auditor_fp_violation": 0.020579305979964605,
            "ave_precision_score": 0.829404401917839,
            "fpr": 0.20636663007683864,
            "logloss": 1.0394692546955426,
            "mae": 0.28266395573218905,
            "precision": 0.6835016835016835,
            "recall": 0.8693790149892934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8417397870009106,
            "auditor_fn_violation": 0.012579253575416983,
            "auditor_fp_violation": 0.001274509803921576,
            "ave_precision_score": 0.8421070797488891,
            "fpr": 0.21271929824561403,
            "logloss": 0.5975492784200541,
            "mae": 0.31589994443939967,
            "precision": 0.680921052631579,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8407690166365803,
            "auditor_fn_violation": 0.007686214410124179,
            "auditor_fp_violation": 0.009392213289029984,
            "ave_precision_score": 0.8410397932788716,
            "fpr": 0.22941822173435786,
            "logloss": 0.5944328868901685,
            "mae": 0.31735726973730927,
            "precision": 0.6579378068739771,
            "recall": 0.860813704496788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8510350839634937,
            "auditor_fn_violation": 0.012655805324399305,
            "auditor_fp_violation": 0.013789989680082564,
            "ave_precision_score": 0.8514176258849291,
            "fpr": 0.1074561403508772,
            "logloss": 0.675422408430071,
            "mae": 0.27459327298390906,
            "precision": 0.7860262008733624,
            "recall": 0.7392197125256673
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8440273153657051,
            "auditor_fn_violation": 0.005408556378500226,
            "auditor_fp_violation": 0.0118966386803928,
            "ave_precision_score": 0.8443025121046456,
            "fpr": 0.11855104281009879,
            "logloss": 0.6690731907336329,
            "mae": 0.2722155263641549,
            "precision": 0.7626373626373626,
            "recall": 0.7430406852248393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.8708099738737065,
            "auditor_fn_violation": 0.002740102309160993,
            "auditor_fp_violation": 0.014169246646026838,
            "ave_precision_score": 0.871381435738998,
            "fpr": 0.39364035087719296,
            "logloss": 1.974448038940137,
            "mae": 0.3929739243867117,
            "precision": 0.5721096543504172,
            "recall": 0.9856262833675564
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8730275807685599,
            "auditor_fn_violation": 0.003673869456582291,
            "auditor_fp_violation": 0.019392608854738383,
            "ave_precision_score": 0.8731825044305475,
            "fpr": 0.4061470911086718,
            "logloss": 1.9989321274173868,
            "mae": 0.405048978693172,
            "precision": 0.5542168674698795,
            "recall": 0.9850107066381156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.757917031084611,
            "auditor_fn_violation": 0.014603371879390472,
            "auditor_fp_violation": 0.0022703818369453144,
            "ave_precision_score": 0.723085023008977,
            "fpr": 0.20833333333333334,
            "logloss": 3.5565397089126316,
            "mae": 0.29914228415090927,
            "precision": 0.6854304635761589,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7742067569353945,
            "auditor_fn_violation": 0.018597348138502296,
            "auditor_fp_violation": 0.020490303695572632,
            "ave_precision_score": 0.7446703097747569,
            "fpr": 0.2030735455543359,
            "logloss": 3.1102729238917437,
            "mae": 0.2905730375804573,
            "precision": 0.6777003484320557,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 5740,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.854102900242862,
            "auditor_fn_violation": 0.023566681076407654,
            "auditor_fp_violation": 0.021473168214654285,
            "ave_precision_score": 0.8545020043352103,
            "fpr": 0.11732456140350878,
            "logloss": 0.6104144655651661,
            "mae": 0.26643120932623543,
            "precision": 0.7816326530612245,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8489011718412972,
            "auditor_fn_violation": 0.014258280309423022,
            "auditor_fp_violation": 0.025353289623322558,
            "ave_precision_score": 0.8491747215801149,
            "fpr": 0.12623490669593854,
            "logloss": 0.604525645543086,
            "mae": 0.26411444616771285,
            "precision": 0.760914760914761,
            "recall": 0.7837259100642399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8301441241079283,
            "auditor_fn_violation": 0.009586980799020137,
            "auditor_fp_violation": 0.01963106295149639,
            "ave_precision_score": 0.8304445012735397,
            "fpr": 0.18530701754385964,
            "logloss": 0.8366992372069683,
            "mae": 0.27871607468892634,
            "precision": 0.7050610820244329,
            "recall": 0.8295687885010267
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8154603271899117,
            "auditor_fn_violation": 0.0083138043940701,
            "auditor_fp_violation": 0.02824833615173901,
            "ave_precision_score": 0.8158954374381551,
            "fpr": 0.18990120746432493,
            "logloss": 0.8811397063149249,
            "mae": 0.27835343146031677,
            "precision": 0.6964912280701754,
            "recall": 0.8501070663811563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8622476212720582,
            "auditor_fn_violation": 0.009071382254403978,
            "auditor_fp_violation": 0.007401960784313728,
            "ave_precision_score": 0.862625180089741,
            "fpr": 0.12938596491228072,
            "logloss": 0.5131461635246259,
            "mae": 0.2827348396845321,
            "precision": 0.764,
            "recall": 0.784394250513347
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8611466720635426,
            "auditor_fn_violation": 0.005046575638696214,
            "auditor_fp_violation": 0.017088438603257483,
            "ave_precision_score": 0.8613881552953384,
            "fpr": 0.12843029637760703,
            "logloss": 0.5013306932365996,
            "mae": 0.2797415101948362,
            "precision": 0.7592592592592593,
            "recall": 0.7901498929336188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7555171331943097,
            "auditor_fn_violation": 0.016001567059332113,
            "auditor_fp_violation": 0.0018601651186790531,
            "ave_precision_score": 0.7114817158582729,
            "fpr": 0.19846491228070176,
            "logloss": 3.980395282367627,
            "mae": 0.30746004977977276,
            "precision": 0.6841186736474695,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7767380778640952,
            "auditor_fn_violation": 0.01799326339740079,
            "auditor_fp_violation": 0.01833447058474501,
            "ave_precision_score": 0.7388665186590225,
            "fpr": 0.18660812294182216,
            "logloss": 3.4732006639046595,
            "mae": 0.2924157419661439,
            "precision": 0.6875,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8158868041063941,
            "auditor_fn_violation": 0.02405075831261933,
            "auditor_fp_violation": 0.018181114551083594,
            "ave_precision_score": 0.8163879263625267,
            "fpr": 0.13925438596491227,
            "logloss": 0.7828154598469206,
            "mae": 0.289947142154362,
            "precision": 0.7449799196787149,
            "recall": 0.7618069815195072
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7968984341299449,
            "auditor_fn_violation": 0.01035405947296545,
            "auditor_fp_violation": 0.022643664520722702,
            "ave_precision_score": 0.7977566940346317,
            "fpr": 0.14818880351262348,
            "logloss": 0.8102671132329723,
            "mae": 0.28684521428147797,
            "precision": 0.7278225806451613,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8578496763683994,
            "auditor_fn_violation": 0.03772875463813538,
            "auditor_fp_violation": 0.02359649122807018,
            "ave_precision_score": 0.8582363073175528,
            "fpr": 0.1118421052631579,
            "logloss": 0.5281178147325956,
            "mae": 0.30422441404843925,
            "precision": 0.7879417879417879,
            "recall": 0.7782340862422998
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8625561044337977,
            "auditor_fn_violation": 0.04002237699118789,
            "auditor_fp_violation": 0.03031763926385222,
            "ave_precision_score": 0.8628331138577503,
            "fpr": 0.11745334796926454,
            "logloss": 0.5188075274216467,
            "mae": 0.2983458452990517,
            "precision": 0.772823779193206,
            "recall": 0.7794432548179872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 5740,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.820849722901286,
            "auditor_fn_violation": 0.008422943910083216,
            "auditor_fp_violation": 0.02712074303405574,
            "ave_precision_score": 0.8213964546098772,
            "fpr": 0.24780701754385964,
            "logloss": 1.0656447751435185,
            "mae": 0.30287346394748443,
            "precision": 0.6631892697466468,
            "recall": 0.9137577002053389
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8083937523685241,
            "auditor_fn_violation": 0.005744681351175381,
            "auditor_fp_violation": 0.02360043907793634,
            "ave_precision_score": 0.8087298560861759,
            "fpr": 0.24368825466520308,
            "logloss": 1.135894026385846,
            "mae": 0.3064644849003278,
            "precision": 0.65527950310559,
            "recall": 0.9036402569593148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.8392377002530725,
            "auditor_fn_violation": 0.005793166180337909,
            "auditor_fp_violation": 0.011086171310629517,
            "ave_precision_score": 0.8397101751348652,
            "fpr": 0.35855263157894735,
            "logloss": 1.8299408100164045,
            "mae": 0.37016415529493824,
            "precision": 0.5902255639097744,
            "recall": 0.9671457905544147
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.8301828069324397,
            "auditor_fn_violation": 0.00043484699262170506,
            "auditor_fp_violation": 0.014230476360004352,
            "ave_precision_score": 0.8299673425110482,
            "fpr": 0.37760702524698136,
            "logloss": 1.8807352269997542,
            "mae": 0.38199050377469623,
            "precision": 0.57,
            "recall": 0.9764453961456103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8516814999495217,
            "auditor_fn_violation": 0.01472045102489283,
            "auditor_fp_violation": 0.0198813209494324,
            "ave_precision_score": 0.8519678812634646,
            "fpr": 0.14692982456140352,
            "logloss": 0.6732933274076628,
            "mae": 0.2678334591694624,
            "precision": 0.7452471482889734,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.843533864615301,
            "auditor_fn_violation": 0.00830440229693233,
            "auditor_fp_violation": 0.027086361883288345,
            "ave_precision_score": 0.8438351673312854,
            "fpr": 0.15806805708013172,
            "logloss": 0.680089759569459,
            "mae": 0.26569381960723903,
            "precision": 0.7267552182163188,
            "recall": 0.8201284796573876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8268747345451732,
            "auditor_fn_violation": 0.008485986526892184,
            "auditor_fp_violation": 0.022257481940144486,
            "ave_precision_score": 0.8271874950128695,
            "fpr": 0.1875,
            "logloss": 0.8490857715647969,
            "mae": 0.2818575820597916,
            "precision": 0.7036395147313691,
            "recall": 0.8336755646817249
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8091414460553344,
            "auditor_fn_violation": 0.008887332319473862,
            "auditor_fp_violation": 0.024408876494496707,
            "ave_precision_score": 0.8095555034561612,
            "fpr": 0.19209659714599342,
            "logloss": 0.8962728146932175,
            "mae": 0.28321346589393914,
            "precision": 0.6935201401050788,
            "recall": 0.8479657387580299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6544986989186212,
            "auditor_fn_violation": 0.004363449691991788,
            "auditor_fp_violation": 0.0004927760577915493,
            "ave_precision_score": 0.6482677527890195,
            "fpr": 0.3848684210526316,
            "logloss": 3.323091652306217,
            "mae": 0.3921809034415576,
            "precision": 0.5755743651753326,
            "recall": 0.9774127310061602
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.644404695285963,
            "auditor_fn_violation": 0.0029287532584142888,
            "auditor_fp_violation": 0.014685376924674398,
            "ave_precision_score": 0.6376705535684681,
            "fpr": 0.4083424807903403,
            "logloss": 3.3114773856547175,
            "mae": 0.41150009617314887,
            "precision": 0.5512665862484921,
            "recall": 0.9785867237687366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8244381574717948,
            "auditor_fn_violation": 0.010017021506538422,
            "auditor_fp_violation": 0.019171826625386995,
            "ave_precision_score": 0.8250677971401785,
            "fpr": 0.20175438596491227,
            "logloss": 0.9321892943981899,
            "mae": 0.28797500635301715,
            "precision": 0.6928213689482471,
            "recall": 0.8521560574948666
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.817864981386942,
            "auditor_fn_violation": 0.005041874590127331,
            "auditor_fp_violation": 0.01604513404732944,
            "ave_precision_score": 0.8182491971830865,
            "fpr": 0.19209659714599342,
            "logloss": 0.9087361433794714,
            "mae": 0.28356103653986314,
            "precision": 0.6956521739130435,
            "recall": 0.8565310492505354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8364538735104348,
            "auditor_fn_violation": 0.0156593357109406,
            "auditor_fp_violation": 0.009754901960784313,
            "ave_precision_score": 0.8367482387673701,
            "fpr": 0.11074561403508772,
            "logloss": 0.8706790106445792,
            "mae": 0.2721311976220713,
            "precision": 0.7770419426048565,
            "recall": 0.7227926078028748
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8216916410345296,
            "auditor_fn_violation": 0.008346711734052287,
            "auditor_fp_violation": 0.019617586851395863,
            "ave_precision_score": 0.8220529392290877,
            "fpr": 0.12843029637760703,
            "logloss": 0.9333967987614116,
            "mae": 0.2736976191758668,
            "precision": 0.7450980392156863,
            "recall": 0.7323340471092077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 5740,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7190965688453018,
            "auditor_fn_violation": 0.012617529449908136,
            "auditor_fp_violation": 0.015147058823529418,
            "ave_precision_score": 0.7038460553522893,
            "fpr": 0.15789473684210525,
            "logloss": 2.6296122335276384,
            "mae": 0.28477228068795646,
            "precision": 0.7283018867924528,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7434524492427557,
            "auditor_fn_violation": 0.009242261486424548,
            "auditor_fp_violation": 0.014633458925445755,
            "ave_precision_score": 0.7327833003776256,
            "fpr": 0.14818880351262348,
            "logloss": 2.011397375831462,
            "mae": 0.2768845226595238,
            "precision": 0.7278225806451613,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7957158499985021,
            "auditor_fn_violation": 0.01940361684498721,
            "auditor_fp_violation": 0.018655830753353978,
            "ave_precision_score": 0.7643686387209822,
            "fpr": 0.13486842105263158,
            "logloss": 3.3415721355473162,
            "mae": 0.2782085780910114,
            "precision": 0.7510121457489879,
            "recall": 0.7618069815195072
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7828993579224864,
            "auditor_fn_violation": 0.005279277542855933,
            "auditor_fp_violation": 0.021098485972251068,
            "ave_precision_score": 0.747799643942054,
            "fpr": 0.14270032930845225,
            "logloss": 3.5772946811548403,
            "mae": 0.2762482960462982,
            "precision": 0.7341513292433538,
            "recall": 0.7687366167023555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8607264225659319,
            "auditor_fn_violation": 0.011975845671674059,
            "auditor_fp_violation": 0.012432920536635708,
            "ave_precision_score": 0.8599371749124141,
            "fpr": 0.08552631578947369,
            "logloss": 0.8290312420940791,
            "mae": 0.2617587662794663,
            "precision": 0.8198614318706697,
            "recall": 0.728952772073922
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8527569042285729,
            "auditor_fn_violation": 0.004087561730644026,
            "auditor_fp_violation": 0.011510962114694278,
            "ave_precision_score": 0.8509364518865608,
            "fpr": 0.0889132821075741,
            "logloss": 0.8168187553716041,
            "mae": 0.2565082425619795,
            "precision": 0.8076009501187649,
            "recall": 0.728051391862955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8401463465565869,
            "auditor_fn_violation": 0.012070409596887498,
            "auditor_fp_violation": 0.020356037151702786,
            "ave_precision_score": 0.840454415034159,
            "fpr": 0.12609649122807018,
            "logloss": 0.7930719517308176,
            "mae": 0.2680278905919472,
            "precision": 0.7638603696098563,
            "recall": 0.7638603696098563
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8285052940035966,
            "auditor_fn_violation": 0.007982380469963826,
            "auditor_fp_violation": 0.016547008039873023,
            "ave_precision_score": 0.8288130478104359,
            "fpr": 0.1350164654226125,
            "logloss": 0.7913813268765896,
            "mae": 0.2676930806613334,
            "precision": 0.7448132780082988,
            "recall": 0.7687366167023555
        }
    }
]