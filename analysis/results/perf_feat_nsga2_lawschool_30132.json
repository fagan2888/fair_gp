[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6785163673155159,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.6789268141841884,
            "fpr": 0.44846491228070173,
            "logloss": 0.7077612432612308,
            "mae": 0.47163348282246215,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.719787024794228,
            "auditor_fn_violation": 0.0012752631239103763,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.7198791137004976,
            "fpr": 0.45334796926454446,
            "logloss": 0.6965674123237549,
            "mae": 0.4679610494986324,
            "precision": 0.5317460317460317,
            "recall": 0.9852941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7870358157305133,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.7873776914607763,
            "fpr": 0.44846491228070173,
            "logloss": 0.6817272793776917,
            "mae": 0.45768105689632266,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8100501300086126,
            "auditor_fn_violation": 0.0017664585043677186,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.8100889516293577,
            "fpr": 0.45334796926454446,
            "logloss": 0.6742349729431681,
            "mae": 0.4559455094235396,
            "precision": 0.5322763306908267,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6940781493227305,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.6944734390744495,
            "fpr": 0.4407894736842105,
            "logloss": 0.712905450341676,
            "mae": 0.4709023887193517,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7352076534634853,
            "auditor_fn_violation": 0.001752622014777371,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.7353556008401021,
            "fpr": 0.4478594950603732,
            "logloss": 0.7062995600329923,
            "mae": 0.4686868770127762,
            "precision": 0.5342465753424658,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6950655814052341,
            "auditor_fn_violation": 0.004188688247816201,
            "auditor_fp_violation": 0.008701188455008491,
            "ave_precision_score": 0.6552579416588112,
            "fpr": 0.03070175438596491,
            "logloss": 0.6743191240061738,
            "mae": 0.47777829750588063,
            "precision": 0.8486486486486486,
            "recall": 0.3284518828451883
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7371211350522925,
            "auditor_fn_violation": 0.009860804914721103,
            "auditor_fp_violation": 0.0047440604615365195,
            "ave_precision_score": 0.6866486306102716,
            "fpr": 0.027442371020856202,
            "logloss": 0.6567944475916276,
            "mae": 0.4710113371831787,
            "precision": 0.8633879781420765,
            "recall": 0.3319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6942669772619012,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.6946517235544887,
            "fpr": 0.4407894736842105,
            "logloss": 0.7125182733067548,
            "mae": 0.47069933507264705,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7354568434453159,
            "auditor_fn_violation": 0.001752622014777371,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.7355772228381786,
            "fpr": 0.4478594950603732,
            "logloss": 0.7057463746472048,
            "mae": 0.46843765798698533,
            "precision": 0.5342465753424658,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7969448421666662,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.7973504191561611,
            "fpr": 0.44846491228070173,
            "logloss": 0.6492404376675313,
            "mae": 0.43373710658858744,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.8139204578280516,
            "auditor_fn_violation": 0.00146205573338007,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.8141568628146448,
            "fpr": 0.45334796926454446,
            "logloss": 0.6377298412274717,
            "mae": 0.43343603280582493,
            "precision": 0.5328054298642534,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6982553719490139,
            "auditor_fn_violation": 0.007436871467371368,
            "auditor_fp_violation": 0.00711708707252001,
            "ave_precision_score": 0.6584217843678345,
            "fpr": 0.029605263157894735,
            "logloss": 0.6741524938788229,
            "mae": 0.47758305393028677,
            "precision": 0.8524590163934426,
            "recall": 0.3263598326359833
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7394652104264189,
            "auditor_fn_violation": 0.008663948565156053,
            "auditor_fp_violation": 0.005405200802452782,
            "ave_precision_score": 0.6889866559285884,
            "fpr": 0.026344676180021953,
            "logloss": 0.6564939467190468,
            "mae": 0.47075013700222473,
            "precision": 0.8674033149171271,
            "recall": 0.32983193277310924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7090281615120485,
            "auditor_fn_violation": 0.09116246421493064,
            "auditor_fp_violation": 0.08879557765381196,
            "ave_precision_score": 0.5562628678390072,
            "fpr": 0.2741228070175439,
            "logloss": 0.686427817161675,
            "mae": 0.4947970913755789,
            "precision": 0.5667244367417678,
            "recall": 0.6841004184100419
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7175660285209778,
            "auditor_fn_violation": 0.0784206108348938,
            "auditor_fp_violation": 0.08221355842386163,
            "ave_precision_score": 0.5668587568278411,
            "fpr": 0.2579582875960483,
            "logloss": 0.6831842404796428,
            "mae": 0.49317600014573526,
            "precision": 0.5833333333333334,
            "recall": 0.6911764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7619637816426659,
            "auditor_fn_violation": 0.002972913455186083,
            "auditor_fp_violation": 0.015995128951410805,
            "ave_precision_score": 0.7625623010693958,
            "fpr": 0.3892543859649123,
            "logloss": 0.6405154380795565,
            "mae": 0.43132285589940456,
            "precision": 0.56865127582017,
            "recall": 0.9790794979079498
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7734682501320915,
            "auditor_fn_violation": 0.004146334713907518,
            "auditor_fp_violation": 0.016180274297538398,
            "ave_precision_score": 0.7738561315796291,
            "fpr": 0.4039517014270033,
            "logloss": 0.6386396216126647,
            "mae": 0.43403999706981733,
            "precision": 0.5582232893157263,
            "recall": 0.976890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7923313896334492,
            "auditor_fn_violation": 0.0518699992659473,
            "auditor_fp_violation": 0.0935403023688253,
            "ave_precision_score": 0.7927048542449755,
            "fpr": 0.26535087719298245,
            "logloss": 0.6057567441385022,
            "mae": 0.42881038219651635,
            "precision": 0.6109324758842444,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.808820442842558,
            "auditor_fn_violation": 0.05282079901115221,
            "auditor_fp_violation": 0.0908563281476715,
            "ave_precision_score": 0.8090652972605741,
            "fpr": 0.2689352360043908,
            "logloss": 0.593471913087987,
            "mae": 0.4269651168656794,
            "precision": 0.6098726114649682,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5387756194580651,
            "auditor_fn_violation": 0.09043529325405564,
            "auditor_fp_violation": 0.08808058452583072,
            "ave_precision_score": 0.556391613519812,
            "fpr": 0.27521929824561403,
            "logloss": 0.6851149611038546,
            "mae": 0.493871759786679,
            "precision": 0.5664939550949913,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.487662940289045,
            "auditor_fn_violation": 0.0776780525602118,
            "auditor_fp_violation": 0.08141867595291269,
            "ave_precision_score": 0.5661980930291355,
            "fpr": 0.2601536772777168,
            "logloss": 0.6824002299052211,
            "mae": 0.49242818097120844,
            "precision": 0.582010582010582,
            "recall": 0.6932773109243697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6986331232108647,
            "auditor_fn_violation": 0.006565183880202599,
            "auditor_fp_violation": 0.007205513784461159,
            "ave_precision_score": 0.6991510708278819,
            "fpr": 0.43859649122807015,
            "logloss": 0.6792648714433785,
            "mae": 0.47280527502625136,
            "precision": 0.5327102803738317,
            "recall": 0.9539748953974896
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7347714615841505,
            "auditor_fn_violation": 0.0030901493418443115,
            "auditor_fp_violation": 0.006225317637558841,
            "ave_precision_score": 0.7351089412382438,
            "fpr": 0.4489571899012075,
            "logloss": 0.6709602883690663,
            "mae": 0.46981355428499394,
            "precision": 0.526071842410197,
            "recall": 0.9537815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6569244239479956,
            "auditor_fn_violation": 0.006973500697350067,
            "auditor_fp_violation": 0.003324844368986984,
            "ave_precision_score": 0.6576885209767172,
            "fpr": 0.03508771929824561,
            "logloss": 0.6730530132690202,
            "mae": 0.4812357367196104,
            "precision": 0.8117647058823529,
            "recall": 0.28870292887029286
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6384507417279857,
            "auditor_fn_violation": 0.00401488806279921,
            "auditor_fp_violation": 0.005579317915136833,
            "ave_precision_score": 0.638982194869482,
            "fpr": 0.052689352360043906,
            "logloss": 0.67860832981558,
            "mae": 0.4813752654694792,
            "precision": 0.7192982456140351,
            "recall": 0.25840336134453784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7846610355765304,
            "auditor_fn_violation": 0.010691936431035748,
            "auditor_fp_violation": 0.007190354919556959,
            "ave_precision_score": 0.7850448450629354,
            "fpr": 0.09649122807017543,
            "logloss": 0.5983350410513247,
            "mae": 0.4101393123304373,
            "precision": 0.7589041095890411,
            "recall": 0.5794979079497908
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8178075271290233,
            "auditor_fn_violation": 0.001420546264609022,
            "auditor_fp_violation": 0.010656471983547196,
            "ave_precision_score": 0.8180323027904236,
            "fpr": 0.08342480790340286,
            "logloss": 0.616688750902044,
            "mae": 0.40402393916598683,
            "precision": 0.7877094972067039,
            "recall": 0.592436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7577214746874433,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.7580941881386023,
            "fpr": 0.4407894736842105,
            "logloss": 0.6758761432063647,
            "mae": 0.4420454716473295,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7761054322430229,
            "auditor_fn_violation": 0.0019878423378132813,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.7763742093020964,
            "fpr": 0.4478594950603732,
            "logloss": 0.66763592973803,
            "mae": 0.44197066152789327,
            "precision": 0.5353075170842825,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6932364903757522,
            "auditor_fn_violation": 0.0029407986493430226,
            "auditor_fp_violation": 0.005500141482739107,
            "ave_precision_score": 0.6937709274250599,
            "fpr": 0.4375,
            "logloss": 0.6807751253837331,
            "mae": 0.4730936322328553,
            "precision": 0.5305882352941177,
            "recall": 0.9435146443514645
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7326920476033082,
            "auditor_fn_violation": 0.0037450765157874357,
            "auditor_fp_violation": 0.006225317637558841,
            "ave_precision_score": 0.7330364152607235,
            "fpr": 0.4489571899012075,
            "logloss": 0.6745081437485433,
            "mae": 0.4709752285045405,
            "precision": 0.5227537922987164,
            "recall": 0.9411764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7739538084886903,
            "auditor_fn_violation": 0.0023833773764956327,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.774370516521175,
            "fpr": 0.4407894736842105,
            "logloss": 0.663863690253267,
            "mae": 0.4481975815602039,
            "precision": 0.5363321799307958,
            "recall": 0.9728033472803347
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7818816945255249,
            "auditor_fn_violation": 0.0029056628139730103,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.782141820284932,
            "fpr": 0.4478594950603732,
            "logloss": 0.6798647683311755,
            "mae": 0.45205366011246145,
            "precision": 0.5277777777777778,
            "recall": 0.957983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7699053208961553,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.7702842984094915,
            "fpr": 0.4407894736842105,
            "logloss": 0.6677214250222766,
            "mae": 0.44161861915990974,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7902476441050467,
            "auditor_fn_violation": 0.0019878423378132813,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.7905053857580564,
            "fpr": 0.4478594950603732,
            "logloss": 0.6572894757168949,
            "mae": 0.4407044512707368,
            "precision": 0.5353075170842825,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7838779755710106,
            "auditor_fn_violation": 0.010496953681274328,
            "auditor_fp_violation": 0.005394029428409735,
            "ave_precision_score": 0.7842524007327843,
            "fpr": 0.09539473684210527,
            "logloss": 0.5984556079602967,
            "mae": 0.4099395016796496,
            "precision": 0.7563025210084033,
            "recall": 0.5648535564853556
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8179337288962102,
            "auditor_fn_violation": 0.0035605899879161355,
            "auditor_fp_violation": 0.014005072107195583,
            "ave_precision_score": 0.8181653331044504,
            "fpr": 0.0801317233809001,
            "logloss": 0.6005112616495502,
            "mae": 0.40272761492874454,
            "precision": 0.7908309455587392,
            "recall": 0.5798319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7791203139800602,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.006462729404155548,
            "ave_precision_score": 0.7795027526789228,
            "fpr": 0.4407894736842105,
            "logloss": 0.698771255685186,
            "mae": 0.45010707334598954,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7924630190917802,
            "auditor_fn_violation": 0.00146205573338007,
            "auditor_fp_violation": 0.0071009500738105245,
            "ave_precision_score": 0.7927286353995611,
            "fpr": 0.4478594950603732,
            "logloss": 0.6925827091730751,
            "mae": 0.449693825484369,
            "precision": 0.5358361774744027,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7666518691016975,
            "auditor_fn_violation": 0.007840600455112678,
            "auditor_fp_violation": 0.013238742016331156,
            "ave_precision_score": 0.7672007120407586,
            "fpr": 0.125,
            "logloss": 0.6451784066103413,
            "mae": 0.407653341429276,
            "precision": 0.7246376811594203,
            "recall": 0.6276150627615062
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.799812604865118,
            "auditor_fn_violation": 0.0004911953804573551,
            "auditor_fp_violation": 0.012430447783791975,
            "ave_precision_score": 0.8011230041627749,
            "fpr": 0.10318331503841932,
            "logloss": 0.6751354435741774,
            "mae": 0.40075069607023905,
            "precision": 0.7667493796526055,
            "recall": 0.6491596638655462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.5995956566465732,
            "auditor_fn_violation": 0.06358272773985173,
            "auditor_fp_violation": 0.06490520656479909,
            "ave_precision_score": 0.5929230598736464,
            "fpr": 0.2138157894736842,
            "logloss": 1.4431903548770904,
            "mae": 0.4379739236707489,
            "precision": 0.643510054844607,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.5908609331698245,
            "auditor_fn_violation": 0.06950991153870988,
            "auditor_fp_violation": 0.07246300011355464,
            "ave_precision_score": 0.5858745609486851,
            "fpr": 0.2217343578485181,
            "logloss": 1.4131119662768117,
            "mae": 0.43467626054939923,
            "precision": 0.6366906474820144,
            "recall": 0.7436974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5387756194580651,
            "auditor_fn_violation": 0.09043529325405564,
            "auditor_fp_violation": 0.08808058452583072,
            "ave_precision_score": 0.556391613519812,
            "fpr": 0.27521929824561403,
            "logloss": 0.6851099447315052,
            "mae": 0.49386731708389625,
            "precision": 0.5664939550949913,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.487662940289045,
            "auditor_fn_violation": 0.0776780525602118,
            "auditor_fp_violation": 0.08141867595291269,
            "ave_precision_score": 0.5661980930291355,
            "fpr": 0.2601536772777168,
            "logloss": 0.6823970003090151,
            "mae": 0.4924242070883218,
            "precision": 0.582010582010582,
            "recall": 0.6932773109243697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7808646718192324,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.7821765170752236,
            "fpr": 0.4407894736842105,
            "logloss": 0.6663574897461481,
            "mae": 0.4362483219684739,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7965148604165201,
            "auditor_fn_violation": 0.002921805385161749,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.7967997933013168,
            "fpr": 0.4478594950603732,
            "logloss": 0.6587354140200736,
            "mae": 0.4371178726922275,
            "precision": 0.5347776510832383,
            "recall": 0.9852941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.526830427750236,
            "auditor_fn_violation": 0.006225684504147404,
            "auditor_fp_violation": 0.006755800792303339,
            "ave_precision_score": 0.5283724563831751,
            "fpr": 0.03070175438596491,
            "logloss": 1.0183771211081103,
            "mae": 0.5190637016141983,
            "precision": 0.6266666666666667,
            "recall": 0.09832635983263599
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5072073486243566,
            "auditor_fn_violation": 0.001524319936536646,
            "auditor_fp_violation": 0.0038154358605549045,
            "ave_precision_score": 0.5090430701629987,
            "fpr": 0.036223929747530186,
            "logloss": 1.012843378582483,
            "mae": 0.5225034379630332,
            "precision": 0.484375,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5571603050476578,
            "auditor_fn_violation": 0.0010850216545547995,
            "auditor_fp_violation": 0.003612862802166707,
            "ave_precision_score": 0.5580274664035481,
            "fpr": 0.017543859649122806,
            "logloss": 1.0151686444793777,
            "mae": 0.5176984129796263,
            "precision": 0.7192982456140351,
            "recall": 0.08577405857740586
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5122712016876894,
            "auditor_fn_violation": 0.0013605881430508529,
            "auditor_fp_violation": 0.0033561704328955184,
            "ave_precision_score": 0.5142677125384922,
            "fpr": 0.027442371020856202,
            "logloss": 1.008946831657217,
            "mae": 0.5211884004056748,
            "precision": 0.5535714285714286,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.8022896815885074,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.007273728676530054,
            "ave_precision_score": 0.8030601163091831,
            "fpr": 0.43969298245614036,
            "logloss": 0.6659791181076637,
            "mae": 0.43638363253455936,
            "precision": 0.5406643757159221,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.8159760320484419,
            "auditor_fn_violation": 0.0019878423378132813,
            "auditor_fp_violation": 0.006952067325283576,
            "ave_precision_score": 0.8162748217819739,
            "fpr": 0.4456641053787047,
            "logloss": 0.6570862070155965,
            "mae": 0.4361798245741952,
            "precision": 0.5365296803652968,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6667651286260448,
            "auditor_fn_violation": 0.0099326506643177,
            "auditor_fp_violation": 0.0055430915999676615,
            "ave_precision_score": 0.6676765888363523,
            "fpr": 0.02631578947368421,
            "logloss": 0.668559989553187,
            "mae": 0.47902534588387136,
            "precision": 0.8285714285714286,
            "recall": 0.24267782426778242
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6568847223704728,
            "auditor_fn_violation": 0.00291949930356337,
            "auditor_fp_violation": 0.004019834210227487,
            "ave_precision_score": 0.6573878763408045,
            "fpr": 0.029637760702524697,
            "logloss": 0.6660635604644041,
            "mae": 0.47760504830943507,
            "precision": 0.8085106382978723,
            "recall": 0.23949579831932774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6921798439302432,
            "auditor_fn_violation": 0.011763194597372087,
            "auditor_fp_violation": 0.011106395019807584,
            "ave_precision_score": 0.6510521347686937,
            "fpr": 0.03837719298245614,
            "logloss": 0.6767213987733615,
            "mae": 0.48035436728152264,
            "precision": 0.8205128205128205,
            "recall": 0.33472803347280333
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7333078669908766,
            "auditor_fn_violation": 0.0081174072263373,
            "auditor_fp_violation": 0.007244785949506036,
            "ave_precision_score": 0.6817877120903242,
            "fpr": 0.031833150384193196,
            "logloss": 0.6603202303608139,
            "mae": 0.47385837734726993,
            "precision": 0.8465608465608465,
            "recall": 0.33613445378151263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.769849170357791,
            "auditor_fn_violation": 0.006514717756734932,
            "auditor_fp_violation": 0.0056390977443609045,
            "ave_precision_score": 0.7702736461997916,
            "fpr": 0.10197368421052631,
            "logloss": 0.6084804634445061,
            "mae": 0.4026126971840045,
            "precision": 0.7372881355932204,
            "recall": 0.5460251046025104
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.789963180799968,
            "auditor_fn_violation": 0.008299587672610215,
            "auditor_fp_violation": 0.007608160793368411,
            "ave_precision_score": 0.790241666512443,
            "fpr": 0.09110867178924259,
            "logloss": 0.6120743920726002,
            "mae": 0.40003168929478705,
            "precision": 0.7558823529411764,
            "recall": 0.5399159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6920005974342555,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.6923883833698761,
            "fpr": 0.44846491228070173,
            "logloss": 0.714489265163852,
            "mae": 0.4727193615807776,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7326902614919578,
            "auditor_fn_violation": 0.0012752631239103763,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.7327763269771688,
            "fpr": 0.45334796926454446,
            "logloss": 0.7068160509146586,
            "mae": 0.46998282521145274,
            "precision": 0.5317460317460317,
            "recall": 0.9852941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7090281615120485,
            "auditor_fn_violation": 0.09116246421493064,
            "auditor_fp_violation": 0.08879557765381196,
            "ave_precision_score": 0.5562628678390072,
            "fpr": 0.2741228070175439,
            "logloss": 0.6863964362144552,
            "mae": 0.4946931785854854,
            "precision": 0.5667244367417678,
            "recall": 0.6841004184100419
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7175660285209778,
            "auditor_fn_violation": 0.0784206108348938,
            "auditor_fp_violation": 0.08221355842386163,
            "ave_precision_score": 0.5668587568278411,
            "fpr": 0.2579582875960483,
            "logloss": 0.683201553112961,
            "mae": 0.49310081575626075,
            "precision": 0.5833333333333334,
            "recall": 0.6911764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6737916328565907,
            "auditor_fn_violation": 0.001738787344931371,
            "auditor_fp_violation": 0.028761419678227835,
            "ave_precision_score": 0.6535916899432099,
            "fpr": 0.1875,
            "logloss": 2.487491543749218,
            "mae": 0.31344216476937964,
            "precision": 0.6856617647058824,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6432082082493601,
            "auditor_fn_violation": 0.00477589499026834,
            "auditor_fp_violation": 0.0334986184185624,
            "ave_precision_score": 0.6232001161667295,
            "fpr": 0.21953896816684962,
            "logloss": 2.9558753992202145,
            "mae": 0.3227480558839738,
            "precision": 0.6649916247906198,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.6748231458539989,
            "auditor_fn_violation": 0.004707112970711303,
            "auditor_fp_violation": 0.036292849058129205,
            "ave_precision_score": 0.6546257576154626,
            "fpr": 0.17214912280701755,
            "logloss": 2.2002295974278483,
            "mae": 0.33441702214277985,
            "precision": 0.7119266055045872,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.650288995755983,
            "auditor_fn_violation": 0.013744246326412015,
            "auditor_fp_violation": 0.03358946212952799,
            "ave_precision_score": 0.6301232059507057,
            "fpr": 0.19099890230515917,
            "logloss": 2.6207264033240527,
            "mae": 0.3455253539092708,
            "precision": 0.6952714535901926,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7116691310486504,
            "auditor_fn_violation": 0.09483272773985171,
            "auditor_fp_violation": 0.09013461072034927,
            "ave_precision_score": 0.5569842304193555,
            "fpr": 0.27850877192982454,
            "logloss": 0.6834651762155954,
            "mae": 0.49358795024454594,
            "precision": 0.5658119658119658,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7255144449228222,
            "auditor_fn_violation": 0.08107260467304375,
            "auditor_fp_violation": 0.08787614974071692,
            "ave_precision_score": 0.5704156437412182,
            "fpr": 0.2667398463227223,
            "logloss": 0.6792293931820321,
            "mae": 0.49128485291901847,
            "precision": 0.5831903945111492,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5605384837931683,
            "auditor_fn_violation": 0.0010850216545547995,
            "auditor_fp_violation": 0.003612862802166707,
            "ave_precision_score": 0.5612970298874986,
            "fpr": 0.017543859649122806,
            "logloss": 1.0244924300157583,
            "mae": 0.517699515487868,
            "precision": 0.7192982456140351,
            "recall": 0.08577405857740586
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.513123283791951,
            "auditor_fn_violation": 0.002965620935531186,
            "auditor_fp_violation": 0.004307505961618533,
            "ave_precision_score": 0.5146194964248272,
            "fpr": 0.026344676180021953,
            "logloss": 1.0187984791516924,
            "mae": 0.5213597254576131,
            "precision": 0.5555555555555556,
            "recall": 0.06302521008403361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7838695080251967,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.009034683482900794,
            "ave_precision_score": 0.7843004770297681,
            "fpr": 0.43859649122807015,
            "logloss": 0.6550699281205431,
            "mae": 0.4301615749534808,
            "precision": 0.5412844036697247,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.79073801635135,
            "auditor_fn_violation": 0.0019878423378132813,
            "auditor_fp_violation": 0.006952067325283576,
            "ave_precision_score": 0.7910313960239321,
            "fpr": 0.4456641053787047,
            "logloss": 0.6467608339084946,
            "mae": 0.4312426202023723,
            "precision": 0.5365296803652968,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7709069683410434,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.7722271608059641,
            "fpr": 0.44846491228070173,
            "logloss": 0.6695824876840144,
            "mae": 0.4364540349822818,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7858656263986155,
            "auditor_fn_violation": 0.0019186598898615428,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.7861537243113053,
            "fpr": 0.45334796926454446,
            "logloss": 0.6607099417421755,
            "mae": 0.4371683837520828,
            "precision": 0.5322763306908267,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5920237165113285,
            "auditor_fn_violation": 0.09806485355648535,
            "auditor_fp_violation": 0.08415696499312798,
            "ave_precision_score": 0.5935318837369095,
            "fpr": 0.27521929824561403,
            "logloss": 0.6801184250995278,
            "mae": 0.4862805150055864,
            "precision": 0.5694682675814752,
            "recall": 0.694560669456067
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5821942650519198,
            "auditor_fn_violation": 0.10707598077650379,
            "auditor_fp_violation": 0.08739164994890042,
            "ave_precision_score": 0.5832591706320261,
            "fpr": 0.2667398463227223,
            "logloss": 0.6850838707701615,
            "mae": 0.48815787720029336,
            "precision": 0.5676156583629893,
            "recall": 0.6701680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.709497197359046,
            "auditor_fn_violation": 0.09116246421493064,
            "auditor_fp_violation": 0.08879557765381196,
            "ave_precision_score": 0.5566234892646811,
            "fpr": 0.2741228070175439,
            "logloss": 0.6851952316165564,
            "mae": 0.4937783711377466,
            "precision": 0.5667244367417678,
            "recall": 0.6841004184100419
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7184636277727106,
            "auditor_fn_violation": 0.0784206108348938,
            "auditor_fp_violation": 0.08221355842386163,
            "ave_precision_score": 0.5675320276870095,
            "fpr": 0.2579582875960483,
            "logloss": 0.6821908093682044,
            "mae": 0.4922183873755479,
            "precision": 0.5833333333333334,
            "recall": 0.6911764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7061463904511526,
            "auditor_fn_violation": 0.002323735594215665,
            "auditor_fp_violation": 0.004668930390492378,
            "ave_precision_score": 0.5489864784500514,
            "fpr": 0.4605263157894737,
            "logloss": 0.7589207329997294,
            "mae": 0.48436066436401587,
            "precision": 0.5286195286195287,
            "recall": 0.9853556485355649
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7161840958892544,
            "auditor_fn_violation": 0.0034591223975869168,
            "auditor_fp_violation": 0.0034823422536810725,
            "ave_precision_score": 0.5606238964381992,
            "fpr": 0.4676180021953897,
            "logloss": 0.7586745803718434,
            "mae": 0.48491964745207494,
            "precision": 0.5245535714285714,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 30132,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5232692464998813,
            "auditor_fn_violation": 0.002704525434926235,
            "auditor_fp_violation": 0.00972693831352575,
            "ave_precision_score": 0.524826857583112,
            "fpr": 0.03070175438596491,
            "logloss": 1.0193190775067118,
            "mae": 0.5215356681953397,
            "precision": 0.6164383561643836,
            "recall": 0.09414225941422594
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5031435587449298,
            "auditor_fn_violation": 0.001524319936536646,
            "auditor_fp_violation": 0.001390413465056716,
            "ave_precision_score": 0.5049736180248701,
            "fpr": 0.031833150384193196,
            "logloss": 1.0128766159678237,
            "mae": 0.5248930355458307,
            "precision": 0.5166666666666667,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5571764119783122,
            "auditor_fn_violation": 0.0010850216545547995,
            "auditor_fp_violation": 0.003612862802166707,
            "ave_precision_score": 0.5580444400391993,
            "fpr": 0.017543859649122806,
            "logloss": 1.0157355321881771,
            "mae": 0.5176924345933163,
            "precision": 0.7192982456140351,
            "recall": 0.08577405857740586
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5123586983762225,
            "auditor_fn_violation": 0.0013605881430508529,
            "auditor_fp_violation": 0.0033561704328955184,
            "ave_precision_score": 0.5143427337930362,
            "fpr": 0.027442371020856202,
            "logloss": 1.0094998102121622,
            "mae": 0.5211792556992215,
            "precision": 0.5535714285714286,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 30132,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6768853201972737,
            "auditor_fn_violation": 0.00017433751743375206,
            "auditor_fp_violation": 0.0286426752364783,
            "ave_precision_score": 0.6563688129826873,
            "fpr": 0.1962719298245614,
            "logloss": 2.5189706620923977,
            "mae": 0.32054205052809903,
            "precision": 0.6786355475763016,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6503728384816836,
            "auditor_fn_violation": 0.00659539337139906,
            "auditor_fp_violation": 0.032824860895567576,
            "ave_precision_score": 0.6298074153480626,
            "fpr": 0.2239297475301866,
            "logloss": 3.022602387992226,
            "mae": 0.32750984448436077,
            "precision": 0.6622516556291391,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8017285138337187,
            "auditor_fn_violation": 0.008308559054540117,
            "auditor_fp_violation": 0.0025466893039049255,
            "ave_precision_score": 0.8021884951993578,
            "fpr": 0.08552631578947369,
            "logloss": 0.5821388507179616,
            "mae": 0.39405708220836455,
            "precision": 0.7815126050420168,
            "recall": 0.5836820083682008
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8349052947731472,
            "auditor_fn_violation": 0.004051785368373479,
            "auditor_fp_violation": 0.01075488600375992,
            "ave_precision_score": 0.8351263498012177,
            "fpr": 0.07464324917672886,
            "logloss": 0.6158819336322255,
            "mae": 0.38571836709011204,
            "precision": 0.8073654390934845,
            "recall": 0.5987394957983193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6746489342116073,
            "auditor_fn_violation": 0.00011010790574764008,
            "auditor_fp_violation": 0.032187323146576116,
            "ave_precision_score": 0.6544482329923569,
            "fpr": 0.18311403508771928,
            "logloss": 2.4635894270474026,
            "mae": 0.31230458685244283,
            "precision": 0.6913123844731978,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6439544625364999,
            "auditor_fn_violation": 0.005151786290806113,
            "auditor_fp_violation": 0.033130196701868606,
            "ave_precision_score": 0.6239387458865722,
            "fpr": 0.21624588364434688,
            "logloss": 2.9241338752990247,
            "mae": 0.32241148074105747,
            "precision": 0.6666666666666666,
            "recall": 0.8277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6867176828411333,
            "auditor_fn_violation": 0.0012570652572854743,
            "auditor_fp_violation": 0.03421103161128629,
            "ave_precision_score": 0.6665115188697258,
            "fpr": 0.18311403508771928,
            "logloss": 2.427267244316195,
            "mae": 0.29971666853477646,
            "precision": 0.6980108499095841,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6526928525122369,
            "auditor_fn_violation": 0.00844487081330886,
            "auditor_fp_violation": 0.0319492284593159,
            "ave_precision_score": 0.6329393190945912,
            "fpr": 0.21514818880351264,
            "logloss": 2.9027338330110077,
            "mae": 0.3143722525124403,
            "precision": 0.6738768718801996,
            "recall": 0.8508403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6791514333659763,
            "auditor_fn_violation": 4.1290464655364e-05,
            "auditor_fp_violation": 0.027361751152073736,
            "ave_precision_score": 0.658172901232083,
            "fpr": 0.22587719298245615,
            "logloss": 2.545172592046861,
            "mae": 0.3456473701065422,
            "precision": 0.6514382402707276,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6558096071305561,
            "auditor_fn_violation": 0.01013984078812645,
            "auditor_fp_violation": 0.027101707104735234,
            "ave_precision_score": 0.6333184411494461,
            "fpr": 0.2414928649835346,
            "logloss": 3.0333400983430523,
            "mae": 0.3476541785308579,
            "precision": 0.6491228070175439,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7807625159583671,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.004825571994502388,
            "ave_precision_score": 0.7811430883419526,
            "fpr": 0.4473684210526316,
            "logloss": 0.7020207118914117,
            "mae": 0.45108287712853207,
            "precision": 0.5363636363636364,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7915258145055155,
            "auditor_fn_violation": 0.00146205573338007,
            "auditor_fp_violation": 0.006757762721273853,
            "ave_precision_score": 0.791791903865773,
            "fpr": 0.4522502744237102,
            "logloss": 0.6953390277525946,
            "mae": 0.45038869770900086,
            "precision": 0.5334088335220838,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.6908262622414714,
            "auditor_fn_violation": 0.0009703259194010137,
            "auditor_fp_violation": 0.03357941224027812,
            "ave_precision_score": 0.6708466733008281,
            "fpr": 0.1875,
            "logloss": 2.4324107204545893,
            "mae": 0.3054211485673078,
            "precision": 0.7061855670103093,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6593385972761638,
            "auditor_fn_violation": 0.011129149793836309,
            "auditor_fp_violation": 0.03423041497911856,
            "ave_precision_score": 0.6400323619133547,
            "fpr": 0.22502744237102085,
            "logloss": 2.877997183566803,
            "mae": 0.3198369180296883,
            "precision": 0.6672077922077922,
            "recall": 0.8634453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 30132,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5191753256935044,
            "auditor_fn_violation": 0.009143544006459666,
            "auditor_fp_violation": 0.0030595642331635543,
            "ave_precision_score": 0.5206925645519815,
            "fpr": 0.023026315789473683,
            "logloss": 1.0830182973770177,
            "mae": 0.523067541367358,
            "precision": 0.6666666666666666,
            "recall": 0.08786610878661087
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5009953958201026,
            "auditor_fn_violation": 0.004349269894565961,
            "auditor_fp_violation": 0.0016427571066278067,
            "ave_precision_score": 0.5028249464302308,
            "fpr": 0.02305159165751921,
            "logloss": 1.074965742779972,
            "mae": 0.5267055062689582,
            "precision": 0.58,
            "recall": 0.06092436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.5375805450031553,
            "auditor_fn_violation": 0.07622449166850181,
            "auditor_fp_violation": 0.10327734659228718,
            "ave_precision_score": 0.5322064504078163,
            "fpr": 0.31359649122807015,
            "logloss": 1.4698808549120406,
            "mae": 0.4909486715730868,
            "precision": 0.5686274509803921,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5409776180257801,
            "auditor_fn_violation": 0.0792069846599452,
            "auditor_fp_violation": 0.0998927539523323,
            "ave_precision_score": 0.5367474872298437,
            "fpr": 0.3084522502744237,
            "logloss": 1.4156711746151942,
            "mae": 0.4883711727992371,
            "precision": 0.5676923076923077,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5376395810837546,
            "auditor_fn_violation": 0.07622449166850181,
            "auditor_fp_violation": 0.10399739267523649,
            "ave_precision_score": 0.5322941026566256,
            "fpr": 0.3125,
            "logloss": 1.4716795185791731,
            "mae": 0.4907571076366462,
            "precision": 0.5694864048338368,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5409728133505118,
            "auditor_fn_violation": 0.0799472368530288,
            "auditor_fp_violation": 0.09980191024136668,
            "ave_precision_score": 0.5367370959877645,
            "fpr": 0.30735455543358947,
            "logloss": 1.417156238963076,
            "mae": 0.48817745014681646,
            "precision": 0.5679012345679012,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.5399565595563949,
            "auditor_fn_violation": 0.0694322102326947,
            "auditor_fp_violation": 0.09758266634327756,
            "ave_precision_score": 0.5346523369454391,
            "fpr": 0.3267543859649123,
            "logloss": 1.369306927816233,
            "mae": 0.49317255959306894,
            "precision": 0.564327485380117,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5443547724149439,
            "auditor_fn_violation": 0.07314660221937293,
            "auditor_fp_violation": 0.096054607164036,
            "ave_precision_score": 0.5393968867794592,
            "fpr": 0.3238199780461032,
            "logloss": 1.344582171773548,
            "mae": 0.49073032908853137,
            "precision": 0.5623145400593472,
            "recall": 0.7962184873949579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.779753747940221,
            "auditor_fn_violation": 0.003014203919841451,
            "auditor_fp_violation": 0.009363125555825046,
            "ave_precision_score": 0.7802112678969656,
            "fpr": 0.09429824561403509,
            "logloss": 0.6072479491207036,
            "mae": 0.4026202526190821,
            "precision": 0.7584269662921348,
            "recall": 0.5648535564853556
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8048484634985489,
            "auditor_fn_violation": 0.0046490605023568245,
            "auditor_fp_violation": 0.016730383436163367,
            "ave_precision_score": 0.805107196968881,
            "fpr": 0.08562019758507135,
            "logloss": 0.6049647097756645,
            "mae": 0.3992550396222584,
            "precision": 0.7732558139534884,
            "recall": 0.5588235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7289667479680549,
            "auditor_fn_violation": 0.008340673860383174,
            "auditor_fp_violation": 0.02605050933786078,
            "ave_precision_score": 0.7298225444353237,
            "fpr": 0.17653508771929824,
            "logloss": 0.9131855680805286,
            "mae": 0.29923045470314447,
            "precision": 0.7078039927404719,
            "recall": 0.8158995815899581
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7217257232960421,
            "auditor_fn_violation": 0.005617614773681154,
            "auditor_fp_violation": 0.03277943904008479,
            "ave_precision_score": 0.7224345967366573,
            "fpr": 0.1942919868276619,
            "logloss": 0.986508177893916,
            "mae": 0.30204576517783827,
            "precision": 0.6963979416809606,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 30132,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6823263799590441,
            "auditor_fn_violation": 0.004934210526315792,
            "auditor_fp_violation": 0.026083353545153228,
            "ave_precision_score": 0.6623445706675731,
            "fpr": 0.24451754385964913,
            "logloss": 2.45363852340041,
            "mae": 0.3415787393564722,
            "precision": 0.6600609756097561,
            "recall": 0.9058577405857741
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6539473299529501,
            "auditor_fn_violation": 0.008876108072208028,
            "auditor_fp_violation": 0.026836746281085587,
            "ave_precision_score": 0.6359888265131587,
            "fpr": 0.27991218441273324,
            "logloss": 2.8828853453575047,
            "mae": 0.3531302710444693,
            "precision": 0.6357142857142857,
            "recall": 0.9348739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6596495209329319,
            "auditor_fn_violation": 0.007732786464068117,
            "auditor_fp_violation": 0.03263703613873393,
            "ave_precision_score": 0.6258428368978479,
            "fpr": 0.16666666666666666,
            "logloss": 3.183194891140802,
            "mae": 0.39450723238212776,
            "precision": 0.6853002070393375,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6382044046758966,
            "auditor_fn_violation": 0.018015109446632666,
            "auditor_fp_violation": 0.03358189182028085,
            "ave_precision_score": 0.604174744450562,
            "fpr": 0.17672886937431395,
            "logloss": 3.623344674626291,
            "mae": 0.4030691910409933,
            "precision": 0.6714285714285714,
            "recall": 0.6911764705882353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7859551073261406,
            "auditor_fn_violation": 0.005815073772296863,
            "auditor_fp_violation": 0.010110962891098713,
            "ave_precision_score": 0.7864065664932418,
            "fpr": 0.09100877192982457,
            "logloss": 0.6011197360206894,
            "mae": 0.3956666325388165,
            "precision": 0.7614942528735632,
            "recall": 0.5543933054393305
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.80905726704084,
            "auditor_fn_violation": 0.00950797443016724,
            "auditor_fp_violation": 0.012400166546803438,
            "ave_precision_score": 0.8093117827221349,
            "fpr": 0.08122941822173436,
            "logloss": 0.5945991038890138,
            "mae": 0.3927848984072969,
            "precision": 0.7791044776119403,
            "recall": 0.5483193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6794420208644292,
            "auditor_fn_violation": 0.0008602180136533825,
            "auditor_fp_violation": 0.02781904357668365,
            "ave_precision_score": 0.6583921962556465,
            "fpr": 0.2225877192982456,
            "logloss": 2.542529127874384,
            "mae": 0.34407906141731665,
            "precision": 0.6535836177474402,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6558196473575555,
            "auditor_fn_violation": 0.010880092981210046,
            "auditor_fp_violation": 0.028169120708580946,
            "ave_precision_score": 0.6332420888557423,
            "fpr": 0.23819978046103182,
            "logloss": 3.0297186191881473,
            "mae": 0.3462191647678042,
            "precision": 0.651685393258427,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7809958147791797,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.004825571994502388,
            "ave_precision_score": 0.7813784200304725,
            "fpr": 0.4473684210526316,
            "logloss": 0.703219951541222,
            "mae": 0.45116631716097655,
            "precision": 0.5363636363636364,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7910951094069201,
            "auditor_fn_violation": 0.00146205573338007,
            "auditor_fp_violation": 0.006757762721273853,
            "ave_precision_score": 0.7913654526739594,
            "fpr": 0.4522502744237102,
            "logloss": 0.6966149155095287,
            "mae": 0.4504932706887322,
            "precision": 0.5334088335220838,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.6925170754085436,
            "auditor_fn_violation": 0.002550833149820163,
            "auditor_fp_violation": 0.034213558088770316,
            "ave_precision_score": 0.672520354251309,
            "fpr": 0.17324561403508773,
            "logloss": 2.330696488856033,
            "mae": 0.2969322193878689,
            "precision": 0.7079482439926063,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6561953110910265,
            "auditor_fn_violation": 0.013347600291488715,
            "auditor_fp_violation": 0.03443228989237545,
            "ave_precision_score": 0.6383076657389033,
            "fpr": 0.20856201975850713,
            "logloss": 2.7046891544724927,
            "mae": 0.31304284508499985,
            "precision": 0.676320272572402,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5265062288500906,
            "auditor_fn_violation": 0.006225684504147404,
            "auditor_fp_violation": 0.006755800792303339,
            "ave_precision_score": 0.5280460035851671,
            "fpr": 0.03070175438596491,
            "logloss": 1.018392434733306,
            "mae": 0.5190680143831853,
            "precision": 0.6266666666666667,
            "recall": 0.09832635983263599
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5073345331392558,
            "auditor_fn_violation": 0.001524319936536646,
            "auditor_fp_violation": 0.0038154358605549045,
            "ave_precision_score": 0.5091688382320434,
            "fpr": 0.036223929747530186,
            "logloss": 1.0128419394660955,
            "mae": 0.522502228676962,
            "precision": 0.484375,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.673822855379221,
            "auditor_fn_violation": 0.001738787344931371,
            "auditor_fp_violation": 0.029387986094267935,
            "ave_precision_score": 0.6536228905787139,
            "fpr": 0.18640350877192982,
            "logloss": 2.4865127725214826,
            "mae": 0.3134062777385215,
            "precision": 0.6869244935543278,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6432403701626757,
            "auditor_fn_violation": 0.00477589499026834,
            "auditor_fp_violation": 0.0334986184185624,
            "ave_precision_score": 0.6232322442093545,
            "fpr": 0.21953896816684962,
            "logloss": 2.954838906446726,
            "mae": 0.3227370084053218,
            "precision": 0.6649916247906198,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.789627938678034,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.008135257498585177,
            "ave_precision_score": 0.7904094197892464,
            "fpr": 0.4407894736842105,
            "logloss": 0.66927199946158,
            "mae": 0.43773421723591655,
            "precision": 0.540045766590389,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.8061550394567863,
            "auditor_fn_violation": 0.002921805385161749,
            "auditor_fp_violation": 0.006760286157689548,
            "ave_precision_score": 0.8064311561042945,
            "fpr": 0.4478594950603732,
            "logloss": 0.6622523790275273,
            "mae": 0.43835571386189937,
            "precision": 0.5347776510832383,
            "recall": 0.9852941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 30132,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6770008724357569,
            "auditor_fn_violation": 0.00011010790574764008,
            "auditor_fp_violation": 0.030772495755517836,
            "ave_precision_score": 0.6565022291921111,
            "fpr": 0.19188596491228072,
            "logloss": 2.5839842049843957,
            "mae": 0.31536033856280665,
            "precision": 0.6812386156648452,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6435649397434695,
            "auditor_fn_violation": 0.005151786290806113,
            "auditor_fp_violation": 0.03258261099965933,
            "ave_precision_score": 0.6231367578455497,
            "fpr": 0.22063666300768386,
            "logloss": 3.091096912481633,
            "mae": 0.32319365271832273,
            "precision": 0.6621848739495798,
            "recall": 0.8277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6599021325562047,
            "auditor_fn_violation": 0.008088343243044853,
            "auditor_fp_violation": 0.03165170991996119,
            "ave_precision_score": 0.6260952879583171,
            "fpr": 0.1600877192982456,
            "logloss": 3.183871230368853,
            "mae": 0.3931085165169519,
            "precision": 0.690677966101695,
            "recall": 0.6820083682008368
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6384897574008239,
            "auditor_fn_violation": 0.014994142552740085,
            "auditor_fp_violation": 0.035338203565615664,
            "ave_precision_score": 0.6044581325728243,
            "fpr": 0.17453347969264543,
            "logloss": 3.6201380960416993,
            "mae": 0.40192634637114444,
            "precision": 0.6714876033057852,
            "recall": 0.6827731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8396484502748967,
            "auditor_fn_violation": 0.007588269837774357,
            "auditor_fp_violation": 0.016790969358881074,
            "ave_precision_score": 0.8399528280170725,
            "fpr": 0.14912280701754385,
            "logloss": 0.6036638629637125,
            "mae": 0.27759925074209796,
            "precision": 0.7409523809523809,
            "recall": 0.8138075313807531
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8546084387006233,
            "auditor_fn_violation": 0.0059658330950382345,
            "auditor_fp_violation": 0.016881789621106025,
            "ave_precision_score": 0.8548456104676074,
            "fpr": 0.14818880351262348,
            "logloss": 0.5910150165088758,
            "mae": 0.27593180887543206,
            "precision": 0.7423664122137404,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6738639330200218,
            "auditor_fn_violation": 0.002092050209205024,
            "auditor_fp_violation": 0.029387986094267935,
            "ave_precision_score": 0.6536639505094317,
            "fpr": 0.18640350877192982,
            "logloss": 2.4704050623715252,
            "mae": 0.31384267510595654,
            "precision": 0.6880733944954128,
            "recall": 0.7845188284518828
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6429287566116462,
            "auditor_fn_violation": 0.00659539337139906,
            "auditor_fp_violation": 0.0334986184185624,
            "ave_precision_score": 0.6229074341807116,
            "fpr": 0.21953896816684962,
            "logloss": 2.9408606760113316,
            "mae": 0.3233617741887603,
            "precision": 0.6666666666666666,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.5996112057280947,
            "auditor_fn_violation": 0.06358272773985173,
            "auditor_fp_violation": 0.06490520656479909,
            "ave_precision_score": 0.5929386372083962,
            "fpr": 0.2138157894736842,
            "logloss": 1.4436605952230785,
            "mae": 0.43779742398315613,
            "precision": 0.643510054844607,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.5908539653968177,
            "auditor_fn_violation": 0.06950991153870988,
            "auditor_fp_violation": 0.07246300011355464,
            "ave_precision_score": 0.585858825235735,
            "fpr": 0.2217343578485181,
            "logloss": 1.413724334912117,
            "mae": 0.43449677386281255,
            "precision": 0.6366906474820144,
            "recall": 0.7436974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5438818479056008,
            "auditor_fn_violation": 0.08980905454011598,
            "auditor_fp_violation": 0.10502819548872182,
            "ave_precision_score": 0.5382225189580875,
            "fpr": 0.3059210526315789,
            "logloss": 1.4343696465276314,
            "mae": 0.4915764009612694,
            "precision": 0.5626959247648903,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5455859391458886,
            "auditor_fn_violation": 0.09572083498602517,
            "auditor_fp_violation": 0.10543169688481775,
            "ave_precision_score": 0.5412167429130459,
            "fpr": 0.29308452250274425,
            "logloss": 1.4025168344775774,
            "mae": 0.48945607645713146,
            "precision": 0.5658536585365853,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5432054571849676,
            "auditor_fn_violation": 0.08980905454011598,
            "auditor_fp_violation": 0.10502819548872182,
            "ave_precision_score": 0.5369978291785742,
            "fpr": 0.3059210526315789,
            "logloss": 1.449789793225354,
            "mae": 0.49255863577127457,
            "precision": 0.5626959247648903,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5457424746028664,
            "auditor_fn_violation": 0.09572083498602517,
            "auditor_fp_violation": 0.10543169688481775,
            "ave_precision_score": 0.540983601848692,
            "fpr": 0.29308452250274425,
            "logloss": 1.3997434178103403,
            "mae": 0.4903562953521863,
            "precision": 0.5658536585365853,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5579077979324187,
            "auditor_fn_violation": 0.09817496146223299,
            "auditor_fp_violation": 0.07714598997493735,
            "ave_precision_score": 0.5586788138686734,
            "fpr": 0.24451754385964913,
            "logloss": 0.9024939126430893,
            "mae": 0.5142500217464802,
            "precision": 0.4920273348519362,
            "recall": 0.45188284518828453
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0.5128726588151449,
            "auditor_fn_violation": 0.0876449372284589,
            "auditor_fp_violation": 0.06733790075324576,
            "ave_precision_score": 0.5143578513900399,
            "fpr": 0.2579582875960483,
            "logloss": 0.9030161283048778,
            "mae": 0.5183808290973125,
            "precision": 0.48123620309050774,
            "recall": 0.4579831932773109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5916510791136087,
            "auditor_fn_violation": 0.09733309476620422,
            "auditor_fp_violation": 0.08415696499312798,
            "ave_precision_score": 0.5931550174012332,
            "fpr": 0.27521929824561403,
            "logloss": 0.679870130191995,
            "mae": 0.4862858133323435,
            "precision": 0.5702054794520548,
            "recall": 0.696652719665272
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5816630950903297,
            "auditor_fn_violation": 0.10707598077650379,
            "auditor_fp_violation": 0.09075791412745879,
            "ave_precision_score": 0.5827305618610825,
            "fpr": 0.265642151481888,
            "logloss": 0.6849538161553903,
            "mae": 0.48816036646717337,
            "precision": 0.5686274509803921,
            "recall": 0.6701680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7738291569539825,
            "auditor_fn_violation": 0.012313734126110257,
            "auditor_fp_violation": 0.010762794081979143,
            "ave_precision_score": 0.7743661489761794,
            "fpr": 0.11403508771929824,
            "logloss": 0.6361812496176654,
            "mae": 0.4031559531168569,
            "precision": 0.7333333333333333,
            "recall": 0.5983263598326359
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8038269227760371,
            "auditor_fn_violation": 0.0027949708972502324,
            "auditor_fp_violation": 0.010283003394021982,
            "ave_precision_score": 0.8051193456861911,
            "fpr": 0.09330406147091108,
            "logloss": 0.6475151755866937,
            "mae": 0.39782579863520223,
            "precision": 0.7696476964769647,
            "recall": 0.5966386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.6929953807895864,
            "auditor_fn_violation": 0.0020507597445496594,
            "auditor_fp_violation": 0.03399122807017544,
            "ave_precision_score": 0.6730130525155303,
            "fpr": 0.1699561403508772,
            "logloss": 2.3266688452073514,
            "mae": 0.2967696286325064,
            "precision": 0.712430426716141,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6566814135695431,
            "auditor_fn_violation": 0.013347600291488715,
            "auditor_fp_violation": 0.03327150914114842,
            "ave_precision_score": 0.6387847352625612,
            "fpr": 0.2074643249176729,
            "logloss": 2.7016441494835894,
            "mae": 0.313133775234299,
            "precision": 0.6774744027303754,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5429963882049649,
            "auditor_fn_violation": 0.09483272773985171,
            "auditor_fp_violation": 0.09013461072034927,
            "ave_precision_score": 0.5451284504523959,
            "fpr": 0.27850877192982454,
            "logloss": 0.6836009014269725,
            "mae": 0.49366276038059015,
            "precision": 0.5658119658119658,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.5922171114710942,
            "auditor_fn_violation": 0.08107260467304375,
            "auditor_fp_violation": 0.08787614974071692,
            "ave_precision_score": 0.5935031959909067,
            "fpr": 0.2667398463227223,
            "logloss": 0.6791738139587363,
            "mae": 0.4912617656389,
            "precision": 0.5831903945111492,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5471437517850838,
            "auditor_fn_violation": 0.08980905454011598,
            "auditor_fp_violation": 0.10502819548872182,
            "ave_precision_score": 0.5409319905848617,
            "fpr": 0.3059210526315789,
            "logloss": 1.4405838523328174,
            "mae": 0.4896089926427394,
            "precision": 0.5626959247648903,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5489558503656311,
            "auditor_fn_violation": 0.09572083498602517,
            "auditor_fp_violation": 0.10543169688481775,
            "ave_precision_score": 0.5439065336805678,
            "fpr": 0.29308452250274425,
            "logloss": 1.4070014930871482,
            "mae": 0.4877073098746927,
            "precision": 0.5658536585365853,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5439527321026434,
            "auditor_fn_violation": 0.08980905454011598,
            "auditor_fp_violation": 0.10502819548872182,
            "ave_precision_score": 0.5377619696946578,
            "fpr": 0.3059210526315789,
            "logloss": 1.4559278764252073,
            "mae": 0.49193368839067325,
            "precision": 0.5626959247648903,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5462578510437218,
            "auditor_fn_violation": 0.09572083498602517,
            "auditor_fp_violation": 0.10543169688481775,
            "ave_precision_score": 0.5415267437948612,
            "fpr": 0.29308452250274425,
            "logloss": 1.4043332402972475,
            "mae": 0.48976789871240944,
            "precision": 0.5658536585365853,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6865372451951134,
            "auditor_fn_violation": 0.0011286060339132367,
            "auditor_fp_violation": 0.0331675964103808,
            "ave_precision_score": 0.6663260178719447,
            "fpr": 0.17982456140350878,
            "logloss": 2.4276975236303393,
            "mae": 0.2994446098376405,
            "precision": 0.7023593466424682,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6524536813036887,
            "auditor_fn_violation": 0.012314475735409426,
            "auditor_fp_violation": 0.03216876742748275,
            "ave_precision_score": 0.6325602784171835,
            "fpr": 0.21295279912184412,
            "logloss": 2.923034722604973,
            "mae": 0.3138217016571461,
            "precision": 0.676126878130217,
            "recall": 0.8508403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6595041553351417,
            "auditor_fn_violation": 0.009060963077148938,
            "auditor_fp_violation": 0.03250313283208021,
            "ave_precision_score": 0.6256869526419995,
            "fpr": 0.1699561403508772,
            "logloss": 3.1815727648063468,
            "mae": 0.39449456513866127,
            "precision": 0.6843177189409368,
            "recall": 0.702928870292887
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6376164656894632,
            "auditor_fn_violation": 0.018234187198479832,
            "auditor_fp_violation": 0.032199048664471284,
            "ave_precision_score": 0.6035817819549061,
            "fpr": 0.1800219538968167,
            "logloss": 3.6265910285042158,
            "mae": 0.40312218862617666,
            "precision": 0.6739562624254473,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5517719700749493,
            "auditor_fn_violation": 0.08980905454011598,
            "auditor_fp_violation": 0.10502819548872182,
            "ave_precision_score": 0.5450176876264925,
            "fpr": 0.3059210526315789,
            "logloss": 1.4671840031604042,
            "mae": 0.4855823158694987,
            "precision": 0.5626959247648903,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5541912339628018,
            "auditor_fn_violation": 0.09572083498602517,
            "auditor_fp_violation": 0.10502037674905687,
            "ave_precision_score": 0.5482528365661581,
            "fpr": 0.29198682766191,
            "logloss": 1.4187556398519383,
            "mae": 0.48351286509320646,
            "precision": 0.5667752442996743,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5482208005185888,
            "auditor_fn_violation": 0.08980905454011598,
            "auditor_fp_violation": 0.10502819548872182,
            "ave_precision_score": 0.5419818635572818,
            "fpr": 0.3059210526315789,
            "logloss": 1.4534731009986905,
            "mae": 0.4884290686694154,
            "precision": 0.5626959247648903,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5498039266684642,
            "auditor_fn_violation": 0.09572083498602517,
            "auditor_fp_violation": 0.10543169688481775,
            "ave_precision_score": 0.5447264675024505,
            "fpr": 0.29308452250274425,
            "logloss": 1.416860123370888,
            "mae": 0.4866476573876047,
            "precision": 0.5658536585365853,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.5996109421940126,
            "auditor_fn_violation": 0.06358272773985173,
            "auditor_fp_violation": 0.06490520656479909,
            "ave_precision_score": 0.5929384779581615,
            "fpr": 0.2138157894736842,
            "logloss": 1.440473641918211,
            "mae": 0.43796209220594745,
            "precision": 0.643510054844607,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.5909689482263423,
            "auditor_fn_violation": 0.06950991153870988,
            "auditor_fp_violation": 0.07246300011355464,
            "ave_precision_score": 0.5859801458884301,
            "fpr": 0.2217343578485181,
            "logloss": 1.4114634525697138,
            "mae": 0.4346630235011439,
            "precision": 0.6366906474820144,
            "recall": 0.7436974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.6930082453769846,
            "auditor_fn_violation": 0.0020507597445496594,
            "auditor_fp_violation": 0.03399122807017544,
            "ave_precision_score": 0.6730170064591467,
            "fpr": 0.1699561403508772,
            "logloss": 2.326867712803168,
            "mae": 0.29680301131610687,
            "precision": 0.712430426716141,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6567198198459718,
            "auditor_fn_violation": 0.013347600291488715,
            "auditor_fp_violation": 0.0354643753864012,
            "ave_precision_score": 0.6388108623713121,
            "fpr": 0.20636663007683864,
            "logloss": 2.701770041132426,
            "mae": 0.31312780630234793,
            "precision": 0.6786324786324787,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6949235235345699,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.6930803017714213,
            "fpr": 0.44846491228070173,
            "logloss": 0.7159368011791893,
            "mae": 0.47271748994918245,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7372579856908252,
            "auditor_fn_violation": 0.0012752631239103763,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.7339234283977003,
            "fpr": 0.45334796926454446,
            "logloss": 0.7083792715413141,
            "mae": 0.47002130053307695,
            "precision": 0.5317460317460317,
            "recall": 0.9852941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6631052569034914,
            "auditor_fn_violation": 0.010184981281656024,
            "auditor_fp_violation": 0.036876465356940745,
            "ave_precision_score": 0.6322634889919079,
            "fpr": 0.13157894736842105,
            "logloss": 3.04910641571731,
            "mae": 0.38577016563784794,
            "precision": 0.7209302325581395,
            "recall": 0.6485355648535565
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6448298981146462,
            "auditor_fn_violation": 0.023987860786466073,
            "auditor_fp_violation": 0.04104621673795374,
            "ave_precision_score": 0.6147046620260981,
            "fpr": 0.14050493962678376,
            "logloss": 3.362917310866681,
            "mae": 0.3917080261097277,
            "precision": 0.7104072398190046,
            "recall": 0.6596638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7945315811054756,
            "auditor_fn_violation": 0.009586269544153266,
            "auditor_fp_violation": 0.005396555905893767,
            "ave_precision_score": 0.7949470110469234,
            "fpr": 0.09320175438596491,
            "logloss": 0.5886366198009384,
            "mae": 0.4012742773793115,
            "precision": 0.76775956284153,
            "recall": 0.5878661087866108
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8260069434805533,
            "auditor_fn_violation": 0.0012914056950991263,
            "auditor_fp_violation": 0.011953518301222611,
            "ave_precision_score": 0.826234800737222,
            "fpr": 0.0845225027442371,
            "logloss": 0.6244404898114059,
            "mae": 0.3964143053482312,
            "precision": 0.7843137254901961,
            "recall": 0.5882352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6731676088505354,
            "auditor_fn_violation": 0.0017066725390883063,
            "auditor_fp_violation": 0.026032823995472562,
            "ave_precision_score": 0.6531944280334094,
            "fpr": 0.26096491228070173,
            "logloss": 2.533473628473322,
            "mae": 0.35342750881452384,
            "precision": 0.6447761194029851,
            "recall": 0.9037656903765691
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6470810519113865,
            "auditor_fn_violation": 0.008145080205517994,
            "auditor_fp_violation": 0.02625383246905636,
            "ave_precision_score": 0.627481959843037,
            "fpr": 0.283205268935236,
            "logloss": 3.000710197336886,
            "mae": 0.35823110992453877,
            "precision": 0.6303724928366762,
            "recall": 0.9243697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7542113719040046,
            "auditor_fn_violation": 0.007418520149746755,
            "auditor_fp_violation": 0.036588446923761016,
            "ave_precision_score": 0.7008891591802662,
            "fpr": 0.2050438596491228,
            "logloss": 3.341169055043574,
            "mae": 0.3099370071204089,
            "precision": 0.6929392446633826,
            "recall": 0.8828451882845189
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.734799565536111,
            "auditor_fn_violation": 0.013172338090010982,
            "auditor_fp_violation": 0.03233279079450396,
            "ave_precision_score": 0.667316601950071,
            "fpr": 0.24039517014270034,
            "logloss": 4.299275716329033,
            "mae": 0.3251804076395847,
            "precision": 0.6599378881987578,
            "recall": 0.8928571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.690826079988839,
            "auditor_fn_violation": 0.0009703259194010137,
            "auditor_fp_violation": 0.03357941224027812,
            "ave_precision_score": 0.670858359719124,
            "fpr": 0.1875,
            "logloss": 2.432061170988507,
            "mae": 0.30539428451460515,
            "precision": 0.7061855670103093,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6593196017060265,
            "auditor_fn_violation": 0.011129149793836309,
            "auditor_fp_violation": 0.03423041497911856,
            "ave_precision_score": 0.6400171529866141,
            "fpr": 0.22502744237102085,
            "logloss": 2.8775887859417306,
            "mae": 0.3197969246540565,
            "precision": 0.6672077922077922,
            "recall": 0.8634453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6691643707288204,
            "auditor_fn_violation": 0.003055494384496807,
            "auditor_fp_violation": 0.022556390977443604,
            "ave_precision_score": 0.6492033591094057,
            "fpr": 0.2719298245614035,
            "logloss": 2.5811460560031123,
            "mae": 0.3572820046866851,
            "precision": 0.6390101892285298,
            "recall": 0.9184100418410042
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6464704007999337,
            "auditor_fn_violation": 0.005580717468106893,
            "auditor_fp_violation": 0.022983458874295017,
            "ave_precision_score": 0.6263259924638993,
            "fpr": 0.2996706915477497,
            "logloss": 3.057177239565127,
            "mae": 0.361341991814635,
            "precision": 0.6192468619246861,
            "recall": 0.9327731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5572079305944235,
            "auditor_fn_violation": 0.0010850216545547995,
            "auditor_fp_violation": 0.003612862802166707,
            "ave_precision_score": 0.5580759072459562,
            "fpr": 0.017543859649122806,
            "logloss": 1.0158078148729726,
            "mae": 0.5176915531577706,
            "precision": 0.7192982456140351,
            "recall": 0.08577405857740586
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5124598429048826,
            "auditor_fn_violation": 0.0013605881430508529,
            "auditor_fp_violation": 0.0033561704328955184,
            "ave_precision_score": 0.5144457270383481,
            "fpr": 0.027442371020856202,
            "logloss": 1.0095711382858508,
            "mae": 0.5211781750378964,
            "precision": 0.5535714285714286,
            "recall": 0.06512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7724904378928382,
            "auditor_fn_violation": 0.0003027967408059901,
            "auditor_fp_violation": 0.00685685989166464,
            "ave_precision_score": 0.7740646552701336,
            "fpr": 0.44846491228070173,
            "logloss": 0.8890510605864937,
            "mae": 0.44573857184303434,
            "precision": 0.5357548240635641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7856689612855051,
            "auditor_fn_violation": 0.0019186598898615428,
            "auditor_fp_violation": 0.005892224030684988,
            "ave_precision_score": 0.7859563339363058,
            "fpr": 0.45334796926454446,
            "logloss": 0.885762216019222,
            "mae": 0.4491024124839892,
            "precision": 0.5322763306908267,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.672117264537047,
            "auditor_fn_violation": 0.005555861410849301,
            "auditor_fp_violation": 0.02209657207534967,
            "ave_precision_score": 0.6519102263823646,
            "fpr": 0.2642543859649123,
            "logloss": 2.5508954805902313,
            "mae": 0.3529116383270185,
            "precision": 0.6440177252584933,
            "recall": 0.9121338912133892
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6473231422121334,
            "auditor_fn_violation": 0.005723694527207151,
            "auditor_fp_violation": 0.026152895012427943,
            "ave_precision_score": 0.626873192714199,
            "fpr": 0.287596048298573,
            "logloss": 3.0603777453036773,
            "mae": 0.3581042383283374,
            "precision": 0.6278409090909091,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8398614551312237,
            "auditor_fn_violation": 0.010428136240182049,
            "auditor_fp_violation": 0.01648273910582909,
            "ave_precision_score": 0.8401782953204732,
            "fpr": 0.13815789473684212,
            "logloss": 0.5934392800720092,
            "mae": 0.2770590313652575,
            "precision": 0.75,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8549864984108507,
            "auditor_fn_violation": 0.008320342406995732,
            "auditor_fp_violation": 0.01659159443329927,
            "ave_precision_score": 0.8552227718566032,
            "fpr": 0.13611416026344675,
            "logloss": 0.5769668987400357,
            "mae": 0.2739317258181794,
            "precision": 0.7549407114624506,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    }
]