[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5758903162627431,
            "auditor_fn_violation": 0.029684554878932887,
            "auditor_fp_violation": 0.0308657156910969,
            "ave_precision_score": 0.5714582561047216,
            "fpr": 0.08771929824561403,
            "logloss": 10.819576832240644,
            "mae": 0.5050127523734759,
            "precision": 0.6208530805687204,
            "recall": 0.2706611570247934
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.561645497737958,
            "auditor_fn_violation": 0.03780274190158115,
            "auditor_fp_violation": 0.03547719856328921,
            "ave_precision_score": 0.5556869211073271,
            "fpr": 0.1119648737650933,
            "logloss": 9.820067129989427,
            "mae": 0.48927413040588924,
            "precision": 0.592,
            "recall": 0.3148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5666746301709293,
            "auditor_fn_violation": 0.02975478468899523,
            "auditor_fp_violation": 0.02805275454992622,
            "ave_precision_score": 0.5619104649982051,
            "fpr": 0.08442982456140351,
            "logloss": 10.848778458379531,
            "mae": 0.5057662897939778,
            "precision": 0.6280193236714976,
            "recall": 0.26859504132231404
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5678383809278934,
            "auditor_fn_violation": 0.03596935796529417,
            "auditor_fp_violation": 0.03402854006586169,
            "ave_precision_score": 0.5618527308539789,
            "fpr": 0.10757409440175632,
            "logloss": 9.846399440447357,
            "mae": 0.48831997117441517,
            "precision": 0.5933609958506224,
            "recall": 0.30425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7576792319545741,
            "auditor_fn_violation": 0.012473720458170226,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6396857750757828,
            "fpr": 0.09868421052631579,
            "logloss": 0.704656761017547,
            "mae": 0.4211531904967208,
            "precision": 0.7383720930232558,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7378567143307565,
            "auditor_fn_violation": 0.014092533339561392,
            "auditor_fp_violation": 0.008082120517434933,
            "ave_precision_score": 0.6171429499381087,
            "fpr": 0.09769484083424808,
            "logloss": 0.7179141151719207,
            "mae": 0.4312166774770169,
            "precision": 0.721875,
            "recall": 0.49148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5580906538040764,
            "auditor_fn_violation": 0.10722506162099463,
            "auditor_fp_violation": 0.09468765371372356,
            "ave_precision_score": 0.5609886781599432,
            "fpr": 0.2532894736842105,
            "logloss": 0.7957623275953575,
            "mae": 0.4736992514839298,
            "precision": 0.5815217391304348,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5526326550034557,
            "auditor_fn_violation": 0.10338183431814467,
            "auditor_fp_violation": 0.09330406147091108,
            "ave_precision_score": 0.5599559258817609,
            "fpr": 0.27991218441273324,
            "logloss": 0.8111392805307132,
            "mae": 0.47483641095663925,
            "precision": 0.5603448275862069,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6097348619837594,
            "auditor_fn_violation": 0.13261880165289258,
            "auditor_fp_violation": 0.11236473192326611,
            "ave_precision_score": 0.5671262608673137,
            "fpr": 0.18640350877192982,
            "logloss": 0.6881853320336794,
            "mae": 0.49596411094330906,
            "precision": 0.592326139088729,
            "recall": 0.5103305785123967
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5920886510785197,
            "auditor_fn_violation": 0.12643576149660182,
            "auditor_fp_violation": 0.11788396295217686,
            "ave_precision_score": 0.5590204924081484,
            "fpr": 0.2030735455543359,
            "logloss": 0.6887364822856269,
            "mae": 0.49626076751430526,
            "precision": 0.5916114790286976,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5661477628933698,
            "auditor_fn_violation": 0.02975478468899523,
            "auditor_fp_violation": 0.02805275454992622,
            "ave_precision_score": 0.5617901036750149,
            "fpr": 0.08442982456140351,
            "logloss": 10.843975147711557,
            "mae": 0.505721274798189,
            "precision": 0.6280193236714976,
            "recall": 0.26859504132231404
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.567940179266291,
            "auditor_fn_violation": 0.03596935796529417,
            "auditor_fp_violation": 0.033356482000044804,
            "ave_precision_score": 0.5619500252768053,
            "fpr": 0.10867178924259056,
            "logloss": 9.841020779828867,
            "mae": 0.4882477722279076,
            "precision": 0.5909090909090909,
            "recall": 0.30425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.699352454233971,
            "auditor_fn_violation": 0.023726348412353205,
            "auditor_fp_violation": 0.02537301196917528,
            "ave_precision_score": 0.7001440105238863,
            "fpr": 0.1206140350877193,
            "logloss": 0.7228742134757444,
            "mae": 0.4172985833791787,
            "precision": 0.7157622739018088,
            "recall": 0.5723140495867769
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6800807383293405,
            "auditor_fn_violation": 0.02586122334586731,
            "auditor_fp_violation": 0.024268763487832013,
            "ave_precision_score": 0.6806571048680793,
            "fpr": 0.1207464324917673,
            "logloss": 0.7352378045186452,
            "mae": 0.42737757485732025,
            "precision": 0.7018970189701897,
            "recall": 0.551063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7437615746255837,
            "auditor_fn_violation": 0.004897962882412645,
            "auditor_fp_violation": 0.014174967207738979,
            "ave_precision_score": 0.7440300638836627,
            "fpr": 0.17434210526315788,
            "logloss": 0.6506159815242127,
            "mae": 0.42674485022169456,
            "precision": 0.6701244813278008,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7105349828451027,
            "auditor_fn_violation": 0.017376275778312352,
            "auditor_fp_violation": 0.012318575436028795,
            "ave_precision_score": 0.7116916839411105,
            "fpr": 0.17672886937431395,
            "logloss": 0.6709835629299676,
            "mae": 0.43572526126609284,
            "precision": 0.6537634408602151,
            "recall": 0.6468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6855462131520716,
            "auditor_fn_violation": 0.01030792373495724,
            "auditor_fp_violation": 0.010367990654205607,
            "ave_precision_score": 0.6669117638231826,
            "fpr": 0.13706140350877194,
            "logloss": 0.7069263780769314,
            "mae": 0.422617569598451,
            "precision": 0.6736292428198434,
            "recall": 0.5330578512396694
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6701905400872099,
            "auditor_fn_violation": 0.01256977368802112,
            "auditor_fp_violation": 0.003890469469895541,
            "ave_precision_score": 0.6606453592295561,
            "fpr": 0.12623490669593854,
            "logloss": 0.7186133821980224,
            "mae": 0.4318794887819615,
            "precision": 0.670487106017192,
            "recall": 0.4978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8357632524246589,
            "auditor_fn_violation": 0.017376214296070763,
            "auditor_fp_violation": 0.02351819970486966,
            "ave_precision_score": 0.8360859465803512,
            "fpr": 0.18201754385964913,
            "logloss": 0.5307383914846865,
            "mae": 0.34302077594156,
            "precision": 0.7118055555555556,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7878867912677754,
            "auditor_fn_violation": 0.01861410187542331,
            "auditor_fp_violation": 0.006944600013441168,
            "ave_precision_score": 0.7892456719772032,
            "fpr": 0.19758507135016465,
            "logloss": 0.6751348890989844,
            "mae": 0.3558350592058328,
            "precision": 0.6896551724137931,
            "recall": 0.851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7516078759781412,
            "auditor_fn_violation": 0.010346436856604323,
            "auditor_fp_violation": 0.015376496146909339,
            "ave_precision_score": 0.7511912607605117,
            "fpr": 0.16557017543859648,
            "logloss": 1.0461372717430912,
            "mae": 0.3391953343877838,
            "precision": 0.6731601731601732,
            "recall": 0.6425619834710744
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7506110246493232,
            "auditor_fn_violation": 0.01515285984538852,
            "auditor_fp_violation": 0.009490953351702922,
            "ave_precision_score": 0.7502929710049591,
            "fpr": 0.16465422612513722,
            "logloss": 0.9890393732753742,
            "mae": 0.3392019576963835,
            "precision": 0.6651785714285714,
            "recall": 0.6340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6097348619837594,
            "auditor_fn_violation": 0.13261880165289258,
            "auditor_fp_violation": 0.11236473192326611,
            "ave_precision_score": 0.5671262608673137,
            "fpr": 0.18640350877192982,
            "logloss": 0.6881853322942484,
            "mae": 0.49596411225042847,
            "precision": 0.592326139088729,
            "recall": 0.5103305785123967
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5920886510785197,
            "auditor_fn_violation": 0.12643576149660182,
            "auditor_fp_violation": 0.11788396295217686,
            "ave_precision_score": 0.5590204924081484,
            "fpr": 0.2030735455543359,
            "logloss": 0.6887364814945575,
            "mae": 0.49626076829943777,
            "precision": 0.5916114790286976,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5588193293656345,
            "auditor_fn_violation": 0.023948365231259986,
            "auditor_fp_violation": 0.027624918019347435,
            "ave_precision_score": 0.5548001825345967,
            "fpr": 0.08662280701754387,
            "logloss": 10.813142719792989,
            "mae": 0.5062047721848421,
            "precision": 0.6201923076923077,
            "recall": 0.2665289256198347
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.563449672016646,
            "auditor_fn_violation": 0.03639909381787609,
            "auditor_fp_violation": 0.035900346234359094,
            "ave_precision_score": 0.5577555044724627,
            "fpr": 0.11306256860592755,
            "logloss": 9.809734761172615,
            "mae": 0.48918802941595135,
            "precision": 0.5813008130081301,
            "recall": 0.30425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7337187679979986,
            "auditor_fn_violation": 0.01409580252283601,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.7342919439269249,
            "fpr": 0.09868421052631579,
            "logloss": 0.7005936175296406,
            "mae": 0.4196110085763952,
            "precision": 0.7471910112359551,
            "recall": 0.5495867768595041
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7368473849185716,
            "auditor_fn_violation": 0.013536679356330435,
            "auditor_fp_violation": 0.010401965396476922,
            "ave_precision_score": 0.7372493864832497,
            "fpr": 0.09989023051591657,
            "logloss": 0.7140621203314846,
            "mae": 0.42977563256620704,
            "precision": 0.7307692307692307,
            "recall": 0.5255319148936171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6855462131520716,
            "auditor_fn_violation": 0.01030792373495724,
            "auditor_fp_violation": 0.010367990654205607,
            "ave_precision_score": 0.6669117638231826,
            "fpr": 0.13706140350877194,
            "logloss": 0.7069265810233225,
            "mae": 0.422617633059098,
            "precision": 0.6736292428198434,
            "recall": 0.5330578512396694
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6701905400872099,
            "auditor_fn_violation": 0.01256977368802112,
            "auditor_fp_violation": 0.003890469469895541,
            "ave_precision_score": 0.6606453592295561,
            "fpr": 0.12623490669593854,
            "logloss": 0.7186135027625788,
            "mae": 0.43187951197608504,
            "precision": 0.670487106017192,
            "recall": 0.4978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6826247184169427,
            "auditor_fn_violation": 0.011019283746556485,
            "auditor_fp_violation": 0.012194622069191675,
            "ave_precision_score": 0.6726605411361649,
            "fpr": 0.19846491228070176,
            "logloss": 0.7099859806938204,
            "mae": 0.42346145918494776,
            "precision": 0.6073752711496746,
            "recall": 0.5785123966942148
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6721789254875626,
            "auditor_fn_violation": 0.008006165775276181,
            "auditor_fp_violation": 0.0045152345607104944,
            "ave_precision_score": 0.6678153618091602,
            "fpr": 0.16245883644346873,
            "logloss": 0.7223011985358411,
            "mae": 0.4330725817400328,
            "precision": 0.6390243902439025,
            "recall": 0.5574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7576792319545741,
            "auditor_fn_violation": 0.012473720458170226,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6396857750757828,
            "fpr": 0.09868421052631579,
            "logloss": 0.704656761017547,
            "mae": 0.4211531904967208,
            "precision": 0.7383720930232558,
            "recall": 0.5247933884297521
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7378567143307565,
            "auditor_fn_violation": 0.014092533339561392,
            "auditor_fp_violation": 0.008082120517434933,
            "ave_precision_score": 0.6171429499381087,
            "fpr": 0.09769484083424808,
            "logloss": 0.7179141151719207,
            "mae": 0.4312166774770169,
            "precision": 0.721875,
            "recall": 0.49148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6315561223888898,
            "auditor_fn_violation": 0.009261273017253876,
            "auditor_fp_violation": 0.010665170519757343,
            "ave_precision_score": 0.6265004808161049,
            "fpr": 0.0756578947368421,
            "logloss": 10.753867973886356,
            "mae": 0.46537183037626145,
            "precision": 0.6790697674418604,
            "recall": 0.30165289256198347
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6251948490989238,
            "auditor_fn_violation": 0.014830557955952077,
            "auditor_fp_violation": 0.015001829491401393,
            "ave_precision_score": 0.6189634012283849,
            "fpr": 0.08562019758507135,
            "logloss": 9.819616162867067,
            "mae": 0.449278753335786,
            "precision": 0.6708860759493671,
            "recall": 0.3382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7210740944979112,
            "auditor_fn_violation": 0.004893431926924759,
            "auditor_fp_violation": 0.02140975979668798,
            "ave_precision_score": 0.720022193519781,
            "fpr": 0.25109649122807015,
            "logloss": 0.7374289196213486,
            "mae": 0.4182874961968577,
            "precision": 0.6176961602671118,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7265152120726333,
            "auditor_fn_violation": 0.014239671158651941,
            "auditor_fp_violation": 0.009177326254321721,
            "ave_precision_score": 0.7259208081749016,
            "fpr": 0.24039517014270034,
            "logloss": 0.7190301791692592,
            "mae": 0.4194249222883147,
            "precision": 0.6171328671328671,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6826247184169427,
            "auditor_fn_violation": 0.010294330868493556,
            "auditor_fp_violation": 0.010493523528447294,
            "ave_precision_score": 0.6726605411361649,
            "fpr": 0.1425438596491228,
            "logloss": 0.7095357637462538,
            "mae": 0.42325395038514807,
            "precision": 0.6666666666666666,
            "recall": 0.5371900826446281
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6721789254875626,
            "auditor_fn_violation": 0.01256977368802112,
            "auditor_fp_violation": 0.004537636496237722,
            "ave_precision_score": 0.6678153618091602,
            "fpr": 0.12952799121844127,
            "logloss": 0.7218174755268616,
            "mae": 0.43284603547709705,
            "precision": 0.6647727272727273,
            "recall": 0.4978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6992251938631859,
            "auditor_fn_violation": 0.022024974626649263,
            "auditor_fp_violation": 0.026013485817347106,
            "ave_precision_score": 0.6875217755819336,
            "fpr": 0.12171052631578948,
            "logloss": 0.7239716406015976,
            "mae": 0.4169322541473727,
            "precision": 0.7175572519083969,
            "recall": 0.5826446280991735
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7023563713863208,
            "auditor_fn_violation": 0.025774809071163328,
            "auditor_fp_violation": 0.024268763487832013,
            "ave_precision_score": 0.6886936786071167,
            "fpr": 0.1207464324917673,
            "logloss": 0.7349465912578,
            "mae": 0.42657894285397785,
            "precision": 0.708994708994709,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7337187679979986,
            "auditor_fn_violation": 0.01409580252283601,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.7342919439269249,
            "fpr": 0.09868421052631579,
            "logloss": 0.7005936170294614,
            "mae": 0.4196110082496154,
            "precision": 0.7471910112359551,
            "recall": 0.5495867768595041
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7368473849185716,
            "auditor_fn_violation": 0.013536679356330435,
            "auditor_fp_violation": 0.010401965396476922,
            "ave_precision_score": 0.7372493864832497,
            "fpr": 0.09989023051591657,
            "logloss": 0.7140621200581667,
            "mae": 0.42977563236992394,
            "precision": 0.7307692307692307,
            "recall": 0.5255319148936171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7246138398001107,
            "auditor_fn_violation": 0.003839984775989562,
            "auditor_fp_violation": 0.017779554025250055,
            "ave_precision_score": 0.7252594826368913,
            "fpr": 0.21929824561403508,
            "logloss": 0.6510601679817704,
            "mae": 0.41867799741796036,
            "precision": 0.6396396396396397,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7255205730597297,
            "auditor_fn_violation": 0.012378260971109608,
            "auditor_fp_violation": 0.005520832555488352,
            "ave_precision_score": 0.7262337544117394,
            "fpr": 0.21844127332601537,
            "logloss": 0.6552977406594569,
            "mae": 0.42407253386430305,
            "precision": 0.6341911764705882,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5757963416345914,
            "auditor_fn_violation": 0.029684554878932887,
            "auditor_fp_violation": 0.0308657156910969,
            "ave_precision_score": 0.5713563973165426,
            "fpr": 0.08771929824561403,
            "logloss": 10.817880095275003,
            "mae": 0.5049787928014792,
            "precision": 0.6208530805687204,
            "recall": 0.2706611570247934
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.5616394067666002,
            "auditor_fn_violation": 0.038919120909918975,
            "auditor_fp_violation": 0.035643968527769694,
            "ave_precision_score": 0.5556732080810655,
            "fpr": 0.11306256860592755,
            "logloss": 9.81808090435878,
            "mae": 0.48913888793233123,
            "precision": 0.5912698412698413,
            "recall": 0.3170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.748194183020008,
            "auditor_fn_violation": 0.009546723212991163,
            "auditor_fp_violation": 0.0177488112805378,
            "ave_precision_score": 0.7478032925840203,
            "fpr": 0.16228070175438597,
            "logloss": 1.1581537735540415,
            "mae": 0.33617093946806337,
            "precision": 0.6768558951965066,
            "recall": 0.640495867768595
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7470143909158979,
            "auditor_fn_violation": 0.011700959899105494,
            "auditor_fp_violation": 0.012074643249176734,
            "ave_precision_score": 0.7466376868375464,
            "fpr": 0.16136114160263446,
            "logloss": 1.0867174584086579,
            "mae": 0.33665451793353823,
            "precision": 0.6666666666666666,
            "recall": 0.625531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8379411132781023,
            "auditor_fn_violation": 0.008921451355661886,
            "auditor_fp_violation": 0.02042599196589605,
            "ave_precision_score": 0.8383164612665205,
            "fpr": 0.1524122807017544,
            "logloss": 0.6414771863143546,
            "mae": 0.27957827351670617,
            "precision": 0.7392120075046904,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8418925295089271,
            "auditor_fn_violation": 0.01802555059906112,
            "auditor_fp_violation": 0.012455476153139631,
            "ave_precision_score": 0.8421046704008444,
            "fpr": 0.15477497255762898,
            "logloss": 0.6157466526754063,
            "mae": 0.28633810244373686,
            "precision": 0.72568093385214,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5580906538040764,
            "auditor_fn_violation": 0.10722506162099463,
            "auditor_fp_violation": 0.09468765371372356,
            "ave_precision_score": 0.5609886781599432,
            "fpr": 0.2532894736842105,
            "logloss": 0.7957623360891531,
            "mae": 0.4736992516799977,
            "precision": 0.5815217391304348,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5526326550034557,
            "auditor_fn_violation": 0.10338183431814467,
            "auditor_fp_violation": 0.09330406147091108,
            "ave_precision_score": 0.5599559258817609,
            "fpr": 0.27991218441273324,
            "logloss": 0.8111392850450967,
            "mae": 0.47483641036778984,
            "precision": 0.5603448275862069,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8362735212780013,
            "auditor_fn_violation": 0.010335109467884594,
            "auditor_fp_violation": 0.01914248237415971,
            "ave_precision_score": 0.8366235814563141,
            "fpr": 0.15350877192982457,
            "logloss": 0.6636014104253396,
            "mae": 0.2802689715834138,
            "precision": 0.7353497164461248,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8415955427233573,
            "auditor_fn_violation": 0.02063432748674592,
            "auditor_fp_violation": 0.015688822180903103,
            "ave_precision_score": 0.8418132411476322,
            "fpr": 0.1437980241492865,
            "logloss": 0.6276807007713513,
            "mae": 0.28374803617361055,
            "precision": 0.738,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 2917,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6015198962812703,
            "auditor_fn_violation": 0.0872412824416413,
            "auditor_fp_violation": 0.07565789473684212,
            "ave_precision_score": 0.6062554112732899,
            "fpr": 0.23464912280701755,
            "logloss": 0.6756062951036234,
            "mae": 0.47935718141104044,
            "precision": 0.6130198915009042,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6160967471065185,
            "auditor_fn_violation": 0.07819324100240559,
            "auditor_fp_violation": 0.07778947656633091,
            "ave_precision_score": 0.6194573372053203,
            "fpr": 0.2678375411635565,
            "logloss": 0.6683472380273561,
            "mae": 0.4753796278154549,
            "precision": 0.5857385398981324,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6454701616310748,
            "auditor_fn_violation": 0.003216978396404237,
            "auditor_fp_violation": 0.001908612067552065,
            "ave_precision_score": 0.6465582615076255,
            "fpr": 0.40460526315789475,
            "logloss": 0.8017631631376223,
            "mae": 0.4704320925827089,
            "precision": 0.5293367346938775,
            "recall": 0.8574380165289256
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.6433693457285568,
            "auditor_fn_violation": 0.006048999229278093,
            "auditor_fp_violation": 0.010401965396476934,
            "ave_precision_score": 0.6444370687398157,
            "fpr": 0.4138309549945115,
            "logloss": 0.812058949126995,
            "mae": 0.47838267046062666,
            "precision": 0.5103896103896104,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7337211179254981,
            "auditor_fn_violation": 0.01409580252283601,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.734296643781924,
            "fpr": 0.09868421052631579,
            "logloss": 0.700593617093405,
            "mae": 0.4196110075306997,
            "precision": 0.7471910112359551,
            "recall": 0.5495867768595041
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7368474564064197,
            "auditor_fn_violation": 0.013536679356330435,
            "auditor_fp_violation": 0.010401965396476922,
            "ave_precision_score": 0.7372442800127939,
            "fpr": 0.09989023051591657,
            "logloss": 0.7140621269724322,
            "mae": 0.4297756322063547,
            "precision": 0.7307692307692307,
            "recall": 0.5255319148936171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8391761639589921,
            "auditor_fn_violation": 0.007874800637958534,
            "auditor_fp_violation": 0.019903365305787835,
            "ave_precision_score": 0.8395449757503353,
            "fpr": 0.15679824561403508,
            "logloss": 0.6292703569571423,
            "mae": 0.2804415383815898,
            "precision": 0.7346938775510204,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.844328153148729,
            "auditor_fn_violation": 0.01939183034775907,
            "auditor_fp_violation": 0.013752299309771484,
            "ave_precision_score": 0.8445389186596122,
            "fpr": 0.15697036223929747,
            "logloss": 0.6019420648681444,
            "mae": 0.28657723916947103,
            "precision": 0.725,
            "recall": 0.8021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5580906538040764,
            "auditor_fn_violation": 0.10722506162099463,
            "auditor_fp_violation": 0.09468765371372356,
            "ave_precision_score": 0.5609886781599432,
            "fpr": 0.2532894736842105,
            "logloss": 0.7957623360891531,
            "mae": 0.4736992516799977,
            "precision": 0.5815217391304348,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5526326550034557,
            "auditor_fn_violation": 0.10338183431814467,
            "auditor_fp_violation": 0.09330406147091108,
            "ave_precision_score": 0.5599559258817609,
            "fpr": 0.27991218441273324,
            "logloss": 0.8111392850450967,
            "mae": 0.47483641036778984,
            "precision": 0.5603448275862069,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7453195566229541,
            "auditor_fn_violation": 0.009476493402928816,
            "auditor_fp_violation": 0.015637809476963443,
            "ave_precision_score": 0.7449984425686176,
            "fpr": 0.1600877192982456,
            "logloss": 1.1521339238879755,
            "mae": 0.33737104054740374,
            "precision": 0.6777041942604857,
            "recall": 0.6342975206611571
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7462838863553714,
            "auditor_fn_violation": 0.013120956629376184,
            "auditor_fp_violation": 0.009879253567508245,
            "ave_precision_score": 0.7459179960512023,
            "fpr": 0.16136114160263446,
            "logloss": 1.083498387664167,
            "mae": 0.33763749813403166,
            "precision": 0.6696629213483146,
            "recall": 0.6340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8253663826291766,
            "auditor_fn_violation": 0.01083351457155285,
            "auditor_fp_violation": 0.021845282013444833,
            "ave_precision_score": 0.8257509942431602,
            "fpr": 0.15460526315789475,
            "logloss": 0.7796135592696407,
            "mae": 0.2777894911219275,
            "precision": 0.7349624060150376,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8295888905348824,
            "auditor_fn_violation": 0.018644463647616603,
            "auditor_fp_violation": 0.015330391212467428,
            "ave_precision_score": 0.8298454466765679,
            "fpr": 0.15148188803512624,
            "logloss": 0.7326330250898379,
            "mae": 0.28189265556946397,
            "precision": 0.7330754352030948,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.711386628694534,
            "auditor_fn_violation": 0.0031444831085979453,
            "auditor_fp_violation": 0.011651500245941958,
            "ave_precision_score": 0.7113041969602116,
            "fpr": 0.2412280701754386,
            "logloss": 0.8077705578952726,
            "mae": 0.4171020965859817,
            "precision": 0.5948434622467772,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7084834514667085,
            "auditor_fn_violation": 0.0016465422612513742,
            "auditor_fp_violation": 0.016609790641466986,
            "ave_precision_score": 0.7084386191567276,
            "fpr": 0.23161361141602635,
            "logloss": 0.7864929858409974,
            "mae": 0.4179819032762498,
            "precision": 0.6033834586466166,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7067923330866228,
            "auditor_fn_violation": 0.022115593736407133,
            "auditor_fp_violation": 0.022713764551565836,
            "ave_precision_score": 0.7079205475465005,
            "fpr": 0.1162280701754386,
            "logloss": 0.7210858384985374,
            "mae": 0.4160249285203846,
            "precision": 0.7210526315789474,
            "recall": 0.5661157024793388
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6878767766002327,
            "auditor_fn_violation": 0.025774809071163314,
            "auditor_fp_violation": 0.022708095312768357,
            "ave_precision_score": 0.6884062970014755,
            "fpr": 0.11745334796926454,
            "logloss": 0.7334601659250487,
            "mae": 0.426359867781368,
            "precision": 0.7052341597796143,
            "recall": 0.5446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7001005276818568,
            "auditor_fn_violation": 0.0028975460345077642,
            "auditor_fp_violation": 0.016224483521888843,
            "ave_precision_score": 0.7008910654795791,
            "fpr": 0.17214912280701755,
            "logloss": 0.7008505779858926,
            "mae": 0.4171770661415761,
            "precision": 0.6673728813559322,
            "recall": 0.6508264462809917
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6898383008073727,
            "auditor_fn_violation": 0.011229184669640574,
            "auditor_fp_violation": 0.006877394206859483,
            "ave_precision_score": 0.690311590032257,
            "fpr": 0.1877058177826564,
            "logloss": 0.7166348857699444,
            "mae": 0.4284494103931308,
            "precision": 0.6241758241758242,
            "recall": 0.6042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6992251938631859,
            "auditor_fn_violation": 0.022024974626649263,
            "auditor_fp_violation": 0.026013485817347106,
            "ave_precision_score": 0.6875217755819336,
            "fpr": 0.12171052631578948,
            "logloss": 0.7239716129545924,
            "mae": 0.4169322578073071,
            "precision": 0.7175572519083969,
            "recall": 0.5826446280991735
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7023563713863208,
            "auditor_fn_violation": 0.025774809071163328,
            "auditor_fp_violation": 0.024268763487832013,
            "ave_precision_score": 0.6886936786071167,
            "fpr": 0.1207464324917673,
            "logloss": 0.734946560684465,
            "mae": 0.4265789459290803,
            "precision": 0.708994708994709,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.822027159846114,
            "auditor_fn_violation": 0.009868421052631582,
            "auditor_fp_violation": 0.021376455156583044,
            "ave_precision_score": 0.8223979122602484,
            "fpr": 0.15679824561403508,
            "logloss": 0.8039021485106324,
            "mae": 0.28002520085375815,
            "precision": 0.7286527514231499,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8286638358095421,
            "auditor_fn_violation": 0.020120512880397973,
            "auditor_fp_violation": 0.01585061393748865,
            "ave_precision_score": 0.8289212092045266,
            "fpr": 0.1525795828759605,
            "logloss": 0.7468002103003757,
            "mae": 0.28060164200269994,
            "precision": 0.7295719844357976,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6535412953073065,
            "auditor_fn_violation": 0.00469860084094534,
            "auditor_fp_violation": 0.0011887194622069394,
            "ave_precision_score": 0.6545864420704877,
            "fpr": 0.4057017543859649,
            "logloss": 0.7897101609936215,
            "mae": 0.47027157671880304,
            "precision": 0.5298602287166455,
            "recall": 0.8615702479338843
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.6440809141337578,
            "auditor_fn_violation": 0.001177102552724389,
            "auditor_fp_violation": 0.011133761957033105,
            "ave_precision_score": 0.6454345305500868,
            "fpr": 0.4149286498353458,
            "logloss": 0.7984573038461246,
            "mae": 0.47784759190943576,
            "precision": 0.5103626943005182,
            "recall": 0.8382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5791164219826257,
            "auditor_fn_violation": 0.10722506162099463,
            "auditor_fp_violation": 0.09468765371372356,
            "ave_precision_score": 0.5746241797307731,
            "fpr": 0.2532894736842105,
            "logloss": 1.208406942756536,
            "mae": 0.4617117085216338,
            "precision": 0.5815217391304348,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5782511403076457,
            "auditor_fn_violation": 0.10338183431814467,
            "auditor_fp_violation": 0.09330406147091108,
            "ave_precision_score": 0.5755155037421728,
            "fpr": 0.27991218441273324,
            "logloss": 1.2610967220199918,
            "mae": 0.4622745402688907,
            "precision": 0.5603448275862069,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6097348619837594,
            "auditor_fn_violation": 0.13261880165289258,
            "auditor_fp_violation": 0.11236473192326611,
            "ave_precision_score": 0.5671262608673137,
            "fpr": 0.18640350877192982,
            "logloss": 0.6881853320336794,
            "mae": 0.49596411094330906,
            "precision": 0.592326139088729,
            "recall": 0.5103305785123967
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5920886510785197,
            "auditor_fn_violation": 0.12643576149660182,
            "auditor_fp_violation": 0.11788396295217686,
            "ave_precision_score": 0.5590204924081484,
            "fpr": 0.2030735455543359,
            "logloss": 0.6887364822856269,
            "mae": 0.49626076751430526,
            "precision": 0.5916114790286976,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7049256632366581,
            "auditor_fn_violation": 0.004331593446425987,
            "auditor_fp_violation": 0.01379324479422857,
            "ave_precision_score": 0.7053940909619278,
            "fpr": 0.16228070175438597,
            "logloss": 0.637585294236833,
            "mae": 0.44078852014060604,
            "precision": 0.6844349680170576,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7099780478441189,
            "auditor_fn_violation": 0.01953429712497373,
            "auditor_fp_violation": 0.005463583164696547,
            "ave_precision_score": 0.7104142046760568,
            "fpr": 0.15916575192096596,
            "logloss": 0.643004135601389,
            "mae": 0.4438534273993956,
            "precision": 0.6756152125279642,
            "recall": 0.6425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7273872507542398,
            "auditor_fn_violation": 0.0017398869073510235,
            "auditor_fp_violation": 0.01840978029185112,
            "ave_precision_score": 0.7260200755696212,
            "fpr": 0.26096491228070173,
            "logloss": 0.7102225704880393,
            "mae": 0.4132666462019347,
            "precision": 0.6222222222222222,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7441642507530032,
            "auditor_fn_violation": 0.014139243758320298,
            "auditor_fp_violation": 0.015188512287461646,
            "ave_precision_score": 0.7425837589555606,
            "fpr": 0.25686059275521406,
            "logloss": 0.6963509913631976,
            "mae": 0.413474203039341,
            "precision": 0.6138613861386139,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7348284003905412,
            "auditor_fn_violation": 0.0035703929244599118,
            "auditor_fp_violation": 0.017203127561895393,
            "ave_precision_score": 0.7336977659335077,
            "fpr": 0.2138157894736842,
            "logloss": 0.6366658286871275,
            "mae": 0.4248274092219378,
            "precision": 0.6486486486486487,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7307744262867188,
            "auditor_fn_violation": 0.01473713711843427,
            "auditor_fp_violation": 0.0027877964211663444,
            "ave_precision_score": 0.7304788659285566,
            "fpr": 0.2030735455543359,
            "logloss": 0.6395565330614364,
            "mae": 0.42729769086078806,
            "precision": 0.6476190476190476,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6795518948994759,
            "auditor_fn_violation": 0.016766800782949107,
            "auditor_fp_violation": 0.020382439744220358,
            "ave_precision_score": 0.6810069314728369,
            "fpr": 0.2324561403508772,
            "logloss": 0.7738705325258357,
            "mae": 0.3710229162636352,
            "precision": 0.6460767946577629,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6950500871868543,
            "auditor_fn_violation": 0.01091155382208002,
            "auditor_fp_violation": 0.0016801451645422154,
            "ave_precision_score": 0.696750311050233,
            "fpr": 0.22722283205268934,
            "logloss": 0.822786210186874,
            "mae": 0.3617510756479758,
            "precision": 0.6509274873524452,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7474961480563704,
            "auditor_fn_violation": 0.01173970566913152,
            "auditor_fp_violation": 0.01690850959173635,
            "ave_precision_score": 0.747167035232963,
            "fpr": 0.16447368421052633,
            "logloss": 1.1463222285950623,
            "mae": 0.3372958885802889,
            "precision": 0.6739130434782609,
            "recall": 0.640495867768595
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7469066916823976,
            "auditor_fn_violation": 0.013627764672910304,
            "auditor_fp_violation": 0.011469790989941539,
            "ave_precision_score": 0.7465279011720702,
            "fpr": 0.16245883644346873,
            "logloss": 1.0848975728739696,
            "mae": 0.3377631041613751,
            "precision": 0.668903803131991,
            "recall": 0.6361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7874359048088758,
            "auditor_fn_violation": 0.011399884007539515,
            "auditor_fp_violation": 0.007526848663715366,
            "ave_precision_score": 0.7881946965765877,
            "fpr": 0.06359649122807018,
            "logloss": 0.7726697388888625,
            "mae": 0.317443707714193,
            "precision": 0.8294117647058824,
            "recall": 0.5826446280991735
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7854047123155224,
            "auditor_fn_violation": 0.011731321671298789,
            "auditor_fp_violation": 0.0050976848844184585,
            "ave_precision_score": 0.7868637828969236,
            "fpr": 0.06476399560922064,
            "logloss": 0.7534566574614462,
            "mae": 0.32014756089501223,
            "precision": 0.8167701863354038,
            "recall": 0.5595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7622345298192504,
            "auditor_fn_violation": 0.009476493402928814,
            "auditor_fp_violation": 0.013826549434333504,
            "ave_precision_score": 0.7629877509774432,
            "fpr": 0.09758771929824561,
            "logloss": 0.7568396473618642,
            "mae": 0.3232938506076256,
            "precision": 0.7870813397129187,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7592258960639698,
            "auditor_fn_violation": 0.012460004203937702,
            "auditor_fp_violation": 0.0013416270276863053,
            "ave_precision_score": 0.7598108159540836,
            "fpr": 0.10757409440175632,
            "logloss": 0.7288690065657694,
            "mae": 0.32365717595962523,
            "precision": 0.766109785202864,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.777032092500462,
            "auditor_fn_violation": 0.02325286356386835,
            "auditor_fp_violation": 0.007106697819314643,
            "ave_precision_score": 0.7778104444559184,
            "fpr": 0.06798245614035088,
            "logloss": 0.9695435407866517,
            "mae": 0.3263878553447071,
            "precision": 0.8165680473372781,
            "recall": 0.5702479338842975
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7755816554045845,
            "auditor_fn_violation": 0.018842982927341947,
            "auditor_fp_violation": 0.010645897583328979,
            "ave_precision_score": 0.7760201496111686,
            "fpr": 0.07464324917672886,
            "logloss": 0.9283109712758674,
            "mae": 0.32637388456830246,
            "precision": 0.8,
            "recall": 0.5787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 2917,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.835667198834436,
            "auditor_fn_violation": 0.011397618529795567,
            "auditor_fp_violation": 0.014400414002295457,
            "ave_precision_score": 0.8360208905047017,
            "fpr": 0.17214912280701755,
            "logloss": 0.5309632675343715,
            "mae": 0.3145914535495665,
            "precision": 0.724561403508772,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7977667426006229,
            "auditor_fn_violation": 0.015120162552257283,
            "auditor_fp_violation": 0.008662081737195439,
            "ave_precision_score": 0.7990722842160021,
            "fpr": 0.1964873765093304,
            "logloss": 0.6761068737151542,
            "mae": 0.3303987625965891,
            "precision": 0.6919104991394148,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7178238920869782,
            "auditor_fn_violation": 0.012047810642308258,
            "auditor_fp_violation": 0.016401254303984265,
            "ave_precision_score": 0.7183234869239583,
            "fpr": 0.25219298245614036,
            "logloss": 0.8277060472120612,
            "mae": 0.41727245608834845,
            "precision": 0.5979020979020979,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.7129216342649417,
            "auditor_fn_violation": 0.014662400448420022,
            "auditor_fp_violation": 0.008550072059559287,
            "ave_precision_score": 0.713544234889657,
            "fpr": 0.2414928649835346,
            "logloss": 0.807585083587914,
            "mae": 0.41756807164617216,
            "precision": 0.6057347670250897,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7220193249889287,
            "auditor_fn_violation": 0.00011780484268522822,
            "auditor_fp_violation": 0.01439272831611741,
            "ave_precision_score": 0.7206785308660056,
            "fpr": 0.28399122807017546,
            "logloss": 0.7413448873270956,
            "mae": 0.4186520217999555,
            "precision": 0.602760736196319,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7422847152110446,
            "auditor_fn_violation": 0.01305089100123783,
            "auditor_fp_violation": 0.013209674649223029,
            "ave_precision_score": 0.7407154967894921,
            "fpr": 0.2722283205268935,
            "logloss": 0.7234340091690947,
            "mae": 0.4185061302653521,
            "precision": 0.6044657097288676,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8229874723398525,
            "auditor_fn_violation": 0.02349980063795854,
            "auditor_fp_violation": 0.01992129857353665,
            "ave_precision_score": 0.8233245355148402,
            "fpr": 0.10416666666666667,
            "logloss": 0.5381767343805923,
            "mae": 0.3575154426752737,
            "precision": 0.7790697674418605,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8320382230094514,
            "auditor_fn_violation": 0.028147698344115655,
            "auditor_fp_violation": 0.008087098725329873,
            "ave_precision_score": 0.8333000305812062,
            "fpr": 0.09440175631174534,
            "logloss": 0.5275647763595605,
            "mae": 0.3533761270945374,
            "precision": 0.7912621359223301,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7931344117049625,
            "auditor_fn_violation": 0.019338118022328547,
            "auditor_fp_violation": 0.011461919986883097,
            "ave_precision_score": 0.7936101205142182,
            "fpr": 0.07675438596491228,
            "logloss": 0.8632225700385928,
            "mae": 0.30255384908940136,
            "precision": 0.8148148148148148,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7920085439098092,
            "auditor_fn_violation": 0.02090991895742346,
            "auditor_fp_violation": 0.013802081388720876,
            "ave_precision_score": 0.7923754598158906,
            "fpr": 0.08122941822173436,
            "logloss": 0.8300383856117606,
            "mae": 0.3044309396236676,
            "precision": 0.8016085790884718,
            "recall": 0.6361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8384882981528801,
            "auditor_fn_violation": 0.0074035812672176345,
            "auditor_fp_violation": 0.019040006558452213,
            "ave_precision_score": 0.8388818603405178,
            "fpr": 0.15570175438596492,
            "logloss": 0.644301737201435,
            "mae": 0.2792024119554566,
            "precision": 0.7355679702048417,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8419229549590517,
            "auditor_fn_violation": 0.01997804610318332,
            "auditor_fp_violation": 0.015624105478268884,
            "ave_precision_score": 0.8421374485679225,
            "fpr": 0.1602634467618002,
            "logloss": 0.6187572669504328,
            "mae": 0.2860210174117033,
            "precision": 0.7203065134099617,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7016651934684385,
            "auditor_fn_violation": 0.007337882412643185,
            "auditor_fp_violation": 0.011666871618298087,
            "ave_precision_score": 0.7024219656066404,
            "fpr": 0.0712719298245614,
            "logloss": 0.8559557012601823,
            "mae": 0.4122320946118092,
            "precision": 0.7336065573770492,
            "recall": 0.36983471074380164
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6678063255315786,
            "auditor_fn_violation": 0.014480229815260296,
            "auditor_fp_violation": 0.009946459374089927,
            "ave_precision_score": 0.66854974019114,
            "fpr": 0.06586169045005488,
            "logloss": 0.8610878665764292,
            "mae": 0.4229840549040263,
            "precision": 0.7272727272727273,
            "recall": 0.3404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7114906617878776,
            "auditor_fn_violation": 0.023726348412353205,
            "auditor_fp_violation": 0.02537301196917528,
            "ave_precision_score": 0.6694552624570436,
            "fpr": 0.1206140350877193,
            "logloss": 0.7236297514439556,
            "mae": 0.4170924125467999,
            "precision": 0.7157622739018088,
            "recall": 0.5723140495867769
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6818066992380711,
            "auditor_fn_violation": 0.02586122334586731,
            "auditor_fp_violation": 0.024268763487832013,
            "ave_precision_score": 0.6458009483039564,
            "fpr": 0.1207464324917673,
            "logloss": 0.7359378918700665,
            "mae": 0.4271518935487247,
            "precision": 0.7018970189701897,
            "recall": 0.551063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8354984231103288,
            "auditor_fn_violation": 0.016447368421052634,
            "auditor_fp_violation": 0.022900782915232003,
            "ave_precision_score": 0.8358208217319404,
            "fpr": 0.18092105263157895,
            "logloss": 0.5319362808348257,
            "mae": 0.34362976122116506,
            "precision": 0.7130434782608696,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7879480404347096,
            "auditor_fn_violation": 0.018132984562206602,
            "auditor_fp_violation": 0.006944600013441168,
            "ave_precision_score": 0.7893063918391825,
            "fpr": 0.19758507135016465,
            "logloss": 0.6758702668766823,
            "mae": 0.35630775609848003,
            "precision": 0.6901893287435457,
            "recall": 0.8531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7016651934684385,
            "auditor_fn_violation": 0.007337882412643185,
            "auditor_fp_violation": 0.011666871618298087,
            "ave_precision_score": 0.7024219656066404,
            "fpr": 0.0712719298245614,
            "logloss": 0.8559556455707313,
            "mae": 0.4122321049452008,
            "precision": 0.7336065573770492,
            "recall": 0.36983471074380164
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6678063255315787,
            "auditor_fn_violation": 0.014480229815260296,
            "auditor_fp_violation": 0.009946459374089927,
            "ave_precision_score": 0.66854974019114,
            "fpr": 0.06586169045005488,
            "logloss": 0.8610878346080066,
            "mae": 0.42298406624346646,
            "precision": 0.7272727272727273,
            "recall": 0.3404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7825870209992727,
            "auditor_fn_violation": 0.022251522401043944,
            "auditor_fp_violation": 0.008187817675028696,
            "ave_precision_score": 0.783160596458898,
            "fpr": 0.06469298245614036,
            "logloss": 0.9766352954104343,
            "mae": 0.3217315294419229,
            "precision": 0.8269794721407625,
            "recall": 0.5826446280991735
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7784820966680728,
            "auditor_fn_violation": 0.019151271691150714,
            "auditor_fp_violation": 0.0056751570002314886,
            "ave_precision_score": 0.7789128984573115,
            "fpr": 0.07244785949506037,
            "logloss": 0.9330024204017896,
            "mae": 0.32230464600250297,
            "precision": 0.8070175438596491,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7779985877760413,
            "auditor_fn_violation": 0.021114252573582726,
            "auditor_fp_violation": 0.007201487948844074,
            "ave_precision_score": 0.778767648276976,
            "fpr": 0.06469298245614036,
            "logloss": 0.8064760431052915,
            "mae": 0.33075925474491397,
            "precision": 0.8195718654434251,
            "recall": 0.5537190082644629
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7807077014137536,
            "auditor_fn_violation": 0.010332344629469605,
            "auditor_fp_violation": 0.008853742741150616,
            "ave_precision_score": 0.7812542492065979,
            "fpr": 0.06366630076838639,
            "logloss": 0.7857923641967355,
            "mae": 0.33115779471631696,
            "precision": 0.8141025641025641,
            "recall": 0.5404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5569405427205807,
            "auditor_fn_violation": 0.01420907641003335,
            "auditor_fp_violation": 0.008958948188227582,
            "ave_precision_score": 0.5522506009756002,
            "fpr": 0.06907894736842106,
            "logloss": 11.045116710697826,
            "mae": 0.5093283034365066,
            "precision": 0.6012658227848101,
            "recall": 0.1962809917355372
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5487737136759352,
            "auditor_fn_violation": 0.010752738398299756,
            "auditor_fp_violation": 0.007108880873974182,
            "ave_precision_score": 0.5407230731489931,
            "fpr": 0.0845225027442371,
            "logloss": 10.064859402605263,
            "mae": 0.493825529040815,
            "precision": 0.5925925925925926,
            "recall": 0.23829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 2917,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8282784152830927,
            "auditor_fn_violation": 0.009206901551399159,
            "auditor_fp_violation": 0.020858952287260216,
            "ave_precision_score": 0.8286828818778235,
            "fpr": 0.15570175438596492,
            "logloss": 0.6816386647193916,
            "mae": 0.2826029475737342,
            "precision": 0.737037037037037,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8314156247877436,
            "auditor_fn_violation": 0.019235350444916744,
            "auditor_fp_violation": 0.013886710922934866,
            "ave_precision_score": 0.8316445844427001,
            "fpr": 0.1690450054884742,
            "logloss": 0.6643336875876945,
            "mae": 0.293961231916347,
            "precision": 0.7105263157894737,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6912476643935175,
            "auditor_fn_violation": 0.007439828911120779,
            "auditor_fp_violation": 0.013344913100508287,
            "ave_precision_score": 0.6929441918156567,
            "fpr": 0.1699561403508772,
            "logloss": 0.6383528944570023,
            "mae": 0.431095537864358,
            "precision": 0.6709129511677282,
            "recall": 0.6528925619834711
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6913300277848047,
            "auditor_fn_violation": 0.014835228997827974,
            "auditor_fp_violation": 0.0035519513330396248,
            "ave_precision_score": 0.6921634520861304,
            "fpr": 0.17014270032930845,
            "logloss": 0.6507049853796094,
            "mae": 0.43807610212268083,
            "precision": 0.6637744034707158,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.784877391752659,
            "auditor_fn_violation": 0.01602372408293461,
            "auditor_fp_violation": 0.012148507952123303,
            "ave_precision_score": 0.785530054622067,
            "fpr": 0.0756578947368421,
            "logloss": 0.8424211329940288,
            "mae": 0.31048436534575585,
            "precision": 0.8135135135135135,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7863045639483686,
            "auditor_fn_violation": 0.02527033654856716,
            "auditor_fp_violation": 0.013421248484757974,
            "ave_precision_score": 0.7867076744423822,
            "fpr": 0.07464324917672886,
            "logloss": 0.8108212067073645,
            "mae": 0.3123143567411519,
            "precision": 0.8136986301369863,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7417446626065862,
            "auditor_fn_violation": 0.003647419167754096,
            "auditor_fp_violation": 0.005994835218888353,
            "ave_precision_score": 0.7413165693024311,
            "fpr": 0.25,
            "logloss": 1.3795656553273878,
            "mae": 0.3395432993138067,
            "precision": 0.6431924882629108,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7739918639629901,
            "auditor_fn_violation": 0.00455193030805521,
            "auditor_fp_violation": 0.00036589828027809503,
            "ave_precision_score": 0.7736218675647386,
            "fpr": 0.2305159165751921,
            "logloss": 1.1806212827197322,
            "mae": 0.31878486508614273,
            "precision": 0.6551724137931034,
            "recall": 0.8489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7175584853440867,
            "auditor_fn_violation": 0.010849372915760488,
            "auditor_fp_violation": 0.007665191014920482,
            "ave_precision_score": 0.7181017363415748,
            "fpr": 0.05921052631578947,
            "logloss": 1.815427359027681,
            "mae": 0.40720355649303747,
            "precision": 0.7795918367346939,
            "recall": 0.39462809917355374
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7007935408948307,
            "auditor_fn_violation": 0.015587266739846336,
            "auditor_fp_violation": 0.008467931629292774,
            "ave_precision_score": 0.7012274118163775,
            "fpr": 0.06915477497255763,
            "logloss": 1.7657182966643714,
            "mae": 0.41186965666703884,
            "precision": 0.749003984063745,
            "recall": 0.4
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 2917,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7251694527868847,
            "auditor_fn_violation": 0.014761852979556329,
            "auditor_fp_violation": 0.014935850139367116,
            "ave_precision_score": 0.7256187954061726,
            "fpr": 0.26973684210526316,
            "logloss": 0.8259162447743437,
            "mae": 0.4164027179869121,
            "precision": 0.5858585858585859,
            "recall": 0.71900826446281
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7226097161972559,
            "auditor_fn_violation": 0.011691617815353722,
            "auditor_fp_violation": 0.011156163892560321,
            "ave_precision_score": 0.7232088588239247,
            "fpr": 0.25466520307354557,
            "logloss": 0.7982313306971015,
            "mae": 0.4149485317791856,
            "precision": 0.5986159169550173,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7770382637921354,
            "auditor_fn_violation": 0.02325286356386835,
            "auditor_fp_violation": 0.007106697819314643,
            "ave_precision_score": 0.7778166513395199,
            "fpr": 0.06798245614035088,
            "logloss": 0.9696189897424381,
            "mae": 0.3263245437969836,
            "precision": 0.8165680473372781,
            "recall": 0.5702479338842975
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7756296636200626,
            "auditor_fn_violation": 0.018842982927341947,
            "auditor_fp_violation": 0.010645897583328979,
            "ave_precision_score": 0.7760678113664508,
            "fpr": 0.07464324917672886,
            "logloss": 0.9283640004927846,
            "mae": 0.3263054307992747,
            "precision": 0.8,
            "recall": 0.5787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7620057874747922,
            "auditor_fn_violation": 0.00964866971146876,
            "auditor_fp_violation": 0.014725774717166755,
            "ave_precision_score": 0.7627607900814142,
            "fpr": 0.09649122807017543,
            "logloss": 0.7580221847509326,
            "mae": 0.32335183925534583,
            "precision": 0.7889688249400479,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7588706907924865,
            "auditor_fn_violation": 0.012460004203937702,
            "auditor_fp_violation": 0.0013416270276863053,
            "ave_precision_score": 0.7594555905779815,
            "fpr": 0.10757409440175632,
            "logloss": 0.7302036769307074,
            "mae": 0.3238410604901037,
            "precision": 0.766109785202864,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.715282570378452,
            "auditor_fn_violation": 0.0007158909670871399,
            "auditor_fp_violation": 0.01439272831611741,
            "ave_precision_score": 0.7153428382683085,
            "fpr": 0.28399122807017546,
            "logloss": 0.7395616799996095,
            "mae": 0.4189954856247233,
            "precision": 0.6021505376344086,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7424151606317608,
            "auditor_fn_violation": 0.01305089100123783,
            "auditor_fp_violation": 0.0117460815281107,
            "ave_precision_score": 0.7408866725778499,
            "fpr": 0.27332601536772777,
            "logloss": 0.722295012657217,
            "mae": 0.4187749609858223,
            "precision": 0.6035031847133758,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5682110729209555,
            "auditor_fn_violation": 0.017344497607655513,
            "auditor_fp_violation": 0.00882316773241515,
            "ave_precision_score": 0.5635053903203879,
            "fpr": 0.06798245614035088,
            "logloss": 10.969664747258014,
            "mae": 0.5065589831168348,
            "precision": 0.6172839506172839,
            "recall": 0.2066115702479339
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5546074765645297,
            "auditor_fn_violation": 0.011350631758413726,
            "auditor_fp_violation": 0.006078391839721622,
            "ave_precision_score": 0.5471598760795944,
            "fpr": 0.08232711306256861,
            "logloss": 9.98712127345425,
            "mae": 0.4923312098711011,
            "precision": 0.5945945945945946,
            "recall": 0.23404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6929558015725987,
            "auditor_fn_violation": 0.007720748151370156,
            "auditor_fp_violation": 0.01379324479422857,
            "ave_precision_score": 0.6934766387734331,
            "fpr": 0.16228070175438597,
            "logloss": 0.6394619655119964,
            "mae": 0.4433059826689331,
            "precision": 0.6851063829787234,
            "recall": 0.6652892561983471
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6931136275094492,
            "auditor_fn_violation": 0.01906252189550879,
            "auditor_fp_violation": 0.006591147252900436,
            "ave_precision_score": 0.6936103969721878,
            "fpr": 0.1602634467618002,
            "logloss": 0.6448360398160687,
            "mae": 0.44628738269258933,
            "precision": 0.6733780760626398,
            "recall": 0.6404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7818945225420038,
            "auditor_fn_violation": 0.014091271567348134,
            "auditor_fp_violation": 0.011123749795048371,
            "ave_precision_score": 0.7825359079480381,
            "fpr": 0.07675438596491228,
            "logloss": 0.8629808642541752,
            "mae": 0.3158161657606755,
            "precision": 0.8108108108108109,
            "recall": 0.6198347107438017
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7706998158425269,
            "auditor_fn_violation": 0.016362659691244136,
            "auditor_fp_violation": 0.013421248484757974,
            "ave_precision_score": 0.772169889125633,
            "fpr": 0.07464324917672886,
            "logloss": 0.8345313358925823,
            "mae": 0.31758893319438913,
            "precision": 0.8111111111111111,
            "recall": 0.6212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7228461295811557,
            "auditor_fn_violation": 0.010849372915760488,
            "auditor_fp_violation": 0.007665191014920482,
            "ave_precision_score": 0.7234207577861854,
            "fpr": 0.05921052631578947,
            "logloss": 1.564575612722543,
            "mae": 0.4047080054479367,
            "precision": 0.7795918367346939,
            "recall": 0.39462809917355374
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7061560655812092,
            "auditor_fn_violation": 0.014270032930845234,
            "auditor_fp_violation": 0.0068973070384392345,
            "ave_precision_score": 0.7066019282638789,
            "fpr": 0.07025246981339188,
            "logloss": 1.5248664033826118,
            "mae": 0.40892988202724817,
            "precision": 0.746031746031746,
            "recall": 0.4
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6034601453409995,
            "auditor_fn_violation": 0.015391655792373497,
            "auditor_fp_violation": 0.005523446466633875,
            "ave_precision_score": 0.596865048921071,
            "fpr": 0.30701754385964913,
            "logloss": 1.9466827475847446,
            "mae": 0.3977323979335396,
            "precision": 0.6039603960396039,
            "recall": 0.8822314049586777
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.5675134466617549,
            "auditor_fn_violation": 0.010617278183898923,
            "auditor_fp_violation": 0.011708744968898645,
            "ave_precision_score": 0.5613700138402371,
            "fpr": 0.3227222832052689,
            "logloss": 2.1872657367776127,
            "mae": 0.42016649038278375,
            "precision": 0.5864978902953587,
            "recall": 0.8872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8383586027489,
            "auditor_fn_violation": 0.0074035812672176345,
            "auditor_fp_violation": 0.019040006558452213,
            "ave_precision_score": 0.838752354151926,
            "fpr": 0.15570175438596492,
            "logloss": 0.6449552412147649,
            "mae": 0.2791817585400762,
            "precision": 0.7355679702048417,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8418744509798415,
            "auditor_fn_violation": 0.01997804610318332,
            "auditor_fp_violation": 0.015001829491401397,
            "ave_precision_score": 0.8420889195218261,
            "fpr": 0.16136114160263446,
            "logloss": 0.619347365223004,
            "mae": 0.28600411653790864,
            "precision": 0.7189292543021033,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.847626842623533,
            "auditor_fn_violation": 0.01648361606495578,
            "auditor_fp_violation": 0.029187674208886707,
            "ave_precision_score": 0.8480978598090154,
            "fpr": 0.1524122807017544,
            "logloss": 0.5327847195072318,
            "mae": 0.31096459697603185,
            "precision": 0.7382297551789078,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8519204643244016,
            "auditor_fn_violation": 0.021995936193567982,
            "auditor_fp_violation": 0.018486575017859323,
            "ave_precision_score": 0.8521548043562872,
            "fpr": 0.1602634467618002,
            "logloss": 0.5211875184309607,
            "mae": 0.31239720014612465,
            "precision": 0.7255639097744361,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8484351758757809,
            "auditor_fn_violation": 0.018325449470784405,
            "auditor_fp_violation": 0.02436362518445647,
            "ave_precision_score": 0.84880342231226,
            "fpr": 0.1513157894736842,
            "logloss": 0.5148079799919838,
            "mae": 0.31517832927235295,
            "precision": 0.7420560747663552,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8424649026822657,
            "auditor_fn_violation": 0.01863045052198893,
            "auditor_fp_violation": 0.01083258037938923,
            "ave_precision_score": 0.8437183522912358,
            "fpr": 0.15916575192096596,
            "logloss": 0.5153301501668475,
            "mae": 0.3174748145979006,
            "precision": 0.7274436090225563,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8384477624545597,
            "auditor_fn_violation": 0.0074035812672176345,
            "auditor_fp_violation": 0.019040006558452213,
            "ave_precision_score": 0.8388413777539401,
            "fpr": 0.15570175438596492,
            "logloss": 0.6445157204949918,
            "mae": 0.27919567483719854,
            "precision": 0.7355679702048417,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.841886469708625,
            "auditor_fn_violation": 0.01997804610318332,
            "auditor_fp_violation": 0.015624105478268884,
            "ave_precision_score": 0.8421010259890174,
            "fpr": 0.1602634467618002,
            "logloss": 0.6189504701798664,
            "mae": 0.28601552325340074,
            "precision": 0.7203065134099617,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.717556667212272,
            "auditor_fn_violation": 0.010849372915760488,
            "auditor_fp_violation": 0.007665191014920482,
            "ave_precision_score": 0.7180999186918013,
            "fpr": 0.05921052631578947,
            "logloss": 1.8154537651180986,
            "mae": 0.40720412058214617,
            "precision": 0.7795918367346939,
            "recall": 0.39462809917355374
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7007920328048778,
            "auditor_fn_violation": 0.015587266739846336,
            "auditor_fp_violation": 0.008467931629292774,
            "ave_precision_score": 0.7012259039474988,
            "fpr": 0.06915477497255763,
            "logloss": 1.7657428131625341,
            "mae": 0.4118706626425392,
            "precision": 0.749003984063745,
            "recall": 0.4
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8379168045152994,
            "auditor_fn_violation": 0.008921451355661886,
            "auditor_fp_violation": 0.02042599196589605,
            "ave_precision_score": 0.8382922154042969,
            "fpr": 0.1524122807017544,
            "logloss": 0.6425730721022396,
            "mae": 0.2795392386540253,
            "precision": 0.7392120075046904,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8417064171463989,
            "auditor_fn_violation": 0.01802555059906112,
            "auditor_fp_violation": 0.01494955830850453,
            "ave_precision_score": 0.8419211979756613,
            "fpr": 0.15587266739846323,
            "logloss": 0.6167357990427444,
            "mae": 0.2863072711273778,
            "precision": 0.7242718446601941,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8497663423644534,
            "auditor_fn_violation": 0.01844551979121357,
            "auditor_fp_violation": 0.029328578455484505,
            "ave_precision_score": 0.8501432971627414,
            "fpr": 0.14802631578947367,
            "logloss": 0.5122237293629732,
            "mae": 0.3126176506466755,
            "precision": 0.7471910112359551,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8426098029292992,
            "auditor_fn_violation": 0.018665483336058112,
            "auditor_fp_violation": 0.01818539344021546,
            "ave_precision_score": 0.8438612187705303,
            "fpr": 0.17014270032930845,
            "logloss": 0.5174989528123313,
            "mae": 0.31801516550483694,
            "precision": 0.7134935304990758,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7783990630034839,
            "auditor_fn_violation": 0.009741554298970567,
            "auditor_fp_violation": 0.01108788325955075,
            "ave_precision_score": 0.7790217875173858,
            "fpr": 0.07456140350877193,
            "logloss": 0.8925830634698942,
            "mae": 0.32190484493326826,
            "precision": 0.8111111111111111,
            "recall": 0.6033057851239669
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7708900872123443,
            "auditor_fn_violation": 0.020001401312562773,
            "auditor_fp_violation": 0.013568105617658699,
            "ave_precision_score": 0.7715121136503004,
            "fpr": 0.07574094401756312,
            "logloss": 0.8591107983046672,
            "mae": 0.3230798543467755,
            "precision": 0.8039772727272727,
            "recall": 0.6021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8394739461122732,
            "auditor_fn_violation": 0.013307416267942586,
            "auditor_fp_violation": 0.0178487252008526,
            "ave_precision_score": 0.8398185540657856,
            "fpr": 0.1524122807017544,
            "logloss": 0.6495856874909491,
            "mae": 0.27838449774049656,
            "precision": 0.7372400756143668,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8462494016715094,
            "auditor_fn_violation": 0.020412452997641124,
            "auditor_fp_violation": 0.017518313582293513,
            "ave_precision_score": 0.8464575796451052,
            "fpr": 0.141602634467618,
            "logloss": 0.6123341507188091,
            "mae": 0.2818200832493606,
            "precision": 0.7430278884462151,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8279864965252899,
            "auditor_fn_violation": 0.00798354356966797,
            "auditor_fp_violation": 0.020577143794064612,
            "ave_precision_score": 0.8283894262108633,
            "fpr": 0.15350877192982457,
            "logloss": 0.6807392412851507,
            "mae": 0.28264844171449194,
            "precision": 0.7383177570093458,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.830913201705622,
            "auditor_fn_violation": 0.019235350444916744,
            "auditor_fp_violation": 0.017159882613857848,
            "ave_precision_score": 0.8311445920694341,
            "fpr": 0.16575192096597147,
            "logloss": 0.66358179973063,
            "mae": 0.29401788836173026,
            "precision": 0.7145557655954632,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7619940230475807,
            "auditor_fn_violation": 0.010108561693489924,
            "auditor_fp_violation": 0.014725774717166755,
            "ave_precision_score": 0.7627512045888687,
            "fpr": 0.09649122807017543,
            "logloss": 0.7585667619735755,
            "mae": 0.32348683325715666,
            "precision": 0.7874396135265701,
            "recall": 0.6735537190082644
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7584529605086127,
            "auditor_fn_violation": 0.012140037835439207,
            "auditor_fp_violation": 0.006048522592351979,
            "ave_precision_score": 0.7590399802767972,
            "fpr": 0.10647639956092206,
            "logloss": 0.7318504962117601,
            "mae": 0.3243304514233149,
            "precision": 0.7684964200477327,
            "recall": 0.6851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.770197632889124,
            "auditor_fn_violation": 0.014476402783819058,
            "auditor_fp_violation": 0.0075678389899983605,
            "ave_precision_score": 0.7709726894757658,
            "fpr": 0.06798245614035088,
            "logloss": 0.9715951695423622,
            "mae": 0.3367420868557005,
            "precision": 0.8068535825545171,
            "recall": 0.5351239669421488
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7662776856792701,
            "auditor_fn_violation": 0.018513674475091675,
            "auditor_fp_violation": 0.014688202394020178,
            "ave_precision_score": 0.7667372959058659,
            "fpr": 0.07464324917672886,
            "logloss": 0.9355483075371286,
            "mae": 0.3373671332473628,
            "precision": 0.7920489296636085,
            "recall": 0.551063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8355023761462868,
            "auditor_fn_violation": 0.016447368421052634,
            "auditor_fp_violation": 0.022900782915232003,
            "ave_precision_score": 0.8358247712122449,
            "fpr": 0.18092105263157895,
            "logloss": 0.5319291942294263,
            "mae": 0.34362477533878727,
            "precision": 0.7130434782608696,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7878785204518436,
            "auditor_fn_violation": 0.018132984562206602,
            "auditor_fp_violation": 0.006944600013441168,
            "ave_precision_score": 0.7892369634605372,
            "fpr": 0.19758507135016465,
            "logloss": 0.6759346354237679,
            "mae": 0.3563175786135291,
            "precision": 0.6901893287435457,
            "recall": 0.8531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7422343813292123,
            "auditor_fn_violation": 0.003647419167754096,
            "auditor_fp_violation": 0.005994835218888353,
            "ave_precision_score": 0.7417818959816944,
            "fpr": 0.25,
            "logloss": 1.3769759259526944,
            "mae": 0.33946300660689605,
            "precision": 0.6431924882629108,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7742968526178331,
            "auditor_fn_violation": 0.00455193030805521,
            "auditor_fp_violation": 0.00036589828027809503,
            "ave_precision_score": 0.7739448861453828,
            "fpr": 0.2305159165751921,
            "logloss": 1.1789078949375573,
            "mae": 0.3187173189830646,
            "precision": 0.6551724137931034,
            "recall": 0.8489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7337211179254981,
            "auditor_fn_violation": 0.01409580252283601,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.734296643781924,
            "fpr": 0.09868421052631579,
            "logloss": 0.7005936172291042,
            "mae": 0.41961100766141163,
            "precision": 0.7471910112359551,
            "recall": 0.5495867768595041
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7368474564064197,
            "auditor_fn_violation": 0.013536679356330435,
            "auditor_fp_violation": 0.010401965396476922,
            "ave_precision_score": 0.7372442800127939,
            "fpr": 0.09989023051591657,
            "logloss": 0.7140621252105448,
            "mae": 0.42977563204278535,
            "precision": 0.7307692307692307,
            "recall": 0.5255319148936171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7164402764617772,
            "auditor_fn_violation": 0.010416666666666676,
            "auditor_fp_violation": 0.007665191014920482,
            "ave_precision_score": 0.7169525840725135,
            "fpr": 0.05921052631578947,
            "logloss": 1.833931639462538,
            "mae": 0.4098417482273275,
            "precision": 0.7740585774058577,
            "recall": 0.3822314049586777
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7004945616670815,
            "auditor_fn_violation": 0.013929046873905239,
            "auditor_fp_violation": 0.005645287752861847,
            "ave_precision_score": 0.7009142092105978,
            "fpr": 0.06147091108671789,
            "logloss": 1.7778981113958376,
            "mae": 0.4132250636222741,
            "precision": 0.7666666666666667,
            "recall": 0.39148936170212767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7294503773440664,
            "auditor_fn_violation": 0.002428592141510804,
            "auditor_fp_violation": 0.007772790621413348,
            "ave_precision_score": 0.7289888208187651,
            "fpr": 0.2576754385964912,
            "logloss": 1.3903111760220725,
            "mae": 0.34349768014917853,
            "precision": 0.6406727828746177,
            "recall": 0.8657024793388429
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.764369831916174,
            "auditor_fn_violation": 0.0035826891188079526,
            "auditor_fp_violation": 0.00465960258966376,
            "ave_precision_score": 0.7639940666343298,
            "fpr": 0.24259055982436883,
            "logloss": 1.1892467586808335,
            "mae": 0.3253302194162682,
            "precision": 0.6486486486486487,
            "recall": 0.8680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8279879704879638,
            "auditor_fn_violation": 0.00798354356966797,
            "auditor_fp_violation": 0.020577143794064612,
            "ave_precision_score": 0.8283909085728671,
            "fpr": 0.15350877192982457,
            "logloss": 0.6806325978880644,
            "mae": 0.28265998167901335,
            "precision": 0.7383177570093458,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8309330774252316,
            "auditor_fn_violation": 0.019235350444916744,
            "auditor_fp_violation": 0.017159882613857848,
            "ave_precision_score": 0.8311644457435403,
            "fpr": 0.16575192096597147,
            "logloss": 0.6634734473545363,
            "mae": 0.2940275080123268,
            "precision": 0.7145557655954632,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8344756378438833,
            "auditor_fn_violation": 0.012312871538350013,
            "auditor_fp_violation": 0.01562756189539269,
            "ave_precision_score": 0.8348247809840791,
            "fpr": 0.14802631578947367,
            "logloss": 0.6641811256770204,
            "mae": 0.2806393057364961,
            "precision": 0.7423664122137404,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.839970930723987,
            "auditor_fn_violation": 0.020944951771492634,
            "auditor_fp_violation": 0.014309858594004748,
            "ave_precision_score": 0.8401930901149611,
            "fpr": 0.1394072447859495,
            "logloss": 0.6293850117892821,
            "mae": 0.2839200930377728,
            "precision": 0.7449799196787149,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.782424545486436,
            "auditor_fn_violation": 0.018803465274757142,
            "auditor_fp_violation": 0.011610509919658963,
            "ave_precision_score": 0.7831931748911263,
            "fpr": 0.07017543859649122,
            "logloss": 0.9305088958473692,
            "mae": 0.31577031587136045,
            "precision": 0.8217270194986073,
            "recall": 0.609504132231405
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.780294581522587,
            "auditor_fn_violation": 0.021591891071303465,
            "auditor_fp_violation": 0.006160532269988129,
            "ave_precision_score": 0.7807263560796077,
            "fpr": 0.07574094401756312,
            "logloss": 0.8922889548000605,
            "mae": 0.31721170086636086,
            "precision": 0.8050847457627118,
            "recall": 0.6063829787234043
        }
    }
]