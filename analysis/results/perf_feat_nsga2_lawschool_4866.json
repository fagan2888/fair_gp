[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.897861207303105,
            "mae": 0.5471491228070176,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.25043167912663,
            "mae": 0.4994511525795829,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.897861207303105,
            "mae": 0.5471491228070176,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.25043167912663,
            "mae": 0.4994511525795829,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5516210955381939,
            "auditor_fn_violation": 0.01000026368526527,
            "auditor_fp_violation": 0.007917038358608384,
            "ave_precision_score": 0.5524248748594094,
            "fpr": 0.12280701754385964,
            "logloss": 0.6932253466555465,
            "mae": 0.5000379354480589,
            "precision": 0.5658914728682171,
            "recall": 0.2925851703406814
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5126328626628112,
            "auditor_fn_violation": 0.0010011941954861739,
            "auditor_fp_violation": 0.006937623972114703,
            "ave_precision_score": 0.512821429272452,
            "fpr": 0.13391877058177826,
            "logloss": 0.6931343891614746,
            "mae": 0.49999243282722194,
            "precision": 0.5627240143369175,
            "recall": 0.34505494505494505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.5952818875356932,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011841043286181557,
            "ave_precision_score": 0.6010684346248231,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6932088644092473,
            "mae": 0.5000307420758825,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6931465126378853,
            "mae": 0.49999956520014616,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5435578827762035,
            "auditor_fn_violation": 0.0063372358752592905,
            "auditor_fp_violation": 0.00337443184231766,
            "ave_precision_score": 0.5447838077021914,
            "fpr": 0.2565789473684211,
            "logloss": 0.694765147931755,
            "mae": 0.49768265724190297,
            "precision": 0.5634328358208955,
            "recall": 0.6052104208416834
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5134355181715691,
            "auditor_fn_violation": 0.006241179237886151,
            "auditor_fp_violation": 0.006480251121767098,
            "ave_precision_score": 0.5154218886598138,
            "fpr": 0.27552140504939626,
            "logloss": 0.7387565715113972,
            "mae": 0.49946554039350466,
            "precision": 0.5325884543761639,
            "recall": 0.6285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6973782925214416,
            "mae": 0.4991393424588431,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7007007179384722,
            "mae": 0.49838097791164976,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.791350006611969,
            "auditor_fn_violation": 0.004752926906444469,
            "auditor_fp_violation": 0.0013407459326281817,
            "ave_precision_score": 0.792130989772944,
            "fpr": 0.0625,
            "logloss": 0.5975057049909892,
            "mae": 0.4061927501668578,
            "precision": 0.8298507462686567,
            "recall": 0.5571142284569138
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7454062445682469,
            "auditor_fn_violation": 0.011893704539149112,
            "auditor_fp_violation": 0.009563907023321203,
            "ave_precision_score": 0.7469087881403453,
            "fpr": 0.0867178924259056,
            "logloss": 0.6308392892495683,
            "mae": 0.411317243021831,
            "precision": 0.7569230769230769,
            "recall": 0.5406593406593406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.691557978888862,
            "mae": 0.4984939742298274,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6902561734866138,
            "mae": 0.49784238159075855,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6973782917821194,
            "mae": 0.49913934246573616,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7007007164512827,
            "mae": 0.49838097791855035,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7059639260030788,
            "auditor_fn_violation": 0.013687462644587423,
            "auditor_fp_violation": 0.0002522195318805527,
            "ave_precision_score": 0.6354062493348225,
            "fpr": 0.2324561403508772,
            "logloss": 5.114710856128318,
            "mae": 0.3635885495018673,
            "precision": 0.6552845528455284,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6672656621137762,
            "auditor_fn_violation": 0.0026465301986707086,
            "auditor_fp_violation": 0.0018150480482215453,
            "ave_precision_score": 0.5881049772293999,
            "fpr": 0.2349066959385291,
            "logloss": 5.50950073217869,
            "mae": 0.38514164645634213,
            "precision": 0.6178571428571429,
            "recall": 0.7604395604395604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8108395519042955,
            "auditor_fn_violation": 0.00804459796786556,
            "auditor_fp_violation": 0.016973047024340517,
            "ave_precision_score": 0.7782401581722745,
            "fpr": 0.14473684210526316,
            "logloss": 2.341309783659634,
            "mae": 0.30773864626120245,
            "precision": 0.7518796992481203,
            "recall": 0.8016032064128257
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7618736778961871,
            "auditor_fn_violation": 0.008354543371008794,
            "auditor_fp_violation": 0.021542261251372135,
            "ave_precision_score": 0.7191242214639835,
            "fpr": 0.17453347969264543,
            "logloss": 2.7504596502425245,
            "mae": 0.33467479416061463,
            "precision": 0.6977186311787072,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5435578827762035,
            "auditor_fn_violation": 0.0063372358752592905,
            "auditor_fp_violation": 0.00337443184231766,
            "ave_precision_score": 0.5447838077021914,
            "fpr": 0.2565789473684211,
            "logloss": 0.6947651480597866,
            "mae": 0.49768265736955136,
            "precision": 0.5634328358208955,
            "recall": 0.6052104208416834
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5134355181715691,
            "auditor_fn_violation": 0.006241179237886151,
            "auditor_fp_violation": 0.006480251121767098,
            "ave_precision_score": 0.5154218886598138,
            "fpr": 0.27552140504939626,
            "logloss": 0.7387565741418641,
            "mae": 0.49946554089175205,
            "precision": 0.5325884543761639,
            "recall": 0.6285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8802057463306745,
            "auditor_fn_violation": 0.014907006996449037,
            "auditor_fp_violation": 0.008262180875918613,
            "ave_precision_score": 0.8804165996234077,
            "fpr": 0.08114035087719298,
            "logloss": 0.6975744240191992,
            "mae": 0.2427076264010294,
            "precision": 0.832579185520362,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8510990348297309,
            "auditor_fn_violation": 0.009963691632187795,
            "auditor_fp_violation": 0.009994800392859209,
            "ave_precision_score": 0.8516571574894598,
            "fpr": 0.09879253567508232,
            "logloss": 0.6669286156492266,
            "mae": 0.24455347461758226,
            "precision": 0.7887323943661971,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.775505807857494,
            "auditor_fn_violation": 0.0009624512182259256,
            "auditor_fp_violation": 0.001338090990187339,
            "ave_precision_score": 0.5528163132450786,
            "fpr": 0.4407894736842105,
            "logloss": 0.691637122096765,
            "mae": 0.49905717791172494,
            "precision": 0.5528364849833148,
            "recall": 0.9959919839679359
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.7489096067938452,
            "auditor_fn_violation": 0.0014402721318198817,
            "auditor_fp_violation": 0.00161765555491363,
            "ave_precision_score": 0.501109832130951,
            "fpr": 0.49396267837541163,
            "logloss": 0.6919482689869453,
            "mae": 0.4991399033074845,
            "precision": 0.5011086474501109,
            "recall": 0.9934065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.691557985591156,
            "mae": 0.4984939771820791,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6902561745021085,
            "mae": 0.4978423817001455,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5700268728137916,
            "auditor_fn_violation": 0.06587736877263298,
            "auditor_fp_violation": 0.06127872647720997,
            "ave_precision_score": 0.573230457377051,
            "fpr": 0.17543859649122806,
            "logloss": 0.6954589277021024,
            "mae": 0.4976280444560025,
            "precision": 0.581151832460733,
            "recall": 0.44488977955911824
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5532605744658963,
            "auditor_fn_violation": 0.05637326449620631,
            "auditor_fp_violation": 0.06084984690045642,
            "ave_precision_score": 0.5570268978054237,
            "fpr": 0.19099890230515917,
            "logloss": 0.6981810362056511,
            "mae": 0.49733641361010095,
            "precision": 0.5606060606060606,
            "recall": 0.4879120879120879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7833188772971285,
            "auditor_fn_violation": 0.005150652181556099,
            "auditor_fp_violation": 0.0013407459326281817,
            "ave_precision_score": 0.7839402256142174,
            "fpr": 0.0625,
            "logloss": 0.5969031269180454,
            "mae": 0.39984218705547137,
            "precision": 0.8308605341246291,
            "recall": 0.561122244488978
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7257140174209405,
            "auditor_fn_violation": 0.010603008407618731,
            "auditor_fp_violation": 0.0104569876942631,
            "ave_precision_score": 0.7274049789169501,
            "fpr": 0.08781558726673985,
            "logloss": 0.6381944800538859,
            "mae": 0.40778859066156564,
            "precision": 0.756838905775076,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7913479395947203,
            "auditor_fn_violation": 0.004752926906444469,
            "auditor_fp_violation": 0.0013407459326281817,
            "ave_precision_score": 0.7921289280079635,
            "fpr": 0.0625,
            "logloss": 0.5974693859542547,
            "mae": 0.40619585697589955,
            "precision": 0.8298507462686567,
            "recall": 0.5571142284569138
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7461733697514263,
            "auditor_fn_violation": 0.011893704539149112,
            "auditor_fp_violation": 0.009563907023321203,
            "ave_precision_score": 0.747671350993103,
            "fpr": 0.0867178924259056,
            "logloss": 0.6305013174003472,
            "mae": 0.41132458334279626,
            "precision": 0.7569230769230769,
            "recall": 0.5406593406593406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8112414315960841,
            "auditor_fn_violation": 0.00804459796786556,
            "auditor_fp_violation": 0.016973047024340517,
            "ave_precision_score": 0.7786405676883879,
            "fpr": 0.14473684210526316,
            "logloss": 2.340606166441188,
            "mae": 0.30786404744078405,
            "precision": 0.7518796992481203,
            "recall": 0.8016032064128257
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7620401465307912,
            "auditor_fn_violation": 0.008354543371008794,
            "auditor_fp_violation": 0.021542261251372135,
            "ave_precision_score": 0.7192864561301628,
            "fpr": 0.17453347969264543,
            "logloss": 2.751580159829164,
            "mae": 0.3348930610326431,
            "precision": 0.6977186311787072,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7832894247755692,
            "auditor_fn_violation": 0.005150652181556099,
            "auditor_fp_violation": 0.0013407459326281817,
            "ave_precision_score": 0.7839195532930897,
            "fpr": 0.0625,
            "logloss": 0.5965568024561474,
            "mae": 0.39988104144577574,
            "precision": 0.8308605341246291,
            "recall": 0.561122244488978
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7263292709280951,
            "auditor_fn_violation": 0.010603008407618731,
            "auditor_fp_violation": 0.008622681841816396,
            "ave_precision_score": 0.72801774939557,
            "fpr": 0.0889132821075741,
            "logloss": 0.6400881025511674,
            "mae": 0.4080146554717552,
            "precision": 0.7545454545454545,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8069896789596845,
            "auditor_fn_violation": 0.011810902506767923,
            "auditor_fp_violation": 0.020721825750817723,
            "ave_precision_score": 0.6549508714986749,
            "fpr": 0.23574561403508773,
            "logloss": 0.8353864776586774,
            "mae": 0.42619262037292255,
            "precision": 0.6702453987730062,
            "recall": 0.875751503006012
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7744725326838539,
            "auditor_fn_violation": 0.008212204919120397,
            "auditor_fp_violation": 0.03347969264544457,
            "ave_precision_score": 0.5946938784881222,
            "fpr": 0.2854006586169045,
            "logloss": 0.7948417098793903,
            "mae": 0.42241819986038964,
            "precision": 0.6072507552870091,
            "recall": 0.8835164835164835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8070643849554432,
            "auditor_fn_violation": 0.011810902506767923,
            "auditor_fp_violation": 0.020721825750817723,
            "ave_precision_score": 0.6551002834901921,
            "fpr": 0.23574561403508773,
            "logloss": 0.8224245087963236,
            "mae": 0.4257393294548756,
            "precision": 0.6702453987730062,
            "recall": 0.875751503006012
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.774568641428178,
            "auditor_fn_violation": 0.008212204919120397,
            "auditor_fp_violation": 0.03347969264544457,
            "ave_precision_score": 0.5948860959767703,
            "fpr": 0.2854006586169045,
            "logloss": 0.7840519159210486,
            "mae": 0.4221937379360638,
            "precision": 0.6072507552870091,
            "recall": 0.8835164835164835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8108395519042955,
            "auditor_fn_violation": 0.00804459796786556,
            "auditor_fp_violation": 0.016973047024340517,
            "ave_precision_score": 0.7782401581722745,
            "fpr": 0.14473684210526316,
            "logloss": 2.341309776488554,
            "mae": 0.30773865842762727,
            "precision": 0.7518796992481203,
            "recall": 0.8016032064128257
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7618736778961871,
            "auditor_fn_violation": 0.008354543371008794,
            "auditor_fp_violation": 0.021542261251372135,
            "ave_precision_score": 0.7191242214639835,
            "fpr": 0.17453347969264543,
            "logloss": 2.7504596705348776,
            "mae": 0.3346748127771021,
            "precision": 0.6977186311787072,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5700021243981955,
            "auditor_fn_violation": 0.06587736877263298,
            "auditor_fp_violation": 0.060875175226201096,
            "ave_precision_score": 0.5731904378566895,
            "fpr": 0.17434210526315788,
            "logloss": 0.6955060959651653,
            "mae": 0.49759850303924297,
            "precision": 0.5826771653543307,
            "recall": 0.44488977955911824
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5532446688822181,
            "auditor_fn_violation": 0.05637326449620631,
            "auditor_fp_violation": 0.06084984690045642,
            "ave_precision_score": 0.5569978563376535,
            "fpr": 0.19099890230515917,
            "logloss": 0.6981422145533326,
            "mae": 0.49727049250816097,
            "precision": 0.5606060606060606,
            "recall": 0.4879120879120879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7838715325490178,
            "auditor_fn_violation": 0.002113876876560138,
            "auditor_fp_violation": 0.014472091245061807,
            "ave_precision_score": 0.5737176747607684,
            "fpr": 0.40021929824561403,
            "logloss": 0.6876912639962202,
            "mae": 0.4773743486955043,
            "precision": 0.574095682613769,
            "recall": 0.9859719438877755
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7597045471908259,
            "auditor_fn_violation": 0.0010832197440320383,
            "auditor_fp_violation": 0.010100718316097603,
            "ave_precision_score": 0.5235953842822276,
            "fpr": 0.4500548847420417,
            "logloss": 0.6763294897082369,
            "mae": 0.47715802123498186,
            "precision": 0.5238095238095238,
            "recall": 0.9912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 4866,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7745800879038465,
            "auditor_fn_violation": 0.00436399114017509,
            "auditor_fp_violation": 0.006236459793551677,
            "ave_precision_score": 0.7752905012065082,
            "fpr": 0.03399122807017544,
            "logloss": 0.6751254857920657,
            "mae": 0.39173806179603293,
            "precision": 0.8803088803088803,
            "recall": 0.45691382765531063
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7206531151684394,
            "auditor_fn_violation": 0.0012014330345834314,
            "auditor_fp_violation": 0.005437922468080192,
            "ave_precision_score": 0.72221546999822,
            "fpr": 0.05598243688254665,
            "logloss": 0.6763515013231838,
            "mae": 0.400630747837857,
            "precision": 0.796,
            "recall": 0.43736263736263736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7636452934739406,
            "auditor_fn_violation": 0.011637309707133564,
            "auditor_fp_violation": 0.005859457966951276,
            "ave_precision_score": 0.7642454063437494,
            "fpr": 0.03289473684210526,
            "logloss": 0.6716090065658417,
            "mae": 0.3995705875389015,
            "precision": 0.8841698841698842,
            "recall": 0.4589178356713427
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7116206591351173,
            "auditor_fn_violation": 0.0030228827155281803,
            "auditor_fp_violation": 0.006393591002753866,
            "ave_precision_score": 0.7132822144647293,
            "fpr": 0.06147091108671789,
            "logloss": 0.6745015322805585,
            "mae": 0.4066698631170023,
            "precision": 0.7886792452830189,
            "recall": 0.4593406593406593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8112414315960841,
            "auditor_fn_violation": 0.00804459796786556,
            "auditor_fp_violation": 0.016973047024340517,
            "ave_precision_score": 0.7786405676883879,
            "fpr": 0.14473684210526316,
            "logloss": 2.3406063066030054,
            "mae": 0.3078640665662701,
            "precision": 0.7518796992481203,
            "recall": 0.8016032064128257
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7620401465307912,
            "auditor_fn_violation": 0.008354543371008794,
            "auditor_fp_violation": 0.021542261251372135,
            "ave_precision_score": 0.7192864561301628,
            "fpr": 0.17453347969264543,
            "logloss": 2.7515801474842863,
            "mae": 0.33489308661684836,
            "precision": 0.6977186311787072,
            "recall": 0.8065934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8069896789596845,
            "auditor_fn_violation": 0.011810902506767923,
            "auditor_fp_violation": 0.020721825750817723,
            "ave_precision_score": 0.6549508714986749,
            "fpr": 0.23574561403508773,
            "logloss": 0.8285600724776614,
            "mae": 0.4259712966485766,
            "precision": 0.6702453987730062,
            "recall": 0.875751503006012
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7744725326838539,
            "auditor_fn_violation": 0.008212204919120397,
            "auditor_fp_violation": 0.03347969264544457,
            "ave_precision_score": 0.5946938784881222,
            "fpr": 0.2854006586169045,
            "logloss": 0.7891589540090019,
            "mae": 0.4223175649311389,
            "precision": 0.6072507552870091,
            "recall": 0.8835164835164835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.783696404472809,
            "auditor_fn_violation": 0.005743944028407688,
            "auditor_fp_violation": 0.0012531328320801993,
            "ave_precision_score": 0.7843149529910858,
            "fpr": 0.06469298245614036,
            "logloss": 0.59826939714504,
            "mae": 0.40037626107675106,
            "precision": 0.8264705882352941,
            "recall": 0.56312625250501
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7291969178918464,
            "auditor_fn_violation": 0.006176041302276216,
            "auditor_fp_violation": 0.0015309954359004037,
            "ave_precision_score": 0.7308637546441302,
            "fpr": 0.09220636663007684,
            "logloss": 0.6444530323458466,
            "mae": 0.41084244267159487,
            "precision": 0.7485029940119761,
            "recall": 0.5494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8103815117946395,
            "auditor_fn_violation": 0.006983264775164367,
            "auditor_fp_violation": 0.017891657108873887,
            "ave_precision_score": 0.777780934186002,
            "fpr": 0.14802631578947367,
            "logloss": 2.3460781728196483,
            "mae": 0.3160535559813022,
            "precision": 0.7490706319702602,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7606674159848215,
            "auditor_fn_violation": 0.009741740147887241,
            "auditor_fp_violation": 0.02097174880120169,
            "ave_precision_score": 0.7173001032880126,
            "fpr": 0.1778265642151482,
            "logloss": 2.7855626054770255,
            "mae": 0.345716243745586,
            "precision": 0.6949152542372882,
            "recall": 0.810989010989011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.812147199284768,
            "auditor_fn_violation": 0.008202809127025984,
            "auditor_fp_violation": 0.01672613737734166,
            "ave_precision_score": 0.779491707133381,
            "fpr": 0.1611842105263158,
            "logloss": 2.338335159865836,
            "mae": 0.3141731102428789,
            "precision": 0.7384341637010676,
            "recall": 0.8316633266533067
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7616097345707666,
            "auditor_fn_violation": 0.008130179370574543,
            "auditor_fp_violation": 0.02688148747279836,
            "ave_precision_score": 0.7188433940229979,
            "fpr": 0.2030735455543359,
            "logloss": 2.773312316590309,
            "mae": 0.34690512332197077,
            "precision": 0.6702317290552585,
            "recall": 0.8263736263736263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.4377434330190241,
            "auditor_fn_violation": 0.004768308546918399,
            "auditor_fp_violation": 0.00514262350792235,
            "ave_precision_score": 0.4622048228196033,
            "fpr": 0.4276315789473684,
            "logloss": 0.6905876715017653,
            "mae": 0.49814598519444925,
            "precision": 0.5470383275261324,
            "recall": 0.9438877755511023
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.4101430528990455,
            "auditor_fn_violation": 0.0003377522587182303,
            "auditor_fp_violation": 0.003967107670383427,
            "ave_precision_score": 0.4236208295443594,
            "fpr": 0.47639956092206365,
            "logloss": 0.6899586959931511,
            "mae": 0.4977195751848176,
            "precision": 0.504,
            "recall": 0.9692307692307692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8749872817352307,
            "auditor_fn_violation": 0.012527247477410967,
            "auditor_fp_violation": 0.009929484728771079,
            "ave_precision_score": 0.8751897979772943,
            "fpr": 0.08662280701754387,
            "logloss": 0.6733835446528564,
            "mae": 0.2567933192133675,
            "precision": 0.8236607142857143,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8447890627450176,
            "auditor_fn_violation": 0.01580921822414688,
            "auditor_fp_violation": 0.012989388949871937,
            "ave_precision_score": 0.8453587663491688,
            "fpr": 0.10428100987925357,
            "logloss": 0.63505263616101,
            "mae": 0.25830524769611185,
            "precision": 0.7769953051643192,
            "recall": 0.7274725274725274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7762713341925918,
            "auditor_fn_violation": 0.0031708153148402047,
            "auditor_fp_violation": 0.005362983730512725,
            "ave_precision_score": 0.7769738100461341,
            "fpr": 0.03289473684210526,
            "logloss": 0.6851634933850526,
            "mae": 0.4031754735642746,
            "precision": 0.8795180722891566,
            "recall": 0.43887775551102204
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7307187598598042,
            "auditor_fn_violation": 0.0012448583249900606,
            "auditor_fp_violation": 0.003480848113698075,
            "ave_precision_score": 0.7322519837671397,
            "fpr": 0.05159165751920966,
            "logloss": 0.6695706354055638,
            "mae": 0.4051076658327586,
            "precision": 0.8081632653061225,
            "recall": 0.4351648351648352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8155784280852172,
            "auditor_fn_violation": 0.0018941391555039925,
            "auditor_fp_violation": 0.027574232190646114,
            "ave_precision_score": 0.8163509661573973,
            "fpr": 0.12171052631578948,
            "logloss": 0.7379880971609278,
            "mae": 0.3043333064382477,
            "precision": 0.7628205128205128,
            "recall": 0.7154308617234469
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8178652489126073,
            "auditor_fn_violation": 0.0006055415495591118,
            "auditor_fp_violation": 0.023542665665260858,
            "ave_precision_score": 0.8182903989534199,
            "fpr": 0.13830954994511527,
            "logloss": 0.6596496431387366,
            "mae": 0.29075897205771556,
            "precision": 0.7307692307692307,
            "recall": 0.7516483516483516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.779542226344496,
            "auditor_fn_violation": 0.00019776394895054574,
            "auditor_fp_violation": 0.005278025572405591,
            "ave_precision_score": 0.7801936915025289,
            "fpr": 0.029605263157894735,
            "logloss": 0.6828933501580434,
            "mae": 0.405911354814537,
            "precision": 0.8902439024390244,
            "recall": 0.43887775551102204
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7306582295105819,
            "auditor_fn_violation": 0.007746589305315982,
            "auditor_fp_violation": 0.002700907042579006,
            "ave_precision_score": 0.7321857322062993,
            "fpr": 0.050493962678375415,
            "logloss": 0.6751577404010211,
            "mae": 0.41043556067897785,
            "precision": 0.8106995884773662,
            "recall": 0.432967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.779542226344496,
            "auditor_fn_violation": 0.00019776394895054574,
            "auditor_fp_violation": 0.005278025572405591,
            "ave_precision_score": 0.7801936915025289,
            "fpr": 0.029605263157894735,
            "logloss": 0.6828933313607438,
            "mae": 0.4059113531013741,
            "precision": 0.8902439024390244,
            "recall": 0.43887775551102204
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7306582295105819,
            "auditor_fn_violation": 0.007746589305315982,
            "auditor_fp_violation": 0.002700907042579006,
            "ave_precision_score": 0.7321857322062993,
            "fpr": 0.050493962678375415,
            "logloss": 0.6751577364360626,
            "mae": 0.410435558471751,
            "precision": 0.8106995884773662,
            "recall": 0.432967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7833270061948054,
            "auditor_fn_violation": 0.005150652181556099,
            "auditor_fp_violation": 0.0013407459326281817,
            "ave_precision_score": 0.7839535721778964,
            "fpr": 0.0625,
            "logloss": 0.5969050419952268,
            "mae": 0.3998418503424705,
            "precision": 0.8308605341246291,
            "recall": 0.561122244488978
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7257140174209405,
            "auditor_fn_violation": 0.010603008407618731,
            "auditor_fp_violation": 0.0104569876942631,
            "ave_precision_score": 0.7274049789169501,
            "fpr": 0.08781558726673985,
            "logloss": 0.6381950196355107,
            "mae": 0.4077880971655181,
            "precision": 0.756838905775076,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5694535606930096,
            "auditor_fn_violation": 0.0665783321028021,
            "auditor_fp_violation": 0.060875175226201096,
            "ave_precision_score": 0.5725932824321669,
            "fpr": 0.17434210526315788,
            "logloss": 0.6953187583799803,
            "mae": 0.4976346721855327,
            "precision": 0.5815789473684211,
            "recall": 0.44288577154308617
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5518423208631683,
            "auditor_fn_violation": 0.05637326449620631,
            "auditor_fp_violation": 0.06084984690045642,
            "ave_precision_score": 0.5555368755184289,
            "fpr": 0.19099890230515917,
            "logloss": 0.697589955571078,
            "mae": 0.49725589188660213,
            "precision": 0.5606060606060606,
            "recall": 0.4879120879120879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8674957368771412,
            "auditor_fn_violation": 0.01375338396090427,
            "auditor_fp_violation": 0.008965740622743301,
            "ave_precision_score": 0.8677223221580022,
            "fpr": 0.11403508771929824,
            "logloss": 0.6193803896593326,
            "mae": 0.2510772467814062,
            "precision": 0.7928286852589641,
            "recall": 0.7975951903807615
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.843004316906226,
            "auditor_fn_violation": 0.009734502599486133,
            "auditor_fp_violation": 0.018901534846996748,
            "ave_precision_score": 0.8435861457307631,
            "fpr": 0.13611416026344675,
            "logloss": 0.6144735629505099,
            "mae": 0.2614521438462093,
            "precision": 0.7464212678936605,
            "recall": 0.8021978021978022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.779542226344496,
            "auditor_fn_violation": 0.00019776394895054574,
            "auditor_fp_violation": 0.005278025572405591,
            "ave_precision_score": 0.7801936915025289,
            "fpr": 0.029605263157894735,
            "logloss": 0.6828933235059719,
            "mae": 0.40591135340542656,
            "precision": 0.8902439024390244,
            "recall": 0.43887775551102204
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7306582295105819,
            "auditor_fn_violation": 0.007746589305315982,
            "auditor_fp_violation": 0.002700907042579006,
            "ave_precision_score": 0.7321857322062993,
            "fpr": 0.050493962678375415,
            "logloss": 0.6751577332205012,
            "mae": 0.41043555714287844,
            "precision": 0.8106995884773662,
            "recall": 0.432967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5700120245587802,
            "auditor_fn_violation": 0.06587736877263298,
            "auditor_fp_violation": 0.06127872647720997,
            "ave_precision_score": 0.5732102381778588,
            "fpr": 0.17543859649122806,
            "logloss": 0.6954565102476011,
            "mae": 0.4976297848114515,
            "precision": 0.581151832460733,
            "recall": 0.44488977955911824
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5532577734286638,
            "auditor_fn_violation": 0.05637326449620631,
            "auditor_fp_violation": 0.06084984690045642,
            "ave_precision_score": 0.5570268978054237,
            "fpr": 0.19099890230515917,
            "logloss": 0.6981823030553191,
            "mae": 0.49733984997622777,
            "precision": 0.5606060606060606,
            "recall": 0.4879120879120879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8892352810221006,
            "mae": 0.49988616767222993,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8105688245987052,
            "mae": 0.4978445508720764,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7152048870453989,
            "auditor_fn_violation": 0.011758165453714449,
            "auditor_fp_violation": 0.01596416889681832,
            "ave_precision_score": 0.6657635937060575,
            "fpr": 0.31469298245614036,
            "logloss": 3.9559730889078293,
            "mae": 0.3762734425326208,
            "precision": 0.6152815013404825,
            "recall": 0.9198396793587175
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6752346558689559,
            "auditor_fn_violation": 0.012364145185220927,
            "auditor_fp_violation": 0.011520981377703316,
            "ave_precision_score": 0.6153663387695913,
            "fpr": 0.35016465422612514,
            "logloss": 4.460729415577219,
            "mae": 0.40473256522788875,
            "precision": 0.5624142661179699,
            "recall": 0.9010989010989011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8719955242473435,
            "auditor_fn_violation": 0.006559170973526009,
            "auditor_fp_violation": 0.01320302875833652,
            "ave_precision_score": 0.8722317433327392,
            "fpr": 0.08223684210526316,
            "logloss": 0.7679761384452221,
            "mae": 0.24420324081669706,
            "precision": 0.8306997742663657,
            "recall": 0.7374749498997996
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8533303898805965,
            "auditor_fn_violation": 0.004221903233977883,
            "auditor_fp_violation": 0.010266816877539626,
            "ave_precision_score": 0.8535988669577882,
            "fpr": 0.09769484083424808,
            "logloss": 0.7003043831787658,
            "mae": 0.23781824278239433,
            "precision": 0.7935034802784223,
            "recall": 0.7516483516483516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7794177941202098,
            "auditor_fn_violation": 0.004029989804169747,
            "auditor_fp_violation": 0.005278025572405591,
            "ave_precision_score": 0.7800693829039022,
            "fpr": 0.029605263157894735,
            "logloss": 0.6807854951686536,
            "mae": 0.40608423067662935,
            "precision": 0.889795918367347,
            "recall": 0.43687374749499
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7306752882726963,
            "auditor_fn_violation": 0.003765937684708282,
            "auditor_fp_violation": 0.0029247790166965176,
            "ave_precision_score": 0.7322027544881096,
            "fpr": 0.04939626783754116,
            "logloss": 0.6753123433570899,
            "mae": 0.4105311727170946,
            "precision": 0.8132780082987552,
            "recall": 0.4307692307692308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.691316283164526,
            "mae": 0.49838770649052766,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6902234926302996,
            "mae": 0.4978406058070296,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6161622362078909,
            "auditor_fn_violation": 0.04784569138276553,
            "auditor_fp_violation": 0.05537413448876429,
            "ave_precision_score": 0.6178606225556854,
            "fpr": 0.1600877192982456,
            "logloss": 0.690340087002516,
            "mae": 0.4834443577503982,
            "precision": 0.6032608695652174,
            "recall": 0.44488977955911824
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6148690177562967,
            "auditor_fn_violation": 0.035729363940121356,
            "auditor_fp_violation": 0.048811312034201866,
            "ave_precision_score": 0.6156258730558486,
            "fpr": 0.15916575192096596,
            "logloss": 0.6715332428878195,
            "mae": 0.47455342020123836,
            "precision": 0.596100278551532,
            "recall": 0.4703296703296703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6436802845701229,
            "auditor_fn_violation": 0.002454470344197178,
            "auditor_fp_violation": 0.004834650184783994,
            "ave_precision_score": 0.608167013651787,
            "fpr": 0.019736842105263157,
            "logloss": 0.6877169435217788,
            "mae": 0.47916528394230146,
            "precision": 0.7721518987341772,
            "recall": 0.12224448897795591
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6218669423466795,
            "auditor_fn_violation": 0.006984234207066287,
            "auditor_fp_violation": 0.006227492441311842,
            "ave_precision_score": 0.5837617318164483,
            "fpr": 0.018660812294182216,
            "logloss": 0.6595055853777976,
            "mae": 0.47113338131932303,
            "precision": 0.7571428571428571,
            "recall": 0.11648351648351649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5693836187482282,
            "auditor_fn_violation": 0.0665783321028021,
            "auditor_fp_violation": 0.060875175226201096,
            "ave_precision_score": 0.572473141108921,
            "fpr": 0.17434210526315788,
            "logloss": 0.6953561965138734,
            "mae": 0.49761003567765694,
            "precision": 0.5815789473684211,
            "recall": 0.44288577154308617
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5517586480429981,
            "auditor_fn_violation": 0.05604516230202289,
            "auditor_fp_violation": 0.06084984690045642,
            "ave_precision_score": 0.5553931223685276,
            "fpr": 0.19099890230515917,
            "logloss": 0.6975492378366501,
            "mae": 0.49719917217962667,
            "precision": 0.5594936708860759,
            "recall": 0.4857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4243421052631579,
            "auc_prc": 0.43691244544865554,
            "auditor_fn_violation": 0.005721970256302082,
            "auditor_fp_violation": 0.005222271781147788,
            "ave_precision_score": 0.46020886471546046,
            "fpr": 0.07675438596491228,
            "logloss": 0.6925976116048947,
            "mae": 0.4994881989989887,
            "precision": 0.38596491228070173,
            "recall": 0.08817635270541083
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0.40843839916833047,
            "auditor_fn_violation": 0.003881738459125958,
            "auditor_fp_violation": 0.007799410711190713,
            "ave_precision_score": 0.42169642229123994,
            "fpr": 0.07903402854006586,
            "logloss": 0.6922181872504496,
            "mae": 0.49935021934341783,
            "precision": 0.34545454545454546,
            "recall": 0.08351648351648351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 4866,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5993570386239765,
            "auditor_fn_violation": 0.032738723060155406,
            "auditor_fp_violation": 0.038990484686292015,
            "ave_precision_score": 0.6013182076347943,
            "fpr": 0.1337719298245614,
            "logloss": 0.7076315360144027,
            "mae": 0.48437354033261437,
            "precision": 0.5836177474402731,
            "recall": 0.342685370741483
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5965188023406157,
            "auditor_fn_violation": 0.02990796250949929,
            "auditor_fp_violation": 0.04489475609990949,
            "ave_precision_score": 0.596803243886598,
            "fpr": 0.14270032930845225,
            "logloss": 0.6808096754806354,
            "mae": 0.47532296367398535,
            "precision": 0.5681063122923588,
            "recall": 0.3758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5539537247700941,
            "auditor_fn_violation": 0.026230091762472336,
            "auditor_fp_violation": 0.023291810033558475,
            "ave_precision_score": 0.5552363250040283,
            "fpr": 0.1337719298245614,
            "logloss": 0.6991608381453489,
            "mae": 0.49664076819470593,
            "precision": 0.5563636363636364,
            "recall": 0.3066132264529058
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5309245419715966,
            "auditor_fn_violation": 0.02896225618508824,
            "auditor_fp_violation": 0.03142873649546479,
            "ave_precision_score": 0.5328696864010399,
            "fpr": 0.13830954994511527,
            "logloss": 0.7466007651480998,
            "mae": 0.49835591646770677,
            "precision": 0.5699658703071673,
            "recall": 0.367032967032967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7492663732770238,
            "auditor_fn_violation": 0.013799528882326054,
            "auditor_fp_violation": 0.010248077821672823,
            "ave_precision_score": 0.7115237837725843,
            "fpr": 0.25548245614035087,
            "logloss": 2.9767637848034303,
            "mae": 0.35441920524826537,
            "precision": 0.6532738095238095,
            "recall": 0.8797595190380761
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7123899384615652,
            "auditor_fn_violation": 0.014002243640004344,
            "auditor_fp_violation": 0.006022878271419505,
            "ave_precision_score": 0.666609440846051,
            "fpr": 0.27442371020856204,
            "logloss": 3.302842418297565,
            "mae": 0.37631251457170206,
            "precision": 0.6118012422360248,
            "recall": 0.865934065934066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7794177941202098,
            "auditor_fn_violation": 0.004029989804169747,
            "auditor_fp_violation": 0.005278025572405591,
            "ave_precision_score": 0.7800693829039022,
            "fpr": 0.029605263157894735,
            "logloss": 0.6807854471481035,
            "mae": 0.4060842245197292,
            "precision": 0.889795918367347,
            "recall": 0.43687374749499
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7306752882726963,
            "auditor_fn_violation": 0.003765937684708282,
            "auditor_fp_violation": 0.0029247790166965176,
            "ave_precision_score": 0.7322027544881096,
            "fpr": 0.04939626783754116,
            "logloss": 0.6753123347912815,
            "mae": 0.41053116478360124,
            "precision": 0.8132780082987552,
            "recall": 0.4307692307692308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.6461552649362599,
            "auditor_fn_violation": 0.002454470344197178,
            "auditor_fp_violation": 0.004383309969839854,
            "ave_precision_score": 0.6075507667130199,
            "fpr": 0.01864035087719298,
            "logloss": 0.6859383826679345,
            "mae": 0.478408090698945,
            "precision": 0.782051282051282,
            "recall": 0.12224448897795591
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6150585627280982,
            "auditor_fn_violation": 0.006984234207066287,
            "auditor_fp_violation": 0.006227492441311842,
            "ave_precision_score": 0.5750532485489533,
            "fpr": 0.018660812294182216,
            "logloss": 0.6627675445440984,
            "mae": 0.4722048350571726,
            "precision": 0.7571428571428571,
            "recall": 0.11648351648351649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7741758241758242,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012212735227900386,
            "ave_precision_score": 0.5483516483516484,
            "fpr": 0.4506578947368421,
            "logloss": 0.6914336551712703,
            "mae": 0.49881305892159344,
            "precision": 0.5483516483516484,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.7502750275027503,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000977333564426987,
            "ave_precision_score": 0.5005500550055005,
            "fpr": 0.4983534577387486,
            "logloss": 0.6916405053259908,
            "mae": 0.49891612270865365,
            "precision": 0.5005500550055005,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8515969835681874,
            "auditor_fn_violation": 0.004212372112646355,
            "auditor_fp_violation": 0.012722484176543055,
            "ave_precision_score": 0.8518754681427851,
            "fpr": 0.0756578947368421,
            "logloss": 0.6859381892965133,
            "mae": 0.2890546397894516,
            "precision": 0.8317073170731707,
            "recall": 0.6833667334669339
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8328674924264554,
            "auditor_fn_violation": 0.002465591488643087,
            "auditor_fp_violation": 0.006451364415429355,
            "ave_precision_score": 0.8331754092769064,
            "fpr": 0.08781558726673985,
            "logloss": 0.6252024035716124,
            "mae": 0.2759292909627075,
            "precision": 0.80440097799511,
            "recall": 0.7230769230769231
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7971998819200522,
            "auditor_fn_violation": 0.016478131702000496,
            "auditor_fp_violation": 0.009069283377936367,
            "ave_precision_score": 0.7691142166919228,
            "fpr": 0.2149122807017544,
            "logloss": 2.188086291154862,
            "mae": 0.31347540988687334,
            "precision": 0.6908517350157729,
            "recall": 0.8777555110220441
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7527267217233842,
            "auditor_fn_violation": 0.015198851642320363,
            "auditor_fp_violation": 0.01794586631232308,
            "ave_precision_score": 0.7168828644026178,
            "fpr": 0.2623490669593853,
            "logloss": 2.5401635961678393,
            "mae": 0.34917311788459426,
            "precision": 0.6236220472440945,
            "recall": 0.8703296703296703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6956344586965734,
            "mae": 0.4986041213713562,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.699462161910933,
            "mae": 0.49837542866468104,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7141424903039938,
            "auditor_fn_violation": 0.012509668459726474,
            "auditor_fp_violation": 0.014594218597340817,
            "ave_precision_score": 0.6658539438984199,
            "fpr": 0.3157894736842105,
            "logloss": 3.9322993298913014,
            "mae": 0.3767091498733016,
            "precision": 0.6154873164218959,
            "recall": 0.9238476953907816
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.674244206500506,
            "auditor_fn_violation": 0.012902136283036391,
            "auditor_fp_violation": 0.011309145531226535,
            "ave_precision_score": 0.6172032090478952,
            "fpr": 0.35016465422612514,
            "logloss": 4.373112697879456,
            "mae": 0.4062425415677533,
            "precision": 0.5648021828103683,
            "recall": 0.9098901098901099
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7752865420704369,
            "auditor_fn_violation": 0.002748918890412417,
            "auditor_fp_violation": 0.007340915848944395,
            "ave_precision_score": 0.7759463899725081,
            "fpr": 0.03070175438596491,
            "logloss": 0.6846406101408562,
            "mae": 0.3930884286948055,
            "precision": 0.8884462151394422,
            "recall": 0.4468937875751503
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.721742647163675,
            "auditor_fn_violation": 0.0058672392371624076,
            "auditor_fp_violation": 0.00606139387986982,
            "ave_precision_score": 0.723302148320963,
            "fpr": 0.050493962678375415,
            "logloss": 0.6813227578610033,
            "mae": 0.3997810112316178,
            "precision": 0.8106995884773662,
            "recall": 0.432967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7741758241758242,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012212735227900386,
            "ave_precision_score": 0.5483516483516484,
            "fpr": 0.4506578947368421,
            "logloss": 0.6914336551630446,
            "mae": 0.498813058913424,
            "precision": 0.5483516483516484,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.7502750275027503,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000977333564426987,
            "ave_precision_score": 0.5005500550055005,
            "fpr": 0.4983534577387486,
            "logloss": 0.6916405053177559,
            "mae": 0.4989161227004752,
            "precision": 0.5005500550055005,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8825198522925376,
            "auditor_fn_violation": 0.013590778047322715,
            "auditor_fp_violation": 0.013548171275646746,
            "ave_precision_score": 0.8826726312708044,
            "fpr": 0.08442982456140351,
            "logloss": 0.908247104145974,
            "mae": 0.23042773567966546,
            "precision": 0.8318777292576419,
            "recall": 0.7635270541082164
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.856300648711702,
            "auditor_fn_violation": 0.009541501308790005,
            "auditor_fp_violation": 0.007308336703449076,
            "ave_precision_score": 0.8560216024368719,
            "fpr": 0.10208562019758508,
            "logloss": 0.8896317132598459,
            "mae": 0.23169132050704655,
            "precision": 0.7881548974943052,
            "recall": 0.7604395604395604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5435578827762035,
            "auditor_fn_violation": 0.0063372358752592905,
            "auditor_fp_violation": 0.00337443184231766,
            "ave_precision_score": 0.5447838077021914,
            "fpr": 0.2565789473684211,
            "logloss": 0.694765148107876,
            "mae": 0.4976826572893882,
            "precision": 0.5634328358208955,
            "recall": 0.6052104208416834
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5134355181715691,
            "auditor_fn_violation": 0.006241179237886151,
            "auditor_fp_violation": 0.006480251121767098,
            "ave_precision_score": 0.5154218886598138,
            "fpr": 0.27552140504939626,
            "logloss": 0.7387565718525723,
            "mae": 0.4994655404563766,
            "precision": 0.5325884543761639,
            "recall": 0.6285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7833689199960135,
            "auditor_fn_violation": 0.0005845023380093522,
            "auditor_fp_violation": 0.006979843676989101,
            "ave_precision_score": 0.5693262544788653,
            "fpr": 0.41118421052631576,
            "logloss": 0.6777623422193763,
            "mae": 0.48077961842717376,
            "precision": 0.5694603903559128,
            "recall": 0.9939879759519038
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7566355532502623,
            "auditor_fn_violation": 0.0008347305822607689,
            "auditor_fp_violation": 0.00603732162458837,
            "ave_precision_score": 0.516458547630823,
            "fpr": 0.4643249176728869,
            "logloss": 0.681995524946021,
            "mae": 0.48370507739394347,
            "precision": 0.5165714285714286,
            "recall": 0.9934065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5539537247700941,
            "auditor_fn_violation": 0.026230091762472336,
            "auditor_fp_violation": 0.023291810033558475,
            "ave_precision_score": 0.5552363250040283,
            "fpr": 0.1337719298245614,
            "logloss": 0.6991611226268575,
            "mae": 0.4966407202903116,
            "precision": 0.5563636363636364,
            "recall": 0.3066132264529058
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5309245419715966,
            "auditor_fn_violation": 0.02896225618508824,
            "auditor_fp_violation": 0.03142873649546479,
            "ave_precision_score": 0.5328696864010399,
            "fpr": 0.13830954994511527,
            "logloss": 0.7466012585073715,
            "mae": 0.4983558868994925,
            "precision": 0.5699658703071673,
            "recall": 0.367032967032967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 4866,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5995749504051996,
            "auditor_fn_violation": 0.032738723060155406,
            "auditor_fp_violation": 0.038990484686292015,
            "ave_precision_score": 0.6015357128832391,
            "fpr": 0.1337719298245614,
            "logloss": 0.7076307946518191,
            "mae": 0.4843716939641653,
            "precision": 0.5836177474402731,
            "recall": 0.342685370741483
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5966317663907613,
            "auditor_fn_violation": 0.02990796250949929,
            "auditor_fp_violation": 0.04489475609990949,
            "ave_precision_score": 0.5969111811070236,
            "fpr": 0.14270032930845225,
            "logloss": 0.6808062156459944,
            "mae": 0.4753198768753399,
            "precision": 0.5681063122923588,
            "recall": 0.3758241758241758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5539537247700941,
            "auditor_fn_violation": 0.026230091762472336,
            "auditor_fp_violation": 0.023291810033558475,
            "ave_precision_score": 0.5552363250040283,
            "fpr": 0.1337719298245614,
            "logloss": 0.699160908616119,
            "mae": 0.49664075641990885,
            "precision": 0.5563636363636364,
            "recall": 0.3066132264529058
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5309245419715966,
            "auditor_fn_violation": 0.02896225618508824,
            "auditor_fp_violation": 0.03142873649546479,
            "ave_precision_score": 0.5328696864010399,
            "fpr": 0.13830954994511527,
            "logloss": 0.7466008856025292,
            "mae": 0.49835590947678127,
            "precision": 0.5699658703071673,
            "recall": 0.367032967032967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8293611732995088,
            "auditor_fn_violation": 0.005502232535245934,
            "auditor_fp_violation": 0.00928964360052674,
            "ave_precision_score": 0.8295723575955417,
            "fpr": 0.19736842105263158,
            "logloss": 0.8086108455690549,
            "mae": 0.32011662156860676,
            "precision": 0.6912521440823327,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8132768155870356,
            "auditor_fn_violation": 0.0007092797433082847,
            "auditor_fp_violation": 0.010360698673137294,
            "ave_precision_score": 0.8137867903953799,
            "fpr": 0.20636663007683864,
            "logloss": 0.7620795016629052,
            "mae": 0.31064392524495626,
            "precision": 0.6636851520572451,
            "recall": 0.8153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7762713341925918,
            "auditor_fn_violation": 0.0031708153148402047,
            "auditor_fp_violation": 0.005362983730512725,
            "ave_precision_score": 0.7769738100461341,
            "fpr": 0.03289473684210526,
            "logloss": 0.685163486137013,
            "mae": 0.4031754721907046,
            "precision": 0.8795180722891566,
            "recall": 0.43887775551102204
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7307187598598042,
            "auditor_fn_violation": 0.0012448583249900606,
            "auditor_fp_violation": 0.003480848113698075,
            "ave_precision_score": 0.7322519837671397,
            "fpr": 0.05159165751920966,
            "logloss": 0.66957062778201,
            "mae": 0.40510765641436286,
            "precision": 0.8081632653061225,
            "recall": 0.4351648351648352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8521366005662637,
            "auditor_fn_violation": 0.002672010688042759,
            "auditor_fp_violation": 0.010648974130240858,
            "ave_precision_score": 0.8524053197518189,
            "fpr": 0.08442982456140351,
            "logloss": 0.6697223152827511,
            "mae": 0.2895592286736047,
            "precision": 0.817966903073286,
            "recall": 0.6933867735470942
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.833462996124495,
            "auditor_fn_violation": 0.00242457871437016,
            "auditor_fp_violation": 0.009549463670152334,
            "ave_precision_score": 0.8337700525484066,
            "fpr": 0.09989023051591657,
            "logloss": 0.6158884053394154,
            "mae": 0.2768128236683081,
            "precision": 0.7863849765258216,
            "recall": 0.7362637362637363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.5952818875356932,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011841043286181557,
            "ave_precision_score": 0.6010684346248231,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6932088644092473,
            "mae": 0.5000307420758825,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6931465126378853,
            "mae": 0.49999956520014616,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.5529909959881731,
            "auditor_fn_violation": 0.0055945223780895165,
            "auditor_fp_violation": 0.005376258442716962,
            "ave_precision_score": 0.5537945558438826,
            "fpr": 0.04057017543859649,
            "logloss": 0.6905291397312469,
            "mae": 0.4980260230388427,
            "precision": 0.5432098765432098,
            "recall": 0.08817635270541083
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5169508344599325,
            "auditor_fn_violation": 0.0010976948408342585,
            "auditor_fp_violation": 0.003671018930421555,
            "ave_precision_score": 0.5172107055343769,
            "fpr": 0.038419319429198684,
            "logloss": 0.690153459439972,
            "mae": 0.4978377054998514,
            "precision": 0.5,
            "recall": 0.07692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8105254694998503,
            "auditor_fn_violation": 0.017460359315121472,
            "auditor_fp_violation": 0.01553672316384181,
            "ave_precision_score": 0.7803778944897589,
            "fpr": 0.13815789473684212,
            "logloss": 2.334796022723405,
            "mae": 0.26843793219894313,
            "precision": 0.76,
            "recall": 0.7995991983967936
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7708056262249596,
            "auditor_fn_violation": 0.01155595228043088,
            "auditor_fp_violation": 0.024178173204691206,
            "ave_precision_score": 0.7318769359927053,
            "fpr": 0.16465422612513722,
            "logloss": 2.6235910219609573,
            "mae": 0.2905415336527626,
            "precision": 0.7076023391812866,
            "recall": 0.7978021978021979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8103917851373472,
            "auditor_fn_violation": 0.006983264775164367,
            "auditor_fp_violation": 0.017891657108873887,
            "ave_precision_score": 0.7777925730145875,
            "fpr": 0.14802631578947367,
            "logloss": 2.346024410821159,
            "mae": 0.3160621415190485,
            "precision": 0.7490706319702602,
            "recall": 0.8076152304609219
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7613797667120678,
            "auditor_fn_violation": 0.009741740147887241,
            "auditor_fp_violation": 0.02097174880120169,
            "ave_precision_score": 0.7186305946949773,
            "fpr": 0.1778265642151482,
            "logloss": 2.7657067494487393,
            "mae": 0.3457218053494172,
            "precision": 0.6949152542372882,
            "recall": 0.810989010989011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6782548411929816,
            "auditor_fn_violation": 0.01351606722216363,
            "auditor_fp_violation": 0.01609160613397902,
            "ave_precision_score": 0.6791703566556422,
            "fpr": 0.05482456140350877,
            "logloss": 0.6771360536806696,
            "mae": 0.46172056942024237,
            "precision": 0.696969696969697,
            "recall": 0.23046092184368738
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6488782377633991,
            "auditor_fn_violation": 0.022016622236161226,
            "auditor_fp_violation": 0.017019084483987135,
            "ave_precision_score": 0.6505634681588182,
            "fpr": 0.06037321624588365,
            "logloss": 0.6961987209041491,
            "mae": 0.4532537726564439,
            "precision": 0.6802325581395349,
            "recall": 0.2571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7222866217540258,
            "auditor_fn_violation": 0.011437348380972472,
            "auditor_fp_violation": 0.014814578819931182,
            "ave_precision_score": 0.6773963838049153,
            "fpr": 0.3081140350877193,
            "logloss": 3.6487226637273933,
            "mae": 0.37067477874479826,
            "precision": 0.6197564276048715,
            "recall": 0.9178356713426854
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6877194099030429,
            "auditor_fn_violation": 0.011169949699038615,
            "auditor_fp_violation": 0.01323251872821461,
            "ave_precision_score": 0.6388107324134229,
            "fpr": 0.33699231613611413,
            "logloss": 3.9008340973144744,
            "mae": 0.39903953366633677,
            "precision": 0.5718270571827058,
            "recall": 0.9010989010989011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8091916605681452,
            "auditor_fn_violation": 0.009505853812888938,
            "auditor_fp_violation": 0.017745635274627254,
            "ave_precision_score": 0.7747448274966413,
            "fpr": 0.18969298245614036,
            "logloss": 2.3871648701699417,
            "mae": 0.3215171627908651,
            "precision": 0.7140495867768595,
            "recall": 0.8657314629258517
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.75777687569575,
            "auditor_fn_violation": 0.006586169045005491,
            "auditor_fp_violation": 0.0257669420532671,
            "ave_precision_score": 0.7141698729060462,
            "fpr": 0.23380900109769484,
            "logloss": 2.8159339888854658,
            "mae": 0.35794018809667966,
            "precision": 0.6467661691542289,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 4866,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8188374302900577,
            "auditor_fn_violation": 0.0005910944696410479,
            "auditor_fp_violation": 0.02540514421647339,
            "ave_precision_score": 0.8195732031402074,
            "fpr": 0.1074561403508772,
            "logloss": 0.7362163509819157,
            "mae": 0.29993481307698694,
            "precision": 0.7822222222222223,
            "recall": 0.7054108216432866
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8196639493734323,
            "auditor_fn_violation": 0.0016163858095801075,
            "auditor_fp_violation": 0.017726808789261847,
            "ave_precision_score": 0.8200413168783853,
            "fpr": 0.11745334796926454,
            "logloss": 0.655304882657748,
            "mae": 0.2867844392708156,
            "precision": 0.7606263982102909,
            "recall": 0.7472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6808957140278837,
            "auditor_fn_violation": 0.002454470344197178,
            "auditor_fp_violation": 0.004834650184783994,
            "ave_precision_score": 0.5985106039273835,
            "fpr": 0.019736842105263157,
            "logloss": 0.6876370517274311,
            "mae": 0.47921524104113067,
            "precision": 0.7721518987341772,
            "recall": 0.12224448897795591
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6626160656239318,
            "auditor_fn_violation": 0.006984234207066287,
            "auditor_fp_violation": 0.006227492441311842,
            "ave_precision_score": 0.5707039370965693,
            "fpr": 0.018660812294182216,
            "logloss": 0.6597190943825866,
            "mae": 0.4713306732651275,
            "precision": 0.7571428571428571,
            "recall": 0.11648351648351649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5435578827762035,
            "auditor_fn_violation": 0.0063372358752592905,
            "auditor_fp_violation": 0.00337443184231766,
            "ave_precision_score": 0.5447838077021914,
            "fpr": 0.2565789473684211,
            "logloss": 0.6947651476831629,
            "mae": 0.4976826573981446,
            "precision": 0.5634328358208955,
            "recall": 0.6052104208416834
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5134355181715691,
            "auditor_fn_violation": 0.006241179237886151,
            "auditor_fp_violation": 0.006480251121767098,
            "ave_precision_score": 0.5154218886598138,
            "fpr": 0.27552140504939626,
            "logloss": 0.7387565701605386,
            "mae": 0.49946554052908826,
            "precision": 0.5325884543761639,
            "recall": 0.6285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.8020972853260169,
            "auditor_fn_violation": 0.0008613718665401124,
            "auditor_fp_violation": 0.004035512510088782,
            "ave_precision_score": 0.7352003870124812,
            "fpr": 0.02631578947368421,
            "logloss": 0.6796306826645554,
            "mae": 0.4073396600946348,
            "precision": 0.8987341772151899,
            "recall": 0.42685370741482964
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7668317167988687,
            "auditor_fn_violation": 0.003992714201276229,
            "auditor_fp_violation": 0.0074527702351377895,
            "ave_precision_score": 0.6954651600936939,
            "fpr": 0.036223929747530186,
            "logloss": 0.6291556323964228,
            "mae": 0.4093640868975776,
            "precision": 0.852017937219731,
            "recall": 0.4175824175824176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8793977296949602,
            "auditor_fn_violation": 0.012072390394824745,
            "auditor_fp_violation": 0.008262180875918613,
            "ave_precision_score": 0.8796106900191003,
            "fpr": 0.08114035087719298,
            "logloss": 0.701256114200866,
            "mae": 0.2441263329693894,
            "precision": 0.8321995464852607,
            "recall": 0.7354709418837675
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8504092520546197,
            "auditor_fn_violation": 0.009963691632187795,
            "auditor_fp_violation": 0.009994800392859209,
            "ave_precision_score": 0.8509692709947321,
            "fpr": 0.09879253567508232,
            "logloss": 0.6675712041041754,
            "mae": 0.24502650518279515,
            "precision": 0.7887323943661971,
            "recall": 0.7384615384615385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8090035823577207,
            "auditor_fn_violation": 0.006341630629680416,
            "auditor_fp_violation": 0.016827025190093877,
            "ave_precision_score": 0.7738256414668125,
            "fpr": 0.1962719298245614,
            "logloss": 2.455989712512513,
            "mae": 0.3286344602840887,
            "precision": 0.7094155844155844,
            "recall": 0.875751503006012
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7585161225460133,
            "auditor_fn_violation": 0.008103641693103826,
            "auditor_fp_violation": 0.025998035703969035,
            "ave_precision_score": 0.7149045597985693,
            "fpr": 0.24039517014270034,
            "logloss": 2.878070203309498,
            "mae": 0.36750290501159544,
            "precision": 0.6421568627450981,
            "recall": 0.8637362637362638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 4866,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7745800879038465,
            "auditor_fn_violation": 0.00436399114017509,
            "auditor_fp_violation": 0.006236459793551677,
            "ave_precision_score": 0.7752905012065082,
            "fpr": 0.03399122807017544,
            "logloss": 0.6751254846306216,
            "mae": 0.39173806175232445,
            "precision": 0.8803088803088803,
            "recall": 0.45691382765531063
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7206531151684394,
            "auditor_fn_violation": 0.0012014330345834314,
            "auditor_fp_violation": 0.005437922468080192,
            "ave_precision_score": 0.72221546999822,
            "fpr": 0.05598243688254665,
            "logloss": 0.6763515002700948,
            "mae": 0.4006307474097495,
            "precision": 0.796,
            "recall": 0.43736263736263736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 4866,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7703700524875683,
            "auditor_fn_violation": 0.00028126428295186255,
            "auditor_fp_violation": 0.007340915848944395,
            "ave_precision_score": 0.7710310567335363,
            "fpr": 0.03070175438596491,
            "logloss": 0.6833107784238704,
            "mae": 0.39426364461840513,
            "precision": 0.8893280632411067,
            "recall": 0.45090180360721444
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.722331345171149,
            "auditor_fn_violation": 0.0019420754876298167,
            "auditor_fp_violation": 0.005257380553469296,
            "ave_precision_score": 0.723885967959179,
            "fpr": 0.052689352360043906,
            "logloss": 0.6788918968906671,
            "mae": 0.39944468095428354,
            "precision": 0.808,
            "recall": 0.44395604395604393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.569400052443719,
            "auditor_fn_violation": 0.0665783321028021,
            "auditor_fp_violation": 0.060875175226201096,
            "ave_precision_score": 0.5725182552155559,
            "fpr": 0.17434210526315788,
            "logloss": 0.6953599970555995,
            "mae": 0.49760458345439185,
            "precision": 0.5815789473684211,
            "recall": 0.44288577154308617
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5517557828402959,
            "auditor_fn_violation": 0.05604516230202289,
            "auditor_fp_violation": 0.06084984690045642,
            "ave_precision_score": 0.5553873919631233,
            "fpr": 0.19099890230515917,
            "logloss": 0.6975385062653583,
            "mae": 0.49718792092680736,
            "precision": 0.5594936708860759,
            "recall": 0.4857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8573003628221841,
            "auditor_fn_violation": 0.002131455894244634,
            "auditor_fp_violation": 0.011225096639904847,
            "ave_precision_score": 0.8575150329257587,
            "fpr": 0.07675438596491228,
            "logloss": 0.6517377429257238,
            "mae": 0.2876973621379492,
            "precision": 0.8309178743961353,
            "recall": 0.6893787575150301
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.837822747168093,
            "auditor_fn_violation": 0.005247222590801076,
            "auditor_fp_violation": 0.005770119590964239,
            "ave_precision_score": 0.8381176582148208,
            "fpr": 0.09769484083424808,
            "logloss": 0.5977470306871956,
            "mae": 0.2747168353397654,
            "precision": 0.789598108747045,
            "recall": 0.734065934065934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8749872817352307,
            "auditor_fn_violation": 0.012527247477410967,
            "auditor_fp_violation": 0.009929484728771079,
            "ave_precision_score": 0.8751897979772943,
            "fpr": 0.08662280701754387,
            "logloss": 0.6733833847098141,
            "mae": 0.25679329278379404,
            "precision": 0.8236607142857143,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8447890627450176,
            "auditor_fn_violation": 0.01580921822414688,
            "auditor_fp_violation": 0.012989388949871937,
            "ave_precision_score": 0.8453587663491688,
            "fpr": 0.10428100987925357,
            "logloss": 0.6350525249413362,
            "mae": 0.25830522542545514,
            "precision": 0.7769953051643192,
            "recall": 0.7274725274725274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8521366005662637,
            "auditor_fn_violation": 0.002672010688042759,
            "auditor_fp_violation": 0.010648974130240858,
            "ave_precision_score": 0.8524053197518189,
            "fpr": 0.08442982456140351,
            "logloss": 0.6697222710366852,
            "mae": 0.2895592253969665,
            "precision": 0.817966903073286,
            "recall": 0.6933867735470942
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.833462996124495,
            "auditor_fn_violation": 0.00242457871437016,
            "auditor_fp_violation": 0.009549463670152334,
            "ave_precision_score": 0.8337700525484066,
            "fpr": 0.09989023051591657,
            "logloss": 0.6158883833119879,
            "mae": 0.27681282660845785,
            "precision": 0.7863849765258216,
            "recall": 0.7362637362637363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 4866,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.819808047428491,
            "auditor_fn_violation": 0.0006152656189572272,
            "auditor_fp_violation": 0.026520220041629506,
            "ave_precision_score": 0.8205289500743485,
            "fpr": 0.10416666666666667,
            "logloss": 0.7478237527211093,
            "mae": 0.2989169956400048,
            "precision": 0.786036036036036,
            "recall": 0.6993987975951904
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8199584658365542,
            "auditor_fn_violation": 0.0016163858095801075,
            "auditor_fp_violation": 0.017587189708629426,
            "ave_precision_score": 0.8203354264868635,
            "fpr": 0.11306256860592755,
            "logloss": 0.6617401359357279,
            "mae": 0.28535489026553607,
            "precision": 0.7674943566591422,
            "recall": 0.7472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8516448462207268,
            "auditor_fn_violation": 0.004212372112646355,
            "auditor_fp_violation": 0.012722484176543055,
            "ave_precision_score": 0.8519229589589525,
            "fpr": 0.0756578947368421,
            "logloss": 0.6877870977424646,
            "mae": 0.28886118803740646,
            "precision": 0.8317073170731707,
            "recall": 0.6833667334669339
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8328110405773149,
            "auditor_fn_violation": 0.004861220009408827,
            "auditor_fp_violation": 0.006451364415429355,
            "ave_precision_score": 0.8331188379318166,
            "fpr": 0.08781558726673985,
            "logloss": 0.6273531024875506,
            "mae": 0.27564652154683317,
            "precision": 0.8048780487804879,
            "recall": 0.7252747252747253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7794177941202098,
            "auditor_fn_violation": 0.004029989804169747,
            "auditor_fp_violation": 0.005278025572405591,
            "ave_precision_score": 0.7800693829039022,
            "fpr": 0.029605263157894735,
            "logloss": 0.6807855129936059,
            "mae": 0.4060842327248633,
            "precision": 0.889795918367347,
            "recall": 0.43687374749499
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7306752882726963,
            "auditor_fn_violation": 0.003765937684708282,
            "auditor_fp_violation": 0.0029247790166965176,
            "ave_precision_score": 0.7322027544881096,
            "fpr": 0.04939626783754116,
            "logloss": 0.6753123493552939,
            "mae": 0.4105311743525318,
            "precision": 0.8132780082987552,
            "recall": 0.4307692307692308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6770177372713153,
            "auditor_fn_violation": 0.00983985514889428,
            "auditor_fp_violation": 0.009740983815470897,
            "ave_precision_score": 0.6099999109189819,
            "fpr": 0.3344298245614035,
            "logloss": 5.37008187034055,
            "mae": 0.38870472915056,
            "precision": 0.6028645833333334,
            "recall": 0.9278557114228457
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6401480422362669,
            "auditor_fn_violation": 0.006644069432214329,
            "auditor_fp_violation": 0.015165520827315267,
            "ave_precision_score": 0.5692238157028318,
            "fpr": 0.36553238199780463,
            "logloss": 5.597856667973909,
            "mae": 0.42150097675559833,
            "precision": 0.556,
            "recall": 0.9164835164835164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.696678477710505,
            "mae": 0.5015089436058413,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6936244172922583,
            "mae": 0.49998243488412264,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8517022572292872,
            "auditor_fn_violation": 0.004432109833702498,
            "auditor_fp_violation": 0.012942844399133428,
            "ave_precision_score": 0.8519547183994711,
            "fpr": 0.08552631578947369,
            "logloss": 0.6799922225833219,
            "mae": 0.2905699325748022,
            "precision": 0.8156028368794326,
            "recall": 0.6913827655310621
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8330956573301587,
            "auditor_fn_violation": 0.003874500910724843,
            "auditor_fp_violation": 0.004145242359466173,
            "ave_precision_score": 0.8334249335447568,
            "fpr": 0.09879253567508232,
            "logloss": 0.6222618143804526,
            "mae": 0.2767093820083774,
            "precision": 0.7867298578199052,
            "recall": 0.7296703296703296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.872499767739655,
            "auditor_fn_violation": 0.0064273283408923165,
            "auditor_fp_violation": 0.01320302875833652,
            "ave_precision_score": 0.8727350477909975,
            "fpr": 0.08223684210526316,
            "logloss": 0.7642243725149863,
            "mae": 0.2436681220205735,
            "precision": 0.831081081081081,
            "recall": 0.7394789579158316
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8537209940406457,
            "auditor_fn_violation": 0.0028926068443082707,
            "auditor_fp_violation": 0.009956284784408888,
            "ave_precision_score": 0.8539242500423831,
            "fpr": 0.09659714599341383,
            "logloss": 0.6990625081082399,
            "mae": 0.2375804805764959,
            "precision": 0.7948717948717948,
            "recall": 0.7494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6235262418230814,
            "auditor_fn_violation": 0.07250246106247582,
            "auditor_fp_violation": 0.0611353595854042,
            "ave_precision_score": 0.6252150497797561,
            "fpr": 0.2543859649122807,
            "logloss": 0.6886094784116126,
            "mae": 0.4822790579106495,
            "precision": 0.5951134380453752,
            "recall": 0.6833667334669339
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.619708313114486,
            "auditor_fn_violation": 0.04771956912461853,
            "auditor_fp_violation": 0.06431625166098563,
            "ave_precision_score": 0.6204807890578203,
            "fpr": 0.278814489571899,
            "logloss": 0.6710846079105153,
            "mae": 0.47430080183987167,
            "precision": 0.5620689655172414,
            "recall": 0.7164835164835165
        }
    }
]