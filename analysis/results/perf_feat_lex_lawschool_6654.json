[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7403591053547797,
            "auditor_fn_violation": 0.008417250843811435,
            "auditor_fp_violation": 0.02364324821164529,
            "ave_precision_score": 0.7393228108929398,
            "fpr": 0.20723684210526316,
            "logloss": 1.3025580413381048,
            "mae": 0.3068948704472534,
            "precision": 0.6690017513134852,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7453036499940955,
            "auditor_fn_violation": 0.013366317427788342,
            "auditor_fp_violation": 0.022975008296530777,
            "ave_precision_score": 0.7412311091920335,
            "fpr": 0.18660812294182216,
            "logloss": 1.411606640610303,
            "mae": 0.2936520423824103,
            "precision": 0.6953405017921147,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6980654928913542,
            "auditor_fn_violation": 0.009970420236638116,
            "auditor_fp_violation": 0.023828078168085364,
            "ave_precision_score": 0.6989654997805752,
            "fpr": 0.14692982456140352,
            "logloss": 1.79782590828543,
            "mae": 0.3699754883786123,
            "precision": 0.6723716381418093,
            "recall": 0.5813953488372093
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7305931614309026,
            "auditor_fn_violation": 0.017976179337320954,
            "auditor_fp_violation": 0.022923952722538485,
            "ave_precision_score": 0.7310883285451376,
            "fpr": 0.13721185510428102,
            "logloss": 1.519536656593028,
            "mae": 0.35673241332476463,
            "precision": 0.7002398081534772,
            "recall": 0.6070686070686071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7884631650544122,
            "auditor_fn_violation": 0.01415238678090576,
            "auditor_fp_violation": 0.023675718339128005,
            "ave_precision_score": 0.7893964399827473,
            "fpr": 0.15350877192982457,
            "logloss": 1.0099079867461864,
            "mae": 0.2960779137049281,
            "precision": 0.7154471544715447,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8193220360465008,
            "auditor_fn_violation": 0.015872074049900615,
            "auditor_fp_violation": 0.01933474587088046,
            "ave_precision_score": 0.8196086930601431,
            "fpr": 0.1394072447859495,
            "logloss": 0.9003346987493035,
            "mae": 0.28144259604236993,
            "precision": 0.7413441955193483,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6023867229168348,
            "auditor_fn_violation": 0.06869645042839657,
            "auditor_fp_violation": 0.07804819565999281,
            "ave_precision_score": 0.5816434995231443,
            "fpr": 0.15460526315789475,
            "logloss": 3.943499886041288,
            "mae": 0.4280109924395329,
            "precision": 0.6094182825484764,
            "recall": 0.46511627906976744
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.60630525702476,
            "auditor_fn_violation": 0.06639570415640669,
            "auditor_fp_violation": 0.07773211140326246,
            "ave_precision_score": 0.581640362733993,
            "fpr": 0.15367727771679474,
            "logloss": 4.103609184926719,
            "mae": 0.41654057727636773,
            "precision": 0.6382428940568475,
            "recall": 0.5135135135135135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6828077096800098,
            "auditor_fn_violation": 0.0008762657171469946,
            "auditor_fp_violation": 0.02767204172161612,
            "ave_precision_score": 0.6730364502179182,
            "fpr": 0.18530701754385964,
            "logloss": 2.144570864316144,
            "mae": 0.3064407038929959,
            "precision": 0.6876155268022182,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6924799809923575,
            "auditor_fn_violation": 0.006631811242129577,
            "auditor_fp_violation": 0.02795803231817834,
            "ave_precision_score": 0.6788138066650333,
            "fpr": 0.19099890230515917,
            "logloss": 2.205964656081543,
            "mae": 0.3109852079823832,
            "precision": 0.6847826086956522,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.78988751419023,
            "auditor_fn_violation": 0.006560402062238054,
            "auditor_fp_violation": 0.024557407185389443,
            "ave_precision_score": 0.7907349772053753,
            "fpr": 0.18969298245614036,
            "logloss": 1.0842071633991497,
            "mae": 0.29698120982410964,
            "precision": 0.6882882882882883,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8179062422076824,
            "auditor_fn_violation": 0.009687556339587074,
            "auditor_fp_violation": 0.017476322977561073,
            "ave_precision_score": 0.8182228450439308,
            "fpr": 0.17453347969264543,
            "logloss": 0.9775316667283707,
            "mae": 0.2774822822660976,
            "precision": 0.7135135135135136,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8304028537898401,
            "auditor_fn_violation": 0.014759745558399172,
            "auditor_fp_violation": 0.014966231067417983,
            "ave_precision_score": 0.7968988716165681,
            "fpr": 0.11403508771929824,
            "logloss": 3.372543793812878,
            "mae": 0.23716294075441977,
            "precision": 0.7748917748917749,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8333157782004701,
            "auditor_fn_violation": 0.006718531416665338,
            "auditor_fp_violation": 0.03275725627345366,
            "ave_precision_score": 0.800320957721479,
            "fpr": 0.1119648737650933,
            "logloss": 3.171076999285465,
            "mae": 0.2411706806910925,
            "precision": 0.7806451612903226,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8117909084106931,
            "auditor_fn_violation": 0.014734245762397543,
            "auditor_fp_violation": 0.031216281021460256,
            "ave_precision_score": 0.8124133103284878,
            "fpr": 0.13596491228070176,
            "logloss": 0.9854624678427046,
            "mae": 0.27215709267294175,
            "precision": 0.7432712215320911,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8438631282725436,
            "auditor_fn_violation": 0.018259160959490275,
            "auditor_fp_violation": 0.021034896484823734,
            "ave_precision_score": 0.8440743378458357,
            "fpr": 0.13721185510428102,
            "logloss": 0.894228569281964,
            "mae": 0.2660935528490056,
            "precision": 0.7469635627530364,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7858659547145418,
            "auditor_fn_violation": 0.013985479025258712,
            "auditor_fp_violation": 0.027689525636414507,
            "ave_precision_score": 0.7864126018916195,
            "fpr": 0.20175438596491227,
            "logloss": 1.1486115737279097,
            "mae": 0.29853148296613996,
            "precision": 0.6783216783216783,
            "recall": 0.8202959830866807
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8155765220472311,
            "auditor_fn_violation": 0.01679404643180714,
            "auditor_fp_violation": 0.01752737855155336,
            "ave_precision_score": 0.815892212488767,
            "fpr": 0.18221734357848518,
            "logloss": 1.0353046923321578,
            "mae": 0.2795287633926807,
            "precision": 0.7067137809187279,
            "recall": 0.8316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7546538193186645,
            "auditor_fn_violation": 0.0066994918586105855,
            "auditor_fp_violation": 0.019749330615833432,
            "ave_precision_score": 0.5404381278896052,
            "fpr": 0.4232456140350877,
            "logloss": 14.309713739808933,
            "mae": 0.4387621946997352,
            "precision": 0.5453474676089517,
            "recall": 0.9788583509513742
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7552941052297937,
            "auditor_fn_violation": 0.005038898562499002,
            "auditor_fp_violation": 0.00931764225359306,
            "ave_precision_score": 0.545215592614346,
            "fpr": 0.41822173435784854,
            "logloss": 14.143360756640234,
            "mae": 0.4290504030577554,
            "precision": 0.5528169014084507,
            "recall": 0.9792099792099792
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8650759107693963,
            "auditor_fn_violation": 0.0055566373650828985,
            "auditor_fp_violation": 0.013220337289693487,
            "ave_precision_score": 0.8647625673731375,
            "fpr": 0.09868421052631579,
            "logloss": 0.9821319406495721,
            "mae": 0.22143299737096622,
            "precision": 0.8047722342733189,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8845695081898384,
            "auditor_fn_violation": 0.00736208639611494,
            "auditor_fp_violation": 0.00805401679728384,
            "ave_precision_score": 0.8847504436358927,
            "fpr": 0.10428100987925357,
            "logloss": 0.8671912542003981,
            "mae": 0.22812132119607884,
            "precision": 0.7970085470085471,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8300810813065059,
            "auditor_fn_violation": 0.013487073921590445,
            "auditor_fp_violation": 0.016072713103944376,
            "ave_precision_score": 0.7931845748515476,
            "fpr": 0.11732456140350878,
            "logloss": 3.6523378099028796,
            "mae": 0.2384866686600115,
            "precision": 0.7703862660944206,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8353398796390141,
            "auditor_fn_violation": 0.00928590500489513,
            "auditor_fp_violation": 0.03281341740484518,
            "ave_precision_score": 0.7997715656501735,
            "fpr": 0.1119648737650933,
            "logloss": 3.4303568144835292,
            "mae": 0.24208717691438814,
            "precision": 0.7811158798283262,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8109096542054213,
            "auditor_fn_violation": 0.010800322688327587,
            "auditor_fp_violation": 0.014848839068057389,
            "ave_precision_score": 0.7755984328313523,
            "fpr": 0.1118421052631579,
            "logloss": 3.700640459368042,
            "mae": 0.25012810701112254,
            "precision": 0.7743362831858407,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8108967350849542,
            "auditor_fn_violation": 0.008982384394019962,
            "auditor_fp_violation": 0.030393383197610598,
            "ave_precision_score": 0.7786526576879869,
            "fpr": 0.1141602634467618,
            "logloss": 3.5196063524514343,
            "mae": 0.260315481847926,
            "precision": 0.7724288840262582,
            "recall": 0.7338877338877339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6850235847579118,
            "auditor_fn_violation": 2.7817959274507205e-05,
            "auditor_fp_violation": 0.026575550493545944,
            "ave_precision_score": 0.6756353580431314,
            "fpr": 0.18530701754385964,
            "logloss": 2.1000506023638343,
            "mae": 0.3063624245747518,
            "precision": 0.6881918819188192,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6947616665261328,
            "auditor_fn_violation": 0.008432395918674734,
            "auditor_fp_violation": 0.02618129834324663,
            "ave_precision_score": 0.6818141552966751,
            "fpr": 0.19099890230515917,
            "logloss": 2.160220574665847,
            "mae": 0.31010367279077616,
            "precision": 0.6847826086956522,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 6654,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8153083748907346,
            "auditor_fn_violation": 0.011085456770891294,
            "auditor_fp_violation": 0.014813871238460617,
            "ave_precision_score": 0.8157748261368748,
            "fpr": 0.13157894736842105,
            "logloss": 0.8219546567853876,
            "mae": 0.28356963930061413,
            "precision": 0.7494780793319415,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8438753639353352,
            "auditor_fn_violation": 0.008398164270831671,
            "auditor_fp_violation": 0.017236361779797312,
            "ave_precision_score": 0.8441110406506676,
            "fpr": 0.13391877058177826,
            "logloss": 0.7384933752507075,
            "mae": 0.27233084281631903,
            "precision": 0.7505112474437627,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.685571703759269,
            "auditor_fn_violation": 0.0067574459404324844,
            "auditor_fp_violation": 0.03249010909962834,
            "ave_precision_score": 0.6743581041281199,
            "fpr": 0.16776315789473684,
            "logloss": 2.0495847724491805,
            "mae": 0.3075607610364487,
            "precision": 0.7034883720930233,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6935182566508916,
            "auditor_fn_violation": 0.01483827828504009,
            "auditor_fp_violation": 0.035266637735174744,
            "ave_precision_score": 0.6794150583771476,
            "fpr": 0.17014270032930845,
            "logloss": 2.094375138139781,
            "mae": 0.307289966375592,
            "precision": 0.7007722007722008,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8041629929770198,
            "auditor_fn_violation": 0.02065483476132192,
            "auditor_fp_violation": 0.02986252647564241,
            "ave_precision_score": 0.8051123091493395,
            "fpr": 0.12828947368421054,
            "logloss": 0.9732041944306428,
            "mae": 0.27588913286833483,
            "precision": 0.7505330490405118,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8373033043803673,
            "auditor_fn_violation": 0.0173075211494531,
            "auditor_fp_violation": 0.017440584075766475,
            "ave_precision_score": 0.837531198784559,
            "fpr": 0.12843029637760703,
            "logloss": 0.8859415182014517,
            "mae": 0.26962570075283565,
            "precision": 0.7577639751552795,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8314527561505449,
            "auditor_fn_violation": 0.014963743926412231,
            "auditor_fp_violation": 0.019394656915637618,
            "ave_precision_score": 0.797026969823839,
            "fpr": 0.11513157894736842,
            "logloss": 3.443343348526433,
            "mae": 0.2370865648777204,
            "precision": 0.7741935483870968,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8332182230355609,
            "auditor_fn_violation": 0.005620836575831091,
            "auditor_fp_violation": 0.03171572256401093,
            "ave_precision_score": 0.7980082160208563,
            "fpr": 0.1119648737650933,
            "logloss": 3.2740112468868467,
            "mae": 0.23999287894707416,
            "precision": 0.7806451612903226,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.863791707716022,
            "auditor_fn_violation": 0.005906680019287121,
            "auditor_fp_violation": 0.013527554649722254,
            "ave_precision_score": 0.8633079432721626,
            "fpr": 0.09320175438596491,
            "logloss": 1.0063020807622869,
            "mae": 0.22179776242061747,
            "precision": 0.8127753303964758,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8835808896367563,
            "auditor_fn_violation": 0.00885230413221632,
            "auditor_fp_violation": 0.008562019758507141,
            "ave_precision_score": 0.883665822766267,
            "fpr": 0.10208562019758508,
            "logloss": 0.8882728872410797,
            "mae": 0.22933390881180135,
            "precision": 0.7995689655172413,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8087465802574145,
            "auditor_fn_violation": 0.01086291309669523,
            "auditor_fp_violation": 0.023410961915038168,
            "ave_precision_score": 0.809240793167233,
            "fpr": 0.14802631578947367,
            "logloss": 0.9590915030568662,
            "mae": 0.27912885882774424,
            "precision": 0.7294589178356713,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8338044313385173,
            "auditor_fn_violation": 0.011529218993543916,
            "auditor_fp_violation": 0.01597528910218774,
            "ave_precision_score": 0.8340575376085346,
            "fpr": 0.1437980241492865,
            "logloss": 0.8815801019018913,
            "mae": 0.2687406620789586,
            "precision": 0.741106719367589,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7341954270897281,
            "auditor_fn_violation": 0.0033636549089425473,
            "auditor_fp_violation": 0.022699116812532474,
            "ave_precision_score": 0.7347010276393839,
            "fpr": 0.18092105263157895,
            "logloss": 1.2563623606869943,
            "mae": 0.3024387124128037,
            "precision": 0.6921641791044776,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7496665062194656,
            "auditor_fn_violation": 0.010623221380630828,
            "auditor_fp_violation": 0.021800730094708093,
            "ave_precision_score": 0.7500289567284566,
            "fpr": 0.18111964873765093,
            "logloss": 1.2218702563373252,
            "mae": 0.29728040676153344,
            "precision": 0.6978021978021978,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8060147981679351,
            "auditor_fn_violation": 0.017318997811653875,
            "auditor_fp_violation": 0.030302122047716106,
            "ave_precision_score": 0.806712768502506,
            "fpr": 0.12828947368421054,
            "logloss": 1.0439239656019812,
            "mae": 0.27534873649745495,
            "precision": 0.75,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8401058206805636,
            "auditor_fn_violation": 0.018964332905057394,
            "auditor_fp_violation": 0.017917953692594392,
            "ave_precision_score": 0.8403183361135017,
            "fpr": 0.13062568605927552,
            "logloss": 0.9473037867398933,
            "mae": 0.2699778563512575,
            "precision": 0.7531120331950207,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7966386548531488,
            "auditor_fn_violation": 0.010403916768665854,
            "auditor_fp_violation": 0.02241687647364425,
            "ave_precision_score": 0.7765922649653274,
            "fpr": 0.12938596491228072,
            "logloss": 2.265006936641717,
            "mae": 0.236545912656037,
            "precision": 0.7601626016260162,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.7933123940049661,
            "auditor_fn_violation": 0.005401754029635478,
            "auditor_fp_violation": 0.036734485487453096,
            "ave_precision_score": 0.7705061385250325,
            "fpr": 0.13172338090010977,
            "logloss": 2.294896240320887,
            "mae": 0.2406545019476808,
            "precision": 0.7623762376237624,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8747483654662284,
            "auditor_fn_violation": 0.007401895330291906,
            "auditor_fp_violation": 0.007560544299244695,
            "ave_precision_score": 0.873949453314613,
            "fpr": 0.08771929824561403,
            "logloss": 1.042068852717482,
            "mae": 0.21464271860296702,
            "precision": 0.8177676537585421,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8890614618290664,
            "auditor_fn_violation": 0.013051386267632156,
            "auditor_fp_violation": 0.008388430806933352,
            "ave_precision_score": 0.8888920578281263,
            "fpr": 0.08562019758507135,
            "logloss": 0.9380536573757207,
            "mae": 0.21448731619651681,
            "precision": 0.8266666666666667,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.847446542064051,
            "auditor_fn_violation": 0.008199343496161126,
            "auditor_fp_violation": 0.013182871757982658,
            "ave_precision_score": 0.824161928899252,
            "fpr": 0.09539473684210527,
            "logloss": 3.086456259613097,
            "mae": 0.23088467131709672,
            "precision": 0.8013698630136986,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8606531518312741,
            "auditor_fn_violation": 0.013275033033540174,
            "auditor_fp_violation": 0.001827789548924006,
            "ave_precision_score": 0.8489302063505133,
            "fpr": 0.09659714599341383,
            "logloss": 2.739547440913319,
            "mae": 0.24652031910587757,
            "precision": 0.7972350230414746,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8030914030511714,
            "auditor_fn_violation": 0.01806544638551983,
            "auditor_fp_violation": 0.029123206649882105,
            "ave_precision_score": 0.8038025261171877,
            "fpr": 0.13815789473684212,
            "logloss": 1.007163480219921,
            "mae": 0.2777359683692761,
            "precision": 0.7385892116182573,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8369281107484566,
            "auditor_fn_violation": 0.020856201975850714,
            "auditor_fp_violation": 0.02031246011283282,
            "ave_precision_score": 0.8371529269115826,
            "fpr": 0.1394072447859495,
            "logloss": 0.9089500420263766,
            "mae": 0.27039912635784175,
            "precision": 0.744466800804829,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7868996503768184,
            "auditor_fn_violation": 0.01071686881050407,
            "auditor_fp_violation": 0.023698197658154507,
            "ave_precision_score": 0.7876681497102942,
            "fpr": 0.16447368421052633,
            "logloss": 1.0698374978194007,
            "mae": 0.2932575515462334,
            "precision": 0.7064579256360078,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8121895746928653,
            "auditor_fn_violation": 0.017999000435882984,
            "auditor_fp_violation": 0.021593955020039315,
            "ave_precision_score": 0.8125145877224889,
            "fpr": 0.1437980241492865,
            "logloss": 0.9712731319643659,
            "mae": 0.2777137110720603,
            "precision": 0.7395626242544732,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8003360642397307,
            "auditor_fn_violation": 0.023533993546233457,
            "auditor_fp_violation": 0.032033029612756274,
            "ave_precision_score": 0.8008026457398598,
            "fpr": 0.13048245614035087,
            "logloss": 1.0666486670215523,
            "mae": 0.2768794933219443,
            "precision": 0.7457264957264957,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8337491841843792,
            "auditor_fn_violation": 0.021084412961471146,
            "auditor_fp_violation": 0.022553799811094382,
            "ave_precision_score": 0.8339873930763468,
            "fpr": 0.13721185510428102,
            "logloss": 0.9723582745105891,
            "mae": 0.2712854548816042,
            "precision": 0.7448979591836735,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8071338896332502,
            "auditor_fn_violation": 0.016192370461036318,
            "auditor_fp_violation": 0.02567637773248611,
            "ave_precision_score": 0.8078647753302007,
            "fpr": 0.11842105263157894,
            "logloss": 0.9833391973772593,
            "mae": 0.2756249808821172,
            "precision": 0.7647058823529411,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8376904579855827,
            "auditor_fn_violation": 0.01793738346976547,
            "auditor_fp_violation": 0.013613968805044296,
            "ave_precision_score": 0.8379223147578136,
            "fpr": 0.11964873765093303,
            "logloss": 0.887102369152121,
            "mae": 0.268995108896929,
            "precision": 0.7655913978494624,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8689682049266595,
            "auditor_fn_violation": 0.010065464930826015,
            "auditor_fp_violation": 0.009898393478000242,
            "ave_precision_score": 0.856045416084705,
            "fpr": 0.09100877192982457,
            "logloss": 2.3862274345259165,
            "mae": 0.21901326954330383,
            "precision": 0.8113636363636364,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8821672240264242,
            "auditor_fn_violation": 0.01036306085702354,
            "auditor_fp_violation": 0.010068159191279713,
            "ave_precision_score": 0.8733324868601693,
            "fpr": 0.08122941822173436,
            "logloss": 2.1117661415328386,
            "mae": 0.22242196563251576,
            "precision": 0.8254716981132075,
            "recall": 0.7276507276507277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8439583316953189,
            "auditor_fn_violation": 0.0016528504135603303,
            "auditor_fp_violation": 0.0034892898533349314,
            "ave_precision_score": 0.8377076460012554,
            "fpr": 0.10307017543859649,
            "logloss": 1.4733725164768559,
            "mae": 0.2224107846144726,
            "precision": 0.7982832618025751,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8664525803615843,
            "auditor_fn_violation": 0.007471627669212745,
            "auditor_fp_violation": 0.007132463686722997,
            "ave_precision_score": 0.8617794250239623,
            "fpr": 0.10098792535675083,
            "logloss": 1.2230993543793236,
            "mae": 0.22067576972184036,
            "precision": 0.8029978586723768,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7973615231789831,
            "auditor_fn_violation": 0.010661232891955051,
            "auditor_fp_violation": 0.022736582344243302,
            "ave_precision_score": 0.7772335450266792,
            "fpr": 0.12390350877192982,
            "logloss": 2.3006792396301408,
            "mae": 0.23619840403457557,
            "precision": 0.7674897119341564,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7949613752055387,
            "auditor_fn_violation": 0.009534654979221393,
            "auditor_fp_violation": 0.03858269726597402,
            "ave_precision_score": 0.7712334881818037,
            "fpr": 0.13062568605927552,
            "logloss": 2.3388694208144623,
            "mae": 0.24285512122146985,
            "precision": 0.7605633802816901,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6185808231323062,
            "auditor_fn_violation": 0.009140517784948638,
            "auditor_fp_violation": 0.03495783878831476,
            "ave_precision_score": 0.6076357452458648,
            "fpr": 0.18421052631578946,
            "logloss": 2.9768499267416577,
            "mae": 0.38355354488023297,
            "precision": 0.6339869281045751,
            "recall": 0.6152219873150105
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6289327834577048,
            "auditor_fn_violation": 0.012013026283059215,
            "auditor_fp_violation": 0.03233094223061804,
            "ave_precision_score": 0.6149493447196853,
            "fpr": 0.17892425905598244,
            "logloss": 2.808547896012995,
            "mae": 0.38068230770007544,
            "precision": 0.652452025586354,
            "recall": 0.6361746361746362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7974224179142083,
            "auditor_fn_violation": 0.012429991469159157,
            "auditor_fp_violation": 0.022821504216121176,
            "ave_precision_score": 0.7777804536831744,
            "fpr": 0.12280701754385964,
            "logloss": 2.2726805206994487,
            "mae": 0.23695562548727053,
            "precision": 0.768595041322314,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7964220542795072,
            "auditor_fn_violation": 0.008875125230778365,
            "auditor_fp_violation": 0.03785770811528349,
            "ave_precision_score": 0.7721168210230744,
            "fpr": 0.12623490669593854,
            "logloss": 2.3372263271228504,
            "mae": 0.24051107306530053,
            "precision": 0.7681451612903226,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8708099526731016,
            "auditor_fn_violation": 0.005303957568339458,
            "auditor_fp_violation": 0.009031690844423132,
            "ave_precision_score": 0.8523591192632649,
            "fpr": 0.10526315789473684,
            "logloss": 2.472513277330112,
            "mae": 0.21476919938984823,
            "precision": 0.7953091684434968,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8866815415033267,
            "auditor_fn_violation": 0.008179081724636064,
            "auditor_fp_violation": 0.008465014167921782,
            "ave_precision_score": 0.8749817929215375,
            "fpr": 0.09989023051591657,
            "logloss": 2.145259827627027,
            "mae": 0.21292738879014456,
            "precision": 0.8059701492537313,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.832095330423882,
            "auditor_fn_violation": 0.01292376024628167,
            "auditor_fp_violation": 0.019534528234024698,
            "ave_precision_score": 0.7967703165472495,
            "fpr": 0.1162280701754386,
            "logloss": 3.54056878020879,
            "mae": 0.23784496334915695,
            "precision": 0.771551724137931,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8349734112244989,
            "auditor_fn_violation": 0.00869712066199443,
            "auditor_fp_violation": 0.03281341740484518,
            "ave_precision_score": 0.7995353978943248,
            "fpr": 0.1119648737650933,
            "logloss": 3.3512739665587663,
            "mae": 0.24110007745279224,
            "precision": 0.7801724137931034,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7817984531456426,
            "auditor_fn_violation": 0.014310021883461295,
            "auditor_fp_violation": 0.025878691603724576,
            "ave_precision_score": 0.7828123182405327,
            "fpr": 0.15460526315789475,
            "logloss": 1.076579577568752,
            "mae": 0.296727108736348,
            "precision": 0.7145748987854251,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8112870548675338,
            "auditor_fn_violation": 0.01573286534867216,
            "auditor_fp_violation": 0.016439894825517578,
            "ave_precision_score": 0.8116068748785967,
            "fpr": 0.14270032930845225,
            "logloss": 0.9650407649485713,
            "mae": 0.28192257252965613,
            "precision": 0.738430583501006,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.864679213020793,
            "auditor_fn_violation": 0.008945792070027077,
            "auditor_fp_violation": 0.009311433481197298,
            "ave_precision_score": 0.8522109554051479,
            "fpr": 0.09539473684210527,
            "logloss": 2.5042387694898074,
            "mae": 0.21567258090090097,
            "precision": 0.8062360801781737,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8845157338203927,
            "auditor_fn_violation": 0.005413164578916501,
            "auditor_fp_violation": 0.010558292701605703,
            "ave_precision_score": 0.8784365942915142,
            "fpr": 0.09001097694840834,
            "logloss": 2.211842466623737,
            "mae": 0.22261421828322756,
            "precision": 0.8153153153153153,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6988109530454354,
            "auditor_fn_violation": 0.007149215533548462,
            "auditor_fp_violation": 0.02133287375614435,
            "ave_precision_score": 0.6996476009458236,
            "fpr": 0.15570175438596492,
            "logloss": 1.7879223558806152,
            "mae": 0.36846749836355885,
            "precision": 0.6643026004728132,
            "recall": 0.5940803382663847
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7307947987554188,
            "auditor_fn_violation": 0.01456442510229558,
            "auditor_fp_violation": 0.024491358844101804,
            "ave_precision_score": 0.7312931847045709,
            "fpr": 0.14709110867178923,
            "logloss": 1.5101577568652675,
            "mae": 0.35391582443410863,
            "precision": 0.6926605504587156,
            "recall": 0.6278586278586279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8010945957327957,
            "auditor_fn_violation": 0.012045176365861807,
            "auditor_fp_violation": 0.02603354913479599,
            "ave_precision_score": 0.801488015482877,
            "fpr": 0.1524122807017544,
            "logloss": 1.0563518649125445,
            "mae": 0.2832511764833813,
            "precision": 0.7236580516898609,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8308789055897252,
            "auditor_fn_violation": 0.012496833572574523,
            "auditor_fp_violation": 0.018160467669057774,
            "ave_precision_score": 0.8311360828059305,
            "fpr": 0.14709110867178923,
            "logloss": 0.9379794101135168,
            "mae": 0.2710722589038277,
            "precision": 0.7367387033398821,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6989201567610467,
            "auditor_fn_violation": 0.007149215533548462,
            "auditor_fp_violation": 0.02133287375614435,
            "ave_precision_score": 0.6997500881011403,
            "fpr": 0.15570175438596492,
            "logloss": 1.7823653339195784,
            "mae": 0.36849241352306294,
            "precision": 0.6643026004728132,
            "recall": 0.5940803382663847
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7309879229909643,
            "auditor_fn_violation": 0.01456442510229558,
            "auditor_fp_violation": 0.024491358844101804,
            "ave_precision_score": 0.7314832700262144,
            "fpr": 0.14709110867178923,
            "logloss": 1.5052400086235953,
            "mae": 0.3540656114163366,
            "precision": 0.6926605504587156,
            "recall": 0.6278586278586279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8277807326732591,
            "auditor_fn_violation": 0.012863488001186906,
            "auditor_fp_violation": 0.01745394237301683,
            "ave_precision_score": 0.7942994693652056,
            "fpr": 0.1206140350877193,
            "logloss": 3.356676497148696,
            "mae": 0.24092289730390978,
            "precision": 0.7649572649572649,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8286071453623243,
            "auditor_fn_violation": 0.009422831596267384,
            "auditor_fp_violation": 0.03372220662190795,
            "ave_precision_score": 0.7950505375563239,
            "fpr": 0.1207464324917673,
            "logloss": 3.182035062713631,
            "mae": 0.24622604126289963,
            "precision": 0.7669491525423728,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8727427613192167,
            "auditor_fn_violation": 0.0012842624531731043,
            "auditor_fp_violation": 0.010480358070575072,
            "ave_precision_score": 0.8708153009396519,
            "fpr": 0.1074561403508772,
            "logloss": 1.2208349543281698,
            "mae": 0.21552099822445195,
            "precision": 0.7949790794979079,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8861361047651282,
            "auditor_fn_violation": 0.011266776360080428,
            "auditor_fp_violation": 0.007862558394812752,
            "ave_precision_score": 0.8843329631108701,
            "fpr": 0.10428100987925357,
            "logloss": 1.0874364447548626,
            "mae": 0.21783045591648398,
            "precision": 0.8024948024948025,
            "recall": 0.8024948024948025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7965946062242906,
            "auditor_fn_violation": 0.013619209228144363,
            "auditor_fp_violation": 0.02360078727570635,
            "ave_precision_score": 0.7373423271431566,
            "fpr": 0.16337719298245615,
            "logloss": 4.0963980930423585,
            "mae": 0.24771686051386582,
            "precision": 0.7271062271062271,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8143840308694302,
            "auditor_fn_violation": 0.018758943017999005,
            "auditor_fp_violation": 0.018068567635871648,
            "ave_precision_score": 0.7621503219838804,
            "fpr": 0.14928649835345773,
            "logloss": 3.544465055376084,
            "mae": 0.24045034281573585,
            "precision": 0.7448405253283302,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6557676605146704,
            "auditor_fn_violation": 0.014147750454360002,
            "auditor_fp_violation": 0.027444750829237106,
            "ave_precision_score": 0.6457045470210583,
            "fpr": 0.26535087719298245,
            "logloss": 1.813792284254224,
            "mae": 0.3763449146358733,
            "precision": 0.6282642089093702,
            "recall": 0.864693446088795
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6488894423855605,
            "auditor_fn_violation": 0.006812097920769711,
            "auditor_fp_violation": 0.0288617159778419,
            "ave_precision_score": 0.6378907316175809,
            "fpr": 0.2623490669593853,
            "logloss": 1.9434903546619908,
            "mae": 0.377996660429867,
            "precision": 0.6334355828220859,
            "recall": 0.8586278586278586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6775570603408863,
            "auditor_fn_violation": 0.002327435925967139,
            "auditor_fp_violation": 0.024802181992566848,
            "ave_precision_score": 0.6661669342920371,
            "fpr": 0.18640350877192982,
            "logloss": 2.1746867263261924,
            "mae": 0.31729178013093656,
            "precision": 0.6822429906542056,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.68266430602998,
            "auditor_fn_violation": 0.013400549075631407,
            "auditor_fp_violation": 0.028236285196436332,
            "ave_precision_score": 0.6680607358525388,
            "fpr": 0.18551042810098792,
            "logloss": 2.203383402227098,
            "mae": 0.3201024186611619,
            "precision": 0.6841121495327103,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8020058466477533,
            "auditor_fn_violation": 0.014089796372538108,
            "auditor_fp_violation": 0.02257922711105784,
            "ave_precision_score": 0.8025668210094813,
            "fpr": 0.14364035087719298,
            "logloss": 1.0236559253243935,
            "mae": 0.28150793866004725,
            "precision": 0.7304526748971193,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8315229738668259,
            "auditor_fn_violation": 0.010004769609599467,
            "auditor_fp_violation": 0.015536211165854038,
            "ave_precision_score": 0.8317779028837868,
            "fpr": 0.13830954994511527,
            "logloss": 0.9253462756425556,
            "mae": 0.27240401234794703,
            "precision": 0.7454545454545455,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8476549870787231,
            "auditor_fn_violation": 0.0028513408256370357,
            "auditor_fp_violation": 0.008701994165367866,
            "ave_precision_score": 0.846111451579681,
            "fpr": 0.06030701754385965,
            "logloss": 1.9869093841512746,
            "mae": 0.25136049182338166,
            "precision": 0.8509485094850948,
            "recall": 0.6638477801268499
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8746543346416463,
            "auditor_fn_violation": 0.013147234881592732,
            "auditor_fp_violation": 0.01196232098639369,
            "ave_precision_score": 0.8747364794235946,
            "fpr": 0.06256860592755215,
            "logloss": 1.7684927918217808,
            "mae": 0.24824119322385813,
            "precision": 0.8467741935483871,
            "recall": 0.6548856548856549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8640480736947052,
            "auditor_fn_violation": 0.010709914320685434,
            "auditor_fp_violation": 0.011464452703512767,
            "ave_precision_score": 0.8485985240933146,
            "fpr": 0.09100877192982457,
            "logloss": 2.4723040493478283,
            "mae": 0.22171966240247107,
            "precision": 0.8091954022988506,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8791087878633886,
            "auditor_fn_violation": 0.007359804286258739,
            "auditor_fp_violation": 0.012809843514665716,
            "ave_precision_score": 0.8693574517838649,
            "fpr": 0.0801317233809001,
            "logloss": 2.1221625111752087,
            "mae": 0.2221630965143804,
            "precision": 0.8294392523364486,
            "recall": 0.738045738045738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8674487809139824,
            "auditor_fn_violation": 0.012165720856051332,
            "auditor_fp_violation": 0.013400171841905445,
            "ave_precision_score": 0.8500119809932695,
            "fpr": 0.09539473684210527,
            "logloss": 2.559238120652976,
            "mae": 0.22017050453783965,
            "precision": 0.804932735426009,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8837063025710263,
            "auditor_fn_violation": 0.008945870636320697,
            "auditor_fp_violation": 0.010645087177392596,
            "ave_precision_score": 0.8747001676233819,
            "fpr": 0.08781558726673985,
            "logloss": 2.17368471932279,
            "mae": 0.21993312852687372,
            "precision": 0.8177676537585421,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.83089580965702,
            "auditor_fn_violation": 0.016169188828307555,
            "auditor_fp_violation": 0.014966231067417983,
            "ave_precision_score": 0.7973999105116831,
            "fpr": 0.11403508771929824,
            "logloss": 3.3718158035835066,
            "mae": 0.23665745833204896,
            "precision": 0.775377969762419,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8329352562626668,
            "auditor_fn_violation": 0.006022487910523041,
            "auditor_fp_violation": 0.03275725627345366,
            "ave_precision_score": 0.7993217246069391,
            "fpr": 0.1119648737650933,
            "logloss": 3.1888389081733233,
            "mae": 0.24071461532583313,
            "precision": 0.7811158798283262,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6955215365307859,
            "auditor_fn_violation": 0.01162790697674419,
            "auditor_fp_violation": 0.014022099668305166,
            "ave_precision_score": 0.6895072104251345,
            "fpr": 0.18311403508771928,
            "logloss": 2.547518680051198,
            "mae": 0.3978971277196047,
            "precision": 0.6221719457013575,
            "recall": 0.5813953488372093
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6933108147020011,
            "auditor_fn_violation": 0.012658863372365027,
            "auditor_fp_violation": 0.0030122788655451453,
            "ave_precision_score": 0.6874012908181464,
            "fpr": 0.17453347969264543,
            "logloss": 2.614513348268388,
            "mae": 0.3999003101925751,
            "precision": 0.636986301369863,
            "recall": 0.58004158004158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7913516601727903,
            "auditor_fn_violation": 0.016292051481769973,
            "auditor_fp_violation": 0.020251368740758505,
            "ave_precision_score": 0.7922313643937673,
            "fpr": 0.13596491228070176,
            "logloss": 1.0497034751052965,
            "mae": 0.29157445523616377,
            "precision": 0.7367303609341825,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8215655335698584,
            "auditor_fn_violation": 0.011766558418589158,
            "auditor_fp_violation": 0.01763970081433641,
            "ave_precision_score": 0.8218416478349775,
            "fpr": 0.1350164654226125,
            "logloss": 0.9429044939713561,
            "mae": 0.2784773604371343,
            "precision": 0.7453416149068323,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8050605996092846,
            "auditor_fn_violation": 0.0164125959719595,
            "auditor_fp_violation": 0.03406615913359709,
            "ave_precision_score": 0.8054644327873345,
            "fpr": 0.14364035087719298,
            "logloss": 1.0461733223916792,
            "mae": 0.27648309680787286,
            "precision": 0.7315573770491803,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8391190037357936,
            "auditor_fn_violation": 0.02089727995326239,
            "auditor_fp_violation": 0.022283205268935243,
            "ave_precision_score": 0.8393375943455844,
            "fpr": 0.141602634467618,
            "logloss": 0.9448050324042018,
            "mae": 0.2690993765618866,
            "precision": 0.742,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8305314687729553,
            "auditor_fn_violation": 0.011936222692036652,
            "auditor_fp_violation": 0.02075340686568358,
            "ave_precision_score": 0.7944168965242735,
            "fpr": 0.11513157894736842,
            "logloss": 3.5061442341878446,
            "mae": 0.23688430095658608,
            "precision": 0.7741935483870968,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8341219589073239,
            "auditor_fn_violation": 0.008514551873498087,
            "auditor_fp_violation": 0.03384984555688867,
            "ave_precision_score": 0.798739729998144,
            "fpr": 0.11525795828759605,
            "logloss": 3.296510691597547,
            "mae": 0.23985076943519026,
            "precision": 0.7780126849894292,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8022551680080369,
            "auditor_fn_violation": 0.018392307406995292,
            "auditor_fp_violation": 0.0290457778843464,
            "ave_precision_score": 0.8037361500654316,
            "fpr": 0.12719298245614036,
            "logloss": 0.9902470668487655,
            "mae": 0.27582501094819467,
            "precision": 0.75,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8362100901634704,
            "auditor_fn_violation": 0.01831393159603917,
            "auditor_fp_violation": 0.016835575523957834,
            "ave_precision_score": 0.8364298169397252,
            "fpr": 0.12623490669593854,
            "logloss": 0.9002625845936562,
            "mae": 0.269989297030693,
            "precision": 0.7589098532494759,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7960526315789473,
            "auc_prc": 0.8639959840340748,
            "auditor_fn_violation": 0.006657764919698831,
            "auditor_fp_violation": 0.00968608879830556,
            "ave_precision_score": 0.8635976699528669,
            "fpr": 0.08442982456140351,
            "logloss": 1.024104864186349,
            "mae": 0.2216048409383955,
            "precision": 0.8253968253968254,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8838070742614679,
            "auditor_fn_violation": 0.008274930338596645,
            "auditor_fp_violation": 0.0078880861818089,
            "ave_precision_score": 0.8839547461340994,
            "fpr": 0.09659714599341383,
            "logloss": 0.9019891931541553,
            "mae": 0.22884739998980252,
            "precision": 0.8070175438596491,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6830997776526364,
            "auditor_fn_violation": 0.004870461036311714,
            "auditor_fp_violation": 0.026945210406426088,
            "ave_precision_score": 0.6727849146069365,
            "fpr": 0.17543859649122806,
            "logloss": 2.0119420568837514,
            "mae": 0.30846448195386705,
            "precision": 0.6963946869070209,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6911199375123724,
            "auditor_fn_violation": 0.011061386473022043,
            "auditor_fp_violation": 0.03215735327904424,
            "ave_precision_score": 0.6781845750098913,
            "fpr": 0.18551042810098792,
            "logloss": 2.0911006262404275,
            "mae": 0.30981344223845664,
            "precision": 0.686456400742115,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 6654,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.840822961238954,
            "auditor_fn_violation": 0.01303039575683395,
            "auditor_fp_violation": 0.015802961275626432,
            "ave_precision_score": 0.8150684874646819,
            "fpr": 0.11403508771929824,
            "logloss": 3.043202668350426,
            "mae": 0.23563641197254792,
            "precision": 0.7734204793028322,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8384933354158525,
            "auditor_fn_violation": 0.0035349881672603984,
            "auditor_fp_violation": 0.030148316442447604,
            "ave_precision_score": 0.8109396600820085,
            "fpr": 0.10867178924259056,
            "logloss": 2.9171920166298073,
            "mae": 0.24103246167793596,
            "precision": 0.7838427947598253,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7960526315789473,
            "auc_prc": 0.8745784651797726,
            "auditor_fn_violation": 0.0023714810281517777,
            "auditor_fp_violation": 0.00975852215961316,
            "ave_precision_score": 0.873720298108378,
            "fpr": 0.08771929824561403,
            "logloss": 1.170077126532161,
            "mae": 0.21420579969441425,
            "precision": 0.8210290827740492,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8859264880336646,
            "auditor_fn_violation": 0.007686145995695948,
            "auditor_fp_violation": 0.007517933270364793,
            "ave_precision_score": 0.8850475195122809,
            "fpr": 0.09330406147091108,
            "logloss": 1.0455132915170249,
            "mae": 0.21921914245576832,
            "precision": 0.8123620309050773,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6388937042531642,
            "auditor_fn_violation": 0.0025152071510700694,
            "auditor_fp_violation": 0.026655476961195707,
            "ave_precision_score": 0.615199618276334,
            "fpr": 0.2324561403508772,
            "logloss": 3.307618902117386,
            "mae": 0.3236965215960316,
            "precision": 0.6518883415435139,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6521726375549444,
            "auditor_fn_violation": 0.009717223767717737,
            "auditor_fp_violation": 0.020289485104536292,
            "ave_precision_score": 0.624971174553097,
            "fpr": 0.22941822173435786,
            "logloss": 3.397515228437169,
            "mae": 0.32183320848889485,
            "precision": 0.6579378068739771,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8039827365691532,
            "auditor_fn_violation": 0.01574496494937132,
            "auditor_fp_violation": 0.03721576149942055,
            "ave_precision_score": 0.8046441855443387,
            "fpr": 0.14473684210526316,
            "logloss": 1.017202635870769,
            "mae": 0.27750063255414775,
            "precision": 0.7338709677419355,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8381678230759103,
            "auditor_fn_violation": 0.018115388038549406,
            "auditor_fp_violation": 0.02239297475301867,
            "ave_precision_score": 0.8383927157878845,
            "fpr": 0.1437980241492865,
            "logloss": 0.9266723485194498,
            "mae": 0.2686637620400989,
            "precision": 0.7400793650793651,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8055780364757927,
            "auditor_fn_violation": 0.009910147991543343,
            "auditor_fp_violation": 0.021814930264156984,
            "ave_precision_score": 0.8061968734600069,
            "fpr": 0.1425438596491228,
            "logloss": 0.959045065340747,
            "mae": 0.27980218700463405,
            "precision": 0.7341513292433538,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8338197702701134,
            "auditor_fn_violation": 0.011061386473022041,
            "auditor_fp_violation": 0.017726495290123306,
            "ave_precision_score": 0.8340662141984698,
            "fpr": 0.13391877058177826,
            "logloss": 0.8793793578553247,
            "mae": 0.2708220908143514,
            "precision": 0.7520325203252033,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 6654,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8735151441870184,
            "auditor_fn_violation": 0.004490282259560108,
            "auditor_fp_violation": 0.009668604883507174,
            "ave_precision_score": 0.8703724767034725,
            "fpr": 0.08991228070175439,
            "logloss": 1.4355403799266868,
            "mae": 0.21209361969819945,
            "precision": 0.8173719376391982,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8871109056605702,
            "auditor_fn_violation": 0.006209620918731791,
            "auditor_fp_violation": 0.0055752686799581345,
            "ave_precision_score": 0.883352939623742,
            "fpr": 0.0889132821075741,
            "logloss": 1.2886355266169944,
            "mae": 0.21349106743511287,
            "precision": 0.8191964285714286,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6816786054051944,
            "auditor_fn_violation": 0.011409999629093887,
            "auditor_fp_violation": 0.041152140031171326,
            "ave_precision_score": 0.6704589189106962,
            "fpr": 0.17434210526315788,
            "logloss": 2.032611054987034,
            "mae": 0.3059090113924949,
            "precision": 0.698292220113852,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.689165633930131,
            "auditor_fn_violation": 0.014276879260413839,
            "auditor_fp_violation": 0.032210961631736146,
            "ave_precision_score": 0.6751477381563027,
            "fpr": 0.1778265642151482,
            "logloss": 2.0960556258700476,
            "mae": 0.3066424728740013,
            "precision": 0.6983240223463687,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.803179958060917,
            "auditor_fn_violation": 0.009483605949334225,
            "auditor_fp_violation": 0.01791351956200296,
            "ave_precision_score": 0.8038298798213976,
            "fpr": 0.13267543859649122,
            "logloss": 0.9852223147722361,
            "mae": 0.28339551861902484,
            "precision": 0.7473903966597077,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8287567874160398,
            "auditor_fn_violation": 0.011024872715322775,
            "auditor_fp_violation": 0.014499783013810537,
            "ave_precision_score": 0.8290306853861364,
            "fpr": 0.13721185510428102,
            "logloss": 0.8905197216443789,
            "mae": 0.27279022200246716,
            "precision": 0.7448979591836735,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.801837987574719,
            "auditor_fn_violation": 0.011600089017469681,
            "auditor_fp_violation": 0.032560044758821884,
            "ave_precision_score": 0.8032671423717248,
            "fpr": 0.15350877192982457,
            "logloss": 0.919707582163187,
            "mae": 0.27796804208318315,
            "precision": 0.724950884086444,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.834943198115021,
            "auditor_fn_violation": 0.01896661501491359,
            "auditor_fp_violation": 0.01914073468970975,
            "ave_precision_score": 0.8351886819241154,
            "fpr": 0.145993413830955,
            "logloss": 0.8437471420749293,
            "mae": 0.27114653381018494,
            "precision": 0.7371541501976284,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8182073266910901,
            "auditor_fn_violation": 0.008653703497644749,
            "auditor_fp_violation": 0.020493645845821848,
            "ave_precision_score": 0.8187766299514777,
            "fpr": 0.13048245614035087,
            "logloss": 0.803989691070839,
            "mae": 0.28101863613820016,
            "precision": 0.7494736842105263,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8462880154168844,
            "auditor_fn_violation": 0.00966245313116883,
            "auditor_fp_violation": 0.01610803359456769,
            "ave_precision_score": 0.8465224662868781,
            "fpr": 0.13391877058177826,
            "logloss": 0.7289314074294896,
            "mae": 0.27066218685276094,
            "precision": 0.7494866529774127,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 6654,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6381533669515908,
            "auditor_fn_violation": 0.00020631653128593282,
            "auditor_fp_violation": 0.022928905407025548,
            "ave_precision_score": 0.6147561645980013,
            "fpr": 0.23135964912280702,
            "logloss": 3.2964867869625114,
            "mae": 0.32509471887335345,
            "precision": 0.6506622516556292,
            "recall": 0.8308668076109936
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6526784978518126,
            "auditor_fn_violation": 0.013781661421617516,
            "auditor_fp_violation": 0.022040691292471864,
            "ave_precision_score": 0.6254947850736979,
            "fpr": 0.2261251372118551,
            "logloss": 3.3892082847607603,
            "mae": 0.3225627376521817,
            "precision": 0.6589403973509934,
            "recall": 0.8274428274428275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8648308524747217,
            "auditor_fn_violation": 0.0055566373650828985,
            "auditor_fp_violation": 0.013035507333253404,
            "ave_precision_score": 0.8645169143719975,
            "fpr": 0.09649122807017543,
            "logloss": 0.980871452344623,
            "mae": 0.22153458878319715,
            "precision": 0.8082788671023965,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8844733985391068,
            "auditor_fn_violation": 0.00736208639611494,
            "auditor_fp_violation": 0.009220636663007688,
            "ave_precision_score": 0.8846526214988442,
            "fpr": 0.10318331503841932,
            "logloss": 0.863817077013348,
            "mae": 0.2281380255897987,
            "precision": 0.7987152034261242,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7960526315789473,
            "auc_prc": 0.8737954981588144,
            "auditor_fn_violation": 0.0026913875598086117,
            "auditor_fp_violation": 0.010280541901450668,
            "ave_precision_score": 0.8719903305774442,
            "fpr": 0.09429824561403509,
            "logloss": 1.2166572839528527,
            "mae": 0.21293409184060397,
            "precision": 0.8126361655773421,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8860046801667611,
            "auditor_fn_violation": 0.007921203310884981,
            "auditor_fp_violation": 0.008858142087662422,
            "ave_precision_score": 0.8843264672961759,
            "fpr": 0.09879253567508232,
            "logloss": 1.0923621471460319,
            "mae": 0.21624951628713687,
            "precision": 0.8072805139186295,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8739732549591999,
            "auditor_fn_violation": 0.0025221616408886978,
            "auditor_fp_violation": 0.010472864964232907,
            "ave_precision_score": 0.8732174107276655,
            "fpr": 0.09429824561403509,
            "logloss": 1.0937862426309326,
            "mae": 0.2140812932857187,
            "precision": 0.8101545253863135,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8878364785307514,
            "auditor_fn_violation": 0.007825354696924403,
            "auditor_fp_violation": 0.00548847420417124,
            "ave_precision_score": 0.8878682042248507,
            "fpr": 0.09330406147091108,
            "logloss": 0.9725660890112809,
            "mae": 0.21940150243342732,
            "precision": 0.8156182212581344,
            "recall": 0.7817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.804922006851025,
            "auditor_fn_violation": 0.013769889840881277,
            "auditor_fp_violation": 0.02235693162290693,
            "ave_precision_score": 0.8056233333577637,
            "fpr": 0.13157894736842105,
            "logloss": 0.9705469805270857,
            "mae": 0.27923923641003473,
            "precision": 0.7463002114164905,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8334900322573316,
            "auditor_fn_violation": 0.010591271842643964,
            "auditor_fp_violation": 0.01646542261251372,
            "ave_precision_score": 0.8337392668274509,
            "fpr": 0.13172338090010977,
            "logloss": 0.8692506239458572,
            "mae": 0.27150406197787863,
            "precision": 0.754601226993865,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8763128256673144,
            "auditor_fn_violation": 0.0028049775601795167,
            "auditor_fp_violation": 0.008647044718858653,
            "ave_precision_score": 0.8753457357094208,
            "fpr": 0.09320175438596491,
            "logloss": 1.1345065515244837,
            "mae": 0.21244045795705496,
            "precision": 0.8135964912280702,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8873109236488227,
            "auditor_fn_violation": 0.008961845405314129,
            "auditor_fp_violation": 0.00614709110867179,
            "ave_precision_score": 0.8869686695281802,
            "fpr": 0.09440175631174534,
            "logloss": 1.0041020345764358,
            "mae": 0.21556414794104103,
            "precision": 0.8134490238611713,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8153611990252038,
            "auditor_fn_violation": 0.010283372278476326,
            "auditor_fp_violation": 0.013634955840626626,
            "ave_precision_score": 0.8159263513141343,
            "fpr": 0.12938596491228072,
            "logloss": 0.830951201023319,
            "mae": 0.2817518591830775,
            "precision": 0.7505285412262156,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8436804834693671,
            "auditor_fn_violation": 0.00966245313116883,
            "auditor_fp_violation": 0.016975978352436628,
            "ave_precision_score": 0.843921897636922,
            "fpr": 0.13172338090010977,
            "logloss": 0.7529107367116371,
            "mae": 0.2713437294176454,
            "precision": 0.7525773195876289,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8051064555170403,
            "auditor_fn_violation": 0.012184266162234338,
            "auditor_fp_violation": 0.02014146984774008,
            "ave_precision_score": 0.8056983096639044,
            "fpr": 0.13267543859649122,
            "logloss": 0.99455246579819,
            "mae": 0.2792650215392198,
            "precision": 0.7457983193277311,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8331029317721147,
            "auditor_fn_violation": 0.010595836062356374,
            "auditor_fp_violation": 0.01370842161693003,
            "ave_precision_score": 0.8333528549569895,
            "fpr": 0.13172338090010977,
            "logloss": 0.9054900176723272,
            "mae": 0.27061905155909954,
            "precision": 0.7540983606557377,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6540595148608535,
            "auditor_fn_violation": 0.012367401060791509,
            "auditor_fp_violation": 0.035657195380250174,
            "ave_precision_score": 0.632069366159054,
            "fpr": 0.18969298245614036,
            "logloss": 3.545205797624422,
            "mae": 0.3131874699146096,
            "precision": 0.6760299625468165,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.655822650515491,
            "auditor_fn_violation": 0.008840893582935298,
            "auditor_fp_violation": 0.031866336507288186,
            "ave_precision_score": 0.6304134276864413,
            "fpr": 0.18990120746432493,
            "logloss": 3.8038382838718086,
            "mae": 0.3232220704122018,
            "precision": 0.6796296296296296,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8650155744987471,
            "auditor_fn_violation": 0.004541281851563372,
            "auditor_fp_violation": 0.012118850657395196,
            "ave_precision_score": 0.8468060798409719,
            "fpr": 0.09210526315789473,
            "logloss": 2.5863360921020453,
            "mae": 0.22109728349323585,
            "precision": 0.8095238095238095,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8826505916308028,
            "auditor_fn_violation": 0.013044539938063546,
            "auditor_fp_violation": 0.008842825415464732,
            "ave_precision_score": 0.8736960932179161,
            "fpr": 0.08342480790340286,
            "logloss": 2.1797439863399095,
            "mae": 0.2213226485074093,
            "precision": 0.8240740740740741,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8004248606010912,
            "auditor_fn_violation": 0.011834223508030123,
            "auditor_fp_violation": 0.026046037645366272,
            "ave_precision_score": 0.8011593485150308,
            "fpr": 0.16337719298245615,
            "logloss": 1.0719156475822111,
            "mae": 0.2844064800853649,
            "precision": 0.7106796116504854,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8303796692144748,
            "auditor_fn_violation": 0.01223210882925483,
            "auditor_fp_violation": 0.0166007198835933,
            "ave_precision_score": 0.8306362111663357,
            "fpr": 0.16136114160263446,
            "logloss": 0.9541206754954423,
            "mae": 0.271643029415494,
            "precision": 0.7210626185958254,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8161453110569609,
            "auditor_fn_violation": 0.010046919624643005,
            "auditor_fp_violation": 0.016582244335211608,
            "ave_precision_score": 0.8166737463331813,
            "fpr": 0.13486842105263158,
            "logloss": 0.8017183776358288,
            "mae": 0.281877871583148,
            "precision": 0.7442827442827443,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8462825126456266,
            "auditor_fn_violation": 0.007950870739015639,
            "auditor_fp_violation": 0.014668266407985095,
            "ave_precision_score": 0.8465142311994349,
            "fpr": 0.13830954994511527,
            "logloss": 0.7266716542652067,
            "mae": 0.2704497219286602,
            "precision": 0.7449392712550608,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8095201614439036,
            "auditor_fn_violation": 0.021035013538073518,
            "auditor_fp_violation": 0.026041042241138155,
            "ave_precision_score": 0.8101296181122534,
            "fpr": 0.11513157894736842,
            "logloss": 0.9885518680274218,
            "mae": 0.2763303594707708,
            "precision": 0.7666666666666667,
            "recall": 0.7293868921775899
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8410248581560538,
            "auditor_fn_violation": 0.018268289398915095,
            "auditor_fp_violation": 0.013039593597631025,
            "ave_precision_score": 0.8412412647181589,
            "fpr": 0.1163556531284303,
            "logloss": 0.8884860956964609,
            "mae": 0.26978767004168264,
            "precision": 0.7695652173913043,
            "recall": 0.735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7860434294214768,
            "auditor_fn_violation": 0.017599495567671826,
            "auditor_fp_violation": 0.036596331375134884,
            "ave_precision_score": 0.7870346833380995,
            "fpr": 0.15350877192982457,
            "logloss": 1.0913432188487406,
            "mae": 0.2827641552683887,
            "precision": 0.7222222222222222,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8248101086882476,
            "auditor_fn_violation": 0.024838483674927147,
            "auditor_fp_violation": 0.023082225001914588,
            "ave_precision_score": 0.8250706916958628,
            "fpr": 0.14489571899012074,
            "logloss": 0.98978423818348,
            "mae": 0.27438939450972527,
            "precision": 0.7391304347826086,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8037361573853329,
            "auditor_fn_violation": 0.02286636252364527,
            "auditor_fp_violation": 0.0306193302162011,
            "ave_precision_score": 0.8046629744117411,
            "fpr": 0.11842105263157894,
            "logloss": 0.9792554494791615,
            "mae": 0.2770537314360533,
            "precision": 0.7589285714285714,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8367441277184441,
            "auditor_fn_violation": 0.018886741169946444,
            "auditor_fp_violation": 0.015194138820105686,
            "ave_precision_score": 0.8369745130463425,
            "fpr": 0.12294182217343579,
            "logloss": 0.8881662283414462,
            "mae": 0.27122192706825365,
            "precision": 0.7611940298507462,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7971491228070176,
            "auc_prc": 0.8747460085303596,
            "auditor_fn_violation": 0.0009295834724231286,
            "auditor_fp_violation": 0.00903668624865124,
            "ave_precision_score": 0.8737559333827069,
            "fpr": 0.08881578947368421,
            "logloss": 1.1810029796196597,
            "mae": 0.21411509175502014,
            "precision": 0.82,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8872694929104377,
            "auditor_fn_violation": 0.008528244532635317,
            "auditor_fp_violation": 0.00548847420417124,
            "ave_precision_score": 0.8863306578335983,
            "fpr": 0.09330406147091108,
            "logloss": 1.0538809427620495,
            "mae": 0.21739239498574447,
            "precision": 0.8131868131868132,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6385276864762142,
            "auditor_fn_violation": 0.0025152071510700694,
            "auditor_fp_violation": 0.026655476961195707,
            "ave_precision_score": 0.6146960965619377,
            "fpr": 0.2324561403508772,
            "logloss": 3.328673367797689,
            "mae": 0.3238392128487051,
            "precision": 0.6518883415435139,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6521093737660066,
            "auditor_fn_violation": 0.009717223767717737,
            "auditor_fp_violation": 0.020289485104536292,
            "ave_precision_score": 0.6249514060573972,
            "fpr": 0.22941822173435786,
            "logloss": 3.3986557035188265,
            "mae": 0.32185929035905225,
            "precision": 0.6579378068739771,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7847597288174071,
            "auditor_fn_violation": 0.0133108935128519,
            "auditor_fp_violation": 0.024637333653039207,
            "ave_precision_score": 0.7852448783267656,
            "fpr": 0.1513157894736842,
            "logloss": 1.1377811215602975,
            "mae": 0.29238366750610023,
            "precision": 0.7183673469387755,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8118009314291,
            "auditor_fn_violation": 0.012074643249176733,
            "auditor_fp_violation": 0.0182702371531412,
            "ave_precision_score": 0.81213202071973,
            "fpr": 0.1350164654226125,
            "logloss": 1.0327018823778005,
            "mae": 0.2770546728140173,
            "precision": 0.7474332648870636,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7893442494742524,
            "auditor_fn_violation": 0.01057314268758577,
            "auditor_fp_violation": 0.020838328737561446,
            "ave_precision_score": 0.7909261629819581,
            "fpr": 0.17434210526315788,
            "logloss": 1.0881969689941868,
            "mae": 0.29380351822396994,
            "precision": 0.7005649717514124,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8204403927688584,
            "auditor_fn_violation": 0.012576707417541666,
            "auditor_fp_violation": 0.01608250580757155,
            "ave_precision_score": 0.8207476982690189,
            "fpr": 0.15587266739846323,
            "logloss": 0.9711781506613868,
            "mae": 0.27530667384445595,
            "precision": 0.7269230769230769,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6250072332347334,
            "auditor_fn_violation": 0.050675049145061386,
            "auditor_fp_violation": 0.06784758022619192,
            "ave_precision_score": 0.6100099248679133,
            "fpr": 0.15021929824561403,
            "logloss": 3.2308575229923915,
            "mae": 0.38510984800231063,
            "precision": 0.6522842639593909,
            "recall": 0.5433403805496829
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.634461421212595,
            "auditor_fn_violation": 0.052032104721457084,
            "auditor_fp_violation": 0.0662139739106017,
            "ave_precision_score": 0.6149408053251619,
            "fpr": 0.14709110867178923,
            "logloss": 3.3276411580574057,
            "mae": 0.3788691051338088,
            "precision": 0.6715686274509803,
            "recall": 0.5696465696465697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8290078173824444,
            "auditor_fn_violation": 0.012135584733503957,
            "auditor_fp_violation": 0.016807037525476565,
            "ave_precision_score": 0.7945575283526897,
            "fpr": 0.11842105263157894,
            "logloss": 3.4610714394153534,
            "mae": 0.23902446103830333,
            "precision": 0.7697228144989339,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8316076253034201,
            "auditor_fn_violation": 0.00826351978931562,
            "auditor_fp_violation": 0.03494754039772292,
            "ave_precision_score": 0.7971236603805847,
            "fpr": 0.11525795828759605,
            "logloss": 3.271818659102603,
            "mae": 0.24070515876238163,
            "precision": 0.7780126849894292,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8266540325024575,
            "auditor_fn_violation": 0.01242999146915916,
            "auditor_fp_violation": 0.018455520920752914,
            "ave_precision_score": 0.7933052158772934,
            "fpr": 0.12171052631578948,
            "logloss": 3.2861406172575105,
            "mae": 0.24038278119548434,
            "precision": 0.7638297872340426,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8285271003396254,
            "auditor_fn_violation": 0.00789838221232294,
            "auditor_fp_violation": 0.03347713986674496,
            "ave_precision_score": 0.7950299856289376,
            "fpr": 0.11964873765093303,
            "logloss": 3.111629922085693,
            "mae": 0.2443788562131081,
            "precision": 0.7690677966101694,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 6654,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8760494007346147,
            "auditor_fn_violation": 0.003818014910426175,
            "auditor_fp_violation": 0.012975562482516087,
            "ave_precision_score": 0.8749864153734217,
            "fpr": 0.09539473684210527,
            "logloss": 1.2079560998826493,
            "mae": 0.21084752652160937,
            "precision": 0.8104575163398693,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8852169656240602,
            "auditor_fn_violation": 0.006173107161032518,
            "auditor_fp_violation": 0.008347586347739517,
            "ave_precision_score": 0.8835181503951056,
            "fpr": 0.09769484083424808,
            "logloss": 1.1205934501057766,
            "mae": 0.21803160782429296,
            "precision": 0.8077753779697624,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8690092518070662,
            "auditor_fn_violation": 0.008394069211082671,
            "auditor_fp_violation": 0.008547136634296452,
            "ave_precision_score": 0.8590686465550543,
            "fpr": 0.08881578947368421,
            "logloss": 2.122428386607102,
            "mae": 0.2192035556250238,
            "precision": 0.8146453089244852,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8842685882357253,
            "auditor_fn_violation": 0.005723531519360288,
            "auditor_fp_violation": 0.0073264748678937034,
            "ave_precision_score": 0.8773565827993953,
            "fpr": 0.08232711306256861,
            "logloss": 1.873589882572042,
            "mae": 0.216866083467387,
            "precision": 0.8263888888888888,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8288240950080756,
            "auditor_fn_violation": 0.015077333926783133,
            "auditor_fp_violation": 0.01662470527115055,
            "ave_precision_score": 0.7943432537305286,
            "fpr": 0.12390350877192982,
            "logloss": 3.401875683385339,
            "mae": 0.2388514385429006,
            "precision": 0.7645833333333333,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8304412306039669,
            "auditor_fn_violation": 0.012839150051005159,
            "auditor_fp_violation": 0.03418170678783857,
            "ave_precision_score": 0.795245032378953,
            "fpr": 0.1207464324917673,
            "logloss": 3.233300219495328,
            "mae": 0.24021964527379577,
            "precision": 0.7717842323651453,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8477842476894066,
            "auditor_fn_violation": 0.010684414524683805,
            "auditor_fp_violation": 0.015445789873316552,
            "ave_precision_score": 0.8479109442322217,
            "fpr": 0.10964912280701754,
            "logloss": 0.9374056809679698,
            "mae": 0.23434582918991131,
            "precision": 0.7890295358649789,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8694818441323067,
            "auditor_fn_violation": 0.0096464783621754,
            "auditor_fp_violation": 0.0037015291144410667,
            "ave_precision_score": 0.8696840901018876,
            "fpr": 0.11525795828759605,
            "logloss": 0.8491971332214298,
            "mae": 0.23921475593062452,
            "precision": 0.7803347280334728,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.676669682718156,
            "auditor_fn_violation": 0.00531554838470383,
            "auditor_fp_violation": 0.031810734124605375,
            "ave_precision_score": 0.6667550430732516,
            "fpr": 0.18530701754385964,
            "logloss": 1.971837832953667,
            "mae": 0.3162787463238266,
            "precision": 0.6835205992509363,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6873099844497157,
            "auditor_fn_violation": 0.011588553849805222,
            "auditor_fp_violation": 0.03164935031782096,
            "ave_precision_score": 0.6748685418441266,
            "fpr": 0.1800219538968167,
            "logloss": 2.0321528900908366,
            "mae": 0.312792224676111,
            "precision": 0.6911487758945386,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.873334640169873,
            "auditor_fn_violation": 0.004448555320648346,
            "auditor_fp_violation": 0.009776006074411543,
            "ave_precision_score": 0.8711491732021318,
            "fpr": 0.09320175438596491,
            "logloss": 1.4178251017816064,
            "mae": 0.2133307348832211,
            "precision": 0.8123620309050773,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.88773426480831,
            "auditor_fn_violation": 0.00653368051831279,
            "auditor_fp_violation": 0.009159369974216933,
            "ave_precision_score": 0.8849083045004803,
            "fpr": 0.09220636663007684,
            "logloss": 1.2385574895366431,
            "mae": 0.21422197553008934,
            "precision": 0.8161925601750547,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6809293403302302,
            "auditor_fn_violation": 0.017318997811653875,
            "auditor_fp_violation": 0.018517963473604297,
            "ave_precision_score": 0.6712548098618898,
            "fpr": 0.20285087719298245,
            "logloss": 1.6664965167314483,
            "mae": 0.3406993026769217,
            "precision": 0.6821305841924399,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.6847254556792564,
            "auditor_fn_violation": 0.006159414501895294,
            "auditor_fp_violation": 0.026104714982258182,
            "ave_precision_score": 0.674481956151816,
            "fpr": 0.19978046103183314,
            "logloss": 1.7833179630534945,
            "mae": 0.34194403385927624,
            "precision": 0.6878216123499142,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8650166830338589,
            "auditor_fn_violation": 0.0055566373650828985,
            "auditor_fp_violation": 0.012768253207049515,
            "ave_precision_score": 0.8647267635155536,
            "fpr": 0.09539473684210527,
            "logloss": 0.98358622673508,
            "mae": 0.22113484199164116,
            "precision": 0.8100436681222707,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8847202384625679,
            "auditor_fn_violation": 0.00736208639611494,
            "auditor_fp_violation": 0.008689658693487866,
            "ave_precision_score": 0.8849023925379039,
            "fpr": 0.10098792535675083,
            "logloss": 0.8659009565148329,
            "mae": 0.22759152946601782,
            "precision": 0.8021505376344086,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8061808382930109,
            "auditor_fn_violation": 0.012485627387708174,
            "auditor_fp_violation": 0.017823602285896977,
            "ave_precision_score": 0.8066249656695414,
            "fpr": 0.13815789473684212,
            "logloss": 0.9937250681044857,
            "mae": 0.28183321634038544,
            "precision": 0.7402061855670103,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8332265157599739,
            "auditor_fn_violation": 0.009888382006933056,
            "auditor_fp_violation": 0.012768999055471885,
            "ave_precision_score": 0.8334868949646953,
            "fpr": 0.13611416026344675,
            "logloss": 0.8968878903684631,
            "mae": 0.2708914035057252,
            "precision": 0.746938775510204,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8296562083972633,
            "auditor_fn_violation": 0.011936222692036652,
            "auditor_fp_violation": 0.01920732925708349,
            "ave_precision_score": 0.7952421816462265,
            "fpr": 0.11403508771929824,
            "logloss": 3.4638308769986215,
            "mae": 0.2375787349349652,
            "precision": 0.7758620689655172,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8332444526579719,
            "auditor_fn_violation": 0.00832057253572073,
            "auditor_fp_violation": 0.03384984555688867,
            "ave_precision_score": 0.7986440705239537,
            "fpr": 0.11525795828759605,
            "logloss": 3.2753516561085942,
            "mae": 0.2409618741722641,
            "precision": 0.776595744680851,
            "recall": 0.7588357588357588
        }
    }
]