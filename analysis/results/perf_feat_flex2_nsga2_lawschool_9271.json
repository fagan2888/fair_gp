[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.49816484389469623,
            "auditor_fn_violation": 0.0074833183385815015,
            "auditor_fp_violation": 0.004455113007744601,
            "ave_precision_score": 0.4983787092599872,
            "fpr": 0.38048245614035087,
            "logloss": 0.6952899850219311,
            "mae": 0.5004058410985428,
            "precision": 0.48208955223880595,
            "recall": 0.6901709401709402
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5651356342759724,
            "auditor_fn_violation": 0.012634783826392564,
            "auditor_fp_violation": 0.010860721895783574,
            "ave_precision_score": 0.5663498569373606,
            "fpr": 0.3534577387486279,
            "logloss": 0.690420261518641,
            "mae": 0.4979873126869537,
            "precision": 0.5208333333333334,
            "recall": 0.720164609053498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5258938348157935,
            "auditor_fn_violation": 0.004308648223121902,
            "auditor_fp_violation": 0.01287142405563459,
            "ave_precision_score": 0.5265159510353978,
            "fpr": 0.2324561403508772,
            "logloss": 0.696133930752838,
            "mae": 0.49811865722662524,
            "precision": 0.5299334811529933,
            "recall": 0.5106837606837606
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5885876887702173,
            "auditor_fn_violation": 0.007909727021813863,
            "auditor_fp_violation": 0.0008264996448634381,
            "ave_precision_score": 0.5897380127329233,
            "fpr": 0.19758507135016465,
            "logloss": 0.6847436782184636,
            "mae": 0.4926532862542359,
            "precision": 0.5927601809954751,
            "recall": 0.5390946502057613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7546435996233094,
            "auditor_fn_violation": 0.009896536212325693,
            "auditor_fp_violation": 0.014701379010589535,
            "ave_precision_score": 0.6241575962431841,
            "fpr": 0.14583333333333334,
            "logloss": 0.6670938311788149,
            "mae": 0.44056368148640584,
            "precision": 0.6892523364485982,
            "recall": 0.6303418803418803
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7847178483545523,
            "auditor_fn_violation": 0.018425914632769127,
            "auditor_fp_violation": 0.02004519919932847,
            "ave_precision_score": 0.6616056193279864,
            "fpr": 0.132821075740944,
            "logloss": 0.640364193090323,
            "mae": 0.4273700879643437,
            "precision": 0.7268623024830699,
            "recall": 0.6625514403292181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.501300568400691,
            "auditor_fn_violation": 0.014362160743739697,
            "auditor_fp_violation": 0.017758712660028455,
            "ave_precision_score": 0.50150388618061,
            "fpr": 0.28618421052631576,
            "logloss": 0.6962411424765758,
            "mae": 0.5002761343330667,
            "precision": 0.5075471698113208,
            "recall": 0.5747863247863247
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5683149982574734,
            "auditor_fn_violation": 0.00280522014879864,
            "auditor_fp_violation": 0.0004933169755278638,
            "ave_precision_score": 0.5695145531990939,
            "fpr": 0.2557628979143798,
            "logloss": 0.6890580135408462,
            "mae": 0.49673513837494,
            "precision": 0.5578747628083491,
            "recall": 0.6049382716049383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6210366821378873,
            "auditor_fn_violation": 0.009896536212325693,
            "auditor_fp_violation": 0.014701379010589535,
            "ave_precision_score": 0.6141145565787284,
            "fpr": 0.14583333333333334,
            "logloss": 0.666958151542373,
            "mae": 0.44251951575279236,
            "precision": 0.6892523364485982,
            "recall": 0.6303418803418803
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.692861112906144,
            "auditor_fn_violation": 0.018425914632769127,
            "auditor_fp_violation": 0.02004519919932847,
            "ave_precision_score": 0.6592980441227797,
            "fpr": 0.132821075740944,
            "logloss": 0.6390642920154614,
            "mae": 0.4293327567737006,
            "precision": 0.7268623024830699,
            "recall": 0.6625514403292181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7527629169312218,
            "auditor_fn_violation": 0.008905476833108422,
            "auditor_fp_violation": 0.01182432432432433,
            "ave_precision_score": 0.6484321873835328,
            "fpr": 0.13925438596491227,
            "logloss": 0.6554292742411288,
            "mae": 0.423425231259643,
            "precision": 0.6947115384615384,
            "recall": 0.6175213675213675
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7836741151652713,
            "auditor_fn_violation": 0.018073568140649494,
            "auditor_fp_violation": 0.020993090979531222,
            "ave_precision_score": 0.6820952963404598,
            "fpr": 0.12733260153677278,
            "logloss": 0.6295887912489138,
            "mae": 0.40843862735152114,
            "precision": 0.7333333333333333,
            "recall": 0.6563786008230452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 9271,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6471547567916852,
            "auditor_fn_violation": 0.03928390688259109,
            "auditor_fp_violation": 0.06573514303777463,
            "ave_precision_score": 0.6548759872630171,
            "fpr": 0.33114035087719296,
            "logloss": 0.659242627953138,
            "mae": 0.4361048573464678,
            "precision": 0.576437587657784,
            "recall": 0.8782051282051282
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7057634994705665,
            "auditor_fn_violation": 0.02848134144633718,
            "auditor_fp_violation": 0.06077613482275457,
            "ave_precision_score": 0.6920461794159118,
            "fpr": 0.33260153677277715,
            "logloss": 0.6315613341355689,
            "mae": 0.42302009994910394,
            "precision": 0.5916442048517521,
            "recall": 0.9032921810699589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 9271,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6471547567916852,
            "auditor_fn_violation": 0.03928390688259109,
            "auditor_fp_violation": 0.06573514303777463,
            "ave_precision_score": 0.6548759872630171,
            "fpr": 0.33114035087719296,
            "logloss": 0.659242627953138,
            "mae": 0.4361048573464678,
            "precision": 0.576437587657784,
            "recall": 0.8782051282051282
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7057634994705665,
            "auditor_fn_violation": 0.02848134144633718,
            "auditor_fp_violation": 0.06077613482275457,
            "ave_precision_score": 0.6920461794159118,
            "fpr": 0.33260153677277715,
            "logloss": 0.6315613341355689,
            "mae": 0.42302009994910394,
            "precision": 0.5916442048517521,
            "recall": 0.9032921810699589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6608389703724915,
            "auditor_fn_violation": 0.013837344429449694,
            "auditor_fp_violation": 0.021589023233760083,
            "ave_precision_score": 0.6627900550619058,
            "fpr": 0.19078947368421054,
            "logloss": 0.6611012558763749,
            "mae": 0.4233125419061827,
            "precision": 0.6594911937377691,
            "recall": 0.7200854700854701
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7373182782715431,
            "auditor_fn_violation": 0.013002940738030384,
            "auditor_fp_violation": 0.02301026667527605,
            "ave_precision_score": 0.7388290793276167,
            "fpr": 0.17672886937431395,
            "logloss": 0.6207939899610521,
            "mae": 0.4036174403865434,
            "precision": 0.6891891891891891,
            "recall": 0.7345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5822677896846724,
            "auditor_fn_violation": 0.013099321487479384,
            "auditor_fp_violation": 0.017336415362731162,
            "ave_precision_score": 0.5832352858411621,
            "fpr": 0.32894736842105265,
            "logloss": 0.7546780884022909,
            "mae": 0.47019243124349597,
            "precision": 0.5502248875562219,
            "recall": 0.7841880341880342
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.617296033772173,
            "auditor_fn_violation": 0.021079806480465098,
            "auditor_fp_violation": 0.028940401627171177,
            "ave_precision_score": 0.6185407279757094,
            "fpr": 0.31613611416026344,
            "logloss": 0.6940650649644046,
            "mae": 0.4636159933097538,
            "precision": 0.5616438356164384,
            "recall": 0.7592592592592593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6532342861618293,
            "auditor_fn_violation": 0.04215165317139002,
            "auditor_fp_violation": 0.06967164532954008,
            "ave_precision_score": 0.654399841005193,
            "fpr": 0.2675438596491228,
            "logloss": 0.6638275915035214,
            "mae": 0.4292405644970897,
            "precision": 0.6006546644844517,
            "recall": 0.7841880341880342
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7231014843523793,
            "auditor_fn_violation": 0.04207830223197951,
            "auditor_fp_violation": 0.057790404855685415,
            "ave_precision_score": 0.7242043764010655,
            "fpr": 0.23600439077936333,
            "logloss": 0.6262984274756878,
            "mae": 0.41012684502828,
            "precision": 0.6446280991735537,
            "recall": 0.8024691358024691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7215228379670615,
            "auditor_fn_violation": 0.008905476833108422,
            "auditor_fp_violation": 0.01182432432432433,
            "ave_precision_score": 0.6790298557576843,
            "fpr": 0.13925438596491227,
            "logloss": 0.6533273249217617,
            "mae": 0.4225472808619471,
            "precision": 0.6947115384615384,
            "recall": 0.6175213675213675
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7453572313522946,
            "auditor_fn_violation": 0.018073568140649494,
            "auditor_fp_violation": 0.020993090979531222,
            "ave_precision_score": 0.7002720643976734,
            "fpr": 0.12733260153677278,
            "logloss": 0.6297811372814249,
            "mae": 0.40843603573535064,
            "precision": 0.7333333333333333,
            "recall": 0.6563786008230452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 9271,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6411936314278827,
            "auditor_fn_violation": 0.006897585844954268,
            "auditor_fp_violation": 0.0036747273589378864,
            "ave_precision_score": 0.6418690918202763,
            "fpr": 0.043859649122807015,
            "logloss": 8.282801715876236,
            "mae": 0.46766186129272097,
            "precision": 0.696969696969697,
            "recall": 0.19658119658119658
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6841714830021917,
            "auditor_fn_violation": 0.0052829387504347985,
            "auditor_fp_violation": 0.005888809969651966,
            "ave_precision_score": 0.6846389834996771,
            "fpr": 0.038419319429198684,
            "logloss": 8.753054628768737,
            "mae": 0.4707817094373477,
            "precision": 0.7426470588235294,
            "recall": 0.20781893004115226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7439655918199948,
            "auditor_fn_violation": 0.03497525865946919,
            "auditor_fp_violation": 0.05883268136557612,
            "ave_precision_score": 0.6723866459068325,
            "fpr": 0.31469298245614036,
            "logloss": 0.6701936704419152,
            "mae": 0.4339942827559354,
            "precision": 0.5846599131693199,
            "recall": 0.8632478632478633
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.768394606597774,
            "auditor_fn_violation": 0.027993477072633065,
            "auditor_fp_violation": 0.050429392393620466,
            "ave_precision_score": 0.6985369626467968,
            "fpr": 0.31394072447859495,
            "logloss": 0.6433146476692644,
            "mae": 0.42018883766117787,
            "precision": 0.5994397759103641,
            "recall": 0.8806584362139918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6088043067177263,
            "auditor_fn_violation": 0.008905476833108422,
            "auditor_fp_violation": 0.013772818871503091,
            "ave_precision_score": 0.6109095626831859,
            "fpr": 0.14144736842105263,
            "logloss": 0.6587079461282068,
            "mae": 0.4265403587354772,
            "precision": 0.6913875598086124,
            "recall": 0.6175213675213675
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6511825666900466,
            "auditor_fn_violation": 0.018073568140649494,
            "auditor_fp_violation": 0.020993090979531222,
            "ave_precision_score": 0.6524294203507787,
            "fpr": 0.12733260153677278,
            "logloss": 0.6362954874074379,
            "mae": 0.41331386847501267,
            "precision": 0.7333333333333333,
            "recall": 0.6563786008230452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6260969676870588,
            "auditor_fn_violation": 0.01942757534862798,
            "auditor_fp_violation": 0.027083827248300954,
            "ave_precision_score": 0.6281761078695975,
            "fpr": 0.25109649122807015,
            "logloss": 0.6701507283589867,
            "mae": 0.43234731889280836,
            "precision": 0.6058519793459552,
            "recall": 0.7521367521367521
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7184975725439383,
            "auditor_fn_violation": 0.010078013127165462,
            "auditor_fp_violation": 0.033527474656163236,
            "ave_precision_score": 0.7195035554786051,
            "fpr": 0.2261251372118551,
            "logloss": 0.6285846959312622,
            "mae": 0.4123174110601291,
            "precision": 0.6484641638225256,
            "recall": 0.7818930041152263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.679002113222108,
            "auditor_fn_violation": 0.015266531713900135,
            "auditor_fp_violation": 0.005452821242294929,
            "ave_precision_score": 0.6795836511055704,
            "fpr": 0.0668859649122807,
            "logloss": 6.927022182365713,
            "mae": 0.4490907769933974,
            "precision": 0.6995073891625616,
            "recall": 0.3034188034188034
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7126703079464957,
            "auditor_fn_violation": 0.006166063612093621,
            "auditor_fp_violation": 0.005979208368308905,
            "ave_precision_score": 0.7131100730060259,
            "fpr": 0.06805708013172337,
            "logloss": 7.372068440480622,
            "mae": 0.4558407055891885,
            "precision": 0.7102803738317757,
            "recall": 0.31275720164609055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6604047911417352,
            "auditor_fn_violation": 0.006958502024291502,
            "auditor_fp_violation": 0.00454401770191244,
            "ave_precision_score": 0.6609938119414658,
            "fpr": 0.03728070175438596,
            "logloss": 7.728598826422478,
            "mae": 0.45954727797212125,
            "precision": 0.7258064516129032,
            "recall": 0.19230769230769232
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6998774011770984,
            "auditor_fn_violation": 0.007114688783184934,
            "auditor_fp_violation": 0.00756247175050042,
            "ave_precision_score": 0.700299760375364,
            "fpr": 0.03402854006586169,
            "logloss": 8.18479669463325,
            "mae": 0.46580683878356166,
            "precision": 0.7559055118110236,
            "recall": 0.19753086419753085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6843610557691373,
            "auditor_fn_violation": 0.01172402159244265,
            "auditor_fp_violation": 0.011765054528212422,
            "ave_precision_score": 0.6850685746699772,
            "fpr": 0.2543859649122807,
            "logloss": 0.6642928845663111,
            "mae": 0.4284915795647784,
            "precision": 0.6074450084602369,
            "recall": 0.7670940170940171
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7595915402636405,
            "auditor_fn_violation": 0.011053741874573678,
            "auditor_fp_violation": 0.014363014140892362,
            "ave_precision_score": 0.7600650611176315,
            "fpr": 0.21734357848518113,
            "logloss": 0.6195168654008528,
            "mae": 0.4075901230018173,
            "precision": 0.6586206896551724,
            "recall": 0.7860082304526749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 9271,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.4983556275888158,
            "auditor_fn_violation": 0.007220910181436497,
            "auditor_fp_violation": 0.004988541172751697,
            "ave_precision_score": 0.4985666068015222,
            "fpr": 0.37719298245614036,
            "logloss": 0.6954034191746155,
            "mae": 0.500380446154036,
            "precision": 0.48425787106446777,
            "recall": 0.6901709401709402
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5652214576328262,
            "auditor_fn_violation": 0.012634783826392564,
            "auditor_fp_violation": 0.01078065474268743,
            "ave_precision_score": 0.566433693126714,
            "fpr": 0.34906695938529086,
            "logloss": 0.6902121323465409,
            "mae": 0.4978040612162664,
            "precision": 0.5239520958083832,
            "recall": 0.720164609053498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6618466323010195,
            "auditor_fn_violation": 0.013912318188633983,
            "auditor_fp_violation": 0.024221590011063707,
            "ave_precision_score": 0.6620479512199221,
            "fpr": 0.09429824561403509,
            "logloss": 8.889111820844436,
            "mae": 0.4620591570815371,
            "precision": 0.6340425531914894,
            "recall": 0.31837606837606836
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.687788864455541,
            "auditor_fn_violation": 0.01184878011320261,
            "auditor_fp_violation": 0.01287014915735778,
            "ave_precision_score": 0.6880421015279229,
            "fpr": 0.09659714599341383,
            "logloss": 9.476919242829826,
            "mae": 0.4708699542838987,
            "precision": 0.6422764227642277,
            "recall": 0.32510288065843623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.728447383050773,
            "auditor_fn_violation": 0.046788311590943175,
            "auditor_fp_violation": 0.06784909909909911,
            "ave_precision_score": 0.6844913349155382,
            "fpr": 0.3223684210526316,
            "logloss": 0.6484452504003756,
            "mae": 0.4410479509582122,
            "precision": 0.576978417266187,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7385496719984781,
            "auditor_fn_violation": 0.035614099280400054,
            "auditor_fp_violation": 0.06900497191192616,
            "ave_precision_score": 0.6939558712304936,
            "fpr": 0.32491767288693746,
            "logloss": 0.6369609196685933,
            "mae": 0.4327608245035427,
            "precision": 0.5934065934065934,
            "recall": 0.8888888888888888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6595689849052331,
            "auditor_fn_violation": 0.010655645524066589,
            "auditor_fp_violation": 0.00650979927295717,
            "ave_precision_score": 0.6603209936066785,
            "fpr": 0.07675438596491228,
            "logloss": 5.835205805828148,
            "mae": 0.4557776945542001,
            "precision": 0.6601941747572816,
            "recall": 0.2905982905982906
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6981315901987313,
            "auditor_fn_violation": 0.014473309753221947,
            "auditor_fp_violation": 0.010240847162135984,
            "ave_precision_score": 0.6986356632444971,
            "fpr": 0.06586169045005488,
            "logloss": 6.171931045582822,
            "mae": 0.46019835964718747,
            "precision": 0.7014925373134329,
            "recall": 0.29012345679012347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6891335894187983,
            "auditor_fn_violation": 0.04264132553606238,
            "auditor_fp_violation": 0.06192705863758496,
            "ave_precision_score": 0.6413413659674108,
            "fpr": 0.2719298245614035,
            "logloss": 0.6720246444979218,
            "mae": 0.43282040396476523,
            "precision": 0.5993537964458805,
            "recall": 0.7927350427350427
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7350056419707943,
            "auditor_fn_violation": 0.03991227475798765,
            "auditor_fp_violation": 0.06940014205462647,
            "ave_precision_score": 0.6874722559891515,
            "fpr": 0.2414928649835346,
            "logloss": 0.6362979735158331,
            "mae": 0.41482564113404435,
            "precision": 0.6434359805510534,
            "recall": 0.8168724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7877589040883539,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.5974979820292998,
            "fpr": 0.4791666666666667,
            "logloss": 13.29966499750367,
            "mae": 0.4791888890264966,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7942032548525543,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.6130404280103136,
            "fpr": 0.4610318331503842,
            "logloss": 12.835041709230739,
            "mae": 0.46205077001458866,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7910778358463986,
            "auditor_fn_violation": 0.0006349340230919179,
            "auditor_fp_violation": 0.007260550023707918,
            "ave_precision_score": 0.6117363810627672,
            "fpr": 0.46710526315789475,
            "logloss": 12.29138811705643,
            "mae": 0.46742087110658703,
            "precision": 0.522956326987682,
            "recall": 0.9978632478632479
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.798097304563519,
            "auditor_fn_violation": 0.0009712114846887381,
            "auditor_fp_violation": 0.003556531284302974,
            "ave_precision_score": 0.6249148556938189,
            "fpr": 0.4478594950603732,
            "logloss": 11.990743100719229,
            "mae": 0.44971701521158863,
            "precision": 0.5426008968609866,
            "recall": 0.9958847736625515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7553772188924768,
            "auditor_fn_violation": 0.009896536212325693,
            "auditor_fp_violation": 0.014701379010589535,
            "ave_precision_score": 0.6256248347815189,
            "fpr": 0.14583333333333334,
            "logloss": 0.6711933109978631,
            "mae": 0.4375244602111675,
            "precision": 0.6892523364485982,
            "recall": 0.6303418803418803
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7849273956032081,
            "auditor_fn_violation": 0.018425914632769127,
            "auditor_fp_violation": 0.02004519919932847,
            "ave_precision_score": 0.6624212597786315,
            "fpr": 0.132821075740944,
            "logloss": 0.6474192880554761,
            "mae": 0.4254003534529002,
            "precision": 0.7268623024830699,
            "recall": 0.6625514403292181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7877589040883539,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.5974979820292998,
            "fpr": 0.4791666666666667,
            "logloss": 13.299667735427368,
            "mae": 0.47918890936489633,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7942025381874346,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.6130389946800741,
            "fpr": 0.4610318331503842,
            "logloss": 12.835142540285641,
            "mae": 0.4620507740666751,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6618466323010195,
            "auditor_fn_violation": 0.013912318188633983,
            "auditor_fp_violation": 0.024221590011063707,
            "ave_precision_score": 0.6620479512199221,
            "fpr": 0.09429824561403509,
            "logloss": 8.889105041948646,
            "mae": 0.4620591545061034,
            "precision": 0.6340425531914894,
            "recall": 0.31837606837606836
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.687788864455541,
            "auditor_fn_violation": 0.01184878011320261,
            "auditor_fp_violation": 0.01287014915735778,
            "ave_precision_score": 0.6880421015279229,
            "fpr": 0.09659714599341383,
            "logloss": 9.47691203857737,
            "mae": 0.4708699499186436,
            "precision": 0.6422764227642277,
            "recall": 0.32510288065843623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7890146929371601,
            "auditor_fn_violation": 0.001321412505623032,
            "auditor_fp_violation": 0.008361980401454083,
            "ave_precision_score": 0.6206969891292236,
            "fpr": 0.4594298245614035,
            "logloss": 11.684101913839674,
            "mae": 0.4623584467010816,
            "precision": 0.5265536723163842,
            "recall": 0.9957264957264957
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7969605495833005,
            "auditor_fn_violation": 0.0005081920559417816,
            "auditor_fp_violation": 0.0026499644863433873,
            "ave_precision_score": 0.6346048361233806,
            "fpr": 0.4434687156970362,
            "logloss": 11.38755099139565,
            "mae": 0.4461668709969345,
            "precision": 0.5445321307779031,
            "recall": 0.9938271604938271
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8276236310552355,
            "auditor_fn_violation": 0.014036493477282952,
            "auditor_fp_violation": 0.021752015173067806,
            "ave_precision_score": 0.8277515803284747,
            "fpr": 0.17105263157894737,
            "logloss": 0.5551603232811302,
            "mae": 0.3259633048842181,
            "precision": 0.7051039697542533,
            "recall": 0.7970085470085471
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8435386649439885,
            "auditor_fn_violation": 0.018981537947265478,
            "auditor_fp_violation": 0.026021824756247182,
            "ave_precision_score": 0.8437580241454224,
            "fpr": 0.16465422612513722,
            "logloss": 0.5495394483845187,
            "mae": 0.32685431483294713,
            "precision": 0.7217068645640075,
            "recall": 0.8004115226337448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7933254139724514,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000605045835309003,
            "ave_precision_score": 0.6328525623000786,
            "fpr": 0.4857456140350877,
            "logloss": 11.587334062018972,
            "mae": 0.48517390902627977,
            "precision": 0.5137211855104281,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7987027243439095,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00010072964421774858,
            "ave_precision_score": 0.6432817132056392,
            "fpr": 0.4643249176728869,
            "logloss": 11.325578421168826,
            "mae": 0.46407371926255336,
            "precision": 0.5346534653465347,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7890092578630861,
            "auditor_fn_violation": 0.001321412505623032,
            "auditor_fp_violation": 0.008361980401454083,
            "ave_precision_score": 0.6206879643701847,
            "fpr": 0.4594298245614035,
            "logloss": 11.684775453996771,
            "mae": 0.46235226148487785,
            "precision": 0.5265536723163842,
            "recall": 0.9957264957264957
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7969677410551405,
            "auditor_fn_violation": 0.0005081920559417816,
            "auditor_fp_violation": 0.0026499644863433873,
            "ave_precision_score": 0.6346119661524025,
            "fpr": 0.4434687156970362,
            "logloss": 11.387454731020124,
            "mae": 0.44616277872678145,
            "precision": 0.5445321307779031,
            "recall": 0.9938271604938271
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.668459962876229,
            "auditor_fn_violation": 0.016812865497076036,
            "auditor_fp_violation": 0.011382270428323063,
            "ave_precision_score": 0.6687606619596294,
            "fpr": 0.07785087719298246,
            "logloss": 9.080370723860497,
            "mae": 0.4615744109518064,
            "precision": 0.6570048309178744,
            "recall": 0.2905982905982906
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6962359295443528,
            "auditor_fn_violation": 0.011573227087314177,
            "auditor_fp_violation": 0.012301930651514172,
            "ave_precision_score": 0.6966314397963459,
            "fpr": 0.0845225027442371,
            "logloss": 9.675744758628369,
            "mae": 0.4689115036220892,
            "precision": 0.6681034482758621,
            "recall": 0.31893004115226337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5940158857711487,
            "auditor_fn_violation": 0.004442195231668922,
            "auditor_fp_violation": 0.015499051683262214,
            "ave_precision_score": 0.5952294955230042,
            "fpr": 0.10087719298245613,
            "logloss": 9.131141495210331,
            "mae": 0.4683463119885786,
            "precision": 0.6118143459915611,
            "recall": 0.30982905982905984
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6115283109290701,
            "auditor_fn_violation": 0.0035053958703184273,
            "auditor_fp_violation": 0.010189190934332024,
            "ave_precision_score": 0.6121175089893649,
            "fpr": 0.08781558726673985,
            "logloss": 9.77803494454656,
            "mae": 0.4767105685072897,
            "precision": 0.6296296296296297,
            "recall": 0.27983539094650206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6623987204746011,
            "auditor_fn_violation": 0.014744058329584649,
            "auditor_fp_violation": 0.01175517622886044,
            "ave_precision_score": 0.663035189478765,
            "fpr": 0.06030701754385965,
            "logloss": 8.247930109063944,
            "mae": 0.45596325431493173,
            "precision": 0.7074468085106383,
            "recall": 0.2841880341880342
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7000733828689549,
            "auditor_fn_violation": 0.012481196893930159,
            "auditor_fp_violation": 0.006723058048685998,
            "ave_precision_score": 0.7004830155203806,
            "fpr": 0.06476399560922064,
            "logloss": 8.772051383506717,
            "mae": 0.46516991701955496,
            "precision": 0.7035175879396985,
            "recall": 0.2880658436213992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.660526751156579,
            "auditor_fn_violation": 0.02179862048283102,
            "auditor_fp_violation": 0.014950806069227121,
            "ave_precision_score": 0.6605511679421945,
            "fpr": 0.0756578947368421,
            "logloss": 8.85326434849553,
            "mae": 0.46216780828350784,
            "precision": 0.6634146341463415,
            "recall": 0.2905982905982906
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6871719227621758,
            "auditor_fn_violation": 0.015516797441422397,
            "auditor_fp_violation": 0.01673661780848453,
            "ave_precision_score": 0.6872738483452423,
            "fpr": 0.0867178924259056,
            "logloss": 9.43841763232236,
            "mae": 0.471296660844245,
            "precision": 0.6473214285714286,
            "recall": 0.29835390946502055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7909192153295935,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00426248617038091,
            "ave_precision_score": 0.6347713515329025,
            "fpr": 0.4758771929824561,
            "logloss": 11.285219521658053,
            "mae": 0.47584137146614214,
            "precision": 0.5188470066518847,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.801459542253726,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0025182411054432757,
            "ave_precision_score": 0.651674392815586,
            "fpr": 0.4588364434687157,
            "logloss": 10.942001936383797,
            "mae": 0.459242205675834,
            "precision": 0.5370985603543743,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7871037646632842,
            "auditor_fn_violation": 0.006682036287299448,
            "auditor_fp_violation": 0.007319819819819825,
            "ave_precision_score": 0.7875616274982289,
            "fpr": 0.13267543859649122,
            "logloss": 0.6923777869070286,
            "mae": 0.3555855566499527,
            "precision": 0.7231121281464531,
            "recall": 0.6752136752136753
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8170122860810358,
            "auditor_fn_violation": 0.01338464943782666,
            "auditor_fp_violation": 0.01598501969393685,
            "ave_precision_score": 0.817344678969913,
            "fpr": 0.13611416026344675,
            "logloss": 0.6522112217286044,
            "mae": 0.3467807266521283,
            "precision": 0.7350427350427351,
            "recall": 0.7078189300411523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.728447383050773,
            "auditor_fn_violation": 0.046788311590943175,
            "auditor_fp_violation": 0.06784909909909911,
            "ave_precision_score": 0.6844913349155382,
            "fpr": 0.3223684210526316,
            "logloss": 0.6484452504003756,
            "mae": 0.4410479509582122,
            "precision": 0.576978417266187,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7385496719984781,
            "auditor_fn_violation": 0.035614099280400054,
            "auditor_fp_violation": 0.06900497191192616,
            "ave_precision_score": 0.6939558712304936,
            "fpr": 0.32491767288693746,
            "logloss": 0.6369609196685933,
            "mae": 0.4327608245035427,
            "precision": 0.5934065934065934,
            "recall": 0.8888888888888888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8278517415349796,
            "auditor_fn_violation": 0.014036493477282952,
            "auditor_fp_violation": 0.021752015173067806,
            "ave_precision_score": 0.8279789951883821,
            "fpr": 0.17105263157894737,
            "logloss": 0.5550908271642933,
            "mae": 0.3261394556256914,
            "precision": 0.7051039697542533,
            "recall": 0.7970085470085471
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8438134606915279,
            "auditor_fn_violation": 0.018981537947265478,
            "auditor_fp_violation": 0.023568153935558857,
            "ave_precision_score": 0.8440287468854679,
            "fpr": 0.1668496158068057,
            "logloss": 0.5498198702319536,
            "mae": 0.32689410663781326,
            "precision": 0.7190388170055453,
            "recall": 0.8004115226337448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6748882671297813,
            "auditor_fn_violation": 0.03308217124006598,
            "auditor_fp_violation": 0.04161727516990675,
            "ave_precision_score": 0.5823001659297737,
            "fpr": 0.34978070175438597,
            "logloss": 0.6762532865034042,
            "mae": 0.48590621157761726,
            "precision": 0.5587828492392808,
            "recall": 0.8632478632478633
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.671055039625815,
            "auditor_fn_violation": 0.044124622243905086,
            "auditor_fp_violation": 0.04139730096209725,
            "ave_precision_score": 0.5793275396216244,
            "fpr": 0.3424807903402854,
            "logloss": 0.6771208008159981,
            "mae": 0.4864592663575737,
            "precision": 0.5666666666666667,
            "recall": 0.8395061728395061
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6450979024743566,
            "auditor_fn_violation": 0.01773129404708353,
            "auditor_fp_violation": 0.015173067804646754,
            "ave_precision_score": 0.645780324899645,
            "fpr": 0.08333333333333333,
            "logloss": 9.30572127863223,
            "mae": 0.4668623021005746,
            "precision": 0.6481481481481481,
            "recall": 0.29914529914529914
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6840239020117336,
            "auditor_fn_violation": 0.013944790015042507,
            "auditor_fp_violation": 0.01492606702395558,
            "ave_precision_score": 0.684490857000641,
            "fpr": 0.08562019758507135,
            "logloss": 9.904605029319669,
            "mae": 0.47365275376584337,
            "precision": 0.6593886462882096,
            "recall": 0.31069958847736623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.78972334649363,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000570471787577054,
            "ave_precision_score": 0.6107210025563041,
            "fpr": 0.48355263157894735,
            "logloss": 12.469194406816817,
            "mae": 0.4830847303301357,
            "precision": 0.5148514851485149,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7996909679224505,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0007309356234261072,
            "ave_precision_score": 0.6271643483055593,
            "fpr": 0.4632272228320527,
            "logloss": 12.126455375261434,
            "mae": 0.46284279788094934,
            "precision": 0.5352422907488987,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6445299396089966,
            "auditor_fn_violation": 0.01773129404708353,
            "auditor_fp_violation": 0.013528330962541493,
            "ave_precision_score": 0.6452153965291196,
            "fpr": 0.08442982456140351,
            "logloss": 9.320866864716013,
            "mae": 0.4669085613299346,
            "precision": 0.6451612903225806,
            "recall": 0.29914529914529914
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6835352857337451,
            "auditor_fn_violation": 0.013944790015042507,
            "auditor_fp_violation": 0.01492606702395558,
            "ave_precision_score": 0.6840041806660843,
            "fpr": 0.08562019758507135,
            "logloss": 9.920589838339131,
            "mae": 0.47367974093420945,
            "precision": 0.6593886462882096,
            "recall": 0.31069958847736623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6891335894187983,
            "auditor_fn_violation": 0.04264132553606238,
            "auditor_fp_violation": 0.06192705863758496,
            "ave_precision_score": 0.6413413659674108,
            "fpr": 0.2719298245614035,
            "logloss": 0.6720246444979218,
            "mae": 0.43282040396476523,
            "precision": 0.5993537964458805,
            "recall": 0.7927350427350427
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7350056419707943,
            "auditor_fn_violation": 0.03991227475798765,
            "auditor_fp_violation": 0.06940014205462647,
            "ave_precision_score": 0.6874722559891515,
            "fpr": 0.2414928649835346,
            "logloss": 0.6362979735158331,
            "mae": 0.41482564113404435,
            "precision": 0.6434359805510534,
            "recall": 0.8168724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7555551100919783,
            "auditor_fn_violation": 0.007401315789473691,
            "auditor_fp_violation": 0.02646396396396397,
            "ave_precision_score": 0.7308731509601576,
            "fpr": 0.21052631578947367,
            "logloss": 4.42005979272417,
            "mae": 0.3393326926011575,
            "precision": 0.6464088397790055,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7599115301471182,
            "auditor_fn_violation": 0.011464812782046597,
            "auditor_fp_violation": 0.012926971007942144,
            "ave_precision_score": 0.7320286765569033,
            "fpr": 0.2030735455543359,
            "logloss": 4.58141411691607,
            "mae": 0.3384131768778714,
            "precision": 0.6611721611721612,
            "recall": 0.742798353909465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.667310623316814,
            "auditor_fn_violation": 0.01678475033738192,
            "auditor_fp_violation": 0.012088568831989888,
            "ave_precision_score": 0.6677753866854029,
            "fpr": 0.06469298245614036,
            "logloss": 9.034761642454669,
            "mae": 0.4571274776407175,
            "precision": 0.6958762886597938,
            "recall": 0.28846153846153844
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.703886658987239,
            "auditor_fn_violation": 0.01360147804836184,
            "auditor_fp_violation": 0.012722928908116486,
            "ave_precision_score": 0.7041917592661331,
            "fpr": 0.06695938529088913,
            "logloss": 9.619246208289594,
            "mae": 0.4629866219846492,
            "precision": 0.7081339712918661,
            "recall": 0.3045267489711934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 9271,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6471547567916852,
            "auditor_fn_violation": 0.03928390688259109,
            "auditor_fp_violation": 0.06573514303777463,
            "ave_precision_score": 0.6548759872630171,
            "fpr": 0.33114035087719296,
            "logloss": 0.659242627953138,
            "mae": 0.4361048573464678,
            "precision": 0.576437587657784,
            "recall": 0.8782051282051282
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7057634994705665,
            "auditor_fn_violation": 0.02848134144633718,
            "auditor_fp_violation": 0.06077613482275457,
            "ave_precision_score": 0.6920461794159118,
            "fpr": 0.33260153677277715,
            "logloss": 0.6315613341355689,
            "mae": 0.42302009994910394,
            "precision": 0.5916442048517521,
            "recall": 0.9032921810699589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7924731838918679,
            "auditor_fn_violation": 0.005313765182186241,
            "auditor_fp_violation": 0.007571716453295397,
            "ave_precision_score": 0.7927815870926403,
            "fpr": 0.15021929824561403,
            "logloss": 0.6809757312921677,
            "mae": 0.35410860652573,
            "precision": 0.702819956616052,
            "recall": 0.6923076923076923
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8167142521045958,
            "auditor_fn_violation": 0.018595311984749726,
            "auditor_fp_violation": 0.0037993155549815964,
            "ave_precision_score": 0.8170308981914021,
            "fpr": 0.1350164654226125,
            "logloss": 0.6433012787739957,
            "mae": 0.3437635748913976,
            "precision": 0.7382978723404255,
            "recall": 0.7139917695473251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7875577482064088,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002153469258732421,
            "ave_precision_score": 0.593066824209071,
            "fpr": 0.4824561403508772,
            "logloss": 13.362562203182732,
            "mae": 0.4822622455938376,
            "precision": 0.5154185022026432,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.791542217276453,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0004390779363336977,
            "ave_precision_score": 0.6053801207642977,
            "fpr": 0.4610318331503842,
            "logloss": 12.961302324721691,
            "mae": 0.46180989116181864,
            "precision": 0.5364238410596026,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5917910741788028,
            "auditor_fn_violation": 0.003833033438296603,
            "auditor_fp_violation": 0.014409969179706023,
            "ave_precision_score": 0.5930238696592283,
            "fpr": 0.07785087719298246,
            "logloss": 9.036103715977681,
            "mae": 0.46838474772166877,
            "precision": 0.6432160804020101,
            "recall": 0.27350427350427353
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6105958829148675,
            "auditor_fn_violation": 0.002839099619194758,
            "auditor_fp_violation": 0.009305869438884224,
            "ave_precision_score": 0.6112115884301755,
            "fpr": 0.07574094401756312,
            "logloss": 9.683333889239089,
            "mae": 0.4786452988361963,
            "precision": 0.6443298969072165,
            "recall": 0.257201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6579052402355864,
            "auditor_fn_violation": 0.009123369320737738,
            "auditor_fp_violation": 0.003817962699541648,
            "ave_precision_score": 0.6586535738613098,
            "fpr": 0.07675438596491228,
            "logloss": 5.676794273964575,
            "mae": 0.45580319107651096,
            "precision": 0.6551724137931034,
            "recall": 0.2841880341880342
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6981760379076511,
            "auditor_fn_violation": 0.013339476810631839,
            "auditor_fp_violation": 0.009737198941047331,
            "ave_precision_score": 0.6986791414666936,
            "fpr": 0.06586169045005488,
            "logloss": 5.990817846006663,
            "mae": 0.46063866968169115,
            "precision": 0.7,
            "recall": 0.2880658436213992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7823797552421463,
            "auditor_fn_violation": 0.001508846903583746,
            "auditor_fp_violation": 0.008394084874348036,
            "ave_precision_score": 0.6185806944984686,
            "fpr": 0.46381578947368424,
            "logloss": 11.423402010764102,
            "mae": 0.4676000252710282,
            "precision": 0.5231116121758738,
            "recall": 0.9914529914529915
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7963216524374924,
            "auditor_fn_violation": 0.0012422472478576883,
            "auditor_fp_violation": 0.006160005165622794,
            "ave_precision_score": 0.636041124635138,
            "fpr": 0.4500548847420417,
            "logloss": 11.174473380086852,
            "mae": 0.4510488782322705,
            "precision": 0.5413870246085011,
            "recall": 0.9958847736625515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7886022030735661,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00426248617038091,
            "ave_precision_score": 0.6424520605586317,
            "fpr": 0.4758771929824561,
            "logloss": 10.818804574561044,
            "mae": 0.4750912578722069,
            "precision": 0.5188470066518847,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7982082791516406,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0025182411054432757,
            "ave_precision_score": 0.6578877282434165,
            "fpr": 0.4588364434687157,
            "logloss": 10.51436796151951,
            "mae": 0.45860516068665047,
            "precision": 0.5370985603543743,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7924122352576878,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00426248617038091,
            "ave_precision_score": 0.6449945387405895,
            "fpr": 0.4758771929824561,
            "logloss": 10.855337137581962,
            "mae": 0.47519645786291664,
            "precision": 0.5188470066518847,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7985694987184043,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0025182411054432757,
            "ave_precision_score": 0.6555878104440507,
            "fpr": 0.4588364434687157,
            "logloss": 10.620951880294534,
            "mae": 0.4586412976925331,
            "precision": 0.5370985603543743,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5585249596909778,
            "auditor_fn_violation": 0.003964237516869113,
            "auditor_fp_violation": 0.01488659712343923,
            "ave_precision_score": 0.559735804677056,
            "fpr": 0.08771929824561403,
            "logloss": 9.128834178114717,
            "mae": 0.47744366488682494,
            "precision": 0.6,
            "recall": 0.2564102564102564
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.58507396580435,
            "auditor_fn_violation": 0.0026425986908972673,
            "auditor_fp_violation": 0.009504745915929494,
            "ave_precision_score": 0.5858322625977727,
            "fpr": 0.07903402854006586,
            "logloss": 9.795756710867133,
            "mae": 0.48898878836029624,
            "precision": 0.6170212765957447,
            "recall": 0.23868312757201646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6582960712544985,
            "auditor_fn_violation": 0.006857756035387625,
            "auditor_fp_violation": 0.0058158487434803235,
            "ave_precision_score": 0.658832323369342,
            "fpr": 0.03179824561403509,
            "logloss": 7.662417475092697,
            "mae": 0.46259944351506027,
            "precision": 0.7542372881355932,
            "recall": 0.19017094017094016
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6952362889980228,
            "auditor_fn_violation": 0.006936256905765396,
            "auditor_fp_violation": 0.007404920255698331,
            "ave_precision_score": 0.6956117167404949,
            "fpr": 0.03512623490669594,
            "logloss": 8.123225148354985,
            "mae": 0.47114210600585626,
            "precision": 0.7480314960629921,
            "recall": 0.19547325102880658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7865467017916357,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003195629840366687,
            "ave_precision_score": 0.6451895637831663,
            "fpr": 0.4725877192982456,
            "logloss": 10.532039883072217,
            "mae": 0.47384986977469684,
            "precision": 0.5205784204671857,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.795300652076348,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.001960353845160473,
            "ave_precision_score": 0.6573791838890692,
            "fpr": 0.4566410537870472,
            "logloss": 10.341115848864998,
            "mae": 0.45672984703848546,
            "precision": 0.5382907880133185,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 9271,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6674235063103877,
            "auditor_fn_violation": 0.01678475033738192,
            "auditor_fp_violation": 0.011290896159317214,
            "ave_precision_score": 0.6678875657998515,
            "fpr": 0.06578947368421052,
            "logloss": 9.080485539130501,
            "mae": 0.4571296205711484,
            "precision": 0.6923076923076923,
            "recall": 0.28846153846153844
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7037638919916351,
            "auditor_fn_violation": 0.01360147804836184,
            "auditor_fp_violation": 0.013665655065538837,
            "ave_precision_score": 0.7040695189036821,
            "fpr": 0.06805708013172337,
            "logloss": 9.66785335141602,
            "mae": 0.46301460486469864,
            "precision": 0.7047619047619048,
            "recall": 0.3045267489711934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7827450090663771,
            "auditor_fn_violation": 0.0008364260008996852,
            "auditor_fp_violation": 0.008490398293029873,
            "ave_precision_score": 0.5880325858013176,
            "fpr": 0.45723684210526316,
            "logloss": 13.1307177848998,
            "mae": 0.4596401496783113,
            "precision": 0.5272108843537415,
            "recall": 0.9935897435897436
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7885013019782069,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.008122941822173433,
            "ave_precision_score": 0.6021125803642015,
            "fpr": 0.433589462129528,
            "logloss": 12.62711395008265,
            "mae": 0.43480867806803314,
            "precision": 0.5516458569807038,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6622675666588969,
            "auditor_fn_violation": 0.01277834008097167,
            "auditor_fp_violation": 0.024221590011063707,
            "ave_precision_score": 0.6624627970341779,
            "fpr": 0.09429824561403509,
            "logloss": 8.893929284540052,
            "mae": 0.46195882791044535,
            "precision": 0.635593220338983,
            "recall": 0.32051282051282054
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6879079534439585,
            "auditor_fn_violation": 0.01184878011320261,
            "auditor_fp_violation": 0.01287014915735778,
            "ave_precision_score": 0.688161968980565,
            "fpr": 0.09659714599341383,
            "logloss": 9.482046401294035,
            "mae": 0.4708198127004781,
            "precision": 0.6422764227642277,
            "recall": 0.32510288065843623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7918769698311259,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.6364789586392928,
            "fpr": 0.4791666666666667,
            "logloss": 11.454374815797575,
            "mae": 0.4786139203991645,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7996576820165636,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.6500353914323215,
            "fpr": 0.4610318331503842,
            "logloss": 11.135297706866792,
            "mae": 0.4615691230473254,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5940158857711487,
            "auditor_fn_violation": 0.004442195231668922,
            "auditor_fp_violation": 0.015499051683262214,
            "ave_precision_score": 0.5952294955230042,
            "fpr": 0.10087719298245613,
            "logloss": 9.131090883691348,
            "mae": 0.46834627553015884,
            "precision": 0.6118143459915611,
            "recall": 0.30982905982905984
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6115283109290701,
            "auditor_fn_violation": 0.0035053958703184273,
            "auditor_fp_violation": 0.010189190934332024,
            "ave_precision_score": 0.6121175089893649,
            "fpr": 0.08781558726673985,
            "logloss": 9.777980944471995,
            "mae": 0.4767105182424512,
            "precision": 0.6296296296296297,
            "recall": 0.27983539094650206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7359826315895304,
            "auditor_fn_violation": 0.0021086369770580327,
            "auditor_fp_violation": 0.019129326695116168,
            "ave_precision_score": 0.6548746068250504,
            "fpr": 0.3223684210526316,
            "logloss": 6.492066290447562,
            "mae": 0.36241523684637217,
            "precision": 0.5950413223140496,
            "recall": 0.9230769230769231
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7615627677197031,
            "auditor_fn_violation": 0.007406052228591563,
            "auditor_fp_violation": 0.00794731064763996,
            "ave_precision_score": 0.6950497194384967,
            "fpr": 0.3172338090010977,
            "logloss": 5.800515121604361,
            "mae": 0.3582135541074552,
            "precision": 0.6073369565217391,
            "recall": 0.9197530864197531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 9271,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5992292695020063,
            "auditor_fn_violation": 0.0036034263007947262,
            "auditor_fp_violation": 0.005275011853959222,
            "ave_precision_score": 0.599581242775022,
            "fpr": 0.017543859649122806,
            "logloss": 10.371984721868733,
            "mae": 0.4961032687708753,
            "precision": 0.5897435897435898,
            "recall": 0.049145299145299144
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.623004079589401,
            "auditor_fn_violation": 0.0017685083546773977,
            "auditor_fp_violation": 0.004507005875895914,
            "ave_precision_score": 0.6242443476734294,
            "fpr": 0.019758507135016465,
            "logloss": 11.116355946374492,
            "mae": 0.5146879443180975,
            "precision": 0.6,
            "recall": 0.05555555555555555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6673229914547198,
            "auditor_fn_violation": 0.010184716599190298,
            "auditor_fp_violation": 0.0024300616405879606,
            "ave_precision_score": 0.6679623999240977,
            "fpr": 0.07346491228070176,
            "logloss": 5.981881634227049,
            "mae": 0.452131193168927,
            "precision": 0.6683168316831684,
            "recall": 0.28846153846153844
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7035917225297358,
            "auditor_fn_violation": 0.013560822683886475,
            "auditor_fp_violation": 0.007200878155872667,
            "ave_precision_score": 0.7040683338938372,
            "fpr": 0.05598243688254665,
            "logloss": 6.330551155503746,
            "mae": 0.4561941313488032,
            "precision": 0.7315789473684211,
            "recall": 0.28600823045267487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.789214929792703,
            "auditor_fn_violation": 0.0003514394961763384,
            "auditor_fp_violation": 0.00592697961119015,
            "ave_precision_score": 0.6452899576378317,
            "fpr": 0.4758771929824561,
            "logloss": 10.552224979504118,
            "mae": 0.47621437454399074,
            "precision": 0.5177777777777778,
            "recall": 0.9957264957264957
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7973824232099099,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017098211403112457,
            "ave_precision_score": 0.6613592225662831,
            "fpr": 0.45773874862788144,
            "logloss": 10.191887876406783,
            "mae": 0.4560920850219947,
            "precision": 0.5382059800664452,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7889547765762617,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.5998510534859997,
            "fpr": 0.4791666666666667,
            "logloss": 13.231427421246412,
            "mae": 0.4791802194606377,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7939457287795086,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.613307039756684,
            "fpr": 0.4610318331503842,
            "logloss": 12.808792886275674,
            "mae": 0.46205159395392054,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.6638246076310467,
            "auditor_fn_violation": 0.0024741340530814383,
            "auditor_fp_violation": 0.006260372214319582,
            "ave_precision_score": 0.6657477102864408,
            "fpr": 0.01425438596491228,
            "logloss": 12.110211775350818,
            "mae": 0.5182659584922149,
            "precision": 0.38095238095238093,
            "recall": 0.017094017094017096
        },
        "train": {
            "accuracy": 0.4566410537870472,
            "auc_prc": 0.6648204026802043,
            "auditor_fn_violation": 0.0023038039869360777,
            "auditor_fp_violation": 0.0027946019241944864,
            "ave_precision_score": 0.6660492731252814,
            "fpr": 0.014270032930845226,
            "logloss": 12.663953121366891,
            "mae": 0.5428172332389887,
            "precision": 0.23529411764705882,
            "recall": 0.00823045267489712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7930635716988086,
            "auditor_fn_violation": 0.0025397360923676716,
            "auditor_fp_violation": 0.010046230440967288,
            "ave_precision_score": 0.630930861671173,
            "fpr": 0.44956140350877194,
            "logloss": 11.46423971729176,
            "mae": 0.4551341346252644,
            "precision": 0.5308924485125858,
            "recall": 0.9914529914529915
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7974493002872761,
            "auditor_fn_violation": 0.002764564784323292,
            "auditor_fp_violation": 0.0022005553044489035,
            "ave_precision_score": 0.6369861654340341,
            "fpr": 0.43249176728869376,
            "logloss": 11.412542447121435,
            "mae": 0.4385585866042471,
            "precision": 0.5491990846681922,
            "recall": 0.9876543209876543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7890092578630861,
            "auditor_fn_violation": 0.001321412505623032,
            "auditor_fp_violation": 0.008361980401454083,
            "ave_precision_score": 0.6206879643701847,
            "fpr": 0.4594298245614035,
            "logloss": 11.684774853507992,
            "mae": 0.4623522103259765,
            "precision": 0.5265536723163842,
            "recall": 0.9957264957264957
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7969677410551405,
            "auditor_fn_violation": 0.0005081920559417816,
            "auditor_fp_violation": 0.0026499644863433873,
            "ave_precision_score": 0.6346119661524025,
            "fpr": 0.4434687156970362,
            "logloss": 11.387444237319654,
            "mae": 0.44616274379015636,
            "precision": 0.5445321307779031,
            "recall": 0.9938271604938271
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8221892177986435,
            "auditor_fn_violation": 0.012019230769230768,
            "auditor_fp_violation": 0.011155069543227437,
            "ave_precision_score": 0.8224597312849111,
            "fpr": 0.14364035087719298,
            "logloss": 0.7115088116834473,
            "mae": 0.2875031305222353,
            "precision": 0.7348178137651822,
            "recall": 0.7756410256410257
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8310235154755589,
            "auditor_fn_violation": 0.020937512704801403,
            "auditor_fp_violation": 0.01732033318266934,
            "ave_precision_score": 0.8313257107190632,
            "fpr": 0.145993413830955,
            "logloss": 0.7023131919746288,
            "mae": 0.2815879108623925,
            "precision": 0.7387033398821218,
            "recall": 0.7736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5599817977452395,
            "auditor_fn_violation": 0.003964237516869113,
            "auditor_fp_violation": 0.01488659712343923,
            "ave_precision_score": 0.5611893768883931,
            "fpr": 0.08771929824561403,
            "logloss": 9.284475722240218,
            "mae": 0.4770399563550255,
            "precision": 0.6,
            "recall": 0.2564102564102564
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5857162074378239,
            "auditor_fn_violation": 0.002012440541529468,
            "auditor_fp_violation": 0.009504745915929494,
            "ave_precision_score": 0.5864664095705892,
            "fpr": 0.07903402854006586,
            "logloss": 9.962018276903237,
            "mae": 0.4886132544463606,
            "precision": 0.6190476190476191,
            "recall": 0.24074074074074073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7894768341717663,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.6016867302227128,
            "fpr": 0.4791666666666667,
            "logloss": 13.156717289312482,
            "mae": 0.47918129096888373,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7934692652748659,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.6139042181841362,
            "fpr": 0.4610318331503842,
            "logloss": 12.754845212581415,
            "mae": 0.46204766246681195,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6505312738156985,
            "auditor_fn_violation": 0.006269680611785899,
            "auditor_fp_violation": 0.0031709340919867245,
            "ave_precision_score": 0.651217012878581,
            "fpr": 0.04824561403508772,
            "logloss": 7.304829426223605,
            "mae": 0.4651127976036906,
            "precision": 0.6834532374100719,
            "recall": 0.202991452991453
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6885485890707675,
            "auditor_fn_violation": 0.010755602535087847,
            "auditor_fp_violation": 0.00816168399302641,
            "ave_precision_score": 0.6889993965785417,
            "fpr": 0.04500548847420417,
            "logloss": 7.708143348104145,
            "mae": 0.4733844587572874,
            "precision": 0.7152777777777778,
            "recall": 0.21193415637860083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8276251884074841,
            "auditor_fn_violation": 0.014036493477282952,
            "auditor_fp_violation": 0.021752015173067806,
            "ave_precision_score": 0.8277527765047049,
            "fpr": 0.17105263157894737,
            "logloss": 0.5551603231940425,
            "mae": 0.325963283793387,
            "precision": 0.7051039697542533,
            "recall": 0.7970085470085471
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8435386649439885,
            "auditor_fn_violation": 0.018981537947265478,
            "auditor_fp_violation": 0.026021824756247182,
            "ave_precision_score": 0.8437580241454224,
            "fpr": 0.16465422612513722,
            "logloss": 0.5495394541758493,
            "mae": 0.3268542987479533,
            "precision": 0.7217068645640075,
            "recall": 0.8004115226337448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7839904842367853,
            "auditor_fn_violation": 0.001508846903583746,
            "auditor_fp_violation": 0.008394084874348036,
            "ave_precision_score": 0.6177255348196234,
            "fpr": 0.46381578947368424,
            "logloss": 11.573207405376344,
            "mae": 0.46898371183530074,
            "precision": 0.5231116121758738,
            "recall": 0.9914529914529915
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7958057932588024,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.005470394524439871,
            "ave_precision_score": 0.6335474555605105,
            "fpr": 0.4522502744237102,
            "logloss": 11.32269999434504,
            "mae": 0.45284751319864164,
            "precision": 0.5406911928651059,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6637032654373022,
            "auditor_fn_violation": 0.010114428699955035,
            "auditor_fp_violation": 0.004410660660660662,
            "ave_precision_score": 0.6643683886894615,
            "fpr": 0.06030701754385965,
            "logloss": 6.015566832108628,
            "mae": 0.4535491117369851,
            "precision": 0.6910112359550562,
            "recall": 0.26282051282051283
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6991139472489751,
            "auditor_fn_violation": 0.009020973650806568,
            "auditor_fp_violation": 0.007872409117324206,
            "ave_precision_score": 0.6996109397413124,
            "fpr": 0.04500548847420417,
            "logloss": 6.372090195121248,
            "mae": 0.4615721956989756,
            "precision": 0.757396449704142,
            "recall": 0.26337448559670784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6471974195096695,
            "auditor_fn_violation": 0.006250937171989806,
            "auditor_fp_violation": 0.005892405563458197,
            "ave_precision_score": 0.6478339966021185,
            "fpr": 0.03728070175438596,
            "logloss": 8.218995779024546,
            "mae": 0.46478223380385525,
            "precision": 0.7301587301587301,
            "recall": 0.19658119658119658
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6871883333281772,
            "auditor_fn_violation": 0.0052829387504347985,
            "auditor_fp_violation": 0.006069606766965842,
            "ave_precision_score": 0.6876199454149685,
            "fpr": 0.038419319429198684,
            "logloss": 8.710066045533992,
            "mae": 0.4721653884697782,
            "precision": 0.7426470588235294,
            "recall": 0.20781893004115226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.6642544362826437,
            "auditor_fn_violation": 0.001307354925775989,
            "auditor_fp_violation": 0.005186107159791371,
            "ave_precision_score": 0.6654298759257852,
            "fpr": 0.010964912280701754,
            "logloss": 12.080058757490931,
            "mae": 0.5179110416745845,
            "precision": 0.375,
            "recall": 0.01282051282051282
        },
        "train": {
            "accuracy": 0.4566410537870472,
            "auc_prc": 0.674734906053686,
            "auditor_fn_violation": 0.0023038039869360777,
            "auditor_fp_violation": 0.0027946019241944864,
            "ave_precision_score": 0.6762218492039762,
            "fpr": 0.014270032930845226,
            "logloss": 12.670988950427756,
            "mae": 0.5432433836987058,
            "precision": 0.23529411764705882,
            "recall": 0.00823045267489712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.790564334812415,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.603424998773761,
            "fpr": 0.4868421052631579,
            "logloss": 13.085303775080343,
            "mae": 0.48646872738997143,
            "precision": 0.5131578947368421,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7955214172157202,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005449732033318209,
            "ave_precision_score": 0.6170293237681368,
            "fpr": 0.4654226125137212,
            "logloss": 12.663063225084773,
            "mae": 0.4657949218045998,
            "precision": 0.5340659340659341,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6569741045790571,
            "auditor_fn_violation": 0.010543184885290158,
            "auditor_fp_violation": 0.004277303619408887,
            "ave_precision_score": 0.657702957020898,
            "fpr": 0.07675438596491228,
            "logloss": 5.73313952917261,
            "mae": 0.4571318497938733,
            "precision": 0.6534653465346535,
            "recall": 0.28205128205128205
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6951141234290175,
            "auditor_fn_violation": 0.01136543300221798,
            "auditor_fp_violation": 0.010873635952734554,
            "ave_precision_score": 0.6956328076211986,
            "fpr": 0.06476399560922064,
            "logloss": 6.051672790625965,
            "mae": 0.46298733961412614,
            "precision": 0.7035175879396985,
            "recall": 0.2880658436213992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.728447383050773,
            "auditor_fn_violation": 0.046788311590943175,
            "auditor_fp_violation": 0.06784909909909911,
            "ave_precision_score": 0.6844913349155382,
            "fpr": 0.3223684210526316,
            "logloss": 0.6484452505319138,
            "mae": 0.44104795113794115,
            "precision": 0.576978417266187,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7385496719984781,
            "auditor_fn_violation": 0.035614099280400054,
            "auditor_fp_violation": 0.06900497191192616,
            "ave_precision_score": 0.6939558712304936,
            "fpr": 0.32491767288693746,
            "logloss": 0.6369609197179376,
            "mae": 0.43276082465075505,
            "precision": 0.5934065934065934,
            "recall": 0.8888888888888888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6620864518649359,
            "auditor_fn_violation": 0.014744058329584649,
            "auditor_fp_violation": 0.01175517622886044,
            "ave_precision_score": 0.6625217125261575,
            "fpr": 0.06030701754385965,
            "logloss": 8.243758321817927,
            "mae": 0.45598621006424095,
            "precision": 0.7074468085106383,
            "recall": 0.2841880341880342
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7002310788910135,
            "auditor_fn_violation": 0.012481196893930159,
            "auditor_fp_violation": 0.006723058048685998,
            "ave_precision_score": 0.700481992971151,
            "fpr": 0.06476399560922064,
            "logloss": 8.766122852520073,
            "mae": 0.4650986769170536,
            "precision": 0.7035175879396985,
            "recall": 0.2880658436213992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.668459962876229,
            "auditor_fn_violation": 0.016812865497076036,
            "auditor_fp_violation": 0.011382270428323063,
            "ave_precision_score": 0.6687606619596294,
            "fpr": 0.07785087719298246,
            "logloss": 9.080347163886229,
            "mae": 0.4615744067843421,
            "precision": 0.6570048309178744,
            "recall": 0.2905982905982906
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6962359295443528,
            "auditor_fn_violation": 0.011573227087314177,
            "auditor_fp_violation": 0.012301930651514172,
            "ave_precision_score": 0.6966314397963459,
            "fpr": 0.0845225027442371,
            "logloss": 9.675719651291011,
            "mae": 0.4689115048999742,
            "precision": 0.6681034482758621,
            "recall": 0.31893004115226337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6673936153371272,
            "auditor_fn_violation": 0.01678475033738192,
            "auditor_fp_violation": 0.012088568831989888,
            "ave_precision_score": 0.6678583207618201,
            "fpr": 0.06469298245614036,
            "logloss": 9.029596961511041,
            "mae": 0.45711106987326594,
            "precision": 0.6958762886597938,
            "recall": 0.28846153846153844
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7039079341996619,
            "auditor_fn_violation": 0.01360147804836184,
            "auditor_fp_violation": 0.012722928908116486,
            "ave_precision_score": 0.7042130715055065,
            "fpr": 0.06695938529088913,
            "logloss": 9.613897172127764,
            "mae": 0.46294815291136177,
            "precision": 0.7081339712918661,
            "recall": 0.3045267489711934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7919391069809869,
            "auditor_fn_violation": 0.0025397360923676716,
            "auditor_fp_violation": 0.009483167377904228,
            "ave_precision_score": 0.6294512708457579,
            "fpr": 0.4506578947368421,
            "logloss": 11.517530684855773,
            "mae": 0.4554303876990289,
            "precision": 0.5302857142857142,
            "recall": 0.9914529914529915
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7963562877829192,
            "auditor_fn_violation": 0.002764564784323292,
            "auditor_fp_violation": 0.0022005553044489035,
            "ave_precision_score": 0.6355892422857155,
            "fpr": 0.43249176728869376,
            "logloss": 11.468796141723724,
            "mae": 0.4386920512834836,
            "precision": 0.5491990846681922,
            "recall": 0.9876543209876543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6445299396089966,
            "auditor_fn_violation": 0.01773129404708353,
            "auditor_fp_violation": 0.013528330962541493,
            "ave_precision_score": 0.6452153965291196,
            "fpr": 0.08442982456140351,
            "logloss": 9.320900728479517,
            "mae": 0.46690854018523587,
            "precision": 0.6451612903225806,
            "recall": 0.29914529914529914
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6835352857337451,
            "auditor_fn_violation": 0.013944790015042507,
            "auditor_fp_violation": 0.01492606702395558,
            "ave_precision_score": 0.6840041806660843,
            "fpr": 0.08562019758507135,
            "logloss": 9.920625150266948,
            "mae": 0.4736797749647977,
            "precision": 0.6593886462882096,
            "recall": 0.31069958847736623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7936383785839074,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000605045835309003,
            "ave_precision_score": 0.6257729370993945,
            "fpr": 0.4857456140350877,
            "logloss": 11.904795276730399,
            "mae": 0.4846767388414918,
            "precision": 0.5137211855104281,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8014903981759987,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005449732033318209,
            "ave_precision_score": 0.6402230396379983,
            "fpr": 0.4654226125137212,
            "logloss": 11.5896464733183,
            "mae": 0.46433549808209473,
            "precision": 0.5340659340659341,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7890685418843543,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002153469258732421,
            "ave_precision_score": 0.5961213158928338,
            "fpr": 0.4824561403508772,
            "logloss": 13.256322785965738,
            "mae": 0.4821453519541313,
            "precision": 0.5154185022026432,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7921375432361238,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0004390779363336977,
            "ave_precision_score": 0.608198931590418,
            "fpr": 0.4610318331503842,
            "logloss": 12.833449044196337,
            "mae": 0.46167285221988696,
            "precision": 0.5364238410596026,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.678638699665235,
            "auditor_fn_violation": 0.015266531713900135,
            "auditor_fp_violation": 0.0040056503872293375,
            "ave_precision_score": 0.6792220526610451,
            "fpr": 0.06798245614035088,
            "logloss": 6.926446094545209,
            "mae": 0.4494323867398921,
            "precision": 0.696078431372549,
            "recall": 0.3034188034188034
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7129538067779133,
            "auditor_fn_violation": 0.006166063612093621,
            "auditor_fp_violation": 0.005979208368308905,
            "ave_precision_score": 0.713392563346272,
            "fpr": 0.06805708013172337,
            "logloss": 7.36967012430838,
            "mae": 0.4557173410689048,
            "precision": 0.7102803738317757,
            "recall": 0.31275720164609055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7880526255315152,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.5963004196019226,
            "fpr": 0.4791666666666667,
            "logloss": 13.381734473665395,
            "mae": 0.4792027783755712,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.794367949475623,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.6117423625365179,
            "fpr": 0.4610318331503842,
            "logloss": 12.915381549691233,
            "mae": 0.46207141068807794,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6624120819533347,
            "auditor_fn_violation": 0.01277834008097167,
            "auditor_fp_violation": 0.021080290817132925,
            "ave_precision_score": 0.6625841613434107,
            "fpr": 0.09320175438596491,
            "logloss": 8.847811242794952,
            "mae": 0.46223987278765294,
            "precision": 0.6382978723404256,
            "recall": 0.32051282051282054
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6889829860282279,
            "auditor_fn_violation": 0.012969061267634266,
            "auditor_fp_violation": 0.012947633499063733,
            "ave_precision_score": 0.68922903690894,
            "fpr": 0.09659714599341383,
            "logloss": 9.430913028991661,
            "mae": 0.47065843354167947,
            "precision": 0.6437246963562753,
            "recall": 0.3271604938271605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7871814597140326,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002059625414888595,
            "ave_precision_score": 0.5928117335588812,
            "fpr": 0.4791666666666667,
            "logloss": 13.540974181476473,
            "mae": 0.4792191416607153,
            "precision": 0.5171270718232044,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7947681428766289,
            "auditor_fn_violation": 0.0006211236239288441,
            "auditor_fp_violation": 0.0027377800736101358,
            "ave_precision_score": 0.6101473197138966,
            "fpr": 0.4610318331503842,
            "logloss": 13.033987149437172,
            "mae": 0.46209286969298574,
            "precision": 0.5359116022099447,
            "recall": 0.9979423868312757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7787475237583251,
            "auditor_fn_violation": 0.009071824861298547,
            "auditor_fp_violation": 0.013009720246562361,
            "ave_precision_score": 0.7801768687908286,
            "fpr": 0.1600877192982456,
            "logloss": 1.0302508386910807,
            "mae": 0.2911810115256593,
            "precision": 0.7103174603174603,
            "recall": 0.7649572649572649
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7861334561507002,
            "auditor_fn_violation": 0.01158452024411288,
            "auditor_fp_violation": 0.020063278879059857,
            "ave_precision_score": 0.7874720176796968,
            "fpr": 0.15148188803512624,
            "logloss": 1.0002363156714456,
            "mae": 0.28052244577438135,
            "precision": 0.7351247600767754,
            "recall": 0.7880658436213992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.7836070226586863,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011113086770981617,
            "ave_precision_score": 0.6483277862340638,
            "fpr": 0.48464912280701755,
            "logloss": 10.30888854768106,
            "mae": 0.48201074135865557,
            "precision": 0.5142857142857142,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7906364370363121,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006973590753535285,
            "ave_precision_score": 0.6584124351782358,
            "fpr": 0.4621295279912184,
            "logloss": 10.12673880383965,
            "mae": 0.46142072352845503,
            "precision": 0.535832414553473,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7871037646632842,
            "auditor_fn_violation": 0.006682036287299448,
            "auditor_fp_violation": 0.007319819819819825,
            "ave_precision_score": 0.7875616274982289,
            "fpr": 0.13267543859649122,
            "logloss": 0.6923845928970933,
            "mae": 0.35558586690967786,
            "precision": 0.7231121281464531,
            "recall": 0.6752136752136753
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8170122860810358,
            "auditor_fn_violation": 0.01338464943782666,
            "auditor_fp_violation": 0.01598501969393685,
            "ave_precision_score": 0.817344678969913,
            "fpr": 0.13611416026344675,
            "logloss": 0.6522163725784701,
            "mae": 0.34678077329901935,
            "precision": 0.7350427350427351,
            "recall": 0.7078189300411523
        }
    }
]