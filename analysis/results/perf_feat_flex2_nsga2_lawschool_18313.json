[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.6965458012624484,
            "auditor_fn_violation": 0.002192982456140372,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6611557669527043,
            "fpr": 0.0,
            "logloss": 0.6961022399627318,
            "mae": 0.49914814371681004,
            "precision": 1.0,
            "recall": 0.01680672268907563
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.6924313860276234,
            "auditor_fn_violation": 0.00528638812468712,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6600123774553405,
            "fpr": 0.0,
            "logloss": 0.6969415007375469,
            "mae": 0.4995408199817498,
            "precision": 1.0,
            "recall": 0.02092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6268004645277903,
            "auditor_fn_violation": 0.022201643815420922,
            "auditor_fp_violation": 0.042197308063737324,
            "ave_precision_score": 0.6273918891448558,
            "fpr": 0.21820175438596492,
            "logloss": 0.6805707782154838,
            "mae": 0.48712075988582354,
            "precision": 0.49363867684478374,
            "recall": 0.40756302521008403
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6548540522112472,
            "auditor_fn_violation": 0.024447822752136843,
            "auditor_fp_violation": 0.037633440905737676,
            "ave_precision_score": 0.6553492412470154,
            "fpr": 0.20965971459934138,
            "logloss": 0.6764712645438351,
            "mae": 0.4844719074363897,
            "precision": 0.5272277227722773,
            "recall": 0.4456066945606695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.725453339230429,
            "auditor_fn_violation": 0.08735072976559045,
            "auditor_fp_violation": 0.100542712860132,
            "ave_precision_score": 0.5589498957477728,
            "fpr": 0.29276315789473684,
            "logloss": 0.6821325816771543,
            "mae": 0.49030010379328015,
            "precision": 0.5714285714285714,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.715960386926281,
            "auditor_fn_violation": 0.094500502918766,
            "auditor_fp_violation": 0.10338612239931248,
            "ave_precision_score": 0.5506135614842806,
            "fpr": 0.300768386388584,
            "logloss": 0.6865715823006604,
            "mae": 0.49250685704133906,
            "precision": 0.5601926163723917,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5846402843603626,
            "auditor_fn_violation": 0.1292408410732714,
            "auditor_fp_violation": 0.11181444149364236,
            "ave_precision_score": 0.5541322998484991,
            "fpr": 0.1962719298245614,
            "logloss": 0.6910690045457683,
            "mae": 0.49788589272321315,
            "precision": 0.57981220657277,
            "recall": 0.5189075630252101
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6079417073844255,
            "auditor_fn_violation": 0.1277275879648554,
            "auditor_fp_violation": 0.11442391301592292,
            "ave_precision_score": 0.5697421312854589,
            "fpr": 0.2030735455543359,
            "logloss": 0.689486539689681,
            "mae": 0.49720523634804853,
            "precision": 0.5951859956236324,
            "recall": 0.5690376569037657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6315390664561954,
            "auditor_fn_violation": 0.03353282102314611,
            "auditor_fp_violation": 0.05828253259295027,
            "ave_precision_score": 0.6318631832807164,
            "fpr": 0.21162280701754385,
            "logloss": 0.6809120852542428,
            "mae": 0.4858735791293153,
            "precision": 0.5613636363636364,
            "recall": 0.5189075630252101
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6572161800629859,
            "auditor_fn_violation": 0.029444860353926225,
            "auditor_fp_violation": 0.05496586498606967,
            "ave_precision_score": 0.6575131295251441,
            "fpr": 0.20636663007683864,
            "logloss": 0.6756581512693112,
            "mae": 0.4827753309360843,
            "precision": 0.5756207674943566,
            "recall": 0.5334728033472803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5687960321058458,
            "auditor_fn_violation": 0.005795739348370943,
            "auditor_fp_violation": 0.016668678577176885,
            "ave_precision_score": 0.5708461417859441,
            "fpr": 0.1074561403508772,
            "logloss": 0.692479084682704,
            "mae": 0.4995298769913222,
            "precision": 0.51,
            "recall": 0.21428571428571427
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5463238855254527,
            "auditor_fn_violation": 0.010770269463415546,
            "auditor_fp_violation": 0.015284069735311042,
            "ave_precision_score": 0.5482976761095324,
            "fpr": 0.11525795828759605,
            "logloss": 0.6936479378290448,
            "mae": 0.5001079458109503,
            "precision": 0.4927536231884058,
            "recall": 0.21338912133891214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6942195573460053,
            "auditor_fn_violation": 0.016412815126050414,
            "auditor_fp_violation": 0.01747344278126509,
            "ave_precision_score": 0.6271625589584879,
            "fpr": 0.046052631578947366,
            "logloss": 0.6555428970028307,
            "mae": 0.44608077508184996,
            "precision": 0.7801047120418848,
            "recall": 0.3130252100840336
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7073689609427968,
            "auditor_fn_violation": 0.013142484464632648,
            "auditor_fp_violation": 0.01782930211452025,
            "ave_precision_score": 0.6417485867759626,
            "fpr": 0.04939626783754116,
            "logloss": 0.6499361583180672,
            "mae": 0.4408450487318206,
            "precision": 0.7857142857142857,
            "recall": 0.34518828451882844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.46155422327518547,
            "auditor_fn_violation": 0.002377266696152145,
            "auditor_fp_violation": 0.00695115081281185,
            "ave_precision_score": 0.5706364906579293,
            "fpr": 0.4517543859649123,
            "logloss": 0.6900898223049756,
            "mae": 0.4982289103627728,
            "precision": 0.5318181818181819,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.47391761786692715,
            "auditor_fn_violation": 0.0021012359400906636,
            "auditor_fp_violation": 0.006920801190479221,
            "ave_precision_score": 0.5827636845368569,
            "fpr": 0.4489571899012075,
            "logloss": 0.6896374331045239,
            "mae": 0.4980061604803925,
            "precision": 0.5352272727272728,
            "recall": 0.9853556485355649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 18313,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.6246669847744923,
            "auditor_fn_violation": 0.01046043417366947,
            "auditor_fp_violation": 0.0024947690326734316,
            "ave_precision_score": 0.6251427463881779,
            "fpr": 0.18530701754385964,
            "logloss": 0.6872205479589334,
            "mae": 0.490719849505184,
            "precision": 0.4940119760479042,
            "recall": 0.34663865546218486
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6606641187631286,
            "auditor_fn_violation": 0.008352125807770226,
            "auditor_fp_violation": 0.015055911454306235,
            "ave_precision_score": 0.6613640617974513,
            "fpr": 0.19099890230515917,
            "logloss": 0.6802387776830437,
            "mae": 0.48682881353584523,
            "precision": 0.5309973045822103,
            "recall": 0.4121338912133891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 18313,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5223524536618568,
            "auditor_fn_violation": 0.004643962848297232,
            "auditor_fp_violation": 0.01769475293738935,
            "ave_precision_score": 0.5257895112467916,
            "fpr": 0.10526315789473684,
            "logloss": 0.6926918010756804,
            "mae": 0.49963023343630003,
            "precision": 0.5223880597014925,
            "recall": 0.22058823529411764
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5076915373485971,
            "auditor_fn_violation": 0.01050388326773192,
            "auditor_fp_violation": 0.014526077223972844,
            "ave_precision_score": 0.5107543997441502,
            "fpr": 0.1119648737650933,
            "logloss": 0.6936852358706196,
            "mae": 0.5001205993667,
            "precision": 0.5096153846153846,
            "recall": 0.2217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.43866175897611953,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5587656931726949,
            "fpr": 0.4780701754385965,
            "logloss": 0.6994018972947078,
            "mae": 0.4998361547395848,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.4456089656320102,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5836265585665564,
            "fpr": 0.47530186608122943,
            "logloss": 0.6975203991203358,
            "mae": 0.4992260162183927,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.583066329093393,
            "auditor_fn_violation": 0.06081379920389209,
            "auditor_fp_violation": 0.09322690326734269,
            "ave_precision_score": 0.5842976873962493,
            "fpr": 0.33223684210526316,
            "logloss": 0.68185483217588,
            "mae": 0.49164489457351074,
            "precision": 0.5665236051502146,
            "recall": 0.8319327731092437
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5520612388771011,
            "auditor_fn_violation": 0.07700398201433893,
            "auditor_fp_violation": 0.09240156871493652,
            "ave_precision_score": 0.5539914065986826,
            "fpr": 0.3358946212952799,
            "logloss": 0.6874265593270892,
            "mae": 0.49429922985193103,
            "precision": 0.5519765739385066,
            "recall": 0.7887029288702929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6719646132907311,
            "auditor_fn_violation": 0.008329647648533112,
            "auditor_fp_violation": 0.013849488974730404,
            "ave_precision_score": 0.6737179369598123,
            "fpr": 0.10855263157894737,
            "logloss": 0.9513899177441827,
            "mae": 0.4179327898620183,
            "precision": 0.7009063444108762,
            "recall": 0.48739495798319327
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6980515791905015,
            "auditor_fn_violation": 0.005805381919725902,
            "auditor_fp_violation": 0.014842963725368414,
            "ave_precision_score": 0.6990015707909701,
            "fpr": 0.10318331503841932,
            "logloss": 0.9221105874949667,
            "mae": 0.402385025324362,
            "precision": 0.7134146341463414,
            "recall": 0.4895397489539749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5349419290428535,
            "auditor_fn_violation": 0.006836945304437585,
            "auditor_fp_violation": 0.009124014163849994,
            "ave_precision_score": 0.5394087589826861,
            "fpr": 0.11842105263157894,
            "logloss": 0.6924073966625945,
            "mae": 0.4995009244926143,
            "precision": 0.509090909090909,
            "recall": 0.23529411764705882
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5318314375773421,
            "auditor_fn_violation": 0.009622053102710271,
            "auditor_fp_violation": 0.010568798594544992,
            "ave_precision_score": 0.5299344178291134,
            "fpr": 0.11855104281009879,
            "logloss": 0.6931912026586735,
            "mae": 0.4998937780783807,
            "precision": 0.5068493150684932,
            "recall": 0.23221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 18313,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.618205397620848,
            "auditor_fn_violation": 0.02425180598555213,
            "auditor_fp_violation": 0.04557983260904556,
            "ave_precision_score": 0.6190749711064871,
            "fpr": 0.21710526315789475,
            "logloss": 0.6808645645143506,
            "mae": 0.48749730190294877,
            "precision": 0.5062344139650873,
            "recall": 0.4264705882352941
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.6447342461505086,
            "auditor_fn_violation": 0.030023561399721677,
            "auditor_fp_violation": 0.03740781771674403,
            "ave_precision_score": 0.646249134054129,
            "fpr": 0.20965971459934138,
            "logloss": 0.678419818315876,
            "mae": 0.48586164475403293,
            "precision": 0.5295566502463054,
            "recall": 0.4497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7440181244163148,
            "auditor_fn_violation": 0.018124355005159968,
            "auditor_fp_violation": 0.029062047320135204,
            "ave_precision_score": 0.7435318664750441,
            "fpr": 0.10087719298245613,
            "logloss": 2.1991956505349726,
            "mae": 0.32248984513928,
            "precision": 0.7733990147783252,
            "recall": 0.6596638655462185
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7231898746846538,
            "auditor_fn_violation": 0.016502165536056292,
            "auditor_fp_violation": 0.02103112332462107,
            "ave_precision_score": 0.7225406212103109,
            "fpr": 0.10867178924259056,
            "logloss": 2.4159156667287016,
            "mae": 0.32972988120224694,
            "precision": 0.7597087378640777,
            "recall": 0.6548117154811716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7246706083528517,
            "auditor_fn_violation": 0.01120448179271709,
            "auditor_fp_violation": 0.014183969097054563,
            "ave_precision_score": 0.6924229891928033,
            "fpr": 0.13486842105263158,
            "logloss": 0.8410435908955644,
            "mae": 0.39749308319337534,
            "precision": 0.716589861751152,
            "recall": 0.6533613445378151
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7304772310137972,
            "auditor_fn_violation": 0.020323429584483466,
            "auditor_fp_violation": 0.018959953151499637,
            "ave_precision_score": 0.6977899355501912,
            "fpr": 0.1437980241492865,
            "logloss": 0.8572051050059569,
            "mae": 0.40252714187855515,
            "precision": 0.700228832951945,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5873330660478604,
            "auditor_fn_violation": 0.08058749815715761,
            "auditor_fp_violation": 0.09157210687268631,
            "ave_precision_score": 0.5852929658376095,
            "fpr": 0.26206140350877194,
            "logloss": 0.6829351746474539,
            "mae": 0.4879091619922404,
            "precision": 0.5724508050089445,
            "recall": 0.6722689075630253
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5654402207930586,
            "auditor_fn_violation": 0.0907619104483096,
            "auditor_fp_violation": 0.09235593705873556,
            "ave_precision_score": 0.5692928179240648,
            "fpr": 0.2711306256860593,
            "logloss": 0.6844285693101951,
            "mae": 0.48859877323345347,
            "precision": 0.5711805555555556,
            "recall": 0.6882845188284519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7869260234028207,
            "auditor_fn_violation": 0.023673614182515117,
            "auditor_fp_violation": 0.022362385321100926,
            "ave_precision_score": 0.7886024132560177,
            "fpr": 0.11842105263157894,
            "logloss": 0.6592412653340534,
            "mae": 0.30623101615738163,
            "precision": 0.7615894039735099,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7859333189914791,
            "auditor_fn_violation": 0.025485810342214418,
            "auditor_fp_violation": 0.016133325559051167,
            "ave_precision_score": 0.7871499204380946,
            "fpr": 0.11745334796926454,
            "logloss": 0.6647510711643049,
            "mae": 0.3066195088984099,
            "precision": 0.76431718061674,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.725453339230429,
            "auditor_fn_violation": 0.08735072976559045,
            "auditor_fp_violation": 0.100542712860132,
            "ave_precision_score": 0.5589498957477728,
            "fpr": 0.29276315789473684,
            "logloss": 0.6821325816771543,
            "mae": 0.49030010379328015,
            "precision": 0.5714285714285714,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.715960386926281,
            "auditor_fn_violation": 0.094500502918766,
            "auditor_fp_violation": 0.10338612239931248,
            "ave_precision_score": 0.5506135614842806,
            "fpr": 0.300768386388584,
            "logloss": 0.6865715823006604,
            "mae": 0.49250685704133906,
            "precision": 0.5601926163723917,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.756634590944529,
            "auditor_fn_violation": 0.025150191655609618,
            "auditor_fp_violation": 0.024605665539996786,
            "ave_precision_score": 0.7555805353289066,
            "fpr": 0.12280701754385964,
            "logloss": 0.8868950245414386,
            "mae": 0.31207363026796503,
            "precision": 0.7554585152838428,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7352892192180558,
            "auditor_fn_violation": 0.025646560632713148,
            "auditor_fp_violation": 0.014282708390901053,
            "ave_precision_score": 0.7346389261138917,
            "fpr": 0.12733260153677278,
            "logloss": 1.0776364272830115,
            "mae": 0.3165738941182295,
            "precision": 0.7456140350877193,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7779412089523369,
            "auditor_fn_violation": 0.014208314904909336,
            "auditor_fp_violation": 0.02100937550297763,
            "ave_precision_score": 0.7483662310939727,
            "fpr": 0.14692982456140352,
            "logloss": 3.97801576210154,
            "mae": 0.28846910947999854,
            "precision": 0.7298387096774194,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.77892914908378,
            "auditor_fn_violation": 0.01280261242186388,
            "auditor_fp_violation": 0.03265452019581051,
            "ave_precision_score": 0.7494070857800538,
            "fpr": 0.15367727771679474,
            "logloss": 3.911886095066345,
            "mae": 0.28173087137906944,
            "precision": 0.726027397260274,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5937168482996856,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013027120553677869,
            "ave_precision_score": 0.5581912082371201,
            "fpr": 0.4725877192982456,
            "logloss": 0.6875176905432451,
            "mae": 0.49552764112881403,
            "precision": 0.5248070562293274,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6117256068649047,
            "auditor_fn_violation": 0.0006475940274377781,
            "auditor_fp_violation": 0.0044009197313816485,
            "ave_precision_score": 0.5709788148165587,
            "fpr": 0.4676180021953897,
            "logloss": 0.6864978830087392,
            "mae": 0.4944670982536186,
            "precision": 0.5282392026578073,
            "recall": 0.997907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7824649802806019,
            "auditor_fn_violation": 0.014514687453928941,
            "auditor_fp_violation": 0.025058345404796397,
            "ave_precision_score": 0.7498099132813272,
            "fpr": 0.14692982456140352,
            "logloss": 4.162765734809435,
            "mae": 0.2893869171458844,
            "precision": 0.7281947261663286,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7803216055719963,
            "auditor_fn_violation": 0.012432886753716777,
            "auditor_fp_violation": 0.03415782975843109,
            "ave_precision_score": 0.7486193504645223,
            "fpr": 0.1525795828759605,
            "logloss": 4.078013448703737,
            "mae": 0.28078782623753845,
            "precision": 0.7269155206286837,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7872858639320179,
            "auditor_fn_violation": 0.008513931888544893,
            "auditor_fp_violation": 0.03310598744567842,
            "ave_precision_score": 0.7880702265290802,
            "fpr": 0.21820175438596492,
            "logloss": 1.9924886745782064,
            "mae": 0.34341689675676834,
            "precision": 0.6632825719120136,
            "recall": 0.8235294117647058
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7838232497954675,
            "auditor_fn_violation": 0.013273381129753044,
            "auditor_fp_violation": 0.02689732623845583,
            "ave_precision_score": 0.7846146619950167,
            "fpr": 0.23380900109769484,
            "logloss": 2.0662982656361737,
            "mae": 0.3452055046380602,
            "precision": 0.6508196721311476,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 18313,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5643384185216209,
            "auditor_fn_violation": 0.046577841662980984,
            "auditor_fp_violation": 0.07742837598583617,
            "ave_precision_score": 0.5656355330020127,
            "fpr": 0.34649122807017546,
            "logloss": 0.6829901953997068,
            "mae": 0.490674247164606,
            "precision": 0.5647382920110193,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5629367947065549,
            "auditor_fn_violation": 0.06128719646900506,
            "auditor_fp_violation": 0.06894436233563098,
            "ave_precision_score": 0.5645177752796182,
            "fpr": 0.3600439077936334,
            "logloss": 0.6863315876014345,
            "mae": 0.4923219249453948,
            "precision": 0.5444444444444444,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7474735224663646,
            "auditor_fn_violation": 0.014613740232935287,
            "auditor_fp_violation": 0.025837960727506843,
            "ave_precision_score": 0.7469584102631363,
            "fpr": 0.09758771929824561,
            "logloss": 2.148672518461504,
            "mae": 0.32658676566972583,
            "precision": 0.7712082262210797,
            "recall": 0.6302521008403361
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.727162108794767,
            "auditor_fn_violation": 0.010586554845702681,
            "auditor_fp_violation": 0.01806253057954739,
            "ave_precision_score": 0.7265135531224625,
            "fpr": 0.09549945115257959,
            "logloss": 2.3728361419449566,
            "mae": 0.33399110259133474,
            "precision": 0.7757731958762887,
            "recall": 0.6297071129707112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6622663580614283,
            "auditor_fn_violation": 0.01506984372696448,
            "auditor_fp_violation": 0.009300056333494282,
            "ave_precision_score": 0.6630399488368401,
            "fpr": 0.20833333333333334,
            "logloss": 0.8030513036787702,
            "mae": 0.44106977774199624,
            "precision": 0.6066252587991718,
            "recall": 0.615546218487395
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6800694472072903,
            "auditor_fn_violation": 0.008510579665547547,
            "auditor_fp_violation": 0.01199859048884179,
            "ave_precision_score": 0.680910392896619,
            "fpr": 0.22502744237102085,
            "logloss": 0.8034142806832001,
            "mae": 0.43242050694581213,
            "precision": 0.5816326530612245,
            "recall": 0.5962343096234309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7535881761616874,
            "auditor_fn_violation": 0.008265148164528972,
            "auditor_fp_violation": 0.03734105906969258,
            "ave_precision_score": 0.7525412553122436,
            "fpr": 0.27631578947368424,
            "logloss": 1.0553944839853269,
            "mae": 0.34685282511588567,
            "precision": 0.6304985337243402,
            "recall": 0.9033613445378151
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7333012698455779,
            "auditor_fn_violation": 0.010044596723449793,
            "auditor_fp_violation": 0.03699966790294655,
            "ave_precision_score": 0.7326576464600201,
            "fpr": 0.28869374313940727,
            "logloss": 1.256569075024493,
            "mae": 0.35300279689738556,
            "precision": 0.6215827338129496,
            "recall": 0.9037656903765691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.5773558174229309,
            "auditor_fn_violation": 0.05707282913165267,
            "auditor_fp_violation": 0.08833544583936906,
            "ave_precision_score": 0.578531748612862,
            "fpr": 0.34100877192982454,
            "logloss": 0.6817658012538262,
            "mae": 0.4912452466393772,
            "precision": 0.5625879043600562,
            "recall": 0.8403361344537815
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5556861502357171,
            "auditor_fn_violation": 0.06896187462395915,
            "auditor_fp_violation": 0.08808937720394562,
            "ave_precision_score": 0.5576137027375495,
            "fpr": 0.3446761800219539,
            "logloss": 0.6869955805956278,
            "mae": 0.4937183280055269,
            "precision": 0.5520684736091298,
            "recall": 0.8096234309623431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7247620204463294,
            "auditor_fn_violation": 0.018170426065162913,
            "auditor_fp_violation": 0.037270642201834875,
            "ave_precision_score": 0.7229869191760125,
            "fpr": 0.1206140350877193,
            "logloss": 2.191844334569454,
            "mae": 0.33576177516641204,
            "precision": 0.7355769230769231,
            "recall": 0.6428571428571429
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7555357347977187,
            "auditor_fn_violation": 0.020254536602841152,
            "auditor_fp_violation": 0.04360358259203018,
            "ave_precision_score": 0.7552004489718023,
            "fpr": 0.12733260153677278,
            "logloss": 2.096315045834455,
            "mae": 0.3235962664690984,
            "precision": 0.7381489841986456,
            "recall": 0.6841004184100419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6621090274616592,
            "auditor_fn_violation": 0.01506984372696448,
            "auditor_fp_violation": 0.009300056333494282,
            "ave_precision_score": 0.6628833651652875,
            "fpr": 0.20833333333333334,
            "logloss": 0.8036601365544931,
            "mae": 0.4410440414364538,
            "precision": 0.6066252587991718,
            "recall": 0.615546218487395
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6796601485469956,
            "auditor_fn_violation": 0.008510579665547547,
            "auditor_fp_violation": 0.012954320177050838,
            "ave_precision_score": 0.6805056360632386,
            "fpr": 0.2239297475301866,
            "logloss": 0.8040463249139553,
            "mae": 0.4324092092870609,
            "precision": 0.5828220858895705,
            "recall": 0.5962343096234309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7823124067480722,
            "auditor_fn_violation": 0.01489707725195341,
            "auditor_fp_violation": 0.020943988411395466,
            "ave_precision_score": 0.7512322547366623,
            "fpr": 0.1513157894736842,
            "logloss": 4.104666583242795,
            "mae": 0.29008897392107363,
            "precision": 0.7245508982035929,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7798797008330739,
            "auditor_fn_violation": 0.013034552126726346,
            "auditor_fp_violation": 0.03456344448021741,
            "ave_precision_score": 0.7496415167268884,
            "fpr": 0.15806805708013172,
            "logloss": 4.0285876397585225,
            "mae": 0.2830311832280437,
            "precision": 0.7209302325581395,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.747877189998682,
            "auditor_fn_violation": 0.019112579242223204,
            "auditor_fp_violation": 0.0274525189119588,
            "ave_precision_score": 0.7467601810892441,
            "fpr": 0.09868421052631579,
            "logloss": 1.8868405736935132,
            "mae": 0.31895281559916006,
            "precision": 0.7766749379652605,
            "recall": 0.657563025210084
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7219353928744793,
            "auditor_fn_violation": 0.017746832071060818,
            "auditor_fp_violation": 0.01851377695753468,
            "ave_precision_score": 0.7213784691394076,
            "fpr": 0.10537870472008781,
            "logloss": 2.1876364479323924,
            "mae": 0.33043133138618525,
            "precision": 0.7635467980295566,
            "recall": 0.6485355648535565
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7895757465858873,
            "auditor_fn_violation": 0.023804916703523516,
            "auditor_fp_violation": 0.02093392885884436,
            "ave_precision_score": 0.7912243818367426,
            "fpr": 0.11842105263157894,
            "logloss": 0.640120893087483,
            "mae": 0.30954100147168045,
            "precision": 0.7636761487964989,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7922315877603181,
            "auditor_fn_violation": 0.01737940283563513,
            "auditor_fp_violation": 0.01847321548535605,
            "ave_precision_score": 0.7934240551157234,
            "fpr": 0.1207464324917673,
            "logloss": 0.6377460552373785,
            "mae": 0.30850464931278715,
            "precision": 0.7613882863340564,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6517453362885511,
            "auditor_fn_violation": 0.011110036119711049,
            "auditor_fp_violation": 0.01611540318686625,
            "ave_precision_score": 0.6527476766363522,
            "fpr": 0.039473684210526314,
            "logloss": 0.6825750456919117,
            "mae": 0.4316946394305648,
            "precision": 0.8115183246073299,
            "recall": 0.32563025210084034
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.6988914379317812,
            "auditor_fn_violation": 0.007047752022009044,
            "auditor_fp_violation": 0.01777606518228579,
            "ave_precision_score": 0.6995638693449522,
            "fpr": 0.03951701427003293,
            "logloss": 0.6648888071958687,
            "mae": 0.4164963880275007,
            "precision": 0.8309859154929577,
            "recall": 0.3702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.5746966667084425,
            "auditor_fn_violation": 0.05591644552557866,
            "auditor_fp_violation": 0.08671334299050379,
            "ave_precision_score": 0.5758910436407281,
            "fpr": 0.3355263157894737,
            "logloss": 0.6815291390962048,
            "mae": 0.49107258822442146,
            "precision": 0.5671852899575672,
            "recall": 0.842436974789916
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5566198000954099,
            "auditor_fn_violation": 0.06989422630885184,
            "auditor_fp_violation": 0.08660888346942552,
            "ave_precision_score": 0.5584852215176663,
            "fpr": 0.3468715697036224,
            "logloss": 0.6868205164993105,
            "mae": 0.4935723416891632,
            "precision": 0.5472779369627507,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 18313,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7567443811049961,
            "auditor_fn_violation": 0.015155075187969932,
            "auditor_fp_violation": 0.024676082407854506,
            "ave_precision_score": 0.7556022902359971,
            "fpr": 0.10087719298245613,
            "logloss": 1.859368675347369,
            "mae": 0.3195393271126095,
            "precision": 0.7783132530120482,
            "recall": 0.6785714285714286
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.731703611400869,
            "auditor_fn_violation": 0.01478213742771979,
            "auditor_fp_violation": 0.019195716708537938,
            "ave_precision_score": 0.7311079422943086,
            "fpr": 0.10208562019758508,
            "logloss": 2.147064925225215,
            "mae": 0.3301107131043067,
            "precision": 0.7742718446601942,
            "recall": 0.6673640167364017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7779412089523369,
            "auditor_fn_violation": 0.014208314904909336,
            "auditor_fp_violation": 0.02100937550297763,
            "ave_precision_score": 0.7483662310939727,
            "fpr": 0.14692982456140352,
            "logloss": 3.97802125369562,
            "mae": 0.2884684918721012,
            "precision": 0.7298387096774194,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.77892914908378,
            "auditor_fn_violation": 0.01280261242186388,
            "auditor_fp_violation": 0.03265452019581051,
            "ave_precision_score": 0.7494070857800538,
            "fpr": 0.15367727771679474,
            "logloss": 3.911891871120979,
            "mae": 0.28172992040928047,
            "precision": 0.726027397260274,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7573093240825727,
            "auditor_fn_violation": 0.02468487394957983,
            "auditor_fp_violation": 0.02272452921294061,
            "ave_precision_score": 0.7562518901625912,
            "fpr": 0.12280701754385964,
            "logloss": 0.8848988879607883,
            "mae": 0.3122128237269071,
            "precision": 0.7570498915401301,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7350002220485401,
            "auditor_fn_violation": 0.020236165141069865,
            "auditor_fp_violation": 0.015294210103355705,
            "ave_precision_score": 0.7343525477642363,
            "fpr": 0.12184412733260154,
            "logloss": 1.077644458807736,
            "mae": 0.3172301971175924,
            "precision": 0.7571115973741794,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7565277467240099,
            "auditor_fn_violation": 0.023887844611528826,
            "auditor_fp_violation": 0.025782633188475783,
            "ave_precision_score": 0.7553869377596927,
            "fpr": 0.09649122807017543,
            "logloss": 1.8688757062034085,
            "mae": 0.31900759623845637,
            "precision": 0.7766497461928934,
            "recall": 0.6428571428571429
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7316165668407683,
            "auditor_fn_violation": 0.0096748710553027,
            "auditor_fp_violation": 0.016995256842847112,
            "ave_precision_score": 0.7310211677776124,
            "fpr": 0.09659714599341383,
            "logloss": 2.152158594522196,
            "mae": 0.3283887715666043,
            "precision": 0.7783375314861462,
            "recall": 0.6464435146443515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6942195573460053,
            "auditor_fn_violation": 0.016412815126050414,
            "auditor_fp_violation": 0.01747344278126509,
            "ave_precision_score": 0.6271625589584879,
            "fpr": 0.046052631578947366,
            "logloss": 0.6555428970028307,
            "mae": 0.44608077508184996,
            "precision": 0.7801047120418848,
            "recall": 0.3130252100840336
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7073689609427968,
            "auditor_fn_violation": 0.013142484464632648,
            "auditor_fp_violation": 0.01782930211452025,
            "ave_precision_score": 0.6417485867759626,
            "fpr": 0.04939626783754116,
            "logloss": 0.6499361583180672,
            "mae": 0.4408450487318206,
            "precision": 0.7857142857142857,
            "recall": 0.34518828451882844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6853284837264848,
            "auditor_fn_violation": 0.005913220551378448,
            "auditor_fp_violation": 0.012169543698696291,
            "ave_precision_score": 0.6845926700268594,
            "fpr": 0.3059210526315789,
            "logloss": 0.7781328819918825,
            "mae": 0.4493382160935575,
            "precision": 0.5694444444444444,
            "recall": 0.7752100840336135
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6930757725828818,
            "auditor_fn_violation": 0.009769024796880526,
            "auditor_fp_violation": 0.0149519726818485,
            "ave_precision_score": 0.6920606494505692,
            "fpr": 0.31394072447859495,
            "logloss": 0.8026546017189696,
            "mae": 0.4504466746311649,
            "precision": 0.5559006211180124,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7872875634476811,
            "auditor_fn_violation": 0.011725084770750408,
            "auditor_fp_violation": 0.019505472396587807,
            "ave_precision_score": 0.7538117835114957,
            "fpr": 0.15570175438596492,
            "logloss": 3.693189947607935,
            "mae": 0.28896066783056934,
            "precision": 0.7204724409448819,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7833562173790267,
            "auditor_fn_violation": 0.014710948013356054,
            "auditor_fp_violation": 0.032000466456930055,
            "ave_precision_score": 0.7484759749826444,
            "fpr": 0.15806805708013172,
            "logloss": 3.539447421807732,
            "mae": 0.2826953640855511,
            "precision": 0.7230769230769231,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7793467690665827,
            "auditor_fn_violation": 0.018596583370190184,
            "auditor_fp_violation": 0.025224328021889588,
            "ave_precision_score": 0.7804176250551313,
            "fpr": 0.09868421052631579,
            "logloss": 1.6566817611239721,
            "mae": 0.31549058294444043,
            "precision": 0.7799511002444988,
            "recall": 0.6701680672268907
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7699867117441348,
            "auditor_fn_violation": 0.017388588566520778,
            "auditor_fp_violation": 0.02340650453908225,
            "ave_precision_score": 0.7711730259466835,
            "fpr": 0.09989023051591657,
            "logloss": 1.803123399428859,
            "mae": 0.32331592050877256,
            "precision": 0.7753086419753087,
            "recall": 0.6569037656903766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7568539229692737,
            "auditor_fn_violation": 0.024325519681556836,
            "auditor_fp_violation": 0.02272452921294061,
            "ave_precision_score": 0.7557974411660123,
            "fpr": 0.12280701754385964,
            "logloss": 0.8841398437170795,
            "mae": 0.31286449193675925,
            "precision": 0.7586206896551724,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7347765725857017,
            "auditor_fn_violation": 0.020236165141069865,
            "auditor_fp_violation": 0.015491947280226539,
            "ave_precision_score": 0.7341271258740556,
            "fpr": 0.12403951701427003,
            "logloss": 1.076568306208718,
            "mae": 0.31784230714331047,
            "precision": 0.7538126361655774,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8032790887284438,
            "auditor_fn_violation": 0.03956121922453192,
            "auditor_fp_violation": 0.01189542089167874,
            "ave_precision_score": 0.8035381498759008,
            "fpr": 0.08662280701754387,
            "logloss": 2.6727712833041894,
            "mae": 0.309219490239854,
            "precision": 0.7904509283819628,
            "recall": 0.6260504201680672
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8004667649219843,
            "auditor_fn_violation": 0.03189056120222846,
            "auditor_fp_violation": 0.024019996805784073,
            "ave_precision_score": 0.8009599541942497,
            "fpr": 0.09659714599341383,
            "logloss": 2.722432234166187,
            "mae": 0.3137868382389424,
            "precision": 0.7737789203084833,
            "recall": 0.6297071129707112
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5689464269806332,
            "auditor_fn_violation": 0.005795739348370943,
            "auditor_fp_violation": 0.016668678577176885,
            "ave_precision_score": 0.5709963753600102,
            "fpr": 0.1074561403508772,
            "logloss": 0.6924805520595468,
            "mae": 0.4995305015983289,
            "precision": 0.51,
            "recall": 0.21428571428571427
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5462588407645301,
            "auditor_fn_violation": 0.010770269463415546,
            "auditor_fp_violation": 0.015284069735311042,
            "ave_precision_score": 0.5482325673339665,
            "fpr": 0.11525795828759605,
            "logloss": 0.6936489308047238,
            "mae": 0.5001083899996807,
            "precision": 0.4927536231884058,
            "recall": 0.21338912133891214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7573093240825727,
            "auditor_fn_violation": 0.02468487394957983,
            "auditor_fp_violation": 0.02272452921294061,
            "ave_precision_score": 0.7562518901625912,
            "fpr": 0.12280701754385964,
            "logloss": 0.8849079755884333,
            "mae": 0.3122114446069227,
            "precision": 0.7570498915401301,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7349939894040304,
            "auditor_fn_violation": 0.020236165141069865,
            "auditor_fp_violation": 0.015294210103355705,
            "ave_precision_score": 0.734346320225657,
            "fpr": 0.12184412733260154,
            "logloss": 1.07765471866935,
            "mae": 0.3172285467248058,
            "precision": 0.7571115973741794,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7569630294937211,
            "auditor_fn_violation": 0.0017691287041132246,
            "auditor_fp_violation": 0.0031939079349750563,
            "ave_precision_score": 0.5248749035039512,
            "fpr": 0.4616228070175439,
            "logloss": 15.95932512399358,
            "mae": 0.46872471364418233,
            "precision": 0.528555431131019,
            "recall": 0.9915966386554622
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7619158026039664,
            "auditor_fn_violation": 0.0008129371833793389,
            "auditor_fp_violation": 0.0021497580254675338,
            "ave_precision_score": 0.5297414368634404,
            "fpr": 0.4621295279912184,
            "logloss": 15.898637030503888,
            "mae": 0.46633784696783476,
            "precision": 0.529608938547486,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 18313,
        "test": {
            "accuracy": 0.43969298245614036,
            "auc_prc": 0.44690353270595035,
            "auditor_fn_violation": 0.015834623323013428,
            "auditor_fp_violation": 0.010834138097537438,
            "ave_precision_score": 0.4518858259824072,
            "fpr": 0.375,
            "logloss": 0.7540317281320554,
            "mae": 0.5137376254587843,
            "precision": 0.47303543913713403,
            "recall": 0.6449579831932774
        },
        "train": {
            "accuracy": 0.43029637760702527,
            "auc_prc": 0.4695116556260879,
            "auditor_fn_violation": 0.012954176981476977,
            "auditor_fp_violation": 0.022007133748919414,
            "ave_precision_score": 0.47824684449017535,
            "fpr": 0.36443468715697036,
            "logloss": 0.7481765195550706,
            "mae": 0.5111051933302183,
            "precision": 0.46709470304975925,
            "recall": 0.608786610878661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7869880762343007,
            "auditor_fn_violation": 0.023673614182515117,
            "auditor_fp_violation": 0.021929824561403508,
            "ave_precision_score": 0.7886639548393949,
            "fpr": 0.11951754385964912,
            "logloss": 0.659394924656089,
            "mae": 0.30625173737732625,
            "precision": 0.7599118942731278,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7860258947971612,
            "auditor_fn_violation": 0.025485810342214418,
            "auditor_fp_violation": 0.018561943705746806,
            "ave_precision_score": 0.7872414673290788,
            "fpr": 0.11745334796926454,
            "logloss": 0.6645339914410586,
            "mae": 0.30669884063256564,
            "precision": 0.76431718061674,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6858854477160993,
            "auditor_fn_violation": 0.0037225416482382446,
            "auditor_fp_violation": 0.010185296957991311,
            "ave_precision_score": 0.6851315389418715,
            "fpr": 0.31030701754385964,
            "logloss": 0.7492192935072558,
            "mae": 0.44926635685010835,
            "precision": 0.5679389312977099,
            "recall": 0.7815126050420168
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6907999923561758,
            "auditor_fn_violation": 0.01156483518502359,
            "auditor_fp_violation": 0.01575813194139881,
            "ave_precision_score": 0.6897430169901322,
            "fpr": 0.3238199780461032,
            "logloss": 0.7800934167525617,
            "mae": 0.4514023307659072,
            "precision": 0.549618320610687,
            "recall": 0.7531380753138075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6198110484443708,
            "auditor_fn_violation": 0.012605042016806726,
            "auditor_fp_violation": 0.00044765008852406445,
            "ave_precision_score": 0.6217128547107098,
            "fpr": 0.20833333333333334,
            "logloss": 2.1177182048629524,
            "mae": 0.4595636163056573,
            "precision": 0.592274678111588,
            "recall": 0.5798319327731093
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6290675520397662,
            "auditor_fn_violation": 0.014570865617350014,
            "auditor_fp_violation": 0.014052015017885078,
            "ave_precision_score": 0.6308610253709019,
            "fpr": 0.22283205268935236,
            "logloss": 2.195041915354013,
            "mae": 0.4581964524286215,
            "precision": 0.5699152542372882,
            "recall": 0.5627615062761506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7476549566846475,
            "auditor_fn_violation": 0.0113657305027274,
            "auditor_fp_violation": 0.030611218413004997,
            "ave_precision_score": 0.7471404738442814,
            "fpr": 0.09649122807017543,
            "logloss": 2.148535162884642,
            "mae": 0.32680148431320644,
            "precision": 0.772020725388601,
            "recall": 0.6260504201680672
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7263700973259815,
            "auditor_fn_violation": 0.011551056588695124,
            "auditor_fp_violation": 0.019821884435295582,
            "ave_precision_score": 0.7257231699163089,
            "fpr": 0.09769484083424808,
            "logloss": 2.374659476052021,
            "mae": 0.33411240124178465,
            "precision": 0.7712082262210797,
            "recall": 0.6276150627615062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7571755927057059,
            "auditor_fn_violation": 0.02526997641161728,
            "auditor_fp_violation": 0.023121881538709164,
            "ave_precision_score": 0.7561182517743436,
            "fpr": 0.12390350877192982,
            "logloss": 0.8851830737079384,
            "mae": 0.3121262344235205,
            "precision": 0.7554112554112554,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.734764059827929,
            "auditor_fn_violation": 0.01931299918706282,
            "auditor_fp_violation": 0.015966009486314308,
            "ave_precision_score": 0.7341153069894193,
            "fpr": 0.12294182217343579,
            "logloss": 1.0781678488441033,
            "mae": 0.3172348366333249,
            "precision": 0.7549234135667396,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 18313,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.4525489463540154,
            "auditor_fn_violation": 0.0048558897243107845,
            "auditor_fp_violation": 0.008958031546756806,
            "ave_precision_score": 0.47063119470351256,
            "fpr": 0.36622807017543857,
            "logloss": 0.7511221369549183,
            "mae": 0.5130630116582963,
            "precision": 0.4900763358778626,
            "recall": 0.6743697478991597
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.4647884884794022,
            "auditor_fn_violation": 0.011146884429726863,
            "auditor_fp_violation": 0.012325617358282017,
            "ave_precision_score": 0.4940283369381938,
            "fpr": 0.3600439077936334,
            "logloss": 0.7463245374295059,
            "mae": 0.5108358641160176,
            "precision": 0.48264984227129337,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7781172347884192,
            "auditor_fn_violation": 0.01533244876898128,
            "auditor_fp_violation": 0.02223161113793659,
            "ave_precision_score": 0.7485900491776104,
            "fpr": 0.14473684210526316,
            "logloss": 3.975249597210753,
            "mae": 0.2882554958464011,
            "precision": 0.7322515212981744,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.778395851719501,
            "auditor_fn_violation": 0.01280261242186388,
            "auditor_fp_violation": 0.03423895270278836,
            "ave_precision_score": 0.7489303045116604,
            "fpr": 0.1525795828759605,
            "logloss": 3.912878886658684,
            "mae": 0.28214178782922406,
            "precision": 0.7274509803921568,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7674922153800583,
            "auditor_fn_violation": 0.024339340999557726,
            "auditor_fp_violation": 0.04947539433446,
            "ave_precision_score": 0.7678149555253619,
            "fpr": 0.13925438596491227,
            "logloss": 2.412137409538928,
            "mae": 0.345353905745602,
            "precision": 0.713963963963964,
            "recall": 0.6659663865546218
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7882031973288676,
            "auditor_fn_violation": 0.030825016419493964,
            "auditor_fp_violation": 0.05101619163267531,
            "ave_precision_score": 0.7884791093748738,
            "fpr": 0.1525795828759605,
            "logloss": 2.2895650825858405,
            "mae": 0.3373626951162132,
            "precision": 0.7017167381974249,
            "recall": 0.6841004184100419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7822917002667193,
            "auditor_fn_violation": 0.018949026979212746,
            "auditor_fp_violation": 0.024990443425076454,
            "ave_precision_score": 0.7503295227929317,
            "fpr": 0.14364035087719298,
            "logloss": 4.153500017005122,
            "mae": 0.29084428883156566,
            "precision": 0.7298969072164948,
            "recall": 0.7436974789915967
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7799773443506121,
            "auditor_fn_violation": 0.013245823937096115,
            "auditor_fp_violation": 0.031939624248662105,
            "ave_precision_score": 0.7483369394506444,
            "fpr": 0.145993413830955,
            "logloss": 4.0747125023810895,
            "mae": 0.2822549665951454,
            "precision": 0.7313131313131314,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7682871225603606,
            "auditor_fn_violation": 0.025348297213622296,
            "auditor_fp_violation": 0.048235554482536615,
            "ave_precision_score": 0.7686183990567669,
            "fpr": 0.13596491228070176,
            "logloss": 2.4039826788584144,
            "mae": 0.3440096951489913,
            "precision": 0.7175398633257403,
            "recall": 0.6617647058823529
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7892376766438731,
            "auditor_fn_violation": 0.029343817314184152,
            "auditor_fp_violation": 0.05017454108496868,
            "ave_precision_score": 0.789512010258547,
            "fpr": 0.14818880351262348,
            "logloss": 2.279948336585047,
            "mae": 0.3363301740225467,
            "precision": 0.7058823529411765,
            "recall": 0.6778242677824268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.6300602437285259,
            "auditor_fn_violation": 0.015069843726964486,
            "auditor_fp_violation": 0.03923225494929986,
            "ave_precision_score": 0.6305847845527957,
            "fpr": 0.21052631578947367,
            "logloss": 0.6820578027416034,
            "mae": 0.48772806991218476,
            "precision": 0.488,
            "recall": 0.38445378151260506
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6588231118561175,
            "auditor_fn_violation": 0.023712964281285453,
            "auditor_fp_violation": 0.03426937380692234,
            "ave_precision_score": 0.6592623906162233,
            "fpr": 0.20636663007683864,
            "logloss": 0.6771316013339009,
            "mae": 0.48461668829624793,
            "precision": 0.5240506329113924,
            "recall": 0.4330543933054393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 18313,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6703711792725633,
            "auditor_fn_violation": 0.006551304732419295,
            "auditor_fp_violation": 0.012652402221149203,
            "ave_precision_score": 0.6721097234336837,
            "fpr": 0.10855263157894737,
            "logloss": 0.9631832850179456,
            "mae": 0.4179072976344319,
            "precision": 0.7018072289156626,
            "recall": 0.4894957983193277
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6968416220647484,
            "auditor_fn_violation": 0.00032609344644030823,
            "auditor_fp_violation": 0.012523354535152855,
            "ave_precision_score": 0.6977889058806973,
            "fpr": 0.10537870472008781,
            "logloss": 0.9340719597117236,
            "mae": 0.4027622820504637,
            "precision": 0.7073170731707317,
            "recall": 0.48535564853556484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7869745364946854,
            "auditor_fn_violation": 0.023673614182515117,
            "auditor_fp_violation": 0.021929824561403508,
            "ave_precision_score": 0.7886504788990198,
            "fpr": 0.11951754385964912,
            "logloss": 0.6593637105048953,
            "mae": 0.3062505732605461,
            "precision": 0.7599118942731278,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7860246428464747,
            "auditor_fn_violation": 0.025485810342214418,
            "auditor_fp_violation": 0.018561943705746806,
            "ave_precision_score": 0.7872402070344847,
            "fpr": 0.11745334796926454,
            "logloss": 0.6645328369014187,
            "mae": 0.3067072530119562,
            "precision": 0.76431718061674,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 18313,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.6301296436261076,
            "auditor_fn_violation": 0.03126382131800091,
            "auditor_fp_violation": 0.0427681876710124,
            "ave_precision_score": 0.6306573025041244,
            "fpr": 0.23464912280701755,
            "logloss": 0.6813261447924048,
            "mae": 0.487459788752491,
            "precision": 0.5180180180180181,
            "recall": 0.4831932773109244
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6582632842080903,
            "auditor_fn_violation": 0.027708757216539828,
            "auditor_fp_violation": 0.030760806463470597,
            "ave_precision_score": 0.658702767464636,
            "fpr": 0.22941822173435786,
            "logloss": 0.6764098329773763,
            "mae": 0.48434756495034004,
            "precision": 0.5365853658536586,
            "recall": 0.5062761506276151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5328876123224858,
            "auditor_fn_violation": 0.006081379920389208,
            "auditor_fp_violation": 0.010788870111057464,
            "ave_precision_score": 0.5359326908438744,
            "fpr": 0.4616228070175439,
            "logloss": 0.6909885811179299,
            "mae": 0.49849516290583107,
            "precision": 0.5264341957255343,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.51344708802757,
            "auditor_fn_violation": 0.005658410225555622,
            "auditor_fp_violation": 0.008943804615388531,
            "ave_precision_score": 0.5159599617272876,
            "fpr": 0.4621295279912184,
            "logloss": 0.691773912817797,
            "mae": 0.4988551260218531,
            "precision": 0.5274971941638609,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 18313,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.6286898572625238,
            "auditor_fn_violation": 0.018852277753206557,
            "auditor_fp_violation": 0.040660711411556416,
            "ave_precision_score": 0.6292359906095248,
            "fpr": 0.21271929824561403,
            "logloss": 0.6815732187912434,
            "mae": 0.48747319816366624,
            "precision": 0.49214659685863876,
            "recall": 0.3949579831932773
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.6574474084346735,
            "auditor_fn_violation": 0.023712964281285453,
            "auditor_fp_violation": 0.034626821780496524,
            "ave_precision_score": 0.657899963337207,
            "fpr": 0.2074643249176729,
            "logloss": 0.676561206721262,
            "mae": 0.4842754560231377,
            "precision": 0.5227272727272727,
            "recall": 0.4330543933054393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7558771346619018,
            "auditor_fn_violation": 0.026057791537667706,
            "auditor_fp_violation": 0.025614135683244815,
            "ave_precision_score": 0.7547391326445725,
            "fpr": 0.09758771929824561,
            "logloss": 1.868944736395183,
            "mae": 0.3192692922710141,
            "precision": 0.7758186397984886,
            "recall": 0.6470588235294118
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7307245471064308,
            "auditor_fn_violation": 0.010834569579615035,
            "auditor_fp_violation": 0.01826787303245171,
            "ave_precision_score": 0.7301312366516006,
            "fpr": 0.09549945115257959,
            "logloss": 2.1524409243156586,
            "mae": 0.32894010219581205,
            "precision": 0.779746835443038,
            "recall": 0.6443514644351465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.46155422327518547,
            "auditor_fn_violation": 0.002377266696152145,
            "auditor_fp_violation": 0.00695115081281185,
            "ave_precision_score": 0.5706364906579293,
            "fpr": 0.4517543859649123,
            "logloss": 0.6900898218771963,
            "mae": 0.4982289101013489,
            "precision": 0.5318181818181819,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.47391761786692715,
            "auditor_fn_violation": 0.0021012359400906636,
            "auditor_fp_violation": 0.006920801190479221,
            "ave_precision_score": 0.5827636845368569,
            "fpr": 0.4489571899012075,
            "logloss": 0.6896374326028012,
            "mae": 0.49800616018596777,
            "precision": 0.5352272727272728,
            "recall": 0.9853556485355649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7821312699796529,
            "auditor_fn_violation": 0.014514687453928941,
            "auditor_fp_violation": 0.021939884113954616,
            "ave_precision_score": 0.74873518854356,
            "fpr": 0.14583333333333334,
            "logloss": 4.190127988672343,
            "mae": 0.28925875823397695,
            "precision": 0.7296747967479674,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7785340503172355,
            "auditor_fn_violation": 0.013523692296386797,
            "auditor_fp_violation": 0.03081657848771621,
            "ave_precision_score": 0.744046144063916,
            "fpr": 0.14818880351262348,
            "logloss": 4.16800520486051,
            "mae": 0.2805104404584562,
            "precision": 0.733201581027668,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6621088776274346,
            "auditor_fn_violation": 0.01506984372696448,
            "auditor_fp_violation": 0.009300056333494282,
            "ave_precision_score": 0.6628832145787927,
            "fpr": 0.20833333333333334,
            "logloss": 0.8036434938409196,
            "mae": 0.441044766437641,
            "precision": 0.6066252587991718,
            "recall": 0.615546218487395
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6796492512923674,
            "auditor_fn_violation": 0.008510579665547547,
            "auditor_fp_violation": 0.012954320177050838,
            "ave_precision_score": 0.6804947717234889,
            "fpr": 0.2239297475301866,
            "logloss": 0.8040289933752633,
            "mae": 0.4324095258384389,
            "precision": 0.5828220858895705,
            "recall": 0.5962343096234309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.781694431667579,
            "auditor_fn_violation": 0.014514687453928941,
            "auditor_fp_violation": 0.023853713986801868,
            "ave_precision_score": 0.747541965929412,
            "fpr": 0.14583333333333334,
            "logloss": 4.239090985436722,
            "mae": 0.2890881593531158,
            "precision": 0.7296747967479674,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7792503462076827,
            "auditor_fn_violation": 0.013392795631266392,
            "auditor_fp_violation": 0.03415782975843109,
            "ave_precision_score": 0.7446546743124673,
            "fpr": 0.1525795828759605,
            "logloss": 4.173774899914723,
            "mae": 0.2807785598814112,
            "precision": 0.7263779527559056,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7199693650053501,
            "auditor_fn_violation": 0.01814278342916114,
            "auditor_fp_violation": 0.04562258570738774,
            "ave_precision_score": 0.7182611323116939,
            "fpr": 0.18092105263157895,
            "logloss": 2.237947449874531,
            "mae": 0.35499950828137034,
            "precision": 0.6771037181996086,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7495036116851586,
            "auditor_fn_violation": 0.017053309389194835,
            "auditor_fp_violation": 0.04833913446888555,
            "ave_precision_score": 0.7490689038951757,
            "fpr": 0.18551042810098792,
            "logloss": 2.1733923822966483,
            "mae": 0.34569777114367795,
            "precision": 0.6774809160305344,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.779126628863611,
            "auditor_fn_violation": 0.018320157010172495,
            "auditor_fp_violation": 0.022143590053114438,
            "ave_precision_score": 0.7495223490698517,
            "fpr": 0.14583333333333334,
            "logloss": 3.990487021097496,
            "mae": 0.288523765685385,
            "precision": 0.7307692307692307,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7771683733826065,
            "auditor_fn_violation": 0.014752283802341441,
            "auditor_fp_violation": 0.03282944154458087,
            "ave_precision_score": 0.7479499627374219,
            "fpr": 0.1525795828759605,
            "logloss": 3.9214476722465044,
            "mae": 0.2820925136873712,
            "precision": 0.7274509803921568,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7818753805205676,
            "auditor_fn_violation": 0.014514687453928941,
            "auditor_fp_violation": 0.023853713986801868,
            "ave_precision_score": 0.747633382643869,
            "fpr": 0.14583333333333334,
            "logloss": 4.253573621901896,
            "mae": 0.28922457704776106,
            "precision": 0.7296747967479674,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7788105008289794,
            "auditor_fn_violation": 0.012432886753716777,
            "auditor_fp_violation": 0.03415782975843109,
            "ave_precision_score": 0.7442142257717654,
            "fpr": 0.1525795828759605,
            "logloss": 4.2085720780928595,
            "mae": 0.2809719419203472,
            "precision": 0.7269155206286837,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7485138616048322,
            "auditor_fn_violation": 0.01994876898127673,
            "auditor_fp_violation": 0.027027502816674712,
            "ave_precision_score": 0.747412969459035,
            "fpr": 0.09978070175438597,
            "logloss": 1.90177920094712,
            "mae": 0.31892008100357033,
            "precision": 0.7741935483870968,
            "recall": 0.6554621848739496
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7231661780572739,
            "auditor_fn_violation": 0.017746832071060818,
            "auditor_fp_violation": 0.01851377695753468,
            "ave_precision_score": 0.7225797664692224,
            "fpr": 0.10537870472008781,
            "logloss": 2.1916328871002757,
            "mae": 0.3295126255540645,
            "precision": 0.7635467980295566,
            "recall": 0.6485355648535565
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7873032357657292,
            "auditor_fn_violation": 0.011725084770750408,
            "auditor_fp_violation": 0.022352325768549817,
            "ave_precision_score": 0.7538328895737869,
            "fpr": 0.15789473684210525,
            "logloss": 3.6916217264991857,
            "mae": 0.28903554995314307,
            "precision": 0.7176470588235294,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7833677985563074,
            "auditor_fn_violation": 0.014710948013356054,
            "auditor_fp_violation": 0.03186610658033834,
            "ave_precision_score": 0.7484857092848949,
            "fpr": 0.15916575192096596,
            "logloss": 3.536954108247449,
            "mae": 0.2826683252190507,
            "precision": 0.7216890595009597,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7706351248095629,
            "auditor_fn_violation": 0.02797434763379036,
            "auditor_fp_violation": 0.026703082246901662,
            "ave_precision_score": 0.7408612903285273,
            "fpr": 0.13706140350877194,
            "logloss": 4.593274591038718,
            "mae": 0.30508851291198924,
            "precision": 0.7264770240700219,
            "recall": 0.6974789915966386
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7695511323018773,
            "auditor_fn_violation": 0.03197093634747784,
            "auditor_fp_violation": 0.036588982997137885,
            "ave_precision_score": 0.7384061492057035,
            "fpr": 0.1437980241492865,
            "logloss": 4.653000065492622,
            "mae": 0.2964048749852102,
            "precision": 0.7247899159663865,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 18313,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7455038689822762,
            "auditor_fn_violation": 0.013987173816895173,
            "auditor_fp_violation": 0.02760592708836311,
            "ave_precision_score": 0.7450063316557762,
            "fpr": 0.09758771929824561,
            "logloss": 2.215608547240825,
            "mae": 0.3272446452867362,
            "precision": 0.7694300518134715,
            "recall": 0.6239495798319328
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7261318994877877,
            "auditor_fn_violation": 0.01122266670953342,
            "auditor_fp_violation": 0.01766452113379455,
            "ave_precision_score": 0.7255012273679708,
            "fpr": 0.09659714599341383,
            "logloss": 2.4236403263085657,
            "mae": 0.3341762323088772,
            "precision": 0.772609819121447,
            "recall": 0.6255230125523012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 18313,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6792901741193941,
            "auditor_fn_violation": 0.024493679050567596,
            "auditor_fp_violation": 0.04716924191211975,
            "ave_precision_score": 0.6641008500532005,
            "fpr": 0.1600877192982456,
            "logloss": 3.1539650920701865,
            "mae": 0.3301629265219413,
            "precision": 0.7014314928425358,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6996385758894461,
            "auditor_fn_violation": 0.025591446247399285,
            "auditor_fp_violation": 0.049206135936703845,
            "ave_precision_score": 0.6851123378648815,
            "fpr": 0.15806805708013172,
            "logloss": 3.0854917874183383,
            "mae": 0.32262440518501784,
            "precision": 0.710261569416499,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7563348545788651,
            "auditor_fn_violation": 0.02447755417956657,
            "auditor_fp_violation": 0.02389646708514406,
            "ave_precision_score": 0.7552797569484908,
            "fpr": 0.12171052631578948,
            "logloss": 0.8886331806652207,
            "mae": 0.3120965187431701,
            "precision": 0.7592190889370932,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7341909927461725,
            "auditor_fn_violation": 0.02315033826453987,
            "auditor_fp_violation": 0.015966009486314308,
            "ave_precision_score": 0.7335425829893342,
            "fpr": 0.12294182217343579,
            "logloss": 1.0817621821755146,
            "mae": 0.3171085032706091,
            "precision": 0.7549234135667396,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6228086505560791,
            "auditor_fn_violation": 0.035490841073271426,
            "auditor_fp_violation": 0.047727547078705954,
            "ave_precision_score": 0.6233983000904988,
            "fpr": 0.23135964912280702,
            "logloss": 0.6849337937235639,
            "mae": 0.4911119052159943,
            "precision": 0.5226244343891403,
            "recall": 0.4852941176470588
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6415661190699252,
            "auditor_fn_violation": 0.03209264728171259,
            "auditor_fp_violation": 0.04028768224142695,
            "ave_precision_score": 0.642137168061887,
            "fpr": 0.22502744237102085,
            "logloss": 0.6831508043993139,
            "mae": 0.48979077734355736,
            "precision": 0.5340909090909091,
            "recall": 0.4916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7733701638258684,
            "auditor_fn_violation": 0.02360220403951055,
            "auditor_fp_violation": 0.02250321905681635,
            "ave_precision_score": 0.7749337460795855,
            "fpr": 0.08552631578947369,
            "logloss": 1.8050693759943768,
            "mae": 0.3161674811397585,
            "precision": 0.7947368421052632,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7715469370059157,
            "auditor_fn_violation": 0.0242227723454386,
            "auditor_fp_violation": 0.015083797466429044,
            "ave_precision_score": 0.7726854484528791,
            "fpr": 0.08342480790340286,
            "logloss": 1.9050742690614113,
            "mae": 0.31653143203226697,
            "precision": 0.7978723404255319,
            "recall": 0.6276150627615062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7761167686619059,
            "auditor_fn_violation": 0.027313227922748054,
            "auditor_fp_violation": 0.04325859085787864,
            "ave_precision_score": 0.7764295681912519,
            "fpr": 0.12828947368421054,
            "logloss": 2.387464059542954,
            "mae": 0.33760496765670206,
            "precision": 0.727906976744186,
            "recall": 0.657563025210084
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7941732291234822,
            "auditor_fn_violation": 0.029617092808032007,
            "auditor_fp_violation": 0.04925176759290479,
            "ave_precision_score": 0.794441890375416,
            "fpr": 0.14709110867178923,
            "logloss": 2.262246911534801,
            "mae": 0.3318544401257528,
            "precision": 0.7105831533477321,
            "recall": 0.6882845188284519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7490806774678521,
            "auditor_fn_violation": 0.020128446115288228,
            "auditor_fp_violation": 0.027344378722034445,
            "ave_precision_score": 0.7479596844192955,
            "fpr": 0.10197368421052631,
            "logloss": 1.8881508790756576,
            "mae": 0.31926930817232346,
            "precision": 0.7669172932330827,
            "recall": 0.6428571428571429
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7237738694757936,
            "auditor_fn_violation": 0.010607222740195382,
            "auditor_fp_violation": 0.017626494753627084,
            "ave_precision_score": 0.7232192351561171,
            "fpr": 0.09769484083424808,
            "logloss": 2.183157204295685,
            "mae": 0.3294616598233035,
            "precision": 0.7752525252525253,
            "recall": 0.6422594142259415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7246706083528517,
            "auditor_fn_violation": 0.01120448179271709,
            "auditor_fp_violation": 0.014183969097054563,
            "ave_precision_score": 0.6924229891928033,
            "fpr": 0.13486842105263158,
            "logloss": 0.8208399889615295,
            "mae": 0.3965204166934678,
            "precision": 0.716589861751152,
            "recall": 0.6533613445378151
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7304772310137972,
            "auditor_fn_violation": 0.020323429584483466,
            "auditor_fp_violation": 0.018959953151499637,
            "ave_precision_score": 0.6977899355501912,
            "fpr": 0.1437980241492865,
            "logloss": 0.8358377763792745,
            "mae": 0.4017560164046471,
            "precision": 0.700228832951945,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7845979808825008,
            "auditor_fn_violation": 0.022901923927465723,
            "auditor_fp_violation": 0.021487204249155,
            "ave_precision_score": 0.7862743035181716,
            "fpr": 0.125,
            "logloss": 0.6637563016354637,
            "mae": 0.3093847117705442,
            "precision": 0.7569296375266524,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7842770300334247,
            "auditor_fn_violation": 0.01996518607994342,
            "auditor_fp_violation": 0.01786986358669888,
            "ave_precision_score": 0.7855169345272583,
            "fpr": 0.12733260153677278,
            "logloss": 0.6670665009714225,
            "mae": 0.30949673228677277,
            "precision": 0.7521367521367521,
            "recall": 0.7364016736401674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7800086183843219,
            "auditor_fn_violation": 0.018064462627156132,
            "auditor_fp_violation": 0.0366167712860132,
            "ave_precision_score": 0.7802789534503904,
            "fpr": 0.15350877192982457,
            "logloss": 1.9630321933636825,
            "mae": 0.3426941764693681,
            "precision": 0.7046413502109705,
            "recall": 0.7016806722689075
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7963636869619837,
            "auditor_fn_violation": 0.017365624239306668,
            "auditor_fp_violation": 0.04127890321779229,
            "ave_precision_score": 0.7966277630754621,
            "fpr": 0.17014270032930845,
            "logloss": 1.9932324420947096,
            "mae": 0.3367822260311122,
            "precision": 0.6881287726358148,
            "recall": 0.7154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7434457640733139,
            "auditor_fn_violation": 0.017258219077104526,
            "auditor_fp_violation": 0.029062047320135204,
            "ave_precision_score": 0.7429582958533294,
            "fpr": 0.10087719298245613,
            "logloss": 2.2366652076975027,
            "mae": 0.32240984484312557,
            "precision": 0.7733990147783252,
            "recall": 0.6596638655462185
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7228890820872824,
            "auditor_fn_violation": 0.016502165536056292,
            "auditor_fp_violation": 0.019781322963116948,
            "ave_precision_score": 0.7222578311907457,
            "fpr": 0.10647639956092206,
            "logloss": 2.4452462005824764,
            "mae": 0.32929803534820273,
            "precision": 0.7634146341463415,
            "recall": 0.6548117154811716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7790920219579608,
            "auditor_fn_violation": 0.01778342916113814,
            "auditor_fp_violation": 0.022186343151456622,
            "ave_precision_score": 0.7494915429494229,
            "fpr": 0.14692982456140352,
            "logloss": 3.9916431813498345,
            "mae": 0.28856904151872453,
            "precision": 0.728744939271255,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7771551194949907,
            "auditor_fn_violation": 0.014752283802341441,
            "auditor_fp_violation": 0.03282944154458087,
            "ave_precision_score": 0.7479489643361295,
            "fpr": 0.1525795828759605,
            "logloss": 3.9230103622792694,
            "mae": 0.28211034223621795,
            "precision": 0.7274509803921568,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7872924115749945,
            "auditor_fn_violation": 0.011725084770750408,
            "auditor_fp_violation": 0.019505472396587807,
            "ave_precision_score": 0.7538114783203049,
            "fpr": 0.15570175438596492,
            "logloss": 3.6959473440712953,
            "mae": 0.28891775478793386,
            "precision": 0.7204724409448819,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7833890724601433,
            "auditor_fn_violation": 0.014710948013356054,
            "auditor_fp_violation": 0.032000466456930055,
            "ave_precision_score": 0.748516262003913,
            "fpr": 0.15806805708013172,
            "logloss": 3.542252788016126,
            "mae": 0.28269203959110734,
            "precision": 0.7230769230769231,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7246706083528517,
            "auditor_fn_violation": 0.01120448179271709,
            "auditor_fp_violation": 0.014183969097054563,
            "ave_precision_score": 0.6924229891928033,
            "fpr": 0.13486842105263158,
            "logloss": 0.8288461796715358,
            "mae": 0.39698793941683935,
            "precision": 0.716589861751152,
            "recall": 0.6533613445378151
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7304772310137972,
            "auditor_fn_violation": 0.020323429584483466,
            "auditor_fp_violation": 0.018959953151499637,
            "ave_precision_score": 0.6977899355501912,
            "fpr": 0.1437980241492865,
            "logloss": 0.8442837507068816,
            "mae": 0.4021302735111978,
            "precision": 0.700228832951945,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7791069901538541,
            "auditor_fn_violation": 0.017672858617131058,
            "auditor_fp_violation": 0.020003420247867377,
            "ave_precision_score": 0.7494857894375808,
            "fpr": 0.15021929824561403,
            "logloss": 3.98733411085715,
            "mae": 0.28981015446680647,
            "precision": 0.7265469061876247,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7758357241052033,
            "auditor_fn_violation": 0.014851030409362096,
            "auditor_fp_violation": 0.03184075566022669,
            "ave_precision_score": 0.7466523400863116,
            "fpr": 0.15916575192096596,
            "logloss": 3.9288239315199434,
            "mae": 0.28497384142801796,
            "precision": 0.7200772200772201,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.803612031076601,
            "auditor_fn_violation": 0.03956121922453192,
            "auditor_fp_violation": 0.012393368742958316,
            "ave_precision_score": 0.8038726772727943,
            "fpr": 0.08771929824561403,
            "logloss": 2.671306626935571,
            "mae": 0.3092378394144624,
            "precision": 0.7883597883597884,
            "recall": 0.6260504201680672
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7998696540344575,
            "auditor_fn_violation": 0.030955913084614355,
            "auditor_fp_violation": 0.022602880371543087,
            "ave_precision_score": 0.8003655878229472,
            "fpr": 0.09549945115257959,
            "logloss": 2.7233953965663753,
            "mae": 0.3143266626160843,
            "precision": 0.7763496143958869,
            "recall": 0.6317991631799164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5380304121753658,
            "auditor_fn_violation": 0.014328099660916997,
            "auditor_fp_violation": 0.017071060679220987,
            "ave_precision_score": 0.5389936610663049,
            "fpr": 0.40460526315789475,
            "logloss": 0.7129134151116986,
            "mae": 0.4966749292716645,
            "precision": 0.5427509293680297,
            "recall": 0.9201680672268907
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5867162862299293,
            "auditor_fn_violation": 0.006678026353861912,
            "auditor_fp_violation": 0.012994881649229469,
            "ave_precision_score": 0.5878553254474097,
            "fpr": 0.3995609220636663,
            "logloss": 0.6939342031262458,
            "mae": 0.48706694910738263,
            "precision": 0.5577156743620899,
            "recall": 0.9602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.776129368893504,
            "auditor_fn_violation": 0.027313227922748054,
            "auditor_fp_violation": 0.04325859085787864,
            "ave_precision_score": 0.7764419158342548,
            "fpr": 0.12828947368421054,
            "logloss": 2.3874643574276964,
            "mae": 0.3375899345111181,
            "precision": 0.727906976744186,
            "recall": 0.657563025210084
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7942854344480916,
            "auditor_fn_violation": 0.029013131002301025,
            "auditor_fp_violation": 0.04925176759290479,
            "ave_precision_score": 0.7945534753755555,
            "fpr": 0.14709110867178923,
            "logloss": 2.262063322689142,
            "mae": 0.3318859772802987,
            "precision": 0.7112068965517241,
            "recall": 0.6903765690376569
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7818856228443536,
            "auditor_fn_violation": 0.014514687453928941,
            "auditor_fp_violation": 0.023853713986801868,
            "ave_precision_score": 0.747640340625143,
            "fpr": 0.14583333333333334,
            "logloss": 4.253565093333161,
            "mae": 0.2892257025726462,
            "precision": 0.7296747967479674,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7788345188589039,
            "auditor_fn_violation": 0.012432886753716777,
            "auditor_fp_violation": 0.03415782975843109,
            "ave_precision_score": 0.7442382231113769,
            "fpr": 0.1525795828759605,
            "logloss": 4.208594748148822,
            "mae": 0.2809830742616906,
            "precision": 0.7269155206286837,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7654024593685014,
            "auditor_fn_violation": 0.025928792569659458,
            "auditor_fp_violation": 0.03554039916304523,
            "ave_precision_score": 0.7659513903435793,
            "fpr": 0.09868421052631579,
            "logloss": 2.447257789776896,
            "mae": 0.334929440930879,
            "precision": 0.7567567567567568,
            "recall": 0.5882352941176471
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7860619352384073,
            "auditor_fn_violation": 0.03049203367488943,
            "auditor_fp_violation": 0.037861599186742485,
            "ave_precision_score": 0.7864987884713356,
            "fpr": 0.10647639956092206,
            "logloss": 2.3211776989011144,
            "mae": 0.32825400702180424,
            "precision": 0.7544303797468355,
            "recall": 0.6234309623430963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7867283886585467,
            "auditor_fn_violation": 0.019934947663275842,
            "auditor_fp_violation": 0.024555367777241276,
            "ave_precision_score": 0.7884010104577499,
            "fpr": 0.11842105263157894,
            "logloss": 0.6587573447380917,
            "mae": 0.3073019912201127,
            "precision": 0.7626373626373626,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7868670437409508,
            "auditor_fn_violation": 0.027111684708973082,
            "auditor_fp_violation": 0.01903854100384574,
            "ave_precision_score": 0.78807822086371,
            "fpr": 0.11855104281009879,
            "logloss": 0.6609768552876176,
            "mae": 0.3068737537448407,
            "precision": 0.7615894039735099,
            "recall": 0.7217573221757322
        }
    }
]