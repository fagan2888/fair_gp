[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 19863,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8353658005086326,
            "auditor_fn_violation": 0.009988650353955065,
            "auditor_fp_violation": 0.01890725992613112,
            "ave_precision_score": 0.835615002535133,
            "fpr": 0.1524122807017544,
            "logloss": 0.5750901331718102,
            "mae": 0.28410204554941293,
            "precision": 0.7252964426877471,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8409836940566373,
            "auditor_fn_violation": 0.013227443252703466,
            "auditor_fp_violation": 0.02568818556092739,
            "ave_precision_score": 0.8417155219197061,
            "fpr": 0.13172338090010977,
            "logloss": 0.5796137984827815,
            "mae": 0.2803411076319967,
            "precision": 0.7669902912621359,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.803645873160489,
            "auditor_fn_violation": 0.012609649122807015,
            "auditor_fp_violation": 0.022333795013850417,
            "ave_precision_score": 0.8040189816581926,
            "fpr": 0.15789473684210525,
            "logloss": 0.7537123523858315,
            "mae": 0.2821873940097867,
            "precision": 0.7137176938369781,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8248005412652074,
            "auditor_fn_violation": 0.007895467710578872,
            "auditor_fp_violation": 0.02746097601815848,
            "ave_precision_score": 0.8256374368278069,
            "fpr": 0.13172338090010977,
            "logloss": 0.7586198534564425,
            "mae": 0.2826837648746411,
            "precision": 0.7590361445783133,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8569900957205684,
            "auditor_fn_violation": 0.027412280701754388,
            "auditor_fp_violation": 0.03211565096952909,
            "ave_precision_score": 0.8572548337437402,
            "fpr": 0.12828947368421054,
            "logloss": 0.5073352200654692,
            "mae": 0.30284664485754964,
            "precision": 0.7515923566878981,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8451446006021972,
            "auditor_fn_violation": 0.03404617371792329,
            "auditor_fp_violation": 0.02426623219568205,
            "ave_precision_score": 0.8454424089435146,
            "fpr": 0.10867178924259056,
            "logloss": 0.5470776383446805,
            "mae": 0.3174283857312044,
            "precision": 0.7875536480686696,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7858246167799496,
            "auditor_fn_violation": 0.013177131425053867,
            "auditor_fp_violation": 0.021814404432132967,
            "ave_precision_score": 0.7862661286786754,
            "fpr": 0.15789473684210525,
            "logloss": 0.8761000250360647,
            "mae": 0.2880585141380981,
            "precision": 0.7114228456913828,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8189830476176728,
            "auditor_fn_violation": 0.008093846296271806,
            "auditor_fp_violation": 0.021541929019277442,
            "ave_precision_score": 0.8194121706017813,
            "fpr": 0.12733260153677278,
            "logloss": 0.8582438592197648,
            "mae": 0.2855782940298518,
            "precision": 0.7573221757322176,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.779575648219308,
            "auditor_fn_violation": 0.005448791935980302,
            "auditor_fp_violation": 0.022199138196368123,
            "ave_precision_score": 0.77975188904479,
            "fpr": 0.38706140350877194,
            "logloss": 2.295008769402508,
            "mae": 0.3973224228664683,
            "precision": 0.5559748427672956,
            "recall": 0.9692982456140351
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8157801813329919,
            "auditor_fn_violation": 0.0037471510630887983,
            "auditor_fp_violation": 0.013980326544281227,
            "ave_precision_score": 0.8157224167143289,
            "fpr": 0.3446761800219539,
            "logloss": 2.019120233217919,
            "mae": 0.3552827158160757,
            "precision": 0.6070087609511889,
            "recall": 0.9738955823293173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8124349286462826,
            "auditor_fn_violation": 0.010496018005540167,
            "auditor_fp_violation": 0.017442867036011087,
            "ave_precision_score": 0.8127578848718058,
            "fpr": 0.14802631578947367,
            "logloss": 0.7406974701525894,
            "mae": 0.2801391512858441,
            "precision": 0.725609756097561,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8300839298084588,
            "auditor_fn_violation": 0.0037559678891195955,
            "auditor_fp_violation": 0.01829402806165165,
            "ave_precision_score": 0.8307202809921775,
            "fpr": 0.12623490669593854,
            "logloss": 0.7475049554952825,
            "mae": 0.27984235455753065,
            "precision": 0.7638603696098563,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8035636463189981,
            "auditor_fn_violation": 0.009777046783625733,
            "auditor_fp_violation": 0.012811634349030482,
            "ave_precision_score": 0.8039310717639355,
            "fpr": 0.16228070175438597,
            "logloss": 0.7873833807882886,
            "mae": 0.2805819165377486,
            "precision": 0.7126213592233009,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8281502010347653,
            "auditor_fn_violation": 0.0065905774580208906,
            "auditor_fp_violation": 0.02255191458711524,
            "ave_precision_score": 0.8285671936809519,
            "fpr": 0.132821075740944,
            "logloss": 0.7809316338056121,
            "mae": 0.2803749648280532,
            "precision": 0.7584830339321357,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7894911183570504,
            "auditor_fn_violation": 0.01688019390581718,
            "auditor_fp_violation": 0.016408895044629116,
            "ave_precision_score": 0.7899010547368608,
            "fpr": 0.1524122807017544,
            "logloss": 0.8855168893503795,
            "mae": 0.28276535951770365,
            "precision": 0.7145790554414785,
            "recall": 0.7631578947368421
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8190324451513811,
            "auditor_fn_violation": 0.007088728128760928,
            "auditor_fp_violation": 0.02246420531411881,
            "ave_precision_score": 0.8198640188711063,
            "fpr": 0.11964873765093303,
            "logloss": 0.882612412013916,
            "mae": 0.2814861858702093,
            "precision": 0.7719665271966527,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8223410346593643,
            "auditor_fn_violation": 0.011950792551554325,
            "auditor_fp_violation": 0.020140812557710067,
            "ave_precision_score": 0.8226337539137198,
            "fpr": 0.15789473684210525,
            "logloss": 0.7076059157625614,
            "mae": 0.27625919321865894,
            "precision": 0.7170923379174853,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8382965190366655,
            "auditor_fn_violation": 0.0037559678891195946,
            "auditor_fp_violation": 0.025393163460848443,
            "ave_precision_score": 0.8386791357939372,
            "fpr": 0.12623490669593854,
            "logloss": 0.6894081789412068,
            "mae": 0.2735767158006002,
            "precision": 0.7709163346613546,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8228665023920523,
            "auditor_fn_violation": 0.020862188365650975,
            "auditor_fp_violation": 0.04813019390581719,
            "ave_precision_score": 0.823206182346132,
            "fpr": 0.24561403508771928,
            "logloss": 0.6399706970458082,
            "mae": 0.3533354877650517,
            "precision": 0.6241610738255033,
            "recall": 0.8157894736842105
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8298995200449262,
            "auditor_fn_violation": 0.02868333928469091,
            "auditor_fp_violation": 0.043594166535988715,
            "ave_precision_score": 0.8302760995171121,
            "fpr": 0.21953896816684962,
            "logloss": 0.6234246361824436,
            "mae": 0.3470633071348885,
            "precision": 0.6737357259380098,
            "recall": 0.8293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8104850392834009,
            "auditor_fn_violation": 0.01742843951985227,
            "auditor_fp_violation": 0.010676361957525391,
            "ave_precision_score": 0.8108052421156642,
            "fpr": 0.14912280701754385,
            "logloss": 0.7927005866837411,
            "mae": 0.2778269547777198,
            "precision": 0.7258064516129032,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8313069223971088,
            "auditor_fn_violation": 0.013450068109981088,
            "auditor_fp_violation": 0.02093859553533222,
            "ave_precision_score": 0.831902265584896,
            "fpr": 0.1251372118551043,
            "logloss": 0.791266084078154,
            "mae": 0.2791741663832479,
            "precision": 0.7668711656441718,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8320170073909429,
            "auditor_fn_violation": 0.0010580178516466602,
            "auditor_fp_violation": 0.010611438134810715,
            "ave_precision_score": 0.8322758035238145,
            "fpr": 0.12828947368421054,
            "logloss": 0.553515648811753,
            "mae": 0.3295385620409721,
            "precision": 0.7473002159827213,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8427598468396909,
            "auditor_fn_violation": 0.007732356429009125,
            "auditor_fp_violation": 0.014809577852611215,
            "ave_precision_score": 0.8429714059486263,
            "fpr": 0.1163556531284303,
            "logloss": 0.5545217792676514,
            "mae": 0.33986850864939905,
            "precision": 0.7777777777777778,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 19863,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.76520180985393,
            "auditor_fn_violation": 0.013523391812865502,
            "auditor_fp_violation": 0.024853801169590652,
            "ave_precision_score": 0.7282354453235775,
            "fpr": 0.16666666666666666,
            "logloss": 2.796273783654296,
            "mae": 0.27906246032876675,
            "precision": 0.7142857142857143,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8183838496974783,
            "auditor_fn_violation": 0.010897596974065308,
            "auditor_fp_violation": 0.02713140178023246,
            "ave_precision_score": 0.7906095332614366,
            "fpr": 0.13391877058177826,
            "logloss": 2.487093944914482,
            "mae": 0.27459018587548123,
            "precision": 0.7631067961165049,
            "recall": 0.7891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8055942047917314,
            "auditor_fn_violation": 0.013338238688827333,
            "auditor_fp_violation": 0.023286011080332413,
            "ave_precision_score": 0.8058893770362886,
            "fpr": 0.17105263157894737,
            "logloss": 0.5757061197277098,
            "mae": 0.3554160656146034,
            "precision": 0.6947162426614482,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8245007482620994,
            "auditor_fn_violation": 0.01079179506169574,
            "auditor_fp_violation": 0.028957349372612916,
            "ave_precision_score": 0.8248436879683857,
            "fpr": 0.1525795828759605,
            "logloss": 0.5463963377820609,
            "mae": 0.34458943854320245,
            "precision": 0.7382297551789078,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8094279115793763,
            "auditor_fn_violation": 0.014225530932594642,
            "auditor_fp_violation": 0.014869959987688522,
            "ave_precision_score": 0.8097646704681649,
            "fpr": 0.14912280701754385,
            "logloss": 0.772884874718042,
            "mae": 0.278483071066808,
            "precision": 0.7224489795918367,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.828902725730134,
            "auditor_fn_violation": 0.005616318181617803,
            "auditor_fp_violation": 0.01967877143229244,
            "ave_precision_score": 0.8295133229703225,
            "fpr": 0.12184412733260154,
            "logloss": 0.787313104234132,
            "mae": 0.2824085062588966,
            "precision": 0.7697095435684648,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8007801677940694,
            "auditor_fn_violation": 0.012407663896583564,
            "auditor_fp_violation": 0.022550207756232697,
            "ave_precision_score": 0.8011828176173903,
            "fpr": 0.15679824561403508,
            "logloss": 0.761720649822596,
            "mae": 0.2834559799875299,
            "precision": 0.7157057654075547,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8242938380171633,
            "auditor_fn_violation": 0.004443680319521781,
            "auditor_fp_violation": 0.024279521479469386,
            "ave_precision_score": 0.8247236714756002,
            "fpr": 0.1350164654226125,
            "logloss": 0.7689625809373859,
            "mae": 0.2858026547346215,
            "precision": 0.7544910179640718,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 19863,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8634651878728913,
            "auditor_fn_violation": 0.012068617266851342,
            "auditor_fp_violation": 0.04597568482610034,
            "ave_precision_score": 0.8639140148938969,
            "fpr": 0.2850877192982456,
            "logloss": 0.6613876814939311,
            "mae": 0.33201214084641706,
            "precision": 0.6204379562043796,
            "recall": 0.9320175438596491
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8580540395435252,
            "auditor_fn_violation": 0.01625161458126689,
            "auditor_fp_violation": 0.03948246213218587,
            "ave_precision_score": 0.858263674213979,
            "fpr": 0.2349066959385291,
            "logloss": 0.6268202852601319,
            "mae": 0.3195360984380278,
            "precision": 0.6781954887218045,
            "recall": 0.9056224899598394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 19863,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.4010565344825583,
            "auditor_fn_violation": 0.012465373961218832,
            "auditor_fp_violation": 0.01971760541705141,
            "ave_precision_score": 0.3713488314676546,
            "fpr": 0.31798245614035087,
            "logloss": 12.89464457582681,
            "mae": 0.6595439588435464,
            "precision": 0.3348623853211009,
            "recall": 0.3201754385964912
        },
        "train": {
            "accuracy": 0.34577387486278816,
            "auc_prc": 0.4440094781600353,
            "auditor_fn_violation": 0.006220270764727409,
            "auditor_fp_violation": 0.022658228857413965,
            "ave_precision_score": 0.4129354659863073,
            "fpr": 0.2897914379802415,
            "logloss": 13.16018189596123,
            "mae": 0.6583026639703419,
            "precision": 0.386046511627907,
            "recall": 0.3333333333333333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8420476553420483,
            "auditor_fn_violation": 0.015976069559864577,
            "auditor_fp_violation": 0.02911472760849493,
            "ave_precision_score": 0.8423856637165654,
            "fpr": 0.1337719298245614,
            "logloss": 0.5683252241957575,
            "mae": 0.31321500620865744,
            "precision": 0.7431578947368421,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8396970601428123,
            "auditor_fn_violation": 0.03723345632805647,
            "auditor_fp_violation": 0.025374558463546172,
            "ave_precision_score": 0.8399874378093675,
            "fpr": 0.11855104281009879,
            "logloss": 0.5890206996073453,
            "mae": 0.3184452607234046,
            "precision": 0.7759336099585062,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8102101069493404,
            "auditor_fn_violation": 0.011513157894736843,
            "auditor_fp_violation": 0.013042474607571563,
            "ave_precision_score": 0.8105563729402556,
            "fpr": 0.1513157894736842,
            "logloss": 0.7467490471131137,
            "mae": 0.2775176106404214,
            "precision": 0.7234468937875751,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8315380919881048,
            "auditor_fn_violation": 0.005395897530847871,
            "auditor_fp_violation": 0.018849520123962443,
            "ave_precision_score": 0.8318793315072444,
            "fpr": 0.11964873765093303,
            "logloss": 0.7588913677561724,
            "mae": 0.2777948779765715,
            "precision": 0.7729166666666667,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8111463941494391,
            "auditor_fn_violation": 0.012426900584795331,
            "auditor_fp_violation": 0.012984764542936289,
            "ave_precision_score": 0.8116358566204687,
            "fpr": 0.10197368421052631,
            "logloss": 0.5582554779244245,
            "mae": 0.33657980253848474,
            "precision": 0.7790973871733967,
            "recall": 0.7192982456140351
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8248506517984231,
            "auditor_fn_violation": 0.007686068092347444,
            "auditor_fp_violation": 0.01555377774470223,
            "ave_precision_score": 0.8252854947602344,
            "fpr": 0.0867178924259056,
            "logloss": 0.5526439984749485,
            "mae": 0.3398162074646229,
            "precision": 0.8119047619047619,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8174591765364013,
            "auditor_fn_violation": 0.008346318097876282,
            "auditor_fp_violation": 0.007675438596491231,
            "ave_precision_score": 0.8177341423349378,
            "fpr": 0.08333333333333333,
            "logloss": 0.5632639924535107,
            "mae": 0.336738086303261,
            "precision": 0.8056265984654731,
            "recall": 0.6907894736842105
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8233400359933467,
            "auditor_fn_violation": 0.0072804940949307735,
            "auditor_fp_violation": 0.010070619254045923,
            "ave_precision_score": 0.8237606004473392,
            "fpr": 0.0801317233809001,
            "logloss": 0.5645930793976337,
            "mae": 0.3405608360100493,
            "precision": 0.8175,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.808685154026296,
            "auditor_fn_violation": 0.012600030778701152,
            "auditor_fp_violation": 0.020967990150815637,
            "ave_precision_score": 0.8089695423551013,
            "fpr": 0.14035087719298245,
            "logloss": 0.7088842630987661,
            "mae": 0.2956451166228342,
            "precision": 0.7253218884120172,
            "recall": 0.7412280701754386
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8229835972095078,
            "auditor_fn_violation": 0.005171068467062547,
            "auditor_fp_violation": 0.024207759347017754,
            "ave_precision_score": 0.8234938230961479,
            "fpr": 0.11855104281009879,
            "logloss": 0.7495845954397113,
            "mae": 0.2968780053234225,
            "precision": 0.7677419354838709,
            "recall": 0.7168674698795181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 19863,
        "test": {
            "accuracy": 0.34539473684210525,
            "auc_prc": 0.3966385695812499,
            "auditor_fn_violation": 0.009834756848261014,
            "auditor_fp_violation": 0.020677035241612816,
            "ave_precision_score": 0.371111169650191,
            "fpr": 0.31469298245614036,
            "logloss": 11.775744714372461,
            "mae": 0.6570054578856765,
            "precision": 0.3371824480369515,
            "recall": 0.3201754385964912
        },
        "train": {
            "accuracy": 0.3446761800219539,
            "auc_prc": 0.4373005234018586,
            "auditor_fn_violation": 0.00674928032657524,
            "auditor_fp_violation": 0.022676833854716243,
            "ave_precision_score": 0.4119110118418151,
            "fpr": 0.28869374313940727,
            "logloss": 11.961092808208118,
            "mae": 0.6582998802534513,
            "precision": 0.3840749414519906,
            "recall": 0.3293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8070469807659643,
            "auditor_fn_violation": 0.010183421822099106,
            "auditor_fp_violation": 0.016485841797476156,
            "ave_precision_score": 0.8073885384275851,
            "fpr": 0.14912280701754385,
            "logloss": 0.7696871320964014,
            "mae": 0.2795556546760475,
            "precision": 0.7252525252525253,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8289928228416326,
            "auditor_fn_violation": 0.004600178981568429,
            "auditor_fp_violation": 0.0200375820945506,
            "ave_precision_score": 0.8295349942283125,
            "fpr": 0.12294182217343579,
            "logloss": 0.7719131539471243,
            "mae": 0.27769547143278517,
            "precision": 0.7709611451942741,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8504462485533277,
            "auditor_fn_violation": 0.00536703601108034,
            "auditor_fp_violation": 0.012347549245921822,
            "ave_precision_score": 0.8506919610089363,
            "fpr": 0.0800438596491228,
            "logloss": 0.5111728968433816,
            "mae": 0.3141107309825122,
            "precision": 0.8197530864197531,
            "recall": 0.7280701754385965
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8503973282925317,
            "auditor_fn_violation": 0.007392908626823442,
            "auditor_fp_violation": 0.013616200168508119,
            "ave_precision_score": 0.8507620798426467,
            "fpr": 0.0867178924259056,
            "logloss": 0.5273441436134256,
            "mae": 0.3278038033215113,
            "precision": 0.8141176470588235,
            "recall": 0.6947791164658634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8146833939417897,
            "auditor_fn_violation": 0.016089085103108653,
            "auditor_fp_violation": 0.014081255771006478,
            "ave_precision_score": 0.8149792320498128,
            "fpr": 0.16447368421052633,
            "logloss": 0.848882161112236,
            "mae": 0.27649906054118534,
            "precision": 0.7098646034816247,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8351092755644508,
            "auditor_fn_violation": 0.00665009103372877,
            "auditor_fp_violation": 0.017927243829121087,
            "ave_precision_score": 0.8354575431601052,
            "fpr": 0.13391877058177826,
            "logloss": 0.8069832523051258,
            "mae": 0.27834616763920494,
            "precision": 0.7564870259481038,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8287293914416822,
            "auditor_fn_violation": 0.001120537088334872,
            "auditor_fp_violation": 0.011231821329639891,
            "ave_precision_score": 0.829004661896029,
            "fpr": 0.12390350877192982,
            "logloss": 0.5556789570992108,
            "mae": 0.335018661177999,
            "precision": 0.7521929824561403,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8304981118340082,
            "auditor_fn_violation": 0.005495086823694344,
            "auditor_fp_violation": 0.016991678250492366,
            "ave_precision_score": 0.8307548060721994,
            "fpr": 0.10976948408342481,
            "logloss": 0.5681384216959791,
            "mae": 0.3523160384803843,
            "precision": 0.7782705099778271,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7845808570085746,
            "auditor_fn_violation": 0.008021698984302873,
            "auditor_fp_violation": 0.020761195752539246,
            "ave_precision_score": 0.7849690803743374,
            "fpr": 0.13486842105263158,
            "logloss": 0.8270318187629391,
            "mae": 0.30033224312626133,
            "precision": 0.7248322147651006,
            "recall": 0.7105263157894737
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8136226222972968,
            "auditor_fn_violation": 0.010602233302033599,
            "auditor_fp_violation": 0.014028167965915644,
            "ave_precision_score": 0.81429921634651,
            "fpr": 0.09989023051591657,
            "logloss": 0.8272250604246314,
            "mae": 0.29559790858682616,
            "precision": 0.7858823529411765,
            "recall": 0.6706827309236948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8089812255202344,
            "auditor_fn_violation": 0.014225530932594642,
            "auditor_fp_violation": 0.014869959987688522,
            "ave_precision_score": 0.8093197113494914,
            "fpr": 0.14912280701754385,
            "logloss": 0.7735734883075605,
            "mae": 0.27869366448767574,
            "precision": 0.7224489795918367,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8288207508307259,
            "auditor_fn_violation": 0.005616318181617803,
            "auditor_fp_violation": 0.01967877143229244,
            "ave_precision_score": 0.8294313796370099,
            "fpr": 0.12184412733260154,
            "logloss": 0.7876662362600683,
            "mae": 0.2825207997881414,
            "precision": 0.7697095435684648,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8136138289902974,
            "auditor_fn_violation": 0.012426900584795331,
            "auditor_fp_violation": 0.012046975992613113,
            "ave_precision_score": 0.8139833323212924,
            "fpr": 0.10197368421052631,
            "logloss": 0.569934371739773,
            "mae": 0.3419207543974105,
            "precision": 0.7790973871733967,
            "recall": 0.7192982456140351
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.824680372833911,
            "auditor_fn_violation": 0.013458884936011894,
            "auditor_fp_violation": 0.015925877690747738,
            "ave_precision_score": 0.8250372376201994,
            "fpr": 0.09220636663007684,
            "logloss": 0.5608288888713497,
            "mae": 0.3434381351691725,
            "precision": 0.8032786885245902,
            "recall": 0.6887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7876895705019563,
            "auditor_fn_violation": 0.019304016620498618,
            "auditor_fp_violation": 0.012446137273007082,
            "ave_precision_score": 0.7880694090788277,
            "fpr": 0.14364035087719298,
            "logloss": 0.9533148436329208,
            "mae": 0.29066748915930946,
            "precision": 0.7170626349892009,
            "recall": 0.7280701754385965
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8191118670785088,
            "auditor_fn_violation": 0.00571330326795657,
            "auditor_fp_violation": 0.021706716138240448,
            "ave_precision_score": 0.8199115831534649,
            "fpr": 0.1163556531284303,
            "logloss": 0.9335962826441596,
            "mae": 0.2888136771039517,
            "precision": 0.7725321888412017,
            "recall": 0.7228915662650602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7992336271682516,
            "auditor_fn_violation": 0.018284472145275472,
            "auditor_fp_violation": 0.02010233918128656,
            "ave_precision_score": 0.7996479061881401,
            "fpr": 0.16666666666666666,
            "logloss": 0.8243751092846998,
            "mae": 0.28136084995941546,
            "precision": 0.7001972386587771,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8270535679943058,
            "auditor_fn_violation": 0.012074643249176727,
            "auditor_fp_violation": 0.02217715678431227,
            "ave_precision_score": 0.8275616292325788,
            "fpr": 0.13062568605927552,
            "logloss": 0.8119488272296559,
            "mae": 0.27943672673996,
            "precision": 0.7605633802816901,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7879723030242474,
            "auditor_fn_violation": 0.011340027700831026,
            "auditor_fp_violation": 0.021006463527239155,
            "ave_precision_score": 0.7884097127346422,
            "fpr": 0.15789473684210525,
            "logloss": 0.868651367109144,
            "mae": 0.28521799032568934,
            "precision": 0.710261569416499,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8231222870423425,
            "auditor_fn_violation": 0.00989909142607753,
            "auditor_fp_violation": 0.025060931366164954,
            "ave_precision_score": 0.8236507768594359,
            "fpr": 0.1251372118551043,
            "logloss": 0.8259007888670468,
            "mae": 0.2815881098036541,
            "precision": 0.7659137577002053,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8155533270470423,
            "auditor_fn_violation": 0.014384233610341645,
            "auditor_fp_violation": 0.018178670360110807,
            "ave_precision_score": 0.8145221911674365,
            "fpr": 0.13815789473684212,
            "logloss": 0.7554755817197732,
            "mae": 0.2660320054841278,
            "precision": 0.7454545454545455,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7909958550210547,
            "auditor_fn_violation": 0.010439122020463853,
            "auditor_fp_violation": 0.02166684828687843,
            "ave_precision_score": 0.7899514069924908,
            "fpr": 0.11745334796926454,
            "logloss": 0.9020901009393444,
            "mae": 0.2851675050776691,
            "precision": 0.7838383838383839,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8544985452984735,
            "auditor_fn_violation": 0.002640235457063715,
            "auditor_fp_violation": 0.008064981532779316,
            "ave_precision_score": 0.8547160200286558,
            "fpr": 0.13267543859649122,
            "logloss": 0.5228116612944809,
            "mae": 0.30823627856956143,
            "precision": 0.7436440677966102,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8567246151400472,
            "auditor_fn_violation": 0.004897746860107832,
            "auditor_fp_violation": 0.02286288382773899,
            "ave_precision_score": 0.8569871490595142,
            "fpr": 0.1119648737650933,
            "logloss": 0.5040162325751141,
            "mae": 0.3110302431015315,
            "precision": 0.7870563674321504,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8127848621756733,
            "auditor_fn_violation": 0.011734379809172059,
            "auditor_fp_violation": 0.01002712373037858,
            "ave_precision_score": 0.8131662975306494,
            "fpr": 0.09868421052631579,
            "logloss": 0.5680242068054379,
            "mae": 0.3415685184989247,
            "precision": 0.7836538461538461,
            "recall": 0.7149122807017544
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8231021969491409,
            "auditor_fn_violation": 0.010465572498556246,
            "auditor_fp_violation": 0.015925877690747738,
            "ave_precision_score": 0.823468658159249,
            "fpr": 0.09220636663007684,
            "logloss": 0.5599854722886002,
            "mae": 0.34335199528620153,
            "precision": 0.8023529411764706,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8115333812648999,
            "auditor_fn_violation": 0.013340643274853806,
            "auditor_fp_violation": 0.01583419898430286,
            "ave_precision_score": 0.8118598138058084,
            "fpr": 0.1524122807017544,
            "logloss": 0.7709950726618647,
            "mae": 0.27750550660982176,
            "precision": 0.7203219315895373,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8295294663712255,
            "auditor_fn_violation": 0.0055744382579715115,
            "auditor_fp_violation": 0.019971135675613903,
            "ave_precision_score": 0.8302987371478567,
            "fpr": 0.12843029637760703,
            "logloss": 0.7793459884676958,
            "mae": 0.2808686737093565,
            "precision": 0.7631578947368421,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7874429502242982,
            "auditor_fn_violation": 0.011570867959372115,
            "auditor_fp_violation": 0.014802631578947371,
            "ave_precision_score": 0.7878902067532028,
            "fpr": 0.14583333333333334,
            "logloss": 0.8737896680106306,
            "mae": 0.28186417699552196,
            "precision": 0.7252066115702479,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8187274052242572,
            "auditor_fn_violation": 0.00479194494773827,
            "auditor_fp_violation": 0.01982495355395317,
            "ave_precision_score": 0.8191815474225436,
            "fpr": 0.12403951701427003,
            "logloss": 0.879037080286325,
            "mae": 0.28362155355420127,
            "precision": 0.7660455486542443,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8062908041553507,
            "auditor_fn_violation": 0.01781317328408741,
            "auditor_fp_violation": 0.0305767159125885,
            "ave_precision_score": 0.8066529971481475,
            "fpr": 0.14692982456140352,
            "logloss": 0.9110630294466515,
            "mae": 0.27805892049181125,
            "precision": 0.7242798353909465,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8249712702340013,
            "auditor_fn_violation": 0.015387565630248769,
            "auditor_fp_violation": 0.026424411882745996,
            "ave_precision_score": 0.8257283442333241,
            "fpr": 0.1207464324917673,
            "logloss": 0.8729536827144239,
            "mae": 0.28215193756050644,
            "precision": 0.7674418604651163,
            "recall": 0.7289156626506024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8038809444278499,
            "auditor_fn_violation": 0.012176823638042473,
            "auditor_fp_violation": 0.018587449984610656,
            "ave_precision_score": 0.8042357648749741,
            "fpr": 0.15570175438596492,
            "logloss": 0.8212915254711814,
            "mae": 0.2809974743113839,
            "precision": 0.7171314741035857,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8282094692501722,
            "auditor_fn_violation": 0.0070953407482840306,
            "auditor_fp_violation": 0.021013015524541327,
            "ave_precision_score": 0.8287203225094633,
            "fpr": 0.12952799121844127,
            "logloss": 0.8141070648703717,
            "mae": 0.28263869798203806,
            "precision": 0.757700205338809,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 19863,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8196553586829368,
            "auditor_fn_violation": 0.01835180055401662,
            "auditor_fp_violation": 0.02818174823022469,
            "ave_precision_score": 0.8199919983097791,
            "fpr": 0.15350877192982457,
            "logloss": 0.7710709670229097,
            "mae": 0.2712158837871417,
            "precision": 0.7244094488188977,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8347536719337836,
            "auditor_fn_violation": 0.013780699086135986,
            "auditor_fp_violation": 0.029823810675547454,
            "ave_precision_score": 0.8352043474217687,
            "fpr": 0.1251372118551043,
            "logloss": 0.7636489428046654,
            "mae": 0.2714478393020815,
            "precision": 0.7729083665338645,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8358178507379417,
            "auditor_fn_violation": 0.013561865189289018,
            "auditor_fp_violation": 0.024651815943367197,
            "ave_precision_score": 0.8360695542620388,
            "fpr": 0.15679824561403508,
            "logloss": 0.6310442235160231,
            "mae": 0.276749749707346,
            "precision": 0.7157057654075547,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8417248150619407,
            "auditor_fn_violation": 0.005190906325631837,
            "auditor_fp_violation": 0.022020343235621666,
            "ave_precision_score": 0.8421793411188269,
            "fpr": 0.1251372118551043,
            "logloss": 0.6520827741785442,
            "mae": 0.27990309867521695,
            "precision": 0.7696969696969697,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.823476213825876,
            "auditor_fn_violation": 0.014966143428747308,
            "auditor_fp_violation": 0.0247624269005848,
            "ave_precision_score": 0.8238907871453094,
            "fpr": 0.13048245614035087,
            "logloss": 0.5580847277448018,
            "mae": 0.3310362532498281,
            "precision": 0.741304347826087,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8327461980644242,
            "auditor_fn_violation": 0.028498185938044165,
            "auditor_fp_violation": 0.02472338355796653,
            "ave_precision_score": 0.8330667193251998,
            "fpr": 0.12403951701427003,
            "logloss": 0.5487513049185443,
            "mae": 0.3392858061138156,
            "precision": 0.7665289256198347,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8146740697272228,
            "auditor_fn_violation": 0.013518582640812559,
            "auditor_fp_violation": 0.014081255771006478,
            "ave_precision_score": 0.8149833855732654,
            "fpr": 0.16447368421052633,
            "logloss": 0.8108539925448492,
            "mae": 0.276549888616474,
            "precision": 0.7093023255813954,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8340286710569933,
            "auditor_fn_violation": 0.007855791993440284,
            "auditor_fp_violation": 0.022440284603301594,
            "ave_precision_score": 0.834453040510791,
            "fpr": 0.13172338090010977,
            "logloss": 0.7750724438033351,
            "mae": 0.2777027643064714,
            "precision": 0.7590361445783133,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.811530476132823,
            "auditor_fn_violation": 0.013340643274853806,
            "auditor_fp_violation": 0.01583419898430286,
            "ave_precision_score": 0.811856908873006,
            "fpr": 0.1524122807017544,
            "logloss": 0.770962236392389,
            "mae": 0.2775042073376301,
            "precision": 0.7203219315895373,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8295307137976129,
            "auditor_fn_violation": 0.0055744382579715115,
            "auditor_fp_violation": 0.019971135675613903,
            "ave_precision_score": 0.8302999844351324,
            "fpr": 0.12843029637760703,
            "logloss": 0.7793491127323388,
            "mae": 0.2808662623348648,
            "precision": 0.7631578947368421,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8096743199379314,
            "auditor_fn_violation": 0.014016331948291782,
            "auditor_fp_violation": 0.016216528162511547,
            "ave_precision_score": 0.8100036498973349,
            "fpr": 0.15679824561403508,
            "logloss": 0.782719189119618,
            "mae": 0.27911961915937156,
            "precision": 0.7128514056224899,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8326498427826562,
            "auditor_fn_violation": 0.009024021442520912,
            "auditor_fp_violation": 0.023779844409065425,
            "ave_precision_score": 0.8329167218096356,
            "fpr": 0.12623490669593854,
            "logloss": 0.7797207394624905,
            "mae": 0.27895864632327977,
            "precision": 0.7648261758691206,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8508035089264341,
            "auditor_fn_violation": 0.017947830101569716,
            "auditor_fp_violation": 0.024764831486611263,
            "ave_precision_score": 0.8510117061528075,
            "fpr": 0.15021929824561403,
            "logloss": 0.5265856223724463,
            "mae": 0.29378997413298574,
            "precision": 0.7175257731958763,
            "recall": 0.7631578947368421
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8455237278212535,
            "auditor_fn_violation": 0.012722679962440326,
            "auditor_fp_violation": 0.025185850633765945,
            "ave_precision_score": 0.8457801197031216,
            "fpr": 0.12623490669593854,
            "logloss": 0.5476719427796184,
            "mae": 0.2989816152229092,
            "precision": 0.7653061224489796,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8021968199107996,
            "auditor_fn_violation": 0.013309383656509697,
            "auditor_fp_violation": 0.020376461988304097,
            "ave_precision_score": 0.8020232691489515,
            "fpr": 0.1425438596491228,
            "logloss": 0.7314225975045706,
            "mae": 0.2810123337463708,
            "precision": 0.7341513292433538,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.7839002419839692,
            "auditor_fn_violation": 0.014483840962092065,
            "auditor_fp_violation": 0.02429546862001419,
            "ave_precision_score": 0.7853900746792093,
            "fpr": 0.11086717892425905,
            "logloss": 0.8815573159380873,
            "mae": 0.29381981042988264,
            "precision": 0.7913223140495868,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8145643184729674,
            "auditor_fn_violation": 0.013174726839027399,
            "auditor_fp_violation": 0.012984764542936287,
            "ave_precision_score": 0.8148617186020937,
            "fpr": 0.16447368421052633,
            "logloss": 0.8486850772174059,
            "mae": 0.27641342771950445,
            "precision": 0.7098646034816247,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8351949517529352,
            "auditor_fn_violation": 0.00665009103372877,
            "auditor_fp_violation": 0.021042251948873474,
            "ave_precision_score": 0.8355421099336671,
            "fpr": 0.132821075740944,
            "logloss": 0.806733235728883,
            "mae": 0.2783572645790831,
            "precision": 0.758,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7981274103380643,
            "auditor_fn_violation": 0.013850415512465379,
            "auditor_fp_violation": 0.0171879809172053,
            "ave_precision_score": 0.7984758161135111,
            "fpr": 0.16228070175438597,
            "logloss": 0.7698305811952061,
            "mae": 0.2927790612047374,
            "precision": 0.704,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8197303635306772,
            "auditor_fn_violation": 0.00540251015037097,
            "auditor_fp_violation": 0.026881563245030476,
            "ave_precision_score": 0.821014067219582,
            "fpr": 0.13391877058177826,
            "logloss": 0.7492387922419612,
            "mae": 0.2858639575113698,
            "precision": 0.7545271629778671,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 19863,
        "test": {
            "accuracy": 0.3432017543859649,
            "auc_prc": 0.3974126359141367,
            "auditor_fn_violation": 0.012465373961218832,
            "auditor_fp_violation": 0.02026825561711296,
            "ave_precision_score": 0.37098439228385016,
            "fpr": 0.3168859649122807,
            "logloss": 12.489099175663972,
            "mae": 0.6587483796646613,
            "precision": 0.335632183908046,
            "recall": 0.3201754385964912
        },
        "train": {
            "accuracy": 0.3468715697036224,
            "auc_prc": 0.44264145915326814,
            "auditor_fn_violation": 0.006846265412914026,
            "auditor_fp_violation": 0.022658228857413965,
            "ave_precision_score": 0.4130443713093951,
            "fpr": 0.2897914379802415,
            "logloss": 12.759568891371078,
            "mae": 0.6573173269515735,
            "precision": 0.3874709976798144,
            "recall": 0.3353413654618474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8603540169068187,
            "auditor_fn_violation": 0.017502981686672824,
            "auditor_fp_violation": 0.05504578331794399,
            "ave_precision_score": 0.8611072994668313,
            "fpr": 0.24451754385964913,
            "logloss": 0.6306768361998274,
            "mae": 0.3140968225199542,
            "precision": 0.6504702194357367,
            "recall": 0.9100877192982456
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.859546085375188,
            "auditor_fn_violation": 0.024294764127861614,
            "auditor_fp_violation": 0.042400788851885626,
            "ave_precision_score": 0.8597440084940052,
            "fpr": 0.21295279912184412,
            "logloss": 0.615055196924256,
            "mae": 0.3106673607498823,
            "precision": 0.694006309148265,
            "recall": 0.8835341365461847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8399190091339387,
            "auditor_fn_violation": 0.003828100954139744,
            "auditor_fp_violation": 0.004135887965527855,
            "ave_precision_score": 0.8401453729148073,
            "fpr": 0.08442982456140351,
            "logloss": 0.549422264799151,
            "mae": 0.3240488946010906,
            "precision": 0.8060453400503779,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.848482222345931,
            "auditor_fn_violation": 0.009550826797861043,
            "auditor_fp_violation": 0.01107263125161133,
            "ave_precision_score": 0.84875270989591,
            "fpr": 0.07903402854006586,
            "logloss": 0.5351778909454188,
            "mae": 0.33430088850755496,
            "precision": 0.8230958230958231,
            "recall": 0.6726907630522089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.8014936152907092,
            "auditor_fn_violation": 0.0039026431209602955,
            "auditor_fp_violation": 0.019751269621421996,
            "ave_precision_score": 0.8013071999290734,
            "fpr": 0.4144736842105263,
            "logloss": 2.610875953579755,
            "mae": 0.4169101924025912,
            "precision": 0.5418181818181819,
            "recall": 0.9802631578947368
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.8286341730239497,
            "auditor_fn_violation": 0.003237979359810262,
            "auditor_fp_violation": 0.01891330868614168,
            "ave_precision_score": 0.8276461954475176,
            "fpr": 0.37102085620197583,
            "logloss": 2.3204368642316586,
            "mae": 0.3731818578134263,
            "precision": 0.5922798552472859,
            "recall": 0.9859437751004017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7867741982546146,
            "auditor_fn_violation": 0.01729378270236996,
            "auditor_fp_violation": 0.022413146352723918,
            "ave_precision_score": 0.787208776412785,
            "fpr": 0.16337719298245615,
            "logloss": 0.8984474569580215,
            "mae": 0.28221186609913673,
            "precision": 0.7084148727984344,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8172970484120472,
            "auditor_fn_violation": 0.006445099828512739,
            "auditor_fp_violation": 0.024199785776745353,
            "ave_precision_score": 0.8178940183406367,
            "fpr": 0.13611416026344675,
            "logloss": 0.8890682831161205,
            "mae": 0.2818283143987596,
            "precision": 0.753968253968254,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8038380053854303,
            "auditor_fn_violation": 0.014946906740535554,
            "auditor_fp_violation": 0.019347299168975072,
            "ave_precision_score": 0.8041703545749503,
            "fpr": 0.15460526315789475,
            "logloss": 0.8824480701681983,
            "mae": 0.27972814870271295,
            "precision": 0.7151515151515152,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8286235467143386,
            "auditor_fn_violation": 0.0077896657982093045,
            "auditor_fp_violation": 0.023599110149557602,
            "ave_precision_score": 0.829088156654881,
            "fpr": 0.11855104281009879,
            "logloss": 0.8762180917547993,
            "mae": 0.2792602918050291,
            "precision": 0.7721518987341772,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7462620636802557,
            "auditor_fn_violation": 0.01891447368421053,
            "auditor_fp_violation": 0.02606571252693137,
            "ave_precision_score": 0.7306577173527539,
            "fpr": 0.19298245614035087,
            "logloss": 2.7797249048812565,
            "mae": 0.3304273861139719,
            "precision": 0.6500994035785288,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7922393451783001,
            "auditor_fn_violation": 0.01319217594858027,
            "auditor_fp_violation": 0.028359331602182635,
            "ave_precision_score": 0.7799980422561281,
            "fpr": 0.15148188803512624,
            "logloss": 2.6770218412455877,
            "mae": 0.3258610688956602,
            "precision": 0.7142857142857143,
            "recall": 0.6927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8036751883094646,
            "auditor_fn_violation": 0.016399276700523237,
            "auditor_fp_violation": 0.021545090797168362,
            "ave_precision_score": 0.8040182184594145,
            "fpr": 0.16228070175438597,
            "logloss": 0.9116826084475136,
            "mae": 0.27890525146037337,
            "precision": 0.7098039215686275,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8250743039480302,
            "auditor_fn_violation": 0.005675831757325686,
            "auditor_fp_violation": 0.024428361457887595,
            "ave_precision_score": 0.8256794126614417,
            "fpr": 0.13062568605927552,
            "logloss": 0.8981105700009301,
            "mae": 0.28142617135094616,
            "precision": 0.7571428571428571,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8253439499714297,
            "auditor_fn_violation": 0.013432017543859651,
            "auditor_fp_violation": 0.01748614958448754,
            "ave_precision_score": 0.8255802993424495,
            "fpr": 0.15899122807017543,
            "logloss": 0.9110016884814717,
            "mae": 0.27938440614492527,
            "precision": 0.7145669291338582,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8339123483320756,
            "auditor_fn_violation": 0.005254828314355117,
            "auditor_fp_violation": 0.021483456170613147,
            "ave_precision_score": 0.834630626349091,
            "fpr": 0.12952799121844127,
            "logloss": 0.9357270205333678,
            "mae": 0.28107412227155315,
            "precision": 0.7596741344195519,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7934505178959581,
            "auditor_fn_violation": 0.005597876269621426,
            "auditor_fp_violation": 0.011426592797783937,
            "ave_precision_score": 0.7939648408642532,
            "fpr": 0.14473684210526316,
            "logloss": 0.6064386200691081,
            "mae": 0.3306212119634055,
            "precision": 0.7161290322580646,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7867664628945626,
            "auditor_fn_violation": 0.008133522013410398,
            "auditor_fp_violation": 0.02636328117732423,
            "ave_precision_score": 0.7878682844291329,
            "fpr": 0.12733260153677278,
            "logloss": 0.6181636057470162,
            "mae": 0.34118706791036285,
            "precision": 0.7531914893617021,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8111993426471837,
            "auditor_fn_violation": 0.006766505078485688,
            "auditor_fp_violation": 0.014312096029547557,
            "ave_precision_score": 0.8115072567997315,
            "fpr": 0.10087719298245613,
            "logloss": 0.5627460110368119,
            "mae": 0.34015878426904683,
            "precision": 0.7814726840855107,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8377199858605957,
            "auditor_fn_violation": 0.006004258526972877,
            "auditor_fp_violation": 0.012967683119685946,
            "ave_precision_score": 0.8379905863879994,
            "fpr": 0.09989023051591657,
            "logloss": 0.5497485589757639,
            "mae": 0.3390352869197792,
            "precision": 0.7945823927765236,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8018345519378618,
            "auditor_fn_violation": 0.01875096183441059,
            "auditor_fp_violation": 0.02266081871345029,
            "ave_precision_score": 0.8021337156044367,
            "fpr": 0.16666666666666666,
            "logloss": 0.8659063628049503,
            "mae": 0.28456332500486803,
            "precision": 0.7042801556420234,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8226841365826609,
            "auditor_fn_violation": 0.00977345165513867,
            "auditor_fp_violation": 0.02055852201901431,
            "ave_precision_score": 0.8231904812016331,
            "fpr": 0.13830954994511527,
            "logloss": 0.8582822204986248,
            "mae": 0.2889916766873252,
            "precision": 0.749003984063745,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8423058885256198,
            "auditor_fn_violation": 0.004010849492151432,
            "auditor_fp_violation": 0.01742843951985226,
            "ave_precision_score": 0.8425853712044895,
            "fpr": 0.10964912280701754,
            "logloss": 0.5493851450530552,
            "mae": 0.3206604189192723,
            "precision": 0.7807017543859649,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8436080418655403,
            "auditor_fn_violation": 0.008986549931890018,
            "auditor_fp_violation": 0.02619583620160375,
            "ave_precision_score": 0.8439242444023636,
            "fpr": 0.11525795828759605,
            "logloss": 0.555109719224819,
            "mae": 0.3261166126473677,
            "precision": 0.78125,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8025306805646379,
            "auditor_fn_violation": 0.009106167282240693,
            "auditor_fp_violation": 0.016971568174823023,
            "ave_precision_score": 0.8015174918820434,
            "fpr": 0.14364035087719298,
            "logloss": 0.7814183339924362,
            "mae": 0.27442030138184825,
            "precision": 0.7369477911646586,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.786766792401435,
            "auditor_fn_violation": 0.008913811117135944,
            "auditor_fp_violation": 0.022092105368073295,
            "ave_precision_score": 0.7857259122846602,
            "fpr": 0.11306256860592755,
            "logloss": 0.9271067022374875,
            "mae": 0.2892071849875395,
            "precision": 0.7885010266940452,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8026786158583107,
            "auditor_fn_violation": 0.020525546321945216,
            "auditor_fp_violation": 0.023632271468144048,
            "ave_precision_score": 0.8030397324842911,
            "fpr": 0.15460526315789475,
            "logloss": 0.8466869954858626,
            "mae": 0.28323207808496925,
            "precision": 0.709278350515464,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8246022495401643,
            "auditor_fn_violation": 0.012550751854839786,
            "auditor_fp_violation": 0.027601842426304278,
            "ave_precision_score": 0.8259805023586286,
            "fpr": 0.11964873765093303,
            "logloss": 0.8248373469608432,
            "mae": 0.2811002717229383,
            "precision": 0.7705263157894737,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7777772871921995,
            "auditor_fn_violation": 0.011503539550630966,
            "auditor_fp_violation": 0.014485226223453381,
            "ave_precision_score": 0.7781410989839319,
            "fpr": 0.15570175438596492,
            "logloss": 0.870291901328201,
            "mae": 0.3055361170548475,
            "precision": 0.7072164948453609,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8087649433452473,
            "auditor_fn_violation": 0.00939432813581439,
            "auditor_fp_violation": 0.020880122686667932,
            "ave_precision_score": 0.8100921552695046,
            "fpr": 0.11964873765093303,
            "logloss": 0.7965353736098935,
            "mae": 0.2945740747317603,
            "precision": 0.7655913978494624,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.810788864124778,
            "auditor_fn_violation": 0.007454216682056022,
            "auditor_fp_violation": 0.008870517851646664,
            "ave_precision_score": 0.811111548217186,
            "fpr": 0.16557017543859648,
            "logloss": 0.7345895188450665,
            "mae": 0.2871148546252336,
            "precision": 0.7067961165048544,
            "recall": 0.7982456140350878
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8306802845824747,
            "auditor_fn_violation": 0.008702207292396808,
            "auditor_fp_violation": 0.026233046196208306,
            "ave_precision_score": 0.8311870333026427,
            "fpr": 0.13830954994511527,
            "logloss": 0.6970472412080495,
            "mae": 0.27881615722002473,
            "precision": 0.7558139534883721,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8216806108718592,
            "auditor_fn_violation": 0.01707256078793475,
            "auditor_fp_violation": 0.024218990458602648,
            "ave_precision_score": 0.8220069792589686,
            "fpr": 0.15021929824561403,
            "logloss": 0.7523500978426576,
            "mae": 0.2701542999493281,
            "precision": 0.7221095334685599,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.836845529069185,
            "auditor_fn_violation": 0.013478722794581186,
            "auditor_fp_violation": 0.023702766563098852,
            "ave_precision_score": 0.8373481290432905,
            "fpr": 0.11745334796926454,
            "logloss": 0.752964903368312,
            "mae": 0.2693363425400207,
            "precision": 0.7816326530612245,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7841100910182717,
            "auditor_fn_violation": 0.01176083025546322,
            "auditor_fp_violation": 0.017394775315481698,
            "ave_precision_score": 0.7845530071739604,
            "fpr": 0.16557017543859648,
            "logloss": 0.8842223761482968,
            "mae": 0.2888837382296482,
            "precision": 0.7003968253968254,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8206475963180595,
            "auditor_fn_violation": 0.009332610353598818,
            "auditor_fp_violation": 0.016824233274771887,
            "ave_precision_score": 0.8210384467275966,
            "fpr": 0.13172338090010977,
            "logloss": 0.8326832010890948,
            "mae": 0.28568399879380235,
            "precision": 0.757085020242915,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7687125792856361,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5487451868044326,
            "fpr": 0.4956140350877193,
            "logloss": 15.256630481808418,
            "mae": 0.49670733158525665,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7949160587623382,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5964978538616073,
            "fpr": 0.4445664105378705,
            "logloss": 13.769465307520372,
            "mae": 0.44456629446911106,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8047787128743377,
            "auditor_fn_violation": 0.011960410895660205,
            "auditor_fp_violation": 0.017240881809787632,
            "ave_precision_score": 0.8037570996678172,
            "fpr": 0.1425438596491228,
            "logloss": 0.7684537249966186,
            "mae": 0.275400527088192,
            "precision": 0.7363083164300203,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.787593055241455,
            "auditor_fn_violation": 0.012881382830994671,
            "auditor_fp_violation": 0.02375592369824821,
            "ave_precision_score": 0.7865515746524755,
            "fpr": 0.1163556531284303,
            "logloss": 0.9071661712357564,
            "mae": 0.28923527873534965,
            "precision": 0.7849898580121704,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 19863,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7912796802318788,
            "auditor_fn_violation": 0.019438673437980926,
            "auditor_fp_violation": 0.0040204678362573115,
            "ave_precision_score": 0.7916837907134949,
            "fpr": 0.041666666666666664,
            "logloss": 0.7681590357273119,
            "mae": 0.37840144832954503,
            "precision": 0.849802371541502,
            "recall": 0.47149122807017546
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.8089899013321724,
            "auditor_fn_violation": 0.01396585243278272,
            "auditor_fp_violation": 0.012574320319580697,
            "ave_precision_score": 0.8093638293924708,
            "fpr": 0.04061470911086718,
            "logloss": 0.7705236403859973,
            "mae": 0.4031240187542417,
            "precision": 0.8598484848484849,
            "recall": 0.45582329317269077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7954434528450217,
            "auditor_fn_violation": 0.007675438596491231,
            "auditor_fp_violation": 0.015564885349338265,
            "ave_precision_score": 0.795863317104039,
            "fpr": 0.16557017543859648,
            "logloss": 0.7727778245948408,
            "mae": 0.2885765514360102,
            "precision": 0.7021696252465484,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.822826335505708,
            "auditor_fn_violation": 0.00853909601082706,
            "auditor_fp_violation": 0.02404031437129728,
            "ave_precision_score": 0.8233509021337821,
            "fpr": 0.13721185510428102,
            "logloss": 0.7479738068056557,
            "mae": 0.2857905737812865,
            "precision": 0.7504990019960079,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8288652609711687,
            "auditor_fn_violation": 0.013965835641735919,
            "auditor_fp_violation": 0.015466297322253008,
            "ave_precision_score": 0.8291005497235959,
            "fpr": 0.18201754385964913,
            "logloss": 0.7451397805174921,
            "mae": 0.27940412017972593,
            "precision": 0.6937269372693727,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8374382723653858,
            "auditor_fn_violation": 0.005166660054047146,
            "auditor_fp_violation": 0.024630358571455152,
            "ave_precision_score": 0.8381662672033685,
            "fpr": 0.1437980241492865,
            "logloss": 0.7308204766575642,
            "mae": 0.27747543549319464,
            "precision": 0.7495219885277247,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8338926386618388,
            "auditor_fn_violation": 0.014802631578947375,
            "auditor_fp_violation": 0.02536357340720222,
            "ave_precision_score": 0.8341524878471801,
            "fpr": 0.15460526315789475,
            "logloss": 0.6470027346073857,
            "mae": 0.2771465158247769,
            "precision": 0.7191235059760956,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8422601762276154,
            "auditor_fn_violation": 0.006378973633281759,
            "auditor_fp_violation": 0.01941032789978817,
            "ave_precision_score": 0.8427186703687926,
            "fpr": 0.12403951701427003,
            "logloss": 0.6580115314154067,
            "mae": 0.2786172134113445,
            "precision": 0.7717171717171717,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8066763254331601,
            "auditor_fn_violation": 0.015841412742382273,
            "auditor_fp_violation": 0.01852012157586951,
            "ave_precision_score": 0.8070312110453207,
            "fpr": 0.16557017543859648,
            "logloss": 0.7946244521289193,
            "mae": 0.2795334963732577,
            "precision": 0.7079303675048356,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8265930688954117,
            "auditor_fn_violation": 0.005779429463187547,
            "auditor_fp_violation": 0.024385835749768103,
            "ave_precision_score": 0.8275001269201164,
            "fpr": 0.13721185510428102,
            "logloss": 0.7955073415704456,
            "mae": 0.28257071342024,
            "precision": 0.7524752475247525,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8102107713050262,
            "auditor_fn_violation": 0.013432017543859651,
            "auditor_fp_violation": 0.020698676515851035,
            "ave_precision_score": 0.8105494047533416,
            "fpr": 0.15350877192982457,
            "logloss": 0.8149043410414125,
            "mae": 0.2759029825501639,
            "precision": 0.7216699801192843,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8330802861848701,
            "auditor_fn_violation": 0.007247430997315276,
            "auditor_fp_violation": 0.022009711808591792,
            "ave_precision_score": 0.8334307100624792,
            "fpr": 0.12403951701427003,
            "logloss": 0.8165615127159936,
            "mae": 0.2786664244556103,
            "precision": 0.7670103092783506,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.841012808354624,
            "auditor_fn_violation": 0.019967682363804248,
            "auditor_fp_violation": 0.0294970567867036,
            "ave_precision_score": 0.8413488111790178,
            "fpr": 0.13486842105263158,
            "logloss": 0.5741779228690256,
            "mae": 0.30956690909347107,
            "precision": 0.739406779661017,
            "recall": 0.7653508771929824
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.837782324895446,
            "auditor_fn_violation": 0.032467961858410596,
            "auditor_fp_violation": 0.02504232636886268,
            "ave_precision_score": 0.8380723454053982,
            "fpr": 0.12294182217343579,
            "logloss": 0.6024018293471881,
            "mae": 0.3133360004091112,
            "precision": 0.7714285714285715,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8772648524614683,
            "auditor_fn_violation": 0.019491574330563255,
            "auditor_fp_violation": 0.02250692520775623,
            "ave_precision_score": 0.877624888474816,
            "fpr": 0.18421052631578946,
            "logloss": 0.5001899095868213,
            "mae": 0.2919456041774155,
            "precision": 0.7057793345008757,
            "recall": 0.8837719298245614
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8701371427855276,
            "auditor_fn_violation": 0.018834944608290462,
            "auditor_fp_violation": 0.03417738004427989,
            "ave_precision_score": 0.8704299749700246,
            "fpr": 0.16136114160263446,
            "logloss": 0.5073580934065206,
            "mae": 0.29305416316664995,
            "precision": 0.746551724137931,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8315265303222572,
            "auditor_fn_violation": 0.007249826869806096,
            "auditor_fp_violation": 0.006261542012927061,
            "ave_precision_score": 0.831836089372575,
            "fpr": 0.12719298245614036,
            "logloss": 0.5843548998460825,
            "mae": 0.33569415758124943,
            "precision": 0.7505376344086021,
            "recall": 0.7653508771929824
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8334363776632223,
            "auditor_fn_violation": 0.0028831021120706854,
            "auditor_fp_violation": 0.02841248873733199,
            "ave_precision_score": 0.8336956345844186,
            "fpr": 0.1350164654226125,
            "logloss": 0.5857753530417358,
            "mae": 0.34262422856933034,
            "precision": 0.7505070993914807,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.829609427285934,
            "auditor_fn_violation": 0.009822733918128653,
            "auditor_fp_violation": 0.01206140350877193,
            "ave_precision_score": 0.8298930650947711,
            "fpr": 0.125,
            "logloss": 0.5540464230070223,
            "mae": 0.33406497023360426,
            "precision": 0.7537796976241901,
            "recall": 0.7653508771929824
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8354812384374763,
            "auditor_fn_violation": 0.01348533541410428,
            "auditor_fp_violation": 0.01765614243985935,
            "ave_precision_score": 0.8358296303372821,
            "fpr": 0.11855104281009879,
            "logloss": 0.5537025073173616,
            "mae": 0.3419187309695295,
            "precision": 0.7702127659574468,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7959569560480712,
            "auditor_fn_violation": 0.01511282317636196,
            "auditor_fp_violation": 0.012304266697445373,
            "ave_precision_score": 0.796300039900526,
            "fpr": 0.15679824561403508,
            "logloss": 0.8318294262865983,
            "mae": 0.2916916485764721,
            "precision": 0.7105263157894737,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8225140819687512,
            "auditor_fn_violation": 0.004456905558567975,
            "auditor_fp_violation": 0.023894132249636543,
            "ave_precision_score": 0.8238033653707726,
            "fpr": 0.132821075740944,
            "logloss": 0.7765819506854158,
            "mae": 0.28164006488002635,
            "precision": 0.7570281124497992,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.801939989704069,
            "auditor_fn_violation": 0.01403797322253001,
            "auditor_fp_violation": 0.01590874115112343,
            "ave_precision_score": 0.8022746062186584,
            "fpr": 0.15570175438596492,
            "logloss": 0.8575343994595377,
            "mae": 0.284050995830158,
            "precision": 0.716,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8230366694382073,
            "auditor_fn_violation": 0.0035884481945344542,
            "auditor_fp_violation": 0.026262282620540447,
            "ave_precision_score": 0.8239166721879038,
            "fpr": 0.1350164654226125,
            "logloss": 0.8359870311227778,
            "mae": 0.2817066478251084,
            "precision": 0.7535070140280561,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7925364310003571,
            "auditor_fn_violation": 0.009926131117266852,
            "auditor_fp_violation": 0.01852493074792244,
            "ave_precision_score": 0.7929905434678367,
            "fpr": 0.15789473684210525,
            "logloss": 0.7813108746531856,
            "mae": 0.28435175525036566,
            "precision": 0.7142857142857143,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8215222718258415,
            "auditor_fn_violation": 0.005728732713510467,
            "auditor_fp_violation": 0.021507376881430354,
            "ave_precision_score": 0.821938586807943,
            "fpr": 0.13830954994511527,
            "logloss": 0.7690841396180854,
            "mae": 0.28436372706111734,
            "precision": 0.7495029821073559,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.839168103206626,
            "auditor_fn_violation": 0.019582948599569102,
            "auditor_fp_violation": 0.02406509695290859,
            "ave_precision_score": 0.8395696415550562,
            "fpr": 0.1118421052631579,
            "logloss": 0.5690636604606678,
            "mae": 0.30851646474209765,
            "precision": 0.7758241758241758,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8441922939530762,
            "auditor_fn_violation": 0.030722230304312755,
            "auditor_fp_violation": 0.02546492559330008,
            "ave_precision_score": 0.8444700321849244,
            "fpr": 0.1163556531284303,
            "logloss": 0.586239618604695,
            "mae": 0.3152722452926162,
            "precision": 0.7782426778242678,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 19863,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8322282417667268,
            "auditor_fn_violation": 0.0031211526623576486,
            "auditor_fp_violation": 0.007870210064635274,
            "ave_precision_score": 0.8324877758149691,
            "fpr": 0.11951754385964912,
            "logloss": 0.5468335702553939,
            "mae": 0.3325943691845424,
            "precision": 0.7556053811659192,
            "recall": 0.7390350877192983
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8350980287979299,
            "auditor_fn_violation": 0.0099828512733701,
            "auditor_fp_violation": 0.012502558187129063,
            "ave_precision_score": 0.835631692241221,
            "fpr": 0.09989023051591657,
            "logloss": 0.5499413474640792,
            "mae": 0.34198823017088653,
            "precision": 0.795045045045045,
            "recall": 0.7088353413654619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8060814736115302,
            "auditor_fn_violation": 0.013734995383194826,
            "auditor_fp_violation": 0.019837834718374886,
            "ave_precision_score": 0.8064264990458039,
            "fpr": 0.15021929824561403,
            "logloss": 0.9566619171948162,
            "mae": 0.28044149759300546,
            "precision": 0.7221095334685599,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8300858942191844,
            "auditor_fn_violation": 0.005290095618478304,
            "auditor_fp_violation": 0.02220107749512948,
            "ave_precision_score": 0.8306230251530282,
            "fpr": 0.1163556531284303,
            "logloss": 0.8175077587139067,
            "mae": 0.2763460391016253,
            "precision": 0.7782426778242678,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.817941028853854,
            "auditor_fn_violation": 0.010960103108648827,
            "auditor_fp_violation": 0.009171091104955375,
            "ave_precision_score": 0.8182506436865746,
            "fpr": 0.09320175438596491,
            "logloss": 0.5630923216138722,
            "mae": 0.33954505814931746,
            "precision": 0.7911547911547911,
            "recall": 0.706140350877193
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8202084199081037,
            "auditor_fn_violation": 0.009716142285938489,
            "auditor_fp_violation": 0.014474687901170258,
            "ave_precision_score": 0.820839666124564,
            "fpr": 0.0889132821075741,
            "logloss": 0.5568086068726664,
            "mae": 0.3405421705461341,
            "precision": 0.8066825775656324,
            "recall": 0.678714859437751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8366448638275895,
            "auditor_fn_violation": 0.01655797937827024,
            "auditor_fp_violation": 0.025702620036934444,
            "ave_precision_score": 0.8369514754285158,
            "fpr": 0.12828947368421054,
            "logloss": 0.5680165886739591,
            "mae": 0.3123149749076937,
            "precision": 0.7478448275862069,
            "recall": 0.7609649122807017
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8337981512843811,
            "auditor_fn_violation": 0.0355626677952204,
            "auditor_fp_violation": 0.029507525721408783,
            "ave_precision_score": 0.8341125240311864,
            "fpr": 0.11964873765093303,
            "logloss": 0.6062578699213605,
            "mae": 0.32144023670595645,
            "precision": 0.7685774946921444,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8146693288749068,
            "auditor_fn_violation": 0.008541089566020319,
            "auditor_fp_violation": 0.017349088180978765,
            "ave_precision_score": 0.8149658801155327,
            "fpr": 0.15460526315789475,
            "logloss": 0.7429330962804812,
            "mae": 0.281511037425034,
            "precision": 0.7168674698795181,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8275200020139197,
            "auditor_fn_violation": 0.001758956793144036,
            "auditor_fp_violation": 0.02480311926069057,
            "ave_precision_score": 0.8288060853694378,
            "fpr": 0.132821075740944,
            "logloss": 0.7355179688777576,
            "mae": 0.2796640764344121,
            "precision": 0.7575150300601202,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8422381720630734,
            "auditor_fn_violation": 0.019909972299168976,
            "auditor_fp_violation": 0.027621479686057247,
            "ave_precision_score": 0.8425779737674088,
            "fpr": 0.13048245614035087,
            "logloss": 0.5670738284569827,
            "mae": 0.31411361139263344,
            "precision": 0.7468085106382979,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8400959924387097,
            "auditor_fn_violation": 0.037213618469487175,
            "auditor_fp_violation": 0.02439646717679798,
            "ave_precision_score": 0.8403829484591849,
            "fpr": 0.1163556531284303,
            "logloss": 0.5864690548230443,
            "mae": 0.3196883055108776,
            "precision": 0.7777777777777778,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.813788826496766,
            "auditor_fn_violation": 0.00856032625423207,
            "auditor_fp_violation": 0.020669821483533395,
            "ave_precision_score": 0.8141121953613673,
            "fpr": 0.16228070175438597,
            "logloss": 0.7864723578075425,
            "mae": 0.2753390130360728,
            "precision": 0.7142857142857143,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8348541653089223,
            "auditor_fn_violation": 0.0018912091836059957,
            "auditor_fp_violation": 0.022381811754637302,
            "ave_precision_score": 0.8351191391576076,
            "fpr": 0.13062568605927552,
            "logloss": 0.7789995945379433,
            "mae": 0.2768245691614724,
            "precision": 0.762,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8142037743354169,
            "auditor_fn_violation": 0.015624999999999997,
            "auditor_fp_violation": 0.016899430594028934,
            "ave_precision_score": 0.8145118830644044,
            "fpr": 0.16228070175438597,
            "logloss": 0.8059494383793778,
            "mae": 0.2776034713559889,
            "precision": 0.7075098814229249,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8352079021526388,
            "auditor_fn_violation": 0.007093136541776333,
            "auditor_fp_violation": 0.02226752391406618,
            "ave_precision_score": 0.8355986923053484,
            "fpr": 0.12952799121844127,
            "logloss": 0.7664807822512867,
            "mae": 0.27685905735557687,
            "precision": 0.7616161616161616,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8125586181433934,
            "auditor_fn_violation": 0.008454524469067408,
            "auditor_fp_violation": 0.010676361957525391,
            "ave_precision_score": 0.8128665859424131,
            "fpr": 0.15789473684210525,
            "logloss": 0.7159770875981805,
            "mae": 0.2842263517836373,
            "precision": 0.7137176938369781,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.832165550270273,
            "auditor_fn_violation": 0.008155564078487382,
            "auditor_fp_violation": 0.026177231204301477,
            "ave_precision_score": 0.8325223925394685,
            "fpr": 0.13062568605927552,
            "logloss": 0.7222471882391295,
            "mae": 0.2797476737582022,
            "precision": 0.7610441767068273,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8415761628707739,
            "auditor_fn_violation": 0.01781317328408741,
            "auditor_fp_violation": 0.025079832256078797,
            "ave_precision_score": 0.8419193215218139,
            "fpr": 0.12609649122807018,
            "logloss": 0.5637723204828594,
            "mae": 0.31416359276032346,
            "precision": 0.7537473233404711,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8411589996579998,
            "auditor_fn_violation": 0.037213618469487175,
            "auditor_fp_violation": 0.024027025087509937,
            "ave_precision_score": 0.8414520378354474,
            "fpr": 0.1163556531284303,
            "logloss": 0.5817578389976171,
            "mae": 0.3208860772163234,
            "precision": 0.7777777777777778,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7777914791883944,
            "auditor_fn_violation": 0.021237303785780242,
            "auditor_fp_violation": 0.02017928593413359,
            "ave_precision_score": 0.7782557704506345,
            "fpr": 0.14912280701754385,
            "logloss": 1.1648217305679784,
            "mae": 0.2892928824960746,
            "precision": 0.711864406779661,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8135499265196113,
            "auditor_fn_violation": 0.004655284144260908,
            "auditor_fp_violation": 0.018977097248320904,
            "ave_precision_score": 0.814059416011699,
            "fpr": 0.12294182217343579,
            "logloss": 1.1529721936981232,
            "mae": 0.2864036902627537,
            "precision": 0.7611940298507462,
            "recall": 0.7168674698795181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 19863,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8470905299548457,
            "auditor_fn_violation": 0.012099876885195449,
            "auditor_fp_violation": 0.010892774699907667,
            "ave_precision_score": 0.8472959749437063,
            "fpr": 0.10855263157894737,
            "logloss": 0.5409864990470731,
            "mae": 0.32085531861383443,
            "precision": 0.7765237020316027,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8460839181709103,
            "auditor_fn_violation": 0.015354502532633277,
            "auditor_fp_violation": 0.017512618174956078,
            "ave_precision_score": 0.8463652738736733,
            "fpr": 0.09879253567508232,
            "logloss": 0.5473312242061588,
            "mae": 0.3347384345957459,
            "precision": 0.8013245033112583,
            "recall": 0.7289156626506024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8114528224460233,
            "auditor_fn_violation": 0.011087546168051708,
            "auditor_fp_violation": 0.017695348568790403,
            "ave_precision_score": 0.8117860145734804,
            "fpr": 0.1611842105263158,
            "logloss": 0.8102135460603804,
            "mae": 0.2758477072503515,
            "precision": 0.7140077821011673,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8337220369580806,
            "auditor_fn_violation": 0.004523031753798952,
            "auditor_fp_violation": 0.020303367770297395,
            "ave_precision_score": 0.8341545769497376,
            "fpr": 0.13172338090010977,
            "logloss": 0.7816643219172296,
            "mae": 0.2738365030987555,
            "precision": 0.7619047619047619,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8418627213018441,
            "auditor_fn_violation": 0.014449157433056326,
            "auditor_fp_violation": 0.017269736842105265,
            "ave_precision_score": 0.8420917267641577,
            "fpr": 0.1425438596491228,
            "logloss": 0.7207644354760172,
            "mae": 0.2760312014700164,
            "precision": 0.7308488612836439,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8399317385853008,
            "auditor_fn_violation": 0.004240893320813439,
            "auditor_fp_violation": 0.01689333755046606,
            "ave_precision_score": 0.841159040977217,
            "fpr": 0.11306256860592755,
            "logloss": 0.7556239006303208,
            "mae": 0.2802346438300769,
            "precision": 0.7808510638297872,
            "recall": 0.7369477911646586
        }
    }
]