[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6174989082240421,
            "auditor_fn_violation": 0.023566447832053708,
            "auditor_fp_violation": 0.036943511968988534,
            "ave_precision_score": 0.6196151458336097,
            "fpr": 0.15679824561403508,
            "logloss": 0.6585610280365618,
            "mae": 0.4621228266899523,
            "precision": 0.679372197309417,
            "recall": 0.6405919661733616
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6796753123677255,
            "auditor_fn_violation": 0.03497789776604267,
            "auditor_fp_violation": 0.02340898067546525,
            "ave_precision_score": 0.6808537506402487,
            "fpr": 0.13611416026344675,
            "logloss": 0.6294800568464515,
            "mae": 0.45016343029610545,
            "precision": 0.7232142857142857,
            "recall": 0.6735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5622806086101604,
            "auditor_fn_violation": 0.01008169207373614,
            "auditor_fp_violation": 0.02511439475682373,
            "ave_precision_score": 0.5504285715705826,
            "fpr": 0.17105263157894737,
            "logloss": 0.6921000791214297,
            "mae": 0.4994086545091449,
            "precision": 0.5411764705882353,
            "recall": 0.3890063424947146
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5480380078342465,
            "auditor_fn_violation": 0.006221031468012807,
            "auditor_fp_violation": 0.011216909606106247,
            "ave_precision_score": 0.540252399260233,
            "fpr": 0.1877058177826564,
            "logloss": 0.6928823255007214,
            "mae": 0.4998043686903923,
            "precision": 0.5236768802228412,
            "recall": 0.3908523908523909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 12669,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.56296208452736,
            "auditor_fn_violation": 0.0874388004895961,
            "auditor_fp_violation": 0.10597999840147065,
            "ave_precision_score": 0.5638321742486462,
            "fpr": 0.2949561403508772,
            "logloss": 0.6828427287779864,
            "mae": 0.49132903465968475,
            "precision": 0.5647249190938511,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5595237288927972,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09995404998340694,
            "ave_precision_score": 0.560501991823052,
            "fpr": 0.2996706915477497,
            "logloss": 0.6843763246010989,
            "mae": 0.49229419022046117,
            "precision": 0.5673534072900158,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6803902931646882,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6810882978109716,
            "fpr": 0.47368421052631576,
            "logloss": 2.766489082566738,
            "mae": 0.4745280349415064,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6411058706792784,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.64178786563039,
            "fpr": 0.4665203073545554,
            "logloss": 2.7305223134473615,
            "mae": 0.46637296304492376,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5475958660344372,
            "auditor_fn_violation": 0.09939588665108862,
            "auditor_fp_violation": 0.09871917835591258,
            "ave_precision_score": 0.5496842920551027,
            "fpr": 0.22807017543859648,
            "logloss": 0.6887423059230761,
            "mae": 0.4890341677033065,
            "precision": 0.5929549902152642,
            "recall": 0.6405919661733616
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5765778704391864,
            "auditor_fn_violation": 0.09977156080339396,
            "auditor_fp_violation": 0.09231103055676104,
            "ave_precision_score": 0.5775660053162639,
            "fpr": 0.24478594950603733,
            "logloss": 0.6820684760746529,
            "mae": 0.4877047318920215,
            "precision": 0.5823970037453183,
            "recall": 0.6465696465696466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7234764639075277,
            "auditor_fn_violation": 0.020207429249656916,
            "auditor_fp_violation": 0.030177236942013363,
            "ave_precision_score": 0.7248418552040163,
            "fpr": 0.2905701754385965,
            "logloss": 0.8188564637500061,
            "mae": 0.4676296331854428,
            "precision": 0.6074074074074074,
            "recall": 0.8668076109936576
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7385081916404148,
            "auditor_fn_violation": 0.0030625914270261145,
            "auditor_fp_violation": 0.028305210221325927,
            "ave_precision_score": 0.7398377444570327,
            "fpr": 0.29747530186608123,
            "logloss": 0.7735936967821235,
            "mae": 0.4663190438852633,
            "precision": 0.6117478510028653,
            "recall": 0.8877338877338877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8111088815256777,
            "auditor_fn_violation": 0.011831905344757242,
            "auditor_fp_violation": 0.0443392079287056,
            "ave_precision_score": 0.8112738011742079,
            "fpr": 0.20723684210526316,
            "logloss": 0.6348462911263745,
            "mae": 0.3368926959598049,
            "precision": 0.6828859060402684,
            "recall": 0.8604651162790697
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8633722845227134,
            "auditor_fn_violation": 0.020527578156557303,
            "auditor_fp_violation": 0.02761851275112961,
            "ave_precision_score": 0.863367211941939,
            "fpr": 0.1877058177826564,
            "logloss": 0.5788636904559145,
            "mae": 0.31851870989589953,
            "precision": 0.7135678391959799,
            "recall": 0.8856548856548857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.5525869374303565,
            "auditor_fn_violation": 0.12658794184191982,
            "auditor_fp_violation": 0.11427486712224753,
            "ave_precision_score": 0.5538784969514838,
            "fpr": 0.18859649122807018,
            "logloss": 0.7202765761865283,
            "mae": 0.4898185723853414,
            "precision": 0.5990675990675991,
            "recall": 0.5433403805496829
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5441374496756177,
            "auditor_fn_violation": 0.1282522918088231,
            "auditor_fp_violation": 0.1147576136624716,
            "ave_precision_score": 0.5452653975276917,
            "fpr": 0.20087815587266739,
            "logloss": 0.759472707040324,
            "mae": 0.49137554058902966,
            "precision": 0.5896860986547086,
            "recall": 0.5467775467775468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.5508274067529516,
            "auditor_fn_violation": 0.12185888876525351,
            "auditor_fp_violation": 0.11427486712224753,
            "ave_precision_score": 0.552110056819688,
            "fpr": 0.18859649122807018,
            "logloss": 0.6822539142458847,
            "mae": 0.4892687803101644,
            "precision": 0.6064073226544623,
            "recall": 0.5602536997885835
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5467956776525098,
            "auditor_fn_violation": 0.1264722461209838,
            "auditor_fp_violation": 0.11285834630995839,
            "ave_precision_score": 0.5479465569573454,
            "fpr": 0.19758507135016465,
            "logloss": 0.6844922495333114,
            "mae": 0.4900027852419572,
            "precision": 0.5964125560538116,
            "recall": 0.553014553014553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5626969591763429,
            "auditor_fn_violation": 0.12185888876525351,
            "auditor_fp_violation": 0.11211435479358992,
            "ave_precision_score": 0.5639827246922303,
            "fpr": 0.19407894736842105,
            "logloss": 0.6824175302226148,
            "mae": 0.48935745463690217,
            "precision": 0.5995475113122172,
            "recall": 0.5602536997885835
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5583541776061267,
            "auditor_fn_violation": 0.12587889755837067,
            "auditor_fp_violation": 0.11146452913996885,
            "ave_precision_score": 0.5595718402388062,
            "fpr": 0.20087815587266739,
            "logloss": 0.6845875977207903,
            "mae": 0.4900141258271151,
            "precision": 0.5933333333333334,
            "recall": 0.5550935550935551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.568663586669512,
            "auditor_fn_violation": 0.08386882904936761,
            "auditor_fp_violation": 0.10333243416057229,
            "ave_precision_score": 0.5695345174194726,
            "fpr": 0.30701754385964913,
            "logloss": 0.6856760806746524,
            "mae": 0.4931251630840594,
            "precision": 0.5583596214511041,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5669569617674725,
            "auditor_fn_violation": 0.08880374083447629,
            "auditor_fp_violation": 0.09050111045873432,
            "ave_precision_score": 0.5679339753284613,
            "fpr": 0.31174533479692645,
            "logloss": 0.6860199503929172,
            "mae": 0.4932149308115146,
            "precision": 0.5603715170278638,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5686837175076915,
            "auditor_fn_violation": 0.0874388004895961,
            "auditor_fp_violation": 0.10678425848219639,
            "ave_precision_score": 0.5695546378059329,
            "fpr": 0.29714912280701755,
            "logloss": 0.6843841485669231,
            "mae": 0.4920058649425444,
            "precision": 0.5629032258064516,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.5663584591326101,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.10069435580629515,
            "ave_precision_score": 0.5673355696951482,
            "fpr": 0.3018660812294182,
            "logloss": 0.6855193348187854,
            "mae": 0.49252355275379184,
            "precision": 0.5655608214849921,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8212932009038085,
            "auditor_fn_violation": 0.010642687585772042,
            "auditor_fp_violation": 0.02609599168764737,
            "ave_precision_score": 0.8200071814792019,
            "fpr": 0.17543859649122806,
            "logloss": 0.6614409024821203,
            "mae": 0.3230851777871595,
            "precision": 0.7058823529411765,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8808946974960712,
            "auditor_fn_violation": 0.01337544586721316,
            "auditor_fp_violation": 0.01753758966635183,
            "ave_precision_score": 0.8796593155108979,
            "fpr": 0.15367727771679474,
            "logloss": 0.5878955415718707,
            "mae": 0.28907843688272017,
            "precision": 0.750445632798574,
            "recall": 0.8752598752598753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7745425333192013,
            "auditor_fn_violation": 0.05402711323763955,
            "auditor_fp_violation": 0.06915138072972865,
            "ave_precision_score": 0.775109228976023,
            "fpr": 0.23793859649122806,
            "logloss": 0.6362908079845109,
            "mae": 0.4528779770618044,
            "precision": 0.640728476821192,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.8065729939809035,
            "auditor_fn_violation": 0.04517436460356329,
            "auditor_fp_violation": 0.06012814949072064,
            "ave_precision_score": 0.8068531806701331,
            "fpr": 0.2502744237102086,
            "logloss": 0.6139541846092407,
            "mae": 0.4493836336712507,
            "precision": 0.6426332288401254,
            "recall": 0.8523908523908524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8290776583244132,
            "auditor_fn_violation": 0.0038875598086124423,
            "auditor_fp_violation": 0.0139421732006554,
            "ave_precision_score": 0.8305190679554229,
            "fpr": 0.19517543859649122,
            "logloss": 0.6956285950009131,
            "mae": 0.29782192458383416,
            "precision": 0.693631669535284,
            "recall": 0.8520084566596194
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8961856243890387,
            "auditor_fn_violation": 0.005488474204171241,
            "auditor_fp_violation": 0.006734230209583134,
            "ave_precision_score": 0.896369997987019,
            "fpr": 0.17672886937431395,
            "logloss": 0.5876734129409651,
            "mae": 0.25916021357338437,
            "precision": 0.7330016583747927,
            "recall": 0.918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8254688339448799,
            "auditor_fn_violation": 0.00769630206594711,
            "auditor_fp_violation": 0.025746313391679657,
            "ave_precision_score": 0.8257688429511967,
            "fpr": 0.16666666666666666,
            "logloss": 0.7895060757493257,
            "mae": 0.2918998786389431,
            "precision": 0.708253358925144,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8671792530106981,
            "auditor_fn_violation": 0.009584861396057886,
            "auditor_fp_violation": 0.015880836290301997,
            "ave_precision_score": 0.8674265285119004,
            "fpr": 0.15477497255762898,
            "logloss": 0.6935797070726568,
            "mae": 0.2624000291554878,
            "precision": 0.7403314917127072,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 12669,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5555792370235992,
            "auditor_fn_violation": 0.0874388004895961,
            "auditor_fp_violation": 0.10597999840147065,
            "ave_precision_score": 0.5576278030757633,
            "fpr": 0.2949561403508772,
            "logloss": 0.6826960718859251,
            "mae": 0.491142097272371,
            "precision": 0.5647249190938511,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.576138214959389,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09995404998340694,
            "ave_precision_score": 0.5773071876410072,
            "fpr": 0.2996706915477497,
            "logloss": 0.6841843344436628,
            "mae": 0.49201736972962723,
            "precision": 0.5673534072900158,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8296444502525355,
            "auditor_fn_violation": 0.010990412076703386,
            "auditor_fp_violation": 0.016961895056547986,
            "ave_precision_score": 0.8309793412998754,
            "fpr": 0.12390350877192982,
            "logloss": 0.6519525711890569,
            "mae": 0.28397110407520354,
            "precision": 0.7626050420168067,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.896625431580411,
            "auditor_fn_violation": 0.006937613962860948,
            "auditor_fp_violation": 0.00862328644729789,
            "ave_precision_score": 0.8968134934964838,
            "fpr": 0.11086717892425905,
            "logloss": 0.5429606788028783,
            "mae": 0.2452021558757039,
            "precision": 0.8007889546351085,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8227590083593443,
            "auditor_fn_violation": 0.0030785208263788473,
            "auditor_fp_violation": 0.0259661111777165,
            "ave_precision_score": 0.823038312684317,
            "fpr": 0.17105263157894737,
            "logloss": 0.9188183539203256,
            "mae": 0.2868674202818633,
            "precision": 0.7051039697542533,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.854728195297798,
            "auditor_fn_violation": 0.009523244429940373,
            "auditor_fp_violation": 0.018834401245756006,
            "ave_precision_score": 0.8550242381118829,
            "fpr": 0.16136114160263446,
            "logloss": 0.820957266646855,
            "mae": 0.25804337871758876,
            "precision": 0.7327272727272728,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8268910502189755,
            "auditor_fn_violation": 0.00020863469455881004,
            "auditor_fp_violation": 0.01726911241657675,
            "ave_precision_score": 0.8283162396639031,
            "fpr": 0.13048245614035087,
            "logloss": 0.6391548743705509,
            "mae": 0.2864588882640057,
            "precision": 0.7595959595959596,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8847395972615608,
            "auditor_fn_violation": 0.008754173408399539,
            "auditor_fp_violation": 0.008727950373982081,
            "ave_precision_score": 0.8851709763699126,
            "fpr": 0.12184412733260154,
            "logloss": 0.5325188422600261,
            "mae": 0.2506493516290367,
            "precision": 0.7848837209302325,
            "recall": 0.841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8369727391818407,
            "auditor_fn_violation": 0.011831905344757246,
            "auditor_fp_violation": 0.010657694920672983,
            "ave_precision_score": 0.8373105995618161,
            "fpr": 0.13048245614035087,
            "logloss": 0.6501840420569214,
            "mae": 0.28208209252313954,
            "precision": 0.7561475409836066,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.8955706859687715,
            "auditor_fn_violation": 0.006755045174364606,
            "auditor_fp_violation": 0.012345237791335867,
            "ave_precision_score": 0.8957718856514172,
            "fpr": 0.11745334796926454,
            "logloss": 0.5444166724388991,
            "mae": 0.2446192998525224,
            "precision": 0.791828793774319,
            "recall": 0.8461538461538461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7252384011628732,
            "auditor_fn_violation": 0.022755090686547234,
            "auditor_fp_violation": 0.021580146265435817,
            "ave_precision_score": 0.7257396925836543,
            "fpr": 0.3355263157894737,
            "logloss": 0.7028951436867186,
            "mae": 0.4617330440842187,
            "precision": 0.5802469135802469,
            "recall": 0.8942917547568711
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7722582396368625,
            "auditor_fn_violation": 0.017373702335283018,
            "auditor_fp_violation": 0.022010057948076478,
            "ave_precision_score": 0.7727095022760544,
            "fpr": 0.32711306256860595,
            "logloss": 0.6833169397703895,
            "mae": 0.4558158037815063,
            "precision": 0.5962059620596206,
            "recall": 0.9147609147609148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5500092540068949,
            "auditor_fn_violation": 0.09348457030525574,
            "auditor_fp_violation": 0.08834871917835593,
            "ave_precision_score": 0.5513173089506503,
            "fpr": 0.2543859649122807,
            "logloss": 0.6839636451096285,
            "mae": 0.4892730362255845,
            "precision": 0.5743119266055046,
            "recall": 0.6617336152219874
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5733408585979691,
            "auditor_fn_violation": 0.08968463523897115,
            "auditor_fp_violation": 0.0767365277104128,
            "ave_precision_score": 0.574367878951084,
            "fpr": 0.2810098792535675,
            "logloss": 0.6828806650641492,
            "mae": 0.48836219644441825,
            "precision": 0.5616438356164384,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6876596480861399,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6881439431976194,
            "fpr": 0.47368421052631576,
            "logloss": 2.729381950347145,
            "mae": 0.47491716720776606,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6596255452763907,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.6602945078500225,
            "fpr": 0.4665203073545554,
            "logloss": 2.693697409144683,
            "mae": 0.46679380435443907,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7901708762650281,
            "auditor_fn_violation": 0.012225993101146101,
            "auditor_fp_violation": 0.04574291651680454,
            "ave_precision_score": 0.7906513096423328,
            "fpr": 0.19956140350877194,
            "logloss": 0.6737679290904474,
            "mae": 0.33914793853631314,
            "precision": 0.6856649395509499,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8430273894688431,
            "auditor_fn_violation": 0.02005518141632302,
            "auditor_fp_violation": 0.034942434840323694,
            "ave_precision_score": 0.8434677208077548,
            "fpr": 0.1734357848518112,
            "logloss": 0.6370458657580443,
            "mae": 0.31440743703971524,
            "precision": 0.7289879931389366,
            "recall": 0.8835758835758836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8307180245084443,
            "auditor_fn_violation": 0.00014372612291829208,
            "auditor_fp_violation": 0.021585141669663906,
            "ave_precision_score": 0.8309698140780736,
            "fpr": 0.15679824561403508,
            "logloss": 0.746261435660335,
            "mae": 0.28931445789327265,
            "precision": 0.718503937007874,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8683061272876893,
            "auditor_fn_violation": 0.008215595482335334,
            "auditor_fp_violation": 0.015400913894774465,
            "ave_precision_score": 0.8685720026920152,
            "fpr": 0.150384193194292,
            "logloss": 0.6207163132972175,
            "mae": 0.2606093520917756,
            "precision": 0.7419962335216572,
            "recall": 0.8191268191268192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8286609121214266,
            "auditor_fn_violation": 0.009587923296613628,
            "auditor_fp_violation": 0.018363105942532876,
            "ave_precision_score": 0.8289548221560068,
            "fpr": 0.15570175438596492,
            "logloss": 0.7630016004279806,
            "mae": 0.28821437619563794,
            "precision": 0.7188118811881188,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8714011489123736,
            "auditor_fn_violation": 0.007503577207199603,
            "auditor_fp_violation": 0.018214076021749674,
            "ave_precision_score": 0.8715939117640112,
            "fpr": 0.14818880351262348,
            "logloss": 0.6575506249339661,
            "mae": 0.25875113383117865,
            "precision": 0.7443181818181818,
            "recall": 0.817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8290563191117798,
            "auditor_fn_violation": 0.011500407996736033,
            "auditor_fp_violation": 0.01825820245374257,
            "ave_precision_score": 0.8303908897525841,
            "fpr": 0.1206140350877193,
            "logloss": 0.6510607230975554,
            "mae": 0.28512317960080286,
            "precision": 0.7674418604651163,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8953685142772335,
            "auditor_fn_violation": 0.010563886524369513,
            "auditor_fp_violation": 0.007015035866540734,
            "ave_precision_score": 0.8955594353979816,
            "fpr": 0.1119648737650933,
            "logloss": 0.5399435168346896,
            "mae": 0.24658990825943586,
            "precision": 0.7984189723320159,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5713398109071319,
            "auditor_fn_violation": 0.0011474908200734394,
            "auditor_fp_violation": 0.0015660592255125351,
            "ave_precision_score": 0.572193932023375,
            "fpr": 0.47149122807017546,
            "logloss": 0.7021309896106596,
            "mae": 0.4850173625572209,
            "precision": 0.5216907675194661,
            "recall": 0.9915433403805497
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.5805791931603074,
            "auditor_fn_violation": 0.0029165363962290417,
            "auditor_fp_violation": 0.00510300462052945,
            "ave_precision_score": 0.5815341113807222,
            "fpr": 0.45115257958287597,
            "logloss": 0.6940330598927663,
            "mae": 0.48076147635995886,
            "precision": 0.536117381489842,
            "recall": 0.9875259875259875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8287850965774874,
            "auditor_fn_violation": 0.0075595304328474455,
            "auditor_fp_violation": 0.015513227830396045,
            "ave_precision_score": 0.8301218406602663,
            "fpr": 0.1206140350877193,
            "logloss": 0.6457921468755226,
            "mae": 0.28427018175259683,
            "precision": 0.7684210526315789,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.8079034028540066,
            "auc_prc": 0.894408771772932,
            "auditor_fn_violation": 0.005294494866393884,
            "auditor_fp_violation": 0.007877875067010444,
            "ave_precision_score": 0.8945989144882797,
            "fpr": 0.10757409440175632,
            "logloss": 0.5354254107293055,
            "mae": 0.24687539954688636,
            "precision": 0.8047808764940239,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6436167719605536,
            "auditor_fn_violation": 0.001251808167352843,
            "auditor_fp_violation": 0.0029797586220677136,
            "ave_precision_score": 0.6448150013766805,
            "fpr": 0.4725877192982456,
            "logloss": 2.799590561787511,
            "mae": 0.4744788731064039,
            "precision": 0.5221729490022173,
            "recall": 0.9957716701902748
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6630696669594466,
            "auditor_fn_violation": 0.0017663530287020958,
            "auditor_fp_violation": 0.0014142393995864493,
            "ave_precision_score": 0.6635717367041591,
            "fpr": 0.4643249176728869,
            "logloss": 2.7855542727950793,
            "mae": 0.46776136168772026,
            "precision": 0.5305216426193119,
            "recall": 0.9937629937629938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8236187886960709,
            "auditor_fn_violation": 0.009676013500982902,
            "auditor_fp_violation": 0.019362186788154902,
            "ave_precision_score": 0.8239254072821023,
            "fpr": 0.1524122807017544,
            "logloss": 0.7845760646165685,
            "mae": 0.29252414340844723,
            "precision": 0.722,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8702314568061534,
            "auditor_fn_violation": 0.010776122740996512,
            "auditor_fp_violation": 0.014525310800806684,
            "ave_precision_score": 0.8704473642270161,
            "fpr": 0.14270032930845225,
            "logloss": 0.6746515316784458,
            "mae": 0.2603947425675381,
            "precision": 0.7495183044315993,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8301135807337932,
            "auditor_fn_violation": 0.006755127777159605,
            "auditor_fp_violation": 0.021575150861207693,
            "ave_precision_score": 0.8303608644064332,
            "fpr": 0.16228070175438597,
            "logloss": 0.7487212482068998,
            "mae": 0.29033296096503086,
            "precision": 0.7126213592233009,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8660711426292746,
            "auditor_fn_violation": 0.009792533392972471,
            "auditor_fp_violation": 0.01615398361116075,
            "ave_precision_score": 0.8664005857243464,
            "fpr": 0.14928649835345773,
            "logloss": 0.6250518599528354,
            "mae": 0.2612922696485076,
            "precision": 0.7429111531190926,
            "recall": 0.817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8295050535786568,
            "auditor_fn_violation": 0.0038875598086124423,
            "auditor_fp_violation": 0.012825700355672785,
            "ave_precision_score": 0.8302941584888215,
            "fpr": 0.19846491228070176,
            "logloss": 0.7139047041517724,
            "mae": 0.2988623094621878,
            "precision": 0.690068493150685,
            "recall": 0.8520084566596194
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8971778973494481,
            "auditor_fn_violation": 0.0059083824177128255,
            "auditor_fp_violation": 0.012398846144027776,
            "ave_precision_score": 0.8973593049788492,
            "fpr": 0.18331503841931943,
            "logloss": 0.6071302364892807,
            "mae": 0.2604620491825774,
            "precision": 0.7262295081967213,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5760033232561096,
            "auditor_fn_violation": 0.006175586958940718,
            "auditor_fp_violation": 0.006309195540103106,
            "ave_precision_score": 0.5619419708476977,
            "fpr": 0.041666666666666664,
            "logloss": 13.471174884354413,
            "mae": 0.47146812793340487,
            "precision": 0.6833333333333333,
            "recall": 0.1733615221987315
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6080477115905376,
            "auditor_fn_violation": 0.004075848203180798,
            "auditor_fp_violation": 0.007517933270364793,
            "ave_precision_score": 0.5960986354677643,
            "fpr": 0.038419319429198684,
            "logloss": 13.683233074738224,
            "mae": 0.472947327974462,
            "precision": 0.72,
            "recall": 0.18711018711018712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8080877858450733,
            "auditor_fn_violation": 0.014268294944549537,
            "auditor_fp_violation": 0.041529293050393636,
            "ave_precision_score": 0.8087050798683899,
            "fpr": 0.1875,
            "logloss": 0.6383942415350508,
            "mae": 0.33027018661484325,
            "precision": 0.701048951048951,
            "recall": 0.8477801268498943
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.862797256611229,
            "auditor_fn_violation": 0.023113208623636732,
            "auditor_fp_violation": 0.03212161437724964,
            "ave_precision_score": 0.8639778073673129,
            "fpr": 0.16355653128430298,
            "logloss": 0.6038410810080771,
            "mae": 0.30812292415169634,
            "precision": 0.7385964912280701,
            "recall": 0.8752598752598753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 12669,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5828163530433591,
            "auditor_fn_violation": 0.06396739735173028,
            "auditor_fp_violation": 0.05934040682572033,
            "ave_precision_score": 0.5782923261153644,
            "fpr": 0.18421052631578946,
            "logloss": 0.6832372658324761,
            "mae": 0.4896297468885518,
            "precision": 0.5841584158415841,
            "recall": 0.4989429175475687
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.5799527943175553,
            "auditor_fn_violation": 0.05758676011145825,
            "auditor_fp_violation": 0.05540040333903455,
            "ave_precision_score": 0.5749537946539844,
            "fpr": 0.18331503841931943,
            "logloss": 0.6894887301127991,
            "mae": 0.492834131817132,
            "precision": 0.5782828282828283,
            "recall": 0.4760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8295740810450412,
            "auditor_fn_violation": 0.014136159637995626,
            "auditor_fp_violation": 0.014214422731087402,
            "ave_precision_score": 0.8309092438588078,
            "fpr": 0.11842105263157894,
            "logloss": 0.6511276057563935,
            "mae": 0.2836644191601065,
            "precision": 0.7682403433476395,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.8963678743134309,
            "auditor_fn_violation": 0.009466191683535269,
            "auditor_fp_violation": 0.006210910576162155,
            "ave_precision_score": 0.8965568310362834,
            "fpr": 0.10867178924259056,
            "logloss": 0.5417316435499268,
            "mae": 0.2451757516973634,
            "precision": 0.8031809145129225,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8284558794813899,
            "auditor_fn_violation": 0.00420746634026928,
            "auditor_fp_violation": 0.014529133197458341,
            "ave_precision_score": 0.8298956515234236,
            "fpr": 0.19407894736842105,
            "logloss": 0.6976669804686937,
            "mae": 0.29807350003294814,
            "precision": 0.6932409012131716,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8967714183740161,
            "auditor_fn_violation": 0.0059083824177128255,
            "auditor_fp_violation": 0.013453143746968575,
            "ave_precision_score": 0.8969497645708473,
            "fpr": 0.17453347969264543,
            "logloss": 0.5876220114271008,
            "mae": 0.2590840642869386,
            "precision": 0.7358803986710963,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8310362911123771,
            "auditor_fn_violation": 0.01835521679462928,
            "auditor_fp_violation": 0.008172481317188186,
            "ave_precision_score": 0.8324071017449777,
            "fpr": 0.10526315789473684,
            "logloss": 0.6439581164766655,
            "mae": 0.2802493008497349,
            "precision": 0.785234899328859,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.8079034028540066,
            "auc_prc": 0.8942706146038553,
            "auditor_fn_violation": 0.013124413783030689,
            "auditor_fp_violation": 0.0075868582952543845,
            "ave_precision_score": 0.8945108102353891,
            "fpr": 0.09769484083424808,
            "logloss": 0.5334308036123567,
            "mae": 0.24269025973799255,
            "precision": 0.8161157024793388,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8294839775713646,
            "auditor_fn_violation": 0.011729906160750718,
            "auditor_fp_violation": 0.016297506294209337,
            "ave_precision_score": 0.8308192982263318,
            "fpr": 0.12280701754385964,
            "logloss": 0.6510605412854986,
            "mae": 0.2842140257293634,
            "precision": 0.7632135306553911,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.8966251569249977,
            "auditor_fn_violation": 0.006937613962860948,
            "auditor_fp_violation": 0.00862328644729789,
            "ave_precision_score": 0.8968109435742361,
            "fpr": 0.11086717892425905,
            "logloss": 0.5423515993333758,
            "mae": 0.24550258228966143,
            "precision": 0.8007889546351085,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8315902776312587,
            "auditor_fn_violation": 0.003155020214383738,
            "auditor_fp_violation": 0.021008172481317193,
            "ave_precision_score": 0.8318449503808071,
            "fpr": 0.15021929824561403,
            "logloss": 0.7890025984201164,
            "mae": 0.2884578486590987,
            "precision": 0.7248995983935743,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8728135513121833,
            "auditor_fn_violation": 0.012400984958613945,
            "auditor_fp_violation": 0.015839991831108163,
            "ave_precision_score": 0.8730255051943022,
            "fpr": 0.13721185510428102,
            "logloss": 0.6794944706304503,
            "mae": 0.25565244508688884,
            "precision": 0.7572815533980582,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5761185259877839,
            "auditor_fn_violation": 0.006175586958940718,
            "auditor_fp_violation": 0.006309195540103106,
            "ave_precision_score": 0.5620566789950113,
            "fpr": 0.041666666666666664,
            "logloss": 13.470494761011425,
            "mae": 0.47150937757026423,
            "precision": 0.6833333333333333,
            "recall": 0.1733615221987315
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6081809231276913,
            "auditor_fn_violation": 0.004075848203180798,
            "auditor_fp_violation": 0.007517933270364793,
            "ave_precision_score": 0.5962317368278154,
            "fpr": 0.038419319429198684,
            "logloss": 13.68285525568173,
            "mae": 0.47297813387768617,
            "precision": 0.72,
            "recall": 0.18711018711018712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8401740386075166,
            "auditor_fn_violation": 0.015343922703163829,
            "auditor_fp_violation": 0.009646125564480683,
            "ave_precision_score": 0.8406580726765087,
            "fpr": 0.12609649122807018,
            "logloss": 0.633178998233714,
            "mae": 0.28363293602666517,
            "precision": 0.7599164926931107,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8939842863060359,
            "auditor_fn_violation": 0.016928690913323188,
            "auditor_fp_violation": 0.005105557399229064,
            "ave_precision_score": 0.8941559992379128,
            "fpr": 0.11525795828759605,
            "logloss": 0.5206715040828249,
            "mae": 0.24600004911470852,
            "precision": 0.7912524850894632,
            "recall": 0.8274428274428275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8255697646680619,
            "auditor_fn_violation": 0.0070889432884536936,
            "auditor_fp_violation": 0.025746313391679657,
            "ave_precision_score": 0.8258698169869848,
            "fpr": 0.16666666666666666,
            "logloss": 0.7803421908523916,
            "mae": 0.2919522811250811,
            "precision": 0.7099236641221374,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8671053552146998,
            "auditor_fn_violation": 0.009991076950462247,
            "auditor_fp_violation": 0.015911469634697372,
            "ave_precision_score": 0.8673539453852843,
            "fpr": 0.15697036223929747,
            "logloss": 0.6825720376981053,
            "mae": 0.2626772362640156,
            "precision": 0.7385740402193784,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 12669,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5629704134114077,
            "auditor_fn_violation": 0.0874388004895961,
            "auditor_fp_violation": 0.10597999840147065,
            "ave_precision_score": 0.5638404819889762,
            "fpr": 0.2949561403508772,
            "logloss": 0.6828430787053674,
            "mae": 0.4913291705184077,
            "precision": 0.5647249190938511,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5595104853299819,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09995404998340694,
            "ave_precision_score": 0.5604887496712573,
            "fpr": 0.2996706915477497,
            "logloss": 0.6843766660229698,
            "mae": 0.4922943183606333,
            "precision": 0.5673534072900158,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.835682132970906,
            "auditor_fn_violation": 0.006606765327695562,
            "auditor_fp_violation": 0.009219018502977268,
            "ave_precision_score": 0.8363061280677799,
            "fpr": 0.18311403508771928,
            "logloss": 0.6791445193353981,
            "mae": 0.29559341228580865,
            "precision": 0.7039007092198581,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8957517292669437,
            "auditor_fn_violation": 0.00753552674518646,
            "auditor_fp_violation": 0.004809435070073774,
            "ave_precision_score": 0.895944614722497,
            "fpr": 0.16355653128430298,
            "logloss": 0.5717955016104216,
            "mae": 0.2557968027619701,
            "precision": 0.7448630136986302,
            "recall": 0.9043659043659044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.822924941696453,
            "auditor_fn_violation": 8.113571455064743e-05,
            "auditor_fp_violation": 0.02313871238460617,
            "ave_precision_score": 0.823617082610316,
            "fpr": 0.1513157894736842,
            "logloss": 0.7555664470048632,
            "mae": 0.2868604659082946,
            "precision": 0.7272727272727273,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8718261038051613,
            "auditor_fn_violation": 0.0107715585212841,
            "auditor_fp_violation": 0.019758507135016465,
            "ave_precision_score": 0.8720340602371722,
            "fpr": 0.14709110867178923,
            "logloss": 0.6480922719034129,
            "mae": 0.2571310824932411,
            "precision": 0.7485928705440901,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7961388296611025,
            "auditor_fn_violation": 0.018737713734653758,
            "auditor_fp_violation": 0.04850537505494946,
            "ave_precision_score": 0.7967514244188036,
            "fpr": 0.21600877192982457,
            "logloss": 0.6688372805215548,
            "mae": 0.3490211344430676,
            "precision": 0.6743801652892562,
            "recall": 0.8625792811839323
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8475783495617901,
            "auditor_fn_violation": 0.024792841477803064,
            "auditor_fp_violation": 0.05046332933398004,
            "ave_precision_score": 0.8487710881538371,
            "fpr": 0.2074643249176729,
            "logloss": 0.642742809048922,
            "mae": 0.33001903305142444,
            "precision": 0.6926829268292682,
            "recall": 0.8856548856548857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 12669,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5629653158581838,
            "auditor_fn_violation": 0.0874388004895961,
            "auditor_fp_violation": 0.10597999840147065,
            "ave_precision_score": 0.5638353870178252,
            "fpr": 0.2949561403508772,
            "logloss": 0.6828429119952948,
            "mae": 0.4913291068126758,
            "precision": 0.5647249190938511,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5595151995708773,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09995404998340694,
            "ave_precision_score": 0.5604934635455678,
            "fpr": 0.2996706915477497,
            "logloss": 0.6843765051825197,
            "mae": 0.49229425824892376,
            "precision": 0.5673534072900158,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7294838243315377,
            "auditor_fn_violation": 0.007285987166648122,
            "auditor_fp_violation": 0.011704232106462065,
            "ave_precision_score": 0.6451539882349504,
            "fpr": 0.25109649122807015,
            "logloss": 5.255397882562912,
            "mae": 0.32328558264090984,
            "precision": 0.6509146341463414,
            "recall": 0.9027484143763214
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7358024242487032,
            "auditor_fn_violation": 0.0009379471508999508,
            "auditor_fp_violation": 0.010134531437469691,
            "ave_precision_score": 0.6490141387789903,
            "fpr": 0.25686059275521406,
            "logloss": 5.47428717138344,
            "mae": 0.3094062198146658,
            "precision": 0.6593886462882096,
            "recall": 0.9417879417879418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.724960410426885,
            "auditor_fn_violation": 0.026617150699158047,
            "auditor_fp_violation": 0.026820325300723338,
            "ave_precision_score": 0.7254613615984473,
            "fpr": 0.32346491228070173,
            "logloss": 0.7007730966885798,
            "mae": 0.46053992365481117,
            "precision": 0.5821529745042493,
            "recall": 0.86892177589852
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7666551822075423,
            "auditor_fn_violation": 0.020929229491249254,
            "auditor_fp_violation": 0.03236923391111225,
            "ave_precision_score": 0.7671094254963038,
            "fpr": 0.3150384193194292,
            "logloss": 0.68286308445215,
            "mae": 0.4554640228584248,
            "precision": 0.599721059972106,
            "recall": 0.893970893970894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7233462522718561,
            "auditor_fn_violation": 0.020207429249656916,
            "auditor_fp_violation": 0.030177236942013363,
            "ave_precision_score": 0.7247118488227765,
            "fpr": 0.2905701754385965,
            "logloss": 0.8187616450601588,
            "mae": 0.4675656840140253,
            "precision": 0.6074074074074074,
            "recall": 0.8668076109936576
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7384046577988632,
            "auditor_fn_violation": 0.004247006442396125,
            "auditor_fp_violation": 0.028305210221325927,
            "ave_precision_score": 0.739735043967805,
            "fpr": 0.29747530186608123,
            "logloss": 0.7735163342607158,
            "mae": 0.4662652158797732,
            "precision": 0.6111908177905309,
            "recall": 0.8856548856548857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5824538136945148,
            "auditor_fn_violation": 0.05481065242387152,
            "auditor_fp_violation": 0.07572283499180756,
            "ave_precision_score": 0.5843778156647307,
            "fpr": 0.34100877192982454,
            "logloss": 0.6797322737852098,
            "mae": 0.4840480866923667,
            "precision": 0.5557142857142857,
            "recall": 0.8224101479915433
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.611684921634243,
            "auditor_fn_violation": 0.061162826256130315,
            "auditor_fp_violation": 0.06734230209583134,
            "ave_precision_score": 0.6126486447104555,
            "fpr": 0.3380900109769484,
            "logloss": 0.6786096505984024,
            "mae": 0.4830500215586402,
            "precision": 0.5581061692969871,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8361279867732133,
            "auditor_fn_violation": 0.0017478951077482333,
            "auditor_fp_violation": 0.020183930783679017,
            "ave_precision_score": 0.8363836733376594,
            "fpr": 0.15021929824561403,
            "logloss": 0.7144353737008471,
            "mae": 0.28830253426601926,
            "precision": 0.7287128712871287,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8814026787138377,
            "auditor_fn_violation": 0.01032198287961186,
            "auditor_fp_violation": 0.017221045107599624,
            "ave_precision_score": 0.8815901260204865,
            "fpr": 0.13391877058177826,
            "logloss": 0.6135348542055744,
            "mae": 0.2533738556489491,
            "precision": 0.7667304015296367,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8347788180442571,
            "auditor_fn_violation": 0.007784392270316383,
            "auditor_fp_violation": 0.022202074091835517,
            "ave_precision_score": 0.8350245578141539,
            "fpr": 0.14473684210526316,
            "logloss": 0.7793446568226486,
            "mae": 0.28512897512419993,
            "precision": 0.7306122448979592,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8757011166492689,
            "auditor_fn_violation": 0.01191717766909864,
            "auditor_fp_violation": 0.017741811962320986,
            "ave_precision_score": 0.8759261575522443,
            "fpr": 0.1394072447859495,
            "logloss": 0.6714797942472135,
            "mae": 0.2538113310529695,
            "precision": 0.7529182879377432,
            "recall": 0.8045738045738046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8254350191152067,
            "auditor_fn_violation": 0.00769630206594711,
            "auditor_fp_violation": 0.025746313391679657,
            "ave_precision_score": 0.8257350661137757,
            "fpr": 0.16666666666666666,
            "logloss": 0.7895719575582092,
            "mae": 0.2918965675600809,
            "precision": 0.708253358925144,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8671628092140903,
            "auditor_fn_violation": 0.009584861396057886,
            "auditor_fp_violation": 0.015880836290301997,
            "ave_precision_score": 0.867410133606628,
            "fpr": 0.15477497255762898,
            "logloss": 0.6935739459159284,
            "mae": 0.26238693045994976,
            "precision": 0.7403314917127072,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 12669,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6452738965695846,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.000532010550293732,
            "ave_precision_score": 0.6467360703013587,
            "fpr": 0.48026315789473684,
            "logloss": 1.62793405265433,
            "mae": 0.4794790416842596,
            "precision": 0.5186813186813187,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6487684376448237,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00020932785336840343,
            "ave_precision_score": 0.6503132133272201,
            "fpr": 0.4698133918770582,
            "logloss": 1.5859041050027944,
            "mae": 0.4695574479123819,
            "precision": 0.5291529152915292,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8338896613097424,
            "auditor_fn_violation": 0.005329457364341083,
            "auditor_fp_violation": 0.022501798345522128,
            "ave_precision_score": 0.8341446575150149,
            "fpr": 0.15021929824561403,
            "logloss": 0.7468080352343103,
            "mae": 0.2883481959953452,
            "precision": 0.7254509018036072,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8745704650699284,
            "auditor_fn_violation": 0.009687556339587074,
            "auditor_fp_violation": 0.017366553493477654,
            "ave_precision_score": 0.8749135916397437,
            "fpr": 0.1394072447859495,
            "logloss": 0.6505155164500876,
            "mae": 0.25706389491615733,
            "precision": 0.7571701720841301,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7557926787606575,
            "auditor_fn_violation": 0.03962668298653611,
            "auditor_fp_violation": 0.03758791911441474,
            "ave_precision_score": 0.7573529845406619,
            "fpr": 0.15460526315789475,
            "logloss": 0.6323541973507039,
            "mae": 0.45018809863684234,
            "precision": 0.7025316455696202,
            "recall": 0.7040169133192389
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.782718372318995,
            "auditor_fn_violation": 0.03110059312035163,
            "auditor_fp_violation": 0.03554999617083195,
            "ave_precision_score": 0.7840405390517711,
            "fpr": 0.1668496158068057,
            "logloss": 0.614083264497043,
            "mae": 0.447721474836698,
            "precision": 0.692929292929293,
            "recall": 0.7130977130977131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8302169631555733,
            "auditor_fn_violation": 0.0016598049033789558,
            "auditor_fp_violation": 0.022247032729888507,
            "ave_precision_score": 0.8305019389658622,
            "fpr": 0.15350877192982457,
            "logloss": 0.7727383451718698,
            "mae": 0.2880934314640181,
            "precision": 0.7211155378486056,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8714081701521605,
            "auditor_fn_violation": 0.010646042479192864,
            "auditor_fp_violation": 0.021213590993796747,
            "ave_precision_score": 0.8716857650923688,
            "fpr": 0.14270032930845225,
            "logloss": 0.6720674176808762,
            "mae": 0.2572338637335404,
            "precision": 0.7523809523809524,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8274352488649263,
            "auditor_fn_violation": 0.010823504321056344,
            "auditor_fp_violation": 0.02006404108220438,
            "ave_precision_score": 0.8272964840584093,
            "fpr": 0.18969298245614036,
            "logloss": 0.6894220494453684,
            "mae": 0.31608138364146277,
            "precision": 0.6927175843694494,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8792557959971139,
            "auditor_fn_violation": 0.01755170690406695,
            "auditor_fp_violation": 0.021877313455696528,
            "ave_precision_score": 0.8791345125352807,
            "fpr": 0.16465422612513722,
            "logloss": 0.6211804533776516,
            "mae": 0.2823316623343725,
            "precision": 0.7391304347826086,
            "recall": 0.8835758835758836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5780315136225442,
            "auditor_fn_violation": 0.06193204999814547,
            "auditor_fp_violation": 0.07138682412180794,
            "ave_precision_score": 0.579444492463759,
            "fpr": 0.30043859649122806,
            "logloss": 0.6765209521530255,
            "mae": 0.4793174216409394,
            "precision": 0.568503937007874,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5675968206413541,
            "auditor_fn_violation": 0.062217161009696695,
            "auditor_fp_violation": 0.07183008704975366,
            "ave_precision_score": 0.5688677259246505,
            "fpr": 0.30954994511525796,
            "logloss": 0.6896736599039973,
            "mae": 0.48523780138412764,
            "precision": 0.5559055118110237,
            "recall": 0.7338877338877339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8008558008419291,
            "auditor_fn_violation": 0.008707021252920884,
            "auditor_fp_violation": 0.02772948887023938,
            "ave_precision_score": 0.8012938526733786,
            "fpr": 0.19078947368421054,
            "logloss": 0.7083151460680078,
            "mae": 0.32793654177880055,
            "precision": 0.6909413854351687,
            "recall": 0.8224101479915433
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8504491472803912,
            "auditor_fn_violation": 0.01579220020493347,
            "auditor_fp_violation": 0.02690628749393716,
            "ave_precision_score": 0.8514093164162626,
            "fpr": 0.17014270032930845,
            "logloss": 0.6616214210113245,
            "mae": 0.2959189891116499,
            "precision": 0.7318339100346021,
            "recall": 0.8794178794178794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8331490348477186,
            "auditor_fn_violation": 0.004532009198471865,
            "auditor_fp_violation": 0.017458937777244932,
            "ave_precision_score": 0.8345151283012259,
            "fpr": 0.18530701754385964,
            "logloss": 0.6784705172150723,
            "mae": 0.28824502072137514,
            "precision": 0.70298769771529,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.897727956657016,
            "auditor_fn_violation": 0.005933485626131071,
            "auditor_fp_violation": 0.00877134761187553,
            "ave_precision_score": 0.8979110567111596,
            "fpr": 0.1712403951701427,
            "logloss": 0.5836245999044963,
            "mae": 0.2530218307638613,
            "precision": 0.735593220338983,
            "recall": 0.9022869022869023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5760975217796227,
            "auditor_fn_violation": 0.006175586958940718,
            "auditor_fp_violation": 0.006309195540103106,
            "ave_precision_score": 0.5620357625994533,
            "fpr": 0.041666666666666664,
            "logloss": 13.470457809058038,
            "mae": 0.47150920457808526,
            "precision": 0.6833333333333333,
            "recall": 0.1733615221987315
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6081722575054813,
            "auditor_fn_violation": 0.004075848203180798,
            "auditor_fp_violation": 0.007517933270364793,
            "ave_precision_score": 0.5962230849319525,
            "fpr": 0.038419319429198684,
            "logloss": 13.682844379872387,
            "mae": 0.47298006621127053,
            "precision": 0.72,
            "recall": 0.18711018711018712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8299715416289344,
            "auditor_fn_violation": 0.007522439820481441,
            "auditor_fp_violation": 0.013277784438316753,
            "ave_precision_score": 0.8313244840307853,
            "fpr": 0.1206140350877193,
            "logloss": 0.6484824511813756,
            "mae": 0.2830846425686945,
            "precision": 0.7674418604651163,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8956449969967114,
            "auditor_fn_violation": 0.009584861396057884,
            "auditor_fp_violation": 0.011145431802517043,
            "ave_precision_score": 0.8958625798056611,
            "fpr": 0.1119648737650933,
            "logloss": 0.5425052004036551,
            "mae": 0.24436387066094903,
            "precision": 0.7972166998011928,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8245348394367568,
            "auditor_fn_violation": 0.012995623307740815,
            "auditor_fp_violation": 0.022341945410222597,
            "ave_precision_score": 0.8240215728687502,
            "fpr": 0.17763157894736842,
            "logloss": 0.6843567179525526,
            "mae": 0.3212307686104558,
            "precision": 0.7,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8777861195265856,
            "auditor_fn_violation": 0.018628862756195363,
            "auditor_fp_violation": 0.020680060245577312,
            "ave_precision_score": 0.8775640743692688,
            "fpr": 0.15697036223929747,
            "logloss": 0.624677262822698,
            "mae": 0.28622315850830166,
            "precision": 0.7450980392156863,
            "recall": 0.8690228690228691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8277072634869538,
            "auditor_fn_violation": 0.003688197767145138,
            "auditor_fp_violation": 0.017184190544698878,
            "ave_precision_score": 0.8286718926654838,
            "fpr": 0.20942982456140352,
            "logloss": 0.7292974644911366,
            "mae": 0.30454102895835183,
            "precision": 0.6811352253756261,
            "recall": 0.8625792811839323
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8959108025180113,
            "auditor_fn_violation": 0.00566419666309897,
            "auditor_fp_violation": 0.011334337426288518,
            "ave_precision_score": 0.8960921178925294,
            "fpr": 0.19209659714599342,
            "logloss": 0.6261379339706158,
            "mae": 0.26667112998603826,
            "precision": 0.717741935483871,
            "recall": 0.9251559251559252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6723223926109639,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6727755240605344,
            "fpr": 0.47368421052631576,
            "logloss": 2.485791273144775,
            "mae": 0.4746987240689344,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6442594685643579,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.6450964416304239,
            "fpr": 0.4665203073545554,
            "logloss": 2.440954580196317,
            "mae": 0.46656156818415384,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8295128963581767,
            "auditor_fn_violation": 0.004263102258818294,
            "auditor_fp_violation": 0.012098869040482754,
            "ave_precision_score": 0.8309349668668954,
            "fpr": 0.1962719298245614,
            "logloss": 0.7108997992606624,
            "mae": 0.2984675148689663,
            "precision": 0.692967409948542,
            "recall": 0.854122621564482
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8971720298131315,
            "auditor_fn_violation": 0.005488474204171241,
            "auditor_fp_violation": 0.006734230209583134,
            "ave_precision_score": 0.8973435017667594,
            "fpr": 0.17672886937431395,
            "logloss": 0.6037127911621856,
            "mae": 0.2598784119424348,
            "precision": 0.7330016583747927,
            "recall": 0.918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8295057410062204,
            "auditor_fn_violation": 0.0038875598086124423,
            "auditor_fp_violation": 0.012098869040482754,
            "ave_precision_score": 0.830929824160546,
            "fpr": 0.1962719298245614,
            "logloss": 0.709824472873657,
            "mae": 0.2982353696737316,
            "precision": 0.6924398625429553,
            "recall": 0.8520084566596194
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.89672826556333,
            "auditor_fn_violation": 0.0059083824177128255,
            "auditor_fp_violation": 0.006734230209583134,
            "ave_precision_score": 0.8969060509252778,
            "fpr": 0.17672886937431395,
            "logloss": 0.602908020015637,
            "mae": 0.25953909996497126,
            "precision": 0.7334437086092715,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6728662892501664,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6733222372512697,
            "fpr": 0.47368421052631576,
            "logloss": 2.6886167307391133,
            "mae": 0.4747199125375781,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6431229358147643,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.6437929286635657,
            "fpr": 0.4665203073545554,
            "logloss": 2.646044399762584,
            "mae": 0.46657215788007544,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8238424624640199,
            "auditor_fn_violation": 0.006861763287711879,
            "auditor_fp_violation": 0.022446848899012908,
            "ave_precision_score": 0.8241829356606752,
            "fpr": 0.16228070175438597,
            "logloss": 0.7886604115588206,
            "mae": 0.29275815202675415,
            "precision": 0.7131782945736435,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8668843169736121,
            "auditor_fn_violation": 0.009988794840606038,
            "auditor_fp_violation": 0.015367727771679478,
            "ave_precision_score": 0.8671394026072287,
            "fpr": 0.15148188803512624,
            "logloss": 0.6893280124139876,
            "mae": 0.2621443058336432,
            "precision": 0.7434944237918215,
            "recall": 0.8316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7853186088542247,
            "auditor_fn_violation": 0.01288435147064278,
            "auditor_fp_violation": 0.05081075410622229,
            "ave_precision_score": 0.7861056698407543,
            "fpr": 0.19517543859649122,
            "logloss": 0.6750111455882623,
            "mae": 0.33944105488955056,
            "precision": 0.6920415224913494,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8438478710171678,
            "auditor_fn_violation": 0.02005518141632302,
            "auditor_fp_violation": 0.033995353942766704,
            "ave_precision_score": 0.8442620429316667,
            "fpr": 0.17453347969264543,
            "logloss": 0.6377403096711927,
            "mae": 0.31502773560815905,
            "precision": 0.7277397260273972,
            "recall": 0.8835758835758836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.716744473771012,
            "auditor_fn_violation": 0.08642344497607657,
            "auditor_fp_violation": 0.10517573832074492,
            "ave_precision_score": 0.5669424797192829,
            "fpr": 0.29276315789473684,
            "logloss": 0.7202187742533539,
            "mae": 0.4924672179288775,
            "precision": 0.563011456628478,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7217604353945244,
            "auditor_fn_violation": 0.09125244471018348,
            "auditor_fp_violation": 0.09840196053404131,
            "ave_precision_score": 0.5714290599646089,
            "fpr": 0.29747530186608123,
            "logloss": 0.7204411501519827,
            "mae": 0.4923703630200092,
            "precision": 0.5664,
            "recall": 0.735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6609184958781139,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6614084665530178,
            "fpr": 0.47368421052631576,
            "logloss": 2.466389959122994,
            "mae": 0.4746622984863147,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6382480997821356,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.6393283253481621,
            "fpr": 0.4665203073545554,
            "logloss": 2.420788223632479,
            "mae": 0.46653532359414324,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8260251058747716,
            "auditor_fn_violation": 0.016322187604317348,
            "auditor_fp_violation": 0.010273048795108508,
            "ave_precision_score": 0.8273822689125667,
            "fpr": 0.1206140350877193,
            "logloss": 0.6290711982162849,
            "mae": 0.2873830072496316,
            "precision": 0.7684210526315789,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8926659244775026,
            "auditor_fn_violation": 0.012855124819998585,
            "auditor_fp_violation": 0.007030352538738421,
            "ave_precision_score": 0.8928639022065646,
            "fpr": 0.1119648737650933,
            "logloss": 0.5345594360614017,
            "mae": 0.2536629963439427,
            "precision": 0.7964071856287425,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8301467815466376,
            "auditor_fn_violation": 0.003850469196246428,
            "auditor_fp_violation": 0.02261919034488271,
            "ave_precision_score": 0.8303951754658869,
            "fpr": 0.15789473684210525,
            "logloss": 0.7480011931394582,
            "mae": 0.2902108732164945,
            "precision": 0.7165354330708661,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8670275739294775,
            "auditor_fn_violation": 0.009021180261575437,
            "auditor_fp_violation": 0.015056288770326507,
            "ave_precision_score": 0.8673264815074826,
            "fpr": 0.14928649835345773,
            "logloss": 0.6233468216116722,
            "mae": 0.26154513369143867,
            "precision": 0.7433962264150943,
            "recall": 0.8191268191268192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8397636137351474,
            "auditor_fn_violation": 0.018575442305552473,
            "auditor_fp_violation": 0.009508751948207652,
            "ave_precision_score": 0.8402462224910882,
            "fpr": 0.1162280701754386,
            "logloss": 0.6396241339970327,
            "mae": 0.28336390538490824,
            "precision": 0.7720430107526882,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.8962628149907279,
            "auditor_fn_violation": 0.016894459265480125,
            "auditor_fp_violation": 0.012309498889541276,
            "ave_precision_score": 0.8964118849343958,
            "fpr": 0.10647639956092206,
            "logloss": 0.5237115209026129,
            "mae": 0.24533851571913656,
            "precision": 0.8036437246963563,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8286694874214467,
            "auditor_fn_violation": 0.011611679833834059,
            "auditor_fp_violation": 0.02076339767413979,
            "ave_precision_score": 0.8283039365415176,
            "fpr": 0.19188596491228072,
            "logloss": 0.6886357960517986,
            "mae": 0.31657476834141457,
            "precision": 0.6924428822495606,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8810791003976247,
            "auditor_fn_violation": 0.015041386062242267,
            "auditor_fp_violation": 0.021346335486176704,
            "ave_precision_score": 0.880795281180126,
            "fpr": 0.1690450054884742,
            "logloss": 0.6225299977996644,
            "mae": 0.2835633443896833,
            "precision": 0.7358490566037735,
            "recall": 0.8918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7250375250354382,
            "auditor_fn_violation": 0.026329698453321466,
            "auditor_fp_violation": 0.030986492426967185,
            "ave_precision_score": 0.725544300098548,
            "fpr": 0.3081140350877193,
            "logloss": 0.6964114792414781,
            "mae": 0.45978482978981766,
            "precision": 0.5879765395894428,
            "recall": 0.8477801268498943
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7708623150074787,
            "auditor_fn_violation": 0.02364265811027611,
            "auditor_fp_violation": 0.034199576238735874,
            "ave_precision_score": 0.7713130894164649,
            "fpr": 0.29747530186608123,
            "logloss": 0.678151892238894,
            "mae": 0.454656388347069,
            "precision": 0.6123032904148784,
            "recall": 0.8898128898128899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8330666597645278,
            "auditor_fn_violation": 0.00419819368717778,
            "auditor_fp_violation": 0.016057726891260046,
            "ave_precision_score": 0.8344328837114658,
            "fpr": 0.18640350877192982,
            "logloss": 0.6819466387920935,
            "mae": 0.28901180197997095,
            "precision": 0.7027972027972028,
            "recall": 0.8498942917547568
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8977775752535317,
            "auditor_fn_violation": 0.005340137063517964,
            "auditor_fp_violation": 0.005197457432415186,
            "ave_precision_score": 0.8979608478472584,
            "fpr": 0.1734357848518112,
            "logloss": 0.5877991105551535,
            "mae": 0.2539211052419712,
            "precision": 0.7335581787521079,
            "recall": 0.9043659043659044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8282084053851726,
            "auditor_fn_violation": 0.01415238678090575,
            "auditor_fp_violation": 0.02609599168764737,
            "ave_precision_score": 0.8274379521683388,
            "fpr": 0.17543859649122806,
            "logloss": 0.6577543113061807,
            "mae": 0.3162173778308636,
            "precision": 0.7014925373134329,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8844757979266855,
            "auditor_fn_violation": 0.015456730056071444,
            "auditor_fp_violation": 0.020715799147371913,
            "ave_precision_score": 0.8836294162430771,
            "fpr": 0.15916575192096596,
            "logloss": 0.5824829289904159,
            "mae": 0.2853261907979504,
            "precision": 0.7415329768270945,
            "recall": 0.8648648648648649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8311328100761204,
            "auditor_fn_violation": 0.006634583286970071,
            "auditor_fp_violation": 0.02407285297526276,
            "ave_precision_score": 0.8313762060635239,
            "fpr": 0.15570175438596492,
            "logloss": 0.7971610494985256,
            "mae": 0.28795997109839705,
            "precision": 0.7193675889328063,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8684061412293502,
            "auditor_fn_violation": 0.011143542427845394,
            "auditor_fp_violation": 0.018170678783856233,
            "ave_precision_score": 0.8687706252968114,
            "fpr": 0.14489571899012074,
            "logloss": 0.6939103007526991,
            "mae": 0.2569644158569185,
            "precision": 0.7476099426386233,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7197412492008757,
            "auditor_fn_violation": 0.04229257075034309,
            "auditor_fp_violation": 0.04399952044119411,
            "ave_precision_score": 0.7202283025685665,
            "fpr": 0.23793859649122806,
            "logloss": 0.7009708752821302,
            "mae": 0.4632424621940144,
            "precision": 0.6172839506172839,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7658618043305495,
            "auditor_fn_violation": 0.041534399382917496,
            "auditor_fp_violation": 0.04585301100247619,
            "ave_precision_score": 0.766247409361853,
            "fpr": 0.21844127332601537,
            "logloss": 0.6814066900627077,
            "mae": 0.4578125645999278,
            "precision": 0.6527050610820244,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8331616763905927,
            "auditor_fn_violation": 0.004066058380623866,
            "auditor_fp_violation": 0.017728689605562876,
            "ave_precision_score": 0.8345278860327568,
            "fpr": 0.18311403508771928,
            "logloss": 0.6786600757278076,
            "mae": 0.28780445360533385,
            "precision": 0.7059859154929577,
            "recall": 0.8477801268498943
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8978546906261938,
            "auditor_fn_violation": 0.005319598074812126,
            "auditor_fp_violation": 0.010724223317080646,
            "ave_precision_score": 0.8980373702632989,
            "fpr": 0.16794731064763996,
            "logloss": 0.5831428837858382,
            "mae": 0.25257315902193733,
            "precision": 0.7389078498293515,
            "recall": 0.9002079002079002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8087364786947423,
            "auditor_fn_violation": 0.01517933311078966,
            "auditor_fp_violation": 0.0420762898133717,
            "ave_precision_score": 0.8095967879690155,
            "fpr": 0.18201754385964913,
            "logloss": 0.6295611986463574,
            "mae": 0.32903628607956564,
            "precision": 0.7040998217468806,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.870676053932409,
            "auditor_fn_violation": 0.02439575436282352,
            "auditor_fp_violation": 0.035243662726878205,
            "ave_precision_score": 0.8709797134705377,
            "fpr": 0.15477497255762898,
            "logloss": 0.5895231719598569,
            "mae": 0.304814651271563,
            "precision": 0.7482142857142857,
            "recall": 0.8711018711018711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8373657048968225,
            "auditor_fn_violation": 0.0077519379844961265,
            "auditor_fp_violation": 0.010954921472245539,
            "ave_precision_score": 0.837703425019062,
            "fpr": 0.13048245614035087,
            "logloss": 0.6465927214840915,
            "mae": 0.28269009028439596,
            "precision": 0.7571428571428571,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8961614304719366,
            "auditor_fn_violation": 0.005579758598419412,
            "auditor_fp_violation": 0.010435759324024204,
            "ave_precision_score": 0.8963651075077956,
            "fpr": 0.11855104281009879,
            "logloss": 0.5417481721266451,
            "mae": 0.24537450364547406,
            "precision": 0.7915057915057915,
            "recall": 0.8523908523908524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8284426513478389,
            "auditor_fn_violation": 0.003688197767145138,
            "auditor_fp_violation": 0.015703053191064225,
            "ave_precision_score": 0.8298649924384863,
            "fpr": 0.20833333333333334,
            "logloss": 0.7232157849255738,
            "mae": 0.30361165275742397,
            "precision": 0.6822742474916388,
            "recall": 0.8625792811839323
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8957275207930646,
            "auditor_fn_violation": 0.005235160010132568,
            "auditor_fp_violation": 0.009100656064125804,
            "ave_precision_score": 0.8959052190807816,
            "fpr": 0.19209659714599342,
            "logloss": 0.6197947350252432,
            "mae": 0.26532164754869997,
            "precision": 0.7172859450726979,
            "recall": 0.9230769230769231
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8297196999899208,
            "auditor_fn_violation": 0.008377842068172544,
            "auditor_fp_violation": 0.014384266474843149,
            "ave_precision_score": 0.8310661160205837,
            "fpr": 0.11513157894736842,
            "logloss": 0.6493408892677254,
            "mae": 0.2833451623193315,
            "precision": 0.7732181425485961,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.8046103183315039,
            "auc_prc": 0.8947574634607951,
            "auditor_fn_violation": 0.012067796919608124,
            "auditor_fp_violation": 0.01064253439869298,
            "ave_precision_score": 0.8949764833076174,
            "fpr": 0.10647639956092206,
            "logloss": 0.5426893508543216,
            "mae": 0.24481422028989464,
            "precision": 0.8048289738430584,
            "recall": 0.8316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.830903146684755,
            "auditor_fn_violation": 0.003595471236230111,
            "auditor_fp_violation": 0.023748151700435607,
            "ave_precision_score": 0.8311531472986666,
            "fpr": 0.1524122807017544,
            "logloss": 0.7576710623991111,
            "mae": 0.2903000813990629,
            "precision": 0.7225548902195609,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8690842414846586,
            "auditor_fn_violation": 0.014181030646453263,
            "auditor_fp_violation": 0.01628672810354071,
            "ave_precision_score": 0.8693641127271106,
            "fpr": 0.14270032930845225,
            "logloss": 0.6294994559310562,
            "mae": 0.2595545626224511,
            "precision": 0.75,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6446645469060689,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.6462296584268747,
            "fpr": 0.47368421052631576,
            "logloss": 2.478589738313621,
            "mae": 0.47470040308373423,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6512313108041996,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.6517943491883782,
            "fpr": 0.4665203073545554,
            "logloss": 2.430962122235605,
            "mae": 0.466542908778432,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8246107200851449,
            "auditor_fn_violation": 0.018005174140425056,
            "auditor_fp_violation": 0.021872377412780242,
            "ave_precision_score": 0.8241521224500481,
            "fpr": 0.17653508771929824,
            "logloss": 0.6879465380047234,
            "mae": 0.32073963022865465,
            "precision": 0.7012987012987013,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.877455444205796,
            "auditor_fn_violation": 0.0192381860878019,
            "auditor_fp_violation": 0.0196410793148342,
            "ave_precision_score": 0.877264005725851,
            "fpr": 0.15477497255762898,
            "logloss": 0.6177653031735681,
            "mae": 0.2863274528765106,
            "precision": 0.7473118279569892,
            "recall": 0.8669438669438669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8290816224995113,
            "auditor_fn_violation": 0.0038875598086124423,
            "auditor_fp_violation": 0.0139421732006554,
            "ave_precision_score": 0.8305230305848723,
            "fpr": 0.19517543859649122,
            "logloss": 0.6955028069499162,
            "mae": 0.2978192742384036,
            "precision": 0.693631669535284,
            "recall": 0.8520084566596194
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8961856243890387,
            "auditor_fn_violation": 0.005488474204171241,
            "auditor_fp_violation": 0.006734230209583134,
            "ave_precision_score": 0.896369997987019,
            "fpr": 0.17672886937431395,
            "logloss": 0.5875325105694559,
            "mae": 0.25915961911725316,
            "precision": 0.7330016583747927,
            "recall": 0.918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8241140112781551,
            "auditor_fn_violation": 0.009358425132598939,
            "auditor_fp_violation": 0.026720417216161137,
            "ave_precision_score": 0.824426376329614,
            "fpr": 0.1611842105263158,
            "logloss": 0.7891997277073681,
            "mae": 0.29489839581566607,
            "precision": 0.7106299212598425,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8658657025084634,
            "auditor_fn_violation": 0.012884792248129242,
            "auditor_fp_violation": 0.014147499553263727,
            "ave_precision_score": 0.8660924384690557,
            "fpr": 0.14928649835345773,
            "logloss": 0.6878037256238588,
            "mae": 0.26434132284166,
            "precision": 0.7429111531190926,
            "recall": 0.817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 12669,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8369500756194426,
            "auditor_fn_violation": 0.005769908386187458,
            "auditor_fp_violation": 0.012388602485713142,
            "ave_precision_score": 0.8375462305411552,
            "fpr": 0.18201754385964913,
            "logloss": 0.6729278806064162,
            "mae": 0.2935557492286961,
            "precision": 0.7035714285714286,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8955492565331358,
            "auditor_fn_violation": 0.006437831904352212,
            "auditor_fp_violation": 0.004697112807290735,
            "ave_precision_score": 0.8957207407783538,
            "fpr": 0.16465422612513722,
            "logloss": 0.5649164757592944,
            "mae": 0.25417096135330025,
            "precision": 0.7435897435897436,
            "recall": 0.9043659043659044
        }
    }
]