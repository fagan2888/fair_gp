[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.254046296433057,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.7165244109582393,
            "auditor_fn_violation": 0.005072978088374457,
            "auditor_fp_violation": 0.0011729906160750714,
            "ave_precision_score": 0.5404715973890467,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6882372191001637,
            "mae": 0.4942135624587536,
            "precision": 0.8888888888888888,
            "recall": 0.03319502074688797
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7707968985469497,
            "auditor_fn_violation": 0.0034651807475487837,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5415937970938994,
            "fpr": 0.0,
            "logloss": 0.6785890918241785,
            "mae": 0.48958654258437007,
            "precision": 1.0,
            "recall": 0.048728813559322036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7563110577273058,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6357756424255661,
            "fpr": 0.47149122807017546,
            "logloss": 0.6599156346262913,
            "mae": 0.44647142735489626,
            "precision": 0.5285087719298246,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7667573986688614,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6438403994786684,
            "fpr": 0.4818880351262349,
            "logloss": 0.652999118180921,
            "mae": 0.4429196074817628,
            "precision": 0.5181119648737651,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.254046296433057,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7391651057503318,
            "auditor_fn_violation": 0.005284541748562273,
            "auditor_fp_violation": 0.0018359853121175031,
            "ave_precision_score": 0.5651080602079729,
            "fpr": 0.005482456140350877,
            "logloss": 0.6727001908173929,
            "mae": 0.48230974114777747,
            "precision": 0.9038461538461539,
            "recall": 0.0975103734439834
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7541469991780969,
            "auditor_fn_violation": 0.012186273232990395,
            "auditor_fp_violation": 0.0007626353677777807,
            "ave_precision_score": 0.5611354739294739,
            "fpr": 0.003293084522502744,
            "logloss": 0.6679163126348582,
            "mae": 0.48059152398753247,
            "precision": 0.9411764705882353,
            "recall": 0.1016949152542373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.7652325835335225,
            "auditor_fn_violation": 0.0011374390332678128,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5304651670670453,
            "fpr": 0.0,
            "logloss": 0.6922848198808114,
            "mae": 0.4992943473421691,
            "precision": 1.0,
            "recall": 0.004149377593360996
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.7626293047312508,
            "auditor_fn_violation": 0.002346555284749488,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5252586094625016,
            "fpr": 0.0,
            "logloss": 0.6886897587944806,
            "mae": 0.49685227354062245,
            "precision": 1.0,
            "recall": 0.014830508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6375194338247008,
            "auditor_fn_violation": 0.06335762903108394,
            "auditor_fp_violation": 0.059644022847817224,
            "ave_precision_score": 0.6391461409160568,
            "fpr": 0.19736842105263158,
            "logloss": 0.6548866519771949,
            "mae": 0.4330732107056272,
            "precision": 0.6597353497164461,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6782438783822298,
            "auditor_fn_violation": 0.05125676756776871,
            "auditor_fp_violation": 0.04759094739316229,
            "ave_precision_score": 0.6797011735452471,
            "fpr": 0.19209659714599342,
            "logloss": 0.6107382712290211,
            "mae": 0.4131305137225943,
            "precision": 0.6722846441947565,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7179709416725317,
            "auditor_fn_violation": 0.01504604353206668,
            "auditor_fp_violation": 0.010737964096287229,
            "ave_precision_score": 0.6411523620810444,
            "fpr": 0.13486842105263158,
            "logloss": 0.6449592571543888,
            "mae": 0.4592271050062488,
            "precision": 0.6573816155988857,
            "recall": 0.4896265560165975
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7006128859109961,
            "auditor_fn_violation": 0.0030512195575731695,
            "auditor_fp_violation": 0.004448289571398925,
            "ave_precision_score": 0.6259892555079435,
            "fpr": 0.1437980241492865,
            "logloss": 0.6369364781140692,
            "mae": 0.45669265228817413,
            "precision": 0.6158357771260997,
            "recall": 0.4449152542372881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7563110577273058,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6357756424255661,
            "fpr": 0.47149122807017546,
            "logloss": 0.6598786161657297,
            "mae": 0.4464535062250338,
            "precision": 0.5285087719298246,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7667573986688614,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6438403994786684,
            "fpr": 0.4818880351262349,
            "logloss": 0.6529525323229909,
            "mae": 0.4428968971961154,
            "precision": 0.5181119648737651,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7685919130834866,
            "auditor_fn_violation": 0.020096272839775792,
            "auditor_fp_violation": 0.009419624643002857,
            "ave_precision_score": 0.649725580001391,
            "fpr": 0.09978070175438597,
            "logloss": 0.7009002150407773,
            "mae": 0.4122958273806593,
            "precision": 0.7465181058495822,
            "recall": 0.5560165975103735
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7855505180472298,
            "auditor_fn_violation": 0.0074233939236078945,
            "auditor_fp_violation": 0.01687049451277602,
            "ave_precision_score": 0.6658305461942968,
            "fpr": 0.09330406147091108,
            "logloss": 0.677255395208563,
            "mae": 0.4024783234172281,
            "precision": 0.7671232876712328,
            "recall": 0.5932203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7167811805287236,
            "auditor_fn_violation": 0.0058555361432627365,
            "auditor_fp_violation": 0.0014152386780905753,
            "ave_precision_score": 0.5527239739949938,
            "fpr": 0.005482456140350877,
            "logloss": 0.6833873505859884,
            "mae": 0.48701868327171133,
            "precision": 0.8717948717948718,
            "recall": 0.07053941908713693
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7621264050095284,
            "auditor_fn_violation": 0.0072373439505851195,
            "auditor_fp_violation": 0.0005225927602149382,
            "ave_precision_score": 0.5507661272103401,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6734881729581125,
            "mae": 0.4844600564823716,
            "precision": 0.9714285714285714,
            "recall": 0.07203389830508475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.7165244109582393,
            "auditor_fn_violation": 0.005072978088374457,
            "auditor_fp_violation": 0.0011729906160750714,
            "ave_precision_score": 0.5404715973890467,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6882372191001637,
            "mae": 0.4942135624587536,
            "precision": 0.8888888888888888,
            "recall": 0.03319502074688797
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7707968985469497,
            "auditor_fn_violation": 0.0034651807475487837,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5415937970938994,
            "fpr": 0.0,
            "logloss": 0.6785890918241785,
            "mae": 0.48958654258437007,
            "precision": 1.0,
            "recall": 0.048728813559322036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7086017689451846,
            "auditor_fn_violation": 0.004326818082550772,
            "auditor_fp_violation": 0.0011729906160750714,
            "ave_precision_score": 0.5385728324961783,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6934959159035453,
            "mae": 0.49618580571392124,
            "precision": 0.875,
            "recall": 0.029045643153526972
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.7697759493199874,
            "auditor_fn_violation": 0.005697780423821843,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5395518986399748,
            "fpr": 0.0,
            "logloss": 0.6828564044351394,
            "mae": 0.4910096263780814,
            "precision": 1.0,
            "recall": 0.04449152542372881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7974472656500906,
            "auditor_fn_violation": 0.008194110795661378,
            "auditor_fp_violation": 0.0007904936760505917,
            "ave_precision_score": 0.6380968744781162,
            "fpr": 0.008771929824561403,
            "logloss": 0.621266541052746,
            "mae": 0.4440184014669636,
            "precision": 0.9411764705882353,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7908054103332156,
            "auditor_fn_violation": 0.007237343950585136,
            "auditor_fp_violation": 0.0010151801944845212,
            "ave_precision_score": 0.6203927798735553,
            "fpr": 0.006586169045005488,
            "logloss": 0.6276401650987927,
            "mae": 0.45004238853993717,
            "precision": 0.9491525423728814,
            "recall": 0.23728813559322035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.7375312183266978,
            "auditor_fn_violation": 0.0009963965931426232,
            "auditor_fp_violation": 0.0009434924520603837,
            "ave_precision_score": 0.5481553188749083,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6824078366516115,
            "mae": 0.49040312326529567,
            "precision": 0.9230769230769231,
            "recall": 0.04979253112033195
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7499635652136164,
            "auditor_fn_violation": 0.0052605629872183824,
            "auditor_fp_violation": 0.0005225927602149382,
            "ave_precision_score": 0.539563429862261,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6805174228926083,
            "mae": 0.49010405978177696,
            "precision": 0.9583333333333334,
            "recall": 0.048728813559322036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.8009331044300471,
            "auditor_fn_violation": 0.008194110795661378,
            "auditor_fp_violation": 0.00044879640962872347,
            "ave_precision_score": 0.6399482743280516,
            "fpr": 0.007675438596491228,
            "logloss": 0.6193499000970538,
            "mae": 0.4435367296989027,
            "precision": 0.9481481481481482,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7908054103332156,
            "auditor_fn_violation": 0.007237343950585136,
            "auditor_fp_violation": 0.0010151801944845212,
            "ave_precision_score": 0.6203927798735553,
            "fpr": 0.006586169045005488,
            "logloss": 0.6276401650987927,
            "mae": 0.45004238853993717,
            "precision": 0.9491525423728814,
            "recall": 0.23728813559322035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.7165244109582393,
            "auditor_fn_violation": 0.005072978088374457,
            "auditor_fp_violation": 0.0011729906160750714,
            "ave_precision_score": 0.5404715973890467,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6882372191001637,
            "mae": 0.4942135624587536,
            "precision": 0.8888888888888888,
            "recall": 0.03319502074688797
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7707968985469497,
            "auditor_fn_violation": 0.0034651807475487837,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5415937970938994,
            "fpr": 0.0,
            "logloss": 0.6785890918241785,
            "mae": 0.48958654258437007,
            "precision": 1.0,
            "recall": 0.048728813559322036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7711081679668172,
            "auditor_fn_violation": 0.011633726432263233,
            "auditor_fp_violation": 0.021889024887800885,
            "ave_precision_score": 0.618722134650007,
            "fpr": 0.37609649122807015,
            "logloss": 9.717528153101934,
            "mae": 0.4132862649799299,
            "precision": 0.5685534591194968,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7847442821526238,
            "auditor_fn_violation": 0.005402426091648218,
            "auditor_fp_violation": 0.014877640781238674,
            "ave_precision_score": 0.6368660780256759,
            "fpr": 0.38638858397365533,
            "logloss": 9.043985314222871,
            "mae": 0.40959524190079394,
            "precision": 0.563816604708798,
            "recall": 0.9639830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8147606653624402,
            "auditor_fn_violation": 0.014097419378321324,
            "auditor_fp_violation": 0.016600367197062427,
            "ave_precision_score": 0.8150510079456994,
            "fpr": 0.13706140350877194,
            "logloss": 1.1381435230778822,
            "mae": 0.28145144155451146,
            "precision": 0.7438524590163934,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8377084133549619,
            "auditor_fn_violation": 0.01184905765688664,
            "auditor_fp_violation": 0.01749560546997092,
            "ave_precision_score": 0.8379718923745211,
            "fpr": 0.12623490669593854,
            "logloss": 0.9291946768066175,
            "mae": 0.26055549069581413,
            "precision": 0.7584033613445378,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7740372302009912,
            "auditor_fn_violation": 0.008655911043168088,
            "auditor_fp_violation": 0.017671358629130975,
            "ave_precision_score": 0.6194722582083656,
            "fpr": 0.3618421052631579,
            "logloss": 9.689427027735794,
            "mae": 0.3885288259077143,
            "precision": 0.5838587641866331,
            "recall": 0.9605809128630706
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.790817894954764,
            "auditor_fn_violation": 0.0025116746358071784,
            "auditor_fp_violation": 0.016960510490612077,
            "ave_precision_score": 0.6420972991231526,
            "fpr": 0.36223929747530187,
            "logloss": 8.927384044546747,
            "mae": 0.37817271508217754,
            "precision": 0.5812182741116751,
            "recall": 0.9703389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8106005322316688,
            "auditor_fn_violation": 0.016033340612943148,
            "auditor_fp_violation": 0.016982864137086905,
            "ave_precision_score": 0.810889037243314,
            "fpr": 0.13157894736842105,
            "logloss": 1.1611517421672088,
            "mae": 0.28545865666589676,
            "precision": 0.7468354430379747,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8333942890645967,
            "auditor_fn_violation": 0.01143044521758545,
            "auditor_fp_violation": 0.01895836510980699,
            "ave_precision_score": 0.8336166879068098,
            "fpr": 0.12184412733260154,
            "logloss": 0.9473282220711966,
            "mae": 0.26587204251190644,
            "precision": 0.75764192139738,
            "recall": 0.7351694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8072654980371985,
            "auditor_fn_violation": 0.01568300939069666,
            "auditor_fp_violation": 0.016625866993064054,
            "ave_precision_score": 0.8077298120760179,
            "fpr": 0.1337719298245614,
            "logloss": 1.1607440833490186,
            "mae": 0.28707689433906586,
            "precision": 0.7442348008385744,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8299203287554329,
            "auditor_fn_violation": 0.010046698543228719,
            "auditor_fp_violation": 0.016595445691610262,
            "ave_precision_score": 0.8302088739128441,
            "fpr": 0.1251372118551043,
            "logloss": 0.9516202909258435,
            "mae": 0.26802954384205746,
            "precision": 0.7532467532467533,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7136180572155868,
            "auditor_fn_violation": 0.009995814224357592,
            "auditor_fp_violation": 0.007257241942064464,
            "ave_precision_score": 0.7141571443132082,
            "fpr": 0.041666666666666664,
            "logloss": 2.285804756320417,
            "mae": 0.4138971454079819,
            "precision": 0.8051282051282052,
            "recall": 0.3257261410788382
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.7161448594217339,
            "auditor_fn_violation": 0.006704775902807512,
            "auditor_fp_violation": 0.00562349817092534,
            "ave_precision_score": 0.7166521740319007,
            "fpr": 0.03951701427003293,
            "logloss": 2.2571355937659265,
            "mae": 0.4096407381099486,
            "precision": 0.8011049723756906,
            "recall": 0.3072033898305085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7734146091960077,
            "auditor_fn_violation": 0.013540074252020091,
            "auditor_fp_violation": 0.02468380252957977,
            "ave_precision_score": 0.6206186295096655,
            "fpr": 0.32346491228070173,
            "logloss": 9.501137491543647,
            "mae": 0.37100251920192245,
            "precision": 0.5986394557823129,
            "recall": 0.9128630705394191
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7893764770992259,
            "auditor_fn_violation": 0.008888537461162067,
            "auditor_fp_violation": 0.027117313323114862,
            "ave_precision_score": 0.6452614516570631,
            "fpr": 0.29088913282107576,
            "logloss": 8.419761267166871,
            "mae": 0.3312414999694881,
            "precision": 0.6230440967283073,
            "recall": 0.9279661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7698566638096772,
            "auditor_fn_violation": 0.007052122006260464,
            "auditor_fp_violation": 0.017265911872705025,
            "ave_precision_score": 0.6092148753863512,
            "fpr": 0.38048245614035087,
            "logloss": 10.306206781383416,
            "mae": 0.40541747274784046,
            "precision": 0.5731857318573186,
            "recall": 0.966804979253112
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7864754352958516,
            "auditor_fn_violation": 0.004641946826917711,
            "auditor_fp_violation": 0.011249496785679465,
            "ave_precision_score": 0.6349780427515883,
            "fpr": 0.3787047200878156,
            "logloss": 9.276022993381087,
            "mae": 0.39644117312023835,
            "precision": 0.5714285714285714,
            "recall": 0.9745762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7733438543198842,
            "auditor_fn_violation": 0.01086254276770765,
            "auditor_fp_violation": 0.02214402284781722,
            "ave_precision_score": 0.6226181862825823,
            "fpr": 0.30043859649122806,
            "logloss": 9.221638419389793,
            "mae": 0.3602657127174845,
            "precision": 0.6124469589816125,
            "recall": 0.8983402489626556
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.786597621258968,
            "auditor_fn_violation": 0.00820480381030345,
            "auditor_fp_violation": 0.028855121784116686,
            "ave_precision_score": 0.6396932024815035,
            "fpr": 0.2810098792535675,
            "logloss": 8.471411085118332,
            "mae": 0.33229099936996737,
            "precision": 0.6257309941520468,
            "recall": 0.9067796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.781262884392142,
            "auditor_fn_violation": 0.013872206449734296,
            "auditor_fp_violation": 0.01850010199918401,
            "ave_precision_score": 0.781581520392816,
            "fpr": 0.13267543859649122,
            "logloss": 1.4340987189688856,
            "mae": 0.3034871716143675,
            "precision": 0.7363834422657952,
            "recall": 0.7012448132780082
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7692798212818399,
            "auditor_fn_violation": 0.007535023907421546,
            "auditor_fp_violation": 0.016862993181289684,
            "ave_precision_score": 0.7695920157977176,
            "fpr": 0.13391877058177826,
            "logloss": 1.4039802840910822,
            "mae": 0.3072845813543019,
            "precision": 0.7239819004524887,
            "recall": 0.6779661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7720120477543133,
            "auditor_fn_violation": 0.017721300138312582,
            "auditor_fp_violation": 0.018742350061199512,
            "ave_precision_score": 0.7057124831703925,
            "fpr": 0.18311403508771928,
            "logloss": 6.058156192778573,
            "mae": 0.3316082356618946,
            "precision": 0.6901669758812616,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.791721081201714,
            "auditor_fn_violation": 0.007460603918212434,
            "auditor_fp_violation": 0.02664222899564673,
            "ave_precision_score": 0.7281659407861037,
            "fpr": 0.18111964873765093,
            "logloss": 5.100066443215478,
            "mae": 0.30678981871919153,
            "precision": 0.6950092421441775,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7707777529493192,
            "auditor_fn_violation": 0.012730217660333406,
            "auditor_fp_violation": 0.022985516115871088,
            "ave_precision_score": 0.6179832764063848,
            "fpr": 0.37609649122807015,
            "logloss": 9.74229299602145,
            "mae": 0.41267704068404387,
            "precision": 0.5685534591194968,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7847930351240732,
            "auditor_fn_violation": 0.005023349271614356,
            "auditor_fp_violation": 0.015540258395865267,
            "ave_precision_score": 0.6369137641654614,
            "fpr": 0.38638858397365533,
            "logloss": 9.032222851715066,
            "mae": 0.4089942506873007,
            "precision": 0.5643564356435643,
            "recall": 0.9661016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8073989926889262,
            "auditor_fn_violation": 0.017675802576981873,
            "auditor_fp_violation": 0.015177478580171362,
            "ave_precision_score": 0.8077306022171529,
            "fpr": 0.12719298245614036,
            "logloss": 1.1879098664184433,
            "mae": 0.2851564615015869,
            "precision": 0.75,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8260931789457988,
            "auditor_fn_violation": 0.0076233976446073515,
            "auditor_fp_violation": 0.01800569601104196,
            "ave_precision_score": 0.8263956555984904,
            "fpr": 0.11964873765093303,
            "logloss": 0.9891477084058978,
            "mae": 0.2699695226819158,
            "precision": 0.7577777777777778,
            "recall": 0.722457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7698596013359394,
            "auditor_fn_violation": 0.016738552813569195,
            "auditor_fp_violation": 0.017819257445940446,
            "ave_precision_score": 0.6111032207761844,
            "fpr": 0.34868421052631576,
            "logloss": 9.910133812265386,
            "mae": 0.3921567767148554,
            "precision": 0.5804749340369393,
            "recall": 0.9128630705394191
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7841507094951663,
            "auditor_fn_violation": 0.008046661333234107,
            "auditor_fp_violation": 0.023266629826794255,
            "ave_precision_score": 0.6332080167557299,
            "fpr": 0.3216245883644347,
            "logloss": 8.836061168310632,
            "mae": 0.35752689101942126,
            "precision": 0.6024423337856174,
            "recall": 0.940677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7683768349736565,
            "auditor_fn_violation": 0.012175147412098712,
            "auditor_fp_violation": 0.016763565891472872,
            "ave_precision_score": 0.6164020358393152,
            "fpr": 0.40460526315789475,
            "logloss": 10.133617649997676,
            "mae": 0.44584100238031416,
            "precision": 0.5505481120584653,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7796752049771924,
            "auditor_fn_violation": 0.0057140597964613305,
            "auditor_fp_violation": 0.013862460586754157,
            "ave_precision_score": 0.6317978435722563,
            "fpr": 0.4226125137211855,
            "logloss": 9.623242552443001,
            "mae": 0.4502566619977611,
            "precision": 0.5383693045563549,
            "recall": 0.951271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.7759848863185126,
            "auditor_fn_violation": 0.005832787362597366,
            "auditor_fp_violation": 0.013769889840881277,
            "ave_precision_score": 0.6198742226148133,
            "fpr": 0.39144736842105265,
            "logloss": 9.945276313837507,
            "mae": 0.4082782253077316,
            "precision": 0.5672727272727273,
            "recall": 0.970954356846473
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7913716691559184,
            "auditor_fn_violation": 0.0021698078103778683,
            "auditor_fp_violation": 0.015782801447256897,
            "ave_precision_score": 0.6413650323255647,
            "fpr": 0.3973655323819978,
            "logloss": 9.270834253549449,
            "mae": 0.40292700139319815,
            "precision": 0.5612121212121212,
            "recall": 0.9809322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7816980100702616,
            "auditor_fn_violation": 0.012957705466986975,
            "auditor_fp_violation": 0.01850010199918401,
            "ave_precision_score": 0.7820709301326063,
            "fpr": 0.13267543859649122,
            "logloss": 1.4235832263167287,
            "mae": 0.30306726211177387,
            "precision": 0.7369565217391304,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7694548050311806,
            "auditor_fn_violation": 0.008055963831885254,
            "auditor_fp_violation": 0.01778315651028058,
            "ave_precision_score": 0.7697324405052293,
            "fpr": 0.1350164654226125,
            "logloss": 1.394932490468743,
            "mae": 0.30689519944578403,
            "precision": 0.722972972972973,
            "recall": 0.6800847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6870787696437253,
            "auditor_fn_violation": 0.07164046007134019,
            "auditor_fp_violation": 0.05806303549571604,
            "ave_precision_score": 0.6887719848980018,
            "fpr": 0.19956140350877194,
            "logloss": 0.6448566673599897,
            "mae": 0.4440473572824869,
            "precision": 0.6513409961685823,
            "recall": 0.7053941908713693
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6910668707630189,
            "auditor_fn_violation": 0.06120113862583491,
            "auditor_fp_violation": 0.05537232858832442,
            "ave_precision_score": 0.6922632222945532,
            "fpr": 0.18660812294182216,
            "logloss": 0.6169804208647756,
            "mae": 0.43057710932553406,
            "precision": 0.6705426356589147,
            "recall": 0.7330508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7708487474860067,
            "auditor_fn_violation": 0.009272402999199243,
            "auditor_fp_violation": 0.016396368829049362,
            "ave_precision_score": 0.6113019796538941,
            "fpr": 0.35635964912280704,
            "logloss": 10.03076363260704,
            "mae": 0.38395818500503803,
            "precision": 0.5859872611464968,
            "recall": 0.9543568464730291
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.786970003624222,
            "auditor_fn_violation": 0.0060373216245883645,
            "auditor_fp_violation": 0.022311460284200463,
            "ave_precision_score": 0.6353169751318605,
            "fpr": 0.33699231613611413,
            "logloss": 8.974886103837395,
            "mae": 0.3579969390981642,
            "precision": 0.5971128608923885,
            "recall": 0.9639830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7751906162155647,
            "auditor_fn_violation": 0.011565480090267163,
            "auditor_fp_violation": 0.01889534883720931,
            "ave_precision_score": 0.622395256771129,
            "fpr": 0.3399122807017544,
            "logloss": 9.455102282213076,
            "mae": 0.37115664085538363,
            "precision": 0.5963541666666666,
            "recall": 0.950207468879668
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7910324999834578,
            "auditor_fn_violation": 0.00520939924463711,
            "auditor_fp_violation": 0.022594010436852552,
            "ave_precision_score": 0.6428892543470865,
            "fpr": 0.3336992316136114,
            "logloss": 8.690633476985944,
            "mae": 0.35614016872849363,
            "precision": 0.5978835978835979,
            "recall": 0.9576271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7761771679993243,
            "auditor_fn_violation": 0.0050525041857756425,
            "auditor_fp_violation": 0.014764381884944921,
            "ave_precision_score": 0.6195161287300891,
            "fpr": 0.3969298245614035,
            "logloss": 9.998055619625912,
            "mae": 0.4112388938995586,
            "precision": 0.5643802647412756,
            "recall": 0.9730290456431535
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7913511881599878,
            "auditor_fn_violation": 0.0021698078103778683,
            "auditor_fp_violation": 0.0156727819187906,
            "ave_precision_score": 0.6413395710913394,
            "fpr": 0.39846322722283206,
            "logloss": 9.315738097097013,
            "mae": 0.4060410959656724,
            "precision": 0.5605326876513317,
            "recall": 0.9809322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7761761925225714,
            "auditor_fn_violation": 0.0050525041857756425,
            "auditor_fp_violation": 0.014764381884944921,
            "ave_precision_score": 0.6195141777765832,
            "fpr": 0.3969298245614035,
            "logloss": 9.99835032721043,
            "mae": 0.4112520920648218,
            "precision": 0.5643802647412756,
            "recall": 0.9730290456431535
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7913522538607816,
            "auditor_fn_violation": 0.0021698078103778683,
            "auditor_fp_violation": 0.0156727819187906,
            "ave_precision_score": 0.6413417024929269,
            "fpr": 0.39846322722283206,
            "logloss": 9.316093372417914,
            "mae": 0.40604387962487165,
            "precision": 0.5605326876513317,
            "recall": 0.9809322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7817842350610421,
            "auditor_fn_violation": 0.013378557909296065,
            "auditor_fp_violation": 0.014937780497756027,
            "ave_precision_score": 0.782037724080102,
            "fpr": 0.1337719298245614,
            "logloss": 1.4192627604806247,
            "mae": 0.3034791689818744,
            "precision": 0.7365010799136069,
            "recall": 0.7074688796680498
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7690736831228817,
            "auditor_fn_violation": 0.008521088764442125,
            "auditor_fp_violation": 0.01611786092031336,
            "ave_precision_score": 0.7694548551413806,
            "fpr": 0.13611416026344675,
            "logloss": 1.391079394279791,
            "mae": 0.3068641029475274,
            "precision": 0.7232142857142857,
            "recall": 0.6864406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6379930115475136,
            "auditor_fn_violation": 0.016488316226250282,
            "auditor_fp_violation": 0.020996532027743788,
            "ave_precision_score": 0.5512772199987204,
            "fpr": 0.1875,
            "logloss": 14.237812368525736,
            "mae": 0.47915951102699406,
            "precision": 0.5581395348837209,
            "recall": 0.44813278008298757
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.644770825643166,
            "auditor_fn_violation": 0.01187929077750285,
            "auditor_fp_violation": 0.022123926997041972,
            "ave_precision_score": 0.5598086404255243,
            "fpr": 0.17233809001097694,
            "logloss": 13.310083580209408,
            "mae": 0.4602564682913696,
            "precision": 0.5745257452574526,
            "recall": 0.4491525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7711583863240102,
            "auditor_fn_violation": 0.01181116692145301,
            "auditor_fp_violation": 0.023383312933496533,
            "ave_precision_score": 0.6182192435535145,
            "fpr": 0.38377192982456143,
            "logloss": 9.879154277958238,
            "mae": 0.41888442311263996,
            "precision": 0.564134495641345,
            "recall": 0.9398340248962656
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7841942764836473,
            "auditor_fn_violation": 0.0044465943552438195,
            "auditor_fp_violation": 0.012729759532317,
            "ave_precision_score": 0.6363139645920959,
            "fpr": 0.39626783754116357,
            "logloss": 9.222158662079488,
            "mae": 0.4176353940833789,
            "precision": 0.5570552147239264,
            "recall": 0.961864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6416051337755737,
            "auditor_fn_violation": 0.014065571085389826,
            "auditor_fp_violation": 0.017503059975520194,
            "ave_precision_score": 0.5550643522709422,
            "fpr": 0.19956140350877194,
            "logloss": 13.98994792843809,
            "mae": 0.4610870801287966,
            "precision": 0.5757575757575758,
            "recall": 0.5124481327800829
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6494116945278381,
            "auditor_fn_violation": 0.012632793168244992,
            "auditor_fp_violation": 0.01887835090728604,
            "ave_precision_score": 0.5642460013085682,
            "fpr": 0.1986827661909989,
            "logloss": 13.265707844748855,
            "mae": 0.4488720182094782,
            "precision": 0.5741176470588235,
            "recall": 0.5169491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 22727,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7762864769820671,
            "auditor_fn_violation": 0.011497233748271095,
            "auditor_fp_violation": 0.02247042023663812,
            "ave_precision_score": 0.6239004228717782,
            "fpr": 0.32785087719298245,
            "logloss": 9.345764517417164,
            "mae": 0.3579499857549672,
            "precision": 0.6039735099337749,
            "recall": 0.946058091286307
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7898625897661247,
            "auditor_fn_violation": 0.004646598076243279,
            "auditor_fp_violation": 0.029322704780098473,
            "ave_precision_score": 0.6421174813442991,
            "fpr": 0.30735455543358947,
            "logloss": 8.59039353512641,
            "mae": 0.33899958357263404,
            "precision": 0.6169630642954856,
            "recall": 0.9555084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7702714621593498,
            "auditor_fn_violation": 0.011044533013030502,
            "auditor_fp_violation": 0.0157843737250102,
            "ave_precision_score": 0.6101790101420552,
            "fpr": 0.37280701754385964,
            "logloss": 10.145922071630538,
            "mae": 0.3965544054964816,
            "precision": 0.574468085106383,
            "recall": 0.9522821576763485
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7859755890265668,
            "auditor_fn_violation": 0.005009395523637649,
            "auditor_fp_violation": 0.017178049103715908,
            "ave_precision_score": 0.634755579939152,
            "fpr": 0.3578485181119649,
            "logloss": 9.089464644465505,
            "mae": 0.37804265228434314,
            "precision": 0.5836526181353767,
            "recall": 0.9682203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6561648842306578,
            "auditor_fn_violation": 0.012566426439542845,
            "auditor_fp_violation": 0.02084353325173399,
            "ave_precision_score": 0.560726184574567,
            "fpr": 0.20175438596491227,
            "logloss": 14.11582023264863,
            "mae": 0.45392801208532574,
            "precision": 0.5808656036446469,
            "recall": 0.529045643153527
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6630337129864514,
            "auditor_fn_violation": 0.010530428473087869,
            "auditor_fp_violation": 0.018273243500721386,
            "ave_precision_score": 0.5666381730084704,
            "fpr": 0.2030735455543359,
            "logloss": 13.5415292470523,
            "mae": 0.4489166999001455,
            "precision": 0.5707656612529002,
            "recall": 0.5211864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7741126380351565,
            "auditor_fn_violation": 0.008963019582150396,
            "auditor_fp_violation": 0.02184312525499796,
            "ave_precision_score": 0.6203592624102316,
            "fpr": 0.3355263157894737,
            "logloss": 9.710973588984938,
            "mae": 0.3728104418294916,
            "precision": 0.5973684210526315,
            "recall": 0.941908713692946
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7857960903685991,
            "auditor_fn_violation": 0.004186124393011963,
            "auditor_fp_violation": 0.021286278314400817,
            "ave_precision_score": 0.6387583174122873,
            "fpr": 0.32930845225027444,
            "logloss": 8.83193035745989,
            "mae": 0.3609277960728023,
            "precision": 0.5956873315363881,
            "recall": 0.9364406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7666848521955654,
            "auditor_fn_violation": 0.007857428841814078,
            "auditor_fp_violation": 0.01754385964912282,
            "ave_precision_score": 0.6042607689960258,
            "fpr": 0.37719298245614036,
            "logloss": 10.638667523644452,
            "mae": 0.402319016898266,
            "precision": 0.5732009925558312,
            "recall": 0.9585062240663901
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7798920616703607,
            "auditor_fn_violation": 0.005525684198775791,
            "auditor_fp_violation": 0.01331236294442264,
            "ave_precision_score": 0.6266591623405069,
            "fpr": 0.36443468715697036,
            "logloss": 9.524648969178335,
            "mae": 0.3916369337920528,
            "precision": 0.5759897828863346,
            "recall": 0.9555084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7974472656500906,
            "auditor_fn_violation": 0.008194110795661378,
            "auditor_fp_violation": 0.0007088943288453695,
            "ave_precision_score": 0.6380968744781162,
            "fpr": 0.008771929824561403,
            "logloss": 0.6208242598506911,
            "mae": 0.44297149685914056,
            "precision": 0.9411764705882353,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7936808736662733,
            "auditor_fn_violation": 0.008307131295465979,
            "auditor_fp_violation": 0.0010151801944845212,
            "ave_precision_score": 0.6244553844539693,
            "fpr": 0.006586169045005488,
            "logloss": 0.6241381259916201,
            "mae": 0.4470546596594621,
            "precision": 0.9508196721311475,
            "recall": 0.2457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8145088226679144,
            "auditor_fn_violation": 0.013590121569483879,
            "auditor_fp_violation": 0.016600367197062427,
            "ave_precision_score": 0.8147960909559445,
            "fpr": 0.13706140350877194,
            "logloss": 1.1402057303777196,
            "mae": 0.28135161750992344,
            "precision": 0.7448979591836735,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8378381913884869,
            "auditor_fn_violation": 0.01184905765688664,
            "auditor_fp_violation": 0.015882819200408075,
            "ave_precision_score": 0.838102838068659,
            "fpr": 0.12733260153677278,
            "logloss": 0.9307164276304842,
            "mae": 0.2604795500580763,
            "precision": 0.7568134171907757,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.8009331044300471,
            "auditor_fn_violation": 0.008194110795661378,
            "auditor_fp_violation": 0.00044879640962872347,
            "ave_precision_score": 0.6399482743280516,
            "fpr": 0.007675438596491228,
            "logloss": 0.6193499000970538,
            "mae": 0.4435367296989027,
            "precision": 0.9481481481481482,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7908054103332156,
            "auditor_fn_violation": 0.007237343950585136,
            "auditor_fp_violation": 0.0010151801944845212,
            "ave_precision_score": 0.6203927798735553,
            "fpr": 0.006586169045005488,
            "logloss": 0.6276401650987927,
            "mae": 0.45004238853993717,
            "precision": 0.9491525423728814,
            "recall": 0.23728813559322035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7729318699427331,
            "auditor_fn_violation": 0.015314479143917885,
            "auditor_fp_violation": 0.019354345165238675,
            "ave_precision_score": 0.6187733241179288,
            "fpr": 0.32894736842105265,
            "logloss": 9.466664139400187,
            "mae": 0.3775968756277578,
            "precision": 0.5951417004048583,
            "recall": 0.9149377593360996
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7883368812496417,
            "auditor_fn_violation": 0.00775828387504884,
            "auditor_fp_violation": 0.02479190056234984,
            "ave_precision_score": 0.6400157931444622,
            "fpr": 0.30954994511525796,
            "logloss": 8.567628820447494,
            "mae": 0.3447512486489992,
            "precision": 0.6104972375690608,
            "recall": 0.9364406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7090349473834031,
            "auditor_fn_violation": 0.010823869840576551,
            "auditor_fp_violation": 0.007027743778049777,
            "ave_precision_score": 0.7095383439191995,
            "fpr": 0.04276315789473684,
            "logloss": 2.3685892287336365,
            "mae": 0.41587010992706586,
            "precision": 0.7947368421052632,
            "recall": 0.3132780082987552
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.711660351465051,
            "auditor_fn_violation": 0.004837299298591629,
            "auditor_fp_violation": 0.0030105343698506497,
            "ave_precision_score": 0.7121345982980349,
            "fpr": 0.038419319429198684,
            "logloss": 2.3447649763542655,
            "mae": 0.4095418667585281,
            "precision": 0.8044692737430168,
            "recall": 0.3050847457627119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7086017689451846,
            "auditor_fn_violation": 0.004326818082550772,
            "auditor_fp_violation": 0.0011729906160750714,
            "ave_precision_score": 0.5385728324961783,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6934959159035453,
            "mae": 0.49618580571392124,
            "precision": 0.875,
            "recall": 0.029045643153526972
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.7697759493199874,
            "auditor_fn_violation": 0.005697780423821843,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5395518986399748,
            "fpr": 0.0,
            "logloss": 0.6828564044351394,
            "mae": 0.4910096263780814,
            "precision": 1.0,
            "recall": 0.04449152542372881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.770852276020272,
            "auditor_fn_violation": 0.009272402999199243,
            "auditor_fp_violation": 0.016396368829049362,
            "ave_precision_score": 0.6113074516029416,
            "fpr": 0.35635964912280704,
            "logloss": 10.029937987070976,
            "mae": 0.38398774965636134,
            "precision": 0.5859872611464968,
            "recall": 0.9543568464730291
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7869583759155698,
            "auditor_fn_violation": 0.0060373216245883645,
            "auditor_fp_violation": 0.022138929660014666,
            "ave_precision_score": 0.6353053507909546,
            "fpr": 0.3358946212952799,
            "logloss": 8.974200822499796,
            "mae": 0.3581617397569612,
            "precision": 0.5978975032851511,
            "recall": 0.9639830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7780030516999669,
            "auditor_fn_violation": 0.0034259663682026644,
            "auditor_fp_violation": 0.010041819665442684,
            "ave_precision_score": 0.6167912299293882,
            "fpr": 0.4342105263157895,
            "logloss": 10.67466929282745,
            "mae": 0.44042965565097963,
            "precision": 0.5453501722158438,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7935572759632428,
            "auditor_fn_violation": 0.0009558317364043985,
            "auditor_fp_violation": 0.01283977906078329,
            "ave_precision_score": 0.6349303916269773,
            "fpr": 0.43029637760702527,
            "logloss": 10.186049256079672,
            "mae": 0.43365086377451706,
            "precision": 0.5425904317386231,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7469967023257758,
            "auditor_fn_violation": 0.08769654946494869,
            "auditor_fp_violation": 0.057736638106895145,
            "ave_precision_score": 0.6290590471541581,
            "fpr": 0.17763157894736842,
            "logloss": 0.651135519176187,
            "mae": 0.4395833082104984,
            "precision": 0.6531049250535332,
            "recall": 0.6327800829875518
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7728428682465831,
            "auditor_fn_violation": 0.07474557666189138,
            "auditor_fp_violation": 0.05231678622955575,
            "ave_precision_score": 0.6556923228997582,
            "fpr": 0.16245883644346873,
            "logloss": 0.6144389747713007,
            "mae": 0.42111727644400065,
            "precision": 0.6844349680170576,
            "recall": 0.6800847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6375555503266914,
            "auditor_fn_violation": 0.01743921525806217,
            "auditor_fp_violation": 0.021442778457772343,
            "ave_precision_score": 0.5526430309505956,
            "fpr": 0.19846491228070176,
            "logloss": 13.869523743363006,
            "mae": 0.46850366382793096,
            "precision": 0.565947242206235,
            "recall": 0.4896265560165975
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6468011837899756,
            "auditor_fn_violation": 0.014111890453775882,
            "auditor_fp_violation": 0.020603657149143972,
            "ave_precision_score": 0.5629097018393359,
            "fpr": 0.1877058177826564,
            "logloss": 13.020597817695737,
            "mae": 0.4494693185064924,
            "precision": 0.5777777777777777,
            "recall": 0.4957627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 22727,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7751920776471052,
            "auditor_fn_violation": 0.011565480090267163,
            "auditor_fp_violation": 0.01808445532435741,
            "ave_precision_score": 0.6223977463879213,
            "fpr": 0.34210526315789475,
            "logloss": 9.453179260630899,
            "mae": 0.37143463753981054,
            "precision": 0.5948051948051948,
            "recall": 0.950207468879668
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7910303702541239,
            "auditor_fn_violation": 0.00520939924463711,
            "auditor_fp_violation": 0.023054092101347998,
            "ave_precision_score": 0.642885852739331,
            "fpr": 0.33260153677277715,
            "logloss": 8.68888246093607,
            "mae": 0.3562528276387027,
            "precision": 0.5986754966887418,
            "recall": 0.9576271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7723429460322346,
            "auditor_fn_violation": 0.01583315134308801,
            "auditor_fp_violation": 0.01890554875560997,
            "ave_precision_score": 0.6181845167853027,
            "fpr": 0.33771929824561403,
            "logloss": 9.4990414746604,
            "mae": 0.38277257467387266,
            "precision": 0.5882352941176471,
            "recall": 0.9128630705394191
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7876107622813139,
            "auditor_fn_violation": 0.008442017525907458,
            "auditor_fp_violation": 0.02154882491642267,
            "ave_precision_score": 0.6392898527286958,
            "fpr": 0.3150384193194292,
            "logloss": 8.602256837792394,
            "mae": 0.352152184177451,
            "precision": 0.6084583901773534,
            "recall": 0.9449152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7469967023257758,
            "auditor_fn_violation": 0.08769654946494869,
            "auditor_fp_violation": 0.057736638106895145,
            "ave_precision_score": 0.6290590471541581,
            "fpr": 0.17763157894736842,
            "logloss": 0.651135519176187,
            "mae": 0.4395833082104984,
            "precision": 0.6531049250535332,
            "recall": 0.6327800829875518
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7728428682465831,
            "auditor_fn_violation": 0.07474557666189138,
            "auditor_fp_violation": 0.05231678622955575,
            "ave_precision_score": 0.6556923228997582,
            "fpr": 0.16245883644346873,
            "logloss": 0.6144389747713007,
            "mae": 0.42111727644400065,
            "precision": 0.6844349680170576,
            "recall": 0.6800847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.7448510409842033,
            "auditor_fn_violation": 0.004763594671325631,
            "auditor_fp_violation": 0.0007930436556507548,
            "ave_precision_score": 0.5589448205576182,
            "fpr": 0.003289473684210526,
            "logloss": 0.6817101161978589,
            "mae": 0.4847636619550094,
            "precision": 0.925,
            "recall": 0.07676348547717843
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7602396549167652,
            "auditor_fn_violation": 0.005730339169100825,
            "auditor_fp_violation": 0.0005801029682768691,
            "ave_precision_score": 0.5487278974041518,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6788265524981375,
            "mae": 0.48527161448245254,
            "precision": 0.9696969696969697,
            "recall": 0.06779661016949153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.775335711280924,
            "auditor_fn_violation": 0.010250600567809567,
            "auditor_fp_violation": 0.020093839249286014,
            "ave_precision_score": 0.6225413464974996,
            "fpr": 0.3344298245614035,
            "logloss": 9.437128919870378,
            "mae": 0.36777582646305246,
            "precision": 0.6002621231979031,
            "recall": 0.950207468879668
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7904380537881368,
            "auditor_fn_violation": 0.005890807270832945,
            "auditor_fp_violation": 0.027059803115052926,
            "ave_precision_score": 0.6424271063085599,
            "fpr": 0.3238199780461032,
            "logloss": 8.670950336002548,
            "mae": 0.3523168730769266,
            "precision": 0.6045576407506702,
            "recall": 0.9555084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6440947978702438,
            "auditor_fn_violation": 0.012175147412098715,
            "auditor_fp_violation": 0.02266421868625052,
            "ave_precision_score": 0.5570632517511174,
            "fpr": 0.20065789473684212,
            "logloss": 13.797761210896025,
            "mae": 0.4582482745434903,
            "precision": 0.5773672055427251,
            "recall": 0.5186721991701245
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6500773772030222,
            "auditor_fn_violation": 0.009916463562112784,
            "auditor_fp_violation": 0.024089275846462754,
            "ave_precision_score": 0.564715751563084,
            "fpr": 0.1942919868276619,
            "logloss": 13.083620594281825,
            "mae": 0.44523532852051984,
            "precision": 0.580568720379147,
            "recall": 0.5190677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6440241832814296,
            "auditor_fn_violation": 0.012175147412098715,
            "auditor_fp_violation": 0.02266421868625052,
            "ave_precision_score": 0.5567317097171497,
            "fpr": 0.20065789473684212,
            "logloss": 13.811095623743086,
            "mae": 0.4585553734510659,
            "precision": 0.5773672055427251,
            "recall": 0.5186721991701245
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6505446424211276,
            "auditor_fn_violation": 0.009916463562112784,
            "auditor_fp_violation": 0.024089275846462754,
            "ave_precision_score": 0.5644662929646347,
            "fpr": 0.1942919868276619,
            "logloss": 13.091586243630246,
            "mae": 0.44555373772104423,
            "precision": 0.580568720379147,
            "recall": 0.5190677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.781877047995144,
            "auditor_fn_violation": 0.01465703938268909,
            "auditor_fp_violation": 0.01397388820889433,
            "ave_precision_score": 0.7821853273513086,
            "fpr": 0.1337719298245614,
            "logloss": 1.4280999256370945,
            "mae": 0.30290966641459927,
            "precision": 0.735357917570499,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7694156302614088,
            "auditor_fn_violation": 0.008055963831885254,
            "auditor_fp_violation": 0.01739058682916218,
            "ave_precision_score": 0.7696982445751506,
            "fpr": 0.132821075740944,
            "logloss": 1.3980924821449774,
            "mae": 0.30673072422071357,
            "precision": 0.7262443438914027,
            "recall": 0.6800847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8046190673404774,
            "auditor_fn_violation": 0.013185193273640537,
            "auditor_fp_violation": 0.014993880048959612,
            "ave_precision_score": 0.8048754117310655,
            "fpr": 0.125,
            "logloss": 1.2208409919627246,
            "mae": 0.2855064711270815,
            "precision": 0.7543103448275862,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8076170559736859,
            "auditor_fn_violation": 0.004797763679324271,
            "auditor_fp_violation": 0.022231446081679502,
            "ave_precision_score": 0.8079595393892719,
            "fpr": 0.12403951701427003,
            "logloss": 1.109596291932557,
            "mae": 0.28259566968398114,
            "precision": 0.7454954954954955,
            "recall": 0.701271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6414569683329596,
            "auditor_fn_violation": 0.01267562058673656,
            "auditor_fp_violation": 0.02266421868625052,
            "ave_precision_score": 0.5552831061450751,
            "fpr": 0.20065789473684212,
            "logloss": 13.878014249672448,
            "mae": 0.4612860893421117,
            "precision": 0.572429906542056,
            "recall": 0.508298755186722
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6479823634165134,
            "auditor_fn_violation": 0.012014177007944335,
            "auditor_fp_violation": 0.019783511573304272,
            "ave_precision_score": 0.5631505860585924,
            "fpr": 0.1986827661909989,
            "logloss": 13.1433382094274,
            "mae": 0.44851060026754935,
            "precision": 0.5731132075471698,
            "recall": 0.5148305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7707596500831851,
            "auditor_fn_violation": 0.012730217660333406,
            "auditor_fp_violation": 0.022985516115871088,
            "ave_precision_score": 0.617965178200578,
            "fpr": 0.37609649122807015,
            "logloss": 9.752589119486174,
            "mae": 0.4130718605516174,
            "precision": 0.5685534591194968,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7847608126265425,
            "auditor_fn_violation": 0.004146588773744628,
            "auditor_fp_violation": 0.01571028857622227,
            "ave_precision_score": 0.6368826055180962,
            "fpr": 0.38529088913282106,
            "logloss": 9.04611969004596,
            "mae": 0.40966998905195534,
            "precision": 0.5645161290322581,
            "recall": 0.9639830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6353613973793992,
            "auditor_fn_violation": 0.016488316226250282,
            "auditor_fp_violation": 0.020996532027743788,
            "ave_precision_score": 0.5534951940621731,
            "fpr": 0.1875,
            "logloss": 14.581648158232923,
            "mae": 0.48057124018242114,
            "precision": 0.5581395348837209,
            "recall": 0.44813278008298757
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6448521368798661,
            "auditor_fn_violation": 0.014409570410612312,
            "auditor_fp_violation": 0.021026232156207737,
            "ave_precision_score": 0.5650709933607694,
            "fpr": 0.17233809001097694,
            "logloss": 13.62391757975252,
            "mae": 0.4626174880317777,
            "precision": 0.5722070844686649,
            "recall": 0.4449152542372881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7769140340114016,
            "auditor_fn_violation": 0.005837337118730436,
            "auditor_fp_violation": 0.014509383924928607,
            "ave_precision_score": 0.6221666050816771,
            "fpr": 0.38706140350877194,
            "logloss": 9.807899964636578,
            "mae": 0.4034901140411377,
            "precision": 0.5710814094775213,
            "recall": 0.975103734439834
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7918984177939671,
            "auditor_fn_violation": 0.0016674728832164324,
            "auditor_fp_violation": 0.013842457036123933,
            "ave_precision_score": 0.6423212413845233,
            "fpr": 0.3951701427003293,
            "logloss": 9.227519769210334,
            "mae": 0.40147878396304504,
            "precision": 0.5625759416767923,
            "recall": 0.9809322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6402434420534686,
            "auditor_fn_violation": 0.01267562058673656,
            "auditor_fp_violation": 0.02266421868625052,
            "ave_precision_score": 0.5540534553148763,
            "fpr": 0.20065789473684212,
            "logloss": 13.987037491371238,
            "mae": 0.4623017560817002,
            "precision": 0.572429906542056,
            "recall": 0.508298755186722
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6472043095624014,
            "auditor_fn_violation": 0.011481608960166697,
            "auditor_fp_violation": 0.024089275846462754,
            "ave_precision_score": 0.5623773952610271,
            "fpr": 0.1942919868276619,
            "logloss": 13.224181083535438,
            "mae": 0.44848387882539764,
            "precision": 0.5785714285714286,
            "recall": 0.5148305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.8009331044300471,
            "auditor_fn_violation": 0.008194110795661378,
            "auditor_fp_violation": 0.00044879640962872347,
            "ave_precision_score": 0.6399482743280516,
            "fpr": 0.007675438596491228,
            "logloss": 0.61773809082964,
            "mae": 0.43968929360179526,
            "precision": 0.9481481481481482,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7908054103332156,
            "auditor_fn_violation": 0.007237343950585136,
            "auditor_fp_violation": 0.0010151801944845212,
            "ave_precision_score": 0.6203927798735553,
            "fpr": 0.006586169045005488,
            "logloss": 0.6261300230617026,
            "mae": 0.4466003910704842,
            "precision": 0.9491525423728814,
            "recall": 0.23728813559322035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7097239420467392,
            "auditor_fn_violation": 0.010082259590885937,
            "auditor_fp_violation": 0.007267441860465116,
            "ave_precision_score": 0.7102266452690442,
            "fpr": 0.043859649122807015,
            "logloss": 2.3244863247969687,
            "mae": 0.41491541763851203,
            "precision": 0.7916666666666666,
            "recall": 0.3153526970954357
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7128072545123025,
            "auditor_fn_violation": 0.002013990957971324,
            "auditor_fp_violation": 0.004183242525548285,
            "ave_precision_score": 0.7132804881156218,
            "fpr": 0.03951701427003293,
            "logloss": 2.301347608984489,
            "mae": 0.4081539969671747,
            "precision": 0.8021978021978022,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8067256394054036,
            "auditor_fn_violation": 0.014754859139550122,
            "auditor_fp_violation": 0.016052121583027337,
            "ave_precision_score": 0.8072224969433813,
            "fpr": 0.13486842105263158,
            "logloss": 1.1626677652554822,
            "mae": 0.28724006757561943,
            "precision": 0.7432150313152401,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8290654033280636,
            "auditor_fn_violation": 0.010046698543228719,
            "auditor_fp_violation": 0.016595445691610262,
            "ave_precision_score": 0.8293069152189252,
            "fpr": 0.1251372118551043,
            "logloss": 0.9538741790944971,
            "mae": 0.2682186854340357,
            "precision": 0.7532467532467533,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7708944920962699,
            "auditor_fn_violation": 0.009272402999199243,
            "auditor_fp_violation": 0.01702111383108936,
            "ave_precision_score": 0.6113486884073749,
            "fpr": 0.3541666666666667,
            "logloss": 10.03295990674421,
            "mae": 0.38287020421212287,
            "precision": 0.5874840357598978,
            "recall": 0.9543568464730291
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7876530927536123,
            "auditor_fn_violation": 0.0060373216245883645,
            "auditor_fp_violation": 0.023289133821253284,
            "ave_precision_score": 0.635861827857565,
            "fpr": 0.33479692645444564,
            "logloss": 8.972347532399466,
            "mae": 0.3569148216315347,
            "precision": 0.5986842105263158,
            "recall": 0.9639830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6375017341168177,
            "auditor_fn_violation": 0.06335762903108394,
            "auditor_fp_violation": 0.059644022847817224,
            "ave_precision_score": 0.6391304723961745,
            "fpr": 0.19736842105263158,
            "logloss": 0.6559243760732677,
            "mae": 0.4326369414971978,
            "precision": 0.6597353497164461,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6782609665936461,
            "auditor_fn_violation": 0.05125676756776871,
            "auditor_fp_violation": 0.04759094739316229,
            "ave_precision_score": 0.6797153774546846,
            "fpr": 0.19209659714599342,
            "logloss": 0.6116780298051108,
            "mae": 0.4128275256272728,
            "precision": 0.6722846441947565,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7086418500236991,
            "auditor_fn_violation": 0.011988607410642798,
            "auditor_fp_violation": 0.007027743778049777,
            "ave_precision_score": 0.7091441496663073,
            "fpr": 0.04276315789473684,
            "logloss": 2.3824493191215415,
            "mae": 0.4161084745141203,
            "precision": 0.7925531914893617,
            "recall": 0.3091286307053942
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.710601290768611,
            "auditor_fn_violation": 0.0058070847829727055,
            "auditor_fp_violation": 0.0030105343698506497,
            "ave_precision_score": 0.7110766309603381,
            "fpr": 0.038419319429198684,
            "logloss": 2.36202195872997,
            "mae": 0.41004129951584267,
            "precision": 0.8033707865168539,
            "recall": 0.3029661016949153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6547120792880416,
            "auditor_fn_violation": 0.012566426439542845,
            "auditor_fp_violation": 0.02084353325173399,
            "ave_precision_score": 0.5599321338712808,
            "fpr": 0.20175438596491227,
            "logloss": 14.194725683748159,
            "mae": 0.4536798933203068,
            "precision": 0.5808656036446469,
            "recall": 0.529045643153527
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.661295698633741,
            "auditor_fn_violation": 0.011404863346294826,
            "auditor_fp_violation": 0.018273243500721386,
            "ave_precision_score": 0.5655951635980402,
            "fpr": 0.2030735455543359,
            "logloss": 13.632469559769206,
            "mae": 0.4485790324721819,
            "precision": 0.5727482678983834,
            "recall": 0.5254237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6447140720971845,
            "auditor_fn_violation": 0.011517707650869916,
            "auditor_fp_violation": 0.02266421868625052,
            "ave_precision_score": 0.5571660902004738,
            "fpr": 0.20065789473684212,
            "logloss": 13.80980686735279,
            "mae": 0.45806671432538826,
            "precision": 0.5783410138248848,
            "recall": 0.520746887966805
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6502998363502539,
            "auditor_fn_violation": 0.009916463562112784,
            "auditor_fp_violation": 0.024089275846462754,
            "ave_precision_score": 0.5647425298499094,
            "fpr": 0.1942919868276619,
            "logloss": 13.1036395482128,
            "mae": 0.44540415262830296,
            "precision": 0.580568720379147,
            "recall": 0.5190677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7679570084567756,
            "auditor_fn_violation": 0.012175147412098712,
            "auditor_fp_violation": 0.01823235414116688,
            "ave_precision_score": 0.615572472211539,
            "fpr": 0.4057017543859649,
            "logloss": 10.172801526821376,
            "mae": 0.4457123937260919,
            "precision": 0.5498783454987834,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.77963748246303,
            "auditor_fn_violation": 0.0057140597964613305,
            "auditor_fp_violation": 0.013862460586754157,
            "ave_precision_score": 0.6317601270184752,
            "fpr": 0.4226125137211855,
            "logloss": 9.64284973884465,
            "mae": 0.45030945880997186,
            "precision": 0.5383693045563549,
            "recall": 0.951271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.775924220845236,
            "auditor_fn_violation": 0.005832787362597366,
            "auditor_fp_violation": 0.013591391268869853,
            "ave_precision_score": 0.6198135763711551,
            "fpr": 0.3892543859649123,
            "logloss": 9.94438481420703,
            "mae": 0.4079287707161432,
            "precision": 0.56865127582017,
            "recall": 0.970954356846473
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7913548395336888,
            "auditor_fn_violation": 0.0016674728832164324,
            "auditor_fp_violation": 0.015782801447256897,
            "ave_precision_score": 0.6413516008650199,
            "fpr": 0.3973655323819978,
            "logloss": 9.268805296041823,
            "mae": 0.40297623393976106,
            "precision": 0.5612121212121212,
            "recall": 0.9809322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 22727,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6461785175184227,
            "auditor_fn_violation": 0.012832587173327518,
            "auditor_fp_violation": 0.020797633618931055,
            "ave_precision_score": 0.5585679994157416,
            "fpr": 0.20065789473684212,
            "logloss": 13.976156495230372,
            "mae": 0.4589837029820506,
            "precision": 0.5763888888888888,
            "recall": 0.516597510373444
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.656770800072641,
            "auditor_fn_violation": 0.01302349811159278,
            "auditor_fp_violation": 0.024836908551267856,
            "ave_precision_score": 0.5688793436086999,
            "fpr": 0.1986827661909989,
            "logloss": 13.195813040221475,
            "mae": 0.44382764803960517,
            "precision": 0.578088578088578,
            "recall": 0.5254237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7391651057503318,
            "auditor_fn_violation": 0.005284541748562273,
            "auditor_fp_violation": 0.0018359853121175031,
            "ave_precision_score": 0.5651080602079729,
            "fpr": 0.005482456140350877,
            "logloss": 0.6727001908173929,
            "mae": 0.48230974114777747,
            "precision": 0.9038461538461539,
            "recall": 0.0975103734439834
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7541469991780969,
            "auditor_fn_violation": 0.012186273232990395,
            "auditor_fp_violation": 0.0007626353677777807,
            "ave_precision_score": 0.5611354739294739,
            "fpr": 0.003293084522502744,
            "logloss": 0.6679163126348582,
            "mae": 0.48059152398753247,
            "precision": 0.9411764705882353,
            "recall": 0.1016949152542373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7699542722538583,
            "auditor_fn_violation": 0.011044533013030502,
            "auditor_fp_violation": 0.01853325173398614,
            "ave_precision_score": 0.6100163390820204,
            "fpr": 0.3607456140350877,
            "logloss": 10.083187879258013,
            "mae": 0.39095993165585413,
            "precision": 0.5824873096446701,
            "recall": 0.9522821576763485
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7864725922777208,
            "auditor_fn_violation": 0.004390779363336993,
            "auditor_fp_violation": 0.01832325237729699,
            "ave_precision_score": 0.6352523558806435,
            "fpr": 0.34796926454445665,
            "logloss": 9.007433270720291,
            "mae": 0.36827926092512564,
            "precision": 0.5899094437257438,
            "recall": 0.9661016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7742744479465197,
            "auditor_fn_violation": 0.011030883744631289,
            "auditor_fp_violation": 0.02427835577315382,
            "ave_precision_score": 0.6205200194749705,
            "fpr": 0.34100877192982454,
            "logloss": 9.681418974712669,
            "mae": 0.3731843997153412,
            "precision": 0.5939947780678851,
            "recall": 0.9439834024896265
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.788372394392809,
            "auditor_fn_violation": 0.0067536140207259685,
            "auditor_fp_violation": 0.02117375834210573,
            "ave_precision_score": 0.6403596701875981,
            "fpr": 0.32821075740944017,
            "logloss": 8.815592747639933,
            "mae": 0.358139323117954,
            "precision": 0.5997322623828648,
            "recall": 0.9491525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6449149772396725,
            "auditor_fn_violation": 0.011517707650869916,
            "auditor_fp_violation": 0.020797633618931055,
            "ave_precision_score": 0.5571350382734312,
            "fpr": 0.20065789473684212,
            "logloss": 13.823479640878778,
            "mae": 0.4578777477753784,
            "precision": 0.5783410138248848,
            "recall": 0.520746887966805
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6513994034446855,
            "auditor_fn_violation": 0.009869951068857097,
            "auditor_fp_violation": 0.023846732795071136,
            "ave_precision_score": 0.5652954317054633,
            "fpr": 0.1964873765093304,
            "logloss": 13.131256335012807,
            "mae": 0.44637632410270656,
            "precision": 0.5768321513002365,
            "recall": 0.5169491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7742721174180921,
            "auditor_fn_violation": 0.012470881560748343,
            "auditor_fp_violation": 0.022949816401468807,
            "ave_precision_score": 0.6206648339553011,
            "fpr": 0.3223684210526316,
            "logloss": 9.434211909923027,
            "mae": 0.36054948410780435,
            "precision": 0.6058981233243967,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7889127791854444,
            "auditor_fn_violation": 0.005848946026902826,
            "auditor_fp_violation": 0.0225865091053662,
            "ave_precision_score": 0.6407253748925912,
            "fpr": 0.3029637760702525,
            "logloss": 8.58472181316362,
            "mae": 0.3369420388142977,
            "precision": 0.6171983356449375,
            "recall": 0.9427966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7708640404890656,
            "auditor_fn_violation": 0.011943109849312078,
            "auditor_fp_violation": 0.019298245614035103,
            "ave_precision_score": 0.6179249560356188,
            "fpr": 0.39364035087719296,
            "logloss": 9.931589308701271,
            "mae": 0.4231773252496846,
            "precision": 0.5584255842558425,
            "recall": 0.941908713692946
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7839532825417073,
            "auditor_fn_violation": 0.005172189250032558,
            "auditor_fp_violation": 0.012784769296550164,
            "ave_precision_score": 0.6360741103079119,
            "fpr": 0.40065861690450055,
            "logloss": 9.290008583568296,
            "mae": 0.42168965823412635,
            "precision": 0.5554202192448234,
            "recall": 0.9661016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7651318473962416,
            "auditor_fn_violation": 0.008671835189633837,
            "auditor_fp_violation": 0.01672276621787027,
            "ave_precision_score": 0.6028670350020607,
            "fpr": 0.375,
            "logloss": 10.605518461422724,
            "mae": 0.40772182702427084,
            "precision": 0.5708908406524467,
            "recall": 0.9439834024896265
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7780692358552777,
            "auditor_fn_violation": 0.004693110569498967,
            "auditor_fp_violation": 0.015172693153034678,
            "ave_precision_score": 0.6255494268755855,
            "fpr": 0.3589462129527991,
            "logloss": 9.449580196770727,
            "mae": 0.39622248751459677,
            "precision": 0.5747724317295189,
            "recall": 0.9364406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7752812273057255,
            "auditor_fn_violation": 0.010250600567809567,
            "auditor_fp_violation": 0.01958129334965321,
            "ave_precision_score": 0.622486890632862,
            "fpr": 0.34100877192982454,
            "logloss": 9.479766974881374,
            "mae": 0.3702886296333787,
            "precision": 0.5955786736020806,
            "recall": 0.950207468879668
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7917602760445407,
            "auditor_fn_violation": 0.005362890472380882,
            "auditor_fp_violation": 0.0228340530444154,
            "ave_precision_score": 0.643482792577813,
            "fpr": 0.3380900109769484,
            "logloss": 8.72081042888919,
            "mae": 0.35821086426446486,
            "precision": 0.5958005249343832,
            "recall": 0.961864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6350586495338842,
            "auditor_fn_violation": 0.016488316226250282,
            "auditor_fp_violation": 0.020996532027743788,
            "ave_precision_score": 0.5528357081981519,
            "fpr": 0.1875,
            "logloss": 14.548748916082367,
            "mae": 0.4804758917243399,
            "precision": 0.5581395348837209,
            "recall": 0.44813278008298757
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6450757107003894,
            "auditor_fn_violation": 0.012351392584048092,
            "auditor_fp_violation": 0.02421429803790174,
            "ave_precision_score": 0.5651277344308638,
            "fpr": 0.17453347969264543,
            "logloss": 13.57107710209422,
            "mae": 0.46309411268052697,
            "precision": 0.5702702702702702,
            "recall": 0.4470338983050847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7166897344922838,
            "auditor_fn_violation": 0.009950316663026867,
            "auditor_fp_violation": 0.0071271929824561426,
            "ave_precision_score": 0.7172087293628167,
            "fpr": 0.04276315789473684,
            "logloss": 2.2005682868611953,
            "mae": 0.4120570847038819,
            "precision": 0.796875,
            "recall": 0.31742738589211617
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.724012122033266,
            "auditor_fn_violation": 0.0004511711845801868,
            "auditor_fp_violation": 0.0030105343698506497,
            "ave_precision_score": 0.7244725386111253,
            "fpr": 0.038419319429198684,
            "logloss": 2.144579465565919,
            "mae": 0.40504642229665283,
            "precision": 0.8066298342541437,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7668150134418834,
            "auditor_fn_violation": 0.00836700152871806,
            "auditor_fp_violation": 0.01754385964912282,
            "ave_precision_score": 0.6043899485126335,
            "fpr": 0.37719298245614036,
            "logloss": 10.604664233582996,
            "mae": 0.4012548862663539,
            "precision": 0.5726708074534161,
            "recall": 0.9564315352697096
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7802292697858987,
            "auditor_fn_violation": 0.005018698022288787,
            "auditor_fp_violation": 0.011702077118688578,
            "ave_precision_score": 0.6279910340470669,
            "fpr": 0.3600439077936334,
            "logloss": 9.450090673523519,
            "mae": 0.3894791101473114,
            "precision": 0.5778635778635779,
            "recall": 0.951271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 22727,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7728775221934439,
            "auditor_fn_violation": 0.011401688869476597,
            "auditor_fp_violation": 0.021011831905344766,
            "ave_precision_score": 0.6217439240793265,
            "fpr": 0.30372807017543857,
            "logloss": 9.246896485102353,
            "mae": 0.36173422884323053,
            "precision": 0.6104078762306611,
            "recall": 0.9004149377593361
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7866367067307678,
            "auditor_fn_violation": 0.00820480381030345,
            "auditor_fp_violation": 0.029170177706542923,
            "ave_precision_score": 0.6391586397526199,
            "fpr": 0.283205268935236,
            "logloss": 8.4948470008805,
            "mae": 0.3338023841394276,
            "precision": 0.6239067055393586,
            "recall": 0.9067796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7760586255626235,
            "auditor_fn_violation": 0.0128894591249909,
            "auditor_fp_violation": 0.0208843329253366,
            "ave_precision_score": 0.6236726222126343,
            "fpr": 0.32346491228070173,
            "logloss": 9.368184310026583,
            "mae": 0.3581141406560498,
            "precision": 0.6061415220293725,
            "recall": 0.941908713692946
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7901866482356429,
            "auditor_fn_violation": 0.0032930845225027446,
            "auditor_fp_violation": 0.032055689884954594,
            "ave_precision_score": 0.6423083889862437,
            "fpr": 0.3106476399560922,
            "logloss": 8.614725431855273,
            "mae": 0.3418473315780777,
            "precision": 0.6139154160982264,
            "recall": 0.9533898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.637650950535514,
            "auditor_fn_violation": 0.018522057217733146,
            "auditor_fp_violation": 0.020716034271725838,
            "ave_precision_score": 0.5532422332040823,
            "fpr": 0.19517543859649122,
            "logloss": 13.855803794235324,
            "mae": 0.4690097842108431,
            "precision": 0.5679611650485437,
            "recall": 0.4854771784232365
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6467124784177423,
            "auditor_fn_violation": 0.014039796089229575,
            "auditor_fp_violation": 0.021096244583413557,
            "ave_precision_score": 0.5628210247573238,
            "fpr": 0.18660812294182216,
            "logloss": 13.01952516041303,
            "mae": 0.4498251318204499,
            "precision": 0.5781637717121588,
            "recall": 0.4936440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6393639426394293,
            "auditor_fn_violation": 0.014450025478634363,
            "auditor_fp_violation": 0.020996532027743788,
            "ave_precision_score": 0.5519281728711859,
            "fpr": 0.1875,
            "logloss": 14.189031530444275,
            "mae": 0.47600450861836413,
            "precision": 0.5626598465473146,
            "recall": 0.45643153526970953
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6450261374101391,
            "auditor_fn_violation": 0.010311819754786131,
            "auditor_fp_violation": 0.022443983807125773,
            "ave_precision_score": 0.5596811857978634,
            "fpr": 0.17672886937431395,
            "logloss": 13.27357115111808,
            "mae": 0.45664855570195084,
            "precision": 0.575197889182058,
            "recall": 0.461864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7742739056281711,
            "auditor_fn_violation": 0.01366746742374609,
            "auditor_fp_violation": 0.022949816401468807,
            "ave_precision_score": 0.6206666241086,
            "fpr": 0.3223684210526316,
            "logloss": 9.428764476057953,
            "mae": 0.3594625166918554,
            "precision": 0.6048387096774194,
            "recall": 0.9336099585062241
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7889375171813562,
            "auditor_fn_violation": 0.0054419617109155525,
            "auditor_fp_violation": 0.0225865091053662,
            "ave_precision_score": 0.6407501046423656,
            "fpr": 0.3029637760702525,
            "logloss": 8.57701807164455,
            "mae": 0.3357507470694574,
            "precision": 0.6166666666666667,
            "recall": 0.940677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.748387906204783,
            "auditor_fn_violation": 0.011752020091723084,
            "auditor_fp_violation": 0.01779375764993879,
            "ave_precision_score": 0.5444111488289186,
            "fpr": 0.40350877192982454,
            "logloss": 13.94029700969454,
            "mae": 0.4418129027876555,
            "precision": 0.5501222493887531,
            "recall": 0.9336099585062241
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.7469430468071098,
            "auditor_fn_violation": 0.0066977990288191415,
            "auditor_fp_violation": 0.015060173180739597,
            "ave_precision_score": 0.5390425667142937,
            "fpr": 0.4138309549945115,
            "logloss": 14.014445481923591,
            "mae": 0.44465769584275106,
            "precision": 0.5413625304136253,
            "recall": 0.9427966101694916
        }
    }
]