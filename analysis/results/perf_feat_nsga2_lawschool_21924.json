[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7166118899591136,
            "auditor_fn_violation": 0.10636188230249759,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.561533352219653,
            "fpr": 0.28289473684210525,
            "logloss": 0.6908161974769078,
            "mae": 0.49871995679119174,
            "precision": 0.5714285714285714,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7055467477556129,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5442017376664112,
            "fpr": 0.278814489571899,
            "logloss": 0.691032238940426,
            "mae": 0.4988321858232291,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7529014402147287,
            "auditor_fn_violation": 0.031505699074570334,
            "auditor_fp_violation": 0.0017840771763137065,
            "ave_precision_score": 0.6552962222909176,
            "fpr": 0.005482456140350877,
            "logloss": 0.6294190212014413,
            "mae": 0.4510765988052937,
            "precision": 0.9557522123893806,
            "recall": 0.219959266802444
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7250007905881201,
            "auditor_fn_violation": 0.027285896162335562,
            "auditor_fp_violation": 0.0020238748627881453,
            "ave_precision_score": 0.6245013977232448,
            "fpr": 0.007683863885839737,
            "logloss": 0.643513494994375,
            "mae": 0.4591534138380107,
            "precision": 0.9285714285714286,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7529014402147287,
            "auditor_fn_violation": 0.031505699074570334,
            "auditor_fp_violation": 0.0017840771763137065,
            "ave_precision_score": 0.6552962222909176,
            "fpr": 0.005482456140350877,
            "logloss": 0.6294184933008631,
            "mae": 0.4510763187549616,
            "precision": 0.9557522123893806,
            "recall": 0.219959266802444
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7250007905881201,
            "auditor_fn_violation": 0.027285896162335562,
            "auditor_fp_violation": 0.0020238748627881453,
            "ave_precision_score": 0.6245013977232448,
            "fpr": 0.007683863885839737,
            "logloss": 0.6435129202590203,
            "mae": 0.45915310220582295,
            "precision": 0.9285714285714286,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.8281968646888074,
            "auditor_fn_violation": 0.016018597920463083,
            "auditor_fp_violation": 0.01659321998583157,
            "ave_precision_score": 0.8283477059965422,
            "fpr": 0.08881578947368421,
            "logloss": 0.6011049054617864,
            "mae": 0.41465857919926447,
            "precision": 0.7617647058823529,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7854974864417149,
            "auditor_fn_violation": 0.011413181347248528,
            "auditor_fp_violation": 0.013481064763995613,
            "ave_precision_score": 0.7860165388727474,
            "fpr": 0.07793633369923161,
            "logloss": 0.5984125542102572,
            "mae": 0.41340482293839775,
            "precision": 0.7641196013289037,
            "recall": 0.49676025917926564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7978338097713509,
            "auditor_fn_violation": 0.031505699074570334,
            "auditor_fp_violation": 0.0017840771763137065,
            "ave_precision_score": 0.630182696232859,
            "fpr": 0.005482456140350877,
            "logloss": 0.6300048096660956,
            "mae": 0.45137010589895543,
            "precision": 0.9557522123893806,
            "recall": 0.219959266802444
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7667290929098262,
            "auditor_fn_violation": 0.027285896162335562,
            "auditor_fp_violation": 0.0020238748627881453,
            "ave_precision_score": 0.5908478803583749,
            "fpr": 0.007683863885839737,
            "logloss": 0.6439201260975096,
            "mae": 0.45934825379945315,
            "precision": 0.9285714285714286,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 21924,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8290017103219827,
            "auditor_fn_violation": 0.01507619609104228,
            "auditor_fp_violation": 0.017939742467808478,
            "ave_precision_score": 0.8210330284712695,
            "fpr": 0.10087719298245613,
            "logloss": 0.6078576636239661,
            "mae": 0.42154437125448074,
            "precision": 0.7533512064343163,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7855494222126698,
            "auditor_fn_violation": 0.014744199168786597,
            "auditor_fp_violation": 0.016700642935549632,
            "ave_precision_score": 0.776811650095298,
            "fpr": 0.08781558726673985,
            "logloss": 0.6757379809817432,
            "mae": 0.4245241832000364,
            "precision": 0.7553516819571865,
            "recall": 0.5334773218142549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.585150211969619,
            "auditor_fn_violation": 0.10409743809625899,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.5861771649254444,
            "fpr": 0.28289473684210525,
            "logloss": 0.6871233003944166,
            "mae": 0.4959725281060265,
            "precision": 0.572139303482587,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5641314544874128,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5652908659933016,
            "fpr": 0.278814489571899,
            "logloss": 0.6908337933970413,
            "mae": 0.4964312638527214,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7739515279093544,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.6964200242218725,
            "fpr": 0.01425438596491228,
            "logloss": 0.6072001085613409,
            "mae": 0.4253120605359998,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7482008902674966,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.6709027832220376,
            "fpr": 0.014270032930845226,
            "logloss": 0.6138388491235031,
            "mae": 0.4304681679419969,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 21924,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8232078424280158,
            "auditor_fn_violation": 0.005672276414049375,
            "auditor_fp_violation": 0.0011798349793724248,
            "ave_precision_score": 0.823461437968963,
            "fpr": 0.06140350877192982,
            "logloss": 0.654334671601667,
            "mae": 0.36772498584135965,
            "precision": 0.813953488372093,
            "recall": 0.4989816700610998
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.788967038041957,
            "auditor_fn_violation": 0.0037222049678396914,
            "auditor_fp_violation": 0.003435196801003608,
            "ave_precision_score": 0.7893164388364434,
            "fpr": 0.05159165751920966,
            "logloss": 0.6806808269611209,
            "mae": 0.37337740868521424,
            "precision": 0.821969696969697,
            "recall": 0.468682505399568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.808445311318382,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.6711993621942562,
            "fpr": 0.01425438596491228,
            "logloss": 0.6083886667706917,
            "mae": 0.426422916156681,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7890731018642582,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.6426122689258885,
            "fpr": 0.014270032930845226,
            "logloss": 0.6157169486960593,
            "mae": 0.43191796197718507,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7548128473303649,
            "auditor_fn_violation": 0.018792207096151793,
            "auditor_fp_violation": 0.018952889944576407,
            "ave_precision_score": 0.7539852855415208,
            "fpr": 0.09978070175438597,
            "logloss": 0.6186773358634471,
            "mae": 0.43323688869152155,
            "precision": 0.7527173913043478,
            "recall": 0.5641547861507128
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7187184302595246,
            "auditor_fn_violation": 0.017126884514441918,
            "auditor_fp_violation": 0.016693292300454764,
            "ave_precision_score": 0.7162178119609559,
            "fpr": 0.0867178924259056,
            "logloss": 0.6965327318113257,
            "mae": 0.4408830123596736,
            "precision": 0.7538940809968847,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 21924,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8232108652857932,
            "auditor_fn_violation": 0.005672276414049375,
            "auditor_fp_violation": 0.0011798349793724248,
            "ave_precision_score": 0.8234644400250131,
            "fpr": 0.06140350877192982,
            "logloss": 0.6543372085196004,
            "mae": 0.3677234859802259,
            "precision": 0.813953488372093,
            "recall": 0.4989816700610998
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.788966112984488,
            "auditor_fn_violation": 0.0037222049678396914,
            "auditor_fp_violation": 0.003435196801003608,
            "ave_precision_score": 0.789315515407459,
            "fpr": 0.05159165751920966,
            "logloss": 0.6806972546314053,
            "mae": 0.37338086911251683,
            "precision": 0.821969696969697,
            "recall": 0.468682505399568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7978338097713509,
            "auditor_fn_violation": 0.031505699074570334,
            "auditor_fp_violation": 0.0017840771763137065,
            "ave_precision_score": 0.630182696232859,
            "fpr": 0.005482456140350877,
            "logloss": 0.6299921223373485,
            "mae": 0.45141420595086457,
            "precision": 0.9557522123893806,
            "recall": 0.219959266802444
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7667290929098262,
            "auditor_fn_violation": 0.027285896162335562,
            "auditor_fp_violation": 0.0020238748627881453,
            "ave_precision_score": 0.5908478803583749,
            "fpr": 0.007683863885839737,
            "logloss": 0.6441422027300401,
            "mae": 0.45950945171514274,
            "precision": 0.9285714285714286,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6695177647532478,
            "auditor_fn_violation": 0.025192500089327195,
            "auditor_fp_violation": 0.006451327249239488,
            "ave_precision_score": 0.6678748179922176,
            "fpr": 0.020833333333333332,
            "logloss": 2.322096618534054,
            "mae": 0.46498038069253445,
            "precision": 0.8347826086956521,
            "recall": 0.1955193482688391
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6416002436324161,
            "auditor_fn_violation": 0.02663391758516619,
            "auditor_fp_violation": 0.009808197428257802,
            "ave_precision_score": 0.6393036338062235,
            "fpr": 0.025246981339187707,
            "logloss": 2.1442011353910617,
            "mae": 0.4493292119949874,
            "precision": 0.8083333333333333,
            "recall": 0.20950323974082075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7978338097713509,
            "auditor_fn_violation": 0.031505699074570334,
            "auditor_fp_violation": 0.0017840771763137065,
            "ave_precision_score": 0.630182696232859,
            "fpr": 0.005482456140350877,
            "logloss": 0.6300209590155724,
            "mae": 0.45149089399267706,
            "precision": 0.9557522123893806,
            "recall": 0.219959266802444
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7667290929098262,
            "auditor_fn_violation": 0.027285896162335562,
            "auditor_fp_violation": 0.0020238748627881453,
            "ave_precision_score": 0.5908478803583749,
            "fpr": 0.007683863885839737,
            "logloss": 0.6443528279696892,
            "mae": 0.45967796863630234,
            "precision": 0.9285714285714286,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5840493385610938,
            "auditor_fn_violation": 0.10491478186300783,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.5845841382759182,
            "fpr": 0.28289473684210525,
            "logloss": 0.6867613445095068,
            "mae": 0.49576474173942153,
            "precision": 0.5728476821192053,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5342248863419543,
            "auditor_fn_violation": 0.099304635212059,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5361565000770884,
            "fpr": 0.278814489571899,
            "logloss": 0.6907964082069487,
            "mae": 0.49637875045955376,
            "precision": 0.5605536332179931,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.607215856201567,
            "auditor_fn_violation": 0.004779004537821132,
            "auditor_fp_violation": 0.001916906279951665,
            "ave_precision_score": 0.6111364054766111,
            "fpr": 0.42872807017543857,
            "logloss": 0.6694093090729509,
            "mae": 0.48281095601749,
            "precision": 0.5495391705069125,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5547470547248069,
            "auditor_fn_violation": 0.0038075548906691195,
            "auditor_fp_violation": 0.007272228320526898,
            "ave_precision_score": 0.5605167834214314,
            "fpr": 0.45773874862788144,
            "logloss": 0.6762037711870638,
            "mae": 0.48620483786292973,
            "precision": 0.5195852534562212,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.808445311318382,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.6711993621942562,
            "fpr": 0.01425438596491228,
            "logloss": 0.607916068847468,
            "mae": 0.42565201030096467,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7890731018642582,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.6426122689258885,
            "fpr": 0.014270032930845226,
            "logloss": 0.6144013230802854,
            "mae": 0.43071235668907837,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7549450791702498,
            "auditor_fn_violation": 0.018792207096151793,
            "auditor_fp_violation": 0.018952889944576407,
            "ave_precision_score": 0.7541834815446501,
            "fpr": 0.09978070175438597,
            "logloss": 0.6186959545182256,
            "mae": 0.43326060960820895,
            "precision": 0.7527173913043478,
            "recall": 0.5641547861507128
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7183809659577044,
            "auditor_fn_violation": 0.017126884514441918,
            "auditor_fp_violation": 0.016693292300454764,
            "ave_precision_score": 0.7158359501021085,
            "fpr": 0.0867178924259056,
            "logloss": 0.696570322824393,
            "mae": 0.44090977687343674,
            "precision": 0.7538940809968847,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7706940803435344,
            "auditor_fn_violation": 0.004779004537821132,
            "auditor_fp_violation": 0.001916906279951665,
            "ave_precision_score": 0.579296105329131,
            "fpr": 0.42872807017543857,
            "logloss": 0.6700729572662057,
            "mae": 0.48383316757124767,
            "precision": 0.5495391705069125,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.7399851929756256,
            "auditor_fn_violation": 0.0038075548906691195,
            "auditor_fp_violation": 0.007272228320526898,
            "ave_precision_score": 0.5473991600615553,
            "fpr": 0.45773874862788144,
            "logloss": 0.6751172975033137,
            "mae": 0.4863721358658323,
            "precision": 0.5195852534562212,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7421725029898151,
            "auditor_fn_violation": 0.0019674313073927184,
            "auditor_fp_violation": 0.010266908363545444,
            "ave_precision_score": 0.5410844262034611,
            "fpr": 0.42543859649122806,
            "logloss": 13.93452987127676,
            "mae": 0.4364807702950202,
            "precision": 0.555045871559633,
            "recall": 0.9857433808553971
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7204182342007993,
            "auditor_fn_violation": 0.001145111464628384,
            "auditor_fp_violation": 0.0002327701113376322,
            "ave_precision_score": 0.507197259230282,
            "fpr": 0.4445664105378705,
            "logloss": 14.880197089390064,
            "mae": 0.46238143155688644,
            "precision": 0.5285215366705471,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6242155750897769,
            "auditor_fn_violation": 0.09296503733876442,
            "auditor_fp_violation": 0.09629849564528901,
            "ave_precision_score": 0.5727684127877263,
            "fpr": 0.2905701754385965,
            "logloss": 0.6941429010473069,
            "mae": 0.4929407057270669,
            "precision": 0.5766773162939297,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6987848054606899,
            "auditor_fn_violation": 0.0907554179419763,
            "auditor_fp_violation": 0.09809422534106947,
            "ave_precision_score": 0.5767455231238671,
            "fpr": 0.27991218441273324,
            "logloss": 0.6767189303148086,
            "mae": 0.4867307114548793,
            "precision": 0.5735785953177257,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7421616612385481,
            "auditor_fn_violation": 0.001344374173723515,
            "auditor_fp_violation": 0.0105117306329958,
            "ave_precision_score": 0.5410735857096989,
            "fpr": 0.4243421052631579,
            "logloss": 13.932762767609432,
            "mae": 0.4365954407983002,
            "precision": 0.5551724137931034,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7204157722820426,
            "auditor_fn_violation": 0.0025225643858480347,
            "auditor_fp_violation": 0.001095244629135955,
            "ave_precision_score": 0.5071947974706182,
            "fpr": 0.442371020856202,
            "logloss": 14.880376189893006,
            "mae": 0.46257880599157214,
            "precision": 0.5286549707602339,
            "recall": 0.9762419006479481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 21924,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.644480511709852,
            "auditor_fn_violation": 0.009765694786865342,
            "auditor_fp_violation": 0.0006042421969412844,
            "ave_precision_score": 0.5549606911376423,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6753873642346175,
            "mae": 0.4862617267328396,
            "precision": 0.9722222222222222,
            "recall": 0.07128309572301425
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.62217735669867,
            "auditor_fn_violation": 0.009779678657540564,
            "auditor_fp_violation": 0.0010780931472479222,
            "ave_precision_score": 0.5303631179914301,
            "fpr": 0.0021953896816684962,
            "logloss": 0.677106716866689,
            "mae": 0.48715423556243026,
            "precision": 0.9393939393939394,
            "recall": 0.06695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7333146858683924,
            "auditor_fn_violation": 0.10416889984635723,
            "auditor_fp_violation": 0.089253344168021,
            "ave_precision_score": 0.6286601315360784,
            "fpr": 0.26206140350877194,
            "logloss": 0.6567181411763519,
            "mae": 0.47479341411146153,
            "precision": 0.5900514579759862,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7143913149000742,
            "auditor_fn_violation": 0.0981168487860159,
            "auditor_fp_violation": 0.09252489415085463,
            "ave_precision_score": 0.6056752682112729,
            "fpr": 0.2623490669593853,
            "logloss": 0.6617000265579581,
            "mae": 0.47807391575086783,
            "precision": 0.5701438848920863,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7952671821963163,
            "auditor_fn_violation": 0.02295485403937542,
            "auditor_fp_violation": 0.015030524648914459,
            "ave_precision_score": 0.7954571363671824,
            "fpr": 0.12719298245614036,
            "logloss": 0.6500557357825962,
            "mae": 0.43219912109341013,
            "precision": 0.6881720430107527,
            "recall": 0.5213849287169042
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.749566697654915,
            "auditor_fn_violation": 0.0057326698167110505,
            "auditor_fp_violation": 0.015671554022267536,
            "ave_precision_score": 0.7501297988006154,
            "fpr": 0.1251372118551043,
            "logloss": 0.6388150850955351,
            "mae": 0.42997185660180615,
            "precision": 0.6752136752136753,
            "recall": 0.5118790496760259
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7007307547317416,
            "auditor_fn_violation": 0.011538839461178405,
            "auditor_fp_violation": 0.03429334916864608,
            "ave_precision_score": 0.6927725739233375,
            "fpr": 0.16557017543859648,
            "logloss": 1.648224881027571,
            "mae": 0.2956927262616773,
            "precision": 0.7224264705882353,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.6858601369113142,
            "auditor_fn_violation": 0.008698579635034249,
            "auditor_fp_violation": 0.03581229418221735,
            "ave_precision_score": 0.6788732395453098,
            "fpr": 0.16794731064763996,
            "logloss": 1.5278130261188867,
            "mae": 0.30818864851223776,
            "precision": 0.7017543859649122,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.808445311318382,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.6711993621942562,
            "fpr": 0.01425438596491228,
            "logloss": 0.6076815024088033,
            "mae": 0.4254827461483186,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7890731018642582,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.6426122689258885,
            "fpr": 0.014270032930845226,
            "logloss": 0.6141070797744458,
            "mae": 0.43050192667807236,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.8214628293924121,
            "auditor_fn_violation": 0.007485618322792726,
            "auditor_fp_violation": 0.0011798349793724248,
            "ave_precision_score": 0.8217255538537387,
            "fpr": 0.06140350877192982,
            "logloss": 0.6526459696919531,
            "mae": 0.3690908215681321,
            "precision": 0.8145695364238411,
            "recall": 0.5010183299389002
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7878258820843376,
            "auditor_fn_violation": 0.0037222049678396914,
            "auditor_fp_violation": 0.003435196801003608,
            "ave_precision_score": 0.7881792372437298,
            "fpr": 0.05159165751920966,
            "logloss": 0.677649862943296,
            "mae": 0.3745567265722746,
            "precision": 0.821969696969697,
            "recall": 0.468682505399568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7421724194853172,
            "auditor_fn_violation": 0.0019674313073927184,
            "auditor_fp_violation": 0.0105117306329958,
            "ave_precision_score": 0.5410843426977017,
            "fpr": 0.4243421052631579,
            "logloss": 13.93495972724942,
            "mae": 0.43647764874734557,
            "precision": 0.5556831228473019,
            "recall": 0.9857433808553971
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7204249161402257,
            "auditor_fn_violation": 0.001145111464628384,
            "auditor_fp_violation": 0.0002327701113376322,
            "ave_precision_score": 0.5072039407749716,
            "fpr": 0.4445664105378705,
            "logloss": 14.880069180866384,
            "mae": 0.46238050625161664,
            "precision": 0.5285215366705471,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7421662534578386,
            "auditor_fn_violation": 0.0017463465180262267,
            "auditor_fp_violation": 0.0105117306329958,
            "ave_precision_score": 0.5410781775636354,
            "fpr": 0.4243421052631579,
            "logloss": 13.93363648875934,
            "mae": 0.43660777465546535,
            "precision": 0.5546605293440736,
            "recall": 0.9816700610997964
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7204198035380721,
            "auditor_fn_violation": 0.0010336823987121646,
            "auditor_fp_violation": 0.001095244629135955,
            "ave_precision_score": 0.5071988285171857,
            "fpr": 0.442371020856202,
            "logloss": 14.880779985498322,
            "mae": 0.4626488490612885,
            "precision": 0.5286549707602339,
            "recall": 0.9762419006479481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.720051560452641,
            "auditor_fn_violation": 0.10409743809625899,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.5673285011324555,
            "fpr": 0.28289473684210525,
            "logloss": 0.6872865635737694,
            "mae": 0.49606222100555897,
            "precision": 0.572139303482587,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6585687679400243,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5480550961469283,
            "fpr": 0.278814489571899,
            "logloss": 0.6908741490206541,
            "mae": 0.4964552136336409,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.687701088249212,
            "auditor_fn_violation": 0.014841712223532356,
            "auditor_fp_violation": 0.026258490644663925,
            "ave_precision_score": 0.6989256524986722,
            "fpr": 0.3475877192982456,
            "logloss": 0.7022783268746432,
            "mae": 0.42480175069680337,
            "precision": 0.5925449871465296,
            "recall": 0.9389002036659878
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6447565847499748,
            "auditor_fn_violation": 0.012887838347246163,
            "auditor_fp_violation": 0.02504116355653129,
            "ave_precision_score": 0.665680431038406,
            "fpr": 0.3611416026344676,
            "logloss": 0.7214454098446045,
            "mae": 0.4383592188162024,
            "precision": 0.5665349143610013,
            "recall": 0.9287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6253709114490582,
            "auditor_fn_violation": 0.00511844785078787,
            "auditor_fp_violation": 0.011488415218568996,
            "ave_precision_score": 0.6136270266569259,
            "fpr": 0.1425438596491228,
            "logloss": 11.13141043642716,
            "mae": 0.49181256066142315,
            "precision": 0.5737704918032787,
            "recall": 0.3564154786150713
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6046232944687358,
            "auditor_fn_violation": 0.007456264091627907,
            "auditor_fp_violation": 0.020339207307511376,
            "ave_precision_score": 0.5909840134214142,
            "fpr": 0.16355653128430298,
            "logloss": 10.18268099596512,
            "mae": 0.47434668481950554,
            "precision": 0.5329153605015674,
            "recall": 0.367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.6997392829918226,
            "auditor_fn_violation": 0.01195867724300568,
            "auditor_fp_violation": 0.03342344876442888,
            "ave_precision_score": 0.6922081976679397,
            "fpr": 0.16666666666666666,
            "logloss": 1.6502856532896946,
            "mae": 0.2956695828887492,
            "precision": 0.7205882352941176,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6862981600710646,
            "auditor_fn_violation": 0.008667758829568061,
            "auditor_fp_violation": 0.03581229418221735,
            "ave_precision_score": 0.6793565252960183,
            "fpr": 0.16794731064763996,
            "logloss": 1.5313415210595323,
            "mae": 0.30793692507267634,
            "precision": 0.701171875,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.6974044665891329,
            "auditor_fn_violation": 0.006708471790474148,
            "auditor_fp_violation": 0.02988654831853982,
            "ave_precision_score": 0.6915092861807512,
            "fpr": 0.16447368421052633,
            "logloss": 1.6323615736806245,
            "mae": 0.2962333529157101,
            "precision": 0.7237569060773481,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6859932037831645,
            "auditor_fn_violation": 0.00869383797265484,
            "auditor_fp_violation": 0.03462639172024464,
            "ave_precision_score": 0.6793136553544998,
            "fpr": 0.1712403951701427,
            "logloss": 1.51441469727058,
            "mae": 0.3098277156975463,
            "precision": 0.6929133858267716,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7424313819531994,
            "auditor_fn_violation": 0.0028919676992889562,
            "auditor_fp_violation": 0.00876151185564864,
            "ave_precision_score": 0.5416402133587241,
            "fpr": 0.42214912280701755,
            "logloss": 13.931157324466795,
            "mae": 0.43537404903435073,
            "precision": 0.5549132947976878,
            "recall": 0.9775967413441955
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7213957814623939,
            "auditor_fn_violation": 0.0030417764163938247,
            "auditor_fp_violation": 0.0015779363336992517,
            "ave_precision_score": 0.5092823176594945,
            "fpr": 0.44127332601536773,
            "logloss": 14.811021576453312,
            "mae": 0.461983690772154,
            "precision": 0.5270588235294118,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7567705718019503,
            "auditor_fn_violation": 0.020393396934290924,
            "auditor_fp_violation": 0.017174021752719086,
            "ave_precision_score": 0.7556290840696152,
            "fpr": 0.09978070175438597,
            "logloss": 0.618919666659815,
            "mae": 0.4343224606035571,
            "precision": 0.7533875338753387,
            "recall": 0.5661914460285132
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7144747746540252,
            "auditor_fn_violation": 0.013760304225058277,
            "auditor_fp_violation": 0.017925748784694998,
            "ave_precision_score": 0.7118099337336693,
            "fpr": 0.0889132821075741,
            "logloss": 0.6980799684841014,
            "mae": 0.4422389579329611,
            "precision": 0.7492260061919505,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5837121821761904,
            "auditor_fn_violation": 0.10491478186300783,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.5842339256741367,
            "fpr": 0.28289473684210525,
            "logloss": 0.6867790304511554,
            "mae": 0.49577535234653114,
            "precision": 0.5728476821192053,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5341004295287951,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5360270470211428,
            "fpr": 0.278814489571899,
            "logloss": 0.6907994664877561,
            "mae": 0.4963821103033721,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8009524302063618,
            "auditor_fn_violation": 0.014133794261621476,
            "auditor_fp_violation": 0.012222882026920037,
            "ave_precision_score": 0.7428199190262583,
            "fpr": 0.13157894736842105,
            "logloss": 4.993630876085063,
            "mae": 0.2784750424107833,
            "precision": 0.7619047619047619,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7786205238496668,
            "auditor_fn_violation": 0.007681493054650035,
            "auditor_fp_violation": 0.015710757409440182,
            "ave_precision_score": 0.7232309297782429,
            "fpr": 0.1437980241492865,
            "logloss": 5.182052106830019,
            "mae": 0.2864757051956337,
            "precision": 0.731006160164271,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 21924,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6555481907360303,
            "auditor_fn_violation": 0.06137001107657128,
            "auditor_fp_violation": 0.06862576572071509,
            "ave_precision_score": 0.6559701563096838,
            "fpr": 0.19407894736842105,
            "logloss": 0.6307390817703885,
            "mae": 0.4517700278706718,
            "precision": 0.5354330708661418,
            "recall": 0.4154786150712831
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.625818291711409,
            "auditor_fn_violation": 0.06010057065906736,
            "auditor_fp_violation": 0.07121295279912185,
            "ave_precision_score": 0.6265583626670577,
            "fpr": 0.18990120746432493,
            "logloss": 0.6447688180785013,
            "mae": 0.4598011288108993,
            "precision": 0.5386666666666666,
            "recall": 0.43628509719222464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7978338097713509,
            "auditor_fn_violation": 0.031505699074570334,
            "auditor_fp_violation": 0.0017840771763137065,
            "ave_precision_score": 0.630182696232859,
            "fpr": 0.005482456140350877,
            "logloss": 0.6300115329167871,
            "mae": 0.4514705757692195,
            "precision": 0.9557522123893806,
            "recall": 0.219959266802444
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7667290929098262,
            "auditor_fn_violation": 0.027285896162335562,
            "auditor_fp_violation": 0.0020238748627881453,
            "ave_precision_score": 0.5908478803583749,
            "fpr": 0.007683863885839737,
            "logloss": 0.644294797057095,
            "mae": 0.4596331178422293,
            "precision": 0.9285714285714286,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7520390086355335,
            "auditor_fn_violation": 0.017144120484510667,
            "auditor_fp_violation": 0.023401362670333797,
            "ave_precision_score": 0.6850784895438696,
            "fpr": 0.3508771929824561,
            "logloss": 0.7451697394322739,
            "mae": 0.4309957294414441,
            "precision": 0.5881595881595881,
            "recall": 0.9307535641547862
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.717574394950019,
            "auditor_fn_violation": 0.014104074747565748,
            "auditor_fp_violation": 0.021782381997804624,
            "ave_precision_score": 0.6476225909086131,
            "fpr": 0.36223929747530187,
            "logloss": 0.7715771876067696,
            "mae": 0.44677221294161257,
            "precision": 0.5640686922060766,
            "recall": 0.9222462203023758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7982522120659916,
            "auditor_fn_violation": 0.025878086254332376,
            "auditor_fp_violation": 0.0008126015751968997,
            "ave_precision_score": 0.6152509525526462,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6395403695066063,
            "mae": 0.460782429366781,
            "precision": 0.9772727272727273,
            "recall": 0.17515274949083504
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7496883157942019,
            "auditor_fn_violation": 0.01643697263823724,
            "auditor_fp_violation": 0.0012006037321624589,
            "ave_precision_score": 0.568549476139218,
            "fpr": 0.006586169045005488,
            "logloss": 0.6584111466531463,
            "mae": 0.47025683904976534,
            "precision": 0.918918918918919,
            "recall": 0.1468682505399568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6695177647532478,
            "auditor_fn_violation": 0.025192500089327195,
            "auditor_fp_violation": 0.006451327249239488,
            "ave_precision_score": 0.6678748179922176,
            "fpr": 0.020833333333333332,
            "logloss": 2.322085852535796,
            "mae": 0.464979614404841,
            "precision": 0.8347826086956521,
            "recall": 0.1955193482688391
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6416002436324161,
            "auditor_fn_violation": 0.02663391758516619,
            "auditor_fp_violation": 0.009808197428257802,
            "ave_precision_score": 0.6393036338062235,
            "fpr": 0.025246981339187707,
            "logloss": 2.1441918277029757,
            "mae": 0.4493285648411797,
            "precision": 0.8083333333333333,
            "recall": 0.20950323974082075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8217719174303217,
            "auditor_fn_violation": 0.006063082859899242,
            "auditor_fp_violation": 0.0011798349793724248,
            "ave_precision_score": 0.8220339824543696,
            "fpr": 0.06140350877192982,
            "logloss": 0.6525699004673189,
            "mae": 0.36850763227384103,
            "precision": 0.8151815181518152,
            "recall": 0.5030549898167006
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7894992591700977,
            "auditor_fn_violation": 0.007539243183267632,
            "auditor_fp_violation": 0.005405167006429359,
            "ave_precision_score": 0.7898459764295092,
            "fpr": 0.050493962678375415,
            "logloss": 0.6771252681456491,
            "mae": 0.374023029700159,
            "precision": 0.8270676691729323,
            "recall": 0.47516198704103674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7460355827558192,
            "auditor_fn_violation": 0.03190990459856362,
            "auditor_fp_violation": 0.028112889111138902,
            "ave_precision_score": 0.7456415392279219,
            "fpr": 0.09868421052631579,
            "logloss": 0.6071615037460437,
            "mae": 0.40965146624499504,
            "precision": 0.7506925207756233,
            "recall": 0.5519348268839104
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7245117791024138,
            "auditor_fn_violation": 0.026136043035327766,
            "auditor_fp_violation": 0.030034694997647802,
            "ave_precision_score": 0.7225720580101263,
            "fpr": 0.09440175631174534,
            "logloss": 0.5993871268199512,
            "mae": 0.41166288740973833,
            "precision": 0.73125,
            "recall": 0.5053995680345572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7554947725780191,
            "auditor_fn_violation": 0.016266480866116415,
            "auditor_fp_violation": 0.02635485685710714,
            "ave_precision_score": 0.6698042629350578,
            "fpr": 0.3442982456140351,
            "logloss": 0.7845659272593533,
            "mae": 0.4261100912760747,
            "precision": 0.5937904269081501,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6841321502564577,
            "auditor_fn_violation": 0.012005889144675232,
            "auditor_fp_violation": 0.024639328838011617,
            "ave_precision_score": 0.6380180105502417,
            "fpr": 0.3578485181119649,
            "logloss": 0.8058077794606281,
            "mae": 0.44148855920549807,
            "precision": 0.5670650730411687,
            "recall": 0.9222462203023758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7539781651354983,
            "auditor_fn_violation": 0.016266480866116415,
            "auditor_fp_violation": 0.023401362670333797,
            "ave_precision_score": 0.6669125885733986,
            "fpr": 0.3508771929824561,
            "logloss": 0.7944805597780134,
            "mae": 0.4280619600199555,
            "precision": 0.5892169448010269,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6832827964286731,
            "auditor_fn_violation": 0.011223514852071988,
            "auditor_fp_violation": 0.02178973263289949,
            "ave_precision_score": 0.6359206335962929,
            "fpr": 0.3633369923161361,
            "logloss": 0.8139729846726609,
            "mae": 0.44272894494881615,
            "precision": 0.5638998682476943,
            "recall": 0.9244060475161987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.742148394121976,
            "auditor_fn_violation": 0.001344374173723515,
            "auditor_fp_violation": 0.0105117306329958,
            "ave_precision_score": 0.5410603200020435,
            "fpr": 0.4243421052631579,
            "logloss": 13.933977132991853,
            "mae": 0.4365451677897414,
            "precision": 0.5551724137931034,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7204185126291739,
            "auditor_fn_violation": 0.004831753964622457,
            "auditor_fp_violation": 0.001095244629135955,
            "ave_precision_score": 0.5071975376539697,
            "fpr": 0.442371020856202,
            "logloss": 14.880492097448972,
            "mae": 0.4626334258135404,
            "precision": 0.5281030444964872,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7079849360813447,
            "auditor_fn_violation": 0.0014158359238217743,
            "auditor_fp_violation": 0.004185419010709678,
            "ave_precision_score": 0.5781801549911587,
            "fpr": 0.43640350877192985,
            "logloss": 0.6785027599489281,
            "mae": 0.4712801458673519,
            "precision": 0.5497737556561086,
            "recall": 0.9898167006109979
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7448639029918038,
            "auditor_fn_violation": 0.0014130153890652523,
            "auditor_fp_violation": 0.006456307824996085,
            "ave_precision_score": 0.5698505605308033,
            "fpr": 0.4643249176728869,
            "logloss": 0.6775648859392521,
            "mae": 0.47402344328380963,
            "precision": 0.5176738882554162,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7293240641780628,
            "auditor_fn_violation": 0.10491478186300783,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.6189950428935248,
            "fpr": 0.28289473684210525,
            "logloss": 0.6571751131276568,
            "mae": 0.47492807280076177,
            "precision": 0.5728476821192053,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.714820487208546,
            "auditor_fn_violation": 0.09938998513488845,
            "auditor_fp_violation": 0.0999686372902619,
            "ave_precision_score": 0.5994423813549574,
            "fpr": 0.27991218441273324,
            "logloss": 0.6617792654974438,
            "mae": 0.47803208032371447,
            "precision": 0.5611015490533563,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.8099455285778945,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.6741640556298049,
            "fpr": 0.01425438596491228,
            "logloss": 0.6096796934426925,
            "mae": 0.42681922374718023,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7894728952332635,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.6442443883629632,
            "fpr": 0.014270032930845226,
            "logloss": 0.6165943875770935,
            "mae": 0.43214717405949415,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8100941005277955,
            "auditor_fn_violation": 0.04117313395505056,
            "auditor_fp_violation": 0.003229570362962037,
            "ave_precision_score": 0.6632936398328599,
            "fpr": 0.008771929824561403,
            "logloss": 0.6140740453308626,
            "mae": 0.43594312795290824,
            "precision": 0.9448275862068966,
            "recall": 0.2790224032586558
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7831017377221359,
            "auditor_fn_violation": 0.035387026337563694,
            "auditor_fp_violation": 0.002881448957189901,
            "ave_precision_score": 0.6242344411507134,
            "fpr": 0.008781558726673985,
            "logloss": 0.6276726122396242,
            "mae": 0.44572490754687566,
            "precision": 0.9349593495934959,
            "recall": 0.24838012958963282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 21924,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7979202045529177,
            "auditor_fn_violation": 0.012793886447279097,
            "auditor_fp_violation": 0.020893236654581825,
            "ave_precision_score": 0.7413851986757098,
            "fpr": 0.13815789473684212,
            "logloss": 4.8733665161252615,
            "mae": 0.2797321019651746,
            "precision": 0.7524557956777996,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7754212027136476,
            "auditor_fn_violation": 0.011607589504804493,
            "auditor_fp_violation": 0.00806854712247138,
            "ave_precision_score": 0.7231609976800547,
            "fpr": 0.1394072447859495,
            "logloss": 5.0251543803291,
            "mae": 0.28551341207024916,
            "precision": 0.7337526205450734,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7706940803435344,
            "auditor_fn_violation": 0.004779004537821132,
            "auditor_fp_violation": 0.001916906279951665,
            "ave_precision_score": 0.579296105329131,
            "fpr": 0.42872807017543857,
            "logloss": 0.6700729528244138,
            "mae": 0.4838331641727372,
            "precision": 0.5495391705069125,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.7399851929756256,
            "auditor_fn_violation": 0.0038075548906691195,
            "auditor_fp_violation": 0.007272228320526898,
            "ave_precision_score": 0.5473991600615553,
            "fpr": 0.45773874862788144,
            "logloss": 0.6751172992182555,
            "mae": 0.4863721355386937,
            "precision": 0.5195852534562212,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7576022752145612,
            "auditor_fn_violation": 0.02101422088826957,
            "auditor_fp_violation": 0.017174021752719086,
            "ave_precision_score": 0.7561798998826451,
            "fpr": 0.09978070175438597,
            "logloss": 0.6196427422414664,
            "mae": 0.43507539003826023,
            "precision": 0.7527173913043478,
            "recall": 0.5641547861507128
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7115994154992014,
            "auditor_fn_violation": 0.013760304225058277,
            "auditor_fp_violation": 0.017925748784694998,
            "ave_precision_score": 0.7085808917587801,
            "fpr": 0.0889132821075741,
            "logloss": 0.6992938801922136,
            "mae": 0.4430335613885643,
            "precision": 0.7492260061919505,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8049083284036165,
            "auditor_fn_violation": 0.01575284953728517,
            "auditor_fp_violation": 0.015184189690377969,
            "ave_precision_score": 0.7442529998823874,
            "fpr": 0.14035087719298245,
            "logloss": 5.027552096306913,
            "mae": 0.27831092419699743,
            "precision": 0.751937984496124,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7832951861597552,
            "auditor_fn_violation": 0.007681493054650035,
            "auditor_fp_violation": 0.016190998902305163,
            "ave_precision_score": 0.7238215252714277,
            "fpr": 0.14489571899012074,
            "logloss": 5.229177885947123,
            "mae": 0.28657081286528924,
            "precision": 0.7295081967213115,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.8172684894302089,
            "auditor_fn_violation": 0.010234662521885183,
            "auditor_fp_violation": 0.001799704129682875,
            "ave_precision_score": 0.8175536225359336,
            "fpr": 0.06578947368421052,
            "logloss": 0.6532949740744874,
            "mae": 0.3710166911883635,
            "precision": 0.8051948051948052,
            "recall": 0.505091649694501
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7868868731615695,
            "auditor_fn_violation": 0.013395196221843418,
            "auditor_fp_violation": 0.001136898228006903,
            "ave_precision_score": 0.7872470102692071,
            "fpr": 0.052689352360043906,
            "logloss": 0.6764847705169742,
            "mae": 0.3760992781662325,
            "precision": 0.8279569892473119,
            "recall": 0.49892008639308855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7166118899591136,
            "auditor_fn_violation": 0.10636188230249759,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.561533352219653,
            "fpr": 0.28289473684210525,
            "logloss": 0.6908161974769078,
            "mae": 0.49871995679119174,
            "precision": 0.5714285714285714,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7055467477556129,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5442017376664112,
            "fpr": 0.278814489571899,
            "logloss": 0.691032238940426,
            "mae": 0.4988321858232291,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7079849360813447,
            "auditor_fn_violation": 0.0014158359238217743,
            "auditor_fp_violation": 0.004185419010709678,
            "ave_precision_score": 0.5781801549911587,
            "fpr": 0.43640350877192985,
            "logloss": 0.6786081082890961,
            "mae": 0.47125615467105,
            "precision": 0.5497737556561086,
            "recall": 0.9898167006109979
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7448639029918038,
            "auditor_fn_violation": 0.0014130153890652523,
            "auditor_fp_violation": 0.006456307824996085,
            "ave_precision_score": 0.5698505605308033,
            "fpr": 0.4643249176728869,
            "logloss": 0.6777319416438801,
            "mae": 0.474031041403895,
            "precision": 0.5176738882554162,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.598207840144429,
            "auditor_fn_violation": 0.005911226640940449,
            "auditor_fp_violation": 0.016772929949577027,
            "ave_precision_score": 0.6024514078508171,
            "fpr": 0.1074561403508772,
            "logloss": 0.672784160203364,
            "mae": 0.48516441872764343,
            "precision": 0.5525114155251142,
            "recall": 0.24643584521384929
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5488353340704081,
            "auditor_fn_violation": 0.0070010645032041845,
            "auditor_fp_violation": 0.008820762113846645,
            "ave_precision_score": 0.554649670480678,
            "fpr": 0.1251372118551043,
            "logloss": 0.6753171400507092,
            "mae": 0.4862981279156095,
            "precision": 0.4977973568281938,
            "recall": 0.24406047516198703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 21924,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8219307191069791,
            "auditor_fn_violation": 0.0016592525100939802,
            "auditor_fp_violation": 0.004763616285369006,
            "ave_precision_score": 0.8221886132466899,
            "fpr": 0.05921052631578947,
            "logloss": 0.6624478293534124,
            "mae": 0.36899097017313276,
            "precision": 0.8181818181818182,
            "recall": 0.49490835030549896
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7896146987186161,
            "auditor_fn_violation": 0.001493623649515296,
            "auditor_fp_violation": 0.00408205268935236,
            "ave_precision_score": 0.7899649527536778,
            "fpr": 0.050493962678375415,
            "logloss": 0.6854067097209788,
            "mae": 0.3730413673711408,
            "precision": 0.8244274809160306,
            "recall": 0.46652267818574517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7002713123365341,
            "auditor_fn_violation": 0.008503948261692929,
            "auditor_fp_violation": 0.029824040505063144,
            "ave_precision_score": 0.6942564439595913,
            "fpr": 0.16447368421052633,
            "logloss": 1.6127514023731322,
            "mae": 0.29500736594521487,
            "precision": 0.7217068645640075,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6867617531158942,
            "auditor_fn_violation": 0.011790143506411919,
            "auditor_fp_violation": 0.03667966912341228,
            "ave_precision_score": 0.6815744367497665,
            "fpr": 0.16465422612513722,
            "logloss": 1.4756851191584817,
            "mae": 0.3075984417186018,
            "precision": 0.7035573122529645,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6425219000488321,
            "auditor_fn_violation": 0.0039437953335477284,
            "auditor_fp_violation": 0.0009271992332374885,
            "ave_precision_score": 0.5481123676468838,
            "fpr": 0.010964912280701754,
            "logloss": 0.6972423174380226,
            "mae": 0.4929713387238352,
            "precision": 0.7222222222222222,
            "recall": 0.05295315682281059
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7299748731407745,
            "auditor_fn_violation": 0.008345325787767937,
            "auditor_fp_violation": 0.001345166222361612,
            "ave_precision_score": 0.5373435547768692,
            "fpr": 0.003293084522502744,
            "logloss": 0.6769702699685177,
            "mae": 0.4859151306319839,
            "precision": 0.9166666666666666,
            "recall": 0.07127429805615551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7864393510262311,
            "auditor_fn_violation": 0.00717743952549398,
            "auditor_fp_violation": 0.023057569696212036,
            "ave_precision_score": 0.7242079312072496,
            "fpr": 0.16447368421052633,
            "logloss": 5.19207306670273,
            "mae": 0.2867385834026299,
            "precision": 0.722735674676525,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7644801386120432,
            "auditor_fn_violation": 0.0009886366061077406,
            "auditor_fp_violation": 0.025619413517327903,
            "ave_precision_score": 0.7074237410191699,
            "fpr": 0.1668496158068057,
            "logloss": 5.26064334261034,
            "mae": 0.2924913108358132,
            "precision": 0.7048543689320388,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5884085745296754,
            "auditor_fn_violation": 0.10409743809625899,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.5888891484716007,
            "fpr": 0.28289473684210525,
            "logloss": 0.6863130909282942,
            "mae": 0.49540272890998605,
            "precision": 0.572139303482587,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5352592324468959,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5371586974897036,
            "fpr": 0.278814489571899,
            "logloss": 0.6901315085708599,
            "mae": 0.4959108678687417,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7058114430315606,
            "auditor_fn_violation": 0.014995801622181731,
            "auditor_fp_violation": 0.031839917489686204,
            "ave_precision_score": 0.7038100623773711,
            "fpr": 0.16666666666666666,
            "logloss": 1.22336881384645,
            "mae": 0.30233069830788545,
            "precision": 0.7251356238698011,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.6819978622060734,
            "auditor_fn_violation": 0.007451522429248472,
            "auditor_fp_violation": 0.03821350164654226,
            "ave_precision_score": 0.6804739532180313,
            "fpr": 0.15367727771679474,
            "logloss": 1.0770294036446688,
            "mae": 0.3168238850050906,
            "precision": 0.7165991902834008,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6670224655487005,
            "auditor_fn_violation": 0.02981964840818952,
            "auditor_fp_violation": 0.009962182772846606,
            "ave_precision_score": 0.6652196434390127,
            "fpr": 0.02412280701754386,
            "logloss": 2.387586321917312,
            "mae": 0.46566837574279935,
            "precision": 0.819672131147541,
            "recall": 0.20366598778004075
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6408778826661499,
            "auditor_fn_violation": 0.028464199263619833,
            "auditor_fp_violation": 0.008712952799121843,
            "ave_precision_score": 0.6390146863174574,
            "fpr": 0.024149286498353458,
            "logloss": 2.2010642831521983,
            "mae": 0.4495086568613108,
            "precision": 0.811965811965812,
            "recall": 0.20518358531317496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.7353318883956761,
            "auditor_fn_violation": 0.013684925143816773,
            "auditor_fp_violation": 0.028316039504938134,
            "ave_precision_score": 0.734232656119591,
            "fpr": 0.3618421052631579,
            "logloss": 0.7235856315701554,
            "mae": 0.4235904064977117,
            "precision": 0.5838587641866331,
            "recall": 0.9429735234215886
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7154635591938262,
            "auditor_fn_violation": 0.011240110670399936,
            "auditor_fp_violation": 0.018111964873765107,
            "ave_precision_score": 0.7140401754799313,
            "fpr": 0.36882546652030734,
            "logloss": 0.720605833743709,
            "mae": 0.4302577871980573,
            "precision": 0.5664516129032258,
            "recall": 0.9481641468682506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.801355264923225,
            "auditor_fn_violation": 0.014133794261621476,
            "auditor_fp_violation": 0.012222882026920037,
            "ave_precision_score": 0.7431556192810032,
            "fpr": 0.13157894736842105,
            "logloss": 4.993682684673419,
            "mae": 0.2784628213667586,
            "precision": 0.7619047619047619,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7786303952619222,
            "auditor_fn_violation": 0.007681493054650035,
            "auditor_fp_violation": 0.015710757409440182,
            "ave_precision_score": 0.7232517007136606,
            "fpr": 0.1437980241492865,
            "logloss": 5.182381592061952,
            "mae": 0.286467591779582,
            "precision": 0.731006160164271,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.647515425181172,
            "auditor_fn_violation": 0.09281764747918678,
            "auditor_fp_violation": 0.09629849564528901,
            "ave_precision_score": 0.5816072884488578,
            "fpr": 0.2905701754385965,
            "logloss": 0.6895551787829532,
            "mae": 0.49027960175615654,
            "precision": 0.5773524720893142,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6954699839939292,
            "auditor_fn_violation": 0.0907554179419763,
            "auditor_fp_violation": 0.09809422534106947,
            "ave_precision_score": 0.5796642871469604,
            "fpr": 0.27991218441273324,
            "logloss": 0.6765926387141417,
            "mae": 0.4848973769715013,
            "precision": 0.5735785953177257,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.8062436037316263,
            "auditor_fn_violation": 0.017961464251259517,
            "auditor_fp_violation": 0.005214193440846773,
            "ave_precision_score": 0.8065599407626076,
            "fpr": 0.046052631578947366,
            "logloss": 0.7700035557584305,
            "mae": 0.3857004069742624,
            "precision": 0.825,
            "recall": 0.40325865580448067
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7840947863711712,
            "auditor_fn_violation": 0.01285938837296968,
            "auditor_fp_violation": 0.003449898071193351,
            "ave_precision_score": 0.7844877579391978,
            "fpr": 0.03512623490669594,
            "logloss": 0.7725755789387507,
            "mae": 0.3816112862651732,
            "precision": 0.8391959798994975,
            "recall": 0.36069114470842334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 21924,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.644480511709852,
            "auditor_fn_violation": 0.009765694786865342,
            "auditor_fp_violation": 0.0006042421969412844,
            "ave_precision_score": 0.5549606911376423,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6753873913924101,
            "mae": 0.4862618106499053,
            "precision": 0.9722222222222222,
            "recall": 0.07128309572301425
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.62217735669867,
            "auditor_fn_violation": 0.009779678657540564,
            "auditor_fp_violation": 0.0010780931472479222,
            "ave_precision_score": 0.5303631179914301,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6771067418612938,
            "mae": 0.48715432451140345,
            "precision": 0.9393939393939394,
            "recall": 0.06695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7011998125906171,
            "auditor_fn_violation": 0.008503948261692929,
            "auditor_fp_violation": 0.029514105929907913,
            "ave_precision_score": 0.6953079696191807,
            "fpr": 0.16228070175438597,
            "logloss": 1.5644154315043648,
            "mae": 0.29458531213193756,
            "precision": 0.7243947858472998,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.6867576814459528,
            "auditor_fn_violation": 0.01000253678937299,
            "auditor_fp_violation": 0.035996060059589156,
            "ave_precision_score": 0.6821380538378099,
            "fpr": 0.16355653128430298,
            "logloss": 1.4662251421250354,
            "mae": 0.3070677690672693,
            "precision": 0.7055335968379447,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7539781651354983,
            "auditor_fn_violation": 0.016266480866116415,
            "auditor_fp_violation": 0.023401362670333797,
            "ave_precision_score": 0.6669125885733986,
            "fpr": 0.3508771929824561,
            "logloss": 0.7940110541187297,
            "mae": 0.4279964266083481,
            "precision": 0.5892169448010269,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6832827964286731,
            "auditor_fn_violation": 0.011223514852071988,
            "auditor_fp_violation": 0.02178973263289949,
            "ave_precision_score": 0.6359206335962929,
            "fpr": 0.3633369923161361,
            "logloss": 0.8134340323870118,
            "mae": 0.4426597175561505,
            "precision": 0.5638998682476943,
            "recall": 0.9244060475161987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8100941005277955,
            "auditor_fn_violation": 0.04117313395505056,
            "auditor_fp_violation": 0.003229570362962037,
            "ave_precision_score": 0.6632936398328599,
            "fpr": 0.008771929824561403,
            "logloss": 0.6140756883635319,
            "mae": 0.43594947699130626,
            "precision": 0.9448275862068966,
            "recall": 0.2790224032586558
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7831017377221359,
            "auditor_fn_violation": 0.035387026337563694,
            "auditor_fp_violation": 0.002881448957189901,
            "ave_precision_score": 0.6242344411507134,
            "fpr": 0.008781558726673985,
            "logloss": 0.6276731492177793,
            "mae": 0.44573021667848955,
            "precision": 0.9349593495934959,
            "recall": 0.24838012958963282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7446911724768717,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.7211466623420079,
            "fpr": 0.01425438596491228,
            "logloss": 0.6089821886047109,
            "mae": 0.42210334340077743,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7240674592678655,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.7028928122850958,
            "fpr": 0.014270032930845226,
            "logloss": 0.6148127128736937,
            "mae": 0.4270340899081183,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7421575579616237,
            "auditor_fn_violation": 0.0017463465180262267,
            "auditor_fp_violation": 0.0105117306329958,
            "ave_precision_score": 0.5410694828885886,
            "fpr": 0.4243421052631579,
            "logloss": 13.933967298874055,
            "mae": 0.4365367091622351,
            "precision": 0.5546605293440736,
            "recall": 0.9816700610997964
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7204129085597669,
            "auditor_fn_violation": 0.0016500985080359326,
            "auditor_fp_violation": 0.0030431629292771,
            "ave_precision_score": 0.5071919340542199,
            "fpr": 0.44127332601536773,
            "logloss": 14.880663086264425,
            "mae": 0.4627297042309829,
            "precision": 0.528169014084507,
            "recall": 0.9719222462203023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 21924,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7978321748579258,
            "auditor_fn_violation": 0.013079733447672133,
            "auditor_fp_violation": 0.020432241530191277,
            "ave_precision_score": 0.7412945522037615,
            "fpr": 0.13925438596491227,
            "logloss": 4.874388935477288,
            "mae": 0.2795853286807759,
            "precision": 0.7514677103718199,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.775445745024727,
            "auditor_fn_violation": 0.01055968211895409,
            "auditor_fp_violation": 0.008311118080602163,
            "ave_precision_score": 0.723170328393907,
            "fpr": 0.14050493962678376,
            "logloss": 5.026166625751143,
            "mae": 0.28525392302833685,
            "precision": 0.7333333333333333,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6248264465104046,
            "auditor_fn_violation": 0.09077652124200522,
            "auditor_fp_violation": 0.09686627495103556,
            "ave_precision_score": 0.6255831978978751,
            "fpr": 0.2850877192982456,
            "logloss": 0.687182768634136,
            "mae": 0.4955413766009243,
            "precision": 0.56738768718802,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5458754697712316,
            "auditor_fn_violation": 0.09600206736479744,
            "auditor_fp_violation": 0.09103516543829387,
            "ave_precision_score": 0.5473737028697518,
            "fpr": 0.27991218441273324,
            "logloss": 0.6926117806645316,
            "mae": 0.4971621335861319,
            "precision": 0.5549738219895288,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.607215856201567,
            "auditor_fn_violation": 0.004779004537821132,
            "auditor_fp_violation": 0.001916906279951665,
            "ave_precision_score": 0.6111364054766111,
            "fpr": 0.42872807017543857,
            "logloss": 0.6694093090729509,
            "mae": 0.48281095601749,
            "precision": 0.5495391705069125,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5547470547248069,
            "auditor_fn_violation": 0.0038075548906691195,
            "auditor_fp_violation": 0.007272228320526898,
            "ave_precision_score": 0.5605167834214314,
            "fpr": 0.45773874862788144,
            "logloss": 0.6762037711870638,
            "mae": 0.48620483786292973,
            "precision": 0.5195852534562212,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7421740480418562,
            "auditor_fn_violation": 0.0017463465180262267,
            "auditor_fp_violation": 0.0105117306329958,
            "ave_precision_score": 0.5410859712858846,
            "fpr": 0.4243421052631579,
            "logloss": 13.933008502266109,
            "mae": 0.436555550224352,
            "precision": 0.5546605293440736,
            "recall": 0.9816700610997964
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7204145993585711,
            "auditor_fn_violation": 0.0016500985080359326,
            "auditor_fp_violation": 0.0030431629292771,
            "ave_precision_score": 0.5071936246465079,
            "fpr": 0.44127332601536773,
            "logloss": 14.880885203460783,
            "mae": 0.4627663435917409,
            "precision": 0.528169014084507,
            "recall": 0.9719222462203023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7545489683458764,
            "auditor_fn_violation": 0.016266480866116415,
            "auditor_fp_violation": 0.023401362670333797,
            "ave_precision_score": 0.6684846769105216,
            "fpr": 0.3508771929824561,
            "logloss": 0.7828660468348495,
            "mae": 0.4273108405044727,
            "precision": 0.5892169448010269,
            "recall": 0.9348268839103869
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7312403978806912,
            "auditor_fn_violation": 0.011223514852071988,
            "auditor_fp_violation": 0.02178973263289949,
            "ave_precision_score": 0.6394132088344519,
            "fpr": 0.3633369923161361,
            "logloss": 0.8007276927750039,
            "mae": 0.44155295590668686,
            "precision": 0.5638998682476943,
            "recall": 0.9244060475161987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7037796342207563,
            "auditor_fn_violation": 0.014841712223532356,
            "auditor_fp_violation": 0.026258490644663925,
            "ave_precision_score": 0.7122328926357302,
            "fpr": 0.3475877192982456,
            "logloss": 0.6971668288799541,
            "mae": 0.4233620587671012,
            "precision": 0.5925449871465296,
            "recall": 0.9389002036659878
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6535937152106024,
            "auditor_fn_violation": 0.012887838347246163,
            "auditor_fp_violation": 0.02504116355653129,
            "ave_precision_score": 0.6710090174603084,
            "fpr": 0.3611416026344676,
            "logloss": 0.7177861772158276,
            "mae": 0.43753103507860563,
            "precision": 0.5665349143610013,
            "recall": 0.9287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7056261296844468,
            "auditor_fn_violation": 0.014100296566262908,
            "auditor_fp_violation": 0.03224361378505646,
            "ave_precision_score": 0.7036248805891973,
            "fpr": 0.16557017543859648,
            "logloss": 1.2246103234413261,
            "mae": 0.3024974053921158,
            "precision": 0.7264492753623188,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.6816798773080143,
            "auditor_fn_violation": 0.005436315917997695,
            "auditor_fp_violation": 0.03821350164654226,
            "ave_precision_score": 0.6801037549271942,
            "fpr": 0.15367727771679474,
            "logloss": 1.0785968169959514,
            "mae": 0.31702788003062743,
            "precision": 0.716024340770791,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7430101422299863,
            "auditor_fn_violation": 0.0028919676992889562,
            "auditor_fp_violation": 0.00876151185564864,
            "ave_precision_score": 0.5428150320977053,
            "fpr": 0.42214912280701755,
            "logloss": 13.888998796538383,
            "mae": 0.43551166268264635,
            "precision": 0.5549132947976878,
            "recall": 0.9775967413441955
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7222967188385963,
            "auditor_fn_violation": 0.0030417764163938247,
            "auditor_fp_violation": 0.006047122471381536,
            "ave_precision_score": 0.5110213061680762,
            "fpr": 0.44127332601536773,
            "logloss": 14.728389475065626,
            "mae": 0.4615179069538918,
            "precision": 0.5270588235294118,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7293240641780628,
            "auditor_fn_violation": 0.10491478186300783,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.6189950428935248,
            "fpr": 0.28289473684210525,
            "logloss": 0.6571751131276568,
            "mae": 0.47492807280076177,
            "precision": 0.5728476821192053,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.714820487208546,
            "auditor_fn_violation": 0.09938998513488845,
            "auditor_fp_violation": 0.0999686372902619,
            "ave_precision_score": 0.5994423813549574,
            "fpr": 0.27991218441273324,
            "logloss": 0.6617792654974438,
            "mae": 0.47803208032371447,
            "precision": 0.5611015490533563,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.8054592424538429,
            "auditor_fn_violation": 0.047977632472219256,
            "auditor_fp_violation": 0.005180335041880237,
            "ave_precision_score": 0.6736401341421565,
            "fpr": 0.01425438596491228,
            "logloss": 0.6082964792109707,
            "mae": 0.4258019638885009,
            "precision": 0.9244186046511628,
            "recall": 0.32382892057026474
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7870391396242612,
            "auditor_fn_violation": 0.04353794396777568,
            "auditor_fp_violation": 0.004302571742198526,
            "ave_precision_score": 0.6452909921293122,
            "fpr": 0.014270032930845226,
            "logloss": 0.6146314391828912,
            "mae": 0.4308024334397196,
            "precision": 0.9177215189873418,
            "recall": 0.31317494600431967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7014750989982332,
            "auditor_fn_violation": 0.015739450459141744,
            "auditor_fp_violation": 0.03355367337583865,
            "ave_precision_score": 0.6995260516755684,
            "fpr": 0.1787280701754386,
            "logloss": 1.2717781774444505,
            "mae": 0.30129610201274454,
            "precision": 0.7199312714776632,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.6740468119106645,
            "auditor_fn_violation": 0.004881541419606303,
            "auditor_fp_violation": 0.04132772071506978,
            "ave_precision_score": 0.6724596367556991,
            "fpr": 0.16794731064763996,
            "logloss": 1.1168095695775684,
            "mae": 0.3178453285732173,
            "precision": 0.7085714285714285,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.720051560452641,
            "auditor_fn_violation": 0.10409743809625899,
            "auditor_fp_violation": 0.09824665583197902,
            "ave_precision_score": 0.5673285011324555,
            "fpr": 0.28289473684210525,
            "logloss": 0.6872865635737694,
            "mae": 0.49606222100555897,
            "precision": 0.572139303482587,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6585687679400243,
            "auditor_fn_violation": 0.10355790636639299,
            "auditor_fp_violation": 0.09708718833307199,
            "ave_precision_score": 0.5480550961469283,
            "fpr": 0.278814489571899,
            "logloss": 0.6908741490206541,
            "mae": 0.4964552136336409,
            "precision": 0.5597920277296361,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.8226633589449899,
            "auditor_fn_violation": 0.00490406260049309,
            "auditor_fp_violation": 0.0008516689586198268,
            "ave_precision_score": 0.8229184840949928,
            "fpr": 0.06030701754385965,
            "logloss": 0.657242054221438,
            "mae": 0.3685704651342859,
            "precision": 0.8154362416107382,
            "recall": 0.49490835030549896
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7885830862223406,
            "auditor_fn_violation": 0.004578075027323847,
            "auditor_fp_violation": 0.003435196801003608,
            "ave_precision_score": 0.7889331183799473,
            "fpr": 0.05159165751920966,
            "logloss": 0.6827969345561091,
            "mae": 0.37406967710624783,
            "precision": 0.8212927756653993,
            "recall": 0.46652267818574517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.7641048804743799,
            "auditor_fn_violation": 0.013684925143816773,
            "auditor_fp_violation": 0.028316039504938134,
            "ave_precision_score": 0.7128536523654876,
            "fpr": 0.3618421052631579,
            "logloss": 0.723090608803952,
            "mae": 0.42364048236458185,
            "precision": 0.5838587641866331,
            "recall": 0.9429735234215886
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7500460640393415,
            "auditor_fn_violation": 0.011240110670399936,
            "auditor_fp_violation": 0.018111964873765107,
            "ave_precision_score": 0.6911102285206131,
            "fpr": 0.36882546652030734,
            "logloss": 0.720204281867998,
            "mae": 0.43030526270654407,
            "precision": 0.5664516129032258,
            "recall": 0.9481641468682506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8183565607521479,
            "auditor_fn_violation": 0.013783185050201882,
            "auditor_fp_violation": 0.0004219277409676248,
            "ave_precision_score": 0.8186368885479971,
            "fpr": 0.0668859649122807,
            "logloss": 0.6480341620809821,
            "mae": 0.3696834174557045,
            "precision": 0.8063492063492064,
            "recall": 0.5173116089613035
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7874496077977746,
            "auditor_fn_violation": 0.011377618879402928,
            "auditor_fp_violation": 0.0012349066959385297,
            "ave_precision_score": 0.7878062538265163,
            "fpr": 0.05817782656421515,
            "logloss": 0.6723617887205177,
            "mae": 0.37537014956774917,
            "precision": 0.8146853146853147,
            "recall": 0.5032397408207343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7756247513258121,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00339104888111015,
            "ave_precision_score": 0.698887108030938,
            "fpr": 0.45394736842105265,
            "logloss": 0.6825852984168462,
            "mae": 0.43372638209869985,
            "precision": 0.5425414364640884,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7496466665650757,
            "auditor_fn_violation": 0.0006116744469443542,
            "auditor_fp_violation": 0.002670730751136902,
            "ave_precision_score": 0.6732083669994028,
            "fpr": 0.4862788144895719,
            "logloss": 0.7106493992810193,
            "mae": 0.44969660475539325,
            "precision": 0.5104972375690607,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7517921450919659,
            "auditor_fn_violation": 0.01119492978883053,
            "auditor_fp_violation": 0.016999520773430015,
            "ave_precision_score": 0.6833053255398474,
            "fpr": 0.3991228070175439,
            "logloss": 0.743025198470756,
            "mae": 0.43754276997622166,
            "precision": 0.5625,
            "recall": 0.9531568228105907
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7165519636533416,
            "auditor_fn_violation": 0.011664489453357452,
            "auditor_fp_violation": 0.018976889603261736,
            "ave_precision_score": 0.644690349856481,
            "fpr": 0.4313940724478595,
            "logloss": 0.7812233977204381,
            "mae": 0.4576505285848247,
            "precision": 0.5253623188405797,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7740508076501126,
            "auditor_fn_violation": 0.02611257012184229,
            "auditor_fp_violation": 0.002526357461349336,
            "ave_precision_score": 0.6002753097006679,
            "fpr": 0.005482456140350877,
            "logloss": 0.6581480522491238,
            "mae": 0.47566296875868974,
            "precision": 0.9382716049382716,
            "recall": 0.15478615071283094
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.75395545635612,
            "auditor_fn_violation": 0.01608371879097094,
            "auditor_fp_violation": 0.001867061314097538,
            "ave_precision_score": 0.5682948143944716,
            "fpr": 0.005488474204171241,
            "logloss": 0.6627113171987393,
            "mae": 0.4787022131858097,
            "precision": 0.9295774647887324,
            "recall": 0.14254859611231102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.598207840144429,
            "auditor_fn_violation": 0.005911226640940449,
            "auditor_fp_violation": 0.016772929949577027,
            "ave_precision_score": 0.6024514078508171,
            "fpr": 0.1074561403508772,
            "logloss": 0.6727841559352118,
            "mae": 0.48516441647336506,
            "precision": 0.5525114155251142,
            "recall": 0.24643584521384929
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5488353340704081,
            "auditor_fn_violation": 0.0070010645032041845,
            "auditor_fp_violation": 0.008820762113846645,
            "ave_precision_score": 0.554649670480678,
            "fpr": 0.1251372118551043,
            "logloss": 0.6753171401497527,
            "mae": 0.48629812755674745,
            "precision": 0.4977973568281938,
            "recall": 0.24406047516198703
        }
    }
]